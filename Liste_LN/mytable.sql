-- phpMyAdmin SQL Dump
-- version 4.6.6deb5ubuntu0.5
-- https://www.phpmyadmin.net/
--
-- Client :  localhost:3306
-- Généré le :  Dim 21 Février 2021 à 17:24
-- Version du serveur :  10.1.47-MariaDB-0ubuntu0.18.04.1
-- Version de PHP :  7.2.24-0ubuntu0.18.04.7

SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Base de données :  `ideal`
--

-- --------------------------------------------------------

--
-- Structure de la table `mytable`
--

CREATE TABLE `mytable` (
  `id` int(11) NOT NULL,
  `date` date NOT NULL,
  `organisation` varchar(46) DEFAULT NULL,
  `ville` varchar(32) DEFAULT NULL,
  `sujet` mediumtext NOT NULL
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;

--
-- Contenu de la table `mytable`
--

INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(1, '2007-12-22', 'ARISEM', 'Massy', 'Sujet : Etude, spécification et développement d\'un système d\'extraction de\r\nrelations entre entités nommées.\r\n\r\nDate de démarrage : février/mars 2008\r\nDurée : 6 mois\r\nNiveau : Master en TAL\r\n\r\nContexte\r\n--------\r\n\r\nDans le cadre de ses travaux de R&D, Arisem a créé un nouveau moteur\r\nd\'analyse sémantique et d\'extraction d\'information. Afin d\'améliorer\r\nsa pertinence, nous travaillons actuellement sur l\'extraction de\r\nrelations sémantiques entre entités nommées.\r\n\r\nContenu du stage\r\n----------------\r\n\r\nD\'une durée de 6 mois, ce stage est consacré à l\'étude de la\r\nproblématique concernant l\'extraction de relations et des différentes\r\napproches existantes. Par la suite, le stagiaire sera amené à\r\nparticiper au développement des ressources pour l\'acquisition de\r\nrelations à partir d\'un corpus de textes.\r\n\r\nEn collaboration avec les équipes R&D d\'Arisem, le travail du\r\nstagiaire sera découpé en trois phases :\r\n- Compréhension de notre problématique d\'extraction ;\r\n- Etude et compréhension des différentes approches existantes pour\r\nl\'extraction de relations ;\r\n- Participation au développement du système d\'acquisition de relations\r\nentre entités nommées.\r\n\r\nProfil recherché\r\n----------------\r\n\r\nEtudiant en dernière année de master en traitement automatique des\r\nlangues, le candidat doit avoir de bonnes connaissances en\r\ninformatique et des logiciels de traitement automatique des langues\r\n(Unitex, Gate, etc.).\r\n\r\n\r\nLes candidatures sont à adresser à :\r\nnicolas.dessaigne@arisem.com\r\naurelie.migeotte@arisem.com'),
(2, '2008-01-08', 'IGN', 'Saint-Mandé', 'Contexte\r\n\r\nLe laboratoire COGIT travaille à un projet de conception de carte sur\r\nmesure, c\'est-à-dire une carte pertinente et efficace par rapport aux\r\nobjectifs du concepteur et adaptée à ses goûts.\r\n\r\nUn des axes de recherche vise à constituer des bases de connaissances\r\nqui permettront d\'exploiter la description que l\'utilisateur fait de\r\nson besoin pour l\'aider à concevoir sa carte dans les règles de\r\nl\'art. Pour cela, il est nécessaire d\'établir des correspondances\r\nentre la description que des utilisateurs peuvent faire de leur carte\r\net les paramètres de construction d\'une carte tels qu\'ils sont définis\r\npar des experts.\r\n\r\nDifférentes actions ont été mises en place pour faire décrire une\r\ncarte par des publics variés. Ces travaux ont permis d\'ébaucher une\r\ndescription formalisée de carte.\r\n\r\nSujet\r\n\r\nLe stage a pour objectif d\'exploiter un ensemble commenté et organisé\r\nd\'interviews. Ces interviews font partie d\'une enquête réalisée par un\r\nservice de l\'IGN concernant la carte au 1/50 000 par rapport au thème\r\nde la randonnée (à pied, en vélo, en VTT, ...). Il s\'agit de mettre en\r\nforme ce corpus puis de l\'exploiter (manuellement, avec des outils de\r\nTALN et éventuellement des méthodes numériques) afin d\'identifier en\r\nparticulier les acteurs, les activités, les objectifs des acteurs par\r\nrapport aux activités.  Ces éléments permettront de proposer des\r\ncaractéristiques de cartes pertinentes par rapport aux souhaits des\r\nutilisateurs et cohérentes avec le modèle de description de cartes qui\r\nest en cours d\'élaboration dans l\'équipe de recherche.\r\n\r\nCompétences particulières et formation requise\r\n\r\nmaster avec compétences en informatique linguistique, éventuellement\r\nen cartographie.\r\n\r\nUne bonne maîtrise de la langue française est indispensable.\r\n\r\nLieu du stage\r\nInstitut géographique national\r\n2 avenue Pasteur\r\n94160 Saint-Mandé\r\n\r\nDurée et rémunération \r\ndurée : 4 à 6 mois\r\ndébut : mars/avril 2008\r\nrémunération : 30% du SMIC\r\n\r\nResponsable de stage\r\nCatherine DOMINGUES\r\nmel : catherine.domingues@ign.fr\r\nTél : 01 43 98 85 44\r\nhttp://recherche.ign.fr/cogit'),
(3, '2008-01-13', 'LIMSI - CNRS', 'Orsay', 'Titre : Détection d\'expressions figées pour les systèmes de questions-réponses\r\n\r\nDate de démarrage : mars/avril 2008\r\nDurée : 4 mois\r\n\r\nLieu du stage : LIMSI/CNRS, groupe LIR    (91403 Orsay)\r\n\r\nVoir aussi : \r\nhttp://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_expressions_figees.html\r\n\r\nThème  :\r\n\r\nDans le cadre des systèmes de questions-réponses, de recherche\r\nd\'information, mais aussi en analyse syntaxique et dans de nombreux\r\ndomaines, il est intéressant de connaître les expressions figées ou\r\nsemi-figées.  Par exemple, les locutions comme \"pomme de terre\" ou\r\n\"perdre la vie\", mais aussi des entités nommées ou des expressions\r\nlongues comme \"la déclaration universelle des droits de l\'homme et du\r\ncitoyen\".  En recherche d\'information et dans les systèmes\r\nquestions-réponses, connaître ce type de locutions nous permet de\r\ndécider si la requête doit être constituée de l\'expression entière ou\r\nsi les mots doivent être considérés de façon indépendante.\r\n\r\n\r\nDescription  du  stage  :\r\n\r\nDe nombreux travaux ont traité le problème des locutions, mais de\r\nnombreuses imperfections subsistent.  Le but du stage est d\'étudier\r\nl\'état de l\'art en la matière et de mettre en ½uvre une méthode\r\nadaptée au contexte des systèmes de questions-réponses.\r\n\r\n\r\nContacts :\r\nXavier Tannier : xavier.tannier@limsi.fr\r\nVéronique Moriceau : moriceau@limsi.fr\r\n\r\n---------------'),
(4, '2008-01-13', 'LIMSI - CNRS', 'Orsay', '--------------\r\nTitre : Détection et validation de paraphrases en contexte\r\n\r\nDate de démarrage : mars/avril 2008\r\nDurée : 4 mois\r\n\r\nMots-clés : analyse syntaxique, paraphrases, traitement automatique de\r\nla langue, système de questions-réponses\r\n\r\nLieu du stage : LIMSI/CNRS, groupe LIR     ( 91403 Orsay)\r\n\r\nVoir aussi : \r\nhttp://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_paraphrases.html\r\n\r\nContexte  : \r\nDans le domaine de la recherche d\'information, l\'un des défis actuels\r\nporte sur les systèmes de questions-réponses en domaine ouvert.\r\nL\'objectif de ces systèmes est de fournir une réponse à une question\r\nexprimée en langage naturel en trouvant cette réponse dans un ensemble\r\nde documents, ensemble éventuellement très large et pouvant aller\r\njusqu\'au Web.\r\nLa plupart des systèmes de questions-réponses sont à même d\'extraire\r\nla réponse à une question factuelle lorsqu\'elle est explicitement\r\nprésente dans les textes mais dans le cas contraire, ils ne sont pas\r\ncapables d\'agencer différents morceaux d\'information dans le cadre\r\nd\'un raisonnement pour produire une réponse.\r\nPar exemple un raisonnement dans lequel il faut assembler plusieurs\r\nextraits d\'informations répartis dans plusieurs documents ou dans\r\nplusieurs phrases d\'un même document.  Par exemple, pour répondre à la\r\nquestion \"Quel est l\'âge de la femme de Tom Cruise ?\", il faut tout\r\nd\'abord identifier la femme de Tom Cruise puis chercher son âge.\r\nLe projet CONIQUE a pour objectif de pallier cette insuffisance et\r\ns\'inscrit en cela dans un courant de recherche actuellement très actif\r\nvisant à intégrer dans les systèmes de questions-réponses des\r\nmécanismes de compréhension de textes s\'appuyant sur des inférences.\r\nContrairement à la plupart des travaux allant dans ce sens, le premier\r\naxe de notre projet a pour but non pas de constituer ou d\'exploiter\r\nune base de connaissances a priori permettant de répondre aux\r\nquestions mais de modéliser l\'extraction de ces connaissances à partir\r\nde différents textes en fonction des besoins nécessaires à la\r\nconstruction d\'un chemin inférentiel entre les éléments trouvés dans\r\nles textes et l\'information cherchée, telle qu\'elle est spécifiée par\r\nune question.\r\n\r\n\r\nThème  :\r\nLes analyseurs syntaxiques sont des outils de traitement automatique\r\nde la langue permettant d\'identifier les relations syntaxiques entre\r\nles constituants d\'une phrase (SUJET, OBJET, etc.).  Ils fournissent\r\ndes sorties dans un format qui leur est propre.\r\nDans le cadre de ce projet, on utilise un analyseur syntaxique pour\r\ndéterminer si un passage pré-sélectionné par un moteur de recherche\r\nrépond réellement à la question de l\'utilisateur.  On cherche\r\nnotamment à montrer que certaines relations syntaxiques (ou\r\néventuellement sémantiques) présentes dans des passages sont (ou ne\r\nsont pas) équivalents aux relations présentes dans la question.  Par\r\nexemple, la question pourra porter sur le nombre de personnes ayant\r\n\"perdu la vie\" lors d\'un événement, tandis que le passage précise que\r\ncet événement \"a fait X morts\".  Cet aspect se rapproche de la\r\nproblématique de la recherche de paraphrases.\r\n\r\nTravail  à  réaliser  : \r\nLe but du stage est d\'étudier l\'état de l\'art en la matière, de\r\nréfléchir aux avantages de se situer dans un contexte précis (les\r\npassages) plutôt que dans un cadre général (ce que fait la\r\nlittérature), ainsi que de mettre en place des techniques de\r\nvalidation des paraphrases.\r\n\r\nContacts :\r\nXavier Tannier : xavier.tannier@limsi.fr\r\nVéronique Moriceau : moriceau@limsi.fr\r\n\r\n---------------'),
(5, '2008-01-16', 'ARISEM', 'Massy', 'Sujet : Enrichissement des ressources linguistiques pour l\'extraction\r\nd\'entités nommées\r\n\r\nDate de démarrage: février/mars 2008 \r\nDurée: 6 mois\r\nNiveau: Master en TAL\r\n\r\nContexte\r\n--------\r\n\r\nDans le cadre de ses travaux de R&D, Arisem a créé un nouveau moteur\r\nd\'analyse sémantique et d\'extraction d\'information. L\'approche choisie \r\ns\'appuie sur l\'utilisation conjointe de différents types de ressources\r\nlinguistiques (dictionnaires, grammaires, ontologies, expressions\r\nrégulières, etc.).\r\n\r\nContenu du stage\r\n----------------\r\n\r\nD\'une durée de 6 mois, ce stage est consacré à la mise à jour et\r\nl\'enrichissement des ressources linguistiques dédiées à l\'allemand, le\r\nnéerlandais, l\'italien et le portugais.\r\n\r\nEn collaboration avec les équipes R&D d\'Arisem, le stagiaire aura pour \r\nobjectifs principaux la création et l\'enrichissement des ressources\r\nsuivantes:\r\n- Dictionnaires de langue générale et dictionnaires orientés métier;\r\n- Grammaires locales d\'extraction d\'entités nommées; \r\n- Ontologies métier.\r\n\r\nDans le cadre de son travail, le stagiaire sera également amené à:\r\n- Participer à l\'amélioration de l\'éditeur de ressources linguistiques;\r\n- Créer des corpus de test et des corpus annotés pour permettre \r\nl\'évaluation des ressources et des traitements.\r\n\r\nProfil recherché\r\n----------------\r\n\r\nEtudiant en dernière année de master en traitement automatique des\r\nlangues, le candidat doit être bilingue dans l\'une des langues \r\nsuivantes: allemand, néerlandais, italien ou portugais.\r\n\r\nLa maîtrise des outils Unitex ou Nooj et des compétences en\r\ninformatique (perl, commandes unix) sont appréciées.\r\n\r\n\r\nLes candidatures sont à adresser à : \r\nnicolas.dessaigne@arisem.com <mailto:nicolas.dessaigne@arisem.com>\r\naurelie.migeotte@arisem.com <mailto:aurelie.migeotte@arisem.com>\r\n---\r\nNicolas Dessaigne,\r\nDirecteur technique\r\nArisem'),
(6, '2008-01-21', 'LIMSI - CNRS', 'Orsay', 'Le groupe LIR du LIMSI (Orsay) propose le stage suivant en traduction\r\nautomatique:\r\n\r\n\"Un peu de contexte en traduction automatique : exploitation de\r\nrelations grammaticales en traduction automatique statistique\"\r\n\r\nMots clés      : traduction automatique, traitement automatique des\r\n                 langues, analyse syntaxique, désambiguïsation\r\n                 lexicale\r\nNiveau d\'étude : Master Recherche ou fin d\'école d\'ingénieurs en\r\n                 informatique\r\nDurée du stage : 4 mois à partir de mars 2008\r\nLieu du stage  : laboratoire LIMSI-CNRS, Orsay (RER ligne B)\r\nDescription    : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2R-2008.html\r\nContact        : aurelien.max@limsi.fr\r\n\r\nRésumé :\r\nLa traduction automatique a connu un nouvel essor avec l\'émergence\r\nd\'approches basées sur des corpus. La traduction automatique\r\nstatistique connaît toutefois des limites. Des approches récentes\r\nessaient donc d\'intégrer des connaissances linguistiques dans ces\r\nsystèmes afin de mieux prendre en compte les caractéristiques des\r\ntextes à traduire, de leur traduction, et des relations qu\'ils\r\nentretiennent.\r\n\r\nLes systèmes actuels en traduction automatique statistique se basent\r\nsur une segmentation en groupes de mots des phrases à traduire\r\nauxquels sont associées des traductions (phrase-based machine\r\ntranslation). Les modèles utilisés pour guider la recherche de la\r\nmeilleure traduction se concentrent essentiellement sur les relations\r\nde traduction et sur une bonne formation locale de la langue\r\ncible. L\'objet de ce stage est de travailler sur la prise en compte\r\nd\'informations linguistiques présentes dans la langue source, afin de\r\nmodéliser le contexte dans lequel apparaissent les groupes de mots à\r\ntraduire. On s\'intéressera notamment à l\'exploitation des relations\r\ngrammaticales entre les mots pour la paire de langue français-anglais.'),
(7, '2008-01-21', 'IBISC - Université d\'Evry', 'Evry', 'Proposition de stage à l\'IBISC :\r\nSujet de stage : Aide à l\'annotation d\'articles scientifiques\r\n\r\nContexte\r\nQKDB (http://physiome.ibisc.fr/qkdb) est une base de données sur la\r\nphysiologie du rein, qui décrit 300 articles scientifiques. Les\r\ninformations contenues dans cette base donnent, pour chaque article,\r\ndes détails sur les expériences et les résultats décrits dans\r\nl\'article : espèce concernée, organe, différentes mesures\r\neffectuées... Ces informations ont été introduites manuellement dans\r\nla base, après lecture de chacun des articles par un expert du\r\ndomaine.\r\n\r\nSujet\r\nL\'objet du stage est l\'aide à l\'annotation d\'articles scientifiques\r\npour l\'intégration dans la base de données QKDB en repérant\r\nautomatiquement les éléments du texte qui décrivent les informations à\r\najouter dans la base. A cette fin, il s\'agit de constituer une base de\r\nréférence contenant les textes dans lesquels seront annotés les\r\néléments déjà présents dans la base QKDB. En effet, actuellement, on\r\nretrouve les articles qui répondent à une requête, mais on ne sait pas\r\noù l\'information est donnée dans l\'article.\r\n\r\nIl s\'agira ainsi de revenir au texte à partir des informations de la\r\nBD en :\r\n- transformant les articles de pdf en texte. On partira d\'outils \r\n  existants qu\'il faudra améliorer ;\r\n- projetant les données de la BD dans les textes, en utilisant là\r\n  aussi des outils existants (reconnaissance d\'entités numériques et\r\n  reconnaissance de termes) afin de reconnaître la manière dont les\r\n  attributs et les valeurs de la base sont formulés dans les textes.\r\n\r\nLa base de référence ainsi constituée devra permettre de mettre en\r\nplace un outil d\'extraction automatique des données sur la physiologie\r\ndu rein.\r\n\r\nInformations pratiques\r\nLieu du stage : IBISC, Tour Evry2, Evry \r\n(http://www.ibisc.univ-evry.fr/), équipe AMISBIO (http://amisbio.ibisc.fr)\r\nResponsables : Brigitte Grau, Anne-Laure Ligozat\r\nDurée : 5 mois\r\nNiveau : M2 ou dernière année d\'école d\'ingénieur\r\nStage rémunéré'),
(9, '2008-02-06', 'Syllabs', 'Paris', 'Proposition de stages au sein de la société Syllabs\r\n---------------------------------------------------\r\n\r\nLa société : Syllabs est un jeune laboratoire de recherche privé\r\nspécialisé dans les domaines de la Gestion de l\'Information et du\r\nTraitement Automatique des Langues.  Syllabs est au coeur de trois\r\nactivités complémentaires : La Recherche, les Développements Innovants\r\net le Conseil.\r\n\r\nPour plus d\'infos : www.syllabs.com\r\n\r\nNous recrutons 2 stagiaires :\r\n- 1 linguiste TAL\r\n- 1 linguiste-informaticien(ne)\r\n\r\nSi vous êtes intéressé(e) par l\'un de ces stages, merci d\'envoyer\r\nvotre CV accompagné d\'une lettre de motivation à l\'adresse\r\njobs@syllabs.com\r\n\r\nSyllabs est situé dans le 5ème arrondissement :\r\n62 bis rue Gay Lussac\r\n75005 Paris\r\nTel : 01.75.00.02.80\r\n\r\nAccès :	RER B (Luxembourg) / Bus 21, 27\r\n\r\n\r\n****************************\r\nLINGUISTE TAL\r\n****************************\r\n\r\n* Contexte :\r\n\r\nAnalyse de plagiats et analyse des opinions\r\n\r\n* Sujet du stage :\r\n\r\nAide à la constitution d\'une typologie des transformations des textes\r\net étiquetage d\'un corpus de plagiats + Analyse des opinions et\r\nconstitution de lexiques\r\n\r\n* Objectifs du stage :\r\n\r\nLa personne recrutée pour ce stage mènera deux tâches en parallèle.\r\nLa première est liée au projet Piithie (projet ANR débuté en\r\n2007). Elle concerne la validation et la modification d\'une typologie\r\ndes transformations des textes et l\'étiquetage d\'un corpus de plagiats\r\nd\'une manière fine afin de tester ladite typologie et de constituer un\r\ncorpus de test.\r\nLa seconde se fera dans le cadre du projet RPM2 (projet ANR débuté en\r\n2008) et concernera l\'analyse des opinions. Les travaux consisteront\r\nen un état de l\'art et en la production d\'un lexique simple et d\'un\r\nlexique ouvert (formes non figées).\r\nLa personne travaillera avec des informaticiens et des linguistes et\r\nparticipera aux réunions projet avec les différents partenaires\r\n(entreprises et laboratoires publics).\r\n\r\n* Niveau souhaité : Linguiste TAL Bac+4/Bac+5 - Master\r\n\r\n* Durée : 4-6 mois\r\n\r\n****************************\r\nLINGUISTE-INFORMATICIEN(NE)\r\n****************************\r\n\r\n* Contexte :\r\n\r\nLa création et la gestion de ressources linguistiques prend énormément\r\nde temps. Syllabs développe des outils permettant d\'aider le linguiste\r\ndans cette tâche. De nombreux outils et interfaces sont à développer\r\ndans ce contexte.\r\n\r\n* Sujet du stage :\r\n\r\nAide aux linguistes pour la création et la gestion de ressources\r\nlinguistiques\r\n\r\n* Objectifs du stage :\r\n\r\nLa personne recrutée pour ce stage aura pour tâche de concevoir,\r\nimplémenter et tester des méthodes permettant d\'aider le linguiste\r\ndans sa tâche. Le gros du travail sera centré sur les ressources\r\nlexicales (morphosyntaxiques, thématiques, etc.).\r\nElle participera à la création d\'un formalisme de description des\r\ninformations linguistiques qui s\'insère dans un formalisme de\r\ndescription plus large.\r\nLe stage pourra déboucher sur une thèse avec un sujet plus ou moins\r\nproche (Syllabs devrait débuter deux thèses, fin 2008, sur des sujets\r\nà définir).\r\n\r\n* Connaissances et niveau souhaités :\r\n\r\nLinguistique Informatique, Bac+5 - Master 2\r\n\r\n- Très bonnes connaissances dans les domaines du Traitement\r\n  Automatique des Langues et de la Gestion de l\'information.\r\n- Très bonne maîtrise d\'un langage de script : Perl ou Python\r\n\r\n- Eléments facultatifs mais considérés comme un plus :\r\n	- maîtrise d\'une ou plusieurs langues étrangères\r\n	- maîtrise de Java\r\n	- désir de faire une thèse\r\n\r\nDurée : 6 mois\r\n\r\n-- \r\n\r\n---------------------------------------------------\r\nChristelle Ayache\r\nChef de projet - Syllabs\r\n62 Bis rue Gay Lussac 75005 Paris\r\nTel : +33 (0)1 75 00 02 80\r\nCourriel : ayache@syllabs.com\r\nSite Web : www.syllabs.com\r\n---------------------------------------------------'),
(10, '2008-02-11', 'SPIM - Paris 5', 'Paris', 'Proposition de stage M2 \r\n\r\nADAPTATION DE TERMINOLOGIES EXISTANTES AU TRAVERS DE CORPUS\r\n\r\nNatalia Grabar (natalia.grabar@spim.jussieu.fr)\r\nSPIM - Centre de Recherche des Cordeliers ; U Paris Descartes, UMR_S 872 ;\r\nINSERM, U872 ; HEGP AP-HP\r\n\r\nContexte\r\n\r\nPlusieurs terminologies existent dans le domaine biomédical et\r\nproposent des descriptions de la biologie ou de la médecine. Ces\r\nterminologies ont deux caractéristiques principales : 1. Elles sont\r\nspécifiques aux applications : MeSH (NLM, 2001) pour la recherche\r\nd\'information, MedDRA (Brown et al., 1999) pour la description des\r\neffets indésirables des médicaments, GO (Gene Ontology Consortium,\r\n2000) pour l\'annotation fonctionnelle des gènes, ...  2. Elles sont\r\ngénéralistes de domaines médical ou biologique : elles visent à en\r\nproposer une description aussi exhaustive que possible.\r\n\r\nDu fait de leur spécificité (1), leur utilisation est plus aisée dans\r\ndes applications. Quant à leur nature généraliste (2), cela correspond\r\nà un réel besoin mais peut présenter une limite lorsque l\'on travaille\r\navec des données d\'une seule spécialité médicale (cardiologie,\r\nstomatologie) ou même avec des données relatives à un questionnement\r\nmédical plus précis (diagnostic de métastases hépatiques du cancer\r\ncolorectal). Dans ce dernier cas surtout, il pourrait être intéressant\r\nd\'avoir une ressource terminologique adaptée à la question médicale.\r\n\r\nObjectifs\r\n\r\nLe coût nécessaire à l\'élaboration de ressources terminologiques étant\r\nélevé, nous proposons d\'aborder cette problématique en termes\r\nd\'adaptation de terminologies. L\'objectif du stage consiste à\r\nimplémenter et tester une méthodologie qui permettrait d\'adapter les\r\nterminologies existantes, au travers des corpus, à une question\r\nmédicale précise.\r\n\r\nLe matériel principal de travail sont des mots-clés centraux pour une\r\nquestion, par exemple: \"colorectal neoplasms\" ; \"liver neoplasms\" ;\r\n\"laparoscopy\" ; \"tomography, emission-computed\" ; \"magnetic resonance\r\nimaging\" ; \"tomography, x-ray computed\" pour la question diagnostic de\r\nmétastases hépatiques du cancer colorectal. Ce matériel servira\r\nd\'amorce pour la constitution de corpus (articles scientifiques) et de\r\npoints d\'entrée dans les terminologies (p.ex. l\'UMLS (NLM, 2007) qui\r\npropose plus de 140 terminologies biomédicales). Le stagiaire\r\nutilisera des outils d\'acquisition (Bourigault & Jacquemin, 2000) et\r\nstructuration (Grabar & Hamon, 2004) des terminologies. Le\r\ndéveloppement en Perl (sous Linux/Unix) sera demandé lors de\r\ndifférentes étapes de la méthodologie.\r\n\r\nDéroulement du stage\r\n\r\nLe stage sera encadré par un chercheur en informatique biomédicale et\r\nen TAL, et co-encadré par un médecin. Il s\'agit d\'un stage de 6 mois\r\nrémunéré. Il se déroulera au Centre de Cordeliers (Paris 6). Un CV et\r\nune lettre de motivation sont à envoyer à Natalia Grabar.\r\n\r\nRéférences \r\n\r\nBOURIGAULT, D. & JACQUEMIN , C. (2000). Construction de ressources\r\nterminologiques, In J.-M. PIERREL, Ed., Industrie des langues,\r\npp. 215­233.\r\n\r\nBROWN , E., WOOD , L. & WOOD , S. (1999). The medical dictionary for\r\nregulatory activities (MedDRA). Drug Saf., 20(2), 109­17.\r\n\r\nGENE ONTOLOGY CONSORTIUM (2000). Gene Ontology : tool for the\r\nunification of biology. Nature genetics, 25, 25­29.\r\n\r\nGRABAR , N. & HAMON , T. (2004). Les relations dans les terminologies\r\nstructurées : de la théorie à la pratique. Revue d\'Intelligence\r\nArtificielle (RIA), 18(1).\r\n\r\nNLM (2001). Medical Subject Headings. National Library of Medicine,\r\nBethesda, Maryland. http://www.nlm.nih.gov/mesh/ meshhome.html.\r\n\r\nNLM (2007). UMLS Knowledge Sources Manual. National Library of\r\nMedicine, Bethesda, Maryland. www.nlm.nih.gov/research/umls/.'),
(12, '2008-03-17', 'EDF', 'Clamart', 'Stage Moteur de recherche à EDF\r\n=============================\r\n\r\nContexte\r\n\r\nLe Département Internet de la Direction Informatique et Telecom a en\r\ncharge la promotion des nouvelles technologies au sein d\'EDF. Afin de\r\nmener à bien cette mission il a la responsabilité d\'un certain nombre\r\nd\'Etudes d\'Interêt Général dont l\'objectif est d\'avoir un regard sur\r\nles solutions qu\'il sera pertinent d\'inclure dans le catalogue des\r\nsolutions référencées de l\'entreprise. Ces études comportent\r\ngénéralement cinq phases\r\n\r\n· spécification fonctionnelle du besoin en collaboration avec une\r\n  maîtrise d\'ouvrage identifiée, cette phase comprend si nécessaire un\r\n  maquettage, une étude ergonomique\r\n\r\n· spécification technique : définition de l\'architecture technique,\r\n  choix des outils...\r\n\r\n· réalisation : paramétrage/développement\r\n\r\n· mise en ½uvre pouvant aller jusqu\'à un pilote représentatif déployé\r\n  sur des utilisateurs.\r\n \r\n· retour d\'expérience pour prise de décision.\r\n\r\nLe stage proposé ci-dessous s\'inscrit dans cette dynamique, il est\r\nprévu pour une durée minimale de 3 mois extensibles à 6 mois. Le\r\nstagiaire sera intégré dans les équipes du Département qui dispose de\r\ntoutes les compétences pour guider le stagiaire dans son travail. Le\r\nstage débute dés que possible à partir de mars 2008.\r\n\r\nSujet de stage\r\n\r\nLa disponibilité d\'un moteur de recherche pertinent, transverse,\r\nindexant tous les fonds documentaires utiles et respectant les droits\r\nd\'accès est une nécessité dans l\'entreprise d\'aujourd\'hui.\r\n\r\nUne solution spécifique pour la recherche des documents stockés sur le\r\nposte local doit être trouvée. Le moteur de recherche de Vista\r\napportera en effet un premier niveau de services, mais ne permettra\r\npas la recherche en mode déconnecté dans les bases Quickr (outil de\r\ntravail collaboratif retenu par EDF) ni la recherche sur les bases\r\nNotes e-mail ou les bases documentaires personnelles des utilisateurs.\r\n\r\nEDF dispose dans son catalogue de solution de l\'outil K2 (Verity) de\r\nla société Autonomy. Ce moteur de recherche est mis en place sur\r\ncertains Intranet ou Internet de l\'entreprise.\r\n\r\nLe stage consiste en :\r\n\r\n· La vérification de la pertinence de K2 sur les fonds actuellement\r\n  indexé,\r\n\r\n· La possibilité d\'étendre K2 à d\'autres fonds (Quickr, bases Notes,\r\nposte local,...)\r\n\r\n· Une étude des nouvelles solutions disponibles sur le marché (Google,\r\n  Sinequa, Exalead) à la fois sur le poste de travail mais aussi au\r\n  niveau serveur. Cette étude pourra aborder également aborder des\r\n  sujets connexes tels que la catégorisation automatique, la recherche\r\n  de contenus non textuels, la recherche cross-langage, la veille\r\n  technologique.\r\n\r\nCompétences requises\r\n· Connaissance informatique généraliste\r\n· Bonne autonomie, aptitude à rendre compte de son travail\r\n· Rigueur dans lanalyse des résultats et la comparaison des solutions\r\n\r\nLieu du stage\r\nEDF-DIT, 1 avenue du Général de Gaulle 92141 Clamart\r\n\r\nContact : Cécile Gros\r\ncecile.gros@edfgdf.fr\r\n01 47 65 59 92'),
(13, '2008-06-24', 'LCI', 'Lannion', 'OFFRE DE STAGE LINGUISTIQUE LANNION (22)\r\n\r\nGroupe spécialisé en communication technique multilingue propose un\r\nstage en linguistique, au sein d\'une équipe internationale à Lannion\r\npour des étudiants en Master I ou II de TALN ou Sciences du langage.\r\n\r\nContenu du stage (encadré par linguiste expérimenté) :\r\n\r\n- Participation à un projet sur le langage SMS associé à des icônes :\r\n  validation et enrichissement d’un lexique\r\n\r\n- Correction de requêtes internet\r\n\r\nProfil des stagiaires :\r\nLangue maternelle française.\r\nNiveau Master 1 ou 2.\r\nQualités requises : orthographe parfaite, rigueur, autonomie, bon\r\ncontact humain.\r\nLa connaissance des outils utilisés en TALN (scripts, perl) est un\r\nplus.\r\n\r\nDates : de début juillet à fin août 2008 environ\r\n\r\n\r\nContact : envoyez votre CV par E-mail à\r\nbrigitte.ororke@lci-bretagne.com \r\nwww.lci-europe.com'),
(14, '2008-06-24', 'LCI', 'Lannion ou télétravail', 'STAGE en LINGUISTE INFORMATIQUE - LANNION (22) ou à distance\r\n\r\nGroupe spécialisé en communication technique multilingue recherche un\r\nlinguiste informaticien pour un stage de recherche :\r\n\r\n\r\nDescriptif de la mission principale :\r\n\r\n- Exploitation de bases de données phraséologiques bilingues ou\r\n  multilingues dans le but de générer automatiquement des paraphrases\r\n  pour des applications vocales (serveurs vocaux).\r\n\r\n- Stage soit de 3 mois sur site à Lannion (Bretagne 22), soit en\r\n  partie à temps partiel à distance en parallèle à une année d’études\r\n  et en partie en local, dates à discuter.\r\n\r\nProfil recherché :\r\n\r\nEtudiant en linguistique informatique niveau Bac + 4 minimum (orienté\r\nrecherche)\r\nInformatique : être à l\'aise avec les outils de manipulations de\r\nfichiers (scripts, perl, python, ...). Une bonne connaissance de Linux\r\nest un plus..  Qualités requises : goût pour la recherche, curiosité,\r\nrigueur, autonomie, bon contact humain\r\nLangues : Français courant, anglais lu\r\n\r\nContact : envoyez votre CV et lettre de motivation par E-mail à\r\nbrigitte.ororke@lci-bretagne.com\r\n\r\nhttp://www.lci-europe.com'),
(15, '2009-01-06', 'IGN', 'Saint-Mandé', 'Etude contrastive de corpus de cours de cartographie           \r\nhttp://recherche.ign.fr/labos/cogit/\r\n\r\nMots-clés\r\n\r\nTALN, fouille de textes, extraction d\'informations, cartographie,\r\nsémiologie graphique\r\n\r\n \r\n\r\nContexte\r\n\r\nLe laboratoire COGIT travaille à un projet de conception de carte sur\r\nmesure, c\'est-à-dire une carte pertinente et efficace par rapport aux\r\nbesoins et objectifs du concepteur.\r\n\r\nUn des axes de recherche vise à constituer une base de connaissances\r\n(en particulier une ontologie des termes de la conception d\'une\r\nlégende et une base de règles qui s\'appuie sur cette ontologie) qui\r\npermettra d\'exploiter la description que l\'utilisateur fait de son\r\nbesoin pour l\'aider à concevoir sa carte dans les règles de l\'art.\r\n\r\nLa construction d\'un système graphique cohérent de signes est régie\r\npar les règles de la sémiologie graphique. L\'enseignement de la\r\ncartographie est fondé sur la sémiologie graphique mais les manuels et\r\nles enseignements de cartographie se spécialisent généralement sur un\r\ncertain type de carte.\r\n\r\nDans ce contexte, nous souhaitons analyser, pour les intégrer, les\r\nprincipes de représentation cartographique tels qu\'ils sont enseignés\r\ndans différentes formations. Nous souhaitons en déduire un ensemble\r\ncohérent de règles de représentation cartographique pour répondre au\r\nbesoin de tout utilisateur.\r\n\r\n \r\n\r\nSujet\r\n\r\nLe stage a pour objectif de comparer les règles de représentation des\r\ninformations en réalisant une étude contrastive de deux corpus. L\'un\r\nest la version électronique du manuel de cartographie utilisé à l\'ENSG\r\nqui détaille particulièrement la fabrication de cartes topographiques\r\n; l\'autre est l\'ensemble des notes de cours (version électronique)\r\nd\'un enseignement en cartographie de l\'université, ciblé sur les\r\ncartes thématiques.\r\n\r\nNous nous intéressons aux modes opératoires de construction de la\r\ncarte, l\'ordre des étapes, les concepts (en relation avec notre\r\nontologie) sur lesquels s\'appuient ces modes opératoires et leurs\r\narticulations, les principes de représentation (en relation avec notre\r\nbase de règles).\r\n\r\nPar cette comparaison, nous souhaitons analyser la complémentarité de\r\nces approches et les intégrer dans notre base de connaissances. Cette\r\nétude devra aussi permettre de caractériser une carte topographique et\r\nune carte thématique réussies.\r\n\r\nCette étude contrastive utilisera des outils de traitement automatique\r\ndu langage naturel (TALN).\r\n\r\n \r\n\r\nCompétences particulières et formation requise\r\n\r\nmaster (de préférence M2) avec compétences en TALN, informatique,\r\néventuellement en cartographie.\r\n\r\nUne bonne maîtrise de la langue française est indispensable.\r\n\r\n \r\n\r\nLieu du stage\r\n\r\nInstitut géographique national\r\n\r\n2 avenue Pasteur\r\n\r\n94160 Saint-Mandé\r\n\r\n \r\n\r\nDurée et rémunération \r\n\r\ndurée : 4 à 5 mois\r\n\r\ndébut : mars/avril 2009\r\n\r\nrémunération : 30% du SMIC\r\n\r\n \r\n\r\nProlongements éventuels\r\n\r\nLe COGIT propose chaque année des sujets de thèse ainsi que des stages\r\nde post-doctorant.\r\n\r\n \r\n\r\nResponsable de stage\r\n\r\nCatherine DOMINGUES\r\n\r\nmel : catherine.domingues@ign.fr\r\n\r\nTél : 01 43 98 85 44'),
(16, '2009-01-13', 'LIMSI', 'Orsay', 'Le groupe Traitement du Langage Parlé\r\n(http://www.limsi.fr/tlp/index.html) du LIMSI-CNRS propose plusieurs\r\nstages de master recherche, professionel, ou ingénieurs. Vous\r\ntrouverez les descriptifs de ces propositions à l\'adresse suivante :\r\n\r\nhttp://www.limsi.fr/tlp/stages/index.html.\r\n\r\nN\'hésitez pas à faire circuler cette information et à nous contacter\r\npar mail pour des informations complémentaires. Les personnes\r\nintéressées par l\'une ou l\'autre de ces propositions sont invitées à\r\ncontacter les responsables (de préférence par courrier électronique)\r\nen joignant un CV et en précisant le ou les sujets concernés.\r\n\r\n\r\nDescription des activités du groupes :\r\n\r\nLes recherches du groupe Traitement du Langage Parlé du LIMSI-CNRS ont\r\npour principaux objectifs de modéliser la parole et concevoir des\r\nalgorithmes pour son traitement automatique. Les activités du groupe\r\nsont par essence pluridisciplinaires, elles abordent le traitement de\r\nla parole d\'un point de vue acoustique, phonétique, linguistique et\r\ninformatique. Elles s\'intéressent également au lien entre parole et\r\nsens, ainsi que la modélisation des processus de communication orale.\r\n\r\nLe besoin de confronter nos modèles aux données nous amène à\r\ndévelopper des systèmes de traitement du langage parlé assurant des\r\nfonctions variées telles que la reconnaissance de la parole,\r\nl\'identification de la langue, du locuteur et de son état émotionnel,\r\nle dialogue oral homme-machine, la structuration de documents\r\naudiovisuels, et plus récemment la traduction de la parole.'),
(17, '2009-01-16', 'Temis', 'Paris', '*Sujet du stage : * CRFs pour l\'extraction d\'entités/relations dans\r\ndes textes\r\n\r\n*Lieu :* société Temis, Paris et Lifo (Laboratoire d\'Informatique\r\nFondamentale d\'Orléans)\r\n\r\n*A destination de :* étudiants en M2 recherche informatique ou TALN,\r\nintéressés par l\'apprentissage automatique et/ou le traitement\r\nautomatique du langage\r\n\r\n*Stage rémunéré pouvant donner lieu à une bourse de thèse Cifre*\r\n\r\nLa société Temis édite une solution logicielle pour traiter les\r\ndocuments textuels. Elle est capable de les classer suivant leur\r\nlangue ou leur domaine, d\'en extraire les « entités » importantes et\r\nde caractériser les relations prédicatives qu\'entretiennent ces\r\nentités entre elles.\r\n\r\nLe module d\'extraction est réalisé à l\'aide de règles écrites à la\r\nmain.  Ces règles sont spécifiques de la langue des documents et du\r\ndomaine sur lequel ils portent, elles peuvent donc être longues et\r\nfastidieuses à écrire. Or, des techniques d\'apprentissage automatique\r\nexistent depuis quelques années pour apprendre à extraire de\r\nl\'information à partir d\'exemples (ce sujet a par exemple donné lieu à\r\nla « shared task » de CoNLL 2003, 17 compétiteurs y ont\r\nparticipé). Plusieurs approches différentes possibles peuvent être\r\nmises en oeuvre pour cela : celles qui donnent actuellement les\r\nmeilleurs résultats sont fondées sur les CRFs (Conditional Random\r\nFields), un modèle statistique permettant d\'annoter des items lexicaux\r\navec des labels qui désignent les zones à extraire.\r\n\r\nL\'objectif de ce stage est de tester cette méthode sur un corpus de\r\ndocuments. Différentes étapes seront donc nécessaires :\r\n\r\n- Il faudra dans un premier temps constituer un corpus d\'exemples et\r\n  l\'annoter pour servir de base à l\'apprentissage automatique. L\'outil\r\n  final de Temis peut servir à réaliser cette base, mais comme il ne\r\n  produit pas une extraction parfaite, des stratégies d\'amélioration\r\n  de l\'annotation initiale devront être envisagées.\r\n\r\n- Il s\'agira ensuite de fixer les paramètres de l\'apprentissage. Les\r\n  CRFs requièrent notamment la définition d\'un ensemble de « fonctions\r\n  features » qui caractérisent des configurations locales\r\n  d\'annotations..  La définitions de ces features est laissée à\r\n  l\'initiative du programmeurs, mais des méthodes classiques existent\r\n  pour les générer à partir des données annotées. Or Temis dispose\r\n  aussi de ressources linguistiques sous la forme de dictionnaires ou\r\n  de règles écrites à la main. Le coeur du stage sera d\'étudier dans\r\n  quelle mesure ces ressources peuvent être traduites sous la forme de\r\n  features, de façon aussi automatique que possible.\r\n\r\n- Il faudra ensuite procéder à diverses expériences pour évaluer la\r\n  qualité de l\'extraction obtenue par apprentissage automatique, et la\r\n  comparer avec celle obtenue par les règles écrites à la main. Cette\r\n  qualité peut dépendre grandement de la langue et du domaine du\r\n  document, ainsi que de l\'ensemble des features utilisées pour\r\n  l\'apprentissage.\r\n\r\n- Ce qui est attendu à l\'issue de ce stage est la définition d\'une\r\n  chaîne de traitements mèlant production manuelle de ressources et\r\n  apprentissage automatique, qui optimise la qualité de l\'extraction\r\n  finale.\r\n\r\n*Ref bibliographiques :*\r\n\r\nDaelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.\r\nJousse F., Tellier I., Tommasi M., Marty P. : « Learning to Extract\r\nAnswers in Question Answering: Experimental Studies », Coria 2005,\r\np85-99.\r\nLafferty J., McCallum A., Pereira F. : « Conditional Random Fields:\r\nProbabilistic Models for Segmenting and Labeling Sequence Data »,\r\nactes de ICML, pages 282-289, 2001.\r\nPoibeau, T : Extraction Automatique d’Information, Hermes, Paris,\r\n2003.\r\nSutton , McCallum A : « An Introduction to Conditional Random Fields »\r\ndans « Introduction to Statistical Learning », MIT Press, 2006.\r\n\r\n*Encadrement universitaire :* Isabelle Tellier, professeur à\r\nl\'université d\'Orléans'),
(18, '2009-01-21', 'Syllabs', 'Paris', 'CONTEXTE\r\n--------\r\n\r\nOutil d’aide aux linguistes pour le développement de ressources\r\nlinguistiques.\r\n\r\nSUJET DE STAGE\r\n---------------\r\n\r\nConception et implémentation d’un agent intelligent dédié à\r\nl’aspiration de contenu textuel du web, destiné à alimenter les\r\nressources linguistiques multilingues existantes.\r\n\r\nOBJECTIFS DU STAGE\r\n-------------------\r\n\r\nLa personne recrutée pour ce stage aura comme tâche principale la\r\nconception et le développement d’un agent intelligent dédié à\r\nl’aspiration de contenu textuel du web. Cet agent se situe dans un\r\ncontexte plus large au sein de la société Syllabs, qui est celui de\r\nmise en place d’outils d’aide aux linguistes pour le développement et\r\nmaintenance de ressources linguistiques multilingues. L’un des aspects\r\nclés des applications en Traitement Automatique de Langues est lié à\r\nla qualité de ressources linguistiques sur lesquelles celles-ci\r\ns’appuient. A priori les ressources sont toujours perfectibles, mais\r\nson enrichissement et raffinement est un processus coûteux et parfois\r\nassez fastidieux pour les linguistes. Dans le scénario d’utilisation\r\nprévu, pour une ressource déterminée, un linguiste définit l’ensemble\r\nde critères d’enrichissement de la ressource. L’agent interprète cette\r\nspécification, dont le formalisme est à définir, et établit des\r\nstratégies d’aspiration appropriées. Un mécanisme d’apprentissage fait\r\névoluer ces stratégies suivant deux paramètres : les résultats\r\nd’aspiration et l’exploitation réalisée par les linguistes du contenu\r\naspiré.\r\n\r\nLe stage nécessite une aisance avec les agents intelligents aussi bien\r\nqu’une connaissance de divers outils de TAL (détecteurs de langue,\r\ndétecteurs d’encodage, KWIC, POS guessers, etc.). En même temps, un\r\nsoin particulier doit être accordé aux aspects techniques de l’agent,\r\ncomme la répartition de la charge de travail sur plusieurs machines et\r\nle stockage du contenu textuel avec une accessibilité par langue, par\r\nressource, par utilisateur, entre autres. La personne travaillera avec\r\ndes informaticiens et des linguistes.\r\n\r\nCONNAISSANCES ET NIVEAU SOUHAITÉS\r\n-----------------------------------\r\n\r\n- Ingénierie Informatique, Bac+5 - Master 2\r\n- Connaissances des concepts liés aux agents intelligents ; goût pour\r\n  la modélisation de connaissances\r\n- Bonne maîtrise du langage Java et d’un langage de script\r\n- Bonnes connaissances dans les domaines du Traitement Automatique des\r\n  Langues\r\n\r\nEléments facultatifs mais considérés comme un plus :\r\n\r\n- Maîtrise d\'une ou plusieurs langues étrangères\r\n- Connaissance d’Apache Tomcat et des services web (WSDL, XML, etc.)\r\n\r\nDURÉE : 6 mois\r\n\r\nLA SOCIÉTE\r\n-----------\r\n\r\nSyllabs est un jeune laboratoire de recherche privé spécialisé dans\r\nles domaines de la Gestion de l\'Information et du Traitement\r\nAutomatique des Langues. Syllabs est au coeur de trois activités\r\ncomplémentaires : La Recherche, les Développements Innovants et le\r\nConseil.\r\nNous sommes situés dans le 13ème arrondissement de Paris.\r\n\r\nPour plus d\'informations nous vous invitons à visiter notre site\r\nwww.syllabs.com\r\n\r\nDOSSIER DE CANDIDATURE :\r\n-------------------------\r\n\r\nMerci de nous faire parvenir votre dossier de candidature à l\'adresse\r\nsuivante : jobs@syllabs.com \r\n-	Lettre de motivation\r\n-	CV\r\n\r\n-------------------------------------------------------------------------'),
(19, '2009-01-23', 'LIMSI', 'Orsay', 'Le groupe ILES (anciennement groupes LIR et Geste) du LIMSI-CNRS\r\npropose des stages pour différents niveaux d\'études dans les\r\nthématiques suivantes:\r\n\r\n- Traitement des Langues Signées\r\n- Recherche d\'Information et Question-Réponse\r\n- Constitution de Ressources pour le TAL\r\n- Evaluation pour le TAL\r\n- Analyse de Texte et Traduction Automatique\r\n\r\nLa description des différentes propositions se trouve sur la page\r\nsuivante:\r\n\r\nhttp://www.limsi.fr/Scientifique/lir/stages\r\n\r\nLes candidats devront contacter directement les responsables du/des\r\nstages, en joignant un descriptif de leur parcours sous forme d\'un\r\ncourt CV et en précisant leur motivation pour les stages concernés.\r\n\r\nPage du groupe (anciennement groupe \'LIR\'):\r\nhttp://www.limsi.fr/Scientifique/lir/\r\nPage du laboratoire: http://www.limsi.fr'),
(20, '2009-01-23', 'Arisem', 'Massy', 'Arisem propose cette année six stages de niveau master :\r\n\r\n\r\n- Enrichissement des ressources linguistiques pour l\'extraction\r\n  d\'information en Néerlandais\r\n\r\n- Analyse des opinions et sentiments\r\n\r\n- Exploitation des « Linked Data »\r\n\r\n- Développement d\'une plateforme de démonstration des composants de\r\n  Text Mining\r\n\r\n- Développement d\'un environnement de production de ressources\r\n  linguistiques sous Eclipse RCP\r\n\r\n- Evaluation de la qualité des Ressources Linguistiques\r\n\r\nLes détails de chacun de ces stages sont disponibles sur la page\r\nhttp://www.arisem.com/index.php?page=emploi\r\n\r\nLes candidatures peuvent être directement adressées à :\r\nnicolas.dessaigne@arisem.com\r\naurelie.migeotte@arisem.com'),
(21, '2009-01-23', 'INSERM', 'Paris', 'Proposition de stage M2 \r\n\r\nLOCALISATION  DE  TERMINOLOGIES\r\n\r\nNatalia Grabar (natalia.grabar@spim.jussieu.fr)\r\n\r\nCentre de Recherche des Cordeliers ; U Paris Descartes, UMR_S 872 ; INSERM,\r\nU872 eq 20 ; HEGP AP-HP\r\n\r\n\r\nCONTEXTE. L\'implémentation d\'outils informatiques (p. ex., pour\r\nencodage, archivage ou recherche de documents) nécessite souvent\r\nl\'utilisation de terminologies représentant la connaissance du\r\ndomaine. Dans certains domaines (p. ex., droit, médecine, biologie,\r\nélectricité, téléphonie), il existe déjà des terminologies mais, pour\r\nleur meilleure utilisation, elles doivent être adaptées au contexte de\r\nleur exploitation. Au moins deux objectifs peuvent alors être\r\npoursuivis : (1) leur adaptation à l\'application et (2) leur\r\nadaptation au domaine, plus ciblé et précis que ne le serait une\r\nterminologie généraliste. Le travail sera effectué dans le domaine de\r\nmédecine.\r\n\r\n\r\nOBJECTIFS. L\'objectif du stage consiste à implémenter et tester des\r\nméthodologies qui permettent d\'adapter les terminologies existantes,\r\nentre autres au travers des corpus, à une question médicale\r\nprécise. L\'application visée concerne le filtrage et la sélection\r\nd\'articles scientifiques. Le matériel principal de travail sont des\r\nmots-clés centraux pour une question, par exemple : \"colorectal\r\nneoplasms\" ; \"liver neoplasms\" ; \"laparoscopy\" ; \"tomography,\r\nemission-computed\" ; \"magnetic resonance imaging\" ; \"tomography, x-ray\r\ncomputed\" pour la question \"diagnostic de métastases hépatiques du\r\ncancer colorectal\". Ce matériel servira d\'amorce pour la constitution\r\nde corpus (articles scientifiques) et de points d\'entrée dans les\r\nterminologies (p.ex. l\'UMLS (NLM, 2007) qui propose plus de 140\r\nterminologies biomédicales).\r\n\r\nLe stagiaire s\'intéressera à : \r\n- navigation et manipulation des arbres \r\n- outils d\'acquisition (Bourigault & Jacquemin, 2000) \r\n- outils de structuration (Grabar & Hamon, 2004) des terminologies. \r\n\r\nLe développement en Perl sera demandé lors des différentes étapes du\r\ntravail.\r\n\r\nDÉROULEMENT DU STAGE. Le stage sera encadré par un chercheur en\r\ninformatique biomédicale et en TAL, et co-encadré par un médecin. Il\r\ns\'agit d\'un stage de 6 mois rémunéré.  Le stage se déroulera dans\r\nl\'équipe Inserm du Centre de Recherche de Cordeliers (Paris 06).\r\n\r\nLe CV et une lettre de motivation sont à envoyer à Natalia Grabar.\r\n\r\n\r\nRéférences\r\n\r\nBOURIGAULT, D. & JACQUEMIN, C. (2000). Construction de ressources\r\nterminologiques, In J.-M. PIERREL, Ed., Industrie des langues, pp.\r\n215-233.\r\n\r\nGRABAR, N. & HAMON, T. (2004). Les relations dans les terminologies\r\nstructurées : de la théorie à la pratique. Revue d\'Intelligence\r\nArtificielle (RIA), 18(1).\r\n\r\nNLM (2007). UMLS Knowledge Sources Manual. National Library of\r\nMedicine, Bethesda, Maryland. www.nlm.nih.gov/research/umls/.'),
(22, '2009-01-28', 'INSERM', 'Paris', 'Proposition de stage de master 2\r\n\r\nSERVICE WEB : FILTRAGE DE LA LITTÉRATURE SCIENTIFIQUE\r\n\r\nNatalia Grabar (natalia.grabar@spim.jussieu.fr), Isabelle Colombet\r\n(isabelle.colombet@spim.jussieu.fr)\r\n\r\nUMR 872 EQ 20, Centre des Cordeliers ; HEGP/AP-HP\r\n\r\n\r\nCONTEXTE. \r\nCette proposition de stage s\'inscrit dans le paradigme de la médecine\r\nfondée sur les preuves (EBM). EBM consiste à fonder les décisions\r\nmédicales sur des preuves scientifiques authentifiées. Le niveau de\r\npreuve est établi grâce aux revues systématiques de la littérature\r\nbiomédicale. Ces revues sont extrêmement lourdes à mettre en place et\r\nà réaliser du fait du volume important de la littératude à analyser et\r\nfiltrer. Une aide automatique à la réalisation de revues systématiques\r\ns\'avère nécessaire.\r\n\r\n\r\nOBJECTIFS DU STAGE. \r\nUne des étapes des revues systématiques, qui correspond à l\'examen\r\nsélectif des publications, est l\'étape clé. En effet, l\'oubli de\r\ncertaines études peut aboutir à des résultats biaisés et à des niveaux\r\nde preuve insuffisants.  L\'objectif de ce stage est de répondre à ce\r\nbesoin car très peu est fait pour assister les revues. Afin de\r\nfaciliter le processus de sélection d\'articles, nous proposons\r\nd\'utiliser les méthodes d\'analyse textuelle et sémantique au travers\r\nun service Web dédié.\r\nLe stagiaire aura pour objectif d\'implémenter une première version de\r\nce service Web, selon les spécifications fournies.\r\n\r\nIl devra en particulier : \r\n- compiler une liste unique de références bibliographiques provenant\r\n  de différentes bases,\r\n- collecter et intégrer les résumés des articles scientifiques à\r\n  analyser [1]\r\n- intégrer les connaissances du domaine [2] dans le processus de tri\r\n  et de filtrage des résumés\r\n\r\n\r\nDÉROULEMENT DU STAGE. \r\nLe stage sera encadré par un chercheur en informatique biomédicale et\r\nen TAL, et co-encadré par un médecin. \r\nIl s\'agit d\'un stage de 6 mois rémunéré. \r\nLe stage se déroulera dans l\'équipe Inserm du Centre de Recherche de\r\nCordeliers (Paris 06).\r\n\r\nLe CV et une lettre de motivation sont à envoyer à Natalia Grabar.\r\n\r\n\r\nRÉFÉRENCES\r\n\r\n[1] NLM . Medline : medical literature on-line. National Library of\r\nMedicine, Bethesda, Maryland, 2008. www.ncbi.nlm.nih.gov/sites/entrez.\r\n[2] NLM . UMLS Knowledge Sources Manual. National Library of Medicine,\r\nBethesda, Maryland, 2007. www.nlm.nih.gov/research/umls/.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(23, '2009-01-28', 'LINA', 'Nantes', 'Proposition de stage (niveau M1)\r\n\r\nSujet :\r\n\r\nDe nombreuses langues écrites disposent de ressources lexicales sous\r\nforme de dictionnaires éditoriaux. Ces dictionnaires existent aussi\r\nsous une forme électronique puisqu’ils ont été édités sur des outils\r\nde traitements de texte.  Mais ces fichiers ne peuvent être utilisés\r\ndirectement par des programmes de Traitement Automatique des Langues\r\nNaturelles car ils ne respectent aucun format spécifique.\r\n\r\nIl est possible d’écrire un programme qui soit capable de localiser\r\nles informations à récupérer dans les dictionnaires et qui les\r\nreprésente dans une structure normalisée, mais cette démarche présente\r\nl’inconvénient de nécessiter l’écriture d’un programme, ou la\r\nspécification de règles complexes, pour chaque dictionnaire.\r\n\r\nLe but de ce stage est de s’affranchir de cette difficulté en\r\nconstruisant un programme qui, après apprentissage, est capable de\r\nconvertir un dictionnaire éditorial en un fichier XML.\r\n\r\nLa phase d’apprentissage exploite une partie de dictionnaire\r\ndisponible sous sa forme éditoriale (les données de départ) et sous la\r\nforme structurée au format XML.\r\n\r\nLe convertisseur utilise les connaissances précédemment apprises pour\r\nconvertir le reste du dictionnaire. Il doit être capable de signaler\r\nles parties du dictionnaire qu’il n’a pas été capable de convertir et\r\nqui seront traitées ultérieurement par un linguiste.\r\n\r\nSalaire mensuel : 530 euros bruts / 396 euros net\r\n\r\nDurée : 3 mois, courant 2009\r\n\r\nLieu : Laboratoire d’informatique Nantes Atlantique (UMR CNRS 6241)\r\n\r\nEncadrement : Chantal Enguehard, maître de conférences en\r\ninformatique, équipe Langage Naturel\r\n\r\nPostuler : Envoyer un CV, relevé de notes et une lettre de motivation\r\nà Chantal Enguehard, chantal.enguehard@univ-nantes.fr.\r\n\r\n\r\nChantal Enguehard\r\n\r\nLINA - UMR CNRS 6241\r\n2, rue de la Houssinière\r\nBP 92208\r\n44322 Nantes Cedex 03\r\nFrance\r\nhttp://www.sciences.univ-nantes.fr/info/perso/permanents/enguehard/'),
(24, '2009-02-04', 'CEA', 'Fontenay-aux-Roses', 'Proposition de stage de master 2 \r\n\r\nExtraction d\'information non supervisée\r\n\r\nOlivier Ferret (ferreto__zoe.cea.fr) et Romaric Besançon\r\n(besanconr__zoe.cea.fr)\r\n\r\nCEA LIST/LIC2M, Fontenay-aux-Roses\r\n\r\nCONTEXTE \r\nL\'extraction d\'information à partir de textes consiste classiquement à\r\nrepérer dans les textes des événements d\'un type prédéfini ainsi qu\'un\r\nensemble donné d\'informations prenant généralement la forme d\'entités\r\nnommées et venant s\'insérer dans une description a priori de ce type\r\nd\'événements appelée template. Pour un événement comme le rachat d\'une\r\nsociété par une autre, l\'extraction se focalisera ainsi sur\r\nl\'identification de la société acheteuse, de la société achetée, du\r\nmontant du rachat et de sa date. Cette approche peut être qualifiée\r\nglobalement de dirigée par les buts ou de descendante. Plus récemment,\r\nune approche inverse a fait son apparition, approche que nous\r\nqualifierons ici d\'extraction d\'information non supervisée (Rosenfeld\r\net Feldman, 2007 ; Hasegawa et al., 2006 ; Shinyama et Sekine,\r\n2006). Cette approche prend comme point de départ des entités ou des\r\ntypes d\'entités et se fixe comme objectif de mettre en évidence les\r\nrelations intervenant entre ces entités puis de regrouper ces\r\nrelations en fonction de leurs similarités sémantiques ou\r\nthématiques. Une telle approche s\'incarne typiquement dans une\r\nproblématique de veille telle que « suivre tous les événements faisant\r\nintervenir les sociétés IBM et Sony », qui conduit par exemple à\r\nextraire les « événements » suivants :\r\n\r\n-------------------------------------------------\r\nIBM, Sony et Philips s\'allient à Redhat et Novell pour protéger Linux.\r\n\r\nIBM, Philips, Sony, Red hat et Suse créent un fonds de brevets pour\r\nprotéger Linux\r\n-------------------------------------------------\r\nIBM, Sony et Toshiba présente le processeur Cell.\r\n\r\nIBM, Sony et Toshiba veulent imposer le processeur Cell.\r\n\r\nSony, Toshiba et IBM, développeurs du processeur Cell (\"cellule\" en\r\nanglais), viennent de dévoiler de nouvelles données techniques sur\r\nleur composant.\r\n-------------------------------------------------\r\nIBM, Sony et Nokia s\'associent pour le développement durable.\r\n\r\nIBM, Sony et Nokia cèdent des brevets « écologiques ».\r\n\r\nIBM, Sony, Nokia et Pintey-Bowes ont lancé le 14 janvier la plateforme\r\nEco-Patent Commons (EPEC) qui donne librement au public une trentaine\r\nde brevets visant à résoudre les problèmes environnementaux des\r\nentreprises.\r\n-------------------------------------------------\r\n\r\net à les regrouper en trois grandes catégories, faisant référence à\r\ntrois contextes différents.\r\n\r\n\r\nOBJECTIFS DU STAGE\r\nLe laboratoire LIC2M du CEA LIST dispose d\'une plate-forme modulaire\r\nde traitement des langues permettant de réaliser une analyse\r\nlinguistique d\'un texte allant jusqu\'au niveau syntaxique et intégrant\r\ncertaines analyses sémantiques et discursives. Cette plate-forme\r\ninclut également des outils plus spécifiquement liés à l\'extraction\r\nd\'information comme un module de reconnaissance d\'entités\r\nnommées. L\'objectif du stage est de concevoir et de développer à\r\npartir de cette plate-forme un système complet d\'extraction\r\nd\'information non supervisée. Plus précisément, ce développement passe\r\npar la proposition et l\'implémentation de solutions pour les trois\r\nsous-problèmes suivants :\r\n\r\n  - l\'extraction proprement dite de relations en se focalisant, à\r\n    partir du résultat d\'une analyse syntaxique des phrases, sur\r\n    l\'identification des prédicats intervenant entre les entités\r\n    ciblées et des relations unissant ces prédicats aux entités ;\r\n  - l\'appariement des relations extraites pour regrouper les relations\r\n    équivalentes à un niveau sémantique ;\r\n  - le regroupement des relations relatives à un même événement ou à\r\n    la même sous-thématique.\r\n\r\nCompte tenu de l\'importance de ces problèmes, en particulier des deux\r\nderniers, une approche en deux temps est envisagée. Le premier temps\r\nconsistera à s\'inspirer des travaux existants, notamment (Rosenfeld et\r\nFeldman, 2007 ; Hasegawa et al., 2006 ; Shinyama et Sekine, 2006),\r\nafin de mettre en oeuvre une première solution pour ces trois\r\nsous-problèmes. Le second temps se focalisera sur les problèmes\r\nd\'appariement de relations, soit au niveau sémantique, soit au niveau\r\nthématique, pour proposer des solutions plus originales.\r\n\r\nCe stage est conçu dans la perspective d\'une thèse sur le même sujet\r\npour laquelle un financement CEA a été demandé (la possibilité\r\nd\'obtenir un financement de thèse dépend de la valeur du candidat et\r\nd\'arbitrages internes au CEA). Seront donc privilégiés les candidats\r\nayant comme perspective un projet de thèse.\r\n\r\n\r\nBIBLIOGRAPHIE\r\nHasegawa, T.; Sekine, S. & Grishman, R. (2004) Discovering Relations\r\namong Named Entities from Large Corpora, 42nd Meeting of the\r\nAssociation for Computational Linguistics (ACL\'04), pp. 415-422.\r\n\r\nRosenfeld, B. & Feldman, R. (2007) Clustering for unsupervised\r\nrelation identification, Sixteenth ACM conference on Conference on\r\ninformation and knowledge management (CIKM\'07), ACM, New York, NY,\r\nUSA, pp. 411-418.\r\n\r\nShinyama, Y. & Sekine, S. (2006) Preemptive Information Extraction\r\nusing Unrestricted Relation Discovery, \'Human Language Technology\r\nConference of the NAACL, Association for Computational Linguistics,\r\nNew York City, USA, pp. 304-311.\r\n\r\n\r\nCOMPÉTENCES REQUISES\r\n   - niveau M2 (ou ingénieur) en Informatique avec une spécialisation\r\n     en Traitement Automatique des Langues\r\n   - langage C++ ainsi qu\'un langage de script de type Perl ou Python\r\n\r\nMODALITÉS\r\nLe stage sera rémunéré et se déroulera pour une durée de 6 mois au \r\nsein du Laboratoire d\'Ingénierie de la Connaissance Multimédia \r\nMultilingue (LIC2M) du CEA LIST, situé sur le centre CEA de \r\nFontenay-aux-Roses (92).\r\n\r\nLes candidats intéressés par ce stage sont invités à prendre contact\r\navec Olivier Ferret ou Romaric Besançon en envoyant un CV et une \r\nlettre de motivation.\r\n\r\n\r\nCe stage est également référencé au niveau du site Web du CEA à\r\nl\'adresse :\r\nhttp://www.cea.fr/ressources_humaines/stages_longue_duree/extraction_d_information_non_supervisee'),
(25, '2009-02-16', 'LIPN', 'Villetaneuse', 'PROPOSITION DE STAGE DE MASTER 2 :\r\n\r\nLangage pseudo naturel comportant des expressions spatiales (et/ou\r\ntemporelles) pour un dialogue homme-machine multimodal\r\n\r\nContexte\r\n\r\nIl existe aujourd’hui des logiciels permettant de produire rapidement\r\nla maquette d’une interface graphique. Ces logiciels permettent de\r\ncréer des menus, des icônes, des boîtes de dialogue, etc., et ils\r\ngénèrent le code de programme correspondant de manière automatique. Le\r\nconcepteur ne s’occupe plus d’écrire le code, mais interagit avec la\r\nsouris et le clavier pour placer et/ou spécifier les objets de\r\nl\'interface directement sur l’écran. Ce haut niveau de spécification\r\nconstitue un progrès important par rapport à la programmation\r\ntraditionnelle, mais ce type d’interaction est encore relativement\r\nlourd, et en réalité moins performant que ne pourrait l\'être une\r\ninteraction de type dialogue, effectuée dans un langage proche du\r\nlangage naturel.\r\n\r\nObjectifs\r\nLes objectifs de ce stage sont : d’une part, la définition d’un pseudo\r\nlangage naturel (i.e. un fragment du langage naturel) permettant de\r\nspécifier rapidement des objets et leur disposition sur une interface,\r\nafin de dialoguer avec un logiciel de maquettage qui produit et\r\ncorrige l’état d\'une maquette existante.  D’autre part, la\r\nspécification d’une architecture hybride permettant d’établir un\r\ndialogue multimodal (au moyen de phrases dans le langage précédent, de\r\nl’écran et de la souris) entre le concepteur de l’interface et le\r\nlogiciel de conception. Ainsi, une description comme \"Je veux une\r\nbarre de menu en haut d\'une fenêtre contenant les termes File, Edit,\r\nFormat, Font et Window\" devrait permettre d\'engendrer automatiquement\r\nle code de création de tous les objets nécessaires à l’affichage d\'une\r\ntelle barre de menu (en Java par exemple).  Bien que la visée soit\r\napplicative, le stage consistera principalement en une étude\r\nbibliographique destinée à identifier des problèmes linguistiques liés\r\nà l’utilisation d’expressions spatiales (et/ou temporelles)\r\nrelativement à ce contexte dialogique. Il faudra établir la liste des\r\ntermes (verbes, prépositions, etc.) devant nécessairement faire partie\r\ndu langage, et la liste des problèmes soulevés par l\'emploi de ces\r\ntermes (ou l’interprétation des phrases) dans le contexte prévu. Le\r\nlivre de Frédéric Landragin indiqué en bibliographie pourra servir de\r\nbase à cette réflexion. L\'étude devra donner lieu à un rapport final\r\nétablissant clairement la nature du dialogue finalement envisagé, et\r\ndevra en fixer les limites en spécifiant au maximum l’architecture du\r\nlogiciel de conception (éventuellement en UML).  Pour simplifier le\r\ntravail concernant le volet architectural, l’étudiant(e) pourra\r\ntravailler dans un contexte applicatif simplifié : celui d’un monde\r\nd’objets réduits (de taille et couleur variables par exemple), qu’il\r\ns’agirait simplement de placer sur l’écran via un dialogue en pseudo\r\nlangage naturel.\r\n\r\nBibliographie\r\n\r\nHerskovits A., 1986, Language and spatial cognition : an\r\ninterdisciplinary study of the prepositions in English, Studies in\r\nNatural Language Processing, Cambridge, Cambridge Univ. Press.\r\nLandragin F., 2004, Dialogue homme-machine multimodal, publications\r\nHermès Science, Lavoisier.\r\nVandeloise C., 1986, L\'espace en français : sémantique des\r\nprépositions spatiales, Travaux en linguistique, Paris, Editions du\r\nSeuil.\r\nVandeloise C., 2001, Aristote et le lexique de l’espace – rencontres\r\nentre la physique grecque et la linguistique cognitive, Editions CSLI,\r\ncollection Langage et Esprit, Université de Stanford, Stanford.\r\n\r\nProfil souhaité\r\n- Intérêt pour la linguistique et pour le TAL. Compétences dans ces\r\n  domaines.\r\n- Autonome en informatique : connaissance d\'UNIX et de Java Swing (ou\r\n  sinon de Motif et C).\r\n\r\nConditions\r\nStage de 6 mois rémunéré par le LIPN (sous réserve de l\'approbation\r\npar le conseil de laboratoire).\r\n\r\nResponsable\r\nCatherine Recanati (email : catherine.recanati at gmail.com ; tel :  \r\n01 49 40 28 47)\r\n\r\n---------'),
(26, '2009-02-16', 'LIPN', 'Villetaneuse', 'Extraction d\'information dans les dossiers patients\r\n\r\nResponsable\r\n\r\n  Thierry Hamon, \r\n  thierry.hamon@lipn.univ-paris13.fr\r\n  Tel : 01 49 40 28 32\r\n\r\nContexte\r\n\r\nLes dossiers patients (comptes-rendus d\'hospitalisation, résumés\r\nd\'examens, etc.) sont une source importante d\'information sur les\r\nparamètres en jeu lors des soins apportés aux malades. La médecine\r\ntranslationnelle a pour objectif d\'exploiter ces documents afin d\'en\r\nfaire bénéficier la recherche biomédicale pour créer ou tester des\r\nmédicaments, mais aussi pour améliorer la qualité des soins médicaux\r\nindividuels.\r\n\r\nSi les données structurées associées au patient constituent des\r\ninformations cruciales, la fouille des comptes rendus écrits en texte\r\nlibre reste inévitable. Le texte libre contient par exemple les\r\nfacteurs de risque (par exemple l\'âge, le fait de fumer, etc.),\r\nl\'histoire du patient, les prescriptions (médicaments prescrits et\r\ndoses utilisées), l\'environnement du patient, les co-morbidités ou les\r\ndiagnostics principaux et secondaires [Chapman et al. 2007, Crammer et\r\nal. 2007].\r\n\r\nObjectifs\r\n\r\n\r\nL\'objectif du stage est d\'extraire automatiquement des comptes rendus\r\nmédicaux, les informations relatives aux patients (les informations\r\npersonnelles - âge, sexe, etc., l\'histoire du patient, les\r\nperscriptions, les facteurs de risque, etc.). Il s\'agira de développer\r\nou de réutiliser des approches de traitement automatique des langues\r\n(identification d\'entités nommées, extraction et/ou identification de\r\ntermes, variation sémantique, ...) pour annoter les documents, puis de\r\nmettre en place des approches de fouille de texte pour en extraire les\r\ninformations pertinentes.\r\n\r\nL\'évalution sera réalisée sur des données textuelles dé-identifiées\r\nissues d\'un hôpital. Les documents seront en anglais ou en français.\r\n\r\n\r\nProfil recherché\r\n\r\n- Intérêt pour le TAL (notamment la connaissance d\'outils\r\n  terminologiques, ou une sensibilisation à leur utilisation)\r\n\r\n- Autonomie en informatique : connaissance d\'UNIX, de Perl\r\n\r\nDes connaissances en médecine sont un plus.\r\n\r\n\r\nConditions\r\n\r\n  Stage de 6 mois rémunéré\r\n\r\n  Début du stage : mars 2009\r\n\r\n\r\nRéférences\r\n\r\n  [Chapman et al. 2007] Chapman (Wendy), Dowling (John) et Chu\r\n  (David).  ConText : An Algorithm for Identifying Contextual Features\r\n  from Clinical Text. In : Biological, translational, and clinical\r\n  language processing. pp. 81-88. Prague, Czech Republic, June 2007.\r\n\r\n  [Crammer et al. 2007] Crammer (Koby), Dredze (Mark), Ganchev\r\n  (Kuzman), Pratim Talukdar (Partha) et Carroll (Steven). Automatic\r\n  Code Assignment to Medical Text. In : Biological, translational, and\r\n  clinical language processing. pp. 129-136. Prague, Czech Republic,\r\n  June 2007.'),
(27, '2009-02-24', 'Orange Labs', 'Lannion', 'France Telecom /Orange Labs Lannion/TECH/EASY/LN	\r\n\r\nIntitulé du Stage \r\nExtraction d\'informations structurées dans des documents.\r\n	\r\n\r\nMission:\r\nL\'équipe Langues Naturelles de France Télécom R&D dispose d\'outils de\r\ntraitement automatique des textes. Le travail proposé  consistera à\r\nutiliser nos outils de Traitement Automatique de la Langue Naturelle\r\nainsi que des outils standards d\'analyse de grammaires régulières\r\n(regexp, automates> ...> ) pour analyser des corpus de documents et en\r\nextraire les informations structurées.  Les données récupérées seront\r\nensuite utilisées pour des applications liées aux objectifs d\'Orange\r\nLabs en traitement d\'information,  dans le cadre d\'un projet du\r\ntraitement des contenus multimédia.\r\n	\r\n\r\nProfil:\r\nBac + 5 en informatique ou Bac + 5 en TALN avec une forte compéte\r\nnce en informatique	\r\n\r\nCompétences\r\nConnaissance d\'un langage orienté objet \r\nConnaissance de langages de scripts (shell, python,> ...> )\r\nConnaissance utilisateur de SQL\r\nSensibilisation ou intérêt pour le TALN et des formalismes de type RDF\r\nBonnes capacités d\'analyse	\r\n\r\nModalités \r\nSite de France Telecom Recherche et Développement de Lannion (22)\r\n5 mois à partir de mars ou avril 2009 \r\nStage indemnisé sur la base de 5 mois	\r\n\r\nLe plus de l\'offre\r\nLes équipes de France Telecom R&D travaillent à la fois sur des\r\nproblématiques de recherche très en amont, et sur l\'industrialisation\r\nde solutions standard pour réaliser des services en Langage\r\nNaturel. La mission se déroule dans une équipe pluridisciplinaire\r\ncomposée de linguistes et d\'informaticiens, autour de la technologie\r\nTiLT de traitement des langues, disposant de nombreuses ressources\r\nlinguistiques et de fonctionnalités logicielles puissantes.\r\n\r\nContacts \r\n\r\nOlivier Collin  \r\n- 02 96 05 26 10 \r\n- olivier.collin@orange-ftgroup.com'),
(28, '2009-03-02', 'Memodata', 'Caen', 'Intitulé du stage : Révision de traductions\r\nLexique multilingue à base de concepts.\r\n\r\nMission:\r\nLe Dictionnaire Intégral est fondé sur un jeu d\'environ 45.000\r\nconcepts dont le libellé ne sert qu\'à la lecture par un humain\r\n(identification des contenus et comportements sous-jacents).\r\nCes concepts entretiennent entre eux des relations (parmi 200\r\nrelations) afin de décrire par approximation les sens des mots d\'une\r\nlangue. Ils décrivent ainsi pour le français environ 200.000\r\nmots-sens, pour l\'anglais 160.000 mot-sens, pour l\'allemand 75.000\r\nmots-sens, pour l\'arabe 80.000 mots-sens, pour le japonais 72.000\r\nmots-sens etc.\r\nCes concepts enveloppent les synsets de wordnet comme d\'autres\r\nhyperstructures le font, par exemple comme Sumo (Suggested Upper\r\nMerged Ontology).\r\n\r\nAu fil des 20 dernières années, ces concepts nativement rédigés en\r\nfrançais, ont été traduits en anglais et en d\'autres langues pour en\r\npermettre la lecture par des locuteurs non francophones. Mais ces\r\ntraductions ont été réalisées au hasard, sans prise en considération\r\nréelle du besoin.  Le stage consiste à reprendre ces concepts en\r\nfrançais et leur traduction et à en améliorer la traduction afin de la\r\nrendre publiable.\r\n\r\nLe stage est donc un stage de lexicologie multilingue appliquée à un\r\ncadre quasi-terminologique dans lequel la terminologie est constituée\r\npar le réseau de concepts lui-même.\r\n\r\nLe stage s\'adresse à des étudiants lisant très bien le français et\r\nmaîtrisant au moins une autre langue.\r\n\r\nPlusieurs stages pourront être organisés:\r\n- vers l\'anglais\r\n- vers l\'allemand\r\n- vers le portugais\r\n- vers l\'italien\r\n- vers l\'arabe\r\n- vers le chinois\r\n- vers l\'hindi\r\n- vers le vietanmien\r\n- vers le persan\r\n\r\nMais d\'autres propositions pourront retenir notre attention.\r\nLa durée des stages peut varier en fonction des impératifs d\'étude de\r\nl\'étudiant.\r\n\r\nLe stage est particulièrement indiqué à des étudiants qui souhaitent\r\nélargir leur vocabulaire en français.\r\n\r\nContacts \r\n\r\nContact\r\n- 02 31 35 75 21\r\n- Dominique Dutoit\r\n- d.dutoit@sensagent.com ou d.dutoit@memodata.com\r\n\r\nMot clé : lexicologie multilingue, ontologie, réseaux sémantiques\r\n\r\n\r\nDominique Dutoit\r\nMEMODATA\r\n02 31 35 75 21\r\nwww.sensagent.com'),
(29, '2009-03-02', 'France Telecom R&D', 'Lannion', 'Stage fin d\'études chez France Télécom : \"Titrage à partir des abrégés\r\nautomatiques\"\r\n\r\nMission : \r\nL\'équipe Langues Naturelles de France Télécom R&D dispose d\'un outil\r\nafin d\'abréger automatiquement des textes. Dans le cadre d\'un projet\r\ndu traitement des contenus multimédia nous envisageons d\'utiliser des\r\nabrégés très courts des textes courts et mono-thématiques (souvent\r\nissus de la transcription automatique, donc contenant des erreurs)\r\nafin de générer un titre car souvent les abrégés sont trop longs et\r\ntrop tirés du contexte pour être utilisés directement comme titre. Il\r\nfaut donc en extraire des syntagmes (par ex. groupes nominaux, entités\r\nnommées) qui pourraient servir comme titre. La mission consistera à\r\ntravailler sur l\'analyse des textes et leurs abrégés afin de voir\r\nquels syntagmes pourraient pris comme titre :\r\n\r\n* Faire les abrégés sur un corpus moyen des textes (configuration\r\n  adaptée des outils)\r\n\r\n* Analyse syntaxique des abrégés (et les mots-clés) pour pourvoir\r\n  généraliser une règle qui permet d\'en extraire un titre : groupes\r\n  nominaux, entités nommées, ...\r\n\r\n* Investiguer d\'autres approches afin d\'extraire des groupes nominaux\r\n  des textes afin de générer un titre (par ex. en utilisant les\r\n  mots-clés identifiés par l\'abrégeur ou par le découpeur thématique\r\n\r\n* Évaluation avec des titres créés manuellement sur un (autre) corpus\r\n\r\nProfil : \r\nBac +5 (master pro ou recherche)\r\nSpécialisation du traitement automatique des langues\r\n\r\nCompétences :\r\nBonnes connaissances en linguistique, plus particulièrement en syntaxe\r\n(connaissances en sémantiques seront en plus) Connaissance de langages\r\nde scripts (shell, python,...) Bonnes capacités d\'analyse\r\n\r\nModalités (durée, période, localisation) :\r\nSite de France Telecom Recherche et Développement de Lannion (22)\r\n5 mois à partir de avril 2009\r\n\r\nContacts :\r\nJohannes HEINECKE - 02 96 05 21 77 -\r\njohannes(point)heinecke(arobase)orange-ftgroup(point)com'),
(30, '2009-03-18', 'Dédale', 'Paris', 'ASSISTANT INFORMATIQUE DOCUMENTAIRE (STAGE)\r\n\r\n \r\n\r\nPrésentation de Dédale\r\n\r\n \r\n\r\nDédale est une plateforme de recherche, de production et de diffusion\r\nconsacrée à l\'art, à la culture et aux nouvelles technologies en\r\nEurope.\r\n\r\n \r\n\r\nSon projet s\'articule autour des activités suivantes :\r\n\r\n- le festival Emergences, rendez-vous international des nouvelles\r\n  formes artistiques et des nouveaux médias à Paris (rencontres,\r\n  spectacles, expositions, musiques électroniques),\r\n\r\n- le d-lab, accompagnement de projets artistiques innovants et\r\n  programme de résidences (axes de travail : arts de la scène et\r\n  nouvelles technologies / art en réseau / art et technologies mobiles\r\n  / territoires numériques / art et jeux vidéo),\r\n\r\n- un observatoire européen des nouveaux médias et des nouvelles\r\n  pratiques artistiques (rencontres, workshops et centre de\r\n  ressources),\r\n\r\n- l\'assistance et le conseil aux institutions publiques et aux réseaux\r\n  européens.\r\n\r\n \r\n\r\nDédale est soutenue par la Commission européenne, le Ministère de la\r\nculture et de la communication, la Région Ile-de-France et la Ville de\r\nParis.\r\n\r\n \r\n\r\nActivité européenne\r\n\r\n \r\n\r\nDédale dispose d\'une expertise et d\'un réseau de partenaires étendu en\r\nEurope.\r\n\r\n \r\n\r\nElle intervient en assistance et conseil auprès d\'institutions\r\npubliques et de réseaux en France et à l\'étranger dans des domaines\r\ncomme les technologies et les nouveaux usages, la création artistique\r\net multimédia, la numérisation du patrimoine culturel, ou encore les\r\nnouveaux environnements d\'apprentissage.\r\n\r\nElle réalise des études et développe des projets financés au titre de\r\nplusieurs Directions (culture-IST) et programmes de la Commission\r\neuropéenne : e-Ten, e-Content Plus, PCRD...\r\n\r\nAu côté de la Mission de la recherche et de la technologie (Ministère\r\nfrançais de la culture et de la communication), elle participe au\r\nprojet de Bibliothèque numérique européenne et anime la participation\r\nde la France aux projets européens de numérisation et de valorisation\r\ndu patrimoine.\r\n\r\n \r\n\r\n \r\n\r\nQuelques références :\r\n\r\n \r\n\r\n- ATHENA (2008-2010) / Projet réunissant 23 pays pour le développement\r\n  de l\'accès aux réseaux européens du patrimoine culturel en lien avec\r\n  Europeana, la bibliothèque numérique européenne www.athenaeurope.org\r\n\r\n \r\n\r\n- MICHAEL et MICHAELplus (2004-08) / Inventaire multilingue des\r\n  collections numérisées des musées, des bibliothèques et des archives\r\n  en Europe réunissant 18 pays.  www.michael-culture.org\r\n\r\n \r\n\r\n- MINERVAeC (2007-08) / Réseau ministériel pour la valorisation des\r\n  activités de numérisation réunissant 20 pays européens et 29\r\n  partenaires associés. www.minervaeurope.org\r\n\r\n \r\n\r\n- SmartCity | Nouveaux enjeux urbains et nouvelles pratiques\r\n  artistiques en Europe (2008-09) / Programme de recherche et de\r\n  co-production artistiques dans 11 villes européennes\r\n\r\n\r\nMissions\r\n\r\n \r\n\r\nAssister les chargés et chef de projet pour les aspects d\'informatique\r\ndocumentaire de projets culturels européens visant à valoriser le\r\npatrimoine culturel ou à favoriser les échanges artistiques\r\ninternationaux par le biais des TIC.\r\n\r\n \r\n\r\n    Suivi et gestion des projets existants dans leur volet technique\r\n\r\n \r\n\r\nCréation et gestion de langages documentaires et de référentiels\r\nterminologiques, gestion et organisation des contenus et des\r\nconnaissances dans les bases de données et les sites web, conception,\r\nréalisation et suivi des services documentaires...\r\n\r\n \r\n\r\nExploitation des technologies utilisées et suivi de leurs évolutions,\r\nadministration des systèmes d\'informations existants, interventions de\r\npremier niveau en installation et maintenance sur les matériels et\r\nlogiciels informatiques...\r\n\r\n \r\n\r\nPréparation et rédaction des documents de travail et livrables,\r\néchanges quotidiens avec les partenaires et notamment les\r\ncorrespondants techniques, encadrement des prestataires techniques\r\néventuels, participation aux meetings et aux audits de projet par la\r\nCommission européenne...\r\n\r\n \r\n\r\n    Participation au développement de l\'activité\r\n\r\n \r\n\r\nVeille documentaire et scientifique sur les innovations technologiques\r\nTIC, sur les terminologies, sur le multilinguisme...\r\n\r\n \r\n\r\nParticipation technique aux réponses aux appels à propositions et à la\r\nmise en place de nouveaux projets\r\n\r\n \r\n\r\nCompétences et qualités requises\r\n\r\n \r\n\r\n- Troisième cycle en informatique documentaire apprécié\r\n\r\n- Expérience de la gestion de projets nécessaire\r\n\r\n- Double compétence appréciée (exemple : informatique documentaire et\r\n  ingénierie de projets culturels)\r\n\r\n- Intérêt pour les applications culturelles et artistiques des\r\n  innovations technologiques\r\n\r\n- Connaissances en développement d\'application en environnement JAVA,\r\n  XML...\r\n\r\n- Parfaite maîtrise de l\'anglais à l\'oral comme à l\'écrit\r\n  indispensable (bilingue apprécié)\r\n\r\n- Très bonnes qualités rédactionnelles et de synthèse\r\n\r\n- Autonomie et rigueur\r\n\r\n- Forte capacité d\'adaptation à des milieux professionnels variés,\r\n  aisance relationnelle\r\n\r\n- Une bonne connaissance du paysage institutionnel culturel en Europe\r\n  serait un plus\r\n\r\n\r\nConditions\r\n\r\nDurée du stage : 6 mois (Convention de stage obligatoire)\r\n\r\nIndemnités de stage\r\n\r\nPoste à pourvoir rapidement\r\n\r\n\r\nContact  \r\n\r\nEnvoyer CV et lettre de motivation à l\'attention de Stéphane Cagnot,\r\nDirecteur, à l\'adresse suivante : anne-sophie.lelong@dedale.info'),
(31, '2009-04-14', 'Syllabs', 'Paris', 'PROPOSITION DE 2 STAGES AU SEIN DE LA SOCIÉTÉ SYLLABS \r\n------------------------------------------------------\r\n\r\n* La société : Syllabs (www.syllabs.com) est un jeune laboratoire de\r\n  recherche privé spécialisé dans les domaines de la Gestion de\r\n  l\'Information et du Traitement Automatique des Langues. Syllabs est\r\n  au coeur de trois activités complémentaires : La Recherche, les\r\n  Développements Innovants et le Conseil.\r\n\r\n\r\nNous recherchons deux stagiaires BAC+5 en Informatique :\r\n\r\n- Développement d\'un outil de compression de phrases pour le résumé\r\n  automatique de textes\r\n\r\n- Développement d\'un outil de catégorisation des opinions pour des\r\n  domaines spécifiques\r\n\r\n\r\n********************************\r\nOutil de compression de phrases\r\n********************************\r\n\r\n* CONTEXTE : Projet ANR RPM2 (Résumé Plurimédia, Multi-documents et\r\n  Multi-opinion). Pour plus d\'infos : http://labs.sinequa.com/rpm2/\r\n\r\n* SUJET DU STAGE : Développement d’un outil de compression de phrases\r\n  pour le résumé automatique de textes\r\n\r\n* OBJECTIFS DU STAGE : \r\n\r\nLe stage a pour objectif le développement d’un outil de compression de\r\nphrases pour le résumé automatique de textes. Ce travail s’inscrit\r\ndans le cadre d’un projet de recherche ANR relatif au développement\r\nd’un système de résumé multimédia et multi-opinion. Dans ce contexte\r\nparticulier, nous nous intéressons au cas du résumé par extraction :\r\nil s’agit de constituer un résumé par sélection et concaténation des\r\nphrases les plus pertinentes du document source. Le résumé ainsi\r\nproduit peut alors présenter des éléments superflus et/ou redondants\r\nque l’on souhaiterait éliminer. L’outil de compression de phrases\r\nintervient à ce niveau. Il n’est cependant pas exclu que la\r\ncompression puisse intervenir en amont du système de résumé i.e. avant\r\nla phase d’extraction des phrases pertinentes.\r\n\r\nIl existe deux grandes approches pour la compression de phrases :\r\nl’approche linguistique qui consiste à définir des règles et\r\nl’approche statistique qui utilise un corpus d’apprentissage pour\r\ndétecter des régularités statistiques exploitables. Certaines méthodes\r\ndites « hybrides » s’attachent à combiner ces deux approches afin de\r\ntirer parti des avantages de chacune. A partir d’un état de l’art, la\r\npersonne recrutée sera amenée à réaliser une évaluation des méthodes\r\nexistantes afin de déterminer l’approche finale. Aucune approche n’est\r\nprivilégiée a priori. Une attention particulière devra être portée à\r\ndeux éléments caractéristiques d’une bonne compression : la\r\ngrammaticalité et la concision. La grammaticalité consiste à s’assurer\r\nque la phrase est grammaticalement correcte. La concision correspond\r\nau fait qu’une phrase compressée doit rendre compte de l’information\r\nessentielle de la phrase originale.\r\n\r\nUne évaluation des performances de l’outil sera réalisée en fin de\r\nstage sur la base d’un corpus annoté manuellement. Des mesures\r\nclassiques d’évaluation seront utilisées avec prise en compte de la\r\ngrammaticalité et de la concision.\r\n\r\nLa personne sera intégrée à l’équipe en charge des projets de\r\nrecherche.\r\n\r\n\r\n* CONNAISSANCES ET NIVEAU SOUHAITÉS :\r\n\r\n- Linguistique Informatique, Bac+5 - Master 2\r\n- Apprentissage supervisé (SVM, perceptron, modèles de Markov)\r\n- Modèles de langages\r\n- Bonne maîtrise du langage Java et d’un langage de script (Perl,\r\n  Python)\r\n\r\n* Eléments facultatifs mais considérés comme un plus :\r\n\r\n- Maîtrise d\'une ou plusieurs langues étrangères\r\n- Connaissance des techniques de résumé automatique\r\n\r\n* LIEU DU STAGE : Syllabs - http://www.syllabs.com/fr/contact.html\r\n\r\n* RESPONSABLE : Aude Giraudel\r\n\r\n* DURÉE DU STAGE : 6 mois\r\n\r\n* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre\r\n  de motivation ainsi que votre CV complet à l\'adresse suivante :\r\n  jobs@syllabs.com \r\n\r\n\r\n*************************************\r\nOutil de catégorisation des opinions\r\n*************************************\r\n\r\n* CONTEXTE : Projet ANR RPM2 (Résumé Plurimédia, Multi-documents et\r\n  Multi-opinion). Pour plus d\'infos : http://labs.sinequa.com/rpm2/\r\n\r\n\r\n* SUJET DU STAGE : Développement d’un outil de catégorisation des\r\n  opinions pour des domaines spécifiques\r\n\r\n\r\n* OBJECTIFS DU STAGE : \r\n\r\nL’objectif du stage est la mise en place d’un outil de catégorisation\r\ndes opinions dans un ensemble de classes de type positif, négatif,\r\nneutre. Ce travail s’inscrit dans le cadre d’un projet de recherche\r\nANR relatif au développement d’un système de résumé multimédia et\r\nmulti-opinion. Dans ce contexte particulier, il s’agit de produire des\r\nrésumés textuels prenant en compte les opinions afin de donner la\r\nparole à des courants distincts, des sources d’informations avec des\r\npoints de vue différents. En cela, l’étiquetage de l’opinion, ce\r\nqu’elle exprime, nous intéresse particulièrement et il s’agit ici de\r\nfaire de la catégorisation selon des types d’opinions préétablis afin\r\nde pouvoir rendre dans le résumé final les différents points de vue\r\nexprimés.\r\n\r\nDans une première phase, il s’agira de mettre en place un outil\r\nd’extraction d’opinions et de catégorisation de ces opinions. Le\r\nformalisme utilisé reste à définir. Des lexiques d’opinions\r\nthématiques devront cependant probablement être spécifiés et\r\ndéveloppés. Ce travail sera mené en étroite collaboration avec le pôle\r\nlinguistique de la société. Cette première phase constitue la brique\r\nde base du système.\r\n\r\nDans une seconde phase, on s’attachera à mettre en place un système de\r\nrattachement des objets cibles aux opinions exprimées. On se\r\nfocalisera alors sur les objets du domaine, leurs instances, leurs\r\nattributs ainsi que leurs propriétés pour construire un système\r\ncomplet d’analyse d’opinion. L’étude passera par une étape de\r\nmodélisation du domaine ainsi que par la mise en place d’un processus\r\nqui fera le lien entre le modèle du domaine et les lexiques d’opinions\r\ndéjà développés.\r\n\r\nLa personne sera intégrée à l’équipe en charge des projets de\r\nrecherche.\r\n\r\n\r\n* CONNAISSANCES ET NIVEAU SOUHAITÉS :\r\n\r\n- Linguistique Informatique, Bac+5 - Master 2\r\n- Modélisation des connaissances\r\n- Algorithmes de catégorisation\r\n- Bonne maîtrise du langage Java et d’un langage de script (Perl,\r\n  Python)\r\n- Bonnes connaissances dans les domaines du Traitement Automatique des\r\n  Langues\r\n\r\n\r\n* Eléments facultatifs mais considérés comme un plus :\r\n\r\n- Maîtrise d\'une ou plusieurs langues étrangères\r\n- Analyse et classification d’opinions\r\n\r\n* LIEU DU STAGE : Syllabs - http://www.syllabs.com/fr/contact.html\r\n\r\n* RESPONSABLE : Aude Giraudel\r\n\r\n* DURÉE DU STAGE : 6 mois\r\n\r\n* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre\r\n  de motivation ainsi que votre CV complet à l\'adresse suivante :\r\n  jobs@syllabs.com\r\n\r\n \r\n-------------------------------------------------------------\r\nChristelle Ayache - Chef de projet / Linguiste\r\nSyllabs (entreprise agréée CIR)\r\n15 rue Jean-Baptiste Berlier 75013 Paris\r\nTel : 01.55.43.76.36 / Fax : 01.55.43.76.35 (New!)\r\nCourriel : ayache@syllabs.com\r\nSite Web : www.syllabs.com\r\n-------------------------------------------------------------'),
(32, '2009-04-20', 'Weborama', 'Paris', 'STAGE LINGUISRE INFORMATICIEN\r\n\r\n\r\n\r\nSujet : Participer à l\'optimisation du Ciblage comportemental de Weborama\r\n\r\n\r\n\r\nDescription :\r\n\r\nW.Cluster est la solution de Ciblage comportemental dernière\r\ngénération développée par Weborama. L\'objectif de ce stage est\r\nd\'améliorer l\'extraction d\'information de pages web. Le travail sera\r\négalement axé sur la gestion du lexique et sur la constitution des\r\nclusters de mots.\r\n\r\n\r\n\r\nCompétences requises :\r\n\r\n- Perl\r\n\r\n- MySQL\r\n\r\n- Des connaissances linguistiques (lexicologie, syntaxe, sémantique)\r\n\r\n- Expressions régulières\r\n\r\n\r\n\r\nProfil recherché : Bac +3 à Bac + 5\r\n\r\nSous la responsabilité d’un maître de stage vous devez être :\r\ndynamique, minutieux.\r\nDoté d’un grand sens de l’autonomie et de l’initiative. Etre capable\r\nde rédiger un cahier de charge, étudier et proposer des solutions\r\nadaptées aux besoins.\r\n\r\n\r\n\r\nCadre de travail : Ce poste est une opportunité d\'intégrer un pôle de\r\ndéveloppement composé de passionnés d\'Internet.\r\n\r\n\r\n\r\nType de contrat : Stage conventionné de 6 mois\r\n\r\n\r\n\r\nDébut du contrat : dès que possible\r\n\r\n\r\n\r\nLocalisation du poste : 75019 Paris\r\n\r\n\r\n\r\nIndemnité : selon profil\r\n\r\n\r\n\r\nComment postuler ?\r\n\r\nPour postuler, envoyez votre CV, ainsi qu\'une lettre de motivation et\r\nsi possible des liens vers vos différentes réalisations.\r\n\r\nMerci de faire parvenir votre candidature sous la référence STLI, à\r\nDelphine Peudennier (jobs@weborama.com).\r\n\r\n\r\n\r\nA propos de Weborama :\r\n\r\nPionnier des technologies de tracking numérique, Weborama a développé\r\nune offre complète de solutions à destination des éditeurs, des\r\nagences et des annonceurs sur Internet. Les plates-formes d\'adserving,\r\nde tracking et de web analytics de Weborama permettent aux\r\nresponsables marketing, chargés d\'étude et webmasters de diffuser, de\r\nmesurer et d\'optimiser leurs investissements de communication sur le\r\nweb.\r\n\r\n\r\n\r\nWeborama compte plus de 300 clients grands comptes, en France et en\r\nEurope. Elle a reçu le label «société innovante» par Oseo ANVAR, et\r\nfigure aux palmarès français et européen du Deloitte Technology\r\nFast. Weborama est cotée sur Alternext depuis juin 2006 (codes :\r\nFR0010337444  ALWEB).\r\n\r\n\r\n\r\nPour en savoir plus sur Weborama : http://weborama.com\r\n\r\n\r\n\r\nTessier Léa\r\n\r\nDirection Administrative et Financière\r\n\r\n------------------------------------------------------------\r\n\r\nWeborama\r\n\r\n15 rue Clavel\r\n\r\n75019 Paris\r\n\r\nTel : 01.53.19.21.40\r\n\r\nFax : 01.53.19.21.41'),
(33, '2009-04-23', 'CEA', 'Fontenay-aux-Roses', 'COMMISSARIAT A L\'Ã‰NERGIE ATOMIQUE\r\n\r\nCentre : Fontenay-aux-Roses\r\n\r\nLaboratoire CEA, LIST, LIC2M\r\n\r\nTitre du stage\r\nDÃ©veloppement d\'une interface Web pour un systÃ¨me de rÃ©sumÃ©\r\nautomatique\r\n\r\nObjectifs du stage :\r\nLe laboratoire LIC2M a dÃ©veloppÃ© pour l\'IRSN un logiciel de rÃ©sumÃ©\r\nautomatique nommÃ© Choral, accessible par l\'intermÃ©diaire d\'un service\r\nWeb sÃ©curisÃ© au standard WebContent (http://www.webcontent.fr/). Le\r\ntravail du stagiaire consistera Ã  dÃ©velopper une interface graphique\r\nutilisant les technologies Web pour permettre aux utilisateurs finaux\r\nde l\'IRSN d\'exploiter facilement l\'outil de rÃ©sumÃ©\r\nautomatique. L\'interface graphique sera dÃ©veloppÃ©e sous la forme de\r\nportlets (JSR 286) qui seront intÃ©grÃ©es dans un portail tel que\r\nLiferay. Cela implique l\'utilisation de technologies telles que Java,\r\nXML, JSP, etc. Des tutoriels sont disponibles Ã  partir du site de\r\nWebContent pour aborder le dÃ©veloppement de portlets accÃ©dant Ã  des\r\nweb services. AprÃ¨s dÃ©veloppement et tests, le logiciel sera dÃ©ployÃ© Ã \r\nl\'IRSN par le stagiaire.\r\n\r\nMoyens informatiques mis en oeuvre :\r\nLangages : Java, XML, JSP, XSLT, ...\r\nLogiciels : GNU/Linux, Liferay, navigateurs, Tomcat Autres moyens mis\r\nen oeuvre (expÃ©riences, mÃ©thodes dâ€™analyses, autres...)  â€‚â€‚â€‚â€‚â€‚\r\n\r\nNiveau souhaitÃ© :\r\nBac +4 IngÃ©nieur\r\nBac +5 Master\r\n\r\nDurÃ©e du stage : 4 Ã  6 mois\r\n\r\nContact\r\nGaÃ«l de Chalendar\r\nGael.de-Chalendar@cea.fr\r\n+33 1 46 54 80 18\r\n\r\nHelmut Pitsch\r\nhelmut.pitsch@irsn.fr\r\n+33 1 58 35 91 45'),
(34, '2009-07-06', 'BNP Paribas', 'Paris', 'Nous recherchons un stagiaire pour une mission de six mois (rémunérée)\r\npour travailler sur notre application.\r\n\r\nCette mission consistera à travailler pour un portail d\'informations\r\néconomiques et financières interne \"LEOnard\" qui compte près de 9000\r\nabonnés et environ 1000 connexions par jour.\r\n\r\n Destiné à l\'ensemble des collaborateurs du groupe, ce portail allie\r\nrecherche d\'informations et push (présentation d\'informations)\r\ntoujours plus pointues et pertinentes.\r\n\r\nCes informations proviennent de base de données internes, de sites web\r\net de près de 400 articles issus de la presse quotidienne économique.\r\nPlusieurs technologies sont utilisés dans LEOnard : Polyspot (moteur\r\nde recherche), KB Crawl et KB Platform (outil de surveillance, de\r\ncollecte et de diffussion d\'informations provenant du web) et Temis\r\n(text mining).\r\n\r\nDans le cadre du développement de ce portail, nous recherchons un(e)\r\nstagiaire pour poursuivre un travail entamé de catégorisation\r\nautomatique de tous nouveaux documents entrants (sectorielles --> ex:\r\nconstructeurs automobiles, pétrole, banques ...).\r\nUn corpus de documents provenant de notre centre de Documentation \r\néconomique a été utilisé comme documents référents (masters).\r\n\r\nNous souhaitons également mettre en place une technique dit de \"grains\r\nde similarité\" permettant de proposer suite à une recherche ou\r\naffichage d\'un article un ou plusieurs documents autres similaires\r\n\r\nPour ce faire, nous nous sommes équipés des logiciels de Temis\r\n(entreprise, leader dans le domaine du text mining).\r\n\r\nNous recherchons donc un stagiaire de niveau master (1ère ou 2ème\r\nannée) pour travailler sur ces logiciels et nous apporter ses\r\ncompétences dans l\'utilisation et les perspectives que nous pouvons\r\ntirer de ces technologies.\r\n\r\n- Tests et analyse de l\'outil de Text-mining Temis (extraction\r\n  d\'entités nommées, concepts économiques, catégorisations\r\n  automatisées,..)\r\n\r\n- Suivi du déploiement de la mise à disposition de ce moteur de\r\n  recherche entreprise (outil en langage naturel) auprès des\r\n  utilisateurs, mise à jour guide utilisateur.\r\n\r\n- Participation aux démonstrations en interne et à l’externe.\r\n\r\n- ...etc\r\n\r\nCompétences requises : \r\n\r\n- Etre méthodique, autonome, rigoureux et curieux. \r\n\r\n- Prendre des initiatives, partager ses idées et son savoir-faire et\r\n  donc savoir travailler en équipe\r\n\r\n- Anglais lu parlé obligatoire \r\n\r\n- Notions informatiques type langage html, xml, structuration et\r\n  développement de sites internet \"\r\n\r\n\r\nCordialement\r\nMichel Bernardini\r\n\r\n\r\nMichel Bernardini\r\nBNP PARIBAS\r\nEtudes Economiques\r\n6 Bld Capucines\r\nACI : CIK01A1\r\n75450 paris cedex 09\r\ntel : 01.42.98.05.71 / 06.64.01.64.07\r\nfax : 01.42.98.19.92'),
(35, '2009-10-22', 'France Telecom Orange', 'Paris', 'Intitulé\r\nElaboration d\'un système de règles pour l\'amélioration de données annuaire\r\n\r\nMission\r\n\r\nLa direction 118712 est une entité marketing en charge de la\r\ndéfinition, de la conception et du déploiement des offres de\r\nrenseignements annuaire d\'Orange sur différents canaux (renseignements\r\ntéléphoniques, web, mobile,...).\r\n\r\nL\'annuaire comprend diverses informations reçues des opérateurs sous\r\ndes formes différentes. Ces données font l\'objet de traitements\r\nrécurrents permettant de les normaliser, de les homogénéiser et d\'en\r\nextraire les informations les plus pertinentes pour renseigner les\r\nclients de la meilleure façon possible.\r\n\r\nL\'objectif du stage est de permettre l\'amélioration de la qualité des\r\ndonnées annuaire dans les traitements récurrents par l\'optimisation\r\ndes régles existantes et par la mise mettre en place d\'un nouveau jeu\r\nde règles complexes.\r\n\r\nLe stagiaire devra s\'imprégner de l\'existant (le fonctionnement du\r\nsystème et ses régles en cours) et aura en charge la réalisation des\r\ntâches suivantes :\r\n\r\n *   l\'analyse des données\r\n *   la conception de règles formelles\r\n *   les tests qualité (non-régression et amélioration)\r\n *   la résolution des problèmes inhérents aux règles\r\n\r\nProfil\r\nBac + 5 (Master pro ou recherche)\r\nSpécialiste des langages formels (traitement automatique des langues,\r\nlinguistique)\r\n\r\nCompétences\r\n\r\n *   bonne expérience des langages formels\r\n *   manipulation de gros volumes de données\r\n *   maîtrise d\'excel et d\'outils de manipulation de bases de données\r\n *   capacité d\'abstraction\r\n *   bonnes capacités d\'analyse\r\n *   goût pour la résolution de problèmes\r\n *   rigueur\r\n\r\nModalités\r\nSite de France Télécom en Ile-de-France\r\n6 mois à partir de mars 2010\r\nStage rémunéré\r\n\r\nContact\r\nEstelle Maillebuau - 01 55 22 88 57\r\nestelle.maillebuau@orange-ftgroup.com<mailto:estelle.maillebuau@orange-ftgroup.com>'),
(36, '2009-11-23', 'Xerox XRCE', 'Grenoble', 'Stage de 4 à 6 mois au centre de recherche Xerox Europe\r\n(http://www.xrce.xerox.com/\r\nhttp://www.xrce.xerox.com/Research-Development/Document-Content-Laboratory/Parsing-Semantics/ \r\n)\r\n\r\nDate : à partir de janvier 2010\r\n\r\nSujet : Développements linguistiques pour l\'analyse d\'opinions\r\n\r\nL\'équipe Parsing&Semantics du centre de recherche XRCE Meylan\r\nrecherche un stagiaire pour travailler sur un projet Eurostar, Scoop,\r\ndont le but est de développer un outil pour la recherche et l\'analyse\r\nd\'opinions au sein d\'un moteur de recherche innovant.\r\n\r\nIl s\'agit plus précisément de participer au développement de\r\ngrammaires de dépendances de l\'anglais et du français afin de traiter\r\ndes phénomènes linguistiques typiquement mis en jeu pour l\'expression\r\ndes sentiments.\r\n\r\nLes différentes tâches sont les suivantes:\r\n\r\n- analyse linguistique des corpus cibles et formalisation des\r\n  phénomènes linguistiques mis en jeu\r\n\r\n- Développement de grammaires pour l\'analyse d\'opinion (adaptation et\r\n  développement de règles permettant de couvrir des phénomènes tels\r\n  que la coréférence et la négation, ...)\r\n\r\n- reconnaissance d\'entités nommées, en particulier pour les noms de\r\n  produits.\r\n\r\nProfil demandé :\r\n\r\nLe candidat doit posséder un très bonne connaissance du traitement\r\nautomatique des langues en général et du développement de grammaires\r\nen particulier.\r\n\r\nIl doit maitriser le français et l\'anglais.  \r\nDes connaissances relatives aux techniques d\'analyse d\'opinion\r\nseraient un plus.\r\n\r\nLes candidatures sont à envoyer à l\'adresse suivante: \r\nCaroline.Brun@xrce.xerox.com'),
(37, '2009-12-07', 'EDF', 'Clamart', 'Stage Bac + 5 de 4 à 6 mois au centre de R&D d\'EDF de Clamart\r\n\r\nSujet : Adaptation des techniques de text mining aux données \r\nconversationnelles issues de l\'oral \r\n\r\nEDF utilise les techniques de Text Mining pour optimiser sa relation\r\nclient, en analysant des questions ouvertes d\'enquête de satisfaction,\r\ndes textes libres et des retranscriptions de conversations issues des\r\ncentres d\'appels.\r\n\r\nLa R&D d\'EDF met en ½uvre des techniques de text mining sur les\r\ntranscriptions de conversations téléphoniques des centres d\'appels.\r\nLa chaîne de traitement text mining (lemmatisation, extraction de\r\nconcept métier, segmentation, classement) permet ainsi de classer ces\r\ntranscriptions selon différentes thématiques. Que ces conversations\r\nsoient transcrites automatiquement ou manuellement, les entrées de la\r\nchaîne text mining diffèrent de celles classiquement traitées par les\r\nmodules de text mining : il s\'agit de données issues de l\'oral\r\n(transcription littérale manuelle ou automatique) contenant de\r\nnombreuses disfluences comme par exemple : les hésitations, les\r\nbégaiements sur les amorces de mots, les phrases inachevées, les\r\nrépétitions de mots ou de groupes de mots.  Ces spécificités liées à\r\nl\'oral sont difficiles à traiter, notamment lors de l\'étape\r\nd\'extraction de concepts métiers (cartouches de connaissance),\r\nextraction qui se fait à l\'aide de règles, qui peuvent s\'avérer peu\r\nadaptées à des données dont le fenêtrage syntaxique diffère de celui\r\ndes données textuelles classiques.\r\n\r\nPar ailleurs, les modules de reconnaissance automatique de la parole\r\nutilisés génèrent un certain nombre d\'erreurs incluant des erreurs de\r\nponctuation qui viennent ainsi altérer la transcription.\r\n\r\nDans les deux cas, transcriptions manuelles et automatiques,\r\nl\'objectif de se stage sera d\'analyser l\'impact de l\'oral sur la\r\nchaîne text mining et de proposer des alternatives aux méthodes\r\nutilisées jusque maintenant sur des données textuelles.\r\n\r\nProfil recherché :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du TALN et/ou du\r\ntraitement de la parole.\r\n\r\nContact  et envoi des candidatures :\r\nChloé Clavel , 01 47 65 43 15, chloe.clavel@edf.fr\r\nAnne Peradotto , 01.47.65.44.89, anne.peradotto@edf.fr\r\nLieu du stage :  EDF R&D,    1, av du Général de Gaulle,  92141 Clamart \r\nCedex\r\nDurée : 6 mois environ\r\nRémunération : environ 1.000¤/mois\r\n  \r\n \r\nChloe CLAVEL\r\nIngénieur chercheur\r\nEDF \r\nICAME\r\n1, av. du Général de Gaulle\r\n92141 Clamart\r\n \r\nchloe.clavel@edf.fr\r\nTél. : 33 (0)1 47 65 43 15');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(38, '2009-12-14', 'Xerox XRCE', 'Grenoble', 'Proposition de stage\r\nDate : à partir de janvier 2010\r\nDurée : entre 4 et 6 mois\r\n\r\nSujet : Développer un outil de conversion \"html to text\" pour\r\nl\'extraction d\'évènements à partir d\'articles journalistiques\r\n\r\nL\'équipe Parsing&Semantics du centre de recherche XRCE Meylan\r\nrecherche un stagiaire pour travailler sur un projet européen, SynC3,\r\ndont l\'objectif est de développer un outil capable de représenter les\r\nsentiments provenant de blogs qui parlent d\'évènements mentionnés dans\r\ndes articles de presse.\r\n\r\nIl s\'agit plus précisément de participer au développement d\'un outil\r\ncapable de convertir un article journalistique qui se présente sous la\r\nforme d\'un fichier html en un fichier texte ne contenant que le texte\r\npertinent du fichier html.\r\n\r\nLes différentes tâches sont les suivantes:\r\n\r\n- développer et améliorer un module existant de conversion de fichier\r\n  html en fichier texte (développé en Java)\r\n\r\n- travailler sur la segmentation d\'articles. Identifier les\r\n  différentes parties de l\'article (titre, paragraphes, auteurs,\r\n  etc.).\r\n\r\n\r\nProfil demandé :\r\n\r\nLe candidat doit maîtriser la manipulation de fichiers html et doit\r\nposséder une très bonne connaissance de Java. Un bon niveau en anglais\r\nest requis.\r\nDes connaissances concernant la plateforme UIMA seraient un plus.\r\n\r\nLes candidatures sont à envoyer à l\'adresse suivante:\r\nguillaume.jacquet@xrce.xerox.com'),
(39, '2009-12-14', 'Syllabs', 'Paris', 'Proposition de stage au sein de la société Syllabs\r\n\r\nContexte\r\n\r\nOutil d\'aide aux linguistes pour le développement de ressources\r\nlinguistiques\r\n\r\nSujet du stage\r\n\r\nIntégration d\'un guessing d\'entités nommées pour la création et\r\nmaintenance de lexiques sémantiques et thématiques.\r\n\r\nObjectifs du stage\r\n\r\nL\'objectif du stage est d\'étudier la problématique liée à la création\r\net maintenance de lexiques sémantiques et thématiques, de proposer une\r\nméthode pour alimenter semi-automatiquement ceux-ci à partir de\r\nnouvelles entités nommées et d\'intégrer un module développant la\r\nméthode à l\'ensemble d\'outils de l\'architecture OAL. Etant donnée une\r\nentité nommée inconnue, le module doit suggérer aux linguistes les\r\ntraits sémantiques pertinents ainsi que l\'appartenance à un ou\r\nplusieurs lexiques thématiques existants.  Actuellement Syllabs\r\ndispose de ressources linguistiques en plusieurs langues et pour\r\ndifférents domaines. La personne travaillera avec des informaticiens\r\net des linguistes.\r\n\r\n\r\nConnaissances et niveau souhaités\r\n\r\n- Linguistique Informatique, Bac+5 - Master 2\r\n\r\n- Bonne maîtrise du langage Java\r\n\r\n- Bonnes connaissances dans les domaines du Traitement Automatique des\r\n  Langues\r\n\r\nEléments facultatifs mais considérés comme un plus :\r\n\r\n- Maîtrise d\'une ou plusieurs langues étrangères\r\n\r\nDurée : 6 mois\r\n\r\nLa société\r\n\r\nSyllabs est une entreprise spécialisée dans les domaines de la Gestion de\r\nl\'Information et du Traitement Automatique des Langues. Syllabs est au c½ur\r\nde trois activités complémentaires : La Recherche, les Développements\r\nInnovants et le Conseil.\r\n\r\n\r\nPour plus d\'informations : www.syllabs.com\r\n\r\nLes candidatures doivent s\'adresser à jobs at syllabs.com. Merci d\'indiquer\r\nle nom/code du stage dans l\'objet du mél.'),
(40, '2009-12-14', 'Syllabs', 'Paris', 'Proposition de stage au sein de la société Syllabs\r\n\r\nContexte\r\n\r\nOutil d\'aide aux linguistes pour le développement de ressources\r\nlinguistiques\r\n\r\nSujet du stage\r\n\r\nConception et implémentation d\'une nouvelle gestion client/serveur de\r\nressources linguistiques, dans le cadre de l\'architecture OAL (Outil\r\nd\'Aide aux Linguistes) utilisée par le Département de Développements\r\nLinguistiques de Syllabs.\r\n\r\n\r\nObjectifs du stage\r\n\r\nLa personne recrutée pour ce stage aura pour tâche l\'enrichissement de\r\nla gestion client/serveur de ressources linguistiques. Actuellement\r\nSyllabs dispose de ressources en plusieurs langues et pour différents\r\ndomaines. OAL propose un client riche et une architecture qui permet à\r\nplusieurs linguistes de travailler sur les mêmes\r\nressources. L\'objectif du stage est d\'étudier la solution actuelle,\r\nd\'en analyser les limites, et d\'en proposer une autre, qui sera par la\r\nsuite implémentée. Parmi les fonctionnalités souhaitées se trouvent :\r\ncheck-in et check-out de ressources, versionnage de ressources,\r\ncontrol d\'utilisateurs, gestion de statistiques. La personne\r\ntravaillera avec des informaticiens et des linguistes. Les outils sont\r\ndéveloppés en Java/SWING.\r\n\r\n\r\nConnaissances et niveau souhaités\r\n\r\n- Bac+5 - Master 2\r\n\r\n- Très bonne maîtrise de Java/SWING\r\n\r\n\r\nEléments facultatifs mais considérés comme un plus :\r\n\r\n- Connaissance du domaine du Traitement Automatique des Langues\r\n\r\n- Connaissance de SVN\r\n\r\n- Maîtrise d\'une ou plusieurs langues étrangères\r\n\r\n\r\nDurée : 6 mois\r\n\r\n\r\nLa société\r\n\r\nSyllabs est une entreprise spécialisée dans les domaines de la Gestion\r\nde l\'Information et du Traitement Automatique des Langues. Syllabs est\r\nau c½ur de trois activités complémentaires : La Recherche, les\r\nDéveloppements Innovants et le Conseil.\r\n\r\n \r\n\r\nPour plus d\'informations : www.syllabs.com.\r\n\r\n \r\n\r\nLes candidatures doivent s\'adresser à jobs at syllabs.com. Merci d\'indiquer\r\nle nom/code du stage dans l\'objet du mél.'),
(41, '2009-12-14', 'Syllabs', 'Paris', 'STAGE EN LINGUISTIQUE INFORMATIQUE\r\n\r\nContexte\r\n********\r\nOutil d\'aide aux linguistes (OAL) pour le développement de ressources\r\nlinguistiques multilingues & Linguistic Object Language (LOL) pour\r\nl\'écriture des grammaires pour l\'extraction d\'information.\r\n\r\nL\'un des aspects clés des applications en Traitement Automatique des\r\nLangues est lié à la qualité de ressources linguistiques sur\r\nlesquelles celles-ci s\'appuient. A priori les ressources sont toujours\r\nperfectibles, mais son enrichissement et raffinement est un processus\r\ncoûteux et parfois assez fastidieux pour les linguistes. Le but d\'OAL\r\nest justement de rendre cette tâche plus productive et surtout, de\r\nfaciliter le contrôle de la qualité (test de régression, gestion des\r\nquestions liées aux ressources multilingues).  Sujet du stage\r\n\r\n1) Développement des lexiques morphosyntaxiques SylLex et des lexiques\r\n   SylThème dans OAL, outil d\'aide aux linguistes conçu pour le\r\n   développement de ressources linguistiques ainsi que définition et\r\n   participation à la mise en place des ressources et procédures\r\n   nécessaires pour l\'alimentation semi-automatique de l\'outil.\r\n\r\n2) Écriture des règles d\'extraction d\'information dans un\r\n   environnement multilingue.\r\n\r\nLangues possibles \r\n******************\r\nallemand, danois, chinois, néerlandais, polonais, portugais, russe,\r\nsuédois ou tchèque.\r\n\r\nObjectifs du stage\r\n******************\r\n\r\nLa personne recrutée pour ce stage aura deux tâches principales :\r\n\r\n1) Le développement et l\'intégration des lexiques morphosyntaxiques et\r\nthématiques de Syllabs dans une des langues listées en haut dans OAL,\r\nnotre outil d\'aide aux linguistes conçu pour le développement de\r\nressources linguistiques. La phase de développement des lexiques\r\nimplique la création des ressources et procédures semi-automatiques\r\nnécessaires pour alimenter le lexique tout en assurant leur qualité\r\n(création de corpus, définition des critères linguistiques pour le\r\ncrawling conditionnel, définition du jeux d\'étiquettes\r\nmorphosyntaxiques suivant les conventions du formalisme SylLex,\r\ndéfinition des tests de régression, évaluation quantitative et\r\nqualitative des lexiques, évaluation de la couverture).\r\n\r\n2) L\'écriture des grammaires pour l\'extraction d\'information avec LOL,\r\nun langage de programmation linguistique développé à Syllabs.\r\n\r\nConnaissances souhaitées\r\n************************\r\n\r\nÉtudiant(e) en Linguistique Informatique, Traitement Automatique des\r\nLangues.\r\nTrès bonne maîtrise de la morphologie.\r\nTrès bonne maîtrise de PERL ou Python et Unix. \r\nExpérience avec Intex ou Nooj serait un plus.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse suivante : jobs\r\n/arrobas/ syllabs .com tout en indiquant dans l\'objet du mèl « stage\r\nen linguistique informatique ».'),
(42, '2009-12-16', 'Lingway', 'Nantes', 'Lingway, spécialiste français en Traitement Automatique des Langues\r\npropose, dans le cadre d\'un projet de R&D collaborative, un stage\r\nconventionné (M2 ou équivalent).\r\n\r\nL\'objectif du stage est de réaliser l\'interface d\'accès aux résultats\r\nd\'un système d\'analyse automatique des offres d\'emploi sur le web,\r\nsystème en cours de réalisation dans le cadre du projet SIRE.\r\n\r\nLes tâches à accomplir sont:\r\n\r\n- collecte des informations extraites depuis les différents modules\r\n  des partenaires,\r\n\r\n- formalisation de ces informations forme de triplets RDF,\r\n\r\n- mise en oeuvre d\'une base RDF dédiée (\"triple store\") pour stocker\r\n  ces informations,\r\n\r\n- développement d\'une interface Web permettant la consultation de\r\n  cette base (le site pourra présenter des résultats de requêtes\r\n  pré-définies sous la forme de graphes).\r\n\r\n\r\nCompétences requises:\r\n- bonne connaissance des outils de TAL,\r\n- langage Java, \r\n- développement Web (de préférence Flex),\r\n- bonnes capacités d\'analyse,\r\n- goût pour la résolution de problèmes,\r\n- facilité à travailler en équipe\r\n\r\nStage rémunéré, basé à Nantes, 6 mois à partir de Février 2010\r\n\r\nEnvoyer CV + LM à hugues.de-mazancourt@lingway.com'),
(43, '2009-12-31', 'Arisem', 'Massy-Palaiseau', 'Arisem propose cette année six stages de niveau master :\r\n\r\n- Constitution semi-automatique d\'ontologies\r\n- Enrichissement d\'un environnement de production de ressources\r\n  linguistiques sous Eclipse RCP\r\n- Extraction de relations sémantiques entre entités nommées\r\n- Normalisation des dates et expressions temporelles\r\n- Plateforme de test et d\'évaluation de ressources linguistiques\r\n- Résolution d\'anaphores\r\n\r\nLes détails de chacun de ces stages sont disponibles sur la page\r\n\r\nhttp://www.arisem.com/index.php?page=emploi\r\n\r\nLes candidatures peuvent être directement adressées à :\r\nnicolas.dessaigne@arisem.com\r\naurelie.migeotte@arisem.com'),
(44, '2010-01-06', 'SenseGates', 'Vigneux sur Seine', 'Bonjour,\r\n\r\nSenseGates, nouvelle entreprise installée à Vigneux sur Seine\r\n(Essonne, 13 minutes de la gare de Lyon), propose six stages de niveau\r\nmaster :\r\n\r\n* Profil informaticien strict\r\n   - Changement d\'un moteur de base de données relationnelles\r\n   - Evaluation de différents moteurs d\'indexation clé/valeur (par\r\n     ex. de cassandra à hadoop)\r\n\r\n* Profil linguiste ou lexicographe ou terminologue traducteur\r\n   - Contrôle / évaluation de processus d\'enrichissement automatique\r\n     de lexiques multilingues structurés (le candidat connaît 3\r\n     langues dont le français et l\'anglais)\r\n\r\n* Profil mathématiques, IA\r\n   - formalisation d\'un langage stockant et créant des structures\r\n     ensemblistes et méréotopologiques, leur connexité et leur\r\n     perception selon le point de vue et leur comportement. En\r\n     pratique ce langage est au c½ur d\'un projet d\'intégration en un\r\n     palier d\'analyseurs ou de générateurs linguistiques (grammaires,\r\n     lexique génératif, isotopie, définition, corpus) ordinairement\r\n     réalisé en plusieurs paliers (morphologie, syntaxe, sémantique,\r\n     pragmatique, pour certains, ou par modules spécialisés comme\r\n     figement, référence, relation entités nommées etc).\r\n\r\nLes candidatures devront être adressées à Dominique Dutoit, \r\ndo . dutoit at gmail . com'),
(45, '2010-01-16', 'LIMSI', 'Orsay', 'Le groupe ILES du LIMSI-CNRS propose des stages pour différents\r\nniveaux d\'études sur la thématique de la paraphrase en Traitement\r\nAutomatique des Langues:\r\n\r\nComparaison syntaxique de phrases\r\n         http://www.ensiie.fr/~bg/stage_paraphrase.html\r\n\r\nIdentification de paraphrases dans les révisions de Wikipedia\r\n         http://perso.limsi.fr/amax/recherche/sujet1-amax-M1-2010.html\r\n\r\nParaphrase Automatique pour la Traduction Automatique Statistique \r\n(Réécrire d\'abord pour mieux traduire ensuite)\r\n         http://perso.limsi.fr/amax/recherche/sujet2-amax-M2R-2010.html\r\n\r\nValidation sur corpus monolingues de paraphrases acquises sur corpus \r\nmultilingues\r\n         http://perso.limsi.fr/amax/recherche/sujet3-amax-M2R-2010.html\r\n\r\n\r\nL\'ensemble des propositions de stage se trouve sur la page suivante:\r\n\r\nhttp://www.limsi.fr/Scientifique/iles/propositions\r\n\r\nLes candidats devront contacter directement les responsables du/des\r\nstages, en joignant un descriptif de leur parcours sous forme d\'un\r\ncourt CV et en précisant leur motivation pour les stages concernés.'),
(46, '2010-01-16', 'LIMSI', 'Orsay', 'L\'équipe ILES du LIMSI propose cette année *quatre stages de M2\r\n(master recherche ou master professionnel)* dans le domaine des\r\nsystèmes de questions-réponses, ainsi qu\'*un stage de M1*.\r\n\r\nUn résumé de ces stages est présenté ci-dessous, une description plus\r\ncomplète est disponible aux adresses suivantes :\r\nStages de M2 :\r\nhttp://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_contexte_analyse.html\r\n\r\nhttp://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_contexte_questions_complexes.html\r\n\r\nhttp://sites.google.com/site/delphinebernhard/proposition-de-stage-generation-questions\r\n\r\nhttp://www.ensiie.fr/~bg/stage_fouilleDeTexte.html\r\n\r\nStage de M1 :\r\nhttp://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M1_confiance_question_reponse.html\r\n\r\nPar ailleurs, d\'autres stages dans d\'autres thèmes sont proposés par \r\nl\'équipe :\r\nhttp://www.limsi.fr/Scientifique/iles/propositions'),
(47, '2010-01-16', 'OWI Technologies', 'Châtenay Malabry', 'OWI Technologies.\r\n\r\nNous sommes éditeur d\'un logiciel de moteur sémantique reposant sur\r\nune technologie très innovante.\r\n\r\nLa commercialisation de notre offre commence en 2010, raison pour\r\nlaquelle nous communiquons aussi peu que possible, pour l\'instant.\r\n\r\nNous recherchons, pour la mise en ½uvre de langues supplémentaires, un\r\nstagiaire, idéalement dans le cadre d\'un Master en TAL.\r\nLes tâches à accomplir comprennent :\r\n- l\'identification de ressources linguistiques utiles\r\n- la description et la saisie des comportements linguistiques, au sein \r\n  du modèle OWI\r\n\r\nLes compétences requises sont :\r\n- être au minimum bilingue (anglais et autre)\r\n- disposer d\'une culture linguistique permettant de comprendre \r\n  rapidement le modèle OWI\r\n- savoir travailler en équipe (autonomie et collaboration)\r\n\r\nLa durée du stage pourra être comprise entre 3 et 6 mois, et il\r\ns\'agira de travailler, au sein d\'une équipe de R&D de 5 personnes,\r\nprincipalement avec un docteur en informatique ayant mis en place le\r\nfrançais.\r\n\r\nLe stage est rémunéré (800 euros bruts par mois).\r\n\r\nNos bureaux sont situés au sein de l\'Ecole Centrale Paris, à Châtenay\r\nMalabry (92).\r\n\r\nContact : transmettre curriculum vitae et lettre de motivation à \r\nstages@owi-tech.com.'),
(48, '2010-01-19', 'CEA', 'Fontenay-aux-Roses', 'Proposition de stage de master 2 \r\n\r\nExtraction supervisée de relations entre entités nommées à une large\r\néchelle\r\n\r\nOlivier Ferret (ferreto__zoe.cea.fr) et Romaric Besançon\r\n(besanconr__zoe.cea.fr)\r\n\r\nCEA LIST/LVIC, Fontenay-aux-Roses\r\n\r\nCONTEXTE\r\nLe sujet de stage proposé se situe globalement dans le domaine du\r\nTraitement Automatique des Langues (TAL) et se focalise plus\r\nprécisément sur l\'une de ses branches applicatives les plus actives,\r\nl\'extraction d\'information. Celle-ci a pour objectif de repérer\r\nautomatiquement dans des textes les entités caractéristiques d\'un\r\ndomaine ainsi que les relations intervenant entre ces entités, ceci\r\ndans le but d\'alimenter une base de connaissances ou une base de\r\ndonnées.\r\n\r\nLes entités considérées dans ce cadre sont plus précisément appelées\r\nentités nommées et dans le cas le plus général, correspondent à des\r\nnoms de personnes, de lieux, d\'organisations ou à des entités\r\nnumériques telles que des dates, des montants financiers ou des\r\nmesures. Les relations entre ces entités peuvent être dans les cas les\r\nplus complexes des relations n-aires allant jusqu\'à la notion\r\nd\'événement. Par exemple, un événement de rachat d\'une entreprise par\r\nune autre est représentable par une relation du type :\r\n\r\nAchat_entreprise\r\n   société acheteuse : ORG\r\n   société achetée : ORG\r\n   montant : MONEY\r\n   date : DATE\r\noù société acheteuse définit le rôle d\'une entité et ORG, son type.\r\n\r\nDans le cadre du stage, seules des relations binaires seront\r\nconsidérées. Le processus d\'extraction d\'information peut dans ce cas\r\nse résumer aux deux étapes suivantes :\r\n\r\n   - détection des entités nommées ;\r\n   - détection des relations entre les entités identifiées.\r\n\r\nA titre d\'exemple, pour le passage :\r\n\"With a father from <loc>Kenya</loc> and a mother from\r\n<loc>Kansas</loc>, <pers>President Obama</pers> was born in\r\n<loc>Hawaii</loc> on <date>August 4, 1961</date>.\"\r\nces deux étapes donnent le résultat suivant si l\'on s\'intéresse aux\r\ndonnées de naissance d\'une personne :\r\nDétection des entités nommées\r\n   Noms de lieux : Kenya, Kansas, Hawaii\r\n   Noms de personnes : President Obama\r\n   Date : August 4, 1961\r\n\r\nDétection des relations entre entités\r\n   Lieu_naissance : bornIn(President Obama, Hawaii)\r\n   Date_naissance : bornOn(President Obama, August 4, 1961)\r\n\r\n\r\nOBJECTIFS DU STAGE\r\nDe nombreux travaux ont été réalisés sur la détection des entités\r\nnommées et comparés lors de plusieurs campagnes d\'évaluation (shared\r\ntask CoNLL 2002 et 2003, ACE ...). Le laboratoire LVIC (anciennement\r\nLIC2M) du CEA LIST possède en outre, au travers de sa plate-forme\r\nLIMA, des outils de traitement linguistique intégrant la\r\nreconnaissance d\'entités nommées \"générales\". Le stage se concentrera\r\ndonc sur la phase d\'extraction de relations, pour laquelle le niveau\r\nde performance des systèmes actuels reste à améliorer. C\'est\r\nparticulièrement le cas lorsque l\'objectif est de couvrir un ensemble\r\nlarge de types de relations. Le stage s\'effectuera dans la perspective\r\nde l\'évaluation KBP (Knowledge Base Population) de la campagne TAC\r\n2009 (Text Analysis Conference) et en reprendra les caractéristiques\r\net les données. Plus précisément, cette évaluation vise à rassembler\r\ndes informations factuelles concernant des entités relevant de trois\r\ngrands types : personnes, organisations et entités géopolitiques.  Ces\r\ninformations factuelles prennent la forme de relations appartenant à\r\n42 types possibles (date et lieux de naissance, âge, religion, nombre\r\nd\'employés, fondateur, etc).\r\n\r\n\r\nLe LVIC dispose déjà d\'outils d\'extraction de relations au sein des\r\nphrases, fondés sur la notion de patron linguistique. Un tel patron\r\npeut être vu comme une forme d\'expression régulière intégrant des\r\néléments de différents niveaux de généralité (mots, catégories\r\ngrammaticales, \"joker\" ...) et permettant de valider la présence\r\neffective d\'une relation entre deux entités nommées trouvées dans une\r\nphrase. Par exemple, le patron <maladie> * traiter * par  DET\r\n<traitement> permet de valider la présence de la relation\r\n[traitement]--(traiter)--[maladie] dans les deux cas suivants :\r\n\r\n   <maladie> se traite par une <traitement>\r\n   <maladie> est traitée efficacement par le <traitement>\r\n\r\nLe LVIC dispose également des outils permettant d\'apprendre\r\nautomatiquement ces patrons à partir de corpus annotés. Le stagiaire\r\naura tout d\'abord en charge l\'application de cet existant à l\'échelle\r\ndu grand nombre de relations considérées dans KBP. L\'accent sera mis\r\nsur l\'utilisation de données d\'apprentissage bruitées du fait de\r\nl\'impossibilité de valider manuellement de larges ensembles\r\nd\'apprentissage pour un tel nombre de relations. Deux autres\r\nproblématiques importantes seront ensuite abordées :\r\n\r\n   - le filtrage des relations extraites, en s\'appuyant notamment sur\r\n     des méthodes d\'apprentissage statistique (machines à vecteurs de\r\n     support (SVM)) ;\r\n\r\n   - l\'extension de l\'ensemble des patrons appris pour une relation\r\n     par l\'exploitation de données issues du Web. L\'objectif est ici\r\n     d\'acquérir à partir d\'exemples sondes de nouvelles formulations\r\n     d\'un type de relations ou des paraphrases de formulations déjà\r\n     rencontrées.\r\n\r\n\r\n\r\nBIBLIOGRAPHIE\r\nTask Description for Knowledge-Base Population at TAC 2009,\r\nhttp://apl.jhu.edu/~paulmac/kbp/090601-KBPTaskGuidelines.pdf\r\n\r\n\r\nAutomatic Content Extraction (ACE) Evaluation, http://www.itl.nist.gov/iad/mig/tests/ace/\r\n\r\nMintz, M., Bills, S., Snow, R. & Jurafsky, D. 2009. Distant\r\nsupervision for relation extraction without labeled data. Joint\r\nConference of the 47th Annual Meeting of the ACL and the 4th\r\nInternational Joint Conference on Natural Language Processing of the\r\nAFNLP, August, Suntec, Singapore.\r\n\r\nJun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang and Ji-Rong\r\nWen. 2009. StatSnowball: a Statistical Approach to Extracting Entity\r\nRelationships. 18th international World Wide Web conference (WWW\r\n2009).\r\n\r\nCésar de Pablo-Sanchez, Juan Pereaea,Isabel Segura-Bedmar, Paloma\r\nMartinez. 2009. The UC3M team at the Knowledge Base Population task.\r\n\r\nCulotta, A., Mccallum, A. & Betz, J. 2006. Integrating probabilistic\r\nextraction models and data mining to discover relations and patterns\r\nin text. Human Language Technology Conference of the North American\r\nChapter of the Association of Computational Linguistics, Morristown,\r\nNJ, USA.\r\n\r\n\r\nCOMPÉTENCES REQUISES\r\n   - niveau M2 (ou ingénieur) en Informatique avec une spécialisation\r\n     en Traitement Automatique des Langues\r\n   - langage C++ ainsi qu\'un langage de script de type Perl ou Python\r\n\r\nMODALITÉS\r\nLe stage sera rémunéré et se déroulera pour une durée de 6 mois au\r\nsein du Laboratoire Vision et Ingénierie des Contenus (LVIC,\r\nanciennement LIC2M) du CEA LIST, situé sur le centre CEA de\r\nFontenay-aux-Roses (92).\r\n\r\n\r\nLes candidats intéressés par ce stage sont invités à prendre contact\r\navec Olivier Ferret ou Romaric Besançon en envoyant un CV accompagné\r\nde quelques éléments de motivation.\r\n\r\n\r\nCe stage est également référencé au niveau du site Web du CEA à\r\nl\'adresse :\r\nhttp://www.cea.fr/ressources_humaines/stages_longue_duree/extraction_supervisee_de_relations_entre_entites3'),
(49, '2010-01-22', 'Besoins d\'infos', 'Paris', '* ENTREPRISE : Besoin d\'infos est une start-up internet qui s\'occupe\r\n  de gérer des annuaires thématiques et de développer un moteur de\r\n  recherche en langage naturel sous forme de questions /\r\n  réponses. www.besoindinfos.com . Le principe :\r\n\r\n- Vous posez une question sur tous les sujets...\r\n- Vous recevez immédiatement une réponse de qualité\r\n- Un moteur de recherche sémantique fait la jonction entre la question\r\n  et la bonne réponse\r\n\r\nBesoin d\'infos améliore sa technologie de recherche sémantique et son\r\nmodèle morphosyntaxique pour comparer entre elles des données non\r\nstructurées exprimées en langage naturel.\r\n\r\n* MISSION :\r\nLe stagiaire aura comme missions principales :\r\n- Analyse quotidienne des logs du moteur de recherche pour identifier\r\n  les problèmes sémantiques\r\n- Actions correctrices et paramétrages sémantiques\r\n- Enrichissement et création de dicos et de bases de connaissances\r\n  (KB)\r\n- Création de KB e-commerce sur les produits et services pour faire un\r\n  moteur de suggestions.\r\n- Améliorations sémantiques sur les bases de données de questions\r\n  réponses.\r\n- Modélisation d\'algorithmes sémantiques pour rendre plus efficace la\r\n  compréhension sémantique\r\n\r\n- Pondération syntaxique des éléments d\'une phrase et d\'une question.\r\nLe stage s\'effectuera au sein de l\'équipe R&D de Besoin d\'Infos. Le\r\nstagiaire sera encadré tout au long du stage et bénéficiera du support\r\nde l\'équipe.\r\n\r\n* QUALITES REQUISES : \r\n\r\n- Profil linguistique & sémantique appliquée au Web et à\r\n  l\'informatique.\r\n- Envie de vivre le lancement d\'un site internet et l\'aventure de la\r\n  création d\'entreprise\r\n- Rigueur, esprit d\'initiative et bonne autonomie\r\n- Très bonne culture internet et notamment des sites internet grand\r\n  public et cybermarchands\r\n- Maîtrise des outils bureautique Word & Excel et des navigateurs\r\n  Explorer et Firefox\r\n- Esprit d\'entreprise et forte curiosité\r\n\r\n* ELEMENTS PRATIQUES :\r\n- Profil : Etudiant en stage conventionné\r\n- Formation : Linguistique Informatique, Bac+5 - Master 2\r\n- Durée : 3 à 6 mois de janvier à juillet / Aout 2010\r\n- Possibilité de mi-temps.\r\n- Lieu du stage : Telecom ParisTech, 9 rue Dareau, Paris 14e\r\n- Indemnité de stage prévue en fonction du profil et de la durée\r\n\r\n* RESPONSABLE : directeur R&D de Besoin d\'Infos\r\n\r\n* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre\r\n  de motivation ainsi que votre CV complet par mail à l\'adresse\r\n  suivante : renaud.lacroix@besoindinfos.com'),
(50, '2010-01-27', 'Orange Labs', 'Lannion', 'Intitulé\r\n\r\nEvaluation des outils d\'acquisition de terminologie dans une\r\napplication multimédia\r\n\r\nMission\r\n\r\nLe stage concerne une des activités du laboratoire ACTS d\'Orange Labs\r\n: les applications de moteurs de recherche de contenus vidéo.\r\n\r\nDans ce cadre, un des problèmes à résoudre concerne l\'amélioration de\r\nla recherche par la prise en compte de la terminologie (locutions,\r\nentités nommées...). Il s\'agit d\'enrichir et de maintenir une base\r\nterminologique existante, base construite manuellement au départ. \r\n\r\nLe choix technique porte sur une acquisition automatique des données\r\nde terminologie à partir de techniques d\'apprentissage. \r\n\r\nUn premier travail réalisé dans le cadre d\'un postdoc va concerner\r\nl\'étude et la construction du corpus d\'apprentissage. Ce corpus va\r\nêtre ensuite utilisé pour l\'acquisition de terminologie. Pour ce\r\nfaire, il existe différents outils d\'acquisition (outils développés en\r\ninterne au sein d\'Orange Labs et outils \"libres\" disponibles à des\r\nfins de recherche comme ACABIT).\r\n\r\nL\'objectif du stage est de mettre en oeuvre les outils en question puis\r\nde les évaluer sur la base du même corpus.\r\n\r\n\r\nPlus particulièrement, les aspects suivants sont à explorer :\r\n\r\n* Prise en main des outils d\'acquisition de terminologie existant dans\r\n  le laboratoire\r\n* Recherche d\'autres outils\r\n* Définition des critères d\'évaluation (Rappel/Précision, etc. )\r\n* Protocole d\'évaluation par ordonnancement (algorithme RankBoost)\r\n* Mise en oeuvre des méthodes d\'évaluation\r\n* Evaluation et comparaison des méthodes\r\n* Rédaction d\'un rapport \r\n\r\n\r\nProfil\r\nBac + 5 (Master pro ou recherche ou dernière année de Grande Ecole)\r\norienté informatique\r\nDes connaissances linguistiques (terminologie notamment) seraient un\r\nplus.\r\n\r\n\r\nCompétences\r\n\r\nBonne connaissance en informatique\r\nBonnes capacités d\'analyse\r\nRigueur\r\nIntérêt pour les moteurs de recherche\r\n\r\nModalités\r\nSite d\'Orange Labs (Côtes d\'Armor)\r\nAdresse 2 avenue Pierre Marzin 22301 Lannion\r\n\r\n4 à 6 mois à partir du printemps 2010\r\nStage rémunéré\r\n\r\nContact\r\nNajeh HAJLAOUI  - 02 96 05 12 82 \r\nNajeh.Hajlaoui@orange-ftgroup.com   \r\n\r\nEdmond LASSALLE 02 96 05 15 98\r\nEdmond.Lassalle@orange-ftgroup.com'),
(51, '2010-02-04', 'LIMSI', 'Orsay', 'Le groupe Traitement du Langage Parlé\r\n(http://www.limsi.fr/tlp/index.html) du LIMSI-CNRS propose plusieurs\r\nstages de master recherche, professionel, ou ingénieurs. Vous\r\ntrouverez les descriptifs de ces propositions à l\'adresse suivante :\r\nhttp://www.limsi.fr/Individu/allauzen/stages/index.html\r\n\r\nN\'hésitez pas à faire circuler cette information et à nous contacter\r\npar mail pour des informations complémentaires. Les personnes\r\nintéressées par l\'une ou l\'autre de ces propositions sont invitées à\r\ncontacter les responsables (de préférence par courrier électronique)\r\nen joignant un CV et en précisant le ou les sujets concernés.\r\n\r\n\r\nDescription des activités du groupes :\r\n\r\nLes recherches du groupe Traitement du Langage Parlé du LIMSI-CNRS ont\r\npour principaux objectifs de modéliser la parole et concevoir des\r\nalgorithmes pour son traitement automatique. Les activités du groupe\r\nsont par essence pluridisciplinaires,et elles abordent le traitement\r\nde la parole et du langage d\'un point de vue acoustique, phonétique,\r\nlinguistique et informatique. Elles s\'intéressent également au lien\r\nentre parole et sens, ainsi qu\'à la modélisation des processus de\r\ncommunication orale.\r\n\r\nLe besoin de confronter nos modèles aux données nous amène à\r\ndévelopper des systèmes de traitement du langage parlé assurant des\r\nfonctions variées telles que la reconnaissance de la parole, la\r\ntraduction automatique, l\'identification de la langue, du locuteur et\r\nde son état émotionnel, le dialogue oral homme-machine, la\r\nstructuration de documents audiovisuels.\r\n\r\n\r\n     Alexandre Allauzen\r\nUniv. Paris XI, LIMSI-CNRS\r\nTel : 01.69.85.80.64 (80.88)\r\nBur : 114     LIMSI Bat. 508\r\n     allauzen@limsi.fr'),
(52, '2010-02-04', 'Syllabs', 'Paris', 'STAGE EN TAL\r\n\r\nContexte\r\n********\r\nOutil d\'aide au linguiste\r\n\r\nL\'un des aspects clés des applications en Traitement Automatique des\r\nLangues est lié à la qualité de ressources linguistiques sur\r\nlesquelles celles-ci s\'appuient. A priori les ressources sont toujours\r\nperfectibles, mais son enrichissement et raffinement est un processus\r\ncoûteux et parfois assez fastidieux pour les linguistes. Le but des\r\noutils d\'aide au linguiste à Syllabs est justement de rendre cette\r\ntâche plus productive et surtout, de faciliter le contrôle de la\r\nqualité.\r\n\r\nDescription du stage\r\n********************\r\n\r\nLa personne recrutée pour ce stage aura deux tâches principales :\r\n\r\n- Prise en main d\'un nouvel outil d\'annotation, validation des\r\n  fonctionnalités et du manuel\r\n- annotation d\'un corpus en français (entités nommées, parties de\r\n  discours)\r\n\r\nLangue\r\n*******\r\n\r\nFrançais\r\n\r\n\r\nConnaissances souhaitées\r\n************************\r\n\r\n- Étudiant(e) en Linguistique Informatique, Traitement Automatique des\r\n  Langues.\r\n- Goût pour l\'analyse du discours\r\n\r\nDurée\r\n*****\r\n2-3 mois à mi-temps (10-15h hebdomadaires, à discuter)\r\ndébut en fevrier\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse suivante : jobs\r\n/arrobas/ syllabs .com tout en indiquant dans l\'objet du mèl « stage\r\nTAL français ».'),
(53, '2010-02-04', 'Orange Labs', 'Lannion', 'Stage de Master à Orange Labs.\r\nLieu : site de Lannion, France\r\nDurée : 4 à 6 mois à partir de mars/avril 2010.\r\nStage rémunéré.\r\n\r\nThématique du stage :\r\n\r\nCe stage s\'inscrit dans la thématique de la recherche d\'information et\r\nl\'accès aux contenus multimédia. La recherche d\'information\r\nmultilingue (plus précisément cross-lingue ou CLIR) vise à donner à\r\nl\'utilisateur l\'accès à des documents ou à des contenus exprimés dans\r\nune autre langue ou dans plusieurs autres langues que celle de la\r\nrequête.\r\n\r\nUne fonctionnalité de CLIR a été mise en oeuvre et intégrée à un\r\nmoteur de recherche multimédia. Elle s\'appuie sur la traduction des\r\ncontenus et repose sur une approche de traduction à base\r\nd\'apprentissage.\r\n\r\nL\'objet de ce stage consiste à intégrer un ou plusieurs outils de\r\ntraduction s\'appuyant sur d\'autres approches de traduction\r\nautomatique.\r\nEn outre, deux phases d\'évaluation sont prévues. Une première\r\névaluation portera sur les outils de traduction identifiés en\r\ns\'appuyant sur des corpus spécifiques et une seconde phase portera sur\r\nl\'évaluation de la fonctionnalité de CLIR après l\'intégration du/des\r\nnouveaux outils de traduction.\r\n\r\nIl est à noter que l\'intégration des outils de traduction vise en\r\npriorité la traduction des contenus dans plusieurs langues et pourrait\r\ns\'étendre à la traduction des requêtes.\r\n\r\nPerspectives du stage :\r\nLe stage proposé pourrait être suivi d\'une thèse sur le thème de la\r\nrecherche d\'information multilingue et plus précisément sur le\r\ntraitement des requêtes pour le CLIR.\r\n\r\nProfil recherché :\r\n- Bac + 5 (master recherche ou pro).\r\n- Formation de base de préférence en informatique ou en linguistique.\r\n- Bonnes connaissances du TALN.\r\n- Connaissances de la recherche d\'information et de la traduction\r\n  automatique.\r\n- Maîtrise de Linux, Python ou Java, langage de script, C++ serait un\r\n  plus.\r\n- Langues : français et anglais (et si possible espagnol ou allemand\r\n  ou arabe).\r\n- Motivation pour la R&D dans un milieu industriel.\r\n- Motivation pour effectuer une thèse après le stage.\r\n \r\nContact :\r\nMalek Boualem\r\nTel : 02 96 05 29 83\r\nEmail : malek.boualem@orange-ftgroup.com\r\nMerci de préciser l\'objet : Stage de Master sur le CLIR'),
(55, '2010-02-15', 'I3S', 'Nice', 'Lieu : Sophia Antipolis et Nice\r\nDurée : 4 à 6 mois\r\n\r\nL\'équipe Ressources Linguistiques du Laboratoire I3S (Université de\r\nNice) propose le stage (rémunéré) ci-dessous.\r\n\r\nSi vous êtes intéressé(e), merci d\'envoyer un CV à\r\nJacques.Farre@unice.fr\r\n\r\n*Titre : traitement linguistique de requêtes dans des moteurs de\r\nrecherche*\r\n\r\n\r\n*Sujet :* Le bon classement d\'une page web dans l\'ensemble des pages\r\nrépondant à une requête à un moteur de recherche dépend de la\r\npertinence des mots-clés présents dans cette page. Une étude\r\nstatistique des requêtes permet de définir les mots-clés les plus\r\nintéressants.  Cependant des requêtes analogues peuvent se présenter\r\nsous différentes formes, par exemple :\r\n\r\n	Je cherche un appartement en location sur nice\r\n	cherche location appartement Nice\r\n	cherche location appartement sur nice\r\n	cherch location  appartament Nice (avec fautes d\'orthographes)\r\n\r\ngénèrent des jeux de données statistiques différents.\r\nUn traitement de ces requêtes appliquant des technologies du\r\ntraitement automatique des langues naturelles (TALN) permettrait de\r\ncorriger les fautes d\'orthographes des requêtes, de les épurer de\r\nleurs mots fonctionnels (prépositions, articles,...)  trop généraux et\r\ndonc non porteurs de sens, et éventuellement de les normaliser, par\r\nexemple :\r\n\r\n   (action:location; quoi:appartement;lieu:Nice-06).\r\n\r\nCela permettrait alors de « fusionner » différentes requêtes telle que\r\ncelles données ci-dessus et d\'améliorer ainsi les statistiques\r\ngénérées.\r\n\r\nLe stage consistera à se familiariser avec une chaîne d\'analyse du\r\nfrançais et ses ressources linguistiques (lexiques, grammaires ...)\r\npuis à l\'adapter pour obtenir une forme aussi normalisée que possible\r\ndes requêtes. Il comprendra des visites à une PME niçoise spécialisée\r\ndans le référencement commercial sur le web.'),
(57, '2010-03-08', 'LIPN', 'Villetaneuse', 'Sujet : Indexation et recherche d\'information sémantiques\r\n\r\nContexte\r\n\r\nL\'utilisation d\'ontologies dans le cadre d\'une recherche d\'information\r\na pour but de dépasser les limites d\'une recherche classique par mots\r\nclés. Le Web sémantique propose une infrastructure qui permet de\r\nmettre en place une recherche sémantique.\r\n\r\nLa vision implicite du Web Sémantique repose sur les hypothèses\r\nsuivantes :\r\n\r\n- Il existe des ontologies formelles pour décrire objectivement les\r\n  connaissances d\'un domaine.\r\n\r\n- Il est possible de décrire le contenu de documents en utilisant les\r\n  concepts de ces ontologies.\r\n\r\n- Il est possible pour l?utilisateur de rechercher l\'information en\r\n  utilisant ces mêmes concepts.\r\n\r\nActuellement, même s\'il existe de plus en plus d\'ontologies, il est\r\ndifficile de trouver une ontologie qui couvre la totalité des\r\nconnaissances d\'une base documentaire et qui permettrait de ce fait\r\nd\'accéder à toute l\'information contenue dans cette base. L\'idée est\r\ndonc de proposer des méthodes d\'indexation et de recherche\r\nd\'information qui exploitent la sémantique représentée dans une\r\nontologie (par opposition à la sémantique latente, LSI[1]) mais\r\négalement le texte lui-même pour ne pas être restreint par la\r\ncouverture de l\'ontologie [4].\r\n\r\nObjectifs\r\n\r\n    * Établir un état de l\'art sur les méthodes de recherche\r\n      d\'information sémantique.\r\n\r\n    * Proposer des méthodes d\'indexation qui permettent de combiner\r\n      des modèles classiques de Recherche d\'Information (e.g. modèle\r\n      vectoriel [2]) avec l\'exploitation d\'une ontologie par le biais\r\n      de mesures de proximité sémantique (e.g mesure de Wu&Palmer\r\n      [3]).\r\n\r\n    * Implémenter des propositions sur la base du moteur de recherche\r\n      Lucene[5].\r\n\r\n    * Participer à la création d\'un benchmark pour une évaluation\r\n      comparative par rapport à une recherche d\'information classique.\r\n\r\nProfil recherché\r\n\r\n    * Intérêt pour l\'IC et la Recherche d\'Information\r\n    * Autonome en informatique : connaissance d\'UNIX, de Java (ou\r\n      autre langage OO)\r\n\r\nConditions\r\n\r\nBac + 5 (Master pro ou recherche ou dernière année ingénieur) orienté\r\ninformatique\r\n\r\nStage de 4 à 6 mois, rémunéré.\r\n\r\nLieu du stage : LIPN (http://www-lipn.univ-paris13.fr/), Université\r\nParis 13.\r\n\r\nResponsables\r\n\r\nSylvie Salotti & Haïfa Zargayouna\r\nPour envoyer votre candidature, envoyer un CV et une lettre ou un mail\r\nde motivation à : sylvie.salotti at lipn.univ-paris13.fr,\r\nhaifa.zargayouna at lipn.univ-paris13.fr\r\n\r\nLiens et références\r\n\r\n[1] S. Deerwester, Susan Dumais, G. W. Furnas, T. K. Landauer,\r\nR. Harshman (1990).  Indexing by Latent Semantic Analysis. Journal of\r\nthe American Society for Information Science 41 (6): 391?407.\r\n\r\n[2] G. Salton , A. Wong , CS Yang (1975) A vector space model for\r\nautomatic indexing , Communications of the ACM, v.18 n.11, p.613-620,\r\nNov. 1975\r\n\r\n[3] Z. Wu & M. Palmer (1994) Verb Semantics and Lexical Selection,\r\nProceedings of the 32nd Annual Meetings of the Associations for\r\nComputational Linguistics, pages 133-138.\r\n\r\n[4] H. Zargayouna (2005) \"Indexation sémantique de documents XML\"\r\nThèse, Université Paris-Sud.\r\n\r\n[5] http://lucene.apache.org/'),
(59, '2010-03-15', 'TEMIS', 'Paris', '*Sujet de stage informatique, niveau M2 : * CRF pour l\'extraction \r\nd\'entités/relations dans des textes\r\n\r\n*Lieu :* société Temis, Paris\r\n\r\nLa société Temis édite une solution logicielle pour traiter les\r\ndocuments textuels. Elle est capable de les classer suivant leur\r\nlangue ou leur domaine, d\'en extraire les « entités » importantes et\r\nde caractériser les relations prédicatives qu\'entretiennent ces\r\nentités entre elles.\r\n\r\nLe module d\'extraction est réalisé à l\'aide de règles écrites à la\r\nmain.  Ces règles sont spécifiques de la langue des documents et du\r\ndomaine sur lequel ils portent, elles peuvent donc être longues et\r\nfastidieuses à écrire. Or, des techniques d\'apprentissage automatique\r\nexistent depuis quelques années pour apprendre à extraire de\r\nl\'information à partir d\'exemples (ce sujet a par exemple donné lieu à\r\nla « shared task » de CoNLL 2003, 17 compétiteurs y ont\r\nparticipé). Plusieurs approches différentes possibles peuvent être\r\nmises en oeuvre pour cela : celles qui donnent actuellement les\r\nmeilleurs résultats sont fondées sur les CRF (Conditional Random\r\nFields), un modèle statistique permettant d\'annoter des items lexicaux\r\navec des labels qui désignent les zones à extraire.\r\n\r\nL\'objectif de ce stage est de tester cette méthode sur un corpus de\r\ndocuments. Différentes étapes seront donc nécessaires :\r\n\r\n    * Il faudra dans un premier temps constituer un corpus d\'exemples\r\n      et l\'annoter pour servir de base à l\'apprentissage automatique.\r\n      L\'outil final de Temis peut servir à réaliser cette base, mais\r\n      comme il ne produit pas une extraction parfaite, des stratégies\r\n      d\'amélioration de l\'annotation initiale devront être envisagées.\r\n\r\n    * Il s\'agira ensuite de fixer les paramètres de\r\n      l\'apprentissage. Les CRF requièrent notamment la définition d\'un\r\n      ensemble de « fonctions features » qui caractérisent des\r\n      configurations locales d\'annotations. La définitions de ces\r\n      features est laissée à l\'initiative du programmeurs, mais des\r\n      méthodes classiques existent pour les générer à partir des\r\n      données annotées. Or Temis dispose aussi de ressources\r\n      linguistiques sous la forme de dictionnaires ou de règles\r\n      écrites à la main. Le coeur du stage sera d\'étudier dans quelle\r\n      mesure ces ressources peuvent être traduites sous la forme de\r\n      features, de façon aussi automatique que possible.\r\n\r\n    * Il faudra ensuite procéder à diverses expériences pour évaluer\r\n      la qualité de l\'extraction obtenue par apprentissage\r\n      automatique, et la comparer avec celle obtenue par les règles\r\n      écrites à la main.  Cette qualité peut dépendre grandement de la\r\n      langue et du domaine du document, ainsi que de l\'ensemble des\r\n      features utilisées pour l\'apprentissage.\r\n\r\nCe qui est attendu à l\'issue de ce stage est la définition d\'une\r\nchaîne de traitements mèlant production manuelle de ressources et\r\napprentissage automatique, qui optimise la qualité de l\'extraction\r\nfinale.\r\n\r\n\r\n*Ref bibliographiques :*\r\n\r\nDaelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.\r\n\r\nJousse F., Tellier I., Tommasi M., Marty P. : « Learning to Extract\r\nAnswers in Question Answering: Experimental Studies », Coria 2005,\r\np85-99.\r\n\r\nLafferty J., McCallum A., Pereira F. : « Conditional Random Fields:\r\nProbabilistic Models for Segmenting and Labeling Sequence Data »,\r\nactes de ICML, pages 282--289, 2001.\r\n\r\nPoibeau, T : Extraction Automatique d\'Information, Hermes, Paris,\r\n2003.\r\n\r\nSutton , McCallum A : « An Introduction to Conditional Random Fields »\r\ndans « Introduction to Statistical Learning », MIT Press, 2006.\r\n\r\n\r\n*Compétences requises : *niveau M2 informatique, avec des\r\nconnaissances ou au moins un intérêt pour le TALN, l\'extraction\r\nd\'information et l\'apprentissage automatique\r\n\r\nLe stage peut commencer dès avril pour au moins 4 mois, il est\r\nrémunéré au tarif 1/3 Smic.\r\n\r\n*Encadrement : *Hervé Azoulay, de la société Témis et Isabelle\r\n Tellier, professeur à l\'université d\'Orléans\r\n\r\nEnvoyer CV + lettre de motivation à *herve.azoulay@temis.com* et\r\n*isabelle.tellier@univ-orleans.fr*.'),
(60, '2010-06-16', 'LexisNexis', 'Paris', 'Stage de 3 à 6 mois - Linguiste informaticien / Terminologue\r\n\r\nLexisNexis en France (600 collaborateurs, 139 M¤ de CA), filiale du\r\ngroupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les\r\nservices d\'information professionnelle. Ses activités couvrent trois\r\ndomaines : l\'information et l\'édition juridiques, la diffusion de la\r\npresse et de l\'information économique et financière sur Internet, les\r\nlogiciels professionnels.\r\n\r\nL\'entreprise s\'appuie sur une expertise éditoriale centenaire et sur\r\nune technologie de pointe pour apporter au monde du droit et aux\r\nprofessionnels de tous secteurs d\'activités une vaste gamme de\r\nproduits et services réputés : JurisClasseur, Litec, D.O, Bottin\r\nAdministratif et les services en ligne LexisNexis.\r\n\r\nLexisNexis vous propose de rejoindre le service Veille et management\r\nde l\'information dans le cadre d\'un stage d\'une durée de 3 à 6 mois\r\n\r\nVous interviendrez principalement sur le programme de traitement\r\nautomatique d\'un thesaurus monolingue dans un but d\'indexation de\r\ncontenus juridiques.\r\n\r\nLes principales tâches seront :\r\n\r\n- participer à l\'amélioration et à l\'optimisation du traitement\r\n  automatique\r\n\r\n- réaliser des analyses qualité et des tests de non-régression\r\n\r\nVous serez également amené à travailler sur l\'enrichissement du\r\nthesaurus.\r\n\r\nCOMPETENCES REQUISES :\r\n\r\n- Très bonnes connaissances linguistiques et très bonne orthographe\r\n- Maîtrise de l\'outil informatique\r\n- Esprit d\'analyse\r\n- Des connaissances en droit seraient un plus.\r\n\r\nRigoureux (se), organisé(e) et sérieux(se), vous faites preuve d\'un\r\nbon relationnel.\r\n\r\n \r\nLIEU : \r\n141 rue de Javel\r\n75015 PARIS\r\n\r\nDURÉE : \r\n3 à 6 mois à pourvoir à partir du 15/06/2010.            \r\n\r\nMODALITÉS :\r\nIndemnité mensuelle de 417,09 euros \r\n50 % carte orange.\r\nConvention de stage obligatoire\r\n \r\nCONTACT :\r\nMerci d\'envoyer votre candidature (CV + lettre de motivation) ainsi\r\nque vos disponibilités par mail : recrutement@lexisnexis.fr avec la\r\nréférence SLL005.'),
(61, '2010-09-03', 'Cellfish Media', 'Paris', 'Cellfish Media recherche un stagiaire pour mettre en place un système\r\nde simulation de dialogue en langage naturel dans nos architectures,\r\net l\'implémentation de ce système dans nos services.\r\n\r\n\r\nDans ce cadre, vos missions principales seront :\r\n\r\n· Le suivi de l\'intégration du système de dialogue dans nos\r\n  architectures.\r\n\r\n· Le développement et la documentation du programme de pilotage du\r\n  robot.\r\n\r\n· Le calibrage du système via la définition de méthodes d\'évaluation\r\n  qualitative et quantitative du robot et via la configuration du\r\n  service.\r\n\r\n· La coordination de ces tâches avec les équipes technique, produit et\r\n  marketing.\r\n\r\n· Le suivi de projet en méthodologie agile ou traditionnelle, le suivi\r\n  de la recette, la documentation du projet.\r\n\r\n  Profil du candidat\r\n\r\n\r\n\r\n   - De formation supérieure technique/scientifique/multimédia, vous\r\n     êtes passionné par les nouveaux médias et les enjeux de\r\n     l\'utilisation de l\'internet mobile.\r\n\r\n   - Vous montrez un intérêt pour la R&D dans le domaine du dialogue\r\n     naturel homme/machine. Avoir réalisé des projets dans ce domaine\r\n     serait un atout important.\r\n\r\n   - Vous avez de bonnes connaissances des sujets suivants :\r\n\r\n- principes techniques fondamentaux de l\'internet (HTML, XML,\r\n  protocole http, SQL).\r\n\r\n- programmation objet et UML.\r\n\r\n   - Vous maîtrisez l\'anglais tant à l\'oral qu\'à l\'écrit.\r\n   - Vous êtes à l\'aise avec les outils de bureautique traditionnels.\r\n   - Vous aimez travailler en équipe sur des sujets innovants, savez\r\n     faire preuve d\'autonomie et faire des propositions. Vous aimez\r\n     rechercher des solutions avec persévérance. Enfin, vous aimez les\r\n     environnements stimulants et possédez un esprit très créatif.\r\n\r\n\r\nCe stage de 6 mois à temps plein est à pourvoir dès à présent, avec\r\nopportunité d\'emploi pour candidat de valeur.\r\n\r\nIndemnités de stage très motivantes + prise en charge à 50% du titre\r\nde transport parisien et des déjeuners.\r\n\r\n*Cellfish Media*\r\n\r\nCellfish Media* **est basée aux Etats-Unis et est présente en France,\r\nen Allemagne et au Canada. Elle réunit plus de 320 collaborateurs.***\r\n\r\nCellfish Media est un acteur majeur de l\'édition de services mobiles\r\navec plus de 14 millions de clients uniques dans le monde, notamment\r\nen France où elle est leader. Cellfish Media produit au sein de ses\r\nstudios des contenus originaux spécifiques pour le mobile et les\r\ndiffuse auprès des consommateurs à travers un vaste réseau de sites et\r\nservices mobiles.\r\n\r\nElle propose par ailleurs aux médias et aux opérateurs des solutions\r\nde marketing mobile pour monétiser leur trafic et aux annonceurs, un\r\noutil de conquête puissant et ciblé.\r\n\r\n*Contacts*\r\n\r\nwww.cellfishmedia.fr\r\n\r\n\r\n Xavier Laisney\r\nTechnical Project Manager - Cellfish Media\r\nT: +33 1 72 59 58 15\r\nxavier.laisney@cellfishmedia.fr\r\nwww.cellfishmedia.com');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(62, '2010-09-09', 'Céditec', 'Créteil', 'Offre de stage\r\n\r\nNavigation données textuelles, Textopol, Céditec\r\nUPEC (université de Paris Est Créteil Val de Marne)\r\n\r\nProfil recherché : Etudiant de master 2 en INFORMATIQUE/intégration \r\nmultimédia/développement. Connaissances java et java 3D appréciées ainsi \r\nqu\'un autre langage de programmation. La formation à la textométrie sera \r\nassurée sur place.\r\n\r\nLe stagiaire aura pour mission de développer une interface de navigation \r\ndes données textuelles basée sur un modèle d\'analyse factorielle des \r\ncorrespondances (3D et mouvement) tel que décrit aux adresses suivantes :\r\n\r\nhttp://textopol.free.fr/contrib2010.php \r\n\r\nhttp://textopol.free.fr/dotclear/index.php?2010/06/09/29-pour-une-textomtrie-multimdia-ou-tad-20\r\n\r\n\r\nLa maquette devra disposer d\'un module de segmentation (a minima la forme \r\ngraphique) rendant le dispositif autonome et facilement adaptable à une \r\nversion Web de la plate forme TXM. Cette version sera développée dans un \r\nsecond temps pour compléter l\'interface du site textopol.org.\r\n\r\nhttp://textometrie.ens-lyon.fr/\r\n\r\nOrganisme d\'accueil : Céditec, université de Paris Est Créteil Val de \r\nMarne (61 avenue du général de Gaulle, 94 000 Créteil)\r\nhttp://ceditec.u-pec.fr/\r\n\r\n\r\n4 mois + PFE : 2000 euros nets pour l\'ensemble de la période - \r\nPossibilité d\'un bureau et d\'une machine pour les candidats de la région \r\nparisienne.\r\n\r\nUne ANR sera déposée en avril pour des développements plus poussés. Si \r\ncette ANR est acceptée un contrat de 36 mois (2000 euros nets /mois) est \r\nprévu pour un développeur informatique (post doc, doctorant...)\r\n\r\n\r\nContact : JM Leblanc\r\njean-marc.leblanc@u-pec.fr\r\n\r\nResponsable Textopol : Pierre Fiala\r\nfiala@u-pec.fr\r\n\r\nDirecteurs du Céditec :\r\nCaroline ollivier Yaniv\r\nyaniv@u-pec.fr\r\nDominique Ducard\r\nducard@u-pec.fr\r\n\r\nDate limite de réception des candidatures: 27 septembre 2010 - Envoyer CV \r\net lettre de motivation par mail à \r\njean-marc.leblanc@u-pec.fr'),
(63, '2010-09-24', 'Vision Objects', 'Nantes', 'Poste proposé : Stagiaire ingénieur R&D Traitement Automatique du Langage (TAL)\r\nType d\'offre : Stage (stage conventionné)\r\nRégion : Pays de la Loire\r\nLieu : Nantes (44)\r\n\r\nEntreprise\r\n\r\nCréée en 1998, VISION OBJECTS (www.visionobjects.com) est un éditeur\r\nde logiciels spécialisé dans la reconnaissance d\'écriture manuscrite\r\ns\'appliquant aux marchés de la mobilité (Smartphone, Tablet, PC,\r\nstylos numériques...), du formulaire, de la prise de notes, de\r\nl\'éducation et de l\'automobile.  Vision Objects est leader sur ces\r\nmarchés et réalise 90% de son CA à l\'international.\r\n\r\nMissions\r\n\r\nRattaché(e) au Responsable R&D et en coordination avec les ingénieurs\r\nLinguistes de la société, vous aurez comme principales missions :\r\n\r\n- Prise en main des diverses technologies de modélisation du langage\r\n  développées par la société (N-gram, N-class, etc)\r\n\r\n- Elaboration d\'un protocole expérimental visant à comparer ces\r\n  diverses techniques avec leur différents compromis (back-off,\r\n  cut-off, etc)\r\n\r\n- Définition de critères de performance (perplexité, taux d\'erreurs,\r\n  etc)\r\n\r\n- Mise en ½uvre du protocole sur différentes langues incluant des\r\n  langues latines, cyrilliques, asiatiques, etc\r\n\r\n- Analyse des avantages, faiblesses et complémentarités des diverses\r\n  technologies\r\n\r\n- Développement de nouvelles technologies de modélisation du langage\r\n  visant à améliorer les performances des systèmes actuels de\r\n  reconnaissance (e.g PCFG - Probabilistic Context Free Grammar, LSA -\r\n  Latent Semantic Analysis)\r\n\r\nProfil recherché\r\n\r\n- Ingénieur R&D en TAL\r\n- Titulaire ou en cours d\'obtention d\'un Master 2 en TAL\r\n- Rigoureux(se) et investi(e), vous êtes vif(ve) d\'esprit et curieux(se)\r\n- Pratique régulière des langages scripts tel que Perl\r\n- Solides connaissances en développement C/C++ sous environnement Visual\r\n- Pratique et/ou connaissance de diverses langues souhaitées\r\n\r\nDurée\r\nA définir : minimum 4 mois\r\nDébut du stage : Ce stage est à pourvoir dès que possible\r\nIndemnités de stage\r\n\r\nMerci d\'adresser votre CV et lettre de motivation à  job@visionobjects.com'),
(64, '2010-10-04', 'Temis', 'Paris', '6-12 month Internship - Life Science Text Mining QA at TEMIS France\r\n\r\nTEMIS, is a leading provider of text mining solutions in various\r\nfields (life sciences, competitive intelligence, events, sentiment\r\nanalysis).  With a view to enhancing the life sciences package TEMIS\r\nhas opened a 6-12 month internship position in the R&D Life Sciences\r\ndepartment.\r\n\r\nMain Responsibilities:\r\n\r\n- Evaluate and report on the quality of identified biological and\r\n  medical terms\r\n\r\n- Evaluate and report on the quality of identified biological and\r\n  medical relationships between terms\r\n\r\n- Constitute and annotate a corpus in the life sciences domain\r\n\r\n- Using this annotated corpus as reference, evaluate and report on the\r\n  recall of identified biological and medical terms and relationships\r\n  between them\r\n\r\nSkills, Knowledge and Experience:\r\n\r\n- Fluent English\r\n\r\n- Good knowledge and understanding of biological and medical terms\r\n\r\n- Java and text mining skills would be a plus\r\n\r\nLocation:\r\n\r\n164 rue de Rivoli, Paris\r\n\r\nDuration of the internship:\r\n\r\n6-12 months\r\n\r\nMonthly Indemnity:\r\n\r\n417 Euros net\r\n\r\nPlease send CV and cover letter to dominique.noel@temis.com\r\n\r\nDr Dominique Noel\r\nSenior Computational Linguist\r\n\r\nTEMIS\r\n164 rue de Rivoli \r\n75001 Paris - FRANCE\r\n\r\nTel: 01 80 98 11 36\r\nFax: 01 80 98 11 01\r\n\r\nwww.temis.com <http://www.temis.com/>'),
(65, '2010-11-12', 'Syllabs', 'Paris', 'Stage en linguistique informatique (ANGLAIS)\r\n********************************************\r\n\r\nContexte\r\n********\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse\r\nde données textuelles du Web : identification des pages pertinentes,\r\ncrawling du Web, extraction et catégorisation des informations clé.\r\n\r\nActuellement, nous recherchons un(e) stagiaire pour travailler dans le\r\ndomaine de la création automatique de textes en anglais. L\'idée est de\r\ncréer des textes à partir d\'une base de données existante (par exemple\r\nla liste des informations sur une ville) ou créée en utilisant nos\r\noutils d\'analyse sur des textes crawlés du web.\r\n\r\nSujet du stage\r\n***************\r\n\r\nDéveloppement de règles de création de textes en anglais.\r\n\r\nObjectifs du stage\r\n******************\r\n\r\nLa personne recrutée pour ce stage aura deux tâches principales :\r\n\r\n1. Développement de règles de création de textes. Cette tâche implique\r\n   une prise en main de l\'outil, une formation au langage de l\'outil\r\n   et l\'écriture des règles spécifiques pour différents domaines. Dans\r\n   un premier temps, la personne sera amenée à créer des règles pour\r\n   des textes courts. Ensuite, il lui sera demandé de créer de textes\r\n   plus longs et de réfléchir à l\'articulation des différentes parties\r\n   (ex : choix des connecteurs).\r\n\r\n2. Écriture des règles d\'extraction d\'information pour alimenter une\r\n   base de données.\r\n\r\n3. Enrichissement du lexique morphosyntaxique anglais utilisé dans les\r\n   règles.\r\n\r\nProfil souhaité\r\n***************\r\n\r\n- Étudiant(e) en Linguistique Informatique, Traitement Automatique des\r\n  Langues.\r\n\r\n- Langue maternelle anglais ou équivalent (long séjour dans pays\r\n  anglophone, minimum 5 ans).\r\n\r\n- Excellentes qualités rédactionnelles en anglais, goût pour\r\n  l\'écriture.\r\n\r\n- Aptitude pour la représentation formelle du langage.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage TAL EN ».\r\n\r\nDurée : stage de fin d\'études (3 à 6 mois)\r\nDébut du stage souhaité : entre février et juin 2011.\r\nLieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris.'),
(66, '2010-11-12', 'Syllabs', 'Paris', 'Sujet du stage : détection de concepts émergents dans un flux\r\nmultimédia\r\n\r\nDurée : stage de fin d\'études (5 à 6 mois)\r\nDébut du stage souhaité : entre février et avril 2011\r\nLieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris \r\nhttp://www.syllabs.com \r\n\r\nMots-clés : apprentissage automatique, catégorisation, clustering,\r\nmultimédia\r\n\r\nContexte\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création\r\nautomatique de textes. Nos technologies apportent des solutions\r\nd\'analyse de données textuelles du Web : identification, récupération\r\net nettoyage des pages pertinentes, extraction et catégorisation des\r\ninformations clé.\r\n\r\nNous recherchons un(e) stagiaire dans le cadre du projet ANR SuMACC\r\nauquel participent Eurecom, le Laboratoire Informatique d\'Avignon et\r\nWikio. Le projet SuMACC (apprentissage coopératif semi-Supervisé de\r\nconcepts Multimédias pour l\'Aide à la Catégorisation et la détection\r\nde Concepts) propose d\'explorer des stratégies d\'apprentissage\r\noriginales pour l\'identification de nouveaux concepts ou entités\r\nmultimédias à partir de patrons d\'identification. Le démarrage du\r\nprojet est prévu pour la fin 2010.\r\n\r\nObjectifs\r\n\r\nNous nous plaçons dans le contexte d\'une base de documents volumineuse\r\ncontenant du texte, des images, de l\'audio et de la vidéo. Le maintien\r\nde la base requiert une catégorisation et une indexation des documents\r\ndans un thésaurus par des documentalistes. Le thésaurus peut lui-même\r\nsubir des mises à jour en fonction de l\'évolution du contenu de la\r\nbase (nouveaux thèmes émergents par exemple). Ces tâches sont très\r\ncoûteuses car actuellement effectuées de façon quasi-manuelle par les\r\ndocumentalistes.\r\n\r\nLe stage proposé vise à automatiser une partie de ces tâches. En\r\nparticulier, il faudra concevoir, implémenter et évaluer des méthodes\r\nautomatiques pour :\r\n\r\n- détecter les nouvelles entrées ou concepts à ajouter au thésaurus ;\r\n\r\n- contrôler la cohérence d\'un concept du thésaurus à travers une\r\n  mesure d\'homogénéité des documents qu\'il caractérise ;\r\n\r\n- proposer aux documentalistes de nouveaux termes liés à chaque\r\n  concept du thésaurus ;\r\n\r\nLe point sur le \"contrôle de cohérence\" nécessite la définition d\'une\r\nou plusieurs mesures d\'homogénéité pour un ensemble de documents, en\r\ntenant compte de leur nature multimédia. Ce stage aura pour effet\r\nd\'améliorer l\'efficacité du travail des documentalistes.\r\n\r\nLa personne travaillera au sein de l\'équipe R&D.\r\n\r\nProfil souhaité\r\n\r\n    * Ecole d\'ingénieurs avec un goût pour la recherche, master 2\r\n      recherche en informatique\r\n\r\n    * Bonnes compétences en programmation : maîtrise de Java et Python\r\n      souhaitée\r\n\r\n    * Spécialisation en statistiques, apprentissage automatique,\r\n      classification\r\n\r\nEléments facultatifs mais considérés comme un plus :\r\n\r\n\r\n    * Connaissances souhaitées dans le domaine du\r\n      Traitement Automatique des Langues\r\n\r\n    * Maîtrise d\'une ou plusieurs langues étrangères\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nstage_emergence@syllabs.com .'),
(67, '2010-11-17', 'Atchik Services', 'Toulouse', 'Stage en TALN\r\n\r\n\r\n\r\n\r\n\r\nDescription du poste\r\n\r\n\r\n\r\nDans le cadre de la refonte de ses outils de modération automatique,\r\n\r\nAtchik recherche un stagiaire (H/F)\r\n\r\n\r\n\r\n \r\n\r\nLa société\r\n\r\n\r\n\r\nPionnier du marketing conversationnel et de la modération, Atchik\r\n\r\naccompagne marques et médias dans la gestion de leurs espaces\r\n\r\ncommunautaires. Ses équipes traitent chaque mois près de 40 millions\r\n\r\nde messages sur les blogs, les forums et les réseaux sociaux.\r\n\r\n\r\n\r\nLa mission\r\n\r\n\r\n\r\nAu cour du département technique, vous contribuez au processus\r\n\r\nd\'innovation en étroite collaboration avec les ingénieurs de\r\n\r\ndéveloppement et les autres intervenants de l\'équipe (modérateurs et\r\n\r\ncommunity managers).\r\n\r\n\r\n\r\nVotre mission vise l\'amélioration significative des résultats de notre\r\n\r\nsystème automatique de filtrage de contenu textes.\r\n\r\n\r\n\r\nCette tâche principale fera appel à de nombreuses compétences dans les\r\n\r\ndomaines suivants : information retrieval, computational linguistics,\r\n\r\nmachine learning, information management, matrix and graph algorithms,\r\n\r\nlarge scale data mining.\r\n\r\n\r\n\r\n- adapter des approches existantes aux contraintes spécifiques\r\n\r\n  d\'Atchik et de ses clients (nouvelle problématique de langage...)\r\n\r\n\r\n\r\n- analyser et valoriser les données traitées manuellement par les\r\n\r\n  équipes Atchik, identifier les problèmes,\r\n\r\n\r\n\r\n- concevoir des solutions compatibles avec la taille des données et\r\n\r\n  l\'architecture technique, produire des prototypes, contribuer à\r\n\r\n  l\'industrialisation des solutions\r\n\r\n\r\n\r\n\r\n\r\nProfil\r\n\r\n\r\n\r\nVous terminez une formation initiale ou continue de niveau master ou\r\n\r\ndiplôme d\'ingénieur dans un des domaines suivants ou apparentés:\r\n\r\n\r\n\r\nInformatique, Machine Learning, Linguistique Computationnelle,\r\n\r\nStatistiques, Recherche d\'Information etc\r\n\r\n\r\n\r\n\r\n\r\nCompétences recherchées\r\n\r\n\r\n\r\n- Connaissance forte en Machine Learning, Information Retrieval\r\n\r\n(clustering, classification, test d\'hypothèse)\r\n\r\n- La connaissance de Hadoop est un gros plus.\r\n\r\n- Une connaissance du NLP est un plus (classification de texte,\r\n\r\ndétection du spam).\r\n\r\n- Connaissance et passion pour le monde du Web \r\n\r\n- Connaissance d\'un ou plusieurs langages de scripts :java et perl minimum\r\n\r\n- Connaissance des outils Linux\r\n\r\n- Outils de développement collaboratif (SVN,test unitaires) Conception\r\n\r\net Développement orienté objet en Java \r\n\r\n- Maîtrise de l\'anglais technique.\r\n\r\n \r\n\r\n\r\n\r\n\r\n\r\nSi cette offre vous intéresse, merci d\'adresser votre candidature (CV\r\n\r\n+ lettre de motivation) à job@atchik-services.com en précisant la\r\n\r\nréférence [TALN] dans l\'objet de votre email.'),
(68, '2010-12-15', '118712 (Orange)', 'Paris', 'Intitulé : Amélioration de la qualité des adresses sur des données\r\nannuaire\r\n\r\nMission\r\nLa direction 118712 est une entité marketing en charge de la\r\ndéfinition, de la conception et du déploiement des offres de\r\nrenseignements annuaire d\'Orange sur différents canaux (renseignements\r\ntéléphoniques, web, mobile,...).\r\n\r\nL\'annuaire comprend différentes informations reçues des opérateurs\r\nsous des formes multiples. Ces données font l\'objet de traitements\r\nrécurrents permettant de les normaliser, de les homogénéiser et d\'en\r\nextraire les informations les plus pertinentes pour renseigner les\r\nclients de la meilleure façon possible.\r\n\r\nL\'objectif du stage est de permettre l\'amélioration de la qualité des\r\ndonnées annuaire dans les traitements récurrents permettant\r\nd\'interpréter et de normaliser les adresses (localités, codes postaux,\r\nrues,...).\r\n\r\nLe stagiaire devra s\'imprégner de l\'existant (fonctionnement du\r\nsystème de redressement d\'adresses) et aura en charge la réalisation\r\ndes tâches suivantes :\r\n\r\n- l\'analyse des données\r\n- la proposition d\'améliorations avec les outils mis à disposition\r\n- les tests qualité (non-régression et amélioration)\r\n- la communication des évolutions\r\n- la documentation du travail fourni\r\n\r\nProfil recherché\r\nBac + 5 (Master pro ou recherche)\r\nSpécialiste des langages formels (traitement automatique des langues,\r\nlinguistique)\r\n\r\nCompétences\r\n- manipulation de gros volumes de données\r\n- maîtrise d\'excel et d\'outils de manipulation de bases de données\r\n  (SQL, Access, Business Object,...)\r\n- bonnes capacités d\'analyse\r\n- goût pour la résolution de problèmes\r\n- rigueur\r\n- bonne communication\r\n\r\nModalités\r\n- Site de France Télécom en Ile-de-France\r\n- 6 à 7 mois à partir de mars 2010\r\n- Stage rémunéré\r\n\r\nContact\r\nEstelle Maillebuau\r\nestelle.maillebuau@orange-ftgroup.com'),
(69, '2010-12-27', 'EDF', 'Clamart', 'Stage Bac + 5 au centre de recherche d\'EDF à Clamart (92)\r\n\r\nSujet : Modélisation sémantique de concepts métiers et d\'opinions sur\r\ndes données textuelles « spontanées »\r\n\r\nLa R&D d\'EDF met en œuvre des techniques de Text Mining pour optimiser\r\nsa relation client, en analysant des questions ouvertes d\'enquête de\r\nsatisfaction, des retranscriptions de conversations issues des centres\r\nd\'appels, et des corpus web.\r\nLa chaîne de traitement text mining (lemmatisation, extraction de\r\nconcept métier, segmentation, classement) permet ainsi de classer ces\r\ndonnées selon différentes thématiques et opinions. Que ces données\r\nsoient issues de l\'oral (centres d\'appel) ou du web (blogs, forums,\r\nréseaux sociaux), les entrées de la chaîne text mining diffèrent de\r\ncelles classiquement traitées. Ces spécificités liées à l\'expression\r\nspontanée sont difficiles à appréhender, notamment lors de l\'étape\r\nd\'extraction de concepts métiers qui repose sur une modélisation\r\nsémantique à l\'aide de lexiques et de règles. Ces règles peuvent\r\ns\'avérer peu adaptées à des données présentant des structures\r\ndifférentes de celles des données textuelles classiques.  L\'objectif\r\nde se stage sera d\'identifier ces différences en analysant les\r\ndifférents corpus disponibles à EDF et de proposer des alternatives\r\naux méthodes utilisées jusque maintenant sur des données textuelles\r\nclassiques.\r\n\r\nProfil recherché :\r\nBac+5, stage de fin d\'étude dans le domaine du TALN.\r\n\r\nContact  et envoi des candidatures :\r\nChloé Clavel , 01 47 65 43 15, chloe.clavel@edf.fr\r\nAnne Peradotto , 01.47.65.44.89, anne.peradotto@edf.fr\r\nLieu du stage :  EDF R&D,    1, av du Général de Gaulle,  92141\r\nClamart Cedex\r\nDurée : environ 6 mois \r\nRémunération : environ 1.000€/mois\r\n\r\n\r\nChloe CLAVEL\r\nIngénieur chercheur\r\nEDF \r\nICAME\r\n1, av. du Général de Gaulle\r\n92141 Clamart\r\n \r\nchloe.clavel@edf.fr\r\nTél. : 33 (0)1 47 65 43 15'),
(70, '2010-12-27', 'CNES', 'Toulouse', 'Le service Gestion de l\'information et de la connaissance a pour mission d’assurer la capitalisation et \r\nla valorisation des ressources informationnelles du CNES. En matière de gestion de connaissances, il assure \r\nla maintenance de la base de connaissances, en liaison avec les réseaux d’experts des directions opérationnelles \r\net selon le plan élaboré dans le cadre de la politique de management de l’information. Il met en œuvre les \r\noutils et les moyens associés.\r\n \r\nL’objectif général du stage est de participer au développement de méthodes d\'enrichissement de l\'ontologie \r\nutilisée pour le classement et la recherche des documents de la mémoire d\'entreprise du CNES.\r\n\r\nLa mise en œuvre s\'appuiera d’une part sur une plateforme dédiée qui dispose d\'une capacité d\'analyse de \r\nl\'information textuelle sous la forme d\'un moteur de recherche sémantique, d\'une catégorisation automatique \r\net des fonctions complémentaire et d’autre part, sur des outils d’analyse statistique et d’extraction terminologique.\r\n\r\nDétails et candidature :\r\n\r\nhttp://www.cnes.fr/web/CNES-fr/175-stages-cnes.php?view=item&item=6131'),
(71, '2010-12-27', 'Orange', 'Toulouse', 'Sujet de stage : Etude de l’apport des ontologies à la gestion de produits et de projets\r\n\r\nLieu du stage : Orange, Blagnac\r\n\r\nDurée: de 4 à 5 mois\r\n\r\n\r\nLes activités de Document Process Solutions  telles que la gestion de produits, la gestion de projets, \r\netc. impliquent des processus complexes et faisant intervenir de nombreux composants. L’optimisation \r\nde ces activités nécessite une modélisation rigoureuse qui permette de matérialiser les interactions \r\nentre les divers composants et acteurs. Il s’agit en particulier de s’intéresser à :\r\n\r\n- aider à la rationalisation des activités et à l\'optimisation des pratiques\r\n\r\n- permettre et faciliter la capitalisation des savoirs et savoir faire\r\n\r\n- intégrer la gouvernance venant de l\'urbanisme\r\n\r\nL’objectif du stage est d’étudier l’utilisation des ontologies dans ce cadre. Il s’agit d’étudier la \r\nfaisabilité et l’apport d’une représentation formelle et du  raisonnement permis par les ontologies \r\ndans les domaines en particulier de la gestion de produits et de projets.\r\n\r\nConnaissances/compétences souhaitées:\r\n- ontologies\r\n- gestion de projets et de produits (pour comprendre le domaine)\r\n- UML (un modèle de représentation de certaines connaissances existe en UML)\r\n\r\nContacts : mariajesus.diazvidana@orange-ftgroup.com ; josiane.mothe@irit.fr'),
(72, '2011-01-12', 'Xerox XRCE', 'Grenoble', 'Lien vers le texte de l\'offre : \r\n\r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/Developpement-d-une-interface-pour-un-systeme-d-extraction-automatique-d-opinions-en-ligne\r\n\r\n\r\n\r\n\r\nDéveloppement d\'une interface pour un système d\'extraction automatique d\'opinions en ligne\r\nUnit: Parsing&Semantics\r\n\r\nProposers Caroline Brun\r\nGilbert Rondeau\r\nDuration: 6 mois\r\nStart Date: January to March 2011\r\n\r\nDescription\r\n\r\nDans le cadre d\'un projet de détection automatique d\'opinion en ligne,\r\nce stage vise à la création d\'une interface permettant la\r\nvisualisation des résultats de cette détection. Une visualisation à\r\nbase de facette (« faceted search ») est envisagée.\r\n\r\nCette interface serait développée en JAVA et fonctionnerait sur une\r\napplication JAVA existante qui collecte à partir des textes et stocke\r\ndans une base de données H2 les résultats de l\'extraction automatique\r\nd\'opinions.\r\n\r\nLe stage consistera en:\r\n\r\n   1. Définir l\'interface à partir de la spécification des fonctionnalités attendues\r\n   2. Adapter le stockage dans la base de données en fonction des spécifications\r\n   3. Implanter cette interface (Swing ou FX, à définir) avec les fonctionnalités demandées\r\n\r\nLieu du stage : Meylan (XRCE)\r\nAbout XRCE\r\n\r\nThe Xerox Research Centre Europe (XRCE) is a young, dynamic research\r\norganization, which aims at creating innovative document technologies\r\nto support growth in Xerox content and document management services\r\nacross the different Xerox businesses\r\n\r\nXRCE: Château\r\n\r\nXRCE is both a multicultural and multidisciplinary organization set in\r\nGrenoble, France. Our domains of research stretch from the social\r\nsciences to computing. We have renowned expertise in natural language\r\napplications, work practice studies, image-based document processing,\r\ndistributed applications and knowledge management agents. The\r\ndiversity of culture and disciplines at XRCE makes it an interesting\r\nand stimulating environment to work in, leading to often unexpected\r\ndiscoveries!\r\n\r\nXRCE is part of the Xerox Innovation group made up of 800 researchers\r\nand engineers in four world-renowned research and technology\r\ncentres. Xerox is an equal opportunity employer. XRCE ensures equal\r\nopportunities for all.\r\n\r\nThe \"Charte de la diversité\", adopted by Xerox, proves our engagement\r\nin favour of cultural, ethnic and social diversity.\r\n\r\nThe Grenoble site is set in a park in the heart of the French Alps in\r\na stunning location only a few kilometers from the city centre. The\r\ncity of Grenoble has a large scientific community made up of national\r\nresearch institutes (CNRS, Universities, INRIA) and private\r\nindustries. Stimulated also by the presence of a large student\r\ncommunity, Grenoble has become a resolutely modern city, with a rich\r\nheritage and a vibrant cultural scene. It is a lively and cosmopolitan\r\nplace, offering a host of leisure opportunities. Winter sports resorts\r\njust half an hour from campus and three natural parks at the city\r\nlimits make running, skiing, trekking, climbing and paragliding easily\r\navailable.  Grenoble is close to both the Swiss and Italian borders.'),
(73, '2011-01-14', 'Orange Labs', 'Lannion', 'TECH/ACTS/FAST\r\n\r\nIntitulé du Stage\r\n\r\nExploitation de connaissances pour l\'analyse de textes en langage\r\nnaturel\r\n\r\nMission\r\n\r\nLe but du stage est de concevoir, intégrer, expérimenter et évaluer\r\ndes méthodes de désambiguïsation sémantique dans un analyseur de texte\r\nexistant.  Ces méthodes à implémenter en langage Java consisteront\r\npour la plupart à générer des données linguistiques (lexique,\r\ngrammaire, contraintes et réseau sémantiques) à partir de\r\nconnaissances ontologiques gérées dans une base de connaissances\r\nexistante. Cette base est issue de la fusion de différentes sources\r\nd\'informations disponibles aux formats du web sémantique et devra en\r\nintégrer de nouvelles en fonction des domaines d\'expérimentations\r\nchoisis.\r\n\r\nProfil\r\n\r\nMaster Pro ou Recherche en informatique (éventuellement option\r\nIntelligence Artificielle, Traitement automatique du Langage\r\nNaturelle)\r\nElève de dernière année de Grande Ecole\r\n\r\nCompétences\r\n\r\nBonne connaissance en algorithmique\r\nBonne connaissance de Linux et du langage Java \r\nBonne connaissance en Traitement Automatique du Langage Naturel\r\nConnaissance des techniques du web sémantique (RDFS, OWL, SPARQL)\r\n\r\nModalités \r\n\r\n5 ou 6 mois : entre Avril 2011 et Septembre 2011 à Lannion (Côtes\r\nd\'Armor)\r\n\r\nLe plus de l\'offre\r\n\r\nIntégration au sein d\'une équipe de Traitement Automatique des Langues\r\nNaturelles conduisant à la fois des travaux de recherche et des\r\ndéveloppements opérationnels dans les portails internet et services de\r\ncommunication du groupe Orange.\r\n\r\nUtilisation de techniques innovantes pour des applications à fort\r\nimpact\r\n\r\nContacts :\r\n\r\nMichel PLU, Ingénieur de Recherche, 02 96 05 36 98\r\nmichel.plu@orange-ftgroup.com'),
(74, '2011-01-14', 'Orange Labs', 'Lannion', 'TECH/ACTS/FAST\r\n\r\nIntitulé du Stage (1-2 lignes)\r\n\r\nIndicateurs linguistiques avancés pour la géolocalisation de textes\r\n\r\nMission: (5-6 lignes)\r\n\r\nLa géolocalisation de textes peut se faire selon une stratégie \'sac de\r\nmots\' où tous les indicateurs linguistiques géographiques sont pris en\r\ncompte à plat, indépendamment de leur contexte. Les objectifs de ce\r\nstage sont : d\'évaluer objectivement les performances d\'un système de\r\ngéolocalisation au moyen des mesures standard de l\'état de l\'art sur\r\nun corpus spécialement annoté, d\'évaluer l\'intérêt de l\'import de\r\ndifférentes sources de connaissances complémentaires, de proposer une\r\ntypologie des lieux dans un texte afin de structurer les différents\r\nindices géographiques et distinguer, par exemple, les lieux où ont\r\nlieu les événements, des lieux concernés ou cités dans le document.\r\n\r\nProfil:\r\n\r\nMaster 2 Pro ou R en TAL avec des compétences en syntaxe et analyse\r\ntextuelle\r\n\r\nCompétences\r\n\r\nBonne connaissances en syntaxe et analyse textuelle\r\nEnvironnement Linux\r\nLangage de scripts\r\nProgrammation en python\r\n\r\nModalités\r\n\r\n6 mois : début Avril 2011 à fin Septembre 2011 à Lannion\r\n\r\n\r\nLe plus de l\'offre\r\n\r\nTravail en équipe pluridisciplinaire\r\n\r\n\r\nContacts :\r\n\r\nEmilie De Neef, Linguiste Informaticienne, 02 96 05 19 87\r\nemilie.guimierdeneef@orange-ftgroup.com'),
(75, '2011-01-19', 'Temis', 'Paris', 'Stage M2 informatique, année 2010-2011\r\n\r\n\r\n*Sujet du stage : * CRF pour l\'extraction d\'entités dans des textes\r\n\r\n*Lieu :* société Temis, Paris 1er\r\n\r\nLa société Temis édite une solution logicielle pour traiter les\r\ndocuments textuels. Elle est capable de les classer suivant leur\r\nlangue ou leur domaine, d\'en extraire les « entités » importantes et\r\nde caractériser les relations prédicatives qu\'entretiennent ces\r\nentités entre elles.\r\n\r\nLe module d\'extraction est actuellement réalisé à l\'aide de règles\r\nécrites à la main. Ces règles sont spécifiques de la langue des\r\ndocuments et du domaine sur lequel ils portent, elles peuvent donc\r\nêtre longues et fastidieuses à écrire et à maintenir. Or, des\r\ntechniques d\'apprentissage automatique existent depuis plusieurs\r\nannées pour apprendre à extraire de l\'information à partir\r\nd\'exemples. Celles qui donnent actuellement les meilleurs résultats\r\nsont fondées sur les CRF (Conditional Random Fields), un modèle\r\nstatistique permettant d\'annoter des items lexicaux avec des labels\r\nqui désignent les zones à extraire.\r\n\r\nL\'objectif de ce stage est de tester cette méthode sur différents\r\ncorpus de documents dans différentes langues (au moins français et\r\nanglais) et de styles variés (langue plus ou moins normalisée) et\r\nd\'étudier la robustesse des extracteurs acquis par les CRF sur ces\r\ndifférents exemples. L\'intégration de connaissances linguistiques\r\nexternes (dictionnaires, listes ou règles écrites à la main) dans le\r\nmodèle d\'apprentissage fera partie des problèmes à envisager. Des\r\nquestions de normalisation des entités (variabilité de certains noms\r\npropres suivant la langue du document par exemple) ou de recherche des\r\ncoréférences pourront aussi être abordées.\r\n\r\n*Ref bibliographiques :*\r\n\r\nDaelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.\r\n\r\nLafferty J., McCallum A., Pereira F. : « Conditional Random Fields:\r\nProbabilistic Models for Segmenting and Labeling Sequence Data »,\r\nactes de ICML, pages 282--289, 2001.\r\n\r\nPoibeau, T : Extraction Automatique d\'Information, Hermes, Paris,\r\n2003.\r\n\r\nSutton , McCallum A : « An Introduction to Conditional Random Fields »\r\ndans « Introduction to Statistical Learning », MIT Press, 2006.\r\n\r\nTellier I., Tommasi M., : « Champs markoviens conditionnels pour\r\nl\'extraction d\'information », chapitre du livre « Modèle probabilistes\r\npour l\'accès à l\'information textuelle », à paraître, Hermès 2011.\r\n\r\n*Compétences requises :* M2 d\'informatique, maîtrise de Java et d\'un\r\nlangage de scripts (Python, Perl...), des connaissances en\r\napprentissage automatique et/ou traitement automatique des langues\r\nseraient appréciées\r\n\r\n*Durée : * 6 mois, à commencer suivant disponibilités\r\n\r\n*Rémunération :* 1/3 du Smic + l\'équivalent de 10 tickets restaurant\r\npar mois\r\n\r\n*Encadrement universitaire :* Isabelle Tellier, professeure à\r\nl\'université d\'Orléans\r\n\r\n*Envoyer CV et lettre de motivation à :* christian.lautier@temis.com\r\net isabelle.tellier@univ-orleans.fr'),
(76, '2011-01-25', 'Lingway', 'Paris ou Nantes', 'Stage M2 informatique ou TAL\r\n\r\nSujet: Constitution et qualification de corpus\r\n\r\nDurée: 6 mois, à commencer suivant disponibilité\r\n\r\nLieu: Paris (Porte d\'Italie/Le Kremlin-Bicêtre) ou Nantes\r\n\r\nLingway, leader français en Traitement Automatique des Langues\r\npropose, dans le cadre d\'un projet de R&D collaborative (projet\r\nGramLab), un stage conventionné (M2 ou équivalent).\r\n\r\nIl s\'agit de contribuer à un outillage de constitution automatique de\r\ncorpus Web et aux outils de qualification de ce corpus (typologie des\r\npages, des auteurs, des supports, etc). L\'objectif du stage est de\r\ntester plusieurs méthodes et plateformes, allant des outils de\r\ncollecte (crawling), de stockage en masse (S3, Big Tables, etc.)\r\njusqu\'aux outils d\'apprentissage automatique permettant la\r\nqualification des textes.\r\n\r\n\r\nCompétences requises:\r\n- maîtrise de Java, de préférence complétée par la connaissance d\'un\r\n  langage de scripts (groovy, perl, python);\r\n- des connaissances en TAL, apprentissage automatique, traitement\r\n  distribués seront appréciées\r\n\r\nRémunération: 750 EUR/mois (brut) pour un stage M2\r\n\r\nEnvoyer CV + lettre de motivation à hugues.de-mazancourt@lingway.com'),
(77, '2011-01-25', 'CEA LIST', 'Fontenay-aux-Roses', 'Stage de Master 2 Recherche pouvant donner lieu à poursuite en thèse. \r\n\r\nLes applications qui utilisent une analyse linguistique des textes\r\nsont nombreuses: veille stratégique, résumé automatique,\r\nQuestion-Réponse, traduction automatique, etc. Pendant longtemps, à\r\ndéfaut de capacités suffisantes des analyseurs linguistiques, on a\r\nsupposé que la sémantique serait très utile dans de telles\r\napplications, sans pouvoir le vérifier expérimentalement. Désormais,\r\nsans que ce soit un problème résolu, l\'analyse syntaxique est\r\nsuffisamment performante pour pouvoir développer et exploiter des\r\nméthodes d\'analyse sémantique à échelle réelle [Clark & Harrison,\r\n2008].\r\n\r\nUne précédente thèse au Laboratoire Vision et Ingénierie des Contenus\r\ndu CEA LIST [Mouton, 2010] a permis d\'obtenir des ressources\r\nsémantiques en français de deux types à partir de la traduction de\r\nressources anglaises: une base lexicale du type WordNet (JAWS) et une\r\nbase de cadres sémantiques de type FrameNet.\r\n\r\nCes deux ressources ont permis de développer un outil de\r\ndésambigüisation sémantique (Word Sense Disambigation, WSD) et un\r\nautre d\'annotation en rôles sémantiques (Semantic Role Labeling). Ces\r\ndeux outils travaillent indépendamment et pourraient être utilisés\r\ndans diverses applications. Le présent stage, conçu comme préalable à\r\nune thèse de doctorat aura pour but de reprendre ce travail là où il\r\ns\'est terminé et d\'aller au-delà, en direction d\'un but ultime qui\r\nserait une analyse sémantique complète des textes.\r\n\r\nL\'objectif sera d\'étudier la complémentarité des deux outils et la\r\npossibilité de les intégrer en un seul qui profitera des capacités de\r\nchacun, la désambigüisation devant faciliter l\'annotation en rôles et\r\ncelle-ci devant fournir des indices supplémentaires pour la\r\ndésambigüisation [Che & Liu, 2010]. Il faudra aussi étendre les\r\nressources apprises aux verbes et adjectifs, seul le lexique nominal\r\nayant été traité dans la thèse de Claire Mouton. Ce stage pourra par\r\nailleurs commencer l\'exploration d\'une partie prévue pour lé thèse,\r\nl\'exploitation de nouvelles informations syntaxiques qui aideront\r\nl\'analyse sémantique, en particulier l\'intégration dans l\'analyseur\r\nlinguistique LIMA du CEA LIST d\'informations sur la valence verbale\r\npar l\'intermédiaire du lexique syntaxique Lefff [Sagot & Danlos, 2009]\r\nde l\'équipe Alpage (INRIA et Université Paris VII).\r\n\r\nRéférences:\r\nWanxiang Che & Ting Liu. Jointly Modeling WSD and SRL with Markov\r\nLogic.  Proceedings of the 23rd International Conference on\r\nComputational Linguistics (Coling 2010), 2010.\r\n\r\nClark Peter and Harrison Phil. Boeing\'s NLP System and the Challenges\r\nof Semantic Representation. In Proc SIGSEM Symposium on Text\r\nProcessing (STEP\'08), Venice, Italy, 2008.\r\n\r\nMouton Claire. Ressources et méthodes semi-supervisées pour l\'analyse\r\nsémantique de texte en français, Thèse de doctorat de l\'Université\r\nParis 11, 2010.\r\n\r\nSagot Benoît et Danlos Laurence (2009). Constructions pronominales\r\ndans Dicovalence et le lexique-grammaire – Intégration dans le Lefff\r\n. In Linguisticæ Investigationes 32(2) (pages 293-304).\r\n\r\n\r\nLe stage se fera dans le Laboratoire Vision et Ingénierie des Contenus\r\ndu CEA LIST sous la direction de Gaël de Chalendar.\r\n\r\nGael de Chalendar\r\nCEA LIST\r\nCentre de Fontenay-aux-Roses\r\nLaboratoire Vision et Ingénierie des Contenus\r\n(Vision and Content Engineering Laboratory)\r\nBat. 38-2 ; 18, rue du Panorama ; BP 6\r\n92265 Fontenay aux Roses Cedex ; France\r\nTél.:01.46.54.80.18 ; Fax.:01.46.54.75.80\r\nEmail : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr'),
(78, '2011-02-03', 'LaTTiCe et INRA-SenS', 'Région parisienne', 'Proposition de stage de niveau Master 2\r\n\r\n=== Annotation de données textuelles pour l\'analyse dynamique de blogs\r\n===\r\n\r\nStage proposé par Thierry Poibeau\r\nLaTTiCe-CNRS\r\n\r\net par Jean-Philippe Cointet\r\nINRA-SenS, IFRIS, ISC-PIF, CorText\r\n\r\n\r\nCe stage concerne l\'annotation de données textuelles pour l\'analyse de\r\nla diffusion de l\'information dans des blogs. Il est lié à un projet\r\nen cours entre l\'Institut des Systèmes Complexes de Paris-Ile de\r\nFrance (ISC-PIF, http://www.iscpif.fr/) et le laboratoire LaTTiCe (UMR\r\n8094, http://www.lattice.cnrs.fr/). Ce projet, appelé BlogSem,\r\nbénéficie du soutien de l\'appel à idées 2010 de l\'ISC-PIF.\r\n\r\n*** Descriptif ***\r\n\r\nLe web peut être vu comme un grand réseau d\'individus produisant et\r\néchangeant de l\'information de façon horizontale. De nombreuses études\r\nont porté ces dernières années sur les dynamiques de ces nouvelles\r\nsources d\'information facilement accessibles en ligne comme les\r\nblogs. L\'analyse de celles-ci combine souvent deux points de vue\r\ncomplémentaires : d\'un côté les liens entre blogs forment un réseau\r\nsocial dont la structure est pertinente pour décrire l\'organisation\r\nsociale de ces derniers ; de l\'autre le contenu publié par les\r\nblogueurs est également déterminant pour comprendre les dynamiques\r\nsociales à l\'½uvre dans le système et doit, à ce titre, faire l\'objet\r\nd\'une modélisation sémantique aussi fine que possible (Adamic et\r\nGlance, 2005 ; Thelwall, 2006 ; Cointet et Roth, 2009).\r\n\r\nLe contenu des documents est le plus souvent modélisé par un ensemble\r\nde mots-clés qui rend très imparfaitement compte du contenu sémantique\r\nexprimé : les mots-clés sont par exemple atomiques, non liés entre\r\neux, et non qualifiés. Un moyen d\'aller plus loin consiste donc à\r\nessayer de modéliser plus finement le contenu sémantique. Les\r\ntechniques de traitement automatique des langues (TAL) n\'ont pas\r\nencore été employées à large échelle dans ce type d\'étude alors\r\nqu\'elles sont pourtant relativement mûres (Poibeau, 2003), même si\r\nelles produisent encore des analyses largement imparfaites. C\'est le\r\ncouplage de ces deux domaines de recherche ce que nous nous proposons\r\nd\'explorer dans le cadre de cette proposition, en prenant au sérieux\r\nla question de la caractérisation sémantique des contenus en ligne.\r\n\r\n*** Contenu du stage ***\r\n\r\nLe stage vise à fournir des annotations évoluées pour mieux\r\ncaractériser les contenus du web social. L\'annotation pourra permettre\r\nde déterminer les thèmes abordés, les opinions et les tendances\r\nexprimées. L\'annotation se fera évidemment au moyen d\'outils\r\nautomatiques, soit à partir de lexiques et de grammaires représentés\r\nsous forme d\'automates, soit à partir de méthodes issues de\r\nl\'apprentissage comme les CRF (Conditional random Fields). Il pourra\r\négalement être nécessaire d\'avoir recours à des outils d\'extraction\r\nd\'information (extraction de terminologie par ex.). L\'annotation\r\nportera sur des volumes de données importants (plusieurs dizaines de\r\nmilliers de billets de blogs).\r\n\r\nCette modélisation sera ensuite utilisée pour permettre l\'analyse des\r\ndynamiques à l\'½uvre (notamment l\'évolution dans le temps des thèmes\r\net des opinions exprimées). Cette analyse sera effectuée par des\r\nchercheurs de l\'Institut des Systèmes Complexes qui disposent déjà\r\nd\'outils et de méthodes appropriées pour ce type de traitement. Le\r\nstagiaire devra s\'assurer, en lien avec les autres membres du projet,\r\nque la modélisation du contenu proposée est en phase avec les besoins\r\nd\'analyse en aval.\r\n\r\n*** Profil recherché et compétences requises ***\r\n\r\nProfil master en traitement automatique des langues. Le stagiaire\r\ndevra avoir une expérience de l\'annotation de données, des outils\r\nappropriés et si possible avoir déjà travaillé à large échelle sur des\r\ndonnées réelles. Le stage demande une bonne maîtrise d\'au moins un\r\nlangage de programmation permettant de manipuler facilement des\r\ndonnées textuelles (perl ou python par exemple) et le couplage avec\r\nune base de données (MySQL par exemple).\r\n\r\n*** Conditions du stage ***\r\n\r\nLe stage se déroulera sur 4 à 6 mois, à partir du printemps 2011 en\r\nrégion parisienne. Le stage donnera lieu à une gratification selon les\r\ntarifs en vigueur (à titre indicatif, le tarif était de 417,09 euros\r\npar mois d\'après le taux fixé au 1er janvier 2010). Une poursuite en\r\nthèse pourra être envisagée en cas d\'obtention d\'un financement.\r\n\r\n*** Comment candidater ? ***\r\n\r\nEnvoyer un mail à Thierry Poibeau (prénom.nom@ens.fr) incluant une\r\nbrève présentation des motivations et des compétences en matière\r\nd\'annotation de données textuelles + un CV. Date limite de candidature\r\n: le 14 février 2011.\r\n\r\n*** Bibliographie ***\r\n\r\n- Adamic and Glance. The political blogosphere and the 2004 US\r\n  election: divided they blog. Proceedings of the 3rd international\r\n  workshop on Link discovery (2005)\r\n- Cointet et  Roth. Socio-semantic Dynamics in a Blog Network, IEEE,\r\n  SocialCom Intl Conf on Social Computing, Vancouver, Canada, 2009.\r\n- Leskovec et al. Cascading behavior in large blog graphs. SIAM\r\n  International Conference on Data Mining (SDM 2007), 2007.\r\n- Poibeau. Extraction automatique d\'information. Hermès, Paris, 2003.\r\n- Thelwall. Bloggers during the London attacks: Top information\r\n  sources and topics. Proc. of the World Wide Web 2006 Workshop on the\r\n  Weblogging, 2006.'),
(79, '2011-02-03', 'VIRTUOZ', 'Paris', 'Sujet : STAGE, Intégration d\'un étiqueteur syntaxique probabiliste pour\r\nl\'anglais\r\n\r\nDurée : 4 mois\r\n\r\nDébut du stage : avril 2011\r\n\r\nLieu : VIRTUOZ, 32 rue Mogador 75009 Paris\r\n\r\nVirtuOz est le leader des solutions d\'Agents Virtuels dédiés à la\r\nRelation Client. Les agents virtuels de VirtuOz sont conçus pour\r\ndialoguer avec les clients et répondre à leurs demandes de façon\r\nproactive et en temps réel.Avec plus de 12 millions de conversations\r\npar mois, des clients internationaux, comme eBay, SFR, H&R Block, et\r\nL\'Oreal, s\'appuient sur les solutions de VirtuOz pour optimiser leur\r\nexpérience client.VirtuOz a développé un étiqueteur syntaxique\r\nprobabiliste permettant d\'optimiser les performances linguistiques des\r\nagents. Le système a été éprouvé à grande échelle sur le français et\r\nnous cherchons à présent stagiaire linguiste informaticien afin de\r\ngérer la mise en place de cet étiqueteur pour l\'anglais.\r\n\r\nDescription de la mission :\r\n- Vous intégrerez l\'équipe linguistique\r\n- Vous devrez constituer un grand corpus adapté à nos besoin\r\n- Vous entraînerez l\'étiqueteur sur ce corpus\r\n- Vous veillerez à la qualité des données en réalisant une étude\r\n  comparative des performances des agents avant et après\r\n  l\'intégration.\r\n\r\nProfil :\r\n- Etudiant en linguistique informatique\r\n- Très grande connaissance de la syntaxe, et des grammaire de\r\n  dépendance et d\'unification\r\n- Rigueur, passion pour les nouvelles technologies, professionnalisme\r\n  et dynamisme.\r\n- Maitrise orale et écrite du Français et de l\'Anglais.\r\n- Connaissance des étiqueteurs probabilistes\r\n\r\nVous êtes intéressé? Envoyez votre candidature (CV + Lettre de\r\nmotivation) à Aurélie Cousseau : acousseau@virtuoz.com'),
(80, '2011-02-03', 'ATILF', 'Nancy', 'Offre de stage M2 \"Construction et désambiguïsation de terminologies\r\npar des méthodes de fouille de données\"\r\n\r\nCadre général :\r\n\r\n- projet MSH ASTTIC (Annotation sémantique et terminologique de textes\r\n  pour leur indexation et leur catégorisation)\r\n\r\n- projet transdisciplinaire réunissant l\'ATILF (Analyse et traitement\r\n  informatisé de la langue française) et le LORIA (Laboratoire lorrain\r\n  de recherche en informatique et ses applications)\r\n\r\nDomaine : Fouille de données appliquée à la détection de termes en\r\ntexte intégral\r\n\r\nSujet :\r\n\r\nLa terminologie d\'un domaine est une liste structurée de termes, un\r\nterme pouvant être une unité lexicale simple ou complexe,\r\ni.e. composée de plusieurs mots. Il est fréquent que, dans un même\r\ndomaine, nous ayons des terminologies différentes issues de\r\ncommunautés aussi légèrement différentes. La question qui se pose est\r\ndonc de rapprocher les termes similaires en fonction, par exemple de\r\nleurs usages dans les textes [1, 3, 4].\r\n\r\nL\'idée de ce projet est donc d\'utiliser des méthodes de fouille de\r\ndonnées, notamment des méthodes de classification issue de l\'Analyse\r\nFormelle de Concepts [2], pour confronter les différents usages des\r\ntermes et les regrouper lorsqu\'ils partagent des usages similaires.\r\nInversement, des usages différents du même terme devraient pemettre de\r\ndistinguer des sens différents d\'un même terme [5]. Ainsi, il est\r\npossible de confronter les usages d\'un terme dans un domaine de\r\nspécialité ou dans la langue générale. Si on prend l\'exemple du terme\r\n\"composition\", il correspond à des concepts différents dans deux\r\nsous-domaines des sciences du langage (syntaxe = grammaire et\r\nmorphologie = construction des mots), dans un autre domaine de\r\nspécialité qu\'est la musicologie, probablement dans d\'autres domaines\r\nencore, mais c\'est aussi un nom du français courant.\r\n\r\nLe stage comporte trois objectifs :\r\n- Identifier et extraire des ressources textuelles les élements\r\n  d\'information qui permettront de caractériser les termes et leurs\r\n  usages\r\n- Proposer un modèle de données et définir la méthode de fouille de\r\n  données la plus appropriée à la comparaison des usages\r\n- Réaliser un prototype informatique implémentant cette méthode.\r\n\r\nEncadrement : Evelyne Jacquey (ATILF) et Yannick Toussaint (LORIA)\r\nLieu : ATILF, Nancy\r\nRémunération : indemnités de stage (1/3 du SMIC net)\r\nDurée : 5 mois  (février - juin ou mars - juillet)\r\nContact : Evelyne.Jacquey[AT]atilf.fr\r\n\r\nBibliographie :\r\n[1] N. Aussenac-Gilles and D. Bourigault. The th[ic]2 initiative :\r\nCorpus-based thesaurus construction for indexing www documents. In\r\nProceedings of the EKAW\'2000 workshop Ontologies and texts, pages\r\n71-78, Juan-Les-Pins, Université Paul Sabatier, Toulouse, Octobre\r\n2000.\r\n\r\n[2] Ganter B. and Wille R. Formal Concept Analysis, Mathematical\r\nFoundations. Springer, 1999.\r\n\r\n[3] D. Bourigault, N. Aussenac-Gilles, and J. Charlet. Construction de\r\nressources terminologiques ou ontologiques à partir de textes : un\r\ncadre unificateur pour trois études de cas. Revue d\'Intelligence\r\nArtificielle (RIA), 18(1), 2004. Hermès.\r\n\r\n[4] E. Jacquey, L. Kister, M. Grzesitchak, B. Gaiffe, C. Reutenauer,\r\nM.  Valette, and O. Sandrine. Thesaurus et corpus de spécialité en\r\nsciences du langage : une approche lexicométrique appliquée à\r\nl\'analyse de termes en corpus. In Actes de la conférence TALN2010,\r\nUniversité de Montréal, Juillet 2010.\r\n\r\n[5] G. Stumme and A. Maedche. Fca-merge : Bottom-up merging of\r\nontologies. In 17th International Joint Conferences on Artificial\r\nIntelligence (IJCAI\'01), pages 225-234, San Francisco, CA,\r\n2001. Morgan Kaufmann Publishers, Inc.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(81, '2011-02-03', 'Télécom Bretagne', 'Brest', 'Demande de stage\r\n\r\nService d\'accueil : Telecom-Bretagne\r\n\r\nEntreprise partenaire : Portik\r\n\r\nEmail : jacques.bregand@portik.fr <mailto:jacques.bregand@portik.fr>\r\n\r\nTitre du stage : Application de commande vocale pour saisie de données\r\n\r\nDurée : 5 à 6 mois\r\n\r\nLieu du stage : Télécom Bretagne\r\n\r\nProfil : DNM\r\n\r\nCompétences : informatique, modélisation, traitement du langage,\r\nlangages Java et Prolog\r\n\r\nEncadrant : O. Grisvard\r\n\r\nEmail : olivier.grisvard@telecom-bretagne.eu \r\n<mailto:olivier.grisvard@telecom-bretagne.eu>\r\n\r\nMots clés : traitement automatique du langage naturel, grammaires\r\nformelles, modélisation conceptuelle\r\n\r\nSujet :\r\n\r\nAvec l\'avènement de la téléphonie mobile, les applications de saisie\r\nde données sont de plus en plus répandues. Dans certaines\r\ncirconstances, ces applications peuvent être contraignantes pour\r\nl\'utilisateur, ce qui peut engendrer une réticence de leur part. La\r\nsociété \'Portik\' a développé une application de saisie de données\r\nadaptée aux travaux mobiles. Pour faire adhérer unmaximum\r\nd\'utilisateurs, elle propose que la saisie des données se fasse par la\r\nvoix.\r\n\r\nDe nombreux systèmes de reconnaissance vocale et de traitement\r\nautomatique de la parole existent actuellement, mais ils sont encore\r\nsensibles aux perturbations du milieu extérieur et à la variabilité du\r\nlangage cible. Le moteur de reconnaissance envisagé pour ce projet est\r\nle logiciel Pocket Sphinx. Des traitements complémentaires, tels que\r\nla prise en compte du contexte de dialogue, la correction ou la\r\nrécupération d\'erreurs de reconnaissance ou d\'ambiguïtés lors de\r\nl\'analyse syntaxique et sémantique, viendront s\'ajouter au moteur de\r\nreconnaissance.\r\n\r\nAu cours de ce stage, on s\'intéressera plus particulièrement aux\r\nniveaux de traitements post-reconnaissance vocale, dans le cadre d\'une\r\nplate-forme et d\'outils existants pour le traitement du langage\r\nnaturel et la commande vocale, qu\'il s\'agira de mettre à profit pour\r\noptimiser la performance de l\'application sur smartphone.\r\n\r\nTravail à réaliser :\r\n\r\nIdentification de la phraséologie de l\'application cible en relation\r\navec \'Portik\' et les futurs utilisateurs.\r\n\r\nDéfinition du modèle conceptuel relatif à la phraséologie et\r\ngénération des ressources langagières pour les traitements\r\npost-reconnaissance vocale.\r\n\r\nParticipation au choix définitif du moteur de reconnaissance et\r\nconfiguration de l\'étage de traitement linguistique du moteur retenu\r\npour le projet.\r\n\r\nSupport à l\'intégration des traitements post-reconnaissance vocale sur\r\nle smartphone, intégration réalisée dans le cadre d\'un autre stage.\r\n\r\nEtude et implémentation d\'un générateur de formulaires de saisie\r\nvocale permettant la configuration simple et rapide de l\'application\r\nen vue de son adaptation à d\'autres utilisations.\r\n\r\nRésultats attendus :\r\n\r\nChaîne de traitement et prototype de générateur de formulaires.\r\n\r\nRapport.'),
(82, '2011-02-03', 'LIMSI', 'Orsay', 'Le groupe ILES du LIMSI propose un certain nombre de stages, pour des\r\nétudiants de Master 1, Master 2 Recherche, Master 2 Professionnel ou\r\nécole d\'ingénieur, dans le domaine de la recherche d\'information, de\r\nl\'extraction d\'information et des systèmes de question-réponse.\r\n\r\nStages de niveau M1\r\n\r\n- Apprentissage de patrons d\'extraction \r\n  http://www.limsi.fr/Individu/annlor/docs/stageApprentissagePatrons.pdf\r\n\r\n- Analyse de l\'évolution des noms d\'événements dans les médias \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_TER_stage_evolution_ENE.html\r\n\r\n- Extraction de relations et apprentissage \r\n  http://www.limsi.fr/Individu/annlor/docs/stageExtractionRelationsApprentissage.pdf\r\n\r\n- Extraction des événements saillants dans un ensemble de textes \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_evenements_saillants.html\r\n\r\n- Fait ou supposition ? Identification automatique du niveau de \r\n  certitude d\'un événement \r\n  http://sites.google.com/site/delphinebernhard/proposition-de-stage_evaluation_certitude\r\n\r\n- Génération de réponses avec hésitation pour un système de \r\n  questions-réponses \r\n  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_HesitationQR.pdf\r\n\r\n- Génération de réponses qui reprennent la question pour un système de \r\n  questions-réponses \r\n  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_GeneLangueQR.pdf\r\n\r\n- Simplification syntaxique \r\n  http://sites.google.com/site/delphinebernhard/sentence-simplification-internship\r\n\r\n\r\n\r\nStages de niveau M2\r\n\r\n- Apprentissage de patrons d\'extraction \r\n  http://www.limsi.fr/Individu/annlor/docs/stageApprentissagePatrons.pdf\r\n\r\n- Pondération de graphes de dépendances syntaxiques pour la recherche \r\n  d\'information précise \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_ponderation_graphes.html\r\n\r\n- Comparaison syntaxique de phrases \r\n  http://www.limsi.fr/Individu/bg/pageWeb/stage_paraphrase.html\r\n\r\n- Calcul de la similarité entre une question et un texte \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M2R_similarite_question_document.html\r\n\r\n- Définition d\'un contexte d\'analyse des documents pour les systèmes de \r\n  questions-réponses \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M2R_contexte_analyse.html\r\n\r\n- Extraction de relations et apprentissage \r\n  http://www.limsi.fr/Individu/annlor/docs/stageExtractionRelationsApprentissage.pdf\r\n\r\n- Extraction de relations pour la synthèse de documents avec \r\n  TecKnowMetrix \r\n  http://www.limsi.fr/Individu/annlor/docs/StageTecKnowMetrixILEs.pdf\r\n\r\n- Extraction des événements saillants dans un ensemble de textes \r\n  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_evenements_saillants.html\r\n\r\n- Fait ou supposition ? Identification automatique du niveau de \r\n  certitude d\'un événement \r\n  http://sites.google.com/site/delphinebernhard/proposition-de-stage_evaluation_certitude\r\n\r\n- Génération de réponses avec hésitation pour un système de \r\n  questions-réponses \r\n  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_HesitationQR.pdf\r\n\r\n- Génération de réponses qui reprennent la question pour un système de \r\n  questions-réponses \r\n  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_GeneLangueQR.pdf\r\n\r\n- Interface d\'évaluation générique \r\n  http://www.limsi.fr/Individu/bg/pageWeb/stage_Genericite_REVISE.html\r\n\r\n- Mise en évidence et utilisation de relations entre entités nommées \r\n  pour la fouille de texte et la recherche d\'informations précises \r\n  http://www.limsi.fr/Individu/bg/pageWeb/stage_fouilleDeTexte.html\r\n\r\n- Simplification syntaxique \r\n  http://sites.google.com/site/delphinebernhard/sentence-simplification-internship'),
(83, '2011-02-08', 'LIMSI', 'Orsay', 'Etude et modélisation des marqueurs discursifs dans un corpus oral EDF\r\nde conversations téléphoniques client/conseiller\r\n\r\n\r\nResponsables: \r\nSophie Rosset, Ioana Vasilescu (LIMSI-CNRS) et Chloé Clavel (R&D EDF,\r\nClamart 92)\r\n\r\nCe sujet de stage porte sur l\'étude et la modélisation des marqueurs\r\ndiscursifs et des phénomènes dits \"disfluents\" (par . ex. les\r\nhésitations) dans les corpus oraux d\'EDF.\r\n\r\nLa R&D d\'EDF met en ½uvre des techniques de text mining pour\r\noptimiser sa relation client, en analysant des questions ouvertes\r\nd\'enquête de satisfaction, des retranscriptions de conversations\r\nissues des centres d\'appels, et des corpus web avec le but de classer\r\nces données selon différentes thématiques et opinions. Que ces données\r\nsoient issues de l\'oral (centres d\'appel) ou du web (blogs, forums,\r\nréseaux sociaux), les entrées de la chaîne text mining diffèrent de\r\ncelles classiquement traitées. Ces spécificités sont liées à\r\nl\'expression spontanée et sont difficiles à appréhender, notamment\r\nlors de l\'étape d\'extraction de concepts métiers. Parmi les événements\r\nqui caractérisent ce type de données les phénomènes dits\r\n« disfluents » (incluant des hésitations comme « euh » et\r\nreformulations diverses mais aussi des marqueurs discursifs comme\r\n« bon », « bein », « donc ») sont fréquents et soulèvent la question\r\nde leur traitement par rapport à l\'objectif principal qui est de\r\nmodéliser les concepts métiers. \r\n\r\nNous voulons mettre en évidence/modéliser le fonctionnement des\r\nphénomènes dits \"disfluents\" et des marqueurs discursifs dans les\r\ncorpus oraux d\'EDF. \r\n\r\nCe sujet convient à un(e) étudiant(e) en M2, intéréssé(e) par la\r\nlinguistique en lien avec les technologiques vocales, ayant ainsi un\r\nsolide bagage linguistique mais possédant également des connaissances\r\nen traitemant automatique des langues. \r\n\r\n\r\n\r\nDescription du stage:\r\nLe dialogue homme/homme témoigne d\'une variété de stratégies\r\ninteractionnelles où le contenu verbal d\'un échange est accompagné de\r\nnombre de phénomènes lexicaux et non-lexicaux ayant le rôle d\'assurer\r\nla gestion efficace de l\'interaction : prendre la parole,\r\nconserver/céder le tour de parole, indiquer des difficultés de mise en\r\nmots. Les marqueurs discursifs font partie de ces événements verbaux\r\nayant le rôle de régulation de l\'interaction. Quant aux \"disfluences\"\r\net en particulier aux hésitations telles que \"euh\" en français, des\r\nétudes ont montré leur rôle dans la recherche lexicale: les locuteurs\r\nsemblent faire appel à ces événements afin d\'indiquer qu\'ils se\r\ntrouvent en plein processus de mise en mots d\'une information\r\npertinente au sein de leur tour de parole.\r\n\r\nA titre d\'exemple, des études récentes sur des corpus homme/machine\r\nont montré que ces événements loin d\'être \"disfluents\" permettent\r\nd\'indiquer des zones d\'information pertinente, susceptibles de subir\r\nune reformulation.\r\n\r\n\r\nLe travail de ce stage portera sur l\'analyse des corpus oraux\r\nhomme/homme disponibles à EDF ainsi que sur la modélisation des\r\nphénomènes observés. Il s\'agira de mettre en évidence les différentes\r\nfonctions des (classes de) marqueurs discursifs et hésitations dans le\r\ncorpus, de valider ces fonctions à travers une analyse statistique des\r\ndonnées et de définir les paramètres d\'une modélisation automatique\r\npuis de l\'implémenter.\r\n\r\nPlus précisément, les étapes de ce travail sont: (i) analyse\r\nmorpho-syntaxique de corpus (analyse, définition et extraction de\r\nclasses de marqueurs discursifs, étude et définition de contextes\r\nd\'occurences, classification automatique des marqueurs\r\ndiscursifs/contextes d\'occurences, exploitation d\'outils d\'analyse\r\nmorpho-syntaxique), (ii) validation statistique des données, (iii)\r\nformalisation des résultats, (iv) développement d\'un système de\r\nclassification des différentes classes de disfluences, (v) outil de\r\nvisualisation des documents analysés.\r\n\r\nRéférences:\r\nOn the role of discourse markers in interactive spoken question\r\nanswering systems  / Vasilescu, I. ; Rosset, S. ; Adda-Decker,\r\nM.. LREC 2010. Seventh International Conference on Language Resources\r\nand Evaluation, Valetta, Malta : 2010. - 7p\r\nOn the functions of the vocalic hesitation euh in interactive\r\nman-machine question answering dialogs in French /  Vasilescu, I. ;\r\nRosset, S. ; Adda-Decker, M.. , DISS 2010, Tokyo Japan: 2010. - 4p\r\n\r\n\r\nProfil de la/du candidat(e): \r\nCe stage s\'adresse aux étudiant(e)s en M2 ayant suivi un parcours\r\nlinguistique/informatique/traitement automatique de la parole et de la\r\nlangue. Connaissances souhaitées: Linguistiques:\r\nphonétique/morpho-syntaxe, analyse statistique de\r\ndonnées. Informatiques: environnement linux/unix, algorithme\r\nd\'apprentissage et de classification.\r\n\r\n\r\nLieu et durée du stage: \r\nLe stage se déroulera au laboratoire LIMSI-CNRS\r\n(http://www.limsi.fr/Pratique/acces/), dans le groupe \"Traitement du\r\nLangage Parlé\". La durée prévue du stage est de 5 mois (plein temps, a\r\npartir de mars/avril 2011). Le sujet de stage peut être poursuivi dans\r\nle cadre d\'une thèse.\r\n\r\n\r\nRémunération: ~400 euros/mois (gratification selon les tarifs en\r\nvigueur).\r\n\r\nEncadrants (contacts): Sophie Rosset (rosset at limsi point fr), Ioana\r\nVasilescu (ioana at limsi point fr), Chloé Clavel (chloe clavel at edf\r\npoint fr).'),
(84, '2011-02-18', 'Teletech International', 'Saint Affrique (12)', 'TELETECH International\r\n\r\nRecrute un Ingénieur Linguistique, H/F en stage rémunéré\r\n\r\n\r\nLe groupe Teletech International est spécialisé dans la mise en place,\r\nla gestion et l\'hébergement de Centres d\'Appels. Nous disposons\r\négalement d\'une SSII intégrée, qui conçoit des solutions de relation\r\nclient (CRM) adaptées aux métiers des Centres d\'Appels. Teletech\r\nInternational est spécialisé sur les nouvelles technologies du Web\r\n2.0, la gestion des connaissances, les solutions e-business et les\r\nsolutions mobiles.\r\n\r\nNos experts ont mis en place NestAvatar, un dispositif de création et\r\nde gestion d\'agents virtuels intelligents de 2ème génération, basé sur\r\ndes langages d\'intelligence artificielle.\r\n\r\nSous la responsabilité du Directeur de Centre et du Directeur des\r\nDéveloppements Informatiques, vous aurez à :\r\n\r\nSpécifier le champ de connaissances de l\'agent virtuel, Enrichir le\r\ncontenu des dialogues, du dictionnaire, du référentiel, Perfectionner\r\nla construction de dialogues de cet agent virtuel, Analyser le\r\ncomportement de l\'agent virtuel à travers des outils statistiques,\r\nAméliorer et optimiser les échanges linguistiques entre l\'Avatar et\r\nl\'internaute, Proposer des solutions pour faciliter l\'enrichissement\r\ndes connaissances.\r\n\r\nActuellement en Master Sciences du Langage spécialité TAL, vous\r\npossédez de solides capacités rédactionnelles et d\'analyse, un grand\r\nesprit de synthèse et une bonne méthodologie.\r\n\r\nVous êtes proactif, vous maîtrisez les outils communautaires 2.0 et\r\nêtes à l\'écoute des tendances et des évolutions.\r\n\r\n\r\nHoraires hebdomadaires : à définir\r\nRémunération : 417.06¤/mois pour un temps plein\r\n\r\n\r\nPoste basé à SAINT AFFRIQUE\r\nAdresser CV + photo à service.rh@teletech-int.com réf : Stage IL 0211\r\nOu contacter Mme Rossignol au : 03.80.60.90.61'),
(85, '2011-03-03', 'Lingway', 'Paris', 'Stage M2 TAL \r\n\r\nSujet: Développement d\'un analyseur de sentiment en portugais\r\nDurée: 2 mois, à commencer suivant disponibilité\r\n\r\nLieu: Paris (Porte d\'Italie/Le Kremlin-Bicêtre) \r\n\r\nLingway, spécialiste français en Traitement Automatique des Langues\r\npropose un stage conventionné (M2 ou équivalent).\r\n\r\nL\'objectif du stage est d\'adapter au traitement du portugais les\r\noutils d\'analyse du sentiment développés à Lingway.\r\n\r\nLes tâches à accomplir sont:\r\n\r\n\r\n- analyse d\'un corpus client à traiter,\r\n    - couverture lexicale à prendre en compte\r\n    - identification de marqueurs contextuels\r\n\r\n- adpatation du système existant (règles d\'extraction et lexique)\r\n    \r\n- intégration à une chaine d\'analyse,\r\n\r\n- tests\r\n\r\nCompétences requises:\r\n- portugais (brésilien de préférence)\r\n- bonne connaissance des outils de TAL,\r\n- langage de script (perl, Groovy), \r\n- bonnes capacités d\'analyse,\r\n- goût pour la résolution de problèmes,\r\n- facilité à travailler en équipe\r\n\r\nStage rémunéré 450 euros brut mensuel, basé au Kremlin Bicêtre (porte\r\nd\'italie), dès que possible Envoyer CV + lettre de motivation à\r\ncecile.potier@lingway.com\r\n\r\nCécile Potier \r\nDirectrice Contenus Linguistiques\r\ndirect : +33 (0)1 58 46 12 52'),
(86, '2011-03-07', 'Semantia', 'Marseille', 'Semantia est un fournisseur de services en ligne (ASP), spécialisé\r\ndans le traitement du langage pour l\'optimisation de la gestion de la\r\nrelation client.\r\n\r\nL\'objectif du stage est de participer à l\'optimisation des bases de\r\nconnaissances des applicatifs de la société pour le traitement et\r\nl\'analyse du langage.  Intégré au service de recherche et\r\ndéveloppement, le stagiaire mettra en place un module permettant\r\nd\'améliorer le rendement de certaines règles linguistiques.  Le\r\nstagiaire devra être en mesure de proposer des méthodes et de mettre\r\nen place différentes solutions en situation.\r\n\r\nConnaissances requises et/ou acquises\r\n- Expertise linguistique\r\n- Langages informatiques environnement web : PHP, SQL, HTML\r\n- Bonnes connaissances des expressions régulières\r\n- Facilité d\'adaptation\r\n- Travail en équipe\r\n- Logique\r\n- Rigueur\r\n\r\nNiveau\r\nBac+3 minimum dans la discipline\r\n\r\nDurée du Stage\r\nDe 3 à 5 mois.\r\n\r\nLieu du stage\r\nLes Espaces de la Sainte-Baume\r\n30, Avenue du Château de Jouques\r\n13420 Gémenos\r\n\r\nContacts\r\n- drh@semantia.com\r\n- Tél. : 04 42 36 80 91\r\n\r\n\r\n\r\n*Lucile PAROZ - Linguiste*\r\n\r\n*Semantia*\r\n\r\n*Tél. : 04 42 36 80 91 - e-mail : lucile.paroz@semantia.com*\r\n\r\n*Agence Paris :*\r\n63, avenue Marceau - 75116 Paris\r\nTél. : 09 52 27 34 54\r\n*Siège :*\r\nLes Espaces de la Sainte-Baume - 30, Avenue du Château de Jouques - \r\n13420 Gémenos\r\nTél. : 04 42 36 80 91 - Fax : 04 42 36 81 59\r\ninfo@semantia.com - www.semantia.com'),
(87, '2011-03-09', 'MoDyCo', 'Nanterre', 'Profil du poste : développement web interface graphique\r\n\r\nRecherche CDD ou stagiaires en ingéniérie Web pour le développement\r\nd\'un frontal web dans le cadre du projet ANR Rhapsodie\r\n(http://rhapsodie.risc.cnrs.fr/fr/index.html , laboratoires\r\npartenaires IRCAM, Paris ; MODYCO, Nanterre)\r\n\r\nObjectifs : Développement d\'une interface web de consultation,\r\nvisualisation et d\'annotation de données orales structurées (3h\r\nd\'enregistrement audio avec la transcription et des analyses\r\nlinguistiques)\r\n\r\nTâche demandée : Mise en place d\'une interface web permettant\r\nd\'accéder à des données audio et à des annotations sur ces données par\r\nl\'intermédiaire d\'un langage de requête constitué au préalable.\r\n\r\nCette interface proposera :\r\n- des formulaires de recherche s\'appuyant sur un moteur existant\r\n- la représentation graphique ergonomique des annotations à l\'aide de\r\n  différentes visualisations des données audio et textuelles\r\n- la possibilité de réviser les annotations fournies\r\n- des statistiques sur les données et leurs représentations graphiques\r\n- un backoffice d\'administration des données et des utilisateurs\r\n\r\nCompétence techniques requises :\r\n\r\n- Serveur : PHP ou un autre langage script (Python, Perl) et MySQL\r\n- Client Web : Javascript, HTML 5\r\n\r\nLa connaissance de AJAX, Json, JQuery et SVG ainsi qu\'en développement\r\ndes outils Web avec des accès réservés sera un plus. Un intérêt pour\r\nles structures de la langue sera apprécié mais aucune connaissance\r\nparticulière en parole et linguistique n\'est requise.\r\n\r\nLe candidat collaborera avec l\'équipe du laboratoire (linguistes et\r\ninformaticiens) pour formaliser les spécifications fonctionnelles de\r\nl\'application.\r\n\r\nLieu de travail : laboratoire MODYCO, Université de paris Ouest\r\nNanterre, télétravail possible avec mise à disposition d\'ordinateur.\r\n\r\nDébut  : dès que possible.\r\n\r\nDurée : stage 6 mois minimum et possibilité d\'enchaîner sur un CDD\r\nde 6 à 12 mois ou de démarrer directement sur un CDD selon profil.\r\n\r\nPrière de contacter Atanas Tchobanov atanas@u-paris10.fr si intéressé.\r\n\r\nAtanas Tchobanov\r\nIngénieur de recherche CNRS\r\nMoDyCo UMR 7114'),
(88, '2011-03-31', 'LIPN', 'Villetaneuse', 'Articuler annotation sémantique de textes et mise à jour du modèle  \r\nd\'annotation\r\n\r\nL\'annotation de texte consiste à apposer sur le texte des informations\r\nou métadonnées dont la sémantique est portée par un modèle\r\nd\'annotation (formalisme et jeu d\'étiquettes). Le processus\r\nd\'annotation, qu\'il soit manuel, automatique ou semi-automatique\r\nsuppose qu\'un tel modèle ait été défini au préalable pour spécifier le\r\ntype et la valeur des annotations que peuvent porter différents\r\néléments textuels. \r\n\r\nL\'annotation sémantique obéit à la même logique avec cette spécificité\r\nque les annotations ont pour ob jectif d\'expliciter le sens porté par\r\nle document qui est annoté. L\'influence des travaux issus du web\r\nsémantique et la maîtrise du clacul ontologique font que les modèles\r\nd\'annotation sémantique sont souvent de nature ontologique.\r\nCependant, le processus habituel consiste à construire un modèle puis\r\nà annoter au regard de celui-ci et ne prévoit pas d\'évolution du\r\nmodèle d\'annotation, ce qui pose problème dans les cas nombreux où le\r\nmodèle doit évoluer (correction, précision, enrichissement, mise à\r\njour) au cours de la phase d\'annotation.\r\n\r\nParallèlement, des outils existent pour annoter sémantiquement des\r\ntextes, de manière automatique ou manuelle, au regard d\'une ontologie:\r\namaya, Firefox, SMORE, Gate\'s editor, Melita. Ces outils ne prennent\r\npas non plus en compte la mise à jour dynamique du modèle en cours\r\nd\'annotation et la possible réannotation du texte au regard du modèle\r\nqui est mis à jour.\r\n\r\nL\'objet de ce stage est de formaliser ce processus de mise à jour du\r\nmodèle d\'annotation au cours de l\'annotation et de proposer une\r\nméthode et des outils permettant de la gérer.\r\n\r\nCe travail s\'intégrera dans le projet ONTORULE dont l\'un des enjeux\r\nest l\'annotation sémantique de textes réglementaires et s\'appuiera sur\r\nles pratiques existantes d\'annotation, à la fois manuelle et\r\nautomatique. On fera l\'hypothèse que le modèle d\'annotation est de\r\nnature ontologique, même si d\'autres types de modèles peuvent être\r\nenvisagés. Il s\'agira\r\n\r\n1. de recenser les types de modifications nécessaires sur la base de\r\n   l\'analyse des cas d\'usage du projet ONTORULE (ajout, suppression,\r\n   modification de certaines unités ontologique, restructuration de\r\n   l\'ontologie, modification des connaissances lexicales associées) ;\r\n\r\n2. de définir une stratégie de mise-à-jour pour ces différents types de\r\n   modifications ;\r\n\r\n3. d\'implémenter certaines de ces stratégies sur un outil d\'annotation\r\n   existant ;\r\n\r\n4. de tester et d\'évaluer les stratégies proposées au regard de\r\n   l\'analyse des besoins effectuées au point 1.\r\n\r\nCe stage sera rémunéré. Il aura lieu au LIPN, université Paris 13, à\r\nVilletaneuse (93). Envoyer votre candidature avec CV à\r\nFrancois.Levy@lipn.univ-paris13.fr'),
(89, '2011-04-06', 'BNP Paribas', 'Paris', 'Stage conventionné pour un(e) étudiant(e) M1/M2 en Traitement\r\nAutomatique des Langues pour une durée de 6 mois (rémunéré)\r\npour début mai \r\n\r\nENTREPRISE:  Etudes Economiques BNP Paribas (Paris)\r\n\r\nCe stage consiste à travailler pour un portail d\'informations\r\néconomiques et financières interne \"LEOnard\" qui compte près de 13 000\r\nabonnés et environ 2000 connexions par jour.\r\n\r\nDestiné à l\'ensemble des collaborateurs du groupe, ce portail allie\r\nrecherche d\'informations et push (présentation d\'informations)\r\ntoujours plus pointues et pertinentes.\r\nCes informations proviennent de base de données internes, de sites web\r\net de près de 400 articles issus de la presse quotidienne économique.\r\nPlusieurs technologies sont utilisées dans LEOnard : Polyspot (moteur\r\nde recherche, KB Crawl et KB Platform (outil de surveillance, de\r\ncollecte et de diffusion d\'infomations provenant du web) et Temis\r\n(text mining).  Nous recherchons donc un stagiaire de niveau master\r\n(1ère ou 2ème année) pour travailler sur ces logiciels et nous\r\napporter ses compétences dans l\'utilisation et les perspectives que\r\nnous pouvons tirer de ces technologies.\r\n\r\nMISSIONS: \r\n\r\n- Tests et analyse de l\'outil de text-mining Temis (extractions\r\n  d\'entités nommées, concepts économiques, catégorisation automatique\r\n  ...)\r\n\r\n- Tests sur un outil de catégorisation automatique par secteur\r\n  d\'activité (Agro-alimentaire, Banque, Industrie ...) sur de nouveaux\r\n  documents\r\n\r\n- Suivi du déploiement de la mise à disposition de ce moteur de\r\n  recherche entreprise (outil en langage naturel) auprès des\r\n  utilisateurs, mise à jour du guide utilisateur.\r\n\r\n- Participation aux démonstrations en interne à l\'externe\r\n\r\nCOMPETENCES REQUISES: \r\n\r\n- Etre méthodique, autonome, rigoureux et curieux \r\n\r\n- Prendre des initiatives, partager ses idées et son savoir-faire et\r\n  donc savoir travailler en équipe\r\n\r\n- Anglais lu parlé obligatoire \r\n\r\n- Connaissance des langage de structuration (html, xml) et de\r\n  développement (perl)\r\n\r\n\r\nMerci de nous faire parvenir votre CV et lettre de motivation à M.\r\nBERNARDINI Michel\r\nE-mail : michel.bernardini@bnpparibas.com \r\nTél. : 01.42.98.05.71'),
(90, '2011-04-18', 'Ami Software', 'Montpellier', '*Visualisation graphique de données avec dimension temporelle*\r\n\r\nAmi Software est une société qui développe des logiciels de veille, de\r\ncapitalisation et d\'analyse de documents sur le Web. Dans le cadre de\r\nl\'analyse des documents collectés lors d\'une veille, des outils de\r\nvisualisation de graphes sont utilisés depuis plusieurs années pour\r\nreprésenter les concepts extraits, les sources d\'informations et les\r\ndifférentes relations pouvant exister entre ces éléments.\r\n\r\nAfin de pouvoir développer ses outils de suivi de « tendance » sur le\r\nweb, Ami Software souhaite désormais ajouter une dimension temporelle\r\naux différents graphes proposés.\r\n\r\n\r\nLe stage consistera à ajouter cette dimension temporelle à la\r\nlibrairie de visualisation de graphes employée. Le stagiaire devra\r\nréaliser un succinct état de l\'art sur le sujet, s\'accaparer le\r\nproduit existant, et enfin développer des solutions\r\nappropriées. Il/elle pourra par ailleurs en parallèle être amené(e) à\r\nconstituer différents jeux de données, notamment à l\'aide des outils\r\ndéveloppés par Ami Software, afin de procéder à des tests en situation\r\nréelle et ainsi mettre en avant la valeur ajoutée de la méthode.\r\n\r\nLe stagiaire devra être à l\'aise avec la programmation objet. Des\r\nconnaissances en ActionScript seraient un plus.\r\n\r\nLe stage, d\'une durée de 3 à 6 mois, sera rémunéré. Il se déroulera\r\ndans les locaux R&D de la société, situés à Montpellier.\r\n\r\nPour postuler, merci d\'envoyer un cv à l\'adresse suivante: eal at\r\namisw dot com'),
(91, '2011-04-18', 'Ami Software', 'Montpellier', '*Web temps réel : Intégration avancée de Twitter*\r\n\r\nAmi Software est une société qui développe des logiciels de veille, de\r\ncapitalisation et d\'analyse de documents sur le Web. Depuis quelques\r\nannées, on assiste à l\'évolution du Web 2.0 vers le Web dit « temps\r\nréel », qui se caractérise par la diffusion instantanée (et publique)\r\nde l\'information, notamment via des plateformes de microblogging, dont\r\nl\'exemple le plus connu est Twitter. Cette nouvelle façon de\r\ncommuniquer ouvre la voie à de nouveaux traitements, comme l\'analyse\r\nen temps réel de l\'évolution d\'une thématique ou d\'une opinion en\r\nligne, ce qui peut s\'avérer crucial dans un cadre de veille\r\ninformationnelle.\r\n\r\nAmi Software travaille actuellement sur l\'identification, l\'analyse,\r\nla modélisation et la représentation du cheminement d\'une information\r\nou d\'une opinion sur Internet (le « buzz »). Cette étude passe par\r\nl\'analyse conjointe du contenu sémantique des documents ainsi que de\r\nla topologie du Web, de plus en plus marquée par les réseaux sociaux\r\n(détection de communautés en ligne, calcul d\'autorité). Afin de\r\npouvoir améliorer ses outils de suivi de « tendance » sur le web, Ami\r\nSoftware a réalisé des premières intégrations de Facebook et Twitter.\r\n\r\nLe stage consistera à pousser plus loin l\'intégration de Twitter dans\r\nles outils de la société. Après s\'être imprégné du produit existant,\r\nle stagiaire devra réaliser un succinct état de l\'art sur le sujet :\r\naccès aux données, analyse des différents éléments pertinents à\r\nindexer, etc.  Il s\'agira enfin d\'implémenter les solutions retenues.\r\n\r\nLe stagiaire intègrera l\'équipe R&D et sera notamment encadré par un\r\ndoctorant travaillant sur le sujet. Il/elle devra être à l\'aise en\r\nprogrammation Web, notamment en Javascript. Une bonne\r\nconnaissance/pratique des réseaux sociaux (ainsi que de leurs APIs)\r\nserait un plus.\r\n\r\nLe stage, d\'une durée de 3 à 6 mois, sera rémunéré. Il se déroulera\r\ndans les locaux R&D de la société, situés à Montpellier.\r\n\r\nPour postuler, merci d\'envoyer un cv à l\'adresse suivante: alu at\r\namisw dot com.'),
(92, '2011-05-30', 'OWI Technologies', 'Bourg-la-Reine', 'Présentation de la société.\r\n\r\nOWI Technologies est une jeune entreprise qui développe des logiciels\r\nde Traitement Automatique du Langage Humain.\r\n\r\nL\'équipe est composée de quatre associés, ingénieurs de 45 ans\r\n(Centrale Paris, SupElec, X-Télécom), trois docteurs et deux\r\ningénieurs.  Après 15 ans de recherches sur le procédé, ponctués par\r\nun dépôt de brevet, nous avons réalisé des études de marché, puis\r\ndéveloppé une première offre innovante sur le traitement des mails.\r\n\r\nConfortés par nos premiers succès commerciaux, nous nous engageons à\r\nprésent dans une nouvelle phase de R&D, consistant d\'une part à\r\nrenforcer les performances techniques et fonctionnelles de notre offre\r\nexistante, d\'autre part à initier de nouveaux domaines (notamment sur\r\nl\'apprentissage automatique) qui permettront le développement de\r\nnouvelles offres.\r\n\r\nMission.\r\n\r\nVous rejoignez l\'équipe de Recherche & Développement pour améliorer le\r\ndictionnaire des proximités sémantiques (synonymes) en langue\r\nfrançaise.  Plusieurs stages sont à pourvoir.\r\n\r\nProfil recherché.\r\nEtudiant de langue maternelle française.\r\n\r\nCompétences techniques.\r\nConnaissance de Microsoft Excel.\r\nEsprit d\'analyse.\r\n\r\nConditions pratiques.\r\nLieu : Bourg-la-Reine (92)\r\nType de contrat : stage conventionné.\r\nDurée : 1 ou 2 mois.\r\nCV et lettre de motivation à stages@owi-tech.com'),
(93, '2011-06-01', 'Exalead', 'Paris', 'Descriptif du stage\r\n--------------------------------\r\nExalead, entreprise du groupe Dassault Systèmes, est un fournisseur de\r\nlogiciels de recherche et d\'accès à l\'information en entreprise et sur\r\nle Web.\r\n\r\nNous recherchons un stagiaire dans le cadre d\'un projet de mise en\r\nplace d\'un service de veille sur internet.\r\nAprès une revue de l\'état de l\'art, le stagiaire élaborera un système\r\nde désambiguïsation lexicale capable de s\'adapter à du vocabulaire non\r\nprésent dans les dictionnaires traditionnels. Pour parvenir à cette\r\nfin, il s\'orientera très probablement vers des modèles d\'espaces de\r\nmots.\r\n\r\n\r\nCompétences\r\n-----------------------------\r\n- Traitement automatique des langues\r\n- Programmation (C++, Java, python)\r\n\r\n\r\nMots-clés\r\n-----------------------------\r\nsémantique, espaces de mots, désambiguïsation lexicale, induction de\r\nsens, calcul vectoriel\r\n\r\n\r\nRéférences\r\n-----------------------------\r\nPatrick Pantel and Dekang Lin. 2002. Discovering Word Senses from\r\nText.  In /Proceedings of ACM SIGKDD Conference on Knowledge Discovery\r\nand Data Mining 2002/. pp. 613-619. Edmonton, Canada. [PDF\r\nhttp://webdocs.cs.ualberta.ca/%7Elindek/papers/kdd02.pdf][PS\r\nhttp://webdocs.cs.ualberta.ca/%7Elindek/papers/kdd02.ps]\r\n\r\nJean Véronis/. HyperLex: lexical cartography for information\r\nretrieval.  Computer Speech & Language/ In Word Sense Disambiguation,\r\nVol. 18, No.  3. (July 2004), pp. 223-252. [PDF\r\nhttp://www.google.com/url?sa=t&source=web&cd=1&ved=0CBgQFjAA&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.66.6499%26rep%3Drep1%26type%3Dpdf&rct=j&q=HyperLex%3A%20lexical%20cartography%20for%20information%20retrieval&ei=oMrjTZftJo_E8QON7aWfBw&usg=AFQjCNFIIryl6QLmhPc6btcI-_7WQCshHw&cad=rja }\r\n\r\nEneko Agirre et Philip Edmonds, editeurs. Word sense disambiguation -\r\nalgorithms and applications. Springer, 2007 [PDF\r\nhttp://www.wsdbook.org/wsdbook-ch1.pdf]\r\n\r\n\r\nDurée\r\n-----------------------------\r\n6 mois\r\n\r\n\r\nClaire Mouton\r\nResearch Engineer\r\nTel : +33 1 55 35 27 39\r\nFax : +33 1 55 35 26 27\r\nClaire.Mouton@exalead.com <mailto:Claire.Mouton@exalead.com> 	Exalead\r\n\r\n10 place de la Madeleine - 75008 Paris, France\r\nfr.exalead.com/software <http://fr.exalead.com/software>'),
(94, '2011-06-27', 'Lingway', 'Paris', 'Sujet: Evaluation de ressources et Développement d\'un analyseur de\r\nsentiment en chinois\r\nDurée: 6 mois, à commencer suivant disponibilité\r\n\r\nLieu: Paris (Porte d\'Italie/Le Kremlin-Bicêtre)\r\n\r\nLingway, spécialiste français en Traitement Automatique des Langues\r\npropose un stage conventionné.\r\n\r\nL\'objectif du stage est d\'adapter au traitement du chinois les outils\r\nd\'indexation/recherche et d\'analyse du sentiment développés à Lingway.\r\n\r\nLes tâches à accomplir sont:\r\n- évaluation du système existant,\r\n- définition d\'un bouquet de sources de presse générale en chinois\r\n- analyse d\'un corpus client à traiter:\r\n-- couverture lexicale à prendre en compte\r\n-- identification de marqueurs contextuels\r\n-- implémentation dans le système existant (règles d\'extraction et\r\n   lexique)\r\n- intégration à une chaine d\'analyse,\r\n- tests\r\n\r\nCompétences requises:\r\n- chinois (mandarin de préférence)\r\n- bonne connaissance des outils de TAL,\r\n- langage de script (perl, Groovy),\r\n- bonnes capacités d\'analyse,\r\n- goût pour la résolution de problèmes,\r\n- facilité à travailler en équipe\r\n\r\nStage rémunéré 450 euros brut mensuel, basé au Kremlin Bicêtre (porte\r\nd\'italie), dès que possible.\r\nEnvoyer CV + lettre à hugues.de-mazancourt@lingway.com'),
(95, '2011-10-17', 'Université d\'Artois', 'Arras', 'Offre de stage conventionné (Master TAL)\r\n\r\nIntitulé du stage :     « Traitement automatique de corpus bilingues »\r\n\r\nLieu du stage :         Université d\'Artois, pôle d\'Arras\r\n\r\n                        Centre de recherche : « Grammatica » (EA 4521)\r\n\r\n\r\nhttp://www.univ-artois.fr/recherche/unites-de-recherche/grammatica\r\n\r\nDurée :                 3 mois TC (ou 6 mois TP)\r\n\r\nDébut du stage :        1er novembre 2011\r\n\r\nGratification :         417,09 ¤/mois (temps complet)\r\n\r\n\r\n\r\nDescriptif :\r\n\r\nDans le cadre d\'un projet de constitution de corpus bilingues, le Centre\r\nde recherche Grammatica de l\'Université d\'Artois propose un stage de\r\ntrois mois à temps complet (ou éventuellement, de six mois à temps\r\npartiel) dans le domaine du TAL. Le(la) candidat(e) doit être en mesure\r\nd\'effectuer de façon autonome les tâches suivantes :\r\n\r\n\r\n- récupération de textes au format .txt\r\n\r\n- vérification de textes récupérés au format .txt (correction\r\n  typographique et orthographique)\r\n\r\n- analyses linguistiques automatiques (segmentation, étiquetage)\r\n\r\n- formatage et structuration à la norme TEI (balisage XML standardisé)\r\n\r\n- alignement\r\n\r\n- vérification manuelle d\'alignements automatiques (français-anglais/\r\n  anglais-français)\r\n\r\n\r\n\r\nUne bonne connaissance d\'outils TAL et une bonne maîtrise de l\'anglais\r\nécrit sont indispensables.\r\n\r\n\r\n\r\nLes candidats intéressés sont priés d\'envoyer leur CV accompagné d\'une\r\nlettre de motivation à Mr Dejan STOSIC à l\'adresse :\r\ndejan.stosic@univ-artois.fr pour le 21 octobre 2011 au plus tard.'),
(96, '2011-10-23', 'Syllabs', 'Paris', 'Offre de stage :  Analyse et génération de descriptifs produits\r\n(Syllabs)\r\n\r\n------------------------------------------------------------------------\r\n\r\n------------\r\nContexte\r\n------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création automatique\r\nde textes. Nos technologies sont le fruit d\'années de développement et\r\nmaîtrisent toutes les étapes du processus d\'analyse de données\r\ntextuelles du Web : identification des pages pertinentes, extraction et\r\ncatégorisation des informations clé.\r\n\r\nActuellement, nous recherchons un(e) linguiste francophone pour un stage\r\ndans le domaine de la création automatique de textes en français (langue\r\nmaternelle uniquement). L’idée est de créer des descriptifs de lieux ou\r\nde produits à partir d’une base de données existante (par exemple la\r\nliste des caractéristiques d’un produit).\r\n\r\n----------------------------\r\nDescription du poste\r\n----------------------------\r\n\r\nLes tâches principales concernent:\r\n\r\n- Écriture de règles de génération automatique de descriptifs de\r\n  produits et de lieux.\r\n\r\n- Règles d’extraction d’information sur ces produits et lieux.\r\n\r\n--------------------\r\nProfil souhaité\r\n--------------------\r\n\r\n- Langue maternelle français.\r\n\r\n- Excellentes qualités rédactionnelles en français, goût pour\r\n  l’écriture.\r\n\r\n- Aptitude pour la représentation formelle du langage.\r\n\r\n- Excellente capacité de communication et aptitude pour le travail\r\n  d’équipe.\r\n\r\n- De bonnes connaissances de l’allemand, portugais ou néerlandais\r\n  seraient un plus.\r\n\r\nDiplôme et expérience\r\n\r\n- Formation en cours : Master en Traitement Automatique des Langues ou\r\n  similaire.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en indiquant\r\ndans l\'objet du mél « Stage génération FR ». \r\n\r\nLieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris.\r\n\r\nContrat : stage conventionné rémunéré en fonction du niveau d’étude.'),
(97, '2011-10-25', 'Télécom Bretagne', 'Brest', 'Sujet du stage M2 (5-6 mois) : Un langage contrôle pour les Instructions\r\nNautiques du SHOM\r\n\r\nResponsables : Yannis Haralambous (Télécom Bretagne / Lab-STICC),\r\nGeorges Dubois (SHOM)\r\n\r\nLaboratoire d\'accueil : Télécom Bretagne http://www.telecom-bretagne.eu\r\net Lab-STICC, pôle CID, équipe DECIDE http://www.lab-sticc.fr/\r\n\r\nLes langages contrôlés sont des langages artificiels utilisant un\r\nsous-ensemble du vocabulaire, des formes morphologiques, des\r\nconstructions grammaticales et des interprétations sémantiques d’une\r\nlangue naturelle (dans notre cas : le français). En quelque sorte ils\r\nconstituent le pont entre les langages formels et les langues\r\nnaturelles. De ce fait, ils remplissent la fonction de communication du\r\nmédium texte tout en étant rigoureux et analysables par la machine sans\r\nambiguïté.\r\n\r\nEn particulier, ils peuvent être utilisés pour faciliter l’alimentation\r\nde bases de connaissances, dans le cadre d’une interface homme-machine\r\nau moment de la saisie du texte.\r\n\r\nLe Service Hydrographique et Océanographique de la Marine (SHOM) publie\r\ndepuis plusieurs années les Instructions Nautiques, un recueil de\r\nrenseignements généraux, nautiques et réglementaires, destinés aux\r\nnavigateurs. Ces informations complètent les cartes marines. Elles sont\r\nobligatoires à bord des navires de commerce et de pêche.\r\n\r\nL’Organisation Hydrographique Internationale (OHI) a publié des normes\r\nspécifiant l’échange de données liées à la navigation et notamment un\r\nmodèle universel de données hydrographiques (norme S-100, janvier 2010).\r\n\r\nLe but de ce stage est d’élaborer un langage contrôlé qui couvre les\r\nbesoins des Instructions Nautiques et qui permette l’alimentation de\r\nbases de connaissances conformes à la norme S-100. Comment faire évoluer\r\nle langage selon les évolutions des ontologies concernées et\r\nl\'alimentation de la base de connaissances ?\r\n\r\nDans le contexte d’une thèse CIFRE, deux applications seront envisagées\r\n: (a) une interface homme-machine qui analyse en temps réel le texte\r\nsaisi par l’opérateur des Instructions Nautiques et qui valide son\r\nappartenance au langage contrôlé ; (b) un outil semi-automatique de\r\ntraduction des documents existants dans le langage contrôlé.\r\n\r\nCe stage se concentrera sur la faisabilité d’un langage contrôlé qui\r\nsatisfasse les deux contraintes : exploitation optimale du contenu\r\ntraditionnel des Instructions Nautiques et adéquation avec la norme\r\nS-100. Un prototype de langage sera élaboré, accompagné des algorithmes\r\nd’extraction de connaissances et d’alimentation d’une base de\r\nconnaissance conforme à la norme S-100.\r\n\r\nCe stage est proposé en collaboration avec le SHOM.\r\n\r\nPour candidater : envoyer LM+CV à \r\nyannis.haralambous [ à ] telecom-bretagne.eu'),
(98, '2011-11-10', 'Semantia', 'Marseille', 'Semantia est un fournisseur de services en ligne (ASP), spécialisé\r\ndans le traitement du langage pour l\'optimisation de la gestion de la\r\nrelation client.\r\n\r\nObjectif du Stage :\r\n\r\nL\'objectif du stage est de réaliser une étude qualitative et\r\nstratégique sur l\'histoire et les technologies du traitement\r\nautomatique du langage naturel et écrit.  Le stagiaire devra mettre en\r\nplace des méthodes ainsi que des outils d\'extraction et d\'analyse des\r\ndonnées ciblées par l\'étude, en collaboration avec l\'équipe\r\nlinguistique et de développement.\r\n\r\nConnaissances requises et/ou acquises :\r\n\r\nExpertise linguistique\r\nLangages informatiques environnement web : PHP, SQL, HTML\r\nBonnes connaissances des expressions régulières\r\nFacilité d\'adaptation\r\nTravail en équipe\r\nLogique\r\nRigueur\r\n\r\nNiveau :\r\nBac+3 minimum dans la discipline\r\n\r\nDurée du Stage :\r\nDe 3 à 5 mois.\r\n\r\nLieu du Stage :\r\nPACA, 13420 Gémenos\r\n\r\nContacts :\r\ndrh@semantia.com\r\nTél. 04 42 36 80 91'),
(99, '2011-11-21', 'Syllabs', 'Paris', 'Objet : Stage recherche à Syllabs\r\n\r\nLieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris\r\n\r\nDurée : 5 à 6 mois\r\n\r\nDébut du stage souhaité : entre janvier et avril 2012\r\n\r\n\r\n\r\nSujet du stage\r\n\r\nExtraction automatique d\'objets et d\'attributs en domaine spécialisé\r\n\r\nMots-clés\r\n\r\nextraction d\'information, extraction d\'attributs, moteur de recherche,\r\nweb\r\n\r\nContexte\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création automatique\r\nde textes.\r\nNos technologies sont le fruit d\'années de développement et maîtrisent\r\ntoutes les étapes du processus d\'analyse de données textuelles du Web :\r\nidentification des pages pertinentes, crawling du Web, extraction et\r\ncatégorisation des informations clé.\r\nDans le cadre d\'un projet de recherche, Syllabs développe des méthodes\r\npour construire de manière semi-automatique des moteurs de recherche\r\nverticaux thématiques (i.e. politique, astronomie, ...) et souhaite les\r\nenrichir de connaissances du domaine extraites (semi-) automatiquement.\r\n\r\nObjectifs\r\n\r\nContrairement aux moteurs de recherche généralistes, les moteurs de\r\nrecherche thématiques sont centrés sur un domaine et peuvent tirer parti\r\nde cette verticalité pour réaliser des analyses fines sur leurs\r\ndocuments.\r\nNous nous intéressons, dans le cadre de ce stage, à la découverte\r\nd\'objets d\'un domaine et de leurs propriétés (attributs/valeurs) à\r\npartir d\'un ensemble de documents et de connaissances minimalistes\r\n(quelques objets+attributs du domaine).\r\n\r\nIllustration (astronomie)\r\n - objets : terre, mercure, mars\r\n - caractéristiques : diamètre, volume, distance du soleil...\r\n\r\nLes méthodes utilisées durant ce stage seront centrées sur le traitement\r\nautomatique des langues et l\'apprentissage statistique.  La personne\r\nrecrutée travaillera au sein de l\'équipe R&D.\r\n\r\nProfil recherché\r\n    * École d\'ingénieurs avec un goût pour la recherche, Master 2\r\n      recherche en informatique\r\n    * Bonnes compétences en programmation : maîtrise de Python et/ou\r\n      Java\r\n    * Connaissances en traitement automatique des langues\r\n\r\nÉléments facultatifs mais considérés comme un plus\r\n    * Connaissances en recherche d\'information\r\n    * Connaissances en apprentissage statistique\r\nq\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nstage_extraction_objets@syllabs.com'),
(100, '2011-12-19', 'ELDA', 'Paris', 'ELDA (Evaluation and Language resources Distribution Agency, \r\nwww.elda.org <http://www.elda.org/>) a pour activités principales la \r\ndistribution et la production de ressources linguistiques, ainsi que \r\nl\'évaluation de technologies de la langue.\r\n\r\nDans le cadre de ses activités de production, ELDA offre 1 stage de\r\nconcepteur de documents textuels illustrés (H/F).\r\n\r\nContexte\r\n\r\nELDA participe à un projet visant à évaluer les systèmes d\'analyse\r\nautomatique des documents écrits. Pour les systèmes en compétition, il\r\ns\'agit de répondre automatiquement aux questions suivantes :\r\n\r\n  * Comment le document est-il structuré (zones de texte, images...) ?\r\n\r\n  * Quelles sont les écritures présentes, avec leur type\r\n    (manuscrit/dactylo) et leur langue (Français, Anglais, Arabe, autre)?\r\n\r\n  * Quelles sont les informations principales du documents (auteur,\r\n    destinataire, objet, date...) ?\r\n\r\nAfin de disposer de données pour l\'évaluation des systèmes d\'analyse\r\nautomatique, des documents originaux sont collectés. Rédigés par des\r\nvolontaires (rémunérés) sous une identité fictive qui leur est\r\nattribuée, ces documents se basent sur des scénarios fictifs et des\r\nmodèles de documents crées par ELDA (formulaires, bon de commande, page\r\nde catalogue, tract politique ou commercial, carte de voeux,\r\nen-têtes...).\r\n\r\nUne fois collectés, ces documents font l\'objet d\'une description\r\nmanuelle de leur contenu, afin de pouvoir comparer l\'analyse automatique\r\ndes systèmes avec les performances humaines.\r\n\r\n\r\nMission\r\n\r\nSous la responsabilité du chef de projet, le candidat réalisera les\r\nmodèles de document nécessaires à la rédaction des documents à\r\ncollecter. Les modèles peuvent être :\r\n\r\n  * des fichiers images que les volontaires devront imprimer puis\r\n    compléter manuellement ;\r\n\r\n  * des fichiers .doc ou .ppt à compléter électroniquement (saisie au\r\n    clavier) avant impression ;\r\n\r\n  * des lettres-types au format image guidant la rédaction de courriers\r\n    manuscrits ou dactylo.\r\n\r\nSelon ses compétences, le stagiaire pourra également intervenir sur\r\nd\'autres aspects du projet, comme la maintenance du site web de collecte\r\n(php/mySQL), la validation des documents collectés, ou encore leur\r\nannotation (i.e. la description des documents via un logiciel dédié).\r\n\r\n\r\nProfil recherché\r\n\r\n  * Formation universitaire ou ingénieur\r\n\r\n  * Maîtrise de l\'édition sous Word et Powerpoint\r\n\r\n  * Compétences en traitement d\'image (Gimp/Photoshop, gestion des\r\n    formats)\r\n\r\n  * Qualités rédactionnelles : orthographe, grammaire, inspiration\r\n    (invention des scénarios fictifs)\r\n\r\n  * Un bon niveau d\'anglais et/ou d\'arabe constitue un plus (afin de\r\n    réaliser/décliner les modèles dans les 2 autres langues du projet,\r\n    le français étant la langue principale).\r\n\r\nDurée : Stage long (4 mois minimum)\r\n\r\nCe stage, basé à Paris-13e (RER Cité universitaire), est à pourvoir\r\navant le printemps 2012.\r\n\r\nLes candidatures (CV, lettre de motivation) doivent être adressées à\r\nMatthieu Carré (carre@elda.org). Elles seront étudiées à partir de\r\njanvier 2012.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(101, '2011-12-19', 'Scan-Research', 'Paris', 'SCAN-research\r\n\r\nProposition de stage pour un info-linguiste (niveau Master II)\r\n\r\nStage dans une société innovante d\'étude et d\'analyse de la conversation\r\ndes Internautes\r\n\r\n1. Présentation de la société et du secteur d\'activité\r\n\r\nScan-research est une jeune start-up créée en août 2010, spécialisée\r\ndans l\'observation et l\'analyse de l\'opinion des Internautes. \r\n\r\nNous sommes aujourd\'hui hébergés par l\'incubateur d\'entreprises\r\ninnovantes Agoranov (incubateur créé par UPMC, Paris IX-Dauphine, ENS,\r\nParis tech) ; nous avons reçu le soutien d\'Oséo et de la Mairie de Paris\r\n\r\n  - Nos clients sont de grandes entreprises du luxe (LVMH...), de l\'énergie\r\n    (EDF, ERDF...) et des administrations.\r\n\r\n  - Nous avons conclu un partenariat avec de grands titres de presse\r\n    pour suivre les évolutions de la conversation des Internautes durant\r\n    les élections présidentielles.\r\n\r\n\r\nNous sommes à la recherche d\'étudiants motivés, curieux et autonomes\r\npour nous accompagner dans la réalisation de nos études et de nos\r\nmissions de veille et d\'analyse sur la conversation des Internautes, à\r\nl\'aide de notre plateforme propriétaire.\r\n\r\nLes tâches qui vous seront confiées seront (entre autres) les suivantes :\r\n\r\n- Construire les ontologies en fonction desquelles seront catégorisées\r\n  les conversations observées\r\n\r\n- Rédiger les descripteurs linguistiques de ces ontologies selon les\r\n  méthodologies que nous avons développées\r\n\r\n- Interagir avec les développeurs de notre plateforme, et les\r\n  concepteurs du moteur de TAL avec lequel nous travaillons\r\n\r\n\r\n2. Profil\r\n\r\nVous êtes infolinguistes, avec : \r\n\r\n- une bonne connaissance des problématiques du Traitement Automatique\r\n  des Langues Naturelles\r\n\r\n- Une connaissance des problèmes liés à la constitution d\'ontologies\r\n  appliquées à la réalité sociale\r\n\r\n- Une bonne culture générale notamment en matière de sociologie, ne\r\n  nuira pas ; un intérêt pour les questions de formation de l\'opinion et\r\n  de sémantique politique sera apprécié. \r\n\r\n- Une pratique courante de l\'anglais est un requis\r\n\r\n\r\nNous cherchons des candidats à la fois rigoureux, imaginatifs,\r\nintéressés à  participer à l\'élaboration de méthodologies innovantes en\r\nmatière de mise en ½uvre des techniques de linguistiques appliquées aux\r\nsciences sociales et au marketing.\r\n\r\n3. Modalités pour postuler\r\n\r\nEnvoyez votre candidature par mail à gilles.achache@scan-research.net\r\n\r\n4. Déroulement du stage\r\n\r\nSalaire : à négocier\r\nLieu du stage : Paris (boulevard Raspail)\r\nDurée : 6 mois / 12 mois (possibilité de transformer le stage en premier\r\n        emploi en cas de réussite)\r\nDate de démarrage :     15 janvier 2012'),
(102, '2012-01-03', 'LIMSI', 'Orsay', 'Stage M2 : Détection de réactions et de promesses dans les articles de\r\npresse.\r\n\r\n\r\nMots-clés : traitement automatique de la langue, classification,\r\névénements \r\n\r\nContexte\r\n\r\nEntre autres objectifs, le projet ANR ChronoLines a pour but de créer\r\nde façon semi-automatique des chronologies à partir de dépêches\r\nd\'agences. Étant donnés un thème fourni par l\'utilisateur et un\r\nensemble de textes, il s\'agit de retrouver dans les documents les\r\névénements les plus importants concernant ce thème, puis de les\r\nordonner et de les présenter à l\'utilisateur pour validation. Par\r\nexemple, pour une demande sur un nom de personne, le système devra\r\nretracer les événements marquants de sa vie. Pour les négociations de\r\npaix au Moyen-Orient, les principales dates importantes s\'y\r\nrattachant.\r\n\r\nUn point intéressant se rattachant à ce projet est le fait que de\r\nnombreux événements sont sujets à :\r\n\r\n    * Des projections dans le futur : promesses d\'un homme politique\r\n      ou d\'une entreprise, prévisions, annonces diverses, etc.\r\n\r\n    * Des réactions de personnalités : par exemple, un attentat\r\n      important sera condamné par les gouvernants du monde entier, une\r\n      décision politique d\'envergure sera à la fois louée et critiquée\r\n      par de nombreuses personnes, etc.\r\n\r\nCes aspects sont intéressants à deux titres. Tout d\'abord, un\r\névénement sujet à de nombreuses réactions pourra être qualifié\r\nd\'\"important\", et donc aura plus de chances d\'apparaître dans une\r\nchronologie thématique. D\'autre part, ajouter à ces chronologies des\r\nliens vers les promesses faites au sujet d\'un événement, ou vers\r\nl\'ensemble des réactions qu\'il a suscitées, pourrait apporter une\r\nfonctionnalité appréciée des utilisateurs.\r\n\r\n\r\nTravail à réaliser :\r\n\r\nDurant ce stage, on utilisera un corpus de plusieurs années de\r\ndépêches d\'agence, composant une base très importante d\'événements et\r\nde déclarations de toutes sortes. L\'objectif du stagiaire sera de :\r\n\r\n    * Parcourir la littérature scientifique sur le sujet\r\n      (classification de texte notamment).\r\n\r\n    * Réaliser un système permettant de décider si un article ou une\r\n      partie d\'un article représente une promesse faite par une\r\n      personne ou une organisation, ainsi qu\'une réaction à un\r\n      événement ayant eu lieu auparavant (et d\'indiquer à quel\r\n      événement la réaction correspond).\r\n\r\nLe stagiaire devra avoir de bonnes compétences en informatique et en\r\ntraitement automatique de la langue.\r\n\r\nDurée : 4 à 6 mois\r\n\r\nNiveau : Master 2 (professionnel ou recherche)\r\n\r\nContacts :\r\n\r\nVeronique.Moriceau[at]limsi.fr\r\n\r\nXavier.Tannier[at]limsi.fr'),
(103, '2012-01-03', 'EDF', 'Paris', 'Proposition de stage opérationnel en Text-Mining\r\n\r\nDepuis le 1er juillet 2007, le marché de l\'électricité est entièrement\r\nouvert à la concurrence et permet au consommateur de choisir librement\r\nson fournisseur d\'énergie. Dans ce contexte, il est devenu stratégique\r\npour EDF de comprendre les besoins de ses clients, mais également\r\nd\'expliquer et de prédire leur comportement.\r\n\r\nLe Domaine Analyse de la Connaissance Client au sein du Département des\r\nSystèmes d\'Information de la Branche Commerce a, pour partie, la mission\r\nd\'analyser les différents systèmes d\'information d\'EDF et notamment les\r\ndonnées textuelles présentes dans ses bases. Actuellement, nous\r\nutilisons des techniques de Text Mining pour analyser automatiquement\r\ndes commentaires et notamment des réclamations de clients provenant de\r\nnos différents SI. \r\n\r\nLe stage que nous proposons est opérationnel et va comprendre plusieurs\r\naxes :\r\n\r\nLa création de cartouches d\'extraction de connaissances (Technologie\r\nSkill Cartridge développée par la société TEMIS) permettant à la fois\r\nd\'améliorer et de repérer des concepts métier, mais également de\r\ncontribuer à l\'amélioration de nos modèles de classement.\r\n\r\nUne étude portant sur la comparaison des résultats obtenus en Text\r\nMining sur l\'analyse des commentaires « réclamation » avec les\r\ninformations rentrées manuellement par le conseiller.\r\n\r\nLa mise en place d\'un processus d\'industrialisation plus léger,\r\npermettant, non pas d\'analyser l\'intégralité des champs commentaires,\r\nmais un échantillon représentatif de nos clients. \r\n\r\nLe stage aura une durée de 6 mois et se déroulera dans la tour EDF à la\r\nDéfense au cours de l\'année 2012. Le stagiaire sera rémunéré.  \r\n\r\nLe profil recherché est un étudiant de niveau BAC +5 spécialisé en\r\nTraitement Automatique du Langage. De bonnes connaissances linguistiques\r\net informatiques sont indispensables. Des connaissances statistiques ou\r\ndes outils développés par TEMIS seraient un plus apprécié. \r\n\r\nLes candidatures (CV + lettre de motivation) sont à envoyer à\r\nanne-laure.guenet@edf.fr.'),
(104, '2012-01-03', 'GEOLSemantics', 'Paris', '-------------------------------\r\nStage fin d\'études pré-embauche : Ingénieur Développement\r\n\r\nAvant-vente: Authentification forte grâce à la voix\r\n\r\nLa société :\r\n\r\nLa société GEOLSemantics est une société française basée à Paris et qui\r\ncompte une quinzaine de personnes.\r\nElle a pour vocation de proposer des solutions logicielles pour aider à\r\nla détection et au tracking d\'activités hostiles envers les Etats, les\r\nentreprises et les personnes. Ces solutions s\'appliquent à l\'information\r\ncontenue dans les différents média : texte, audio et vidéo.\r\nElles utilisent des algorithmes sophistiqués d\'analyse sémantique\r\nmultilingue pour permettre aux opérationnels de disposer d\'une\r\ninformation synthétique représentant la connaissance extraite des\r\ndifférentes sources d\'information.\r\nElles utilisent également des technologies d\'avant-garde\r\nd\'identification de locuteur dans les médias audio ou vidéo.\r\n\r\nSujet du stage \r\n\r\nGEOLSemantics recherche un stagiaire bac +5 en informatique pour la\r\nréalisation d\'un prototype `authentification forte de locuteur\'\r\nutilisant nos outils de biométrie vocale.\r\nIntégré(e) au sein d\'une équipe à taille humaine, vous aurez la\r\npossibilité de vous épanouir dans le monde de la sécurité renforcée et\r\nde la lutte contre l\'usurpation d\'identité.\r\n\r\nContenu du stage :\r\n\r\nLe but de ce stage est de réaliser un prototype pour appuyer la vente de\r\nnos solutions de biométrie vocale. L\'objectif est d\'améliorer la\r\nsécurité d\'accès des applications grâce à l\'identification vocale du\r\nlocuteur. Cette authentification forte vient en complément des méthodes\r\nclassiques basées sur un login/mot de passe.\r\n\r\nDéroulement du stage :\r\n-	Choix et mise en place de l\'architecture,\r\n-	Elaboration de scenarii,\r\n-	Développement de l\'infrastructure du prototype,\r\n-	Développement d\'une application sous Androïd pour la mise à\r\n        disposition du prototype sur mobile,\r\n-	Test et présentation aux avant projets client.\r\n\r\nVos capacités d\'autonomie, vos aptitudes à vous exprimer et à rédiger\r\nvous permettront rapidement d\'être responsable de la réalisation et du\r\nsuivi complet de vos travaux sous la conduite d\'un ingénieur\r\nexpérimenté.\r\n\r\nProfil du stagiaire :\r\n\r\nCompétences techniques requises :\r\n\r\n-	Master 2 ou ingénieur en informatique \r\n-	bonnes connaissances en Java Web (notion de HTML/CSS)\r\n-	des connaissances en Androïd (ou capacité à acquérir ces\r\n        connaissances rapidement)\r\n-	capacité à appréhender un domaine nouveau (biométrie vocale)\r\n-	Maîtrise du XML et de RDF\r\n\r\nQualités requises : Bon rédactionnel. Forte curiosité fonctionnelle,\r\nforte autonomie\r\n\r\nLe stage est placé sous la responsabilité du responsable avant-vente\r\n\r\n-	Durée : 6 mois minimum\r\n-	Début du stage : dès que possible\r\n-	Lieu : Paris 15ème\r\n-	Indemnités : à débattre\r\n\r\nCandidature à adresser  (CV, lettre de motivation, photo) à :\r\nEmmanuel Dupont, Directeur des Opérations \r\nSociété GEOLSemantics\r\n32,  rue Brancion\r\n75015 Paris\r\nemmanuel.dupont@geolsemantics.com\r\nSite WEB : en cours de construction\r\n\r\n----------------------------------------\r\n\r\nStage fin d\'études pré-embauche : Ingénieur Développement\r\nModule d\'élaboration de règles linguisitiques\r\n\r\nLa société :\r\n\r\nBasée à Paris, GEOLSemantics est une jeune entreprise innovante qui\r\ndéveloppe et commerciale des logiciels de traitement automatique du\r\nlangage naturel pour satisfaire des besoins de veille stratégique. Les\r\napplications sont multiples et principalement centrées sur la détection\r\nautomatique de menace, de rumeur ou d\'opinion à partir de l\'analyse\r\nsystématique des documents multi-lingues publiés sur le WEB, dans les\r\nsites, les blogs, les forums ou les réseaux sociaux.\r\n\r\nSujet du stage\r\n\r\nGEOLSemantics recherche un stagiaire bac +5 en informatique pour la\r\nréalisation de son module d\'élaboration de règles linguistiques de haut\r\nniveaudestinée à extraire des connaissances structurées exprimées dans\r\nune ontologie. Intégré(e) au sein d\'une équipe à taille humaine, vous\r\naurez la possibilité de vous épanouir dans le monde du Web 3.0 sur des\r\ntechnologies J2ee (Portlet sous Liferay, Java).\r\n\r\nContenu du stage :\r\n\r\nActuellement, l\'écriture de règles linguistiques nécessite une expertise\r\npointue sur notre moteur de traitement. GEOLSémantics souhaite mettre à\r\ndisposition de ses ingénieurs et de ses partenaires un SDK d\'assistance\r\nà l\'écriture de règles linguistiques. Le but de cet outil est\r\nd\'augmenter la productivité en interne et de faciliter la prise en main\r\nde notre progiciel par des intervenants extérieurs.\r\n\r\nA partir du cahier des charges, vous devrez comprendre le besoin\r\nfonctionnel pour rédiger les spécifications fonctionnelles et mettre en\r\nplace rapidement une première maquette. Après validation auprès des\r\nutilisateurs finaux, vous aurez la responsabilité de développer et\r\nlivrer le SDK.\r\n\r\nLa décomposition des activités est la suivante : 60% de spécification :\r\ncompréhension du besoin, des langages manipulés par les linguistes, du\r\nmétier du Web 3.0; 40% de développement en Java (exécutable intégré à\r\nnotre moteur sémantique et IHM).\r\n\r\nVos capacités d\'autonomie, vos aptitudes à vous exprimer et à rédiger\r\nvous permettront rapidement d\'être responsable de la réalisation et du\r\nsuivi complet de vos travaux sous la conduite d\'un ingénieur\r\nexpérimenté.\r\n\r\nProfil du stagiaire :\r\n\r\nCompétences techniques requises :\r\n- Capacité à appréhender un domaine nouveau (le Web sémantique)\r\n- Base algorithmique sur les automates \r\n- Bonnes compétences en Java\r\n- Maîtrise du XML et de RDF\r\n\r\nQualités requises : Bon rédactionnel. Forte curiosité fonctionnelle\r\nLangue : Anglais exigé\r\n\r\nLe stage est placé sous la responsabilité du Directeur des Opérations\r\n\r\n-	Durée : 6 mois minimum\r\n-	Début du stage : dès que possible\r\n-	Lieu : Paris 15ème\r\n-	Indemnités : à débattre\r\n\r\nCandidature à adresser  (CV, lettre de motivation, photo) à :\r\nEmmanuel Dupont, Directeur des Opérations \r\nSociété Cadège/GEOLSemantics\r\n32,  rue Brancion\r\n75015 Paris\r\nemmanuel.dupont@geolsemantics.com\r\nSite WEB : en cours de construction\r\n\r\n---------------------------------------------\r\nStage fin d\'études pré-embauche : Ingénieur Développement\r\n\r\nAlgorithme de clustering\r\n\r\nLa société :\r\n\r\nBasée à Paris, GEOLSemantics est une jeune entreprise innovante qui\r\ndéveloppe et commerciale des logiciels de traitement automatique du\r\nlangage naturel pour satisfaire des besoins de veille stratégique. Les\r\napplications sont multiples et principalement centrées sur la détection\r\nautomatique de menace, de rumeur ou d\'opinion à partir de l\'analyse\r\nsystématique des documents multi-lingues publiés sur le WEB, dans les\r\nsites, les blogs, les forums ou les réseaux sociaux.\r\n\r\nSujet du stage\r\n\r\nGEOLSemantics recherche un stagiaire bac +5 en informatique pour la\r\nréalisation d\'un algorithme de clustering. Intégré(e) au sein d\'une\r\néquipe à taille humaine, vous aurez la possibilité de vous épanouir dans\r\nle monde du Web 3.0.\r\n\r\nContenu du stage :\r\n\r\nDe façon à évaluer la qualité des outils de regroupement d\'information\r\nconcernant des personnes (comme 123people), la communauté scientifique a\r\norganisé plusieurs compétitions internationales (campagnes WEBS). A\r\npartir d\'un ensemble de textes qui concernent des personnes avec des\r\nhomonymes (personnes différentes de même nom), une première phase\r\nconsiste à regrouper les documents parlant de la même personne par des\r\ntechnologies de clustering et dans un deuxième temps pour chaque cluster\r\nqui concerne une seule personne (les homonymes étant sensé avoir été\r\ndistingués par le clustering) on extrait un certain nombre d\'information\r\nconcernant la personne (date et lieu de naissance, adresse, téléphone,\r\ndiplômes, ...).\r\n\r\nLa société GEOLSemantics a développé des traitements linguistiques\r\nautomatiques qui permettent d\'identifier dans les textes les éléments\r\nsignificatifs et d\'extraire des informations concernant les personnes.\r\nEn s\'appuyant sur les outils existant dans la société, il est demandé au\r\nstagiaire de développer un algorithme de clustering qui s\'appuiera sur\r\nles résultats de l\'analyse linguistique des textes décrivant les\r\npersonnes.  Ensuite de compléter les règles d\'extraction des\r\nconnaissances pour extraire de chaque cluster les informations demandées\r\npar la campagne d\'évaluation WEBS. Les résultats pourront être comparés\r\naux résultats obtenus pas les participants aux campagnes précédentes.\r\n\r\nLa langue de la campagne étant l\'anglais, il est demandé au stagiaire\r\nd\'avoir une maîtrise de cette langue.\r\n\r\nVos capacités d\'autonomie, vos aptitudes à vous exprimer et à rédiger\r\nvous permettront rapidement d\'être responsable de la réalisation et du\r\nsuivi complet de vos travaux sous la conduite d\'un ingénieur\r\nexpérimenté.\r\n\r\nProfil du stagiaire :\r\n\r\nCompétences techniques requises :\r\n\r\nProfil demandé :\r\n\r\n- Master 2 ou ingénieur en informatique ayant une connaissance en\r\n  traitement automatique des langues.\r\n- Goût de la compétition (il faut sortir de meilleurs résultats que les\r\n  autres). Les résultats pourront faire l\'objet d\'une publication\r\n  scientifique.\r\n- Capacité à appréhender un domaine nouveau (le Web sémantique)\r\n- Bonnes compétences en Java\r\n- Maîtrise du XML et de RDF\r\n\r\nQualités requises : Bon rédactionnel. Forte curiosité fonctionnelle\r\nLangue : Anglais exigé\r\n\r\nLe stage est placé sous la responsabilité du Directeur Scientifique\r\n\r\n-	Durée : 6 mois minimum\r\n-	Début du stage : dès que possible\r\n-	Lieu : Paris 15ème\r\n-	Indemnités : à débattre\r\n\r\nCandidature à adresser  (CV, lettre de motivation, photo) à :\r\nEmmanuel Dupont, Directeur des Opérations \r\nSociété Cadège/GEOLSemantics\r\n32,  rue Brancion\r\n75015 Paris\r\nemmanuel.dupont@geolsemantics.com\r\nSite WEB : en cours de construction'),
(105, '2012-01-04', 'EDF R&D', 'Clamart', 'Stage Bac+5 : Evaluation d\'outils text mining pour la connaissance\r\nclient - le cas des données web\r\n\r\nLieu du stage : EDF R&D, 1, av du Général de Gaulle, 92141 Clamart\r\n\r\nContexte : stage de R&D en collaboration avec la branche Commerce d\'EDF\r\n- Direction des Système d\'Information- Domaine Analyse de Connaissance\r\nClient- Département Analyse Client\r\n\r\nSujet :\r\n\r\nL\'analyse des opinions des clients en tant que consommateurs mais aussi\r\nen tant que citoyens est une problématique au c½ur des préoccupations\r\nd\'EDF, depuis l\'ouverture du marché de l\'énergie. De quoi se plaignent\r\nles clients ? Quel est l\'impact d\'une nouvelle offre sur la satisfaction\r\n? Quelle est l\'ampleur du phénomène « Green Attitude » ? Comment est\r\nperçu le nouveau compteur communicant? La R&D d\'EDF développe depuis\r\n2002 des techniques de text mining destinées à analyser les opinions\r\nexprimées par les clients dans les questions ouvertes d\'enquêtes de\r\nsatisfaction, et les réclamations des clients provenant de nos\r\ndifférents Systèmes d\'Information. Ces technologies ont été transférées\r\nau niveau opérationnel à la branche commerce d\'EDF avec laquelle nous\r\ntravaillons en étroite collaboration. L\'activité de la R&D se focalise\r\nactuellement sur l\'adaptation de ces techniques sur d\'autres sources ou\r\nsupports d\'information et notamment sur les données issues du web. Ce\r\ndernier type de données pose un certain nombre de problèmes liés à leur\r\ncaractère bruité (usage de smileys, fautes d\'orthographes, abréviations,\r\netc.).\r\n\r\nL\'objectif de ce stage sera d\'évaluer trois outils d\'analyse automatique\r\nde données textuelles existants, dont l\'outil LUXID de la société TEMIS\r\nutilisé actuellement à EDF. Le stagiaire aura pour mission de prendre en\r\nmain ces outils de les comparer selon les critères suivants :\r\n\r\n- La pertinence de leurs sorties sur un corpus issus du Web2.0\r\n  d\'expressions d\'opinions autour d\'EDF.\r\n\r\n- L\'architecture logicielle, l\'ergonomie et les fonctionnalités de ces\r\n  outils.\r\n\r\n\r\nProfil recherché :\r\nBac+5, stage de fin d\'étude dans le domaine du TALN.\r\nCompétences en informatique et en TAL\r\nProgrammation : perl ou équivalent\r\n\r\nContact  et envoi des candidatures :\r\n\r\nChloé Clavel, 01 47 65 43 15, chloe.clavel@edf.fr\r\n\r\nDurée : environ 6 mois\r\n\r\nRémunération : environ 900¤ net /mois\r\n\r\n      Chloe CLAVEL\r\n      Ingénieur chercheur\r\n      EDF\r\n      ICAME\r\n      1, av. du Général de Gaulle\r\n      92141 Clamart\r\n\r\n      chloe.clavel@edf.fr\r\n      Tél. : 33 (0)1 47 65 43 15'),
(106, '2012-01-09', 'IGN', 'Saint-Mandé (94)', 'Extraction de règles de conception de cartes d\'un corpus de la\r\ncartographie\r\n\r\nMots clés\r\nTAL, informatique, gestion des connaissances, cartographie\r\n\r\nContexte\r\n\r\nLe laboratoire COGIT de l\'Institut national de l\'information\r\ngéographique et forestière (IGN) étudie les problématiques liées à\r\nl\'utilisation de données topographiques pour la fabrication de produits\r\n(cartes géographiques, lot de données) ou de services répondant à des\r\nbesoins particuliers, spécifiés par les utilisateurs de ces produits.\r\nCe stage a pour objectif d\'extraire les règles de conception de cartes\r\ntelles qu\'elles sont décrites dans un corpus textuel de la cartographie,\r\ndisponible dans une version électronique. Ce corpus a été formé à partir\r\nde sources différentes : un manuel de cartographie utilisé dans une\r\nécole d\'ingénieurs topographes qui détaille particulièrement la\r\nfabrication de cartes topographiques et des notes de cours de différents\r\nenseignements en cartographie de l\'université, ciblé sur les cartes\r\nthématiques.\r\n\r\nNous nous intéressons particulièrement aux règles de conception de la\r\ncarte, l\'ordre des étapes, les concepts (en relation avec l\'ontologie de\r\nla cartographie OntoCarto) sur lesquels s\'appuient ces modes opératoires\r\net leurs articulations, les principes de représentation (en relation\r\navec la base de règles OntoCartoRules). Pour l\'extraction des règles,\r\nsera mis en oeuvre l\'outil SEMEX, une plateforme d\'exploration\r\nsémantique et d\'aide à l\'acquisition de règles métiers candidates\r\ndéveloppée à Paris 13.\r\n\r\nCe stage est co-encadré par les laboratoires COGIT de l\'IGN et LIPN\r\n(Laboratoire d\'informatique de Paris Nord) à Villetaneuse.\r\n\r\nSujet\r\n\r\nL\'objectif du stage est d\'identifier les règles de conception d\'une\r\ncarte (topographique ou thématique) et de réécrire ces règles dans un\r\nformalisme plus rigide compatible avec la base de connaissances déjà\r\nconstruite.\r\n\r\nPour ce travail, il faudra préciser la notion de règle dans ce corpus ;\r\nreconnaître les variations de vocabulaire autour des noms des concepts\r\ndu domaine ; repérer les indices de désambiguïsation propres à ce corpus\r\n; définir les marqueurs spécifiques au corpus qui annoncent la\r\ndéfinition de règles et le caractère plus ou moins impérieux de cette\r\nrègle. En effet certaines règles sont essentielles à la compréhension de\r\nla carte par le lecteur, d\'autres correspondent plus à des habitudes ou\r\ndes préférences du concepteur. L\'objectif final est d\'identifier les\r\nstructures des phrases correspondant, pour ce corpus, à des règles et si\r\npossible leur impériosité et leur portée, en particulier déterminer si\r\nla règle s\'applique à toutes les cartes ou plus spécifiquement à une\r\ncarte topographique ou à une carte thématique.\r\n\r\nL\'ontologie OntoCarto intègre déjà les concepts correspondant aux\r\ntravaux sur les variables visuelles réalisés par Bertin sur lesquels\r\nsont fondées les règles de la sémiologie cartographique.\r\n\r\nBibliographie\r\n\r\nBertin, J. (1967). Sémiologie graphique : les diagrammes, les réseaux,\r\nles cartes.\r\n\r\nDominguès, C., S. Christophe, et L. Jolivet (2009). \"Connaissances\r\nopérationnelles pour la conception automatique de légendes de\r\ncartes\". 20èmes Journées Francophones d\'Ingénierie des Connaissances\r\n(IC\'2009), Hammamet, Tunisie.\r\n\r\nDominguès, C., O. Corby, et F. Soualah-Alila. \"Raisonner sur une ontologie cartographique\r\npour concevoir des légendes de cartes\". 12e Conférence Internationale Francophone sur\r\nl\'Extraction et la Gestion de Connaissance (EGC\'2012), 31 janvier - 3 février, Bordeaux,\r\nFrance (à paraître).\r\n\r\nmanuel d\'utilisation de SemEx :\r\nhttp://www-lipn.univ-paris13.fr/~guisse/ontorule/SemEx/SemEx_Manual.pdf\r\n\r\nCompétences particulières et formation requise\r\n\r\nCe stage s\'adresse aux étudiants de master 2 ou de 3ème année d\'école d\'ingénieurs\r\navec une spécialisation en informatique ou en traitement automatique du langage\r\nnaturel.\r\n\r\nLieu du stage\r\nIGN/laboratoire COGIT\r\n73 avenue de Paris\r\n94165 Saint-Mandé Cedex\r\nmétro : Saint-Mandé - ligne 1\r\nDurée et rémunération\r\ndurée : 5 à 6 mois\r\ndébut : mars/avril 2012\r\nrémunération : 30% du SMIC\r\nProlongements éventuels\r\n\r\nLe COGIT propose chaque année des sujets de thèse ainsi que des stages\r\nde postdoctorant.\r\n\r\nResponsable du stage\r\nCatherine Dominguès\r\nIGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex\r\ntél : 01 43 98 85 44 mél : catherine.domingues@ign.fr\r\n\r\nLe stage est co-encadré par : François Lévy\r\nLIPN, Institut Galilée, Avenue J.B. Clément, 93430 VILLETANEUSE\r\ntél : 01 49 40 35 78 mél : Francois.Levy@lipn.univ-paris13.fr\r\n\r\nPour candidater\r\nLe dossier de candidature sera envoyé par mail. Il devra se composer\r\nd\'un curriculum vitae et d\'une lettre de motivation, accompagnés des\r\nrelevés de notes des années de M1 et M2 (ou deux dernières années\r\nd\'école d\'ingénieurs) et d\'une description des enseignements suivis (un\r\nlien vers le site internet de la formation est le bienvenu).\r\n\r\nCatherine Dominguès\r\nLaboratoire COGIT/Service de la recherche\r\nT +33 (0)1 43 98 85 44\r\ncatherine.domingues@ign.fr\r\nIGN - INSTITUT NATIONAL DE L\'INFORMATION\r\nGEOGRAPHIQUE ET FORESTIERE\r\n73 AVENUE DE PARIS\r\n94165 SAINT-MANDE CEDEX\r\nhttp://recherche.ign.fr/cogit\r\n\r\n\r\nL\'INSTITUT NATIONAL DE L\'INFORMATION GÉOGRAPHIQUE ET FORESTIÈRE EST NÉ\r\nLE 1ER JANVIER 2012\r\nDE LA FUSION DE L\'INSTITUT GEOGRAPHIQUE NATIONAL ET DE L\'INVENTAIRE\r\nFORESTIER NATIONAL.'),
(108, '2012-01-16', 'Lexis Nexis', 'Paris', 'LexisNexis en France (600 collaborateurs, 140 M¤ de CA), filiale du\r\ngroupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les\r\nservices d\'information professionnelle. Ses activités couvrent trois\r\ndomaines : l\'information et l\'édition juridiques, la diffusion de la\r\npresse et de l\'information économique et financière sur Internet, les\r\nlogiciels professionnels. \r\n\r\n\r\nL\'entreprise s\'appuie sur une expertise éditoriale centenaire et sur une\r\ntechnologie de pointe pour apporter au monde du droit et aux\r\nprofessionnels de tous secteurs d\'activités une vaste gamme de produits\r\net services réputés : JurisClasseur, Litec, D.O, Bottin Administratif et\r\nles services en ligne LexisNexis.  \r\n\r\n\r\nMission :\r\n\r\nIntégré(e) à l\'équipe « Management de l\'information» votre mission\r\nconsistera à participer aux activités relatives au textmining, qui\r\ntraitent de l\'extraction d\'information juridique à valeur ajoutée.\r\n\r\n\r\nProfil :\r\n\r\nMaster 2 en linguistique, avec de bonnes connaissances en TAL.\r\n\r\nVous êtes d\'une nature rigoureuse et méticuleuse. Une sensibilité pour\r\nl\'étude du langage juridique serait un plus.\r\n\r\nNiveau d\'étude :\r\n\r\nMaster 2, stage de fin d\'étude.\r\n\r\nLIEU : \r\n141 rue de Javel\r\n\r\n75015 PARIS\r\n\r\nDUREE : \r\n\r\n5-6 mois à partir de février 2011\r\n\r\nMODALITES:\r\nIndemnité mensuelle de 417,09 euros \r\n\r\n50% carte orange.\r\nConvention de stage obligatoire\r\n\r\nCONTACT :\r\n\r\nMerci d\'envoyer votre candidature (CV + lette de motivation) ainsi que\r\nvos disponibilités par mail : celine.aubier@lexisnexis.fr'),
(109, '2012-01-16', 'CEA-LIST', 'Palaiseau', 'Proposition de stage de Master 2 (6 mois)\r\n\r\nExtraction faiblement supervisée de relations entre entités à une large\r\néchelle\r\n\r\nCEA LIST, Laboratoire Vision et Ingénierie des contenus, Nano-Innov\r\n(Palaiseau)\r\nEncadrants: Olivier Ferret et Romaric Besançon\r\n\r\n\r\nCONTEXTE\r\n\r\nLe sujet de stage proposé se situe dans le domaine de l\'extraction\r\nd\'information. Celle-ci a pour objectif de repérer automatiquement dans\r\ndes textes les entités caractéristiques d\'un domaine ainsi que les\r\nrelations intervenant entre ces entités, ceci dans le but d\'alimenter\r\nune base de connaissances ou une base de données.\r\n\r\nÀ titre d\'exemple, pour le passage :\r\n\"With a father from Kenya and a mother from Kansas, President Obama was\r\nborn in Hawaii on August 4, 1961.\"\r\nune telle extraction donne le résultat suivant si l\'on s\'intéresse aux\r\ndonnées de naissance d\'une personne :\r\nLieu_naissance : bornIn(President Obama, Hawaii)\r\nDate_naissance : bornOn(President Obama, August 4, 1961)\r\n\r\nOBJECTIFS\r\n\r\nLe stage se situe plus précisément dans le cadre de l\'extraction de\r\nrelations à large échelle, c\'est-à-dire opérant sur de larges ensembles\r\nde textes (plusieurs millions) et se focalisant sur un grand nombre de\r\ntypes de relations (plusieurs dizaines). Compte tenu de ce cadre, la\r\nligne directrice est l\'adoption d\'une approche faiblement supervisée :\r\nau lieu d\'apprendre des modèles de relations à partir de corpus annotés\r\nmanuellement, le principe est de prendre comme point de départ des\r\nrelations issues d\'une base de connaissances et de projeter ces\r\nrelations dans un corpus selon un processus d\'annotation non supervisée\r\npour construire des exemples d\'apprentissage automatiquement. Le\r\nlaboratoire LVIC du CEA LIST a déjà mis en ½uvre une telle approche dans\r\nle cadre de l\'évaluation KBP (Knowledge Base Population) de la campagne\r\nTAC (Text Analysis Conference).\r\n\r\nLe stage se situera dans le prolongement de ce travail en développant la\r\nproblématique de l\'apprentissage faiblement supervisé de relations et\r\nplus particulièrement de l\'utilisation de données d\'apprentissage\r\nbruitées. Deux problématiques seront abordées dans cette optique :\r\n\r\n- le filtrage des relations extraites, que ce soit pour la construction\r\n  des exemples d\'apprentissage ou l\'extraction finale des relations, en\r\n  s\'appuyant notamment sur des méthodes d\'apprentissage statistique ;\r\n\r\n- l\'extension de l\'ensemble des exemples pour une relation par\r\n  l\'exploitation de données issues du Web. L\'objectif est ici d\'acquérir\r\n  à partir d\'exemples sondes de nouvelles formulations d\'un type de\r\n  relations ou des paraphrases de formulations déjà rencontrées.\r\n\r\nCOMPÉTENCES REQUISES\r\n    - niveau M2 (ou ingénieur) en Informatique avec une spécialisation\r\n      en Traitement Automatique des Langues\r\n    - langages C++, Python\r\n\r\nLe stage sera rémunéré et se déroulera au centre Nano-Innov du CEA, à\r\nPalaiseau.\r\n\r\n\r\nLes candidats intéressés par ce stage sont invités à prendre contact\r\navec Olivier Ferret (olivier.ferret@cea.fr) ou Romaric Besançon\r\n(romaric.besancon@cea.fr) en envoyant un CV et une lettre de motivation.'),
(110, '2012-01-16', 'CEA-LIST', 'Palaiseau', 'Proposition de stage de Master 2 (6 mois)\r\n\r\nDéveloppement de ressources linguistiques pour l\'extraction d\'événements\r\ndans le domaine financier\r\n\r\nCEA LIST, Laboratoire Vision et Ingénierie des contenus, Nano-Innov\r\n(Palaiseau)\r\n\r\nEncadrants: Romaric Besançon et Nasredine Semmar\r\n\r\nLe stage se situe dans le contexte de l\'extraction d\'information,\r\ndomaine dont l\'objectif est d\'identifier des événements ou faits dans\r\ndes textes, et de structurer les informations retenues. Le stage se\r\nsitue plus précisément dans le cadre d\'un projet sur l\'extraction\r\nd\'événements dans le domaine financier, pour des textes en langues\r\nanglaise et arabe (une seule de ces langues ou les deux seront traitées\r\ndans le cadre du stage selon les connaissances du stagiaire). La\r\nspécification des événements à extraire est définie sous la forme d\'une\r\nontologie. Les événements concernent par exemple les changements de\r\npersonnel dans une entreprise, les évolutions d\'indicateurs financiers,\r\nles mentions de transactions financières.\r\n\r\nLe stage se situera dans le prolongement du travail déjà réalisé dans le\r\ncadre de ce projet, et consistera à développer les ressources\r\nlinguistiques nécessaires pour la reconnaissance des événements.\r\n\r\nPlus précisément, les événements sont reconnus en deux étapes:\r\n\r\n- la reconnaissance des entités nommées relatives aux événements (par\r\n  exemple, les noms des entreprises ou des personnes concernées etc.),\r\n  ainsi que des autres entités spécifiques typées associées aux\r\n  événements (par exemple, les montants, les produits financiers etc.)\r\n\r\n- l\'association des différentes entités relatives à un même événement\r\n  dans une structure commune de formulaire (ou template) associant\r\n  chaque entité retenue à un rôle dans l\'événement : par exemple, une\r\n  personne mentionnée est celle qui quitte un poste et une autre\r\n  personne est celle qui arrive dans le poste.\r\n\r\nLes méthodes pour la reconnaissance des entités nommées et des\r\névénements reposent sur l\'utilisation de patrons lexico-syntaxiques\r\ns\'appuyant sur les résultats d\'un outil d\'analyse linguistique des\r\ntextes.\r\nLe travail du stagiaire consistera à développer ce type de ressources\r\npour la reconnaissance des événements financiers, en s\'appuyant sur le\r\nsystème d\'analyse linguistique existant et sur les modèles de patrons\r\nexistants. Ce travail pourra également porter sur l\'amélioration\r\ngénérale du traitement linguistique (analyse morpho-syntaxique et\r\nsyntaxique), si la reconnaissance des événements est limitée par la\r\nqualité de l\'analyse existante.\r\n\r\nProfil\r\n\r\n- niveau Master M2 informatique ou linguistique, connaissances en\r\n  traitement automatique des langues\r\n\r\n- Maîtrise de l\'anglais, la connaissance de la langue arabe est un plus\r\n\r\nLe stage sera rémunéré et se déroulera au centre Nano-Innov du CEA, à\r\nPalaiseau.\r\n\r\nLes candidats intéressés par ce stage sont invités à prendre contact\r\navec Romaric Besançon (romaric.besancon@cea.fr) ou Nasredine Semmar\r\n(nasredine.semmar@cea.fr) en envoyant un CV et une lettre de motivation.'),
(111, '2012-01-16', 'CEA-LIST', 'Palaiseau', 'Choral est un système de résumé automatique mono-document par extraction\r\ndéveloppé au LVIC, industrialisé et mis à la disposition des 3000\r\nutilisateurs de l\'IRSN [1]. Choral repose largement sur l\'analyseur\r\nlinguistique multilingue du laboratoire, LIMA [2]. Actuellement, Choral\r\nse contente d\'extraire verbatim les phrases du document source qu\'il\r\njuge les plus pertinentes selon plusieurs critères (sens des mots les\r\nplus représentés dans le document, expressions exprimant le point de vue\r\nde l\'auteur, présence de syntagmes nominaux complexes, ...).\r\n\r\nLe but du stage sera d\'améliorer la lisibilité des textes produits de\r\ndeux manières:\r\n\r\n- en exploitant la résolution de coréférences dont LIMA est\r\n  capable. LIMA sait détecter les référents des pronoms: dans les\r\n  phrases \"Nathan va à la bibliothèque. Il va rendre ses livres.\", LIMA\r\n  sera capable de détecter que \"Il\" réfère à \"Nathan\". Or, actuellement,\r\n  Choral n\'exploite pas cette information, pouvant éventuellement\r\n  n\'extraire que la deuxième phrase, ce qui ne permet pas de savoir au\r\n  lecteur qui est le \"Il\" en question. Le stagiaire modifiera Choral\r\n  pour prendre en compte cette information déjà présente dans les\r\n  résultats de l\'analyse linguistique ;\r\n\r\n- en générant du texte permettant de synthétiser les idées principales\r\n  situées entre les phrases retenues pour l\'extraction. Cette partie\r\n  part de la constatation qu\'une phrase extraite peut perdre son intérêt\r\n  hors de son contexte, et ce même si les idées qu\'elle porte sont très\r\n  importantes pour le texte. Il s\'agira donc de réfléchir à des moyens\r\n  de regénérer ce qu\'il faudra pour rendre ce contexte intelligible. Ce\r\n  pourra être la génération de mots-clés, le repérage et l\'extraction\r\n  des définitions de ce dont il est question dans l\'extrait, etc.\r\n\r\nLe stage se déroulera de la manière suivante:\r\n\r\n- prise en main des outils et du code ;\r\n- implémentation de l\'exploitation des coréférences et évaluation ;\r\n- en parallèle, bibliographie orientée sur la deuxième partie\r\n  (génération...)  ;\r\n- proposition de solutions pour la deuxième partie ;\r\n- implémentation des propositions effectuées.\r\n\r\nLe stage se déroulera dans les nouveau locaux du LVIC situés à NanoInnov\r\nà Palaiseau (près de Polytechnique, Sup\'Optique, Thales et Danone).\r\n\r\nDurée du stage : 6 mois\r\nFormation souhaitée : Ingénieur/Master 2\r\n\r\nGael de Chalendar\r\nCEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus\r\n(Vision and Content Engineering Laboratory)\r\n\r\nCEA SACLAY - NANO INNOV\r\nBAT. 861\r\nPoint courier 173\r\n91191 GIF SUR YVETTE\r\n\r\nTél.:+33.1.69.08.01.50Fax:+33.1.69.08.01.15 \r\nEmail : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr'),
(112, '2012-01-16', 'CEA-LIST', 'Palaiseau', 'Stage Bac+5 : Alignement de mots à partir de corpus de textes parallèles\r\npour la construction et la mise à jour de dictionnaires multilingues\r\n\r\nLieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie\r\ndes Contenus (LVIC), 91 191 Gif sur Yvette\r\n\r\nSujet :\r\n\r\nLes dictionnaires bilingues constituent les principaux composants des\r\nsystèmes de traduction automatique et de recherche d\'information\r\ninterlingue. La masse de travail nécessaire pour créer manuellement les\r\ndictionnaires bilingues est importante. C\'est la raison pour laquelle\r\ndepuis quelques années de nombreuses approches de construction\r\nautomatique de ces dictionnaires ont été proposées.\r\n\r\nL\'objectif de ce stage sera, d\'une part, de constituer un corpus de\r\nréférence de textes parallèles multilingues, et d\'autre part, d\'évaluer\r\nles principaux composants du module de construction et de mise à jour de\r\ndictionnaires bilingues développé au Laboratoire Vision et Ingénierie\r\ndes Contenus du CEA LIST.\r\n\r\nCe stage comportera les étapes suivantes:\r\n\r\n- Appropriation des principaux composants du module de construction et\r\n  de mise à jour de dictionnaires bilingues.\r\n\r\n- Constitution d\'un corpus de référence composé de textes parallèles\r\n  multilingues.\r\n\r\n- Mise en place d\'outils d\'évaluation du module d\'alignement de mots\r\n  simples et complexes.\r\n\r\n- Spécification et implémentation d\'un module de nettoyage des\r\n  dictionnaires bilingues construits ou mis à jour automatiquement.\r\n\r\nProfil recherché :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du Traitement Automatique de\r\nla Langue (TAL).\r\n\r\nCompétences en informatique et en TAL\r\n\r\nProgrammation : C++, Perl ou équivalent\r\n\r\nLangues : Maîtrise de l\'anglais et du français, la connaissance de la\r\nlangue arabe est un plus\r\n\r\nContact  et envoi des candidatures :\r\n\r\nNasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr\r\n\r\nDurée : 4 à 6 mois\r\n\r\nNasredine SEMMAR\r\n\r\nCEA Saclay Nano-INNOV\r\nInstitut CARNOT CEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus (LVIC)\r\nPoint courrier n°173\r\n91 191 Gif sur Yvette CEDEX\r\nTel: +33 (0)1 69 08 01 46\r\nFax: +33 (0)1 69 08 01 15\r\nEmail: nasredine.semmar@cea.fr'),
(113, '2012-01-23', 'LIMSI', 'Orsay', 'Proposition de stage M2R (fouille de données et parole)\r\n\r\nContact : Sophie Rosset (rosset@limsi.fr)\r\n\r\nLieu : LIMSI - CNRS, bat 508, BP 133, 91403 Orsay Cedex, groupe\r\nTraitement du Langage Parlé\r\n\r\nTitre : Fouilles de données appliquées à des données audio : erreurs et\r\nentités nommées\r\n\r\nContexte \r\nCe stage de M2 s\'inscrit dans les domaines du Traitement Automatique des\r\nLangues (TAL) et de la Parole (TAP) ainsi que celui de la fouille de\r\ndonnées. Nous nous intéressons plus particulièrement à la\r\ncaractérisation des erreurs d\'un système de transcription de la parole\r\ndont les sorties sont utilisées par un système de reconnaissance\r\nd\'Entités Nommées. Il s\'agit de mettre en place une méthode permettant\r\nde classifier et de caractériser les erreurs de plusieurs systèmes de\r\ntranscription de la parole en quantifiant leur impact sur un (ou\r\nplusieurs) systèmes de reconnaissance d\'Entités Nommées. Cette méthode\r\ndevra être généralisable à d\'autres types d\'applications comme la\r\ntraduction automatique ou un système de dialogue homme/machine.\r\n\r\nSujet\r\n\r\nLes systèmes de reconnaissance de la parole sont évalués en utilisant le\r\ntaux d\'erreurs de mots (WER ou Word Error Rate) qui considère chaque mot\r\ncomme ayant une importance égale. Or on constate que cette métrique\r\nd\'évaluation ne permet de mesurer la difficulté qu\'aura un système\r\nd\'extractions d\'information. Autrement dit, si on applique un même\r\nsystème de détection d\'entités nommées sur deux sorties de système de\r\nreconnaissance ayant pourtant un même WER, le taux d\'erreur du système\r\nde détection d\'entités nommées sera différent.\r\n\r\nL\'objectif de ce stage est donc de caractériser les erreurs d\'un système\r\nde reconnaissance de la parole en fonction d\'une tâche de détection\r\nd\'entités nommées et de l\'impact qu\'ont ces erreurs.\r\n\r\nNous nous focaliserons au cours de ce stage sur la parole journalistique\r\nen utilisant les données d\'une campagne d\'évaluation récente. Cette\r\ncampagne a mis en évidence une très grosse perte de résultats des\r\nsystèmes de reconnaissance d\'entités nommées sur des sorties de système\r\nde reconnaissance automatique de la parole (30% de perte) [1].\r\n\r\nLes sorties de trois systèmes de transcription seront étudiées. Leur\r\nimpact devra être étudié sur au moins un système d\'identification\r\nd\'Entités Nommées également fourni par le LIMSI. Ces systèmes sont à\r\nl\'état de l\'art et pourront donc servir de première référence.\r\n\r\n[1] Olivier Galibert; Sophie Rosset; Cyril Grouin; Pierre Zweigenbaum;\r\nLudovic Quintard. Structured and Extended Named Entity Evaluation in\r\nAutomatic Speech Transcriptions. IJCNLP 2011\r\n(http://aclweb.org/anthology-new/I/I11/I11-1058.pdf)\r\n\r\nInformations pratiques\r\n\r\nLe stage, d\'une durée de 5 mois, se déroulera au LIMSI, dans le groupe\r\nTraitement du Langage Parlé et le stagiaire recevra une gratification\r\n(de l\'ordre de 480 euros/mois).'),
(114, '2012-01-25', 'IMS', 'Puteaux', 'Stage rémunéré de traitement automatique de langage naturel (TAL)\r\n\r\n1. Cadre général\r\n\r\nIMS Health est un partenaire privilégié des plus grands laboratoires\r\npharmaceutiques mondiaux et une entreprise de référence en matière de\r\ntraitement de données de santé/médicament.\r\n\r\nLes bases de données des dossiers patients constituent une des forces\r\nincontournables d\'IMS. En France, la base Disease Analyzer (TM) contient\r\nplus de 5 millions de patients dont certains suivis depuis l\'an\r\n2000. Cette base comporte des informations provenant du dossier\r\npatient des médecins membre d\'un panel représentatif et comprend les\r\ndiagnostics, les traitements et les caractéristiques des patients. Une\r\npartie des informations est saisie sous forme de texte libre. Cette\r\npartie pourrait contenir des informations d\'une grande valeur sur les\r\nrésultats d\'examens biologiques, orientations diagnostiques, consignes\r\nde traitement ou encore des données sur l\'observance\r\nthérapeutique. IMS souhaite mettre en place un outil de traitement de\r\nlangage naturel (TAL) permettant le codage et la structuration de ses\r\ndonnées en commençant par les résultats d\'examens de laboratoire.\r\n\r\n2. Contenu du stage\r\n\r\nLes données sont hébergées chez IMS et dans une base SQL\r\nServer. L\'objectif est d\'examiner un corps de textes courts (quelques\r\nmots à quelques phrases) saisi par les médecins dans les dossiers\r\npatients afin détecter, codifier et structurer les informations\r\npertinentes: \r\n\r\nDans un premier temps on cherche à examiner chaque corps de texte dans\r\nle contexte du dossier patient pour comprendre son orientation globale\r\net pour le classifier selon son thème : examen clinique, imagerie,\r\ndonnées d\'observance, décision thérapeutique, justification\r\ndiagnostique, etc.\r\n\r\nDans un deuxième un travail exploratoire sera réalisé autour\r\nd\'architectures pour le Traitement Automatique de la Langue (UIMA,\r\nGATE, OpenNLP) et en fonction de leur intérêt pour structurer ces\r\ndonnées.\r\n\r\nDans un troisième temps, le stagiaire développera un programme\r\ninformatique (en Java) permettant de structurer et codifier au mieux\r\nl\'information pour une des catégories (examens laboratoire).\r\n\r\n3. Profil\r\n\r\n- Etudiant en informatique avec notamment des connaissances en bases\r\n  de données\r\n\r\n- Forte motivation, rigueur et esprit d\'équipe\r\n\r\n- Connaissance du langage médical ou une expérience précédente de TAL\r\n  sera un plus.\r\n\r\n4. Localisation et encadrement\r\n\r\nLe stagiaire sera encadré par IMS et sera en contact avec un\r\nlaboratoire d\'informatique médicale (LIM&BIO). D\'une durée de 6 mois,\r\nil se déroulera dans les locaux d\'IMS (Puteaux, 92). En fonction des\r\nbesoins, des déplacements au laboratoire seront possibles.\r\n\r\n5-Rémunération\r\n\r\nSelon le profil, pouvant aller jusqu\'à 1000 euros par mois.\r\n\r\n6-Contact\r\n\r\nDr Massoud TOUSSI, MD, PhD\r\nMedical Director, Health Economics & Outcomes Research\r\nIMS Consulting Group\r\n91, rue Jean Jaurès\r\n92800 PUTEAUX\r\nFrance\r\nTel: +33 (0)1-41 35 13 35\r\nFax: +33 (0)1-41 35 13 49\r\nemail: mtoussi@imscg.com\r\nhttp://www.imsconsultinggroup.com');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(115, '2012-02-01', 'ALPAGE', 'Paris', '======================================== \r\nStage Bac+5 : Analyse textuelle de scripts de films pour améliorer le\r\nrepérage d\'actions dans les vidéos de ces films\r\n=========================================\r\n\r\n=========================================\r\nEquipes, projet et lieu du stage :\r\n=========================================\r\nEquipes : ALPAGE (UMR-I Univ Paris Diderot/INRIA\r\n          et WILLOW (UMR CNRS/ENS/INRIA)\r\n\r\nLe stage sera déroulera en cotutelle par ALPAGE et WILLOW, dans le cadre\r\ndu projet ERC VideoWorld :\r\n\"Modeling, interpreting and manipulating digital video\"\r\n\r\nLieu : Le stagiaire sera basé à Alpage :\r\n       175 rue du chevaleret 75013 Paris\r\n\r\n=========================================\r\nSujet :\r\n=========================================\r\nUn nombre énorme de vidéos est aujourd\'hui disponible, en particulier\r\nsur Internet, qu\'il s\'agisse de vidéos informatives, éducatives, de\r\ndivertissement ou autres. Ce nombre va croissant, et de ce fait l\'accès\r\nintelligent à leur contenu devient un enjeu majeur.\r\n\r\nUn scénario de recherche au sein de vidéos peut par exemple se modéliser\r\ncomme la recherche de certaines situations ou actions précises (faire du\r\ncheval, sortir d\'un véhicule, prendre un repas ...). Pour automatiser\r\ncette tâche par des techniques d\'apprentissage supervisé, un problème\r\nimportant est le fait qu\'il est très fastidieux de construire des\r\nexemples d\'apprentissage où les séquences de vidéos sont couplées à des\r\nactions précises. Une solution à ce problème est de construire\r\nautomatiquement des exemples d\'apprentissage en utilisant, lorsqu\'ils\r\nexistent, les textes associés aux vidéos. Ces textes sont en particulier\r\ndisponibles pour un grand nombre de films, sous la forme de scripts de\r\nscenario.\r\n\r\nL\'objet du stage est de construire un système intégré d\'analyse de\r\nscripts (anglais) de films, en vue de permettre la classification\r\nautomatique de descriptions de scènes de films en actions, parmi un\r\nensemble prédéfini d\'actions. Il s\'agira de de coupler l\'utilisation et\r\nl\'adaptation de modules de traitement existants (reconnaissance\r\nd\'entités nommées, résolution d\'anaphores, tagging, parsing) à des\r\nmodules spécifiques. Deux points (de recherche) attireront notre\r\nattention : d\'une part l\'utilisation du cadre FrameNet pour le repérage\r\ndes actions, d\'autre part les informations de factivité (cadre FactBank)\r\npour savoir si une action s\'est effectivement produite.\r\n\r\nPar exemple pour la description de scène suivante issue d\'un script :\r\n\r\n\" The servants move Chang\'s chair back. Before he goes, however, he\r\nturns to Conway and smiles at him. \"\r\n\r\nIl s\'agit de repérer les personnages \"the servants\", Chang, Conway;\r\nrésoudre les références de \"he\" et \"him\"; repérer les actions \"move\r\nchair\", \"turn\", \"smile\" et leurs actants; et idéalement repérer que la\r\nmention de l\'action de partir (to go) n\'est pas réalisée ou pas encore\r\nréalisée.\r\n\r\n=========================================\r\nProfil recherché :\r\n=========================================\r\nEtudiant de niveau BAC +5, avec des connaissances en Traitement\r\nAutomatique des Langues et en apprentissage automatique.\r\nUne autonomie en programmation est indispensable, ainsi qu\'une bonne\r\nmaîtrise de l\'anglais (langue des textes à traiter).\r\nDes connaissances en linguistique seraient un plus apprécié.\r\n\r\n=========================================\r\nDurée : 6 mois\r\n=========================================\r\nRémunération : selon profil\r\n=========================================\r\n\r\nEnvoyez CV et lettre de motivation à :\r\ncontact : marie.candito@gmail.com'),
(116, '2012-02-01', 'LIMSI', 'Orsay', 'Offre de stage de Master 1 à Orsay (91), au LIMSI.\r\nhttp://www.limsi.fr/~xtannier/fr/Stages/sujet_2012_M1_phrase_saillante.html\r\n\r\n\r\n  Sélection automatique de passage représentatif d\'un événement\r\n\r\n\r\n      Mots-clés\r\n\r\n/traitement automatique de la langue, analyse temporelle, événements/\r\n\r\n\r\n    Contexte\r\n\r\nEntre autres objectifs, le projet ANR ChronoLines a pour but de créer de\r\nfaçon semi-automatique des chronologies à partir de dépêches d\'agences.\r\nÉtant donnés un thème fourni par l\'utilisateur et un ensemble de textes,\r\nil s\'agit de retrouver dans les documents les événements les plus\r\nimportants concernant ce thème, puis de les ordonner et de les présenter\r\nà l\'utilisateur pour validation. Par exemple, pour une demande sur un\r\nnom de personne, le système devra retracer les événements marquants de\r\nsa vie. Pour les négociations de paix au Moyen-Orient, les principales\r\ndates importantes s\'y rattachant.\r\n\r\nParmi les étapes nécessaires pour atteindre ce résultat, une phase\r\nconsiste à sélectionner, parmi les événements détectés, ceux qui\r\nsemblent les plus marquants, ou les plus centraux, par rapport au thème\r\nde la requête. Pour chacun de ces événements, il faut ensuite choisir un\r\ntexte caractéristique, expliquant de façon claire et concise de quoi il\r\ns\'agit. Ce passage de texte est à choisir parmi un ensemble de\r\nnombreuses phrases décrivant l\'événement.\r\n\r\n\r\n    Travail à réaliser :\r\n\r\nDurant ce stage, on partira d\'un système existant. Ce système\r\nsélectionne les phrases qui correspondent, de façon plus ou moins\r\nprécise, à chaque événement à insérer dans la chronologie. L\'objectif du\r\nstage est de :\r\n\r\n  * Parcourir la littérature scientifique sur le sujet (sélection de\r\n    texte, résumé automatique, agrégation de résultats, etc.) pour\r\n    identifier les techniques existantes susceptibles d\'être adapter à\r\n    notre problème.\r\n  * Réaliser un outil permettant de choisir (ou éventuellement de\r\n    générer) une phrase explicative d\'un événement, à partir d\'un\r\n    ensemble de courts textes à son sujet.\r\n\r\nLe stagiaire devra avoir de bonnes compétences en informatique et un \r\nintérêt pour les problématiques du traitement de la langue.\r\n\r\n*Durée* : environ 2 mois\r\n*Niveau* : Master 1\r\n\r\n\r\n      Contacts :\r\n\r\nVeronique.Moriceau[at]limsi.fr\r\nXavier.Tannier[at]limsi.fr'),
(117, '2012-02-07', 'CEA-LIST', 'Gif-sur-Yvette', 'Stage Bac+5 : Utilisation d\'un moteur de recherche interlingue et d\'un\r\nmodèle statistique pour la langue cible en traduction automatique\r\n\r\nLieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie\r\ndes Contenus (LVIC), 91191 Gif sur Yvette\r\n\r\nSujet :\r\n\r\nIl existe principalement deux types d\'approches pour la traduction\r\nautomatique: celles à base de règles et celles s\'appuyant sur des\r\ncorpus. La combinaison de ces approches a permis le développement de\r\nsolutions hybrides. Les approches à base de règles utilisent des\r\nressources linguistiques monolingues et bilingues coûteuses car\r\ngénéralement construites à la main. Les approches à base de corpus\r\nutilisent des méthodes statistiques appliquées sur des textes parallèles\r\npour apprendre les modèles de traduction et de langue. Ces approches\r\nnécessitent de gros volumes de corpus parallèles qui n\'existent pas pour\r\ntoutes les langues.\r\n\r\nLe stage s\'appuiera sur le prototype de traduction automatique développé\r\nau CEA-LIST dans le cadre du projet ANR WebCrossling. Ce prototype\r\nutilise une nouvelle approche fondée sur un moteur de recherche\r\ninterlingue et un modèle statistique de la langue cible. Cette approche\r\nconsiste à générer une base de données textuelle composée de la totalité\r\ndes phrases issues des textes accessibles sur le web dans la langue\r\ncible et considérer la phrase à traduire comme une requête au moteur de\r\nrecherche interlingue.\r\n\r\nL\'objectif du stage consiste, d\'une part, à constituer un corpus de\r\nréférence en langue arabe (langue cible) pour la génération du modèle de\r\nlangue, et d\'autre part, à adapter ce prototype de traduction au couple\r\nde langues anglais-arabe et à évaluer ses résultats de traduction par\r\nrapport à Moses, un outil de traduction statistique sous licence libre.\r\n\r\nCe stage comportera les étapes suivantes:\r\n\r\n- Appropriation des moteurs de traduction WebCrossling et Moses.\r\n\r\n- Intégration du lexique bilingue anglais-arabe construit à l\'aide\r\n  d\'outils d\'alignement de mots du CEA-LIST dans les moteurs de\r\n  traduction WebCrossling et Moses.\r\n\r\n- Mise en place d\'outils d\'évaluation des moteurs de traduction\r\n  WebCrossling et Moses.\r\n\r\n- Développement d\'une interface graphique pour le moteur de traduction\r\n  WebCrossling destinée aux traducteurs professionnels.\r\n\r\nProfil recherché :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du Traitement Automatique de\r\nla Langue (TAL)\r\n\r\nCompétences en informatique et en TAL\r\n\r\nProgrammation : C++, Perl ou équivalent\r\n\r\nLangues : Maîtrise de l\'anglais et du français, la connaissance de la\r\nlangue arabe est un plus\r\n\r\nContact  et envoi des candidatures :\r\n\r\nNasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr\r\n\r\nDurée : environ 6 mois\r\n\r\nNasredine SEMMAR\r\nCEA Saclay Nano-INNOV\r\nInstitut CARNOT CEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus (LVIC)\r\nPoint courrier n°173\r\n91 191 Gif sur Yvette CEDEX\r\nTel: +33 (0)1 69 08 01 46\r\nFax: +33 (0)1 69 08 01 15\r\nEmail: nasredine.semmar@cea.fr'),
(118, '2012-02-08', 'Reverso-Softissimo', 'Neuilly', 'tage linguiste / terminologue / traducteur\r\n\r\nType de contrat : Stage de césure ou de fin d\'études (minimum 4 mois)\r\n\r\nLieu : Neuilly-sur-Seine\r\n\r\nIndemnité de stage : Selon durée et expérience\r\n\r\nDébut : Dès que possible\r\n\r\nAvantages : Tickets restaurant et 50% transport\r\n\r\nENTREPRISE\r\n\r\nEditeur de logiciels à rayonnement international, Reverso-Softissimo est\r\nl\'un des leaders mondiaux des solutions Intranet et Internet de\r\ntraduction instantanée et de dictionnaires électroniques.\r\n\r\nSon portail grand public dédié aux langues www.reverso.net génère un\r\ntrès fort trafic avec 200 millions de pages vues par mois et plus de 6\r\nmillions de visiteurs uniques.\r\n\r\nReverso-Softissimo recherche un(e) linguiste pour participer aux travaux\r\nde production et de recherche de notre équipe linguistique dans un\r\ncontexte professionnel motivant : haute technologie, forte croissance et\r\ndéveloppement international.\r\n\r\nVous êtes intéressé(e) par notre domaine ? C\'est le moment de rejoindre\r\nnotre équipe !\r\n\r\nMISSION\r\n\r\nSous la direction du chef de projet linguistique, le stagiaire\r\neffectuera les missions suivantes :\r\n\r\n- création, mise à jour, validation de dictionnaires bilingues ;\r\n- tests de la qualité de traduction et rédaction de rapports d\'analyse ;\r\n- recherche, évaluation et analyse de ressources terminologiques ;\r\n- animation et développement de la communauté d\'utilisateurs du\r\n  dictionnaire collaboratif.\r\n\r\nCette liste n\'est pas exhaustive et pourra être amenée à évoluer en\r\nfonction de l\'implication du/de la stagiaire.\r\n\r\nPROFIL\r\n\r\nÉtudiant(e) en dernière année d\'une école ou d\'une université en TAL,\r\nlangues étrangères, linguistique, ingénierie linguistique ou traduction,\r\nvous maîtrisez parfaitement l\'anglais et le français à l\'oral comme à\r\nl\'écrit, et idéalement une troisième langue.\r\n\r\nVous avez des qualités rédactionnelles ainsi qu\'une grande rigueur, une\r\nbonne méthodologie, un esprit logique et des capacités d\'analyse et de\r\nsynthèse ; votre sens de l\'initiative, votre dynamisme et votre\r\nautonomie seront également des qualités appréciées dans le cadre de ce\r\nstage.\r\n\r\nContact :\r\nJuliette MORNET\r\n01.41.43.10.31\r\njmornet@reverso.com'),
(119, '2012-02-08', 'I3S', 'Nice', 'Bonjour,\r\n\r\nL\'équipe KEIA (Knowledge Extraction, Integration & Algorithms) du\r\nlaboratoire I3S de l\'Université de Nice Sophia-Antipolis, propose deux\r\nstages de Master 2 recherche, financés (4200 euros pour 6 mois de\r\nstage), dans le domaine de fouille de données appliquée au texte. Voir\r\nfichiers attachés pour plus de détails.\r\n\r\nCordialement,\r\n\r\nCélia Pereira.\r\n\r\n------------------------------------------------------------------------\r\n\r\nTitre : techniques d\'apprentissage pour le regroupement de messages courts\r\n\r\nContexte du travail :\r\n\r\nGrâce aux nouvelles technologies, les messages courts sont devenus\r\nomniprésents dans notre société. Ils prennent la forme de SMS sur\r\ntéléphones mobiles, de micro-blogs comme Twitter, de commentaires dans\r\nles réseaux sociaux comme Facebook ou Google+ etc. Leur particularité\r\nconsiste en une brièveté imposée à la fois par le médium et une volonté\r\nd\'échanger l\'information brute et instantanée. Ces messages représentent\r\nune richesse, en termes de quantité d\'information, qui pourrait être\r\nutilisée pour analyser un climat politique, prédire des crises ou\r\ncorriger les défauts d\'un produit. En particulier, ils sont devenus un\r\nnouvel outil de communication directe entre un vendeur et ses acheteurs,\r\nentre les politiques et le peuple, entre les dirigeants d\'entreprise et\r\nleurs salariés. Le nombre de messages, la vitesse à laquelle ils sont\r\nproduits et leur nature spontanée nécessitent de nouveaux moyens\r\nd\'analyse pour en faire ressortir des tendances globales utiles.\r\n\r\nCe stage s\'insère dans le contexte d\'une collaboration avec l\'entreprise\r\nSucceed Together® (Semantic Grouping Company), qui est la propriétaire\r\nde l\'outil \"Meeting Software®\". Ce dernier a été conçu pour améliorer la\r\nperformance des réunions professionnelles :\r\n\r\n- quelque soit le nombre de participants ;\r\n- quelque soit la langue utilisée ;\r\n- quelque soit le nombre de sites impactés.\r\n\r\nLe but principal de ce stage est d\'améliorer les performances de cet\r\noutil afin que son utilisation permette de regrouper de façon optimale\r\nles messages ayant le même sens. Dans sa version actuelle, le résultat\r\ndu regroupement peut éventuellement \"subir\" l\'intervention d\'un pilote,\r\npersonne experte dans le domaine considéré, afin d\'améliorer\r\nultérieurement les regroupements obtenus.  Plus précisément, le travail\r\ndemandé est de fournir les moyens pour optimiser les interventions du\r\npilote en :\r\n\r\n- trouvant les associations [6] entre les regroupements obtenus\r\n  automatiquement et les interventions humaines --- dans quelles\r\n  situations le pilote est-t-il intervenu ?\r\n\r\n- proposant ou en adaptant un algorithme d\'apprentissage [3,4,5] qui\r\n  pourra :\r\n\r\n- apprendre les interventions du pilote ;\r\n\r\n- être en mesure de donner automatiquement des «conseils» à chaque fois\r\n  qu\'une une situation similaire se représente ;\r\n\r\n- apprendre des profils d\'utilisation [1] en construisant des modèles\r\n  des interventions du pilote dans des domaines spécifiques ;\r\n\r\n- sélectionner les caractéristiques pertinentes des textes courts à\r\n  prendre en compte afin d\'optimiser les résultats du regroupement.\r\n\r\nL\'algorithme de regroupement amélioré pourra alors soit s\'auto-corriger\r\nsans le besoin de l\'intervention humaine, soit requérir une intervention\r\ndu pilote mais en la ciblant sur le cas bloquant uniquement.\r\n\r\nPré-requis : très bonnes capacités de programmation.\r\n\r\nType : Recherche\r\n\r\nGratification : 4200 euros pour 6 mois de stage\r\n\r\nBibliographie\r\n\r\n1. Célia da Costa Pereira and Andrea Tettamanzi. An Ontology-Based\r\nMethod for User Model Acquisition. In Zongmin Ma, editor, Soft-Computing\r\nin Ontologies and Semantic Web, vol. 204, 2006, ISBN 3-540-33472-6.\r\n\r\n2. Christiane Fellbaum (ed.). WordNet. An Electronic Lexical\r\nDatabase. The MIT Press, Cambridge, MA, 1998.\r\n\r\n3. Thomas Mitchell. Machine Learning. Editeur : McGraw Hill, 1997, ISBN\r\n: 0070428077.\r\n\r\n4. Vojislav Kecman. \"Learning and Soft Computing - Support Vector\r\nMachines, Neural Networks, Fuzzy Logic Systems\". The MIT Press,\r\nCambridge, MA, 2001.\r\n\r\n5. Kenneth A. De Jong. Evolutionary Computation : A Unified\r\nApproach. The MIT Press, Cambridge, MA, 2006.\r\n\r\n6. Jiawei Han, Hong Cheng, Dong Xi and Xifeng Yan. Frequent pattern mining:\r\ncurrent status and future directions. Data Min Knowl Disc (2007) 15:55-86.\r\n\r\nLieu du stage : Laboratoire I3S\r\n\r\nContact : Célia da Costa Pereira, équipe KEIA du labratoire I3S\r\nE-Mail : celia.pereira@unice.fr\r\n\r\n------------------------------------------------------------------------\r\n\r\nTitre : techniques de fouille de données pour le regroupement de\r\nmessages courts\r\n\r\nContexte du travail :\r\n\r\nGrâce aux nouvelles technologies, les messages courts sont devenus\r\nomniprésents dans notre société. Ils prennent la forme de SMS sur\r\ntéléphones mobiles, de micro-blogs comme Twitter, de commentaires dans\r\nles réseaux sociaux comme Facebook ou Google+ etc. Leur particularité\r\nconsiste en une brièveté imposée à la fois par le médium et une volonté\r\nd\'échanger l\'information brute et instantanée. Ces messages représentent\r\nune richesse, en termes de quantité d\'information, qui pourrait être\r\nutilisée pour analyser un climat politique, prédire des crises ou\r\ncorriger les défauts d\'un produit. En particulier, ils sont devenus un\r\nnouvel outil de communication directe entre un vendeur et ses acheteurs,\r\nentre les politiques et le peuple, entre les dirigeants d\'entreprise et\r\nleurs salariés. Le nombre de messages, la vitesse à laquelle ils sont\r\nproduits et leur nature spontanée nécessitent de nouveaux moyens\r\nd\'analyse pour en faire ressortir des tendances globales utiles.\r\n\r\nCe stage s\'insère dans le contexte d\'une collaboration avec l\'entreprise\r\nSucceed Together® (Semantic Grouping Company), qui est la propriétaire\r\nde l\'outil \"Meeting Software®\". cet outil a été conçu pour améliorer la\r\nperformance des réunions professionnelles :\r\n\r\n- quelque soit le nombre de participants ;\r\n- quelque soit la langue utilisée ;\r\n- quelque soit le nombre de sites impactés.\r\n\r\nLe but principal de ce stage est d\'améliorer les performances de cet\r\noutil afin que son utilisation permette de regrouper de façon optimale\r\nles messages ayant le même sens.\r\n\r\nDans sa version actuelle, le résultat du regroupement peut\r\néventuellement \"subir\" l\'intervention d\'un pilote, personne experte dans\r\nle domaine considéré, afin d\'améliorer ultérieurement les futurs\r\nregroupements obtenus. Plus précisément, le travail demandé est\r\nd\'explorer les méthodes de regroupement existantes [3], comme par\r\nexemple les méthodes itératives basées sur les distances, les méthodes\r\nhiérarchiques, les méthodes basées sur la densité, les méthodes basées\r\nsur les modèles et les méthodes de \"Boosting\" des règles d\'associations\r\nde texte et Structural (latent) SVM [4], en les appliquant aux données\r\ncorrespondant aux messages courts. Pour être en mesure d\'appliquer ces\r\ntechniques, il faudra auparavant disposer d\'une représentation\r\nappropriée des textes courts. Parmi les représentations qui pourront\r\nêtre utilisées, nous nous intéresserons aux représentations sémantiques\r\ntelle que celle utilisée en [1] qui s\'appuie sur la base de données\r\nlexicale WordNet [2], ou d\'autres basées sur l\'extraction des\r\ncaractéristiques du texte. Dans ce contexte, le stagiaire pourra\r\nbénéficier de la collaboration en cours avec d\'autres équipes\r\nparticipant au projet.\r\n\r\nPré-requis : très bonnes capacités de programmation.\r\n\r\nType : Recherche\r\n\r\nGratification : 4200 euros pour 6 mois de stage\r\n\r\nBibliographie\r\n\r\n1. C. da Costa Pereira and A. Tettamanzi. An Ontology-Based Method for\r\nUser Model Acquisition. In Zongmin Ma, editor, Soft-Computing in\r\nOntologies and Semantic Web, vol. 204, 2006, ISBN 3-540-33472-6.\r\n\r\n2. Christiane Fellbaum (ed.). WordNet. An Electronic Lexical\r\nDatabase. The MIT Press, Cambridge, MA, 1998.\r\n\r\n3. Jawei Han and Micheline Kamber. Data Mining: Concepts and Techniques.\r\nMorgan Kaufmann Publishers Inc. San Francisco, CA, USA. ISBN:\r\n1558609016.\r\n\r\n4. Yongwook Yoon and Gary G. Lee. Text Categorization Based on Boosting\r\nAssociation Rules. Proceedings of the 2008 IEEE International Conference\r\non Semantic Computing, pages = {136--143}, 2008, IEEE Computer Society.\r\n\r\nLieu du stage : Laboratoire I3S\r\nContact : Célia da Costa Pereira, équipe KEIA du labratoire I3S\r\nE-Mail : celia.pereira@unice.fr'),
(120, '2012-02-13', 'Tendances Institut', 'Paris', '*Offre de stage*\r\n\r\n*Tendances Institut* est un cabinet de conseil spécialisé dans l\'analyse\r\nde l\'évolution des opinions et des valeurs des différents publics pour\r\nune gestion globale de la réputation de ses clients.\r\n\r\n*Un objectif*: Permettre aux hommes, aux entreprises et aux institutions\r\nd\'atteindre leurs publics par la maîtrise de leur environnement sociétal\r\nen anticipant l\'attitude et le comportement des leaders d\'opinion.\r\n\r\n*Une triple expertise*:\r\n\r\n  * Réputation : veiller les éléments non maîtrisés (buzz, rumeurs,\r\n    campagnes hostiles) et évaluer les éléments maîtrisés (efficacité\r\n    d\'une prise de parole institutionnelle et de sa diffusion dans\r\n    l\'opinion) qui concourent à l\'image d\'une entité publique ou privée.\r\n\r\n  * Influence : déployer une économie du buzz sur la base de dispositifs\r\n    souples et ad hoc qui diffusent l\'information là où elle sera\r\n    entendue et relayée.\r\n\r\n  * Identification des microleaders d\'opinion : s\'appuyer sur une\r\n    communauté d\'internautes prescripteurs/diffuseurs d\'information sur\r\n    les blogs et les réseaux sociaux.\r\n\r\n*Description de la mission* :\r\n\r\nDans le cadre de notre développement, nous recherchons un stagiaire\r\npouvant nous aider à développer des solutions de recherche, de\r\ntraitement automatisée de l\'information sur internet (extraction\r\ntextuelle à partir des réseaux sociaux, blogs, sites d\'information et\r\nautres) et d\'annotation de ses contenus par apprentissage automatique.\r\n\r\n*Compétences requises* :\r\n\r\n  * Vous suivez un cursus d\'ingénierie de la langue et souhaitez\r\n    travailler à la mise en place d\'un outil d\'annotation automatisé\r\n    d\'un corpus de textes venant du web.\r\n\r\n  * Vous savez mettre en place des outils d\'extraction et d\'analyse\r\n    automatisée de données textuelles.\r\n\r\n  * Vous maitrisez différentes technologies Web (PHP/MySql, HTML, CSS,\r\n    JavaScript, Ajax, XML....).\r\n\r\n  * Vous êtes familiarisé avec un ou plusieurs langages de programmation\r\n    (Perl, Python, Java).\r\n\r\n  * Plus généralement, vous avez un goût prononcé pour le web social et\r\n    son exploration automatisée.\r\n\r\n*Profil* :\r\n\r\nDe formation bac +4 ou 5 informatique appliquée à la linguistique, vous\r\nêtes passionné(e) de NTIC. Créatif, vous souhaitez développer de\r\nnouvelles applications au sein d\'une entreprise.\r\n\r\nEventuellement intéressé par la recherche appliquée, vous souhaitez dans\r\nle futur poursuivre vos études dans le cadre d\'un contrat Cifre.\r\n\r\n*Durée du stage* : 6 mois\r\n\r\n*Rémunération* : 435EUR/mois\r\n\r\n*Contact* : Aurélien Miklas -- _amiklas@societale.com -- 06.63.03.08.32'),
(121, '2012-02-13', 'Laboratoire d\'Informatique de Tours', 'Blois', 'Extraction des informations encyclopédiques pour la recherche\r\nd\'information\r\n\r\nPROBLEMATIQUE\r\n\r\nLe Laboratoire LI (Laboratoire d\'Informatique de l\'Université de Tours)\r\npropose un sujet de stage dans le cadre de l\'enrichissement de nos\r\nressources pour nos systèmes de reconnaissance d\'entités nommées.\r\n\r\nLa reconnaissance d\'entités nommées consiste à repérer automatiquement\r\ndans des textes des unités linguistiques (noms de personnes / sociétés /\r\norganisations, lieux, montants, dates, etc.) qui peuvent être utiles à\r\nla recherche d\'informations, à l\'extraction d\'informations pour\r\nl\'utilisateur ou pour des traitements ultérieurs. Nos systèmes reposent\r\nsur l\'utilisation des technologies suivantes :\r\n\r\n- règles symboliques de reconnaissance (transducteurs),\r\n- fouille de données et apprentissage automatique,\r\n- hybridation des deux précédents.\r\n\r\nLes résultats obtenus par ces systèmes, dépendent à la fois des\r\nalgorithmes qu\'ils mettent en ½uvre et des ressources qu\'ils\r\nutilisent. Il est donc essentiel d\'être en mesure d\'enrichir et de\r\nmettre à jour nos ressources de manière aussi automatisée que possible.\r\n\r\nNous nous appuyons notamment sur des lexiques qui listent des noms\r\npropres (personnes, lieux, organisations, etc.). L\'apparition\r\nd\'encyclopédies structurées à large couverture (par ex. Wikipedia) et\r\nleur mise à disposition permet d\'extraire automatiquement ces données\r\nafin de mettre à jour nos lexiques.\r\n\r\nLe stage que nous proposons porte sur l\'automatisation de tels\r\ntraitements : navigation dans les structures des encyclopédies,\r\nsélection et extraction des catégories et entités pertinentes,\r\nintégration dans des lexiques, évaluation de l\'impact sur les\r\nperformances de nos systèmes. Les encyclopédies mettent souvent en place\r\ndes facilités pour les récupérer et les interroger (par exemple les\r\ndumps Wikipedia : http://dumps.wikimedia.org/backup-index.html ). Il\r\nfaut cependant veiller à la pertinence des informations extraites.\r\n\r\nMISSION\r\n\r\nLa personne recrutée sera chargée de la conception et des développements\r\nlogiciels, en deux phases :\r\n\r\n- phase 1 (étude de faisabilité et spécifications) : sélectionner les\r\nencyclopédies et les outils appropriés pour leur interrogation, il\r\ns\'agit de voir comment il sera possible d\'automatiser l\'extraction\r\nd\'entités selon les encyclopédies,\r\n\r\n- phase 2 (conception, prototypage et implémentation) : conception et\r\nimplémentation d\'un prototype modulaire et paramétrable d\'extraction,\r\ntests, évaluation et étude de l\'impact sur les performances de nos\r\nsystèmes, validation.\r\n\r\nPROFIL RECHERCHE\r\n\r\nFormation informatique, de bon niveau académique, compétences en\r\nprogrammation (Java, Python, C++), manipulation de base de données et\r\nXML.  A l\'aise sur toutes plateformes (Windows / Linux).\r\n\r\nCONDITIONS\r\n\r\nDates et durée : dès que possible, pour 3 mois\r\nLieu d\'exercice : Blois, antenne universitaire, laboratoire LI, équipe BDTLN\r\nRémunération : 436,05 ¤ par mois (prévue par la règlementation),\r\nPossibilité d\'extension en CDD d\'un / deux mois, selon le travail\r\nréalisé et les perspectives\r\n\r\nDEPOT DE CANDIDATURES\r\n\r\nContact : nathalie.friburger@univ-tours.fr , Jean-Yves.Antoine@univ-tours.fr,\r\ndamien.nouvel@univ-tours.fr\r\nProcédure : Merci d\'envoyer un CV mentionnant votre formation, vos\r\ncompétences, vos activités passées'),
(122, '2012-02-13', 'CNES', 'Toulouse', 'Développement d\'une base de connaissances à partir de textes.\r\n\r\nDans le cadre de sa mission de capitalisation et de valorisation des\r\nressources informationnelles du CNES, le service Gestion de\r\nl\'Information et de la connaissance, propose de participer au\r\ndéveloppement de méthodes d\'enrichissement de l\'ontologie utilisée pour\r\nle classement et la recherche des documents de la mémoire d\'entreprise\r\ndu CNES. La mise en ½uvre s\'appuiera d\'une part sur une plateforme\r\ndédiée intégrant un moteur de recherche sémantique, d\'une catégorisation\r\nautomatique et des fonctions complémentaire et d\'autre part, sur des\r\noutils d\'analyse statistique et d\'extraction terminologique.\r\n\r\nDurée (mois) : 6 mois\r\nDate de début : pas de contrainte\r\nCe stage vise a priori un étudiant en master 2 spécialité\r\nlinguistique (compétence en linguistique de corpus souhaitée)\r\n\r\nLe stage se déroulera à Toulouse au Centre Spatial de Toulouse\r\n(CST-CNES) et sera bien sûr rémunéré.\r\n\r\nOn pourra retrouver sa référence sur le site du CNES\r\n(http://www.cnes.fr/web/CNES-fr/175-stages-2011-2012.php?view=item&item=6891),\r\nle flèchage Informatique/réseaux n\'indique pas que ce stage s\'adresse en\r\npriorité à des linguistes. Le stage comme indiqué ci-dessus, pourra\r\ncommencer dès le premier semestre.\r\n\r\nLes modalités d\'inscription se trouvent indiquées à l\'adresse suivante :\r\nhttp://www.cnes.fr/web/CNES-fr/712-comment-poser-votre-candidature-.php\r\n. Il est possible d\'avoir des informations supplémentaires par téléphone\r\nen contactant le responsable du sujet au 05 61 27 32 51.'),
(123, '2012-02-14', 'Airbus', 'Toulouse', 'Stage / Identification Optimisation Déploiement Outils de Veille Web 2.0 (h/f)\r\n\r\nReference Code : 10164312 LL FR EXT 1\r\n\r\nFunctional Area :ADMINISTRATION & GESTION D\'INFRASTRUCTURES / Gestion de site\r\n\r\nDescription of the job : Airbus (Toulouse) recherche un(e) stagiaire\r\npour une durée de 6 mois.\r\n\r\nCette offre de stage est à pourvoir à compter du 1er mars 2012\r\n(sujette à une certaine flexibilité).\r\n\r\n\r\nTasks & accountabilities:\r\n\r\nVous aurez, par exemple, les missions suivantes :\r\n- répertorier les dernières évolutions,\r\n- analyser et sélectionner les outils,\r\n- étudier les coûts,\r\n- étudier l\'intégration de ces outils au sein du centre de documentation,\r\n- participer à la mise en place.\r\n\r\nRequired skills:\r\n\r\nVous êtes en deuxième ou dernière année d\'école d\'ingénieur, en master\r\nou université (4ème ou 5ème année) et êtes spécialisé(e) en veille et\r\n/ ou management des nouvelles technologies et / ou sciences de\r\nl\'information et / ou intelligence.\r\n\r\nVous possédez les qualités suivantes :\r\n- organisation,\r\n- curiosité,\r\n- goût pour l\'informatique.\r\n\r\nAnglais : niveau intermédiaire.\r\n\r\nContact Data:\r\n\r\nMerci de bien vouloir postuler en ligne en joignant votre CV sur le site :\r\n\r\nhttp://www.eads.com/eads/int/en/work-for-eads/apply/search-for-vacancies.referringdivision-airbus.html\r\n\r\nen entrant le code du stage  : 10164312 LL FR EXT 1'),
(124, '2012-02-15', 'LORIA', 'Nancy', 'L\'équipe KIWI (Knowledge, Information and Web Intelligence) du\r\nlaboratoire Loria (laboratoire lorrain de recherche en informatique et\r\nses applications) du Loria (Laboratoire lorrain de recherche en\r\ninformatique et ses applications) propose un stage de Master 2\r\nrecherche, dans le domaine des réseaux sociaux, de la détection\r\nd\'opinions et de la e-reputation.  \r\n\r\nGratification : 2500 euros pour 6 mois de stage. \r\n\r\nPoursuite en thèse possible.\r\n\r\nSujet :  Apport des réseaux sociaux pour une meilleure relation client.\r\n\r\nEncadrement : \r\nAnne Boyer - Professeur, Equipe KIWI, LORIA - Anne.Boyer@loria.fr \r\net \r\nArmelle Brun - Maître de conférences, Equipe KIWI, LORIA - Armelle.Brun@loria.fr \r\n\r\nContexte et Problématique\r\n\r\nLa garantie de la rentabilité des entreprises passe par une bonne\r\ncommunication et propagation de l\'information en interne et avec leurs\r\nclients et leurs clients potentiels (prospects).\r\n\r\nLes réseaux sociaux d\'entreprise (RSE) sont un nouveau moyen de\r\nfavoriser la communication et la propagation d\'informations au sein des\r\nentreprises. Si ces réseaux sont en général destinés à un usage interne\r\naux entreprises, ils peuvent aussi être étendus à leurs clients. Dans ce\r\ncadre, les RSE peuvent interagir avec d\'autres services comme les\r\nréseaux sociaux publics (RS) tels que Twitter ou Facebook (en exploitant\r\nles données disponibles sur les utilisateurs). Via cette interaction,\r\nl\'entreprise cherche non seulement à mieux connaître ses clients mais\r\naussi à savoir ce qui se dit d\'elle à l\'extérieur et ainsi réagir pour\r\nune meilleure efficacité.\r\n\r\nLa mise en place de connexions entre les réseaux sociaux (RS) et les\r\nréseaux sociaux d\'entreprise (RSE) permet donc non seulement de faire\r\némerger un nouveau mode de communication entre l\'entreprise et ses\r\nclients. Elle permet également à l\'entreprise d\'être à l\'écoute de ce\r\nqui se dit d\'elle et ainsi proposer des offres adéquates à de futurs\r\nclients.\r\n\r\nDéroulement du stage\r\n\r\nLe stage débutera par la réalisation d\'un état de l\'art sur l\'analyse de\r\nréseaux sociaux, la diffusion de l\'information dans les réseaux sociaux\r\net dans les graphes et la détection d\'opinions et de communautés\r\nd\'opinions.\r\n\r\nSuite à cet état de l\'art, l\'étudiant s\'intéressera à la définition d\'un\r\nmodèle permettant de déterminer automatiquement, dans les réseaux\r\nsociaux ou dans les blogs, l\'activité autour d\'une entreprise : ce qui\r\nse dit d\'elle. Un prototype de ce modèle devra être réalisé.\r\n\r\nL\'étudiant se penchera également sur  la détermination de l\'information\r\npertinente à diffuser sur ces réseaux : quelle information diffuser ?\r\nsur quel réseau la diffuser ? à quelles personnes précisément la\r\ndiffuser ? L\'évaluation se fera par analyse des \"retours\" des\r\nutilisateurs :  au travers de l\'observation et de l\'analyse des actions\r\n(traces d\'usage) que les clients entreprendront suite à la diffusion de\r\ncette information : usage mining.     \r\n\r\nCe stage  s\'appuie sur les compétences et l\'expérience de l\'équipe dans\r\nles domaines comme la personnalisation [1], la modélisation utilisateurs\r\n[2], de la détection de communautés dans les réseaux et les réseaux\r\nsociaux de grande taille [3], la recherche de leaders dans des réseaux\r\n[4][5], etc. \r\n\r\n\r\n\r\nProfil recherché :\r\n\r\nM2 Recherche informatique ou école d\'ingénieurs\r\nBonnes notions en apprentissage automatique\r\nBonnes connaissances en programmation java\r\nBon niveau en anglais\r\n\r\n\r\n\r\nRéférences bibliographiques\r\n\r\n[1] Modélisation de comportements et apprentissage stochastique non\r\nsupervisé de stratégies de recherche et d\'accès à\r\nl\'information. Castagnos S. Thèse de l\'Université Nancy 2, novembre\r\n2008.\r\n\r\n[2]  Compass to Locate the User Model I need: Building the Bridge\r\nbetween Researchers and Practitioners in User Modeling. Brun A., Boyer\r\nA., Razmerita L. User Modeling, Adaptation and Personalization - UMAP\r\n2010, États-Unis (2010).\r\n\r\n[3] From Community Detection to Mentor Selection in Rating-Free\r\nCollaborative Filtering. Brun A., Castagnos S., Boyer A. Advances in\r\nMultimedia Journal (2011) .\r\n\r\n[4]  Social recommendations : mentor and leader détection to alleviate\r\nthe cold-start problem in collaborative filtering. Brun A, Castagnos, S\r\nand Boyer A. in Social Network Mining, Analysis and Research trends :\r\nTechniques and Applications (2011).\r\n\r\n[5] Detecting Leaders to alleviate Latency in Recommender\r\nSystems. Esslimani I., Brun A., Boyer A. International Conference on\r\nElectronic Commerce and Web Technologies, Espagne (2010) \r\n\r\n\r\nContact : \r\n\r\nAnne Boyer (anne.boyer@loria.fr) et Armelle Brun\r\n(armelle.brun@loria.fr). \r\n\r\nLes personnes intéressées par le sujet devront envoyer par mail un CV,\r\nun relevé de notes et une lettre de motivation.'),
(125, '2012-04-02', 'Systran', 'Paris', '########################\r\n\r\nCompany:        SYSTRAN\r\nDepartment:     Linguistic Resources \r\nLocation:       Paris 75002, France\r\nWebsite:        www.systran.fr \r\n\r\n \r\n\r\nInternship description:\r\n\r\nSYSTRAN has currently an opening for an internship of 4-6 months that\r\naims at the development and evaluation of linguistic resources for\r\nEnglish to Russian Machine Translation\r\n\r\nThe internship project would include the following tasks:\r\n\r\n..  Integration and validation of dictionary entries\r\n\r\n..  Creation of domain dictionaries using Bilingual Terminology\r\n    Extraction on parallel domain corpora\r\n\r\n..  Identification of invalid or wrong translations using corpus-based\r\n    methods\r\n\r\n..  Work on attributive translations of nouns\r\n\r\n..  Validation and enrichment of resources used for morphological\r\n    analysis\r\n\r\nRequired skills: \r\n\r\n..  Native competence of Russian and fluency in English\r\n\r\n..  Good working knowledge of computational lexicography and NLP methods\r\n    in general\r\n\r\n..  Strong skills in Russian and English morphology and syntax\r\n\r\n..  Working knowledge of Perl and scripting languages is a plus\r\n\r\n..  Strong communication skills and ability to work in a team\r\n\r\n \r\nPlease send your application and cover letter to Bianka Buschbeck:\r\nbuschbeck at systran.fr'),
(126, '2012-04-19', 'LIMSI', 'Orsay', 'Proposition de stage M1 ou M2 au LIMSI-CNRS\r\ndans le cadre de l\'Action Incitative\r\n\'Transfert de connaissances linguistiques d\'une langue à l\'autre\'\r\n\r\n\r\nResponsables du stage : \r\nPierre Zweigenbaum (groupe ILES) \r\nMarianna Apidianaki (groupe TLP)\r\n\r\n\r\nTitre : Transfert de rôles sémantiques d\'une langue à l\'autre\r\n\r\nLes ressources linguistiques comme les corpus annotés sont actuellement\r\ndisponibles dans peu de langues, notamment en anglais. Cependant, des\r\nressources de ce type sont requises pour le développement d\'outils pour\r\nde nombreuses applications du traitement automatique des langues. De ce\r\nfait, plusieurs travaux se sont récemment intéressés au transfert\r\nautomatique de connaissances de langues riches en ressources vers\r\nd\'autres langues. Le stage proposé rejoint cette problématique.\r\n\r\nLe transfert de connaissances linguistiques d\'une langue à l\'autre a\r\ngénéralement lieu au sein de corpus parallèles et se base sur\r\nl\'alignement des textes. L\'idée sur laquelle reposent les méthodes\r\nproposées est que si l\'on dispose de corpus annotés et de leur\r\ntraduction dans une autre langue, on peut chercher à transférer les\r\nannotations dans cette autre langue. Par ce processus, des ressources\r\nsont créées qui permettent d\'entraîner des outils d\'analyse à différents\r\nniveaux dans les nouvelles langues (Yarowsky et Ngai, 2001; Lopez et\r\nal. 2002).\r\n\r\nCe stage est plus particulièrement centré sur le transfert\r\nd\'informations de rôles sémantiques de l\'anglais vers le français. Les\r\nméthodes d\'étiquetage de rôles sémantiques nécessitent des connaissances\r\nlinguistiques importantes ou de grands corpus annotés. En anglais, ces\r\nressources et les outils dérivés existent (Gildea et Jurafsky, 2002;\r\nPalmer et al., 2005). Pour le français, des travaux sont en cours pour\r\nconstruire de telles ressources et outils, y compris en exploitant des\r\ncorpus parallèles (Padó et Pitel, 2007; Van der Plas et al., 2011) afin\r\nde bénéficier des outils ou annotations disponibles pour l\'anglais.\r\n\r\nL\'objectif de ce stage est de mener une étude sur le processus de\r\ntransfert de rôles sémantiques de l\'anglais vers le français. Plus\r\nprécisément, nous souhaitons explorer les cas où le transfert ne peut\r\npas être effectué. Cela peut être dû à la structure spécifique aux\r\nlangues particulières ; à des erreurs d\'alignement ; ou à des\r\ndivergences de traduction observées au sein de corpus parallèles.  Les\r\nrésultats du processus de transfert proposé par Van der Plas et\r\nal. (2011) seront analysés en comparaison avec un étiquetage de\r\nréférence (gold standard) contenant les résultats corrects. Le/la\r\nstagiaire aura donc à étudier les cas où l\'analyseur ne fournit pas les\r\nrésultats souhaités, à procéder à une analyse des erreurs, étudier\r\nl\'impact de ces sources d\'erreur sur le transfert et envisager des\r\nsolutions pouvant améliorer la performance de la méthode.\r\n\r\nLe corpus qui sera utilisé pour cette étude est la partie\r\nanglais-français du corpus Europarl (Koehn, 2005).\r\n\r\nProfil : le/la stagiaire devra avoir un profil linguistique multilingue\r\net un intérêt pour les problématiques du traitement de la langue. Des\r\ncompétences en informatique seront appréciées mais ne sont pas\r\nindispensables.\r\n\r\nDurée : 4 mois\r\nDate de début : dès disponibilité\r\nNiveau : Master 1 ou 2\r\nLieu : LIMSI-CNRS, Groupe ILES\r\nrue John von Neumann,\r\nUniversité Paris Sud\r\n91403 Orsay Cedex\r\n\r\nSalaire: le/la stagiaire recevra la gratification CNRS standard\r\n(de l\'ordre de 436 ¤/mois).\r\n\r\nContacts : \r\nPierre Zweigenbaum (pz@limsi.fr)\r\nMarianna Apidianaki (marianna@limsi.fr)'),
(127, '2012-04-26', 'CEA-LIST', 'Gif-sur-Yvette', 'Stage Bac+5 : Alignement de mots à partir de corpus de textes parallèles\r\npour la construction et la mise à jour de dictionnaires multilingues\r\n\r\n\r\nLieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie\r\ndes Contenus (LVIC), 91191 Gif-sur-Yvette\r\n\r\nSujet :\r\n\r\nLes dictionnaires bilingues constituent les principaux composants des\r\nsystèmes de traduction automatique et de recherche d\'information\r\ninterlingue. La masse de travail nécessaire pour créer manuellement les\r\ndictionnaires bilingues est importante. C\'est la raison pour laquelle\r\ndepuis quelques années de nombreuses approches de construction\r\nautomatique de ces dictionnaires ont été proposées.\r\n\r\nLe stage consistera, d\'une part, à constituer un corpus de référence de\r\ntextes parallèles et d\'autre part, à évaluer les principaux composants\r\ndu module de construction et de mise à jour de dictionnaires bilingues\r\ndéveloppé au CEA-LIST. Cette évaluation se fera selon deux approches\r\ndifférentes :\r\n\r\n- Une évaluation manuelle comparant les résultats du module d\'alignement\r\n  de mots simples, de mots composés et d\'expressions par rapport à un\r\n  alignement de référence ;\r\n\r\n- Une évaluation automatique en intégrant les résultats du module\r\n  d\'alignement de mots dans la table de traduction du système de\r\n  traduction statistique open source Moses.\r\n\r\nCe stage comportera les étapes suivantes:\r\n\r\n- Appropriation des principaux composants du module de construction et\r\n  de mise à jour de dictionnaires bilingues.\r\n\r\n- Constitution d\'un corpus de référence composé de textes parallèles\r\n  multilingues.\r\n\r\n- Mise en place d\'outils d\'évaluation du module d\'alignement de mots\r\n  simples, de mots composés et d\'expressions.\r\n\r\n- Spécification et implémentation du module de nettoyage des\r\n  dictionnaires bilingues construits ou mis à jour automatiquement.\r\n\r\n- Développement d\'une interface graphique pour la gestion de la\r\n  construction et de la mise à jour de dictionnaires bilingues.\r\n\r\nProfil recherché :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du Traitement Automatique de\r\nla Langue (TAL).\r\n\r\nCompétences en informatique et en TAL\r\n\r\nProgrammation : C++, Perl ou équivalent\r\n\r\nLangues : Maîtrise de l\'anglais et du français, la connaissance de la\r\nlangue arabe est un plus\r\n\r\nContact  et envoi des candidatures :\r\n\r\nNasredine SEMMAR, 01 69 08 01 46,\r\nnasredine.semmar@cea.fr\r\n\r\nDurée : 4 à 6 mois\r\n\r\nNasredine SEMMAR\r\n\r\nCEA Saclay Nano-INNOV\r\nInstitut CARNOT CEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus (LVIC)\r\nPoint courrier n°173\r\n91191 Gif-sur-Yvette CEDEX\r\nTel: +33 (0)1 69 08 01 46\r\nFax: +33 (0)1 69 08 01 15\r\nEmail: nasredine.semmar@cea.fr'),
(128, '2012-05-24', 'INRIA', 'Sophia Antipolis', 'Proposition de stage Master/Ingénieur : Étude et développement d\'un\r\nsystème automatique de question-réponse pour la langue française.\r\n\r\nLieu : INRIA Sophia Antipolis Méditerranée\r\nÉquipe : Wimmics ( http://wimmics.inria.fr )\r\nDurée : 4-6 mois\r\nDate limite de candidature : 15 juin 2012\r\nDescription du stage: https://wimmics.inria.fr/internship\r\n\r\nContacts et envoi des candidatures :\r\nElena Cabrio: elena.cabrio@inria.fr\r\nJulien Cojan: julien.cojan@inria.fr\r\n\r\n\r\nSujet :\r\n\r\nDe nombreux travaux en cours portent sur la conception de systèmes de\r\nréponse automatique à des questions posées en langue naturelle,\r\nnotamment l\'anglais.\r\n\r\nLe système QAKiS [1] développé dans l\'équipe répond à des questions de\r\nculture générale posées en anglais. Les réponses sont obtenues en\r\ninterrogeant avec des requêtes SPARQL DBpedia [2], qui est une base de\r\ndonnées extraites des pages de Wikipedia.\r\n\r\nLe système QAKiS génère des requêtes SPARQL à partir de questions posées\r\nen anglais puis soumet ces requêtes à DBpedia. Pour cela, il s\'appuie\r\nsur une base de motifs de phrases qui donnent différentes manières\r\nd\'exprimer une relation de DBpedia en anglais. Le système compare la\r\nquestion posée aux motifs de la base pour identifier la relation de\r\nDBpedia qui permettra d\'obtenir une réponse. D\'autres outils\r\ninterviennent ensuite pour identifier le type de réponse attendu et les\r\nentités nommées de la question.\r\n\r\nLe but de ce stage sera de porter ce système au français. En\r\nparticulier, il faudra expérimenter des méthodes d\'extraction de motifs\r\nà partir des versions francophones de Wikipédia et DBpedia. Il faudra\r\naussi revoir le traitement linguistique des questions, en intégrant des\r\noutils adaptés a la langue française. Un deuxième développement envisagé\r\nsera d\'améliorer la reconnaissance des entités nommées, en intégrant au\r\nsystème actuel des outils comme DBpedia Spotlight [3], qu\'il faudra\r\naussi porter au français.\r\n\r\n\r\nProfil souhaité :\r\n  Ingénieur / Master.\r\n  Intérêt pour le Web, notamment le web de données.\r\n  Intérêt pour le traitement du langage.\r\n  Programmation : Java, SQL, quelques connaissances sur le Web et le Web\r\n  Sémantique (standards RDF-S/OWL/SPARQL, consommation de linked data )\r\n  et/ou le traitement automatique des langues sont un plus.\r\n  Bon niveau d\'anglais.\r\n\r\n\r\n[1] http://dbpedia.inria.fr/qakis (Cabrio et al., à paraître dans les\r\n    actes de l\'atelier Interacting with Linked Data 2012)\r\n[2] http://dbpedia.org\r\n[3] http://spotlight.dbpedia.org/\r\n\r\n\r\nElena Cabrio \r\nPostdoc Researcher, WIMMICS team \r\n\r\nINRIA Sophia-Antipolis Méditerranée \r\n2004 Route des Lucioles BP93 \r\n06902 SOPHIA ANTIPOLIS cedex \r\nTel: +33 (0)4 92 38 77 67 \r\nemail: elena.cabrio@inria.fr'),
(129, '2012-06-05', 'Homeloc', 'Paris', 'Proposition de stage\r\n\r\nGénération automatique de texte pour le web\r\n\r\nLa société\r\n\r\nHomeloc est un service destiné aux propriétaires de locations de\r\nvacances, proposant de nombreuses fonctionnalités au sein d\'une\r\ninterface unique :\r\n\r\n- Multidiffusion des annonces sur de nombreux sites partenaires, avec\r\nde fortes remises\r\n\r\n- Création automatique d\'un site dédié (ex : www.homeloc.com/test)\r\n\r\n- Messagerie centralisée pour retrouver et traiter facilement les\r\ndemandes de réservation\r\n\r\n- Synchronisation des calendriers de disponibilité\r\n\r\nPour les propriétaires, notre promesse est simple : générer plus de\r\nréservations, tout en économisant du temps et de l\'argent.\r\n\r\nObjet du stage\r\n\r\nL\'objet du stage sera d\'améliorer le système existant de génération de\r\ndescriptions en langage naturel à partir des données structurées sur\r\nles offres de location de vacances.\r\n\r\nLes données structurées (localisation, nombre de pièces, équipements,\r\netc.) sont soit saisies directement par les propriétaires sur le site\r\nHomeloc, soit fournies sous forme de flux de données par des\r\npartenaires. Ces données brutes peuvent, dans un premier temps, être\r\ntraitées et enrichies au moyen d\'API externes et de sources de données\r\nouvertes (Open Data).\r\n\r\nCes données sont ensuite utilisées pour la génération automatique de\r\ndescriptions en langage naturel des offres de location. Ces\r\ndescriptions doivent être :\r\n\r\n- adaptées au contexte de diffusion (site web dédié, flux pour un site\r\n  partenaire...)\r\n\r\n- formulées de manière unique pour chaque site, pour favoriser leur\r\n  référencement\r\n\r\n-écrites dans un français correct !\r\n\r\nIntégré à l\'équipe technique Homeloc, vous interviendrez sur l\'amélioration et l\'enrichissement des modèles de génération existants, ainsi que des règles linguistiques associées.\r\n\r\nVotre profil\r\n\r\nNos attentes :\r\n\r\n- maîtrise d\'au moins un langage dynamique (Python, Ruby, Perl, PHP...)\r\n- connaissances en traitement automatique des langues\r\n- bonne maîtrise de la langue française\r\n- vous êtes organisé, exigeant, curieux, et de bonne humeur\r\n- vous avez envie d\'intégrer une équipe agile\r\n\r\nBonus :\r\n\r\n- expérience d\'un framework de développement web (Django, Rails, Symfony...)\r\n- familiarité avec un système de gestion de version (git, Mercurial, SVN)\r\n- participation à des projets open-source\r\n\r\nNotre environnement technique : Linux, Python, Tornado, MongoDB,\r\nRabbitMQ...\r\n\r\nModalités du stage\r\n\r\nStage conventionné\r\nIndemnité de stage : à négocier (selon profil)\r\nTickets restaurant\r\nRemboursement de la carte orange (50%)\r\nLieu de travail : 46 rue de Provence, Paris 9e\r\nDate de démarrage : dès que possible\r\n\r\nPour postuler\r\n\r\nPar email : jobs@homeloc.com\r\nModalités : envoyez un CV (format PDF) ou un lien vers votre profil LinkedIn\r\nContact : Guillaume Cabane');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(130, '2012-06-13', 'Systran', 'Paris', 'Internship description:\r\n\r\nSYSTRAN has currently an opening for an internship of 4-6 months that\r\naims at the adaptation of its Portuguese language pairs to the new\r\nspelling conventions for Portuguese.\r\n\r\nThe internship project would include the following tasks:\r\n\r\n- Specification of rules to convert text according to the Portuguese\r\n  Language Orthographic Agreement\r\n\r\n- Adaptation of SYSTAN\'s lexical resources to the new spelling\r\n  conventions\r\n\r\n- Work on European Portuguese - Brazilian Portuguese localization of the\r\n  Portuguese MT input and output\r\n\r\n- Integration and testing of results\r\n\r\nRequired skills:\r\n\r\n- Native competence of Portuguese, preferably Brazilian Portuguese, and\r\n  fluency in English and French\r\n\r\n- Profound knowledge of the Portuguese spelling reform and ability to\r\n  specify rules converting text to the new spelling conventions\r\n\r\n- Good working knowledge of computational lexicography and NLP methods\r\n  in general\r\n\r\n- Perl and scripting languages are a plus\r\n\r\n- Strong communication skills and ability to work in a team\r\n\r\nPlease send your application and cover letter to Bianka Buschbeck:\r\nbuschbeck AT systran DOT fr'),
(131, '2012-10-18', 'Technicolor', 'Rennes', 'Internship position available at Technicolor R&D in Rennes.\r\n\r\nTitle\r\n------\r\n\"Which scene are you talking about?\"\r\nRecognizing scenes discussed on cinema or TV forums.\r\n\r\nContext\r\n-------\r\nFor more info on Technicolor Research & Innovation, Rennes :\r\nhttps://research.technicolor.com/rennes/\r\n\r\nThe internship will be hosted at Technicolor R&I in Rennes, France (500\r\nemployees, of which 130 researchers), within the Media Computing\r\nLab. Our lab aims at bringing modern trends in computing to the service\r\nof novel media engines in content creation (visual effects, animation)\r\nas well as content discovery and retrieval.\r\nMore specifically, our team focuses on Web user comments posted on\r\nforums and social networks. We use various approaches such as data\r\nmining, social network analysis and natural language processing.\r\n\r\nObjective\r\n---------\r\nThis internship aims at designing, developing and evaluating an\r\ninformation extraction system for user comments. The domain is dedicated\r\nto cinema and television. Each comment is already attached to a\r\nparticular audiovisual content (movie, TV series, TV program). One of\r\nour goals is to detect within the comments the text segments which refer\r\nto a particular moment in the video. For instance, users may talk about\r\ntheir favorite scene or quote a famous dialogue.\r\n\r\nTask description\r\n-----------------\r\nWe will not analyze the audiovisual signal (image or audio), but solely\r\nthe text of comments. Comments have already been collected and saved\r\ninto a database. Hence the internship will focus on the analysis of the\r\ndataset rather than its collection. The intern will be responsible for\r\nchoosing best techniques, based on a survey he or she will conduct on\r\nstate-of-the-art approaches.\r\nThe developed system will be evaluated by the intern, both\r\nquantitatively and qualitatively. Depending on obtained results and\r\ninnovative ideas, this work may lead to a research publication in a\r\nconference.\r\n\r\nKeywords\r\n---------\r\nNatural language processing (NLP), machine learning, data mining, text\r\nmining\r\n\r\nProfile of the candidate\r\n-------------------------\r\n* Student in final year of master or science engineering school\r\n* Computer science (Python, Java)\r\n* Skills in machine learning, data mining and natural language\r\n  processing\r\n* Strong interest in research (will constitute a survey)\r\n* Interest in social networks\r\n* English mandatory\r\n* Appreciates working with a team spirit\r\n\r\nInternship period & duration\r\n-----------------------------------\r\n6 months, starting preferably around February or March 2013, depending\r\non the candidate\'s constraints.\r\n\r\nPlease email your CV and cover letter to\r\nstage.rennes@technicolor.com<mailto:stage.rennes@technicolor.com> with\r\nreference [TRDF-DM-029] in the subject.'),
(132, '2012-10-31', 'Succeed Together', 'Paris', 'Recrutement stagiaire R&D\r\n\r\n\r\n    Société :\r\n\r\nPME innovante spécialisée dans le développement de la performance des \r\nréunions par l\'accélération des échanges entre les participants, \r\nrecherche un stagiaire pour intégrer notre pôle R&D, constitué de 2 \r\npersonnes, travaillant en lien avec des laboratoires d\'informatique \r\nfondamentale affiliés au CNRS.\r\n\r\nNous développons des outils numériques de traitement de l\'information \r\npermettant le regroupement sémantique de messages courts en temps réel.\r\n\r\n\r\n    Poste et mission :\r\n\r\nNous développons un logiciel visant à synthétiser les idées exprimées \r\ndans des messages courts par des techniques de  TALN.\r\nLe stagiaire aura pour mission principale de développer la performance\r\ndu système existant (clustering, utilisation de dictionnaires, mise au\r\npoint du machine learning ...).\r\n\r\nLe stagiaire sera aussi amené à piloter le logiciel en séminaire devant\r\nnos clients, parmi lesquels figurent de nombreux grands groupes (SNCF,\r\nSodexo, Safran, BNP Paribas, BPCE, Auchan, Vinci, Accor, Foncia, Crédit\r\nAgricole...), afin de tester en situation le résultat de ce travail.\r\n\r\n\r\n    Profil :\r\n\r\n- Niveau Master\r\n- Bon niveau en python\r\n- Connaissance des systèmes GNU/linux\r\n- Connaissances des technologies web appréciées \r\n  (html/javascript/jquery/css/django)\r\n\r\n- Facilité relationnelle et bonne présentation\r\n\r\n- Bonne approche conceptuelle de la résolution de problèmes, autonomie\r\n  décisionnelle\r\n\r\n- Bon niveau en anglais\r\n\r\n- Stage d\'une durée de 6 mois minimum - dès que possible\r\n\r\n- Poste basé à Paris\r\n\r\n\r\nMerci d\'envoyer votre candidature à plloret@succeed-together.eu\r\n\r\n\r\nPatrick LLORET\r\nMob : +33 (0)6 89 74 80 69\r\nMél : plloret@succeed-together.eu\r\nhttp://www.succeed-together.eu'),
(133, '2012-11-09', 'CNES', 'Toulouse', 'Stage CNES Toulouse\r\nSciences de l\'Univers\r\n\r\nUtilisation des méthodes de la linguistique de corpus pour proposer\r\ndes améliorations dans la constitution et la rédaction de\r\nL\'encyclopédie d\'exobiologie\r\n\r\n\"L\'exobiologie est un domaine pluri disciplinaire faisant aussi bien\r\nappel à la biologie, la chimie que la géologie, la planétologie... Une\r\npremière version de l\'encyclopédie a été rédigée par les spécialistes\r\nde ce domaine. Les travaux d\'un stagiaire en linguistique ont\r\nidentifiés certaines pistes possibles d\'amélioration (création d\'un\r\nindiex, d\'un glossaire, clairifer les notions de mots-clés...). Une\r\ndeuxième version de l\'encyclopédie est programmée pour 2014. Le but de\r\nce stage est d\'identifier des axes concrets d\'amélioration et de les\r\nproposer aux rédacteurs de l\'encyclopédie. Ce stage sera encadré par\r\nDCT/PO/PM avec le support de DSI/SD/GI et de la faculté du Mirail. Le\r\nstagiaire se partagera entre le CNES et la faculté du Mirail (afin\r\nd\'accéder aux outils d\'analyse de corpus).\r\n\r\n-Référence : 2013T171\r\n-Accueil : DCT/PO/PM\r\n-Nombre de place(s) : 1\r\n-Durée (mois) : 6\r\n-Date de début : 2ème semestre\r\n\r\n\r\nPostuler en ligne sur :\r\n\r\nhttp://www.cnes.fr/web/CNES-fr/175-stages-2011-2012.php?view=item&item=7352'),
(134, '2012-11-15', 'Plixee', 'Rouen', '** Stage de M2 Recherche : Extraction automatique d\'information de\r\ncontenus textuels\r\n\r\n** Mots-clefs : Extraction de connaissances, analyse de \r\ndialogue/conversation, traitement automatique de la langue.\r\n\r\n** Contexte :\r\n\r\nPlixee est une startup fondée par trois ingénieurs de l\'INSA de Rouen.\r\nElle développe une solution à destination du grand public, associations\r\net TPE visant à faciliter la communication et l\'organisation de projets.\r\nL\'offre comble un manque constaté d\'outils simples pour s\'organiser de\r\nmanière dématérialisée. Elle permet d\'éviter les discussions par emails\r\nou le panachage de plusieurs services dispersant l\'information. Elle se\r\ndifférencie des solutions existantes en ne fournissant que des outils\r\nsimples et ne se substitue pas aux logiciels avancés de gestion de\r\nprojets.\r\nUne des grandes forces de Plixee est d\'accompagner l\'utilisateur dans le\r\nprocessus créatif. En créant un espace dédié à leur projet, les\r\nutilisateurs disposent d\'un espace de discussion au sein duquel ils\r\npeuvent échanger autour de leurs idées. Au fur et à mesure de leurs\r\ndiscussions, les idées vont germer et amener à prendre des décisions.\r\nCelles-ci se matérialisent par des éléments de projet que les\r\nutilisateurs peuvent extraire directement depuis les messages\r\n(questions, tâches, etc.). Ces éléments construisent alors petit à petit\r\nle projet qui sera achevé au terme de leur consultation/réalisation.\r\n\r\n** Objectif du stage :\r\nLe processus d\'extraction d\'éléments au sein des discussions est pour le\r\nmoment réalisé manuellement par les utilisateurs. L\'objectif de ce stage\r\nest de faciliter ce processus en proposant des algorithmes et outils\r\nsuggérant ou extrayant automatiquement les éléments adéquats grâce à une\r\nanalyse du contenu de la discussion. On peut ainsi imaginer que dans une\r\nconversation portant sur le choix d\'une date de départ en vacances, le\r\nsystème suggère automatiquement une question reprenant les différentes\r\npossibilités évoquées dans des messages précédents.\r\nPour répondre à cette problématique, nous envisageons donc de recourir à\r\ndes systèmes d\'analyse de contenu. Trois approches sont envisagées : Une\r\napproche symbolique à l\'aide de patrons linguistiques, qu\'ils soient\r\nconstruits manuellement ou automatiquement (voir [1] comme exemple\r\nappliqué à la détection d\'événements).\r\nUne approche numérique permettant d\'apprendre automatiquement les\r\ninformations à extraire (voir [2] pour une approche entièrement\r\nautomatique).\r\nUne approche hybride, combinant les deux approches précédentes.  Par\r\nailleurs, la structure dialogique pourra également être exploitée afin\r\nde faciliter l\'extraction des éléments en question. [3], par exemple,\r\npropose une méthodologie d\'analyse de dialogues dont l\'approche hybride\r\npourrait servir à détecter des structures courant sur plusieurs\r\nmessages.\r\n\r\n** Travail à effectuer :\r\n- Modélisation formelle du problème\r\n- Étude bibliographique des solutions existantes\r\n- Méthode(s) d\'extraction automatique de connaissances\r\n- Implantation et évaluation des résultats\r\nComme base de travail seront fournis : un corpus annoté et un prototype\r\nsimplifié issu d\'un développement réalisé par deux étudiants en projet.\r\n\r\n** Encadrement :\r\nVincent Durmont (Plixee) : vincent@plixee.com\r\nAlexandre Pauchet (MIU@LITIS - INSA de Rouen) : pauchet@insa-rouen.fr\r\nQuentin Suire (Plixee) : quentin@plixee.com\r\n\r\n** Équipe d\'accueil et déroulement du stage\r\nLe stagiaire sera intégré dans la société Plixee et dans l\'équipe\r\n\"Modélisation Interaction et Usages\" (MIU) du LITIS (EA 4108) à l\'INSA\r\nde Rouen. De façon générale, l\'équipe MIU adopte une approche\r\npluridisciplinaire de sciences cognitives. Elle s\'intéresse notamment à\r\nla relation entre l\'homme et les systèmes d\'information et de sa\r\nmodélisation, posant comme axiome que les interactions sont\r\nreprésentatives de l\'usage. Le défi scientifique est de comprendre\r\ncomment modéliser les interactions entre l\'homme et la machine ou entre\r\nl\'homme et l\'homme avec la machine comme interface.\r\nLe stage se déroulerait de février 2013 à juin 2013. L\'étudiant serait\r\nhébergé dans les locaux du laboratoire LITIS qui lui fournirait le\r\nmatériel nécessaire à son travail. La rémunération de l\'étudiant serait\r\nassurée par la société Plixee au tarif légal en vigueur (436,05EUR par\r\nmois).\r\n\r\n** Références bibliographiques\r\n[1] L. Serrano, T. Charnois, S. Brunessaux, B. Grilhères, M. Bouzid.\r\nCombinaison d\'approches pour l\'extraction automatique d\'événements.\r\nJEP-TALN-RECITAL\'2012 - Grenoble, France.\r\n[2] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P.\r\nKuksa. Natural Language Processing (Almost) from Scratch. Journal of\r\nMachine Learning Research, 12:2493-2537, 2011.\r\n[3] Z. Alès, G. Dubuisson Duplessis, O. Serban, A. Pauchet, A\r\nMethodology to Design Human-Like Embodied Conversational Agents based on\r\nDialogue Analysis, Workshop HAIDM@AAMAS, Valencia, Spain, pp.34-49,\r\n2012.'),
(135, '2012-11-15', 'Centre de Rééducation Fonctionnelle de Kerpape', 'Lorient', 'Proposition de stage de fin d\'études\r\n\"Optimisation ergonomique d\'un système d\'aide à la communication pour\r\ndes personnes lourdement handicapées\"\r\n\r\nRésumé\r\n------------\r\n\r\nProposition de stage de recherche ou de fin d\'études en informatique et\r\nInteraction Homme-Machine pour l\'aide au handicap\r\nd\'une durée de 4 mois minimum.\r\n\r\nVersion PDF : \r\nhttp://www.info.univ-tours.fr/~antoine/documents_enseignement/2013_Proposition_stage_Sibylle.pdf\r\n\r\nContexte scientifique\r\n-------------------------------\r\n\r\nEn collaboration avec le Laboratoire d\'Informatique de l\'Université de\r\nTours, le laboratoire d\'informatique du Centre Mutualiste de Rééducation\r\nde Kerpape (56- Morbihan) propose un sujet de stage dans le cadre du\r\nprojet de recherche TMH (Télécommunications, Mobilité et Handicap)\r\nfinancé par la société BAMSOO.\r\n\r\nUne des actions envisagées dans le cadre du projet TMH est le\r\ndéveloppement de solutions intégrées pour l\'aide à la personne. Plus\r\nprécisément, nous nous intéressons à la mise en place de systèmes d\'aide\r\nà la communication pour des personnes souffrant de handicaps moteurs\r\ntrès sévères (Infirmité Motrice Cérébrale, Scléroses Latérales\r\nAmyotrophiques, syndrome d\'enfermement...) se traduisant par une\r\ntétraplégie ou une athétose accompagnée d\'une perte de l\'usage de la\r\nparole. La communication est alors privée de son support oral habituel,\r\nde même que les capacités très limitées de contrôle physique de\r\nl\'environnement par la personne handicapée empêchent toute saisie\r\ndirecte de message sur un clavier d\'ordinateur. L\'aide à la personne\r\nrecherchée vise donc un objectif principal : pouvoir échanger avec\r\nautrui par l\'intermédiaire d\'un système de suppléance informatique. Ce\r\nsystème repose sur l\'écriture de phrases à l\'aide d\'un clavier virtuel\r\naffiché à l\'écran. Un curseur se déplace automatiquement caractère par\r\ncaractère, le long du clavier virtuel. L\'intervention de la personne\r\nhandicapée se limite à la désignation des symboles lorsque le curseur\r\nest sur la touche ou le caractère désiré. Cette sélection est réalisée à\r\nl\'aide d\'un dispositif physique qui remplace le périphérique d\'entrée de\r\nl\'ordinateur (bouton pressoir, détecteur de souffle, suivi du\r\nregard...). L\'utilisation d\'un module de prédiction de lettres et de\r\nmots permet d\'accélérer la saisie en évitant à l\'utilisateur de saisir\r\ntous les caractères du message.\r\n\r\nLe laboratoire LI a déjà développé un tel système (Sibylle) qui repose\r\nsur une prédiction de mots très efficace et est utilisé en routine dans\r\nplusieurs centres de rééducation et laboratoires de recherche. Dans le\r\ncadre de ce stage, la personne recrutée travaillera avec le centre de\r\nrééducation fonctionnelle de Kerpare. Dans le cadre d\'un projet\r\n(VOLTAIRE) financé par la Fondation Motrice, une nouvelle interface de\r\nl\'application Sibylle a été développée précisément avec le centre de\r\nrééducation de Kerpape, sans que cette dernière ne soit intégrée au\r\nmoteur de prédiction.\r\n\r\nL\'objectif de ce stage est d\'élaborer une interface homme-machine\r\nergonomique qui facilite l\'utilisation du système et permette de\r\nbénéficier d\'une manière optimale de la prédiction de mots. Cette\r\ninterface fera l\'objet d\'expérimentations réelles auprès de patients des\r\ncentres de Kerpape\r\n\r\nTravail à réaliser\r\n------------------------\r\n\r\nLa personne recrutée sera en charge à la fois de la conception et des\r\naspects développement logiciel mis en jeu au cours du stage, ainsi que\r\nde la validation par tests utilisateurs réalisés à Kerpape. Le projet se\r\ndéroulera en trois phases successives :\r\n\r\nPhase 1 - Réingénierie (1 mois 1/2) -- Reprise en main du code de\r\nl\'interface développée au cours du projet VOLTAIRE et interfaçage avec\r\nle moteur de prédiction, documentation du code. Il s\'agit d\'un travail\r\nde réingénierie qui servira avant tout au stagiaire à prendre la mesure\r\ndu projet proposé. Elle consistera à achever le travail d\'intégration en\r\ncours sur le système SIBYLLE seul.\r\n\r\nPhase 2 - Ergonomie (2 mois 1/2) -- Evaluation d\'une première maquette du\r\nlogiciel développé et analyse de ses faiblesse ergonomiques. Proposition\r\nd\'amélioration de l\'interface pour optimiser le recours à la prédiction.\r\nPlusieurs pistes d\'améliorations peuvent déjà être citées :\r\n\r\n- Renforcement des possibilités de configuration du système pour\r\n  adaptation à l\'utilisateur\r\n\r\n- Étude du positionnement de la liste de prédiction, intégration\r\n  éventuelle dans le clavier de lettres\r\n\r\n- Renforcement de l\'adaptation de l\'interface au handicap et à\r\n  l\'utilisateur considéré\r\n\r\n- Étude de l\'adaptation de messages préenregistrés suivant le contexte\r\n  d\'utilisation. Ces phrases, composées à l\'avance, servent le plus\r\n  souvent pour la rédaction rapide de messages d\'alertes ou de demandes\r\n  pressantes. En modifiant la liste des messages suivant le contexte\r\n  d\'utilisation courant du logiciel, on augmente les possibilités de\r\n  communication rapide\r\n\r\nPhase 3 -- Dispositifs d\'entrée intégrés ou mobile (1 à 2 mois suivant\r\nla durée du stage) -- Cette phase est optionnelle. Elle dépendra de\r\nl\'avancée du travail et de la durée du stage. Elle consisterait soit, à\r\nétudier l\'usage du système de communication directement à partir d\'un\r\ndispositif de commande comme, par exemple, le joystick de commande du\r\nfauteuil roulant autonome du patient, soit à travailler plus en avant\r\nsur la portabilité du système sur des systèmes mobiles de type\r\nsmartphone ou tablet PC.\r\n\r\nProfil recherché\r\n-----------------------\r\n\r\nLa personne recrutée sera en cycle terminal d\'études en informatique, de\r\nniveau Bac+5 (Master informatique professionnel, recherche ou\r\nindifférencié, école d\'ingénieur). Des compétences en Interaction\r\nHomme-Machine seront appréciées. Dans le cas d\'un(e) étudiant(e) en\r\nMaster Recherche, le sujet de stage pourra être adapté aux attentes de\r\nl\'étudiant. Le cas échéant, une adaptation du sujet pourra être envisagé\r\npour des étudiants de Licence ou DUT informatique de très bon niveau\r\n(mention Bien appréciée) : prévoir dans ce cas une prolongation de la\r\nconvention de stage.\r\n\r\nRémunération\r\n--------------------\r\n\r\nRémunération maximale prévue par la règlementation à savoir 436,05 EUR\r\npar mois durant les 4 premiers mois de stage. En cas de stage donnant\r\nsatisfaction, et/ou si l\'étudiant doit/veut faire un stage d\'une durée\r\nsupplémentaire, une prolongation de stage peut-être envisagée avec\r\nrémunération au niveau du SMIC. Cette rémunération sera assurée dans le\r\ncadre d\'un projet industriel financé par la société BAMSOO.\r\n\r\nLieu d\'exercice\r\n-----------------------\r\n\r\nLa personne recrutée travaillera près de Lorient, au sein du Centre de\r\nRééducation Fonctionnelle de Kerpape. Il s\'intégrera dans une équipe\r\nprojet composée de Jean-Paul Departe et Willy Allègre (Laboratoire\r\nd\'informatique du Centre de Rééducation Fonctionnelle de Kerpape) et de\r\nJean-Yves Antoine (Université François Rabelais de Tours).\r\n\r\nContact -- Dépôt des candidatures\r\n-------------------------------------------------\r\n\r\nContact : Jean-Yves.Antoine@univ-tours.fr\r\n\r\nDépôt des candidatures : auprès de Jean-Yves Antoine. Merci de déposer\r\nun CV détaillé de vos activités passées, accompagné d\'une lettre de\r\nmotivation et de relevés de notes concernant vos deux dernières années\r\nd\'études.\r\n\r\nRenseignements supplémentaires\r\n--------------------------------------------------\r\n\r\nSystème Sibylle : \r\nhttp://www.info.univ-tours.fr/~antoine/SIBYLLE/Sibylle_fr/index.html\r\nCentre de rééducation de Kerpape : http://www.kerpape.mutualite56.fr/'),
(136, '2012-11-15', 'Inbenta', 'Toulouse', '*Société*\r\n\r\ninbenta (http://www.inbenta.com/fr) est une société d\'origine catalane\r\npionnière dans le Traitement Automatique du Langage Naturel (TALN) et la\r\nrecherche sémantique.  Basée sur ces concepts novateurs, inbenta\r\ndéveloppe depuis 2005 des outils web pour les sites internet de Grands\r\nComptes.\r\n\r\n\r\nDepuis 2009 et fort de son succès, inbenta étend ses activités sur le\r\nterritoire Français et a ouvert début 2012 une filiale sur Toulouse.\r\n\r\n\r\n*Description de l\'offre*\r\n\r\ninbenta développe différents outils web qui permettent de répondre\r\nautomatiquement aux questions des internautes en puisant les réponses\r\ndans une base de connaissances/FAQ constamment mise à jour.\r\n\r\n\r\nNotre système de réponse repose sur un lexique basé sur la Lexicologie\r\nExplicative et Combinatoire qui s\'encadre dans la Théorie\r\nSens-Texte. Grâce à ce lexique et à ses fonctions lexicales, nous\r\npouvons générer des paraphrases. Notre algorithme va donc anticiper les\r\ndifférentes formulations employées par les internautes pour exprimer une\r\nmême idée :\r\n\r\n*J\'ai perdu ma CB*\r\n\r\n*je ne retrouve plus ma carte !!  *\r\n\r\n*perte carte bleue*\r\n\r\n\r\nL\'objet du stage sera de participer à l\'amélioration de notre système de\r\nparaphrasage de notre système de Question / Réponse.\r\n\r\n\r\nLe stagiaire devra comprendre et analyser la solution développée par\r\ninbenta. Il devra s\'imprégner de l\'existant afin de faire évoluer\r\nl\'algorithme à travers notamment des cas clients concrets.\r\n\r\n\r\n*Profil recherché*\r\n\r\nVous terminez vos études en Traitement Automatique du Langage Naturel\r\n(Master 2) et souhaitez intégrer une structure innovante où vous pourrez\r\nfaire vos preuves et exprimer vos ambitions.\r\n\r\n\r\nPassionné(e) par la linguistique informatique, vous avez bien entendu\r\nune excellente maîtrise de la langue française et disposez d\'un niveau\r\nsuffisamment bon en espagnol, anglais ou catalan afin de pouvoir\r\naisément communiquer avec les équipes de Barcelone.\r\n\r\n\r\nBonus :\r\n\r\n\r\n- Maîtrise d\'au moins un langage de programmation (PHP de préférence)\r\n- Maitrise des expressions régulières et du SQL\r\n\r\n\r\n*Modalités du poste*\r\n\r\n\r\n- Stage de fin d\'études conventionné de 6 mois (avec possibilité\r\n  d\'embauche en CDI)\r\n- Rémunération prévue: conventionnelle + prime\r\n- Début : à partir de Février / Mars 2013\r\n- Lieu : Toulouse\r\n\r\n\r\nMerci d\'adresser CV et lettre de motivation par e-mail à l\'adresse\r\nsuivante : *rh@inbenta.com*\r\n\r\nPlus de détails sur cette offre de stage\r\nici : http://www.inbenta.com/images/france/offre-stage-tal.pdf\r\n\r\n*Manon Quintana*\r\nComputational linguist\r\n\r\n*IN**B**ENTA*\r\n+33 (0)5 31 54 94 97\r\nwww.inbenta.fr'),
(137, '2012-11-21', 'Nomao', 'Toulouse', 'Nomao SA est une start-up web innovante basée à Toulouse et fondée en\r\n2006. Elle appartient au groupe leader européen de social media\r\nEbuzzing. Nomao conçoit et développe une application mobile et un site\r\nweb permettant aux gens de trouver, garder et échanger des bonnes\r\nadresses entre amis (restaurants, bars, shopping, médecin...). C\'est\r\nun carnet d\'adresse intelligent et connecté qui s\'appuie sur des\r\ntechnologies de pointe telle que : recherche géolocalisée, data\r\nmining, systèmes de recommandation, traitement automatique des\r\nlangues.\r\n\r\nObjet du stage\r\n\r\n\r\nDans le cadre de son développement, Nomao recherche des stagiaires R&D\r\nde niveau M2 Informatique ou Sciences du Language avec une\r\nspécialisation en Traitement Automatique des Langues. Les sujets de\r\nstage à pourvoir touchent des domaines variés tels que : recherche\r\nd\'information géolocalisée, data mining, systèmes de recommandation,\r\ntraitement automatique des langues.\r\n\r\nDéroulement du stage\r\n\r\nLe/la stagiaire sera accueilli/e dans les locaux de Nomao (Toulouse\r\ncentre ville) et sera intégré/e dans l\'équipe (5 personnes à Toulouse,\r\n4 personnes à Paris). Le/la stagiaire recevra une indemnité de stage\r\n(selon profil) et des titres restaurants.\r\n\r\nCompétences requises\r\n\r\nL\'étudiant/e devra avoir de bonnes compétences en développement\r\nlogiciel et un intérêt pour le Web, les problématiques d\'extraction et\r\nd\'analyse de données. La connaissance de Python, des technologies\r\nlinguistiques et la maîtrise d\'une langue étrangère (hors anglais)\r\nseront appréciées.\r\n\r\nContact Merci d\'envoyer CV et lettre de motivation à : \r\nEstelle Delpech, estelle@nomao.com (responsable R&D)'),
(138, '2012-11-26', 'Reverso-Softissimo', 'Neuilly', 'Stage linguiste / terminologue / traducteur\r\n\r\nType de contrat : Stage de césure ou de fin d\'études (minimum 4 mois)\r\n\r\nLieu : Neuilly-sur-Seine\r\n\r\nIndemnité de stage : Selon durée et expérience\r\n\r\nDébut : Dès que possible\r\n\r\nAvantages : Tickets restaurant et 50% transport\r\n\r\nENTREPRISE\r\n\r\nEditeur de logiciels à rayonnement international, Reverso-Softissimo est\r\nl\'un des leaders mondiaux des solutions Intranet et Internet de\r\ntraduction instantanée et de dictionnaires électroniques.\r\n\r\nSon portail grand public dédié aux langues www.reverso.net génère un\r\ntrès fort trafic avec 200 millions de pages vues par mois et plus de 6\r\nmillions de visiteurs uniques.\r\n\r\nReverso-Softissimo recherche un(e) linguiste pour participer aux travaux\r\nde production et de recherche de notre équipe linguistique dans un\r\ncontexte professionnel motivant : haute technologie, forte croissance et\r\ndéveloppement international.\r\n\r\nVous êtes intéressé(e) par notre domaine ? C\'est le moment de rejoindre\r\nnotre équipe !\r\n\r\nMISSION\r\n\r\nSous la direction du chef de projet linguistique, le stagiaire\r\neffectuera les missions suivantes :\r\n\r\n- création, mise à jour, validation de dictionnaires bilingues ;\r\n- tests de la qualité de traduction et rédaction de rapports d\'analyse ;\r\n- recherche, évaluation et analyse de ressources terminologiques ;\r\n- animation et développement de la communauté d\'utilisateurs du\r\n  dictionnaire collaboratif.\r\n\r\nCette liste n\'est pas exhaustive et pourra être amenée à évoluer en\r\nfonction de l\'implication du/de la stagiaire.\r\n\r\nPROFIL\r\n\r\nÉtudiant(e) en dernière année d\'une école ou d\'une université en TAL,\r\nlangues étrangères, linguistique, ingénierie linguistique ou traduction,\r\nvous maîtrisez parfaitement l\'anglais et le français à l\'oral comme à\r\nl\'écrit, et idéalement une troisième langue.\r\n\r\nVous avez des qualités rédactionnelles ainsi qu\'une grande rigueur, une\r\nbonne méthodologie, un esprit logique et des capacités d\'analyse et de\r\nsynthèse ; votre sens de l\'initiative, votre dynamisme et votre\r\nautonomie seront également des qualités appréciées dans le cadre de ce\r\nstage.\r\n\r\nContact :\r\n\r\nJuliette MORNET\r\n01.41.43.10.31\r\njmornet@reverso.com'),
(139, '2012-12-03', 'Orange', 'Eysines (33)', 'Intitulé : Amélioration de la qualité du moteur de recherche 118712\r\n\r\nMission\r\nLa direction 118712 est une entité marketing en charge de la définition,\r\nde la conception et du déploiement des offres de renseignements annuaire\r\nd\'Orange sur différents canaux (renseignements téléphoniques, web,\r\nmobile,...).\r\n\r\nLe moteur de recherche du 118712 est accessible sur le web (2 millions\r\nde visiteurs uniques par mois) et via l\'appli mobile 118712.\r\n\r\nL\'objectif du stage est de définir et de mettre en ½uvre une stratégie\r\nd\'amélioration de la qualité des Listes Réponses du moteur mono champ\r\n(Google like) du 118712.\r\n\r\nAu moteur proprement dit est associé un analyseur de requêtes qui permet\r\nde typer une requête utilisateur en identifiant ses différents\r\nconstituants (activité professionnelle, localité, adresse,\r\ndénomination...) afin de lui appliquer des traitements\r\nspécifiques. L\'amélioration des réponses moteur et de l\'analyseur de\r\nrequêtes sont à mener en parallèle.\r\n\r\n\r\nL\'ensemble des actions que vous mettrez en ½uvre s\'articuleront en trois\r\nétapes principales :\r\n\r\n1- Analyse des Requêtes internautes et de leur résultat :\r\n - Choix d\'un corpus de requêtes pour l\'évaluation\r\n - Définition des typologies de demande\r\n - Evaluation de la pertinence du moteur de recherche et de l\'analyse de\r\n   requêtes\r\n\r\n\r\n2- Analyse des anomalies de réponse aux requêtes internautes\r\n - Diagnostic sur les causes de non réponses (silence)\r\n - Diagnostic sur les causes de réponses non satisfaisantes (bruit)\r\n\r\n3- Mise en ½uvre d\'un plan d\'action pour améliorer la qualité\r\n - Identification des leviers d\'amélioration : données annuaire,\r\n   paramétrage du moteur et de l\'analyseur de requêtes, évolutions\r\n   logicielles, ...\r\n - Priorisation des actions en fonction du bénéfice attendu\r\n - Prise en charge des paramétrages (référentiels de mots clés,\r\n   stratégie de correction automatique de la requête, ...) et évaluation\r\n   de l\'effet sur le corpus\r\n - Rédaction du cahier des charges pour les évolutions logicielles\r\n\r\nVous mènerez à bien ces réalisations avec le soutien des équipes de\r\ndéveloppement et dans le respect des orientations marketing.\r\n\r\nEnfin, vous opérerez une veille technologique et concurrentielle active,\r\net vous vous en inspirerez pour trouver des propositions\r\nd\'améliorations.\r\n\r\nProfil recherché\r\nFormation bac + 5 (ingénieur, master pro ou recherche) en informatique,\r\ntechnologies internet ou traitement automatique des langues. Stage de\r\nfin d\'étude ou de césure.\r\n\r\nCompétences\r\n- Intérêt marqué pour le web et les moteurs de recherche - Profil \r\n  « Ultra connecté »\r\n- Manipulation de gros volumes de données, maîtrise d\'Excel et d\'outils\r\n  de manipulation de bases de données (SQL, Access, Business Object,\r\n  ...)\r\n- Motivation, sens créatif et savoir être force de proposition, goût\r\n  pour la résolution de problèmes\r\n- Esprit d\'analyse et capacité de synthèse, rigueur\r\n- Qualités rédactionnelles et maîtrise de la langue, \r\n- Bonne communication\r\n\r\nModalités\r\nSite de France Télécom à Eysines (Pres de Bordeaux)\r\n6 mois à partir de mars 2010\r\nStage rémunéré\r\nContact : Laurence Grauby (mail : laurence.grauby@orange.com, Tel : 05\r\n56 16 92 22)'),
(140, '2012-12-03', 'LeGuide.com', 'Paris', 'H/F Stage R&D/Moteur de Recherche\r\n\r\nContexte\r\n\r\nDans le cadre des évolutions de notre moteur de recherche indexant\r\nplusieurs centaines de millions d\'offres d\' e-commerçants et servant\r\nplusieurs dizaines de millions de requêtes par jour, vous êtes au c½ur\r\ndu processus d\'optimisation du moteur et d\'évaluation de nouvelles\r\nsolutions.\r\n\r\nMission\r\n\r\nRattaché(e) au responsable de l\'équipe de moteur de recherche, ce\r\nstage nécessitera votre implication dans les tâches suivantes :\r\n\r\n    Tuning d\'analyseurs linguistiques pour SolR dans 9 langues\r\n\r\n    Développement de scripts en Python utilisés dans une plateforme\r\n    d\'amélioration de la pertinence du moteur de recherche\r\n\r\n    Participation à la création d\'un détecteur d\'entités nommées basé\r\n    sur le modèle de séquences CRF ( Conditional Random Field )\r\n\r\n    Annotation d\'un corpus d\'apprentissage\r\n\r\n    Développement de scripts en Python pour piloter l\'apprentissage du\r\n    détecteur\r\n\r\n    Évaluation du modèle sur des offres d\' e-commerçants\r\n\r\n    Évaluation de l\'apport du détecteur lors de la recherche\r\n\r\n    Développement de tests\r\n\r\nProfil\r\n\r\nVous suivez une formation supérieure de type ingénieur ou\r\néquivalent. Vous avez des connaissances en languages de programmation\r\n(C++ et/ou Java) et idéalement aussi dans un language de scripting\r\n(Python, Shell). Vous avez un réel intérêt pour le traitement\r\nautomatique des langues et les technologies de recherche\r\nd\'information.\r\n\r\nVotre réactivité, votre envie de participer à un projet technique\r\nd\'envergure et votre rigueur seront des atouts pour vous épanouir dans\r\ncette mission.\r\n\r\nUn bon niveau d\'anglais lu est indispensable.  La compréhension de\r\nl\'écrit d\'une ou plusieurs langues parmis allemand, danois, espagnol,\r\nitalien, néerlandais, polonais, suédois est un plus.\r\n\r\nConditions\r\n\r\nType de contrat : Stage conventionné de 6 mois idéalement\r\n\r\nDébut : janvier 2013\r\n\r\nIndemnités de stage : selon profil et durée du stage (+ tickets restaurant et 50% Pass Navigo)\r\n\r\nLieu de travail: Paris 10e arrondissement\r\n\r\n\r\nEnvoyez votre CV et une lettre de motivation par mail à l\'adresse\r\nrecrutement@leguide.com en précisant l\'intitulé du poste.'),
(141, '2012-12-12', 'Compilation', 'Saint-Felix (74)', 'Proposition de stage de M2 dans l\'entreprise Compilatio (Saint-Félix,\r\n74) :\r\n\r\n*Extraction et modélisation de connaissances d\'un document texte*\r\n\r\nLe stage consiste à étudier les méthodes existantes pour faire de\r\nl\'analyse de documents, l\'extraction de mots-clés, l\'extraction de\r\nthématiques dans le but de créer une signature sémantique du document.\r\n\r\n\r\nLe stage de 6 mois se déroulera à Saint-Félix en Haute-Savoie (Vers\r\nAnnecy et Chambéry).\r\nIl sera rémunéré de manière conventielle.\r\n\r\nRenseignements et candidatures :\r\nAlain Simac-Lejeune : alain@compilatio.net\r\n\r\n*L\'entreprise* : Compilatio est un éditeur de logiciel (entreprise\r\ninnovante) propose un service en ligne pour l\'analyse de documents pour\r\nla prévention et la détection de plagiat. Leader français de la\r\ndétection de plagiat créé en 2007, l\'entreprise sert plus de 200\r\nétablissements supérieurs et analyse quotidiennement plus de 1000\r\ndocuments.'),
(142, '2012-12-12', 'Compilation', 'Saint-Felix (74)', 'Proposition de stage de M2 dans l\'entreprise Compilatio (Saint-Félix,\r\n74) :\r\n\r\n*Recherche de similitudes dans Wikipedia avec SPARQL (DBPedia)*\r\n\r\nLe stage consiste à étudier le projet DBpedia, le SPARQL et Wikipédia et\r\nde proposer un outil permettant la recherche d\'articles de Wikipédia\r\nprésentant des similitudes avec le document analysé.\r\n\r\n\r\nLe stage de 6 mois se déroulera à Saint-Félix en Haute-Savoie (Vers\r\nAnnecy et Chambéry).\r\nIl sera rémunéré de manière conventielle.\r\n\r\nRenseignements et candidatures :\r\nAlain Simac-Lejeune : alain@compilatio.net\r\n\r\n*L\'entreprise* : Compilatio est un éditeur de logiciel (entreprise\r\ninnovante) propose un service en ligne pour l\'analyse de documents pour\r\nla prévention et la détection de plagiat. Leader français de la\r\ndétection de plagiat créé en 2007, l\'entreprise sert plus de 200\r\nétablissements supérieurs et analyse quotidiennement plus de 1000\r\ndocuments.'),
(143, '2013-01-09', 'LIMSI', 'Orsay', 'Stage M1/M2Pro/M2R : Analyse temporelle de pages web d\'information.\r\n\r\nMots-clés : traitement automatique de la langue, classification,\r\nanalyse temporelle\r\n\r\nDurée : 2 à 6 mois\r\n\r\nNiveau : Master 1 ou Master 2 (professionnel ou recherche), fin\r\nd\'école d\'ingénieur\r\n\r\nLe contenu et l\'ambition du stage pourront être modulés en fonction du\r\nniveau d\'étude et de la durée du stage du candidat.\r\n\r\nContexte\r\n\r\nL\'analyse temporelle de textes d\'information a pour but général de\r\nmieux localiser dans le temps les événements décrits dans ces textes,\r\net donc d\'alimenter de façon plus précise des moteurs de recherche ou\r\ndes outils d\'extraction d\'information. Pour cela, la première étape\r\nest de détecter correctement les expressions temporelles de ces\r\ntextes. Ces expressions temporelles peuvent être des dates absolues,\r\nc\'est-à-dire que l\'on peut placer sans ambiguïté sur l\'axe des temps\r\n(par exemple, le 14 juillet 1789), mais aussi des dates relatives, qui\r\nnécessitent une phase de résolution ou de normalisation (par exemple,\r\nle 14 juillet dernier, mardi, il y a deux jours ou deux jours\r\navant). On devine que cette normalisation nécessite au minimum de\r\nconnaître la date à laquelle le document a été écrit.\r\n\r\nLes techniques d\'analyse temporelle des textes ont fortement progressé\r\nces dernières années, mais s\'attachent en général au traitement\r\nd\'articles de journaux sous forme structurée, dans lesquels le contenu\r\net les metadonnées sont clairement identifiés. Dans le cas de pages\r\nweb, il est beaucoup plus difficile de distinguer les informations\r\npertinentes (date de création, auteurs, titre et texte de\r\nl\'article...) des données annexes comme les menus, les publicités, les\r\nlégendes d\'images. Des outils de nettoyage de pages existent, mais ils\r\nne sont pas assez précis pour les tâches que nous souhaitons\r\naccomplir.  Travail à réaliser :\r\n\r\nSelon le niveau d\'étude de la personne choisie, nous pourrons nous\r\nintéresser à une ou plusieurs des problématiques suivantes :\r\n\r\n    Extraction de la date de création des pages d\'information, et\r\n    d\'autres métadonnées éventuellement pertinentes\r\n\r\n    Améliorations ciblées du nettoyage des pages web issues des sites\r\n    d\'information\r\n\r\n    Utilisation et adaptation des outils d\'analyse temporelle sur les\r\n    pages web nettoyées\r\n\r\nOn utilisera un corpus de plusieurs millions de pages web en français\r\net en anglais.\r\n\r\nLe stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue et en\r\napprentissage automatique seront un plus.\r\n\r\nDurée : 2 à 6 mois\r\nNiveau : Master 1 ou Master 2 (professionnel ou recherche)\r\nContacts :\r\nVeronique.Moriceau[at]limsi.fr\r\nXavier.Tannier[at]limsi.fr'),
(144, '2013-01-09', 'INRIA', 'Sophia-Antipolis', 'Proposition de stage Master/Ingénieur:\r\nMaquettage d\'un système d\'interaction avec des connaissances linguistiques.\r\n\r\nSujet:\r\n\r\nCe stage à dominante IHM et Ergonomie Logicielle s\'effectuera au sein de\r\nl\'équipe WIMMICS [1] de l\'Inria Sophia-Antipolis. \r\nLes linguistes du projet RELIEF [2] développent une ressource lexicale\r\nde nouvelle génération - le Réseau Lexical du Français (RLF) - en accord\r\navec la théorie Sens-Texte [3]. Pour le moment, le logiciel d\'édition\r\ndéveloppé pour le projet RELIEF, MVS Dicet, ne permet pas de représenter\r\nles définitions des mots aussi formellement que le voudrait la théorie\r\nSens-Texte. Or une telle formalisation est aujourd\'hui nécessaire pour\r\nfaciliter le travail des linguistes et accélérer l\'élaboration du RLF. \r\nL\'équipe WIMMICS s\'inspire des Graphes Conceptuels [4], de la Théorie\r\nSens-Texte et des Grammaires de Dépendances [5], pour développer le\r\nnouveau formalisme mathématique des Graphes d\'Unités [6], qui a pour but\r\nde permettre la formalisation des définitions, et plus généralement la\r\nreprésentation et la manipulation de connaissances linguistiques à base\r\nde graphes et de règles.\r\nCe stage s\'insère donc en amont du développement de deux prototypes\r\nd\'éditeurs: un prototype d\'éditeur permettant l\'interaction avec des\r\nobjets du formalisme générique, et un prototype d\'extension du logiciel\r\nd\'édition lexicographique Mvs Dicet développé pour le projet RELIEF.\r\n\r\nObjectifs:\r\n\r\nL\'objectif de ce stage est de proposer des scénarios d\'interaction avec\r\nles objets de base du formalisme des graphes d\'unités, et de maquetter\r\nun prototype d\'éditeur.\r\n\r\nDurée, lieu: \r\n\r\n4-6 mois, rémunérés, au sein de l\'équipe WIMMICS [1] de l\'Inria\r\nSophia-Antipolis.\r\n\r\n\r\nProfil souhaité: \r\n\r\nCe stage s\'adresse en priorité à des étudiant en Ingénieur / Master,\r\navec une dominante IHM et Ergonomie Logicielle. Un intérêt pour les\r\nGraphes Conceptuels et/ou le traitement du langage est un plus.\r\n\r\nContacts et envoi des candidatures:\r\n\r\nMaxime Lefrançois, maxime.lefrancois[at]inria.fr, Alain Giboin,\r\nalain.giboin[at]inria.fr\r\n\r\nPointeurs\r\n\r\n[1] http://wimmics.inria.fr  \r\n[2] Projet RELIEF, Réseau Lexical du Français, et Bibliographie de\r\n    référence http://www.atilf.fr/spip.php?article908\r\n[3] http://en.wikipedia.org/wiki/Meaning%E2%80%93text_theory\r\n[4] http://en.wikipedia.org/wiki/Conceptual_graph\r\n[5] http://en.wikipedia.org/wiki/Dependency_grammar\r\n[6] http://maxime-lefrancois.info'),
(145, '2013-01-09', 'IRISA', 'Rennes', '*Title: Grapheme-to-phoneme conversion adaptation using conditional \r\nrandom fields*\r\n\r\n*Description:*\r\nGrapheme-to-phoneme conversion consists in generating possible\r\npronunciations for an isolated word or for a sequence of words. More\r\nformally, this conversion is a transliteration of a sequence of\r\ngraphemes, i.e., letters, into a sequence of phonemes, symbolic units to\r\nrepresent elementary sounds of a language. Grapheme-to-phoneme\r\nconverters are used in speech processing\r\n\r\n- either to help automatic speech recognition systems to decode words\r\n  from a speech signal\r\n\r\n- or as a mean to explain speech synthesizers how a written input should\r\n  be acoustically produced.\r\n\r\nA problem with such tools is that they are trained on large and varied\r\namounts of aligned sequences of graphemes and phonemes, leading to\r\ngeneric manners of pronouncing words in a given language. As a\r\nconsequence, they are not adequate as soon as one wants to recognize or\r\nsynthesize specific voices, for instance, accentuated speech, stressed\r\nspeech, dictating voices versus chatting voices, etc. [1].\r\n\r\nWhile multiple methods have been proposed for grapheme-to-phoneme\r\nconversion [2, 3], the primary goal of this internship is to propose a\r\nmethod to adapt grapheme-to-phoneme models which can easily be adapted\r\nunder conditions specified by the user. More precisely, the use of\r\nconditional random fields (CRF) will be studied to model the generic\r\nFrench pronunciation and variants of it [4]. CRFs are state-of-the-art\r\nstatistical tools widely used for labelling problems in natural language\r\nprocessing [5]. A further important goal is to be able to automatically\r\ncharacterize pronunciation distinctive features of a given specific\r\nvoice as compared to a generic voice. This means highlighting and\r\ngeneralizing differences that can be observed between two sequences of\r\nphonemes derived from a same sequence of graphemes.\r\n\r\nResults of this internship would be integrated into the speech synthesis\r\nplatform of the team in order to easily and automatically simulate and\r\nimitate specific voices.\r\n\r\n*Technical skills:* C/C++ and a scripting language (e.g., Perl or\r\n Python)\r\n\r\n*Keywords:* Natural language processing, speech processing, machine\r\n learning, statistical learning\r\n\r\n*Contact:* Gwénolé Lecorvé (gwenole.lecorve@irisa.fr)\r\n\r\n*References:*\r\n[1] B. Hutchinson and J. Droppo. Learning non-parametric models of\r\n    pronunciation. In Proceedings of ICASSP, 2011.\r\n[2] M. Bisani and H. Ney. Joint-sequence models for grapheme-to-phoneme \r\n    conversion. In Speech Communication, 2008.\r\n[3] S. Hahn, P. Lehnen, and Ney H. Powerful extensions to crfs for\r\n    grapheme to phoneme conversion. In Proceedings of ICASSP, 2011.\r\n[4] Irina Illina, Dominique Fohr, and Denis Jouvet. Multiple\r\n    pronunciation generation using grapheme-to-phoneme conversion based\r\n    on conditional random fields. In Proceedings of SPECOM, 2011.\r\n[5] John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira.\r\n    Conditional random fields: probabilistic models for segmenting and\r\n    labeling sequence data. In Proceedings of ICML, 2001.'),
(146, '2013-01-09', 'Semantia', 'Marseille', 'Semantia est un fournisseur de services en ligne (ASP), spécialisé dans\r\nle traitement du langage pour l\'optimisation de la gestion de la\r\nrelation client.\r\n\r\nContexte du stage TAL\r\nIntégré au service de Recherche et Développement, l\'objectif du stage\r\nest de participer à l\'optimisation des Bases de Connaissances des\r\napplicatifs de la société pour le traitement et l\'analyse du langage.\r\nAprès s\'être familiarisé avec les outils et les solutions Semantia, il\r\ndevra proposer des solutions d\'optimisation du module morpho-syntaxique.\r\n\r\nConnaissances requises et/ou acquises :\r\n\r\n  *   Bonnes connaissances des outils disponibles en TALN, plus\r\n      particulièrement des Grammaires\r\n  *   Esprit d\'équipe\r\n  *   Sens de l\'initiative\r\n  *   Autonomie\r\n  *   Rigueur\r\n  *   Motivation\r\n\r\nNiveau : Bac+3 minimum en Linguistique\r\n\r\nDurée du stage : de 3 à 6 mois\r\n\r\n\r\nContacts\r\n\r\n  *   drh@semantia.com\r\n  *   Tél. : 04 42 36 80 91'),
(147, '2013-01-09', 'Sinequa', 'Paris', 'Offre de stage 2013\r\n\r\nSujet : Amélioration d\'un module d\'analyse linguistique pour la\r\nrecherche d\'information en coréen ou en japonais\r\n\r\nLieu : Sinequa, 12 rue d\'Athènes, 75009 Paris\r\n\r\nCadre : Master 1 ou 2 en Linguistique-Informatique ou spécialité TAL\r\n\r\nCompétences :\r\n- Bonnes bases informatiques, maîtrise d\'un langage de script (type\r\n  PERL).\r\n- Maîtrise avancée du coréen ou du japonais.\r\n\r\nIndemnités : selon niveau et expérience.\r\n\r\nDébut : dès que possible.\r\n\r\nContact: Frederik Cailliau, cailliau@sinequa.com'),
(149, '2013-01-09', 'LIRMM', 'Montpellier', 'l\'équipe TEXTE du LIRMM (Montpellier) propose un stage de recherche\r\n(niveau M2 ou équivalent) en Traitement Automatique des Langues\r\n(TAL). Ce stage, d\'une durée de 5 mois environ (a priori de février à\r\njuin 2013), sera financé à hauteur du montant légal en vigueur (environ\r\n400 ¤ net / mois).\r\n\r\nLe stage portera sur l\'un, au choix, des deux sujets proposés (cf. plus\r\nbas).\r\n\r\nDes candidatures rapides sont souhaitées avant le 9 janvier 2013 à 12h00\r\n(midi). Toutefois, si le stage devait ne pas être pourvu, les\r\ncandidatures seraient considérées jusqu\'à la fin janvier.\r\n\r\nMerci de joindre à votre candidature les documents suivants :\r\n- CV\r\n- les notes de M1 et les modules de M2 suivis (ajouter les notes si\r\n  elles sont connues).\r\n\r\nMerci de préciser également quel sujet a votre préférence.\r\n\r\n* Sujet 1 : Acquisition automatique de grammaires de contraintes\r\n\r\nhttp://www.lirmm.fr/~prost/enseignement/M2R-stages/2012-2013/sujetM2R-acquisitionGP.pdf\r\n\r\n* Sujet 2 : Détection et correction d\'erreurs grammaticales\r\nhttp://www.lirmm.fr/~prost/enseignement/M2R-stages/2012-2013/sujetM2R-HOO.pdf\r\n\r\nLes candidatures doivent être envoyées à Jean-Philippe Prost\r\n(Prost@lirmm.fr) et Mathieu Roche (Mathieu.Roche@lirmm.fr).'),
(150, '2013-01-09', 'Airbus', 'Toulouse', 'In the purpose of improving the quality and precision of oral\r\nmessages, the objective of the proposed training job is to study the\r\nway an oral alert should be addressed in cockpit.\r\n\r\nThis study will concern Airbus Civil Aircrafts and will consist in:\r\n \r\nDetails of the mission :\r\n\r\n    Defining the requirements regarding speech synthesis in order to\r\n    ease comprehension :\r\n\r\n    Man vs. Woman\r\n    Prosody\r\n\r\n    Accentuation\r\n    Intensity\r\n    Intonation\r\n    Rhythm\r\n\r\n    Speed\r\n    Repetition\r\n\r\n \r\n\r\n    Describing (in different languages) the different ways to express\r\n    (syntax & terminology):\r\n\r\n    Order\r\n    Prohibition\r\n    Advise\r\n    Questioning\r\n    Normal vs. Abnormal status\r\n\r\n \r\n \r\n\r\n    Defining efficient combinations to describe emergency\r\n    (e.g. repetition + man voice)\r\n\r\n \r\n\r\n    Collecting the distinctive features of different pilots\' mother\r\n    tongues (English US, Arabic, Chinese, Russian, and Italian) in\r\n    order to study the proximity of sounds between English US and the\r\n    mother tongues of end users, to check the relevance of the\r\n    new-built words.\r\n\r\n \r\nRequired competences :\r\n\r\n    Linguistics\r\n    Phonetics/phonology\r\n    Sociolinguistics\r\n    Pragmatics\r\n\r\n \r\nRequired level/diploma : BAC+5, 3ème cycle\r\n \r\nDuration : 6 months (starting in April 2013)\r\n \r\nLocalisation :\r\nAIRBUS France SAS\r\n316, route de Bayonne\r\n31060 Toulouse Cedex 03\r\n \r\nTo file your application, please send us your covering letter and your CV.\r\n \r\nContact:\r\nEmmanuelle Cannesson\r\n( 33.(0)5.67.19.97.34\r\nemmanuelle.cannesson@airbus.com\r\n \r\nFlorence Beaujard\r\n( 33.(0)5.61.93.98.14\r\nflorence.beaujard@airbus.com');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(151, '2013-01-16', 'LIMSI', 'Orsay', 'Le LIMSI-CNRS propose le stage suivant en TAL pour un niveau M2/écoles\r\nd\'ingénieur :\r\n\r\nRéparation d\'erreurs d\'apprenants d\'une langue étrangère à l\'aide de\r\nsystèmes de traduction automatique\r\n\r\nURL : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2R-2013.html\r\n\r\nContact : Ryo Nagata (rnagata@limsi.fr), Gabriel Illouz \r\n(gabriel.illouz@limsi.fr) et Aurélien Max (aurelien.max@limsi.fr)\r\n\r\nToute personne intéressée est invitée à contacter les personnes\r\nci-dessus par e-mail (avec pour titre : \"Re: Stage en TAL au LIMSI-CNRS,\r\nOrsay\"), en envoyant un CV à jour (*dont le fichier porte le nom du\r\ncandidat*) et un court texte motivant l\'intérêt pour ce sujet en\r\nrelation avec les études suivies.\r\n\r\nLe groupe ILES du LIMSI propose en outre de nombreux autres sujets de\r\nstages : http://www.limsi.fr/Scientifique/iles/propositions'),
(152, '2013-01-16', 'Onyme', 'Lille', '------------------------------------------------------------------------\r\nEnvoyez votre candidature par email: recrute@onyme.com \r\n------------------------------------------------------------------------\r\n\r\n\r\nLa société Onyme (http://www.onyme.com) recherche, en *2013*, un(e)\r\nstagiaire de*deuxième année de master en informatique*, avec un attrait\r\npour le traitement automatique des langues. Une embauche à l\'issue du\r\nstage est envisagée.\r\n\r\n*Profil* : Bac +5\r\n*Durée du stage* : de 3 à 6 mois selon le sujet choisi.\r\n*Lieu du stage* : Onyme (http://www.onyme.com), Euratechnologies \r\n (http://www.euratechnologies.com)\r\n\r\nLe stage s\'inscrit au coeur de l\'équipe de R&D composée d\'un doctorant\r\nen informatique (4ème année), d\'un docteur en informatique et du\r\ndirecteur technique de la société.\r\n\r\nIl se compose de *deux sujets au choix* sur le traitement de la langue\r\nfrançaise :\r\n\r\n  * Sujet 1 : Évaluation de différents analyseurs lexicaux et\r\n    syntaxiques sur des textes courts\r\n    (http://blog.onyme.com/offre-de-stage-tal-2013/#suj1)\r\n  * Sujet 2 : Reconnaissance / Extraction de thématiques dans des textes\r\n    courts (http://blog.onyme.com/offre-de-stage-tal-2013/#suj2)\r\n\r\n\r\n  Sujets\r\n\r\n      Sujet 1 : Évaluation de différents analyseurs lexicaux et\r\n      syntaxiques sur des textes courts\r\n\r\n*Durée souhaitée du stage* : de 4 à 6 mois, selon les connaissances du\r\n candidat.\r\n\r\n*Compétences souhaitées* :\r\n\r\n  * Connaissances théoriques sur des analyseurs syntaxiques et lexicaux\r\n    (la pratique est un plus);\r\n  * Connaissances sur l\'étiquetage grammatical et syntaxique de corpus\r\n    écrits;\r\n  * Motivé et autonome.\r\n\r\n*Description du sujet* :\r\n\r\nLes analyseurs lexicaux, i.e. lemmatiseurs et POS annotateurs, et\r\nsyntaxiques fonctionnent soit par apprentissage, soit par règles.\r\n\r\nCes outils, élaborés à partir de connaissances générales (ex :\r\napprentissage à partir d\'un gros corpus de journaux), sont sujets à\r\nerreur quand ils sont utilisés dans un domaine spécialisé.\r\n\r\nL\'idée du stage est d\'améliorer les analyses en fournissant des\r\nconnaissances spécifiques aux analyseurs.\r\n\r\nLe sujet comporte plusieurs aspects :\r\n\r\n  * élaboration de corpus arborés depuis les traitements clients\r\n    destinés à l\'évaluation et à l\'apprentissage des analyseurs;\r\n  * apprentissage spécifique, ou ajout/modification de règles, selon le\r\n    type d\'analyseur;\r\n  * évaluation de différents analyseurs lexicaux sur nos données;\r\n  * évaluation d\'analyseurs syntaxiques de surface (chunker) et\r\n    d\'analyseurs partiels, ou élaboration d\'un chunker.\r\n\r\n\r\n      Sujet 2 : Reconnaissance / Extraction de thématiques dans des\r\n      textes courts\r\n\r\n*Durée souhaitée du stage* : de 3 à 6 mois, selon les connaissances du\r\ncandidat.\r\n\r\n*Compétences souhaitées* :\r\n\r\n  * Connaissances sur les analyseurs syntaxiques : délimitation de\r\n    syntagmes;\r\n  * Programmation en langage orienté objet. Le langage JAVA est un plus;\r\n  * Connaissances en apprentissage artificiel (classification\r\n    thématique);\r\n  * Connaissances en structure du discours (Ex. : \"X mais Y\" implique\r\n    deux idées);\r\n  * Motivé et autonome.\r\n\r\n*Description du sujet* :\r\n\r\nLes textes à analyser comportent des thématiques différentes relatives à\r\nun domaine.\r\n\r\nPar exemple, dans le domaine de la vente, les thématiques fréquemment\r\nabordées sont :\r\n\r\n  * La tarification;\r\n  * L\'agencement des magasins;\r\n  * L\'implantation des magasins;\r\n  * Le personnel.\r\n\r\nLe sujet du stage concerne la résolution des problématiques liées \r\nsuivantes :\r\n\r\n  * l\'évaluation du nombre de thématique abordés dans un message;\r\n  * la détection;\r\n  * la séparation d\'un message en plusieurs syntagmes thématiques.\r\n\r\nLa liste des thèmes à détecter peut être connue à l\'avance ou non. Dans\r\nle premier cas, des techniques relevant de la supervision peuvent être\r\nemployées. Dans le second, il s\'agit de découvrir de façon non\r\nsupervisée les thèmes présents dans un corpus.\r\n\r\n\r\n\r\nPlus de détails concernant les sujets et l\'offre sur notre blog : \r\nhttp://blog.onyme.com\r\n\r\n\r\n------------------------------------------------------------------------\r\nEnvoyez votre candidature par email: recrute@onyme.com \r\n------------------------------------------------------------------------'),
(153, '2013-01-21', 'LIPN', 'Villetaneuse', 'stage M2 : apprentissage multi-objectif pour les données\r\ntextuelles\r\n========================================================================\r\n\r\n    De nombreuses applications en traitement automatique des langues et\r\n    en extraction d\'information utilisent les analyses syntaxiques des\r\n    textes. Bien que les analyseurs syntaxiques modernes, appris sur\r\n    corpus, atteignent des performances globales tout à fait\r\n    satisfaisantes, on remarque souvent que les informations utiles aux\r\n    applications sont mal analysées.\r\n\r\n    Pour pallier ce problème, il peut être intéressant d\'apprendre un\r\n    analyseur pour une application précise, par exemple la traduction\r\n    automatique, les systèmes de questions/réponses, ou l\'extraction de\r\n    relations/événements dans des textes.\r\n\r\n    Récemment, Hall et al. [TDPJOMO] ont proposé une méthode\r\n    d\'apprentissage en ligne (de type perceptron) pour intégrer des\r\n    fonctions de perte non plus strictement syntaxiques mais qui portent\r\n    plus librement sur des structures induites par les structures\r\n    syntaxiques, notamment les structures produites par les applications\r\n    en aval.\r\n\r\n    Le but de ce stage est d\'étudier cette méthode, l\'apprentissage\r\n    multi-objectif, de la généraliser à d\'autres algorithmes\r\n    d\'apprentissage en ligne, de l\'implanter dans un analyseur standard\r\n    -- en l\'occurrence [MSTparser] -- et de l\'appliquer à la tâche\r\n    d\'extraction de relations/événements sur des textes biomédicaux.\r\n\r\n    profil recherché: Nous cherchons un candidat :\r\n      - de niveau M2\r\n      - compétent  en java et python\r\n      - ayant des notions d\'apprentissage automatique\r\n      - avec un intérêt pour le traitement automatique des langues\r\n\r\n    détails: Dans un premier temps, l\'étudiant devra se familiariser\r\n    avec :\r\n      - la notion d\'extraction de relations\r\n      - la chaîne de traitement [TEES] qui a gagné le challenge BioNLP\r\n        2009\r\n      - le corpus GENIA sur lequel le travail portera\r\n      - l\'analyseur MSTParser\r\n\r\n      Dans la suite du stage, il devra d\'abord évaluer la chaîne\r\n      d\'extraction lorsqu\'elle est utilisée avec le MSTParser sur une\r\n      grammaire apprise indépendamment de la tâche. Il s\'agira ensuite\r\n      d\'implanter un algorithme d\'apprentissage multi-objectif de la\r\n      grammaire et d\'évaluer son incidence sur les performances du\r\n      système.\r\n\r\n    contexte: Équipe RCLN du LIPN, Université Paris 13.\r\n\r\n    durée: 6 mois\r\n\r\n    contact: Contacter Joseph Le Roux (leroux@univ-paris13.fr) et\r\n             Antoine Rozenknop (antoine.rozenknop@lipn.univ-paris13.fr)\r\n             en joignant un CV au mail.\r\n\r\n    divers: Stage rémunéré dans le cadre d\'une opération du labex\r\n            [EFL]. Ce stage est susceptible de se prolonger par une\r\n            thèse.\r\n\r\n[TDPJOMO]: http://www.aclweb.org/anthology/D/D11/D11-1138.pdf\r\n[MSTparser]: http://sourceforge.net/projects/mstparser/\r\n[TEES]: https://github.com/jbjorne/TEES\r\n[EFL]: http://www.labex-efl.org/'),
(154, '2013-01-21', 'EpticaLingway', 'Boulogne-Billancourt', 'Linguiste-informaticien pour le chinois - M2\r\n \r\nDébut : Mars 2013\r\n\r\nDurée : 4 à 6 mois\r\n\r\nLieu : Boulogne-Billancourt\r\n\r\n \r\nEpticaLingway est l\'entité de R&D du groupe Eptica, principalement\r\norienté vers les applications de Traitement du Langage Naturel (TAL).\r\n \r\nLe groupe EPTICA est un des leaders français et international de\r\nsolutions d\'interactions clients en pleine croissance. Cette entreprise\r\nà taille humaine et à dimension internationale est basée principalement\r\nen France, Royaume Uni et Singapour. Elle édite une solution reconnue\r\nqui s\'adresse aux grands comptes et au mid-market dans les secteurs du\r\nRetail, de la Finance, de l\'Assurance, du Secteur Public. La société\r\ncompte parmi ses clients français la Société Générale, le Crédit\r\nAgricole, la CNAM, la MAAF, MMA, Pixmania, Darty, Mercer, Carrefour, La\r\nRedoute..., et, également à l\'international Air Asia, Panasonic... Elle est\r\nrépertoriée dans le Magic Quadrant du Gartner Group depuis 2010.\r\n\r\nAfin d\'enrichir ses composants sémantiques de traitement du chinois,\r\nEpticaLingway propose un stage conventionné niveau Master 2, basé à\r\nBoulogne-Billancourt\r\n\r\nDans l\'équipe EpticaLingway, Le candidat participera à l\'ensemble des\r\ntâches suivantes:\r\n\r\n·  Évaluation/amélioration du segmenteur,\r\n·  Constitution de ressources lexicales,\r\n·  Mise en ½uvre de ces ressources dans le moteur de recherche,\r\n·  Constitution d\'un corpus de référence et évaluation\r\n \r\nCompétences requises\r\n·  Chinois courant,\r\n·  Pratique du TAL (étude de corpus, moteur de recherche, grammaires\r\n   locales)\r\n·  Un langage de développement (Java, Groovy, Perl, ...) serait un plus\r\n·  Facilité à travailler en équipe\r\n\r\nEnvoyer CV et lettre de motivation à hugues.de-mazancourt@eptica.com'),
(155, '2013-01-21', 'EpticaLingway', 'Boulogne-Billancourt', 'Linguiste-informaticien - constitution de référentiels en\r\nfrançais\r\n\r\nDébut : Mars 2013\r\n\r\nDurée : 4 à 6 mois\r\n\r\nLieu : Boulogne-Billancourt\r\n\r\nEpticaLingway est l\'entité du groupe EPTICA dédiée aux applications de\r\nTraitement du Langage Naturel (TAL).\r\n\r\nLe groupe EPTICA est un des leaders français et international de\r\nsolutions d\'interactions clients en pleine croissance. Cette entreprise\r\nà taille humaine et à dimension internationale est basée principalement\r\nen France, Royaume Uni et Singapour. Elle édite une solution reconnue\r\nqui s\'adresse aux grands comptes et au mid-market dans les secteurs du\r\nRetail, de la Finance, de l\'Assurance, du Secteur Public. La société\r\ncompte parmi ses clients français la Société Générale, le Crédit\r\nAgricole, la CNAM, la MAAF, MMA, Pixmania, Darty, Mercer, Carrefour, La\r\nRedoute..., et, également à l\'international Air Asia, Panasonic... Elle est\r\nrépertoriée dans le Magic Quadrant du Gartner Group depuis 2010.\r\n\r\nDans le cadre d\'un projet de constitution de référentiel documentaire\r\ngénéraliste pour une bibliothèque, EpticaLingway propose un stage\r\nconventionné niveau M2, basé à Boulogne-Billancourt.\r\n\r\nLe candidat participera à l\'ensemble des tâches suivantes:\r\n\r\n·  Etude du corpus client,\r\n·  Utilisation des outils Lingway de production/structuration des\r\n   référentiels,\r\n·  Validation des résultats\r\n \r\nCompétences requises :\r\n· TAL (étude de corpus, moteur de recherche, grammaires locales)\r\n· Techniques documentaires\r\n· Des connaissances en programmation (Java, Groovy, Perl, ...) sont un\r\n  plus\r\n· Facilité à travailler en équipe\r\n\r\nEnvoyer CV et lettre de motivation à hugues.de-mazancourt@eptica.com'),
(156, '2013-01-28', 'Lattice', 'Montrouge', 'Proposition de stage : acquisition semi-automatique de patrons\r\ncaractéristiques à partir de textes\r\n\r\n\r\n* Descriptif :\r\n\r\nLe stage vise à extraire semi-automatiquement des patrons\r\nsyntaxico-sémantiques à partir de textes. Cette tâche a plusieurs\r\napplications possibles : les patrons peuvent servir à repérer des\r\néléments précis dans un texte (tâche classique d\'extraction\r\nd\'information) mais ils peuvent aussi servir de base à des travaux plus\r\nlinguistiques, visant par exemple à caractériser des textes en fonction\r\nde particularités qui ne sont pas directement observables.\r\n\r\nLes outils existants reposent essentiellement sur des patrons très\r\nproches des formes de surface (Hearst 1992) ou sur des méthodes à base\r\nd\'apprentissage produisant de très nombreux patrons qui sont ensuite\r\ndifficiles à trier et à analyser (Quiniou et al., 2012). Ces études ont\r\ntoutefois mis en avant des approches efficaces et reposant sur un\r\ncertain nombre de points communs (préanalyse du texte par un analyseur\r\nmorphosyntaxique, repérage de séquences continues ou non, contraintes\r\nsur le niveau d\'analyse possible). Pour aller plus loin, il semble\r\nnécessaire de proposer des approches interactives, de sorte que\r\nl\'analyste puisse spécifier dynamiquemlent ses besoins et ainsi guider\r\nau mieux l\'analyse.\r\n\r\n\r\n* Déroulement du stage\r\n\r\nLe stage se déroulera suivant plusieurs étapes :\r\n\r\n- état de l\'art et choix d\'une approche adéquate\r\n- implémentation d\'un algorithme interactif (en réutilisant si possible\r\n  un logiciel existant pour l\'acquisition des patrons eux-mêmes)\r\n- validation sur une tâche à préciser (la tâche visée et le corpus\r\n  seront discutés au début du stage)\r\n- rédaction d\'un rapport de stage\r\n\r\n* Références\r\n\r\n\r\n- Marti Hearst (1992). \"Automatic Acquisition of Hyponyms from Large\r\n  Text Corpora.\" In: Proceedings of the 14th International Conference on\r\n  Computational Linguistics (COLING-1992). doi:10.3115/992133.992154.\r\n\r\n- Solen Quiniou, Peggy Cellier, Thierry Charnois, Dominique Legallois\r\n  (2012). What About Sequential Data Mining Techniques to Identify\r\n  Linguistic Patterns for Stylistics? Proceedings of\r\n  Cicling. http://hal.archives-ouvertes.fr/hal-00675578.\r\n\r\n* Compétences requises\r\n\r\n- bonne connaissance d\'un langage de programmation (java, perl ou python\r\n  seraient particulièrement appréciés)\r\n- intérêt pour le traitement automatique du langage naturel\r\n- intérêt pour l\'intelligence artificielle, en particulier\r\n  l\'apprentissage automatique\r\n- qualité de rédaction en français et en anglais\r\n\r\n\r\n* Conditions :\r\n\r\nLe stage se déroulera au laboratoire Lattice (à Montrouge,\r\nhttp://www.lattice.cnrs.fr/) pendant 6 mois, à partir d\'avril 2013. Ce\r\nstage est indemnisé grâce au soutien du laboratoire d\'excellence\r\n\"Empirical Foundations of Linguistics\" (labex EFL,\r\nhttp://www.labex-efl.org/). Le stage fait partie d\'un projet plus large\r\nvisant à étudier la contribution de sources de connaissances pour\r\nl\'extraction d\'information, mené en commun entre le LATTICE et le LIPN\r\ndans le cadre du labex EFL.\r\n\r\n* Comment postuler ?\r\n\r\nEnvoyer par mail un CV et une lettre de motivation à Thierry Poibeau\r\n(prenom.nom@ens.fr) avant le 7 février 2013. Indiquer \"stage :\r\nacquisition semi-automatique de patrons caractéristiques à partir de\r\ntextes\" comme sujet du mail.'),
(157, '2013-01-31', 'Sinequa', 'Paris', 'Offre de stage 2013\r\n\r\nSujet : Amélioration d\'un module d\'analyse linguistique pour la\r\nrecherche d\'information en chinois.\r\n\r\nLieu : Sinequa, 12 rue d\'Athènes, 75009 Paris\r\n\r\nCadre : Master 1 ou 2 en Linguistique-Informatique ou spécialité TAL\r\n\r\nCompétences :\r\n- Bonnes bases informatiques, maîtrise d\'un langage de script (type\r\n  PERL).\r\n\r\n- Maîtrise avancée du chinois.\r\n\r\nIndemnités : selon niveau d\'études.\r\n\r\nDébut : dès que possible.\r\n\r\nContact: Frederik Cailliau, cailliau@sinequa.com'),
(158, '2013-02-04', 'Idiap', 'Martigny (CH)', 'Internship at the Idiap Research Institute, Martigny, Switzerland\r\n\r\nLearning verb tense translation from parallel corpora for statistical\r\nmachine translation\r\n\r\nhttp://www.idiap.ch/education-and-jobs/\r\n\r\nContact: Andrei Popescu-Belis\r\n\r\n\r\nDescription\r\n\r\nApplications are invited for a 6-month internship (preferably at the\r\nMaster level) in the field of statistical machine translation (SMT).\r\n\r\nAt Idiap, we are studying methods for using text-level information to\r\nimprove SMT, in the context of the Swiss COMTIS project\r\n(www.idiap.ch/comtis). In particular, we have successfully combined\r\nclassifiers for discourse connectives with state-of-the-art SMT systems,\r\nshowing an improvement on such particles. In collaborations with\r\nlinguists, we currently analyze the features that govern the translation\r\nof verb tenses, mainly from English to French. The main challenge for MT\r\nis that there is no one-to-one mapping from English to French tenses,\r\nand the correct choice depends on the context.\r\n\r\nThe goal of the internship is to design and implement a method for\r\npredicting the translation of verb tenses, applied to English/French\r\ntranslation (or another European language). First, training data will be\r\ngenerated by the word alignment of annotated parallel corpora. Then, a\r\nclassifier will be trained to predict tense translation based on lexical\r\nand semantic features. Its output will then be used to train and test a\r\ntense-aware SMT system, which will be evaluated in terms of BLEU\r\nimprovement but also verb-specific scores (METEOR or ACT).\r\n\r\nThe applicants should have a background in computer science or\r\nlinguistics. Knowledge of computational linguistics and machine learning\r\nwould be an advantage. Previous experience with statistical machine\r\ntranslation would be highly appreciated. The applicants should have\r\ndemonstrable programming skills in at least one scripting language such\r\nas Perl or Python, or master a programming language such as Java or\r\nC/C++. Good command of English and knowledge of another European\r\nlanguage (preferably French) are mandatory.\r\n\r\nThe applications should be submitted before March 15, 2013, with\r\npriority given to those submitted earlier. The internship can start\r\nimmediately, but no later than July 1st, 2013. The appointment is for 6\r\nmonths, with a gross salary of 2000 CHF per month.\r\n\r\nAbout Idiap\r\n\r\nIdiap is an independent, non-profit research institute recognized and\r\nsupported by the Swiss Government, and affiliated with the Ecole\r\nPolytechnique Fédérale de Lausanne (EPFL). It is located in the town of\r\nMartigny in Valais, a scenic region in the south of Switzerland,\r\nsurrounded by the highest mountains of Europe, and offering exciting\r\nrecreational activities, including hiking, climbing and skiing, as well\r\nas varied cultural activities. It is within close proximity to Geneva\r\nand Lausanne. Although Idiap is located in the French part of\r\nSwitzerland, English is the working language. Free French lessons are\r\nprovided.\r\n\r\nIdiap offers competitive salaries and conditions at all levels in a\r\nyoung, dynamic, and multicultural environment. Idiap is an equal\r\nopportunity employer and is actively involved in the \"Advancement of\r\nWomen in Science\" European initiative. The Institute seeks to maintain a\r\nprinciple of open competition (on the basis of merit) to appoint the\r\nbest candidate, provides equal opportunity for all candidates, and\r\nequally encourages both genders to apply.\r\n\r\nAPB\r\nIdiap Research Institute  |  tel: (41 27) 721 7729\r\nCentre du Parc, CP 592    |  fax: (41 27) 721 7712\r\nCH-1920 Martigny          |  name.surname@idiap.ch\r\nSwitzerland               |  www.idiap.ch/~apbelis'),
(159, '2013-02-04', 'EDF', 'Paris', 'Proposition de stage opérationnel en Text-Mining\r\n\r\nDepuis le 1er juillet 2007, le marché de l\'électricité est entièrement\r\nouvert à la concurrence et permet au consommateur de choisir librement\r\nson fournisseur d\'énergie. Dans ce contexte, il est devenu stratégique\r\npour EDF de comprendre les besoins de ses clients, mais également\r\nd\'expliquer et de prédire leur comportement.\r\n\r\nLe Domaine Analyse de la Connaissance Client au sein de la Direction des\r\nSystèmes d\'Information de la branche commerce a, pour partie, la mission\r\nd\'analyser les données provenant de nos différents systèmes\r\nd\'information et notamment les données textuelles.\r\n\r\nActuellement, nous utilisons des techniques de Text Mining à travers les\r\noutils de Temis et de Noopsis pour analyser automatiquement des\r\ncommentaires provenant de nos SI mais également les réponses aux\r\nquestions ouvertes d\'enquêtes de satisfaction.\r\n\r\nLe stage que nous proposons est opérationnel et a pour objectif la mise\r\nen place d\'un modèle d\'analyse automatique des réponses à des questions\r\nouvertes issues d\'enquêtes de satisfaction.\r\n\r\nLes tâches à réaliser comprendront :\r\n\r\n- L\'exploration de corpus avec des outils de classifications\r\n  automatiques\r\n\r\n- La définition d\'un plan de catégorisation en coopération avec le\r\n  métier\r\n\r\n- L\'annotation de données\r\n\r\n- La création d\'un modèle de catégorisation et de règles d\'extraction de\r\n  connaissances\r\n\r\nLe profil recherché : \r\n\r\n- Etudiant de niveau BAC +5 spécialisé en Traitement Automatique du\r\n  Langage.\r\n\r\n- Bonnes connaissances linguistiques et informatiques\r\n\r\n- Aisance rédactionnelle\r\n\r\nDébut de stage entre avril et juin 2013 pour une durée totale de 6 mois.\r\nLes candidatures (CV + lettre de motivation) sont à envoyer à\r\nanne-laure.guenet@edf.fr .\r\n\r\n\r\nAnne-Laure GUÉNET\r\nChef de projet spécialisée en Text Mining\r\nEDF - Direction Commerce - DSI\r\nDomaine Analyse et Connaissance Client\r\nDépartement Datamining et Analyse Client\r\n20, place de la défense\r\n92050 Paris La Défense CEDEX\r\n \r\nanne-laure.guenet@edf.fr\r\nTél. : 01.56.65.22.87'),
(160, '2013-02-04', 'IGN', 'Saint-Mandé (94)', 'Mise à jour du glossaire de la géomatique\r\n\r\nContexte\r\n\r\nLa commission de terminologie du Comité Français de Cartographie (CFC) a\r\nédité en 1981 un glossaire de la géomatique sous forme papier2. Ce\r\nglossaire s\'adresse à toute personne concernée par la géomatique,\r\nc\'est-à-dire qui travaille dans le domaine de la géographie,\r\nl\'urbanisme, l\'informatique, etc.\r\n\r\nLa commission a pour objectif de réaliser une mise à jour de la version\r\nélectronique de ce glossaire pour tenir compte en particulier des\r\névolutions techniques du domaine de la géomatique. Ces travaux ont été\r\nentamés en particulier sur les entrées du glossaire : termes obsolètes\r\net à supprimer, termes obsolètes mais présentant un intérêt historique,\r\ntermes conservés, termes à ajouter ont été listés. Le contenu du\r\nglossaire révisé a aussi été précisé, le texte actuel devra être enrichi\r\npour proposer des définitions multiples, des exemples d\'utilisation qui\r\npermettraient de contextualiser les termes concernés et en donner un\r\ncontexte d\'usage et des termes associés : synonyme, opposé, \"voir\r\naussi\".\r\n\r\nEnfin, la mise à jour devrait s\'appuyer sur des sources d\'information\r\nexistantes et des travaux similaires par les thèmes abordés ou par les\r\nmodes de consultation proposés.\r\n\r\nSujet\r\n\r\nL\'objectif du stage est de :\r\n\r\n- préciser la nouvelle ligne éditoriale de ce glossaire à partir des\r\n  études préalables déjà réalisées et des préconisations déjà formulées\r\n  par la commission,\r\n\r\n- proposer une méthode de mise à jour qui tiendra compte en particulier\r\n  de la cohérence, de la couverture et de la granularité des définitions\r\n\r\n- et la tester sur un domaine thématique de la géomatique.\r\n\r\nLe déroulement du stage pourrait être le suivant :\r\n\r\n- analyse du glossaire existant et du projet éditorial tel qu\'il est\r\n  déjà défini afin de bien cadrer les attentes ;\r\n\r\n- définition des principes de sélection des documents primaires qui\r\n  pourraient être les plus intéressants à intégrer au corpus qui doit\r\n  documenter les analyses des termes à décrire (un corpus électronique\r\n  de la géomatique a déjà été constitué, il devra être vérifié dans\r\n  cette étape) ;\r\n\r\n- définition d\'une méthodologie de repérage en corpus des termes absents\r\n  du glossaire mais attestés en corpus afin de pouvoir ensuite définir\r\n  les critères de sélection et d\'intégration des nouveaux termes ;\r\n\r\n- définition du programme d\'information et de l\'organisation\r\n  structurelle des articles du nouveau glossaire ;\r\n\r\n- élaboration du protocole de rédaction des articles (de la\r\n  documentation des usages en corpus à leur traitement textuel et\r\n  structurel, en envisageant éventuellement des enrichissements du type\r\n  annotations du texte des descriptions lexicales ou introduction de\r\n  liens) ;\r\n\r\n- préconisations de traitements éditoriaux en fonction du ou des\r\n  supports de publication envisagés.\r\n\r\nCe programme étant ambitieux, toutes les tâches prévues pourront ne pas\r\nêtre traitées à la même échelle, mais il serait intéressant pour le\r\nstagiaire comme pour la commission de terminologie de pouvoir avoir une\r\nvue d\'ensemble du projet éditorial et de la méthode de\r\ntravail préconisée. Des orientations réfléchies et argumentées seront\r\ndonc attendues pour chaque point.\r\n\r\nUn expert de la géomatique apportera ses compétences afin d\'aider le\r\nstagiaire à maîtriser les notions fondamentales du domaine et vérifiera\r\nrégulièrement les propositions terminologiques.\r\n\r\nDes travaux similaires par les thèmes abordés ou par les modes de\r\nconsultation proposés, ont déjà été recensés et pourront aussi\r\nconstituer des sources d\'exemples.\r\n\r\nResponsables du stage\r\nCatherine Dominguès\r\nIGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex\r\ntél : 01 43 98 85 44 mél : catherine.domingues@ign.fr\r\n\r\nLe stage sera co-encadré par : Nathalie Gasiglia\r\nUniversité Lille 3, UFR Humanités, Département Sciences du langages, &\r\nUMR Savoirs, Textes, Langage, BP 60149, 59 653 Villeneuve d\'Ascq\r\nmél : nathalie.gasiglia@univ-lille3.fr\r\n\r\nDurée, lieu du stage, rémunération\r\nLa durée prévue est de cinq mois, avec un début en mars/avril 2013.\r\nLe stage se déroulera au laboratoire COGIT de l\'IGN à Saint-Mandé.\r\n\r\nIGN/laboratoire COGIT\r\n73 avenue de Paris\r\n94160 Saint-Mandé\r\nmétro : Saint-Mandé - ligne 1 ou RER A : Vincennes\r\nrémunération : 30% du SMIC\r\n\r\nCompétences particulières et formation requise\r\n\r\nCe stage s\'adresse aux étudiants de master (1 ou 2) ou de 3ème année\r\nd\'école d\'ingénieurs avec une spécialisation en lexicographie,\r\nterminologie ou en traitement automatique du langage naturel.\r\n\r\nProlongements éventuels\r\nLe COGIT propose chaque année des sujets de thèse et des contrats de\r\npost-doc.\r\n\r\nPour candidater\r\n\r\nLe dossier de candidature sera envoyé par mail. Il devra se composer\r\nd\'un curriculum vitae et d\'une lettre de motivation, accompagnés des\r\nrelevés de notes des années de M1 et M2 (ou deux dernières années\r\nd\'école d\'ingénieurs) et d\'une description des enseignements suivis (un\r\nlien vers le site internet de la formation est le bienvenu).\r\n\r\n1 La géomatique regroupe l\'ensemble des méthodes et des outils\r\n  informatiques qui permettent d\'acquérir, représenter, analyser et\r\n  intégrer des données géographiques.\r\n\r\n2 Une version électronique (embryonnaire) existe, accessible à partir du\r\n  site du CFC ; http://lecfc.fr/index.php?page=commission&commission=6'),
(161, '2013-02-04', 'INRA', 'Paris ou Grignon', 'INRA Mét@Risk\r\nMéthodologies d\'analyse de risque alimentaire\r\n16, rue Claude Bernard\r\n75231 Paris cedex 05\r\n\r\nINRA GMPA\r\nGénie et Microbiologie des Procédés Alimentaires\r\nAvenue Lucien Brétignières\r\n78850 Thiverval Grignon\r\n\r\n\r\nSujet de stage de master pro 2ème année:\r\n\r\nConstruction d\'un corpus de connaissances sur un système de production\r\net de stabilisation de cellules microbiennes\r\n\r\nContacts : liliana.ibanescu@agroparistech.fr,\r\nlaurie.planes@agroparistech.fr, caroline.penicaud@grignon.inra.fr,\r\nlydie.soler@paris.inra.fr,\r\n\r\nLa production et la stabilisation de cellules microbiennes est un\r\nenjeu majeur pour de nombreuses bio-industries, représentant un marché\r\nde 144 milliards de dollars en 2010 et qui devrait atteindre 259\r\nmilliards de dollars en 2016. Les procédés employés sont très\r\nénergivores, et face au contexte énergétique actuel, des améliorations\r\nvoire des alternatives doivent être envisagées. Au-delà de la question\r\nde l\'énergie, c\'est la durabilité du système qui est mise en question,\r\nintégrant la dimension d\'épuisement des ressources (énergie, eau,\r\nmatières premières) mais aussi l\'impact sur l\'environnement\r\n(e.g. réchauffement climatique) ou sur la santé humaine\r\n(e.g. production de composés toxiques). Cependant, l\'amélioration de\r\nla durabilité du procédé ne peut pas se faire sans tenir compte des\r\ncontraintes spécifiques aux bioproduits, qui sont très fragiles et\r\nsubissent de fortes dégradations au cours des procédés. Les critères\r\nd\'évaluation de la qualité du bioproduit au cours des différentes\r\nopérations sont liés à l\'état physiologique des cellules et mesurables\r\nà différents niveaux d\'échelle (génétique, moléculaire, cellulaire,\r\npopulation). L\'intégration des différents critères (qualité du\r\nbioproduit, performance du procédé, impact environnemental) pour\r\noptimiser globalement le système est nécessaire dans l\'optique de\r\ndévelopper des procédés plus durables tout en préservant la qualité\r\ndes micro-organismes.\r\n\r\nL\'objectif de ce stage est de constituer un corpus de connaissances et\r\nun thésaurus pour la représentation in silico globale d\'un système de\r\nproduction et de stabilisation de cellules microbiennes intégrant les\r\ndifférentes étapes de production, les niveaux d\'échelle nécessaires à\r\nla description de la fonctionnalité du produit, et, les entrées et\r\nsorties liées à l\'impact environnemental, tout en prenant en compte la\r\ncomposante économique du système.\r\n\r\nCe stage sera réalisé dans le cadre d\'une collaboration entre deux\r\néquipes de deux unités INRA, l\'équipe « Ingénierie des connaissances »\r\nde l\'unité Mét@risk qui travaille en particulier sur la constitution\r\nde bases de connaissances et la construction d\'ontologies et l\'équipe\r\n« Bioproduits - Aliments - Micro-organismes - Procédés » de l\'unité\r\nGMPA qui travaille en particulier sur l\'objet d\'étude de ce stage.\r\n\r\nLes étapes du travail seront les suivantes :\r\n1- Extraction de connaissances issues de sources identifiées et du Web pour élaborer et enrichir\r\nle corpus de connaissances ;\r\n\r\n2- Prise en compte du caractère multi-échelles du système dans la construction du corpus de\r\nconnaissances ;\r\n\r\n3- Construction d\'un thésaurus permettant de représenter la connaissance du corpus de façon\r\nstructurée et hiérarchique\r\n\r\nLieu du stage: AgroParisTech (Paris ou Grignon), durée de 6 mois, stage rémunéré'),
(162, '2013-02-06', 'LIPN', 'Villetaneuse', 'Titre du stage M2 : Exploitation de relations sémantiques pour la\r\nRecherche d\'Information\r\n\r\nDescriptif et contexte\r\nLa recherche d\'information sémantique (RIS) a pour but de dépasser les\r\nlimites d\'une recherche classique par mots-clés. Les méthodes de RIS\r\nvisent à s\'affranchir de ces limites via le passage à un niveau\r\nconceptuel par le biais d\'une ressource sémantique. L\'exploitation des\r\nressources sémantiques se limite généralement au niveau des concepts où\r\nles mots-clés sont substitués par les concepts et où le raisonnement se\r\nfait essentiellement sur les liens hiérarchiques entre ces concepts. Ces\r\nméthodes ne permettent pas de prendre en compte toute la richesse des\r\nressources sémantiques qui ne sont considérées que comme des structures\r\ntaxonomiques.\r\n\r\nLe stage vise à enrichir un modèle de recherche d\'information sémantique\r\npour prendre en compte les relations sémantiques entre concepts afin\r\nd\'améliorer la qualité des documents retournés. De nombreux travaux dans\r\nle cadre du Web Sémantique ont montré l\'utilité des relations\r\nsémantiques (i.e rôles) pour améliorer l\'accès à l\'information [1]. Les\r\nrôles permettent d\'appliquer des moteurs d\'inférences et de répondre à\r\ndes requêtes complexes qui nécessitent du raisonnement [2]. Plusieurs\r\npistes sont possibles, comme l\'intégration de mesures de proximité\r\nsémantique (e.g. [2]), ou exploitation des relations sémantiques pour\r\nré-ordonnancer les résultats.\r\n\r\nLe stage se déroulera au LIPN (http ://www-lipn.univ-paris13.fr/),\r\nUniversité Paris 13 dans l\'équipe «Représentation des Connaissances et\r\nLangage Naturel» (RCLN). Ce stage est rémunéré grâce au soutien du\r\nlaboratoire d\'excellence \"Empirical Foundations of Linguistics\" (labex\r\nEFL, http://www.labex-efl.org/). Il fait partie d\'un projet plus large\r\nvisant à étudier la contribution de sources de connaissances pour\r\nl\'extraction d\'information, mené en commun entre le LIPN et le LATTICE\r\ndans le cadre du labex EFL.\r\n\r\nMissions\r\nLes différentes étapes du travail à réaliser sont les suivantes :\r\n* État de l\'art\r\n* Propositions de différents scénarios\r\n* Intégration des propositions dans une plate-forme existante (YaSemIR\r\n  ou TerrierSIR développées au LIPN)\r\n* Mise en place d\'une évaluation\r\n* Analyse des résultats\r\n\r\nRéférences\r\n[1] Claudia d\'Amato, Nicola Fanizzi, Bettina Fazzinga, Georg Gottlob and\r\nThomas Lukasiewicz. (2012) «Ontology-based semantic search on the Web\r\nand its combination with the power of inductive reasoning» In Annals of\r\nMathematics and Artificial Intelligence. Vol. 65. No. 2/3. Pages 83-121.\r\n\r\n[2] Uren, V., Sabou, M., Motta, E., Fernandez, M., Lopez, V., Lei, Y.\r\n(2011) «Reflections on five years of evaluating semantic search\r\nsystems». In International Journal of Metadata, Semantics and\r\nOntologies, 5(2), p.87-98.\r\n\r\n[3] G. Hirst et D. St-Onge. (1998) «Lexical chains as representations of\r\ncontext for the detection and correction of malapropisms.» In WordNet :\r\nAn electronic lexical database. MIT Press. Pages 305-332.\r\n\r\n\r\nProfil recherché\r\n- De niveau Master2\r\n- Autonome en informatique : connaissance d\'UNIX, de Java\r\n- Intérêt pour le web sémantique et la recherche d\'information\r\n- La connaissance de Lucene ou Terrier est un plus\r\n\r\nDurée : 6 mois\r\nDébut souhaité : avril 2013\r\n\r\nModalité de dépôt de candidature\r\n\r\nMerci d\'envoyer un CV détaillant la formation et l\'expérience acquise,\r\nles bulletins de notes ainsi qu\'une lettre de motivation à :\r\nHaïfa Zargayouna (haifa.zargayouna@lipn.univ-paris13.fr)\r\nDavide Buscaldi (davide.buscaldi@lipn.univ-paris13.fr)'),
(163, '2013-02-11', 'REBUZ', 'Strasbourg', 'Sujet : Observation des relations action-objet dans la perspective\r\nd\'innovation technologique dans un domaine d\'activité\r\n\r\nLieu : Strasbourg\r\nSociété : Rebuz SAS\r\n\r\nRebuz est une jeune société innovante qui est spécialisée dans l\'analyse\r\nde textes pour la veille économique. \r\n\r\nSa méthode originale répose sur l\'analyse sémantique épaulée par des\r\nprincipes de la linguistique cognitive. Le prototype du logiciel étant\r\nen cours de construction, la société cherche un(e) stagiaire en TAL qui\r\ncontribuera à l\'enrichissement des ressources lexicales et à l\'étude des\r\nstructures syntaxiques reflétant les relations action-objet dans les\r\nphrases.\r\n\r\nCompétences recherchées :\r\n- excellente maîtrise du français (anglais ou une autre langue sera un\r\n  plus)\r\n- bonnes connaissances des expressions régulières\r\n- aisance dans programmation en Perl (ou un autre langage de scripts)\r\n- notions en programmation orientée objet (Java)\r\n- habitude de travail avec des outils de TAL, tels que AntConc, Unitex,\r\n  etc.\r\n- bonnes capacités de travail en équipe\r\n- rigueur \r\n- responsabilité\r\n- autonomie\r\n\r\nNiveau d\'études : Bac+4, Bac+5\r\n\r\nDurée de stage : 4-6 mois\r\n\r\nGratification : 436,06 euros/mois  (logement possible)\r\n\r\nContact : Jean Marc Zuber (jm.zuber@rebuz.fr)'),
(164, '2013-02-11', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage : Extraction et génération de descriptifs produits\r\n(Syllabs)\r\n------------------------------------------------------------------------\r\n\r\n------------\r\nContexte\r\n------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création automatique\r\nde textes. Nos technologies sont le fruit d\'années de développement et\r\nmaîtrisent toutes les étapes du processus d\'analyse de données\r\ntextuelles du Web : identification des pages pertinentes, extraction et\r\ncatégorisation des informations clé.\r\n\r\nActuellement, nous recherchons un(e) ingénieur linguiste pour un stage\r\ndans le domaine de la création automatique de textes en français (langue\r\nmaternelle uniquement). L\'idée est de créer des descriptifs de lieux ou\r\nde produits à partir d\'une base de données existante (par exemple la\r\nliste des caractéristiques d\'un produit).\r\n\r\n----------------------------\r\nDescription du poste\r\n----------------------------\r\n\r\nLes tâches principales concernent:\r\n\r\n-  Extraction d\'information des caractéristiques produits.\r\n-  Génération automatique de descriptifs de produits.\r\n-  Scripts pour évaluation quantitative des textes générés\r\n\r\n-------------------\r\nProfil souhaité\r\n-------------------\r\n\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture.\r\n- Aptitude pour la représentation formelle du langage.\r\n- Excellente capacité de communication et aptitude pour le travail d\'équipe.\r\n- bon niveau en python serait un plus.\r\n\r\nDiplôme et expérience\r\n\r\n- Formation en cours : Linguistique Informatique ou similaire.  \r\n- Compétences en rédaction web serait un plus.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « Stage TAL ».\r\n\r\nLieu : Syllabs, 53 bis rue Sedaine, 75011 Paris.\r\n\r\nContrat : stage conventionné rémunéré en fonction du niveau d\'étude.'),
(166, '2013-02-13', 'ISIR / Telecom ParisTech', 'Paris', 'Modèle d\'engagement dans une interaction avec un agent virtuel\r\n\r\n* *\r\n\r\n*Résumé*\r\n\r\nLe stage s\'inscrit dans le projet A1:1 (Avatar échelle 1:1) qui vise à\r\nporter l\'interaction entre l\'humain et un agent virtuel à un niveau\r\ninégalé de présence, d\'émotion et d\'engagement...\r\n\r\nLe projet inclus une approche nouvelle de captation des signaux de\r\nl\'humain, (y compris l\'expression du visage et le regard) et\r\nl\'interprétation multimodale de ces signaux ainsi qu\'un modèle d\'agent\r\nvirtuel capable d\'imiter des signaux de l\'humain.\r\n\r\n*Objectifs*\r\n\r\nL\'engagement est considéré, par Sidner et al. (2004), comme «the process\r\nby which two (or more) participants establish, maintain and end their\r\nperceived connection during interactions they jointly undertake» (le\r\nprocessus par lequel deux (ou plusieurs) des participants établissent,\r\nmaintiennent et mettent fin à leur connexion perçue au cours des\r\ninteractions qu\'ils entreprennent conjointement). Ainsi, pour montrer\r\nl\'engagement, un agent virtuel doit être doté de mécanismes qui lui\r\npermettent de percevoir, d\'adapter et de générer des comportements\r\nappropriés au cours d\'une interaction sociale donnée. L\'engagement\r\nenglobe plusieurs phénomènes complexes tels que la notion d\'alignement,\r\nles liens sociaux, et l\'empathie. Il peut être considéré comme une\r\nmesure quantitative de la façon dont l\'interaction se passe, se situe\r\nentre les êtres humains ou entre l\'homme et la machine. Il peut se\r\nmanifester à travers un large spectre d\'actes intentionnels allant des\r\nstratégies de dialogue au mimétisme du comportement (par exemple\r\nsourire).\r\n\r\nLe stage visera à développer un modèle d\'engagement entre humain et\r\nagent virtuel. Elle se focalisera en particulier à donner aux agents la\r\ncapacité d\'imiter les comportements de son interlocuteur humain, de\r\nrépondre à ses signaux sociaux (Vinciarelli et al, à paraître) et d\'en\r\nenvoyer.\r\n\r\nLe mimétisme peut avoir lieu avec un bas niveau de conscience. Il peut\r\nêtre défini comme la tendance à l\'imitation des comportements lors de\r\nl\'interaction. Il s\'applique surtout pour l\'expression du visage, la\r\nqualité vocale et la posture du corps (Hess et al, 1999). Alors que le\r\nmimétisme implique la notion de comportement synchrone, la fenêtre de\r\ntemps de cette synchronicité doit être prudemment définie. Par exemple,\r\nla plupart des imitations du sourire comme celles des gestes se\r\nsuperposent dans le temps (Kimbara, 2006) ; de même l\'alignement lexical\r\npeut être vu sur plusieurs tours de parole. Le stage se focalisera sur\r\nl\'imitation d\'une des modalités d\'expressions.\r\n\r\nAxe thématique du Labex correspondant au stage : Les interfaces et\r\nl\'interaction de l\'humain avec des environnements numériques et des\r\nmondes physiques distants.\r\n\r\nEncadrants :\r\n\r\nMohammed Chetouani    mohamed.chetouani@upmc.fr\r\n\r\nChloé Clavel                  chloe.clavel@telecom-paristech.fr\r\n\r\nCatherine Pelachaud       catherine.pelachaud@telecom-paristech.fr\r\n\r\nLieu du stage : ISIR et Telecom-ParisTech\r\n\r\nFinancement : 1/3 du SMIC'),
(167, '2013-02-18', 'CEA - LVIC', 'Palaiseau', 'COMMISSARIAT A L\'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES\r\nLaboratoire Vision et Ingénierie des Contenus\r\n\r\n\r\nSUJET\r\n\r\nContexte\r\n\r\nDepuis 2002, le LVIC développe l\'analyseur linguistique multilingue LIMA\r\n[1].  Il s\'agit à ce jour d\'un outil très modulaire capable de faire\r\nl\'analyse (tokenisation, analyse morphologique, syntaxique et\r\nsémantique) de textes dans des langues aussi diverses que le Français,\r\nl\'Anglais, l\'Arabe, le Chinois, l\'Espagnol, l\'Allemand ou encore\r\nl\'Italien. LIMA représente à ce jour plus de 100.000 lignes de code\r\n(sans compter les ressources linguistiques). LIMA est déjà utilisé dans\r\nplusieurs produits industriels, mais le CEA LIST a décidé de le diffuser\r\nsous une licence libre pour faciliter son utilisation, sa diffusion et\r\nobtenir des retours plus rapides d\'une communauté d\'utilisateurs plus\r\nlarge.\r\nLIMA est codé en C++ standard. Il utilise largement les biliothèques\r\nboost et Qt. Il est multi-plateformes (GNU/Linux et MS Windows à ce\r\njour). Son architecture le rend très facilement extensible et intégrable\r\ndans des applications.\r\n\r\nObjectifs\r\n\r\nCette libération, qui se fait dans le cadre du projet ANR ASFALDA [2],\r\nnécessite d\'améliorer encore le logiciel avant de le diffuser, et ce sur\r\nplusieurs aspects:\r\n- documentation des API ;\r\n- documentation utilisateur ;\r\n- tests unitaires ;\r\n- tests fonctionnels.\r\n\r\nLIMA dépend de ressources linguistiques pour fonctionner (dictionnaires,\r\nrègles d\'analyse,...). Même si le laboratoire est propriétaire de\r\ncertaines d\'entre elles, d\'autres sont issues de ressources commerciales\r\net ne peuvent être diffusées librement. Il faudra donc produire des\r\nressources de remplacement à partir de ressources linguistiques libres\r\ndisponibles.\r\n\r\nLe travail du stagiaire consistera à intervenir sur ces différents\r\nsujets (codage, documentation et ressources) en vue de la mise à\r\ndisposition de LIMA sur une forge logicielle à la fin du stage. Le ou la\r\ncandidat(e) retenu(e) aura un bon niveau en C++, une compréhension des\r\nproblématiques liées à la diffusion des logiciels (tests,\r\ndocumentation...) et idéalement aura participé à un projet de logiciel\r\nlibre.\r\n\r\nLe stage se déroulera dans les locaux du LVIC situés à Nano-INNOV à\r\nPalaiseau (près de Polytechnique, Sup\'Optique, Thales et Danone).\r\n\r\n[1] \r\nhttp://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=A5D66B8127851343E2F9DB107DF26034?doi=10.1.1.231.3742\r\n[2] https://sites.google.com/site/anrasfalda/\r\n\r\n\r\nDurée du stage : 4 à 6 mois\r\n\r\nFormation souhaitée : Master 1 ou 2, Ingénieur 2° ou 3° année.\r\n\r\nContact:\r\nGaël de Chalendar\r\nMail : Gael.de-Chalendar@cea.fr\r\nTél. : 01 69 08 01 50'),
(168, '2013-03-07', 'LIMSI', 'Orsay', 'Titre : Définition et structuration de notions de cours pour l\'EIAH\r\n\r\nContexte:\r\nAfin d\'exploiter au mieux les informations disponibles sous forme\r\ntextuelle, semi-structurée (Wikipédia), ou structurée (sémantique, base\r\nde données...), il est nécessaire de créer de nouveaux outils qui ne\r\nconsidèrent pas le document comme un tout, mais qui permettent d\'accéder\r\nà la connaissance qu\'il véhicule. De ce fait, nous nous proposons de\r\nconsidérer tous ces documents comme des sources de connaissances : il\r\ns\'agit de pouvoir les analyser dans le but d\'en extraire des objets de\r\nconnaissances réutilisables par des processus automatiques, et ce dans\r\nle cadre des environnements numériques de travail.\r\nNous nous focaliserons sur une tâche précise dans le cadre de systèmes\r\nde question-réponse appliqués aux Environnements Informatiques pour\r\nl\'Apprentissage Humain (EIAH) : engendrer des questionnaires ouverts et\r\nfermés en langue naturelle à partir et sur des documents et en corriger\r\nles réponses données.\r\nL\'objectif du stage est de pouvoir travailler sur le volet annotation de\r\ndocuments afin d\'en extraire une connaissance structurée.\r\n\r\nObjectif :\r\nProduire des objets d\'enseignements structurés correspondant à des \r\nnotions importantes pour  le domaine enseigné et les caractériser en \r\nfonction de leur rôle dans l\'enseignement de la matière et l\'évaluation \r\ndes apprenants.\r\nCe stage se décomposera en plusieurs étapes :\r\n\r\n1) Détermination des concepts de l\'étude: choisir les concepts du\r\ndomaine auxquels on s\'intéresse (nous nous intéresserons plus\r\nparticulièrement à l\'enseignement des bases de données en informatique),\r\npuis les définir par des propriétés que l\'on cherchera à renseigner par\r\nl\'analyse automatique des documents de cours (cf. étape 2)\r\n\r\n2) Structuration des connaissances par :\r\n- annotation de passages de documents par les concepts étudiés et le\r\n  type de présentation de ces notions (définition, explication, exemple,\r\n  etc);\r\n- classification de ces concepts sur une échelle de difficulté et\r\n  granularité\r\n- création d\'un graphe de prérequis.\r\n\r\nMots-clefs: Traitement automatique de la langue, annotation sémantique,\r\nontologie, environnement numérique pour l\'enseignement, apprentissage\r\n\r\nLieu : LIMSI, Orsay\r\nContact : Brigitte Grau bg[at]limsi.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(169, '2013-03-11', 'Laboratoire d\'Informatique de Tours', 'Blois', 'Proposition de stage : Évaluation de ressources et traitements\r\ncomplémentaires pour la reconnaissance d\'entités nommées\r\n\r\nCONTEXTE\r\n\r\nLa reconnaissance automatique des entités nommées (personnes, lieux,\r\norganisation, unités de temps, montants, etc.) est une tâche centrale\r\npour la recherche d\'information. Dans ce cadre, les nombreux travaux\r\nmenés sur ce sujet au sien de l\'équipe BDTLN du LI (université de Tours)\r\nont conduit à l\'implémentation de deux systèmes :\r\n- CasEN, orientés connaissances (transducteurs) [Friburger 2002]\r\n- mXS, orientés données (motifs) [Nouvel 2012]\r\n\r\nCes deux systèmes sont en cours d\'évaluation dans le cadre de la\r\ncampagne Etape (http://www.afcp-parole.org/etape.html en cours\r\nd\'adjudication). Ils reposent sur une base lexicale commune faite de\r\nressources construites semi-automatiquement [Tran & Maurel 2006], dont\r\nProlex ( http://www.cnrtl.fr/lexiques/prolex/). Dans la lignée des\r\ntravaux de [Bunescu & Pasca 2006] et [Charton & Torres-Moreno 2009],\r\nnous avons développé un outil afin d\'extraire automatiquement des\r\nressources lexicales à partir de Wikipedia. Enfin, des expériences\r\npréliminaires ont été menées dans le cadre du projet Ancor\r\n(http://tln.li.univ-tours.fr/Tln_Ancor.html) afin de déterminer les\r\ninteractions qui existent entre les les entités nommées et les\r\nanaphores.\r\n\r\nSUJET DE STAGE\r\n\r\nLe stage proposé vise en premier lieu à déterminer les gains réalisés\r\npar les deux systèmes lors de l\'enrichissement des ressources\r\nlexicales. Il s\'agit donc de manipuler les divers outils et systèmes à\r\ndisposition et de réaliser des évaluations comparatives afin de\r\ndéterminer, dans le cadre d\'Etape (émissions télévisuelles et\r\nradiodiffusées), quelles ressources ont le plus intérêt à être\r\ncomplétées, quelles configurations sont les plus avantageuses, quels\r\nsont les avantages et les inconvénients de chaque approche.\r\n\r\nDe manière plus exploratoire, l\'étudiant sera amené à approfondir nos\r\ntravaux sur les interactions entre reconnaissance d\'entités nommées et\r\nrésolution d\'anaphores. Il s\'agira autant d\'établir une base de travail\r\npour l\'évaluation des systèmes de résolution de coréférences, que\r\nd\'étudier en quoi les mécanismes anaphoriques peuvent aider pour la\r\nreconnaissance des entités nommées et/ou inversement.\r\n\r\nCONDITIONS ET CANDIDATURE\r\n\r\nLe candidat sélectionné devra disposer de solides compétences en\r\ninformatique (programmation Java et scripts Python / Shell) et avoir un\r\nintérêt pour le traitement automatique des langues. Une attention\r\nparticulière sera portée aux capacités à mener des évaluation sur corpus\r\n(outils d\'évaluation, benchmarks, significativité). Des connaissances en\r\nfouille de données (text mining) et/ou en paramétrage de systèmes à base\r\nd\'automates seront un plus.\r\n\r\nDates et durée : courant mars / début avril, pour 3 mois minimum\r\nLieu d\'exercice : campus de Blois (antenne universitaire, 3 place\r\nJean-Jaurès)\r\nRémunération : maximale prévue selon la réglementation 436,05 ¤ par mois\r\n(assurée dans le cadre d\'un projet industriel financé par la société\r\nBAMSOO).\r\n\r\nMerci d\'envoyer un CV détaillé de vos activités passées, accompagné\r\nd\'une lettre de motivation et de vos relevés de notes des deux dernières\r\nannées d\'études à :\r\n- Nathalie Friburger nathalie.friburger@univ-tours.fr ,\r\n- Damien Nouvel damien.nouvel@inria.fr ,\r\n- Jean-Yves Antoine jean-yves.antoine@univ-tours.fr .\r\n\r\nBIBLIOGRAPHIE\r\n\r\n[Bunescu & Pasca 2006] Using Encyclopedic Knowledge for Named entity\r\nDisambiguation. R.C. Bunescu M. Pasca. EACL (2006).\r\n[Charton & Torres-Moreno 2009] Classification d\'un contenu\r\nencyclopédique en vue d\'un étiquetage par entités nommées. E. Charton,\r\nJ.M. Torres-Moreno.  TALN (2009)\r\n[Friburger 2002] Reconnaissance automatique des noms propres :\r\napplication à la classification automatique de textes\r\njournalistiques. Nathalie Friburger. Thèse de doctorat (2002).\r\n[Friburger & Maurel 2004] Finite-state transducer cascades to extract\r\nnamed entities in texts. Nathalie Friburger and Denis Maurel. TCS:313\r\n(2004).\r\n[Nouvel 2012] Reconnaissance des entites nommees par exploration de\r\nregles d\'annotation. Damien Nouvel. Thèse de doctorat (2012).\r\n[Tran & Maurel 2006] Prolexbase - Un dictionnaire relationnel\r\nmultilingue de noms propres. Mickäel Tran, Denis Maurel. TAL:47-3\r\n(2006).'),
(170, '2013-03-18', 'LexisNexis', 'Paris', 'LexisNexis en France (600 collaborateurs, 140 M¤ de CA), filiale du\r\ngroupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les\r\nservices d\'information professionnelle. Ses activités couvrent trois\r\ndomaines : l\'information et l\'édition juridiques, la diffusion de la\r\npresse et de l\'information économique et financière sur Internet, les\r\nlogiciels professionnels.\r\n\r\nL\'entreprise s\'appuie sur une expertise éditoriale centenaire et sur une\r\ntechnologie de pointe pour apporter au monde du droit et aux\r\nprofessionnels de tous secteurs d\'activités une vaste gamme de produits\r\net services réputés : JurisClasseur, Litec, D.O, Bottin Administratif et\r\nles services en ligne LexisNexis.\r\n\r\nMission :\r\n\r\nIntégré(e) à l\'équipe « Management de l\'information» votre mission\r\nconsistera à participer aux activités relatives au textmining, qui\r\ntraitent de l\'extraction d\'information juridique à valeur ajoutée.\r\n\r\nProfil :\r\n\r\nMaster 2 en linguistique informatique\r\n\r\nVous êtes d\'une nature rigoureuse et méticuleuse\r\n\r\nConnaissance d\'Unitex obligatoire\r\n\r\nNiveau d\'étude :\r\nMaster 1 ou 2 / stage de fin d\'étude.\r\n\r\nLIEU : \r\n141 rue de Javel\r\n75015 PARIS\r\n\r\nDUREE : \r\n5-6 mois à partir de avril 2013\r\n\r\nMerci d\'envoyer votre candidature (CV + lettre de motivation) ainsi que\r\nvos disponibilités par mail à : celine.aubier@lexisnexis.fr'),
(171, '2013-03-27', 'CEA - LIST', 'Gif-sur-Yvette', 'Proposition de stage : Construction automatique de lexiques bilingues à\r\nl\'aide d\'outils d\'alignement de mots à partir de corpus de textes\r\nparallèles et comparables\r\n\r\nLieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie\r\ndes Contenus (LVIC), 91 191 Gif sur Yvette\r\n\r\nCONTEXTE :\r\n\r\nLes dictionnaires bilingues jouent un rôle important dans les\r\napplications de Traitement Automatique de la Langue (TAL) telles que la\r\nTraduction Automatique (TA) et la Recherche d\'Information Interlingue\r\n(RII). La quantité de travail nécessaire pour créer manuellement ces\r\ndictionnaires est très importante. C\'est la raison pour laquelle depuis\r\nquelques années de nombreux travaux ont fait appel aux techniques\r\nd\'alignement pour automatiser le processus de construction de\r\ndictionnaires bilingues. Ces techniques constituent un préalable à\r\nl\'exploitation des corpus de textes parallèles [Melamed, 2001] : qu\'il\r\ns\'agisse d\'aligner au niveau des paragraphes, des phrases ou d\'apparier\r\ndes unités lexicales, la plupart des applications reposent sur la\r\npossibilité d\'extraire des correspondances précises entre les textes\r\nsource et cible.\r\n\r\nSUJET DE STAGE :\r\n\r\nLe stage consistera, d\'une part, à constituer un alignement de référence\r\npour les mots simples et les expressions polylexicales à l\'aide de\r\nl\'outil Yawat [Germann, 2008], et d\'autre part, à évaluer les outils\r\nd\'alignement de mots [Mihalcea & Pedersen, 2003] [Carpuat & Diab, 2010]\r\nà partir de corpus de textes parallèles ou comparables développés au\r\nLaboratoire Vision et Ingénierie des Contenus (LVIC) du CEA-LIST\r\n[Bouamor et al., 2012]. Cette évaluation sera réalisée selon deux\r\napproches différentes : une évaluation intrinsèque à petite échelle dans\r\nlaquelle les lexiques bilingues construits automatiquement seront\r\ncomparés à un alignement de référence créé manuellement et une\r\névaluation extrinsèque dans laquelle l\'impact d\'utilisation de ces\r\nlexiques bilingues sera étudié dans un système de traduction automatique\r\nstatistique [Ren et al., 2009] et un moteur de recherche d\'information\r\ninterlingue.\r\n\r\nLe stage comportera les étapes suivantes:\r\n\r\n- Appropriation des principaux outils d\'alignement de mots à partir de\r\n  corpus de textes parallèles ou comparables développés au LVIC.\r\n\r\n- Constitution de deux lexiques bilingues de référence : un pour les\r\n  mots simples et l\'autre pour les expressions polylexicales.\r\n\r\n- Mise en place d\'outils d\'évaluation du module d\'alignement de mots\r\n  simples et d\'expressions polylexicales.\r\n\r\n- Spécification et implémentation d\'un module pour le filtrage des\r\n  lexiques bilingues construits automatiquement.\r\n\r\n- Développement d\'une interface web pour l\'administration et la gestion\r\n  de dictionnaires multilingues.\r\n\r\nBIBLIOGRAPHIE :\r\n\r\n- Bouamor D., Semmar N., Zweigenbaum P., \"Identifying bilingual\r\n  Multi-Word Expressions for Statistical Machine Translation\",\r\n  Proceedings of the Eight International Conference on Language\r\n  Resources and Evaluation (LREC\'12), Turkey, 2012.\r\n\r\n- Germann U., \"Yawat: Yet Another Word Alignment Tool\", Proceedings of\r\n  the ACL-08, Columbus, 2008.\r\n\r\n- Melamed I.D., \"Empirical Methods for Exploiting Parallel Texts\", MIT\r\n  Press, 2001.\r\n\r\n- Mihalcea R., Pedersen T., \"An evaluation exercise for word alignment\",\r\n  Proceedings of HLT-NAACL 2003 Workshop on Building and using parallel\r\n  texts: data driven machine translation and beyond, Canada, 2003.\r\n\r\n- Ren Z., Lu Y., Liu Q., Huang Y., \"Improving statistical machine\r\n  translation using domain bilingual multiword expressions\", Proceedings\r\n  of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP 2009,\r\n  Singapore, 2009.\r\n\r\n- Carpuat M., Diab M., \"Task-based Evaluation of Multiword Expressions:\r\n  a Pilot Study in Statistical Machine Translation\", Proceedings of\r\n  NAACL, Los Angeles, 2010.\r\n\r\nCONDITIONS DE CANDIDATURE :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du Traitement Automatique de\r\nla Langue (TAL).\r\n\r\nCompétences en informatique et en TAL.\r\n\r\nProgrammation : C++, Perl ou équivalent.\r\n\r\nLangues : Maîtrise de l\'anglais et du français, la connaissance de la\r\nlangue arabe est un plus.\r\n\r\nDurée : entre 4 et 6 mois.\r\n\r\nContact et envoi des candidatures (CV détaillé, lettre de motivation et\r\nrelevés de notes des deux dernières années d\'études):\r\n\r\nNasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr\r\n\r\nNasredine SEMMAR\r\nCEA Saclay Nano-INNOV\r\nInstitut CARNOT CEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus (LVIC)\r\nPoint courrier n°173\r\n91191 Gif-sur-Yvette CEDEX\r\nTel: +33 (0)1 69 08 01 46\r\nFax: +33 (0)1 69 08 01 15\r\nEmail: nasredine.semmar@cea.fr'),
(172, '2013-04-08', 'LIMSI', 'Orsay', 'Proposition de stage M1 ou M2 au LIMSI-CNRS\r\nGroupe Traitement du Langage Parlé (http://www.limsi.fr/tlp/) à Orsay\r\n\r\nResponsable du stage : Marianna Apidianaki (CNRS-LIMSI, groupe TLP)\r\n\r\n\r\nTitre : Acquisition de connaissances sémantiques à partir de corpus\r\nparallèles\r\n\r\nLes corpus parallèles multilingues offrent une solution peu coûteuse à\r\nl\'acquisition de connaissances sémantiques. Les différentes méthodes\r\nproposées dans ce but se basent principalement sur des informations\r\ntraductionnelles (Dyvik, 1998; Ide et al., 2002; Bannard and\r\nCallison-Burch, 2005) éventuellement combinées avec des informations du\r\ncontexte (Apidianaki, 2008; Bansal et al. 2012). Les connaissances\r\nsémantiques acquises par ces méthodes peuvent servir à des fins\r\nd\'analyse contrastive ou être exploitées dans des applications\r\nmultilingues, comme la Traduction Automatique. Néanmoins, la nature des\r\nconnaissances obtenues varie de manière importante et dépend fortement\r\ndes informations exploitées par la méthode d\'analyse sémantique\r\nemployée, des techniques utilisées et des hypothèses théoriques\r\nsous-jacentes.\r\n\r\nL\'objectif de ce stage est d\'étudier la sémantique des paraphrases\r\nacquises par une méthode basée sur une hypothèse de correspondance\r\nsémantique inter-langue, la méthode de paraphrasage par pivot\r\n(Callison-Burch, 2008). Des ressources sémantiques construites par cette\r\nméthode sont actuellement largement utilisées dans la Traduction\r\nAutomatique et son évaluation (Zhou et al. 2006; Madnani et al., 2007;\r\nSnover et al., 2009; Denkowsky and Lavie, 2010). Nous sommes intéressés\r\nà examiner la pertinence des descriptions sémantiques engendrées en\r\nexpérimentant avec différentes méthodes de clustering sémantique et de\r\nreprésentation des connaissances. Les résultats de l\'étude permettront\r\nd\'identifier les cas nécessitant une analyse plus poussée et d\'estimer\r\nleur impact dans la Traduction Automatique et son évaluation.\r\n\r\nLe stage est rémunéré et se déroulera au LIMSI-CNRS (Orsay) dans\r\nl\'équipe Traitement du Langage Parlé (http://www.limsi.fr/tlp).\r\n\r\nProfil : \r\n- Master 1 ou 2 en Traitement Automatique des Langues ou Informatique\r\n- bonnes compétences en programmation\r\n- connaissances en apprentissage automatique (clustering) \r\n- expérience avec des systèmes de Traduction Automatique serait un plus\r\n\r\nDurée : 4 mois (plein temps)\r\nDate de début : dès disponibilité\r\nLieu : LIMSI-CNRS, Groupe TLP, rue John von Neumann, Université Paris\r\nSud, 91403 Orsay Cedex\r\n\r\nRémunération : le/la stagiaire recevra la gratification CNRS standard\r\n(environ 400 euros par mois)\r\n\r\nContact: Marianna Apidianaki (marianna@limsi.fr)'),
(173, '2013-09-16', 'Reverso', 'Neuilly', 'Stage linguiste / terminologue / traducteur\r\n\r\nType de contrat : Stage de césure ou de fin d\'études (minimum 4 mois) ou\r\nstage longue durée à temps partiel\r\n\r\nLieu : Neuilly-sur-Seine\r\n\r\nIndemnité de stage : Selon durée et expérience\r\n\r\nDébut : Dès que possible\r\n\r\nENTREPRISE\r\n\r\nEditeur de logiciels à rayonnement international, Reverso-Softissimo est\r\nl\'un des leaders mondiaux des solutions Intranet et Internet de\r\ntraduction instantanée et de dictionnaires électroniques.\r\n\r\nSon portail grand public dédié aux langues www.reverso.net génère un\r\ntrès fort trafic avec 200 millions de pages vues par mois et plus de 6\r\nmillions de visiteurs uniques.\r\n\r\nReverso-Softissimo recherche un(e) linguiste pour participer aux travaux\r\nde production et de recherche de notre équipe linguistique dans un\r\ncontexte professionnel motivant : haute technologie, forte croissance et\r\ndéveloppement international.\r\n\r\nVous êtes intéressé(e) par notre domaine ? C\'est le moment de rejoindre\r\nnotre équipe !\r\n\r\nMISSION\r\n\r\nSous la direction du chef de projet linguistique, le stagiaire\r\neffectuera les missions suivantes :\r\n\r\n- création, mise à jour, validation de dictionnaires bilingues ;\r\n\r\n- tests de la qualité de traduction et rédaction de rapports d\'analyse ;\r\n\r\n- recherche, évaluation et analyse de ressources terminologiques ;\r\n\r\n- animation et développement de la communauté d\'utilisateurs du\r\n  dictionnaire collaboratif.\r\n\r\nCette liste n\'est pas exhaustive et pourra être amenée à évoluer en\r\nfonction de l\'implication du/de la stagiaire.\r\n\r\nPROFIL\r\n\r\nÉtudiant(e) en dernière année d\'une école ou d\'une université en TAL,\r\nlangues étrangères, linguistique, ingénierie linguistique ou traduction,\r\nvous maîtrisez parfaitement l\'anglais et le français à l\'oral comme à\r\nl\'écrit, et idéalement une troisième langue.\r\n\r\nVous avez des qualités rédactionnelles ainsi qu\'une grande rigueur, une\r\nbonne méthodologie, un esprit logique et des capacités d\'analyse et de\r\nsynthèse ; votre sens de l\'initiative, votre dynamisme et votre\r\nautonomie seront également des qualités appréciées dans le cadre de ce\r\nstage.\r\n\r\nContact :\r\n\r\nJuliette MORNET\r\njmornet@reverso.com'),
(174, '2013-10-07', 'CEA LIST', 'Saclay', 'INTRODUCTION\r\nDans le cadre de la thèse de Quentin Pradet, sous la direction du\r\nPr. Laurence Danlos et du Dr. Gaël de Chalendar, le CEA LIST et l\'INRIA\r\nALPAGE ont entamé l\'adaptation au français de la ressource\r\nlexico-syntaxique VerbNet. Le présent stage qui s\'adresse à des\r\nétudiants en linguistique se spécialisant en lexicographie vise à\r\ncontribuer à cette traduction.\r\n\r\nCONTEXTE\r\nVerbNet est une ressource lexicale pour les verbes anglais organisée\r\nautour de classes sémantiques et de sous-classes syntaxiques. Cette\r\nressource est très utilisée, notamment pour l\'annotation en rôles\r\nsémantiques. Il paraît donc nécessaire d\'avoir une ressource équivalente\r\npour le français. Les seuls efforts qui ont été faits pour l\'instant se\r\nlimitent à des constructions automatiques bruitées dont l\'évaluation se\r\nlimite à quelques verbes. De plus ces efforts font abstraction des\r\nressources lexicales qui existent pour le français, or celles-ci\r\nexistent et sont de qualité. Pour les verbes, nous pensons en\r\nparticulier à LVF+1, au Lexique-Grammaire et à Dicovalence. Nous avons\r\ndonc l\'objectif de réaliser un VerbeNet du français semi-automatiquement\r\nen nous appuyant sur ces ressources, en particulier sur LVF+1 et LG, la\r\npremière plus centrée sur les informations sémantiques, la seconde sur\r\nles informations syntaxiques. Ce VerbeNet garde la hiérarchie des\r\nclasses sémantiques du VerbNet anglais, ce qui permet de garder à\r\nl\'identique les informations sémantiques, entre autres les rôles\r\nthématiques.\r\n\r\nOBJECTIFS\r\nLa partie automatique exploitant les liens disponibles entre ressources\r\net un réseau lexico-syntaxique est terminée. Le but de ce stage est de\r\nparticiper en collaboration étroite avec Laurence Danlos et Quentin\r\nPradet à la correction manuelle de la ressource à l\'aide d\'une interface\r\nWeb développée en interne.  Pour chaque classe ou sous-classe VerbNet,\r\non dispose des constructions syntaxiques possibles en anglais, des liens\r\nobtenus automatiquement avec les classes LVF+1 et LG correspondantes et\r\nd\'une liste de verbes pouvant appartenir à cette classe. Le travail\r\nconsiste en l\'édition des frames lexico- syntactico-sémantiques en\r\nréorganisant si nécessaire la hiérarchie de classes, en acceptant ou\r\nrefusant les verbes proposés, en modifiant les constructions syntaxiques\r\net en traduisant les exemples.\r\n\r\nCANDIDAT\r\nNous recherchons pour ce stage un étudiant en linguistique se\r\nspécialisant en lexicographie.\r\n\r\nCONTACT\r\nGaël de Chalendar\r\ngael.de-chalendar@cea.fr\r\n01 69 08 01 50'),
(175, '2013-10-14', 'SFL', 'Paris', 'ANNOTATION DE LA GESTUALITÉ (logiciel : ELAN)\r\nStagiaire : contrat à temps plein (durée : 3 mois).\r\nProfil : niveau Master.\r\nDébut du contrat : février 2014.\r\n\r\nCONTEXTE\r\nLe projet européen CorpAGEst porte sur l\'étude du langage de personnes\r\nâgées, à partir de l\'analyse d\'entretiens enregistrés sur support\r\naudiovisuel (approche multimodale : texte, son, geste). Plusieurs\r\nquestions sont au c½ur du projet, telles que : « Que nous apprend\r\nl\'emploi de marqueurs de discours à haut potentiel d\'expressivité (par\r\nex. \'m\'enfin\') et d\'interactivité (par ex.  \'tu vois\') sur l\'habileté\r\nempathique des personnes âgées ? Une préférence pour l\'un ou l\'autre\r\nmode langagier (verbal ou non verbal) serait-elle le signe d\'une\r\nstratégie adoptée par la personne âgée pour compenser un déficit de sa\r\ncompétence communicative ? ». Les analyses porteront en particulier sur\r\nles marqueurs de discours et les gestes dont la fonction communicative\r\nest (inter)subjective (par ex. : le marqueur de discours tu vois ou un\r\nregard vers l\'interlocuteur). Par ce biais, il s\'agira, d\'une part, de\r\nvoir comment les personnes âgées expriment leurs points de vue et leurs\r\némotions (fonction subjective du langage) et, d\'autre part, d\'examiner\r\nla manière dont elles interagissent avec autrui en situation de\r\ncommunication réelle (fonction intersubjective du langage).\r\n\r\nPROJET EUROPÉEN MARIE-CURIE\r\nLe projet de recherche CorpAGEst « Approche sur corpus de la compétence\r\npragmatique des personnes âgées » est un projet européen financé par les\r\nActions Marie Curie dans le cadre du 7e European Community Framework\r\nProgramme (projet N° 328282, FP7-PEOPLE-2012-IEF). Durée du projet : 2\r\nans (2013-2015).\r\n\r\nLIEU\r\nLe projet est coordonné au sein de l\'unité UMR 7023 (SFL : Structures\r\nFormelles du Langage) à Paris 8 (site Pouchet), par Catherine Bolly\r\n(CNRS & Université catholique de Louvain) et Dominique Boutet\r\n(Université d\'Evry-Val d\'Essonne & UMR 7023 SFL).\r\n\r\nMISSION\r\n\r\nLa méthode d\'analyse sur corpus multimodal adoptée implique la\r\nconstitution et l\'annotation d\'un corpus audiovisuel : 8 sujets d\'étude,\r\nenv. 13 heures.  La personne recrutée aura pour tâche d\'annoter les\r\ncorpus vidéo au niveau mimo-gestuel, au moyen du logiciel ELAN, sur la\r\nbase d\'un schéma d\'annotation préétabli. Des discussions et échanges\r\ndynamiques au sein de l\'équipe permettront d\'optimiser la procédure\r\nd\'annotation sur la base de l\'expérience de chacun.\r\nLa période de stage inclut une période de formation aux fonctions de\r\nbase du logiciel d\'annotation ELAN et une période consacrée à\r\nl\'annotation des données visuelles.\r\n\r\nCOMPÉTENCES/PRÉREQUIS\r\nFamiliarité avec les outils informatiques de base (traitements de texte,\r\nclavier, etc.). Expérience appréciée dans l\'analyse impliquant la\r\nmultimodalité.\r\nDes connaissances en annotation de corpus seraient un plus.\r\n\r\nPROFIL\r\nÉtudiant en Master, dans le domaine des sciences humaines (langues et\r\nlettres, sciences du langage, sciences de la communication, traitement\r\nautomatique du langage, ethnologie, etc.).\r\nIntérêt pour les sciences du langage, la multimodalité et/ou le\r\nvieillissement langagier.\r\n\r\nDURÉE ET CONDITIONS\r\n\r\nStage de 3 mois à temps plein à partir de février 2014 (avec\r\nprolongation possible) au sein du laboratoire de linguistique (SFL, 59\r\nrue Pouchet à Paris) auprès d\'une chercheuse en sciences du langage.\r\nFlexibilité et adaptabilité des horaires.\r\nPossibilité d\'intégrer le travail dans le cadre d\'un mémoire de Master\r\n(à négocier).\r\n\r\nRÉMUNÉRATION\r\n436,05¤ net par mois.\r\n\r\nCANDIDATURE\r\nLettre de motivation et CV.\r\nA envoyer pour le 15 novembre 2013 au plus tard.\r\n\r\nCONTACTS\r\ncatherine.bolly@uclouvain.be\r\ncatherine.bolly@sfl.cnrs.fr\r\ndominique_jean.boutet@orange.fr'),
(176, '2013-10-14', 'SFL', 'Paris', 'TRANSCRIPTION DE L\'ORAL (logiciels : Praat/Exmaralda)\r\nStagiaire : contrat à temps plein (durée : 3 mois).\r\nProfil : niveau Master.\r\nDébut du contrat : février 2014.\r\n\r\nCONTEXTE\r\nLe projet européen CorpAGEst porte sur l\'étude du langage de personnes\r\nâgées, à partir de l\'analyse d\'entretiens enregistrés sur support\r\naudiovisuel (approche multimodale : texte, son, geste). Plusieurs\r\nquestions sont au c½ur du projet, telles que : « Que nous apprend\r\nl\'emploi de marqueurs de discours à haut potentiel d\'expressivité (par\r\nex. \'m\'enfin\') et d\'interactivité (par ex.  \'tu vois\') sur l\'habileté\r\nempathique des personnes âgées ? Une préférence pour l\'un ou l\'autre\r\nmode langagier (verbal ou non verbal) serait-elle le signe d\'une\r\nstratégie adoptée par la personne âgée pour compenser un déficit de sa\r\ncompétence communicative ? ». Les analyses porteront en particulier sur\r\nles marqueurs de discours et les gestes dont la fonction communicative\r\nest (inter)subjective (par ex. : le marqueur de discours tu vois ou un\r\nregard vers l\'interlocuteur). Par ce biais, il s\'agira, d\'une part, de\r\nvoir comment les personnes âgées expriment leurs points de vue et leurs\r\némotions (fonction subjective du langage) et, d\'autre part, d\'examiner\r\nla manière dont elles interagissent avec autrui en situation de\r\ncommunication réelle (fonction intersubjective du langage).\r\n\r\nPROJET EUROPÉEN MARIE-CURIE\r\nLe projet de recherche CorpAGEst « Approche sur corpus de la compétence\r\npragmatique des personnes âgées » est un projet européen financé par les\r\nActions Marie Curie dans le cadre du 7e European Community Framework\r\nProgramme (projet N° 328282, FP7-PEOPLE-2012-IEF). Durée du projet : 2\r\nans (2013-2015).\r\n\r\nLIEU\r\nLe projet est coordonné au sein de l\'unité UMR 7023 (SFL : Structures\r\nFormelles du Langage) à Paris 8 (site Pouchet), par Catherine Bolly\r\n(CNRS & Université catholique de Louvain) et Dominique Boutet\r\n(Université d\'Evry-Val d\'Essonne & UMR 7023 SFL).\r\n\r\nMISSION\r\nLa méthode d\'analyse sur corpus multimodal adoptée implique la\r\nconstitution et l\'annotation d\'un corpus audiovisuel : 8 sujets d\'étude,\r\nenv. 13 heures.  La personne recrutée aura pour tâche de transcrire, au\r\nmoyen du logiciel Exmaralda ou Praat, les données audio des entretiens\r\neffectués sur le terrain.  Les normes de transcription suivront\r\nl\'orthographe standard du français et les conventions de transcription\r\ndu centre Valibel (Université catholique de Louvain). Des discussions et\r\néchanges dynamiques au sein de l\'équipe permettront d\'optimiser la\r\nprocédure de transcription sur la base de l\'expérience de chacun. La\r\npériode de stage inclut une période de formation aux fonctions de base\r\ndes logiciels Exmaralda et Praat. Une réflexion sera notamment menée en\r\ncommun autour des fonctionnalités proposées respectivement par chacun de\r\nces logiciels.\r\n\r\nCOMPÉTENCES/PRÉREQUIS\r\nFamiliarité avec les outils informatiques de base (traitements de texte,\r\nclavier, etc.).\r\nExpérience appréciée dans l\'analyse impliquant le langage oral.\r\nDes connaissances en transcription et annotation de corpus oraux\r\nseraient un plus.\r\n\r\nPROFIL\r\nÉtudiant en Master, dans le domaine des sciences humaines (langues et\r\nlettres, sciences du langage, sciences de la communication, traitement\r\nautomatique du langage, ethnologie, etc.).\r\nIntérêt pour les sciences du langage, le français parlé et/ou le\r\nvieillissement langagier.\r\n\r\nDURÉE ET CONDITIONS\r\nStage de 3 mois à temps plein à partir de février 2014 au sein du\r\nlaboratoire de linguistique (SFL, 59 rue Pouchet à Paris) auprès d\'une\r\nchercheuse en sciences du langage.\r\nFlexibilité et adaptabilité des horaires.\r\nPossibilité d\'intégrer le travail dans le cadre d\'un mémoire de Master\r\n(à négocier).\r\n\r\nRÉMUNÉRATION\r\n436,05¤ net par mois.\r\n\r\nCANDIDATURE\r\nLettre de motivation et CV.\r\nA envoyer pour le 15 novembre 2013 au plus tard.\r\n\r\nCONTACTS\r\ncatherine.bolly@uclouvain.be\r\ncatherine.bolly@sfl.cnrs.fr\r\ndominique_jean.boutet@orange.fr'),
(177, '2013-10-24', 'LIDILEM', 'Grenoble', 'Stage de recherche M1 ou M2 Traitement automatique des langues,\r\nLexicographie ou Linguistique appliquée\r\n\r\nDéveloppement d\'un dictionnaire électronique de collocations du\r\nlangage scientifique\r\n\r\nLieu : LIDILEM, Université Grenoble 3 - Stendhal, \r\nDurée : de 3 à 5 mois, \r\nPériode : janvier à juin 2014.\r\n\r\nStage rémunéré : indemnité (436 euros/mois)\r\n\r\nPersonnes à contacter : Agnès Tutin (agnes.tutin@u-grenoble3.fr),\r\nOlivier Kraif (olivier.kraif@u-grenoble3.fr)\r\n\r\nDans le cadre du projet Termith (Projet ANR-Content :\r\nhttp://www.atilf.fr/ressources/termith/) impliquant plusieurs\r\nlaboratoires de recherche (ATILF, LINA, INRIA, LORIA, LIDILEM), nous\r\nsouhaitons élaborer un lexique d\'expressions spécifiques du français\r\nscientifique, par exemple faire une hypothèse, en premier lieu,\r\ncontrairement à nos attentes ...\r\n\r\nCette phraséologie transdisciplinaire des écrits scientifiques\r\ntraverse en large partie les disciplines et est surreprésentée dans ce\r\ngenre (Pecman 2007 ; Tutin 2007 ; Granger & Paquot 2010). Dans le\r\ncadre du projet Termith, ces expressions seront utilisées dans un\r\nsystème d\'indexation automatique des écrits scientifiques afin de\r\nmieux repérer les concepts spécifiques des textes.\r\n\r\nDans cette phraséologie, les collocations, ici définies comme des\r\nassociations binaires privilégiées et compositionnelles sur le plan\r\nsémantique, constituent les expressions les plus productives. Il\r\ns\'agit d\'expressions comme faire une hypothèse, résultats\r\nencourageants, hypothèse de travail, etc.\r\n\r\nLe sujet du stage consistera à adapter un format d\'encodage pour ces\r\nexpressions à partir des extractions effectuées automatiquement d\'un\r\ngrand corpus d\'écrits scientifiques. L\'extraction sera réalisée\r\nsemi-automatiquement dans notre équipe à partir d\'un corpus analysé\r\nsyntaxiquement en dépendances en utilisant des mesures d\'association\r\n(Kraif & Diwersy 2012 ; Cf aussi Seretan 2010). Le stagiaire sera\r\nchargé de réfléchir au codage linguistique des propriétés pertinentes\r\nà associer à ces collocations (Tutin 2004) (alternances syntaxiques,\r\ndétermination, information d\'usage) à partir des observations en\r\ncorpus, de sélectionner les collocations adaptées et de proposer une\r\nadaptation pour ces expressions du standard Lexical Markup Framework\r\n(Francopoulo et al. 2006).\r\n\r\nFrancopoulo, G., George, M., Calzolari, N., Monachini, M., Bel, N.,\r\nPet, M., & Soria, C. (2006). Lexical markup framework (LMF). In\r\nInternational Conference on Language Resources and Evaluation-LREC\r\n2006.\r\n\r\nGranger, S., Paquot, M., (2010. The Louvain EAP Dictionary (LEAD) »,\r\nProceedings of the XIV EURALEX International Congress , Leeuwarden\r\n(The Netherlands), 6-10 July 2010, 321-326.\r\n\r\nKraif. O & Diwersy S. (2012). Le Lexicoscope : un outil pour l\'étude\r\nde profils combinatoires et l\'extraction de constructions\r\nlexico-syntaxiques.  Actes de la conférence conjointe JEP-TALN-RECITAL\r\n2012, volume 2: TALN. Grenoble, France. 399-406.\r\n\r\nPecman, M. (2007) : Approche onomasiologique de la langue scientifique\r\ngénérale. Revue française de linguistique appliquée. « Lexique des\r\nécrits scientifiques », vol. XII-2. 79-96.\r\n\r\nSeretan V. (2010). Syntax-based collocation extraction.  Springer.\r\n\r\nTutin, A. (2004). Pour une modélisation dynamique des collocations\r\ndans les textes. In Proceedings of the Eleventh EURALEX International\r\nCongress, Lorient, France. 207-219.\r\n\r\nTutin, A. (2007). Lexique et écrits scientifiques. Revue française de\r\nlinguistique appliquée, 12(2).'),
(178, '2013-11-04', 'Lattice', 'Paris', 'proposition de stage M2 recherche en informatique/TAL au Lattice\r\n(http://www.lattice.cnrs.fr) à Montrouge (tout près de Paris)\r\n\r\nCe stage a pour objectifs de tester et adapter des algorithmes\r\nd\'apprentissage automatique pour le repérage des expressions\r\nréférentielles dans des textes écrits ainsi que pour l\'identification\r\ndes chaînes de coréférence. Pour ce faire, le travail s\'appuiera sur\r\nl\'exploitation d\'un corpus de petite taille, déjà annoté en référence et\r\nen coréférence (projet MC4, Modélisation Contrastive et Computationnelle\r\ndes Chaînes de Coréférence). Un premier aspect du travail consistera à\r\nfaire passer sur le texte de départ un ensemble d\'outils libres et/ou\r\ndéveloppés à Lattice : analyse morphosyntaxique, segmentation en chunk,\r\nrepérage d\'entités nommées. Les résultats obtenus permettront d\'enrichir\r\nles données initiales, qui serviront ensuite pour la deuxième étape, au\r\ncoeur du sujet, consistant à tester différentes méthodes d\'apprentissage\r\nautomatique pour l\'identification des expressions référentielles et des\r\nchaînes de coréférence (plusieurs passes pourront être nécessaires pour\r\ncela).\r\n\r\nPour que ce stage de M2 puisse s\'opérer efficacement, le candidat devra\r\navoir des connaissances solides en linguistique de corpus et traitement\r\nautomatique des langues, des compétences pour l\'écriture de scripts\r\n(PERL, PYTHON, voire JAVA : il faudra traiter des problèmes de\r\ntransformation de formats de fichiers) et des connaissances ainsi qu\'un\r\nintérêt pour les techniques d\'apprentissage automatique.\r\n\r\nLe stage peut durer de 4 à 6 mois au sein du Lattice, à partir de 2014,\r\nil sera encadré par Frédéric Landragin (http://fred.landragin.free.fr)\r\net Isabelle Tellier (http://www.lattice.cnrs.fr/sites/itellier/) et sera\r\nfinancé (au tarif stage : 1/3 Smic) par le projet ANR Orfeo\r\n(http://www.projet-orfeo.fr).\r\n\r\nenvoyer CV + lettre de motivation à frederic.landragin@ens.fr et\r\nisabelle.tellier@univ-paris3.fr'),
(179, '2013-11-09', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\n Offre de stage M2 en TAL à Syllabs (Paris)\r\n------------------------------------------------------------------------\r\n\r\n------------------------------------------------------------------------\r\nCaractérisation des objets touristiques pour l\'extraction de facettes\r\ndans le tourisme\r\n------------------------------------------------------------------------\r\n\r\nSyllabs travaille depuis un certain temps sur des outils de TAL\r\nappliqués au tourisme, que ce soit dans un contexte de web mining, de\r\ntext mining ou de production de contenus.Dans le cadre de Tourinflux,\r\nprojet de recherche multi-partenaire en cours, Syllabs doit produire des\r\nbases de connaissances se rapportant à des objets touristiques (hôtels,\r\netc.). Ce projet vise à apporter aux acteurs du tourisme (d\'abord les\r\ninstitutionnels mais aussi les acteurs privés) un ensemble d\'outils leur\r\npermettant de gérer à la fois leurs données internes et les informations\r\ndisponibles sur le web afin de mieux comprendre comment un territoire\r\nest perçu et de mieux agir sur cette perception. C\'est dans ce contexte\r\nque se situe le stage. Celui-ci comporte plusieurs étapes et\r\nobjectifs. La durée du stage ne permettra peut-être pas de tout couvrir.\r\n\r\n----------------------------\r\n Descriptif du stage\r\n----------------------------\r\n\r\n1) Modélisation d\'une base de connaissances des objets touristiques\r\n\r\n- Créer une taxonomie (simple) des différents objets touristiques et\r\n  étudier les facettes communes à plusieurs objets.\r\n\r\n- Déterminer les facettes utilisables pour la génération automatique des\r\n  descriptifs\r\n\r\n- Déterminer les facettes nécessaires pour l\'analyse d\'avis\r\n  d\'internautes\r\n\r\n2) Extraction des facettes via LOL (outil dédié à base de règles\r\n   linguistiques)\r\n\r\n- Extraction des facettes présents dans les \"descriptifs marchands\"\r\n\r\n- Extraction des facettes présents dans les \"avis internautes\"\r\n\r\n3) Création de la base à partir de la sortie d\'extraction\r\n\r\n- Créer une base de données à partir de la sortie d\'extraction,\r\n  manipulation des objets extraits\r\n\r\n4) Génération de descriptifs d\'objets touristiques\r\n\r\n- écrire des règles de génération pour 2 objets touristiques différents\r\n  en fonction de la base obtenue\r\n\r\n------------------------\r\n  Profil souhaité\r\n------------------------\r\n\r\n- Aptitude pour la représentation formelle du langage.\r\n\r\n- Excellente capacité de communication et aptitude pour le travail\r\n  d\'équipe.\r\n\r\n- Bon niveau en python serait un plus.\r\n\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture.\r\n\r\n\r\nFormation en cours : Linguistique Informatique, TAL ou similaire.\r\n\r\nDurée du stage : 6 mois (début entre janvier et avril, en fonction du\r\ncursus universitaire)\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « Stage TAL ».\r\n\r\nLieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris.\r\n\r\nContrat : stage conventionné rémunéré en fonction du niveau d\'étude.'),
(180, '2013-11-15', 'Lattice & LTCI Telecom-ParisTech', 'Paris', 'Proposition de stage de M2\r\n\r\nLaboratoire Lattice & LTCI Telecom-ParisTech\r\n\r\n\r\nTitre :\r\n\r\nModélisation d\'actes communicatifs multimodaux pour un agent\r\nconversationnel animé dans les dialogues humain-machine\r\n\r\n\r\nDescriptif :\r\n\r\nLes Agents Conversationnels Animés (ACA) sont des personnages virtuels\r\npermettant à la machine de dialoguer avec les humains de manière\r\nnaturelle. Ils peuvent prendre le rôle d\'assistant comme les agents\r\nconversationnels présents sur les sites de vente, de tuteur dans le\r\ncadre des Jeux Sérieux (Serious Games).\r\n\r\nComment obtenir chez un ACA une expression naturelle des actes\r\ncommunicatifs? Avec quelles postures, quelles expressions faciales,\r\nquels gestes, quelle intonation, doit-on faire accompagner le discours\r\nd\'un ACA dans un dialogue humain-machine ? Une attention particulière\r\nsera donnée à l\'agencement des niveaux acoustique (intonation) et visuel\r\n(geste, regard, etc.) avec les aspects linguistiques de l\'énoncé\r\n(syntaxe, sémantique).\r\n\r\nOn interrogera notamment les analyses classiques qui tendent à\r\nsimplifier, par exemple en considérant qu\'à une question est associé un\r\ncontour prosodique montant, alors qu\'un contour plat est souvent bien\r\nplus naturel. On interrogera également les matérialisations d\'un ordre\r\nen fonction du contexte socio-émotionnel : si en théorie l\'ordre fait\r\npartie des trois actes de langage classiques (par exemple au sens de la\r\nThéorie de la Pertinence, Sperber & Wilson 1995), en pratique l\'ordre\r\ndirect est ressenti comme agressif et on lui préfère un acte de langage\r\nindirect, comme une question à valeur (cachée) d\'ordre. La notion d\'acte\r\nde langage sera étendue à celle d\'acte communicatif afin d\'intégrer les\r\nmodalités non-verbales (Poggi et Pelachaud, 2000) et le sujet portera\r\nsur la modélisation des actes communicatifs multimodaux, et sur les\r\nconséquences des choix qu\'un système de dialogue humain-machine peut\r\neffectuer. Les modèles construits s\'intégreront dans la plateforme Greta\r\n(Niewiadomski et al., 2011), qui permet de communiquer avec l\'humain en\r\ngénérant chez l\'agent une large palette de comportements expressifs\r\nverbaux et non verbaux (Bevacqua et al., 2012). Plusieurs cas\r\nd\'application pourront être envisagés : dialogues d\'entraînement de\r\njeunes en insertion sociale aux entretiens d\'embauche (projet Tardis),\r\ndialogues entre un ACA et les visiteurs d\'un musée (projet A1:1)\r\n\r\n\r\n\r\nPour ce faire, le travail comportera les étapes suivantes :\r\n- Etude de dialogues Humain-Humain (TCOF, CID...), des dialogues\r\n  Humain-Machine (SCNF, CIO) et de dialogues humain-ACA multimodaux\r\n  (Corpus Semaine (Schröder et al., 2011)), en comparant les actes\r\n  communicatifs et actes de langage présents dans ces corpus et leur\r\n  réalisation verbale et non verbale.\r\n- Construction d\'un modèle spécifiant des paramètres de synthèse\r\n  multimodale retenus pour un ACA.\r\n- Vérification du modèle en situations de communication (soit simulées\r\n  soit via un paramétrage adéquat des ACA de la plateforme GRETA\r\n  (Niewiadomski et al., 2011)).\r\n\r\nCompétences requises :\r\n- Connaissances en interaction homme-machine,\r\n- Intérêt pour les aspects linguistiques et pragmatiques de la\r\n  communication,\r\n- Compétences en programmation (Java),\r\n- Bon niveau en anglais.\r\n\r\nConditions du stage :\r\n- Niveau requis : M2 ou diplôme d\'ingénieur en informatique.\r\n- Rémunération : 1/3 du SMIC.\r\n- Durée : 6 mois en commençant début 2014.\r\n- Lieu : première partie du stage au laboratoire Lattice (1 rue Maurice\r\n  Arnoux, Montrouge - métro Porte d\'Orléans ou trawmay Jean Moulin), et\r\n  deuxième partie à Telecom Paris-Tech (37 rue Dareau, Paris 14e - métro\r\n  Saint-Jacques ou Denfert).\r\n\r\nContacts :\r\n\r\nFrédéric Landragin, chercheur CNRS, laboratoire Lattice.\r\nTel: +33 (0)1 58 07 66 21\r\nE-Mail: frederic.landragin [at] ens.fr\r\n\r\nChloé Clavel, maître de conférences, GRETA team, Télécom ParisTech.\r\nTel:+33 (0)1 45 81 75 93\r\nE-Mail: chloe.clavel [at] telecom-paristech.fr\r\n\r\n\r\nRéférences :\r\n\r\nE. Bevacqua, E. de Sevin, S.J. Hyniewska, C. Pelachaud (2012), A\r\nlistener model : Introducing personality traits, Journal on Multimodal\r\nUser Interfaces, special issue Interacting ECAs, Elisabeth André, Marc\r\nCavazza and Catherine Pelachaud (Guest Editors), 6:27-38, 2012\r\nC. Kerbrat-Orecchioni (2001) Les actes de langage dans le discours.\r\nThéorie et fonctionnement, Paris : Nathan Université.\r\nF. Landragin (2013) Dialogue homme-machine. Conception et enjeux, Paris\r\n: Hermès-Lavoisier.\r\nG. McKeown, M. Valstar, R. Cowie, R., M. Pantic, M. Schroder (2012) The\r\nSEMAINE Database: Annotated Multimodal Records of Emotionally Colored\r\nConversations between a Person and a Limited Agent, IEEE Transactions on\r\nAffective Computing, Volume : 3 , Issue : 1, Page(s) : 5- 17, Jan.-March\r\n2012\r\nR. Niewiadomski, S. Hyniewska, C. Pelachaud (2011), Constraint-Based \r\nModel for Synthesis of Multimodal Sequential Expressions of Emotions, \r\nIEEE Transactions of Affective Computing, vol. 2, no. 3, 134-146, \r\nJuillet 2011\r\nPoggi , C . Pelachaud , Performative facial Expressions in Animated \r\nFaces , In J . Cassell , J . Sullivan , S . Prevost , E . Churchill ( \r\nEds .), Embodied Conversational Agents , Cambridge ( Mass .): MIT Press \r\n, 2000\r\nRiviere, J., Adam, C., Pesty, S., Pelachaud, C., Guiraud, N., Longin, \r\nD., & Lorini, E. (2011). Expressive Multimodal Conversational Acts for \r\nSAIBA Agents, 316-323.'),
(181, '2013-11-18', 'IRISA', 'Lorient', 'Proposition de stage\r\n-------------------------------\r\n\r\nProposition de stage de fin d\'études (Master, Ecole Ingénieur) en\r\ninformatique appliqué au Traitement Automatique des Langues Naturelles,\r\nd\'une durée minimale de 4 mois.\r\nTitre : Enrichissement de lexique émotionnel pour l\'informatique\r\naffective\r\n\r\nContexte scientifique\r\n--------------------------------\r\n\r\nEn collaboration avec le Laboratoire d\'Informatique de l\'Université de\r\nTours, le laboratoire IRISA, antenne de Lorient (56 - Morbihan) propose\r\nun sujet de stage dans le cadre du projet de recherche DAPAI-EMO financé\r\npar la société BAMSOO.\r\n\r\nLe projet DAPAI-EMO fait suite à un projet (EmotiRob) concernant le\r\ndéveloppement d\'un robot compagnon affectif pour des enfants en\r\nhospitalisation longue. Cette poursuite de travaux fait abstraction ici\r\nde sa dimension robotique pour se concentrer sur ses aspects liés à la\r\ncompréhension émotionnelle de la langue. Au cours du projet EmotiRob,\r\nnous avons développé EmoLogus, un système de détection des émotions qui\r\nintervient à la suite d\'un système logique de compréhension de message\r\nappelé Logus. EmoLogus utilise la structure sémantique de l\'énoncé\r\nfourni par Logus pour mettre en ½uvre un calcul de la valence\r\némotionnelle portée par l\'énoncé, c\'est-à-dire pour savoir si celui-ci\r\nporte une émotion positive, négative ou neutre. Ce calcul logique se\r\nbase principalement sur l\'utilisation de normes lexicales émotionnelles\r\nqui décrivent le système de valeurs du système : à chaque mot du\r\nvocabulaire est associée une valence (positif, neutre, négatif) et une\r\nintensité (nul, faible, fort) émotive. Le lexique émotionnel sur lequel\r\nse base le système a été élaboré en collaboration avec l\'équipe de\r\npsycholinguistique d\'Arielle Syssau, de l\'Université Montpellier 2. Basé\r\nsur des jugements évaluatifs contrôlés auprès d\'une population de test\r\néchantillonnée avec soin, il nous garantit la représentativité du\r\nsystème de valeurs d\'EmoLogus.\r\n\r\nLe système a montré une bonne robustesse de détection dans le cadre\r\nrestrictif d\'une communication enfantine. Il souffre toutefois du manque\r\nde couverture de son lexique émotionnel. A l\'heure actuelle, le système\r\nEmoLogus intègre en effet un lexique limité à un millier de mots, alors\r\nque la langue française générale compte entre 50 000 et 100 000 entrées\r\nlexicales. Dans le cadre de ce projet, nous proposons d\'utiliser des\r\ntechniques d\'extension automatique de lexique émotionnel à partir d\'une\r\nressource initiale telle que celle du système EmoLogus. Parmi les\r\nméthodes proposées pour étendre automatiquement un lexique émotionnel\r\nétendu, on distingue deux types d\'approches :\r\n\r\n- celles basées sur des réseaux sémantiques comme WordNet, où sont\r\n  décrits des relations de synonymies entre tous les mots d\'une\r\n  langue. On peut alors rechercher des synonymes des mots germes\r\n  présents dans le lexique originel et leur appliquer un algorithme de\r\n  propagation de valence,\r\n\r\n- celles basées sur des techniques d\'analyse de données sur des corpus\r\n  textuels. Dans ce second cas, on va étudier les cooccurrences de mots\r\n  dans un corpus pour calculer des similarités sémantiques (remplaçant\r\n  les liens de synonymie explicites de Wordnet) et les intégrer dans le\r\n  calcul de la valence des mots du lexique. Dans le cadre de ce stage,\r\n  on se propose ainsi d\'utiliser la technique de l\'analyse sémantique\r\n  latente (LSA : Latent Semantic Analysis) pour calculer ces proximités\r\n  sémantiques et s\'en servir pour estimer la valence d\'un mot.  Les mots\r\n  germes déjà présents dans la norme lexicale émotionnelle actuelle\r\n  serviront de base à l\'espace vectoriel sur lequel sera opérée\r\n  l\'analyse de données permettant l\'extension du lexique.\r\n\r\nCe stage visera à développer au moins une de ces deux techniques pour\r\nétendre le lexique émotionnel d\'EmoLogus, et tester l\'apport de cette\r\nextension sur un corpus de test. En cas d\'avancée significative, ce\r\ntravail pourra donner lieu à communication dans une conférence\r\nscientifique à laquelle sera invité à participer le stagiaire.\r\n\r\nTravail à réaliser\r\n----------------------\r\n\r\nLa personne recrutée sera en charge de la conception de nouvelles\r\ntechniques d\'extension de lexique émotionnel, du développement d\'un\r\nlexique à large couverture pour le système EmoLogus ainsi que de la\r\nréalisation de tests d\'évaluation du système étendu obtenu. Le stage se\r\ndéroulera en trois étapes successives :\r\n\r\n- Phase n°1 - Préparation des données (T0 - T0+1) : Veille technologie\r\n  sur le sujet, définition des formats d\'échange entre les différentes\r\n  techniques d\'extension du lexique, caractérisation d\'une ou plusieurs\r\n  application test et définition des données de test en relation et du\r\n  protocole d\'évaluation final.\r\n\r\n- Phase n°2 - Extension de lexique par relations sémantiques (T0+1 -\r\n  T0+3) : Extension du lexique germe par analyse des relations de\r\n  synonymie et d\'antinomie entre éléments (synsets) de Wordnet,\r\n  évaluation de l\'approche sur données de test (comparaison des\r\n  performances d\'EmoLogus avec ou sans le lexique étendu).\r\n\r\n- Phase n°3 - Extension de lexique par analyse de données (T0+4 - T0+6)\r\n  : Extension du lexique germe par analyse sémantique\r\n  latente. Évaluation sur tests unitaires de l\'approche, évaluation de\r\n  l\'approche sur données de test (comparaison des performances\r\n  d\'EmoLogus avec ou sans le lexique étendu). Cette phase ne sera\r\n  abordée qu\'en cas de stage de durée supérieure à quatre mois.\r\n\r\nProfil recherché\r\n---------------------\r\n\r\nLa personne recrutée sera en cycle terminal d\'études en informatique, de\r\nniveau Bac+5 (Master informatique professionnel, recherche ou\r\nindifférencié, école d\'ingénieur). Des connaissances en Traitement\r\nAutomatique des Langues et en analyse de données seront appréciées, sans\r\nêtre un pré-requis à recrutement. Dans le cas d\'un(e) étudiant(e) en\r\nMaster Recherche, le sujet de stage pourra être adapté aux attentes de\r\nl\'étudiant.\r\n\r\nRémunération\r\n------------------\r\n\r\nRémunération minimale prévue par la règlementation à savoir 436,05 ¤ par\r\nmois. Cette rémunération sera assurée dans le cadre d\'un projet\r\nindustriel financé par la société BAMSOO.\r\n\r\nDurée du stage et lieu d\'exercice\r\n------------------------------------------\r\n\r\nLa personne recrutée travaillera au sein du laboratoire IRISA, dans les\r\nlocaux de l\'ENSIBS, à Lorient (Morbihan). Il s\'intégrera dans une équipe\r\nprojet composée de Jeanne Villaneau (IRISA, équipe SEASIDE) et Jean-Yves\r\nAntoine (Laboratoire d\'Informatique de l\'Université François Rabelais de\r\nTours, équipe BDTLN).\r\n\r\nLa durée minimale de stage sera de 4 mois. Une prolongation de stage est\r\nenvisageable à la demande du stagiaire ou de son établissement.\r\n\r\nContact - Dépôts de candidature\r\n-------------------------------------------\r\n\r\nContact : Jeanne.Villaneau@univ-ubs.fr\r\n\r\nDépôt des candidatures : auprès de Jeanne Villaneau. Merci de déposer un\r\nCV détaillé de vos activités passées, accompagné d\'une lettre de\r\nmotivation et de vos relevés de notes des deux dernières années\r\nd\'études. Un développement Java sera demandé pour la sélection du\r\ncandidat.\r\n\r\nLiens utiles\r\n---------------\r\n\r\nLaboratoire LI, équipe BDTLN : \r\nhttp://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp\r\n\r\nLaboratoire IRISA, équipe SEASIDE : http://www-seaside.irisa.fr/');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(182, '2013-11-20', 'MODYCO & GREYC', 'NR', '*** Proposition de stage de M2 en TAL ***\r\n\r\nLe laboratoire MoDyCo (UMR CNRS-Université Paris Ouest Nanterre), en\r\ncollaboration avec le laboratoire GREYC (UMR CNRS-Université de Caen),\r\npropose un sujet de stage en TAL de niveau Master 2 d\'une durée minimale\r\nde 4 mois, à partir de janvier 2014.\r\n\r\nTitre : Enrichissement de ressources sémantiques pour l\'analyse de la\r\nfactualité pour des systèmes de recherche d\'information.\r\n\r\nRémunération : celle prévue par la règlementation à savoir 436,05 ¤ par\r\nmois.\r\n\r\n*- Contexte applicatif et enjeux théoriques *:\r\n\r\nL\'analyse automatique du degré de factualité des situations (ou\r\névènements) dénotées dans les textes s\'impose depuis quelques années\r\ncomme un enjeu important dans le domaine de la recherche\r\nd\'information. Parmi les applications visées : les systèmes de\r\nquestions/réponses, les moteurs de recherche et, intégrés ou non à ces\r\nderniers, les systèmes visant à proposer en sortie une visualisation des\r\ninformations sur une ligne du temps (ou *timeline*). Ces applications\r\nvisent alors à distinguer les évènements présentés comme déjà réalisés\r\net avérés des événements présentés comme incertains ou seulement\r\npossibles ou encore des événements présentés par l\'auteur d\'un texte\r\ncomme certains selon un co-énonciateur dont l\'auteur ne fait que citer\r\nles propos en montrant qu\'il n\'y adhère pas lui-même.\r\nDans une autre terminologie, on parle de l\'analyse et de la modélisation\r\ndes caractéristiques modales (voire énonciatives) des situations. Un\r\nnuméro entier de la revue *Computational Linguistics* (ModNeg, 2012) a\r\ndernièrement été consacré à cette problématique. Il met l\'accent sur sa\r\ncomplexité théorique, en termes notamment de catégorisation sémantique\r\ndes divers indices (lexicaux et grammaticaux) qui participent à\r\nl\'expression du degré de factualité d\'un évènement, celui-ci pouvant\r\nêtre passé ou à venir. Un autre aspect fondamental, encore cependant peu\r\ndécrit dans la littérature tant linguistique que TAL, a trait aux modes\r\nde calcul de ce degré étant donné plusieurs indices co-présents. Les\r\nexemples ci-après donnent un aperçu des types d\'énoncés qu\'il s\'agit de\r\npouvoir traiter en montrant la variation du statut véri-conditionnel\r\nd\'un même contenu propositionnel (<Pierre, venir>) fonction des indices\r\nsous la portée sémantique desquels il tombe :\r\n\r\n*Paul est venu*\r\n\r\n*Paul est peut-être venu*\r\n\r\n*Je crois que Paul est venu *\r\n\r\n*On dit que Paul est venu *\r\n\r\n*Il semblerait que Paul est venu *\r\n\r\n*Selon Marie, Paul est venu *\r\n\r\n*Selon Marie, Paul est sûrement venu *\r\n\r\n*Marie prétend que Paul est venu*\r\n\r\n*Paul devrait venir*\r\n\r\n*Paul doit venir*\r\n\r\n*Paul pourrait venir*\r\n\r\n*- Sujet de stage :*\r\n\r\nOn note que peu de ressources ont été élaborées pour le français jusqu\'à\r\nprésent. Le stage visera à combler en partie ce déficit et s\'intéressera\r\nà une analyse sémantique fine d\'indices lexicaux (verbes, noms,\r\nadjectifs, adverbes). Cette analyse s\'appuiera sur une méthodologie et\r\ndes ressources déjà constituées (Battistelli et Damiani, 2012, Damiani\r\net Battistelli 2013, (Enjalbert et Mathet, 2013) ainsi que sur des\r\nconceptions linguistiques issues de (Authier-Revuz, 1995) ou (Gosselin,\r\n1999). Ces ressources et cette méthodologie seront testées et évaluées\r\nsur deux types de corpus de textes dans une perspective comparationniste\r\n: des dépêches d\'agence journalistique et des news technologiques\r\npubliées sur le net. Le premier type de corpus est actuellement plus\r\nparticulièrement analysé dans le cadre d\'un système développé pour le\r\nprojet ANR ChronoLines dont MoDyCo est le pilote\r\n(http://chronolines.fr/) ; le second type de corpus est lui plus\r\nparticulièrement analysé dans le cadre d\'une application développée au\r\nsein de l\'entreprise Noopsis (http://noopsis.fr/), partenaire du\r\nlaboratoire GREYC. Le travail visera en outre à préciser les zones de\r\nrecouvrement théorique comme applicatives avec le domaine de\r\nl\'annotation des opinions (Béthard et al., 2004, Wilson et Wiebe, 2003).\r\n\r\n*- Profil du candidat:*\r\n\r\nLe candidat devra être inscrit dans un Master en traitement automatique\r\ndes langues ou en linguistique appliquée.\r\n\r\n- Compétences demandées\r\n\r\n* compétences en traitement automatique des langues et/ou en\r\n  linguistique.\r\n\r\n* compétences de base en informatique et plus spécifiquement maitrise\r\n  des langages de type perl et python.\r\n\r\n- Comment candidater ?\r\n\r\nEnvoyer un CV (avec le détail des cours et notes des deux années de\r\nMaster) et une lettre de motivation à :\r\n\r\nDelphine Battistelli :\r\n\r\ndel.battistelli@gmail.com\r\n\r\nPatrice Enjalbert :\r\n\r\npatrice.enjalbert@unicaen.fr\r\n\r\n*- Références *\r\n\r\nAuthier-Revuz J. (1995). Ces mots qui ne vont pas de soi, Boucles\r\nréflexives et non-coïncidences du dire, Paris: Larousse, 1995\r\n\r\nBattistelli D., Damiani M. (2013) - « Analyzing modal and enunciative\r\ndiscursive heterogeneity: how to combine semantic resources and a\r\nsyntactic parser analysis », in Actes WAMM (Workshop on Annotation of\r\nModal Meaning in Natural Language), held in conjunction with IWCS\'13,\r\nPotsdam, Allemagne.\r\n\r\nBethard S., Yu H., Thornton A., Hatzivassiloglou V., Jurafsky D. (2004).\r\n« Automatic extraction of opinion propositions and their holders\", in\r\nWorking Notes of the AAAI Spring Symposium on Exploring Attitude and\r\nAffect in Text: Theories and Applications, March 22-24, 2004, Stanford\r\n\r\nDamiani M., Battistelli D. (2013) - « Enunciative and modal variations\r\nin newswire texts in French: From guideline to automatic annotation »,\r\nin Actes de The 7th Linguistic Annotation Workshop & Interoperability\r\nwith Discourse, held in conjunction with ACL\'2013, Sofia, Bulgarie.\r\n \r\nEnjalbert, P., Mathet, Y. (2013) - « Constructions `Verbe + Verbe\r\ninfinitif\': étude de corpus et lexique sémantique », Document interne\r\nGREYC-Noopsis, Octobre 2013.\r\n\r\nGosselin L. (2005). *Temporalité et modalité*, Bruxelles, De Boeck\r\nSupérieur « Champs linguistiques », 2005.\r\n\r\nModNeg, 2012. Modality and Negation, Computational Linguistics, Special\r\nIssue - Volume 38, Issue 2 - June 2012\r\n(http://www.mitpressjournals.org/toc/coli/38/2).\r\n\r\nSauri R., Pustejovsky J. (2007). \"Determining Modality and Factuality\r\nfor Text Entailment\", in Actes ICSC 2007, Irvine, California, 2007.\r\n\r\nWilson T., Wiebe J. (2003). \"Annotating opinions in the world Press\", in\r\nActes 4th SIGdial Workshop on Discourse and Dialogue (SIGdial-03), ACL\r\nSIGdial, 2003.'),
(183, '2013-11-20', 'Orange Labs', 'Lannion', 'Stage extraction et qualification des entités nommées du Linked Open Data (f/h)\r\n\r\nref : 0006799 | 13 nov. 2013\r\n\r\n\r\n\r\nOrange\r\n\r\n\r\nAu service de 231 millions de clients sur les cinq continents, Orange\r\nest l\'un des principaux opérateurs de télécommunications au\r\nmonde. C\'est aujourd\'hui un opérateur intégré, fixe, mobile, internet\r\net télévision.\r\n\r\nLa recherche et l\'innovation du Groupe sont portées par le réseau\r\nmondial des Orange Labs et des Technocentres. Les 5000 chercheurs,\r\ningénieurs, concepteurs, développeurs sont répartis sur 4 continents\r\npour être au plus près des besoins des pays. L\'activité de Recherche\r\net de Développement est l\'une des sources principales de l\'\'innovation\r\nd\'Orange qui, avec près de 7500 brevets à son actif à fin 2012,\r\ncontribue à développer la nouvelle génération de services de\r\ncommunication intégrés, innovants et simples d\'utilisation.\r\n\r\nL\'équipe Future Architectures and Textual Technologies d\'Orange Labs a\r\nen charge des travaux de recherche et développement dans le domaine du\r\nTraitement Automatique des Langues (TAL) pour l\'écrit : analyse\r\nsémantique du texte, extraction d\'information, requêtes en langage\r\nnaturel, bases de connaissances linguistiques.\r\n\r\nVotre rôle\r\n\r\nSous la responsabilité d\'un ingénieur de recherche, vous participez à\r\nl\'amélioration des données nécessaires pour pouvoir extraire des\r\ninformations du texte.\r\n\r\nPendant le stage, \r\n\r\n- vous évaluez la pertinence des bases d\'Entités Nommées (EN) du\r\n  Linked Open Data (LOD, freebase, dbpedia...),\r\n\r\n- vous récupérez et fusionnez ces Entitées Nommées en recherchant les\r\n  doublons (SameAs) en exploitant les connaissances existantes du LOD,\r\n\r\n- vous établissez la correspondance entre les classes des données LOD\r\n  et les types et sous-types d\'EN utilisés par les logiciels de\r\n  l\'équipe,\r\n\r\n- vous développez des algorithmes permettant de calculer un poids par\r\n  défaut sur les différentes EN et d\'adapter ce poids au domaine\r\n  d\'application vous définissez et développez le processus\r\n  d\'intégration de ces bases d\'EN pour permettre leur mise à jour\r\n  automatique et régulière.\r\n\r\n\r\nVotre profil\r\n\r\nVous préparez une formation de niveau Bac +5 ou un Master 2 dans le\r\ndomaine des technologies du langage ou du Web sémantique\r\n\r\nVous connaissez les formats et technologies du Web Sémantique (RDF,\r\nontologies, Linked Open Data). Vous maîtrisez Java ou Python\r\n\r\nLe plus de l\'offre\r\n\r\nVous travaillerez sur un domaine technique stimulant, au sein d\'une\r\néquipe pluridisciplinaire.\r\n\r\nContrat\r\n\r\nStage de fin d\'études\r\n\r\n\r\nPour postuler : \r\n\r\nConsultez la page :\r\n\r\nhttp://orange.jobs/jobs/offer.do?joid=35860&lang=fr&wmode=light'),
(184, '2013-11-22', 'INRA', 'Paris ou Grignon', 'INRA Mét@Risk\r\nMéthodologies d\'analyse de risque alimentaire\r\n16, rue Claude Bernard\r\n75231 Paris cedex 05\r\n\r\nINRA GMPA\r\nGénie et Microbiologie des Procédés Alimentaires\r\nAvenue Lucien Brétignières\r\n78850 Thiverval Grignon\r\n\r\nSujet de stage de master M2\r\n\r\nConstruction d\'un corpus de connaissances sur un système de production\r\net de stabilisation de cellules microbiennes\r\n\r\nContacts : liliana.ibanescu@agroparistech.fr,\r\ncaroline.penicaud@grignon.inra.fr, lydie.soler@paris.inra.fr\r\n\r\nLa production et la stabilisation de cellules microbiennes est un\r\nenjeu majeur pour de nombreuses bio-industries, représentant un marché\r\nde 144 milliards de dollars en 2010 et qui devrait atteindre 259\r\nmilliards de dollars en 2016. Les procédés employés sont très\r\nénergivores, et face au contexte énergétique actuel, des améliorations\r\nvoire des alternatives doivent être envisagées. Au-delà de la question\r\nde l\'énergie, c\'est la durabilité du système qui est mise en question,\r\nintégrant la dimension d\'épuisement des ressources (énergie, eau,\r\nmatières premières) mais aussi l\'impact sur l\'environnement\r\n(e.g. réchauffement climatique) ou sur la santé humaine\r\n(e.g. production de composés toxiques). Cependant, l\'amélioration de\r\nla durabilité du procédé ne peut pas se faire sans tenir compte des\r\ncontraintes spécifiques aux bioproduits, qui sont très fragiles et\r\nsubissent de fortes dégradations au cours des procédés. Les critères\r\nd\'évaluation de la qualité du bioproduit au cours des différentes\r\nopérations sont liés à l\'état physiologique des cellules et mesurables\r\nà différents niveaux d\'échelle (génétique, moléculaire, cellulaire,\r\npopulation). L\'intégration des différents critères (qualité du\r\nbioproduit, performance du procédé, impact environnemental) pour\r\noptimiser globalement le système est nécessaire dans l\'optique de\r\ndévelopper des procédés plus durables tout en préservant la qualité\r\ndes micro-organismes.\r\n\r\nL\'objectif de ce stage est de constituer un corpus de connaissances et\r\nun thésaurus pour la représentation in silico globale d\'un système de\r\nproduction et de stabilisation de cellules microbiennes intégrant les\r\ndifférentes étapes de production, les niveaux d\'échelle nécessaires à\r\nla description de la fonctionnalité du produit, et, les entrées et\r\nsorties liées à l\'impact environnemental, tout en prenant en compte la\r\ncomposante économique du système.  Ce stage sera réalisé dans le cadre\r\nd\'une collaboration entre deux équipes de deux unités INRA, l\'équipe «\r\nIngénierie des connaissances » de l\'unité Mét@risk qui travaille en\r\nparticulier sur la constitution de bases de connaissances et la\r\nconstruction d\'ontologies et l\'équipe « Bioproduits - Aliments -\r\nMicro-organismes - Procédés » de l\'unité GMPA qui travaille en\r\nparticulier sur l\'objet d\'étude de ce stage.\r\n\r\nLes étapes du travail seront les suivantes:\r\n\r\n1- Extraction de connaissances issues de sources identifiées et du Web\r\npour élaborer et enrichir le corpus de connaissances ;\r\n\r\n2- Prise en compte du caractère multi-échelles du système dans la\r\nconstruction du corpus de connaissances ;\r\n\r\n3- Construction d\'un thésaurus permettant de représenter la\r\nconnaissance du corpus de façon structurée et hiérarchique\r\n\r\nLieu du stage: AgroParisTech (Paris ou Grignon), durée de 6 mois,\r\nstage rémunéré'),
(185, '2013-11-22', 'AERIAL', 'Paris', 'Offre de Stage en Linguistique-Informatique / Traitement automatique\r\ndes langues\r\n\r\nExtraction automatique d\'informations pertinentes et création de\r\nthésaurus.\r\n\r\nRéférence : LGST-INF-1\r\n\r\nMerci d\'envoyer votre CV & Lettre de motivation à l\'adresse suivante :\r\ncontact@aerial-group.com\r\n\r\nPrésentation d\'Aerial\r\n\r\nAERIAL a pour c½ur de métier le conseil en pilotage d\'entreprise. Sa\r\nvocation est de faire évoluer le mode de fonctionnement de\r\nl\'entreprise pour lui permettre d\'obtenir une amélioration simultanée\r\nde ses ratios de productivité et de sa capacité de croissance.  Pour\r\nexercer cette vocation, AERIAL intervient, sans modifier en profondeur\r\nles structures, à la fois :\r\n\r\n- Sur le pilotage stratégique de l\'entreprise pour lui apporter\r\nsouplesse et réactivité\r\n\r\n- Sur le pilotage de son système d\'information pour en faire un outil\r\nd\'amélioration de son efficience\r\n\r\n- Sur le pilotage de l\'innovation pour lui permettre d\'anticiper sur\r\n  son marché\r\n\r\nDescription du poste :\r\n\r\nDans le cadre de son offre DPO\r\n(http://www.aerial-group.com/nos-approches/509-2/), vous participerez\r\nau développement d\'un système de management de l\'information innovant,\r\npermettant d\'extraire automatiquement des informations pertinentes.\r\n\r\nPour ce faire nos clients nous confient leurs données stockées en\r\ninterne et/ou nous faisons pour eux une veille externe. Ces données\r\nsont ensuite analysées sémantiquement en profondeur pour détecter les\r\ninformations pertinentes et les champs lexicaux utiles au domaine puis\r\nrestituées graphiquement au travail d\'une plateforme SAAS.\r\n\r\nLa pertinence de l\'extraction d\'information dans les corpus client est\r\ndonc un enjeu très fort au sein d\'Aerial.\r\n\r\nLe stagiaire devra dans un premier temps mettre en ½uvre une analyse\r\nde corpus pour identifier le focus ainsi que les attributs pertinents\r\npour le client.  Puis à partir de cette analyse, modéliser\r\nl\'information pertinente par des patrons morphosyntaxiques, et/ou par\r\nla création de thésaurus sémantiquement pertinent pour le domaine\r\nclient.  Enfin, le stagiaire pourra intervenir sur des actions\r\ncorrectrices et des paramétrages sémantiques de l\'outil.\r\n\r\nCompétences techniques :\r\n- XML \r\n- Expressions régulières\r\n- Sémantique\r\n- Morphosyntaxe\r\n- Traitement automatique du langage\r\n\r\nCompétences individuelles : \r\n-  Analyse\r\n- Méthode\r\n- Rigueur\r\n- Autonomie\r\n- Aptitudes à travailler en équipe\r\n- Esprit d\'analyse, de synthèse\r\n- Curiosité dans le domaine\r\n\r\n\r\nProfil et expérience\r\n\r\nDe formation BAC+ 4/5 (école d\'ingénieur ou universitaire) en\r\nlinguistique informatique, Linguistique avancée et appliquée aux\r\nsciences et techniques de l\'information et de la communication\r\nspécialité traitement automatique du langage ou équivalent avec des\r\nconnaissances premières en Text-Mining.  Dynamique, autonome et\r\norganisé(e), vous faite preuve de rigueur et de professionnalisme.\r\n\r\nType de contrat\r\nStage d\'une durée de 6 à 12 mois\r\n\r\nLieu\r\nParis\r\n\r\nRémunération\r\nEn fonction du profil du candidat'),
(186, '2013-11-25', 'L3i', 'La Rochelle', '*Sujet de stage :*\r\n\r\n*Développement de grammaires d\'extractions de descriptions temporelles.*\r\n\r\n**\r\n\r\n*Résumé du travail proposé :*\r\n\r\nL\'objectif de ce stage est de développer une grammaire d\'extraction de \r\nmarqueurs temporels dans le domaine du tourisme. La plupart des \r\ninformations contenues dans une base de données touristiques \r\n(événements, manifestations, hôtels, restaurants, musées...) contiennent \r\ndes marqueurs temporels (date, durée, horaires d\'ouvertures, conditions \r\nd\'ouvertures ou de tarifs...) qu\'il s\'agira d\'identifier au moyen d\'une \r\ngrammaire adaptée.\r\n\r\nA partir de données réelles, vous aurez à développer une grammaire\r\nlocale de reconnaissance de ces marqueurs, en utilisant les outils\r\nUnitex (http://www-igm.univ-mlv.fr/~unitex/) et GramLab\r\n(http://www.gramlab.org/fr/).\r\n\r\n*Mots clés :*\r\n\r\nTraitement automatique des langues, grammaires locales, Unitex, GramLab,\r\nexpressions temporelles\r\n\r\n*Informations complémentaires :*\r\n\r\n*Encadrant(s) *: Alain Couillault, Mickaël Coustaty, Jean-Marc Ogier\r\n\r\n*Axe thématique*://IDDC/(Image, Documents, Données Complexes)/\r\n\r\n*Axe stratégique *: Pertinence Contenu-Interaction\r\n\r\n*Cadre de coopération* : Projet TourInflux (Investissement d\'Avenir)\r\n\r\n*Date de début du stage *: Janvier 2014\r\n\r\n*Durée du stage *: 5 à 6 mois\r\n\r\n*Contexte de l\'étude:*\r\n\r\nLes travaux menés par le candidat se dérouleront au sein du L3i et\r\ns\'inscriront dans le projet Tourinflux. . Le projet Tourinflux,\r\nsélectionné dans le cadre de l\'appel à projets Big Data du Fonds\r\nNational pour la Société Numérique et financé dans le programme\r\nd\'investissements d\'avenir, rassemble deux entreprises, une association\r\nd\'entreprises et le laboratoire L3i, et sera réalisé en partenariat avec\r\nplusieurs acteurs du tourisme de France. Ce projet vise à apporter aux\r\nacteurs du tourisme (d\'abord les institutionnels mais aussi les acteurs\r\nprivés) un ensemble d\'outils leur permettant de gérer à la fois leurs\r\ndonnées internes et les informations disponibles sur le web afin de\r\nmieux comprendre comment un territoire est perçu et de mieux agir sur\r\ncette perception. Les outils actuellement à disposition des\r\ninstitutionnels du tourisme sont insuffisants pour répondre à ce besoin\r\ndu fait des problèmes de collecte, d\'analyse, de manipulation et\r\nd\'échange d\'informations réalisés de manière beaucoup trop artisanale.\r\nL\'objectif de Tourinflux est de proposer un tableau de bord complet\r\npermettant aux institutionnels du tourisme, quelle que soit leur taille,\r\nde visualiser et interpréter l\'information disponible par rapport à leur\r\nterritoire (aux niveaux micro et macro) afin de prendre les décisions\r\nles plus efficaces.\r\n\r\n*Le laboratoire:*\r\n\r\nLe laboratoire L3i, EA 2118 créé en 1993, représente la seule et unique\r\ncomposante de recherche du domaine STIC sur l\'Université de la Rochelle\r\nassociant très efficacement les chercheurs de l\'IUT de la Rochelle, et\r\ndu Pôle Sciences en informatique. Dans le cadre de la politique\r\nquadriennale (désormais quinquennale) de l\'université de la Rochelle, le\r\nL3i vient d\'être évalué A par l\'AERES. Le laboratoire Informatique,\r\nImage et Interaction a choisi d\'axer son projet de laboratoire autour de\r\ndeux thèmes (Axes Thématiques) que sont « Image, Document et Données\r\nComplexes » et « Systèmes Interactifs et Images », véritables coeurs de\r\nmétier du laboratoire. Par ailleurs, le laboratoire propose de mettre en\r\navant ASPIC (Axe Stratégique Pertinence Intraction/Contenus), vecteur de\r\nvisibilité de son action scientifique au sein de projets structurants et\r\nen articulation avec le monde socio-économique. Ainsi, plus d\'une\r\ndizaine de projets sont actuellement menés autour de l\'analyse de\r\ndocuments et de données complexes d\'une part (en lien avec le centre\r\neuropéen de valorisation des contenus numériques -- Valconum), et autour\r\nde l\'interaction appliquée aux jeux vidéos et l\'e-Education d\'autre\r\npart. Par ses activités de ces six dernières années, le L3i a développé\r\ndes outils et des compétences dans l\'analyse de données récurrentes dans\r\nle temps et l\'espace, mais également l\'analyse de contenus et de données\r\ncomplexes et hétérogènes.\r\n\r\n*Description du sujet :*\r\n\r\nLe candidat retenu devra, à partir de corpus dans le domaine du\r\ntourisme, développement une grammaire d\'analyse d\'évènements\r\ntouristiques, récurrents ou non, dans le temps et/ou dans l\'espace («\r\ntous les lundi », « tous les ans », « dans toutes les boutiques du\r\nréseau », «tous les mardis sur la place du marché sauf veille de jours\r\nfériés », « Hôtel ouvert toute l\'année, restauration sur place seulement\r\nen été »...).\r\n\r\n*Qualifications :*\r\n\r\nLe candidat devra justifier de compétences de recherche dans au moins \r\ndeux des quatre domaines suivants :\r\n\r\n- Traitement Automatique des Langues, Fouille de texte\r\n\r\n- Raisonnement temporel et/ou spatial\r\n\r\n- Annotation et évaluation\r\n\r\n- Ecriture de grammaires d\'extraction\r\n\r\n*Contacts -- liens : *\r\n\r\n*Email *: mickael.coustaty@univ-lr.fr ; alain.couillault@univ-lr.fr ;\r\njean-marc.ogier@univ-lr.fr'),
(187, '2013-11-25', 'EDF R&D', 'Clamart', 'STAGE INGÉNIERIE LINGUISTIQUE\r\nSUJET 2014: ÉVALUATION D\'OUTILS TEXT MINING\r\nDURÉE : 6 MOIS ENVIRON\r\n\r\n1.      CONTEXTE\r\n\r\nLe volume des données numériques textuelles, disponibles sur l\'Internet\r\n(forums, twitters etc.) ou relatives à des contacts client (enquêtes,\r\ncentre d\'appel etc.), augmente chaque année. L\'analyse de ces\r\ninformations, structurées ou non, est, aujourd\'hui, un impératif\r\nstratégique pour une entreprise telle qu\'EDF. Dans ce cadre, et dans\r\nl\'objectif de toujours mieux connaître les besoins des clients,\r\nl\'exploitation de ces documents implique l\'utilisation de méthodes et\r\nd\'outils adaptés. Au c½ur de ces problématiques les outils de Text\r\nMining sont de plus en plus nombreux et performants, ainsi nous\r\nsouhaitons étudier les principaux outils évoluant sur le marché\r\naujourd\'hui.\r\n\r\n2.       SUJET DU STAGE\r\n\r\nDepuis 2003, les données textuelles sont essentiellement traitées à la\r\nR&D via des solutions développées par l\'éditeur TEMIS (Text-Mining\r\nSolution).  Ce choix fait suite à différentes campagnes de veille sur\r\nles outils de Text Mining.  Un protocole de test d\'outils de Text Mining\r\navait été défini et appliqué à l\'étude approfondie de différents\r\nlogiciels.\r\n\r\nDans le cadre du suivi des évolutions des outils de Text Mining, nous\r\nsouhaitons effectuer une nouvelle évaluation des outils d\'analyse de\r\ndonnées contenant du texte.\r\n\r\nCe stage se décomposera en 3 parties : \r\n\r\n- Veille d\'outils de Text Mining : Il s\'agira de mener une étude de\r\n  marché des outils existants aujourd\'hui.\r\n\r\n- Evaluation : A partir des solutions émergentes du marché, il s\'agira\r\n  d\'évaluer une sélection d\'outils (entre 3 et 4) jugés à priori\r\n  intéressants par rapport aux besoins d\'EDF.\r\n\r\n- Perspectives : Dans un second temps, il s\'agira d\'identifier les\r\n  perspectives envisageables quant à l\'alliance du Text Mining et du Web\r\n  sémantique au regard des besoins EDF.\r\n\r\nINFORMATIONS PRATIQUES\r\n\r\nInterlocuteurs:\r\nDelphine Lagarde        01.47.65.39.75  delphine.lagarde@edf.fr\r\nAnne Peradotto  01.47.65.44.89  anne.peradotto@edf.fr\r\n\r\nLieu du stage: \r\nEDF R&D - Département ICAME\r\n1, avenue du Général de Gaulle\r\n92141 Clamart Cedex \r\n\r\nDate & Durée : Début 2014 - 6 mois environ\r\n\r\nRémunération: A définir (environ 1.000¤/mois)'),
(188, '2013-11-25', 'LGI2P', 'Nîmes', 'Le laboratoire LGI2P à Nîmes de l\'École des Mines d\'Ales, propose le\r\nstage Master 2 suivant :\r\n\r\n*Lieu : *Nîmes, site EERIE, EMA, parc Georges Besse, 30000 Nîmes\r\n\r\n*Sujet : *SÉMANTIQUE, ÉQUILIBRES ET STABILITÉS DE CONSTRUCTION DE\r\nCOMMUNAUTÉS RECOUVRANTES DANS LES RÉSEAUX SOCIAUX\r\n\r\n*Descriptif succinct* /(pour une description plus détaillée, voir \r\nadresse ci-dessous)/\r\nLes réseaux sociaux occupent une part de plus en plus importante dans\r\nl\'échange de données sur le web. La recommandation de produits et de\r\nservices, les modèles utilisateurs enrichis par des données sociales\r\npeuvent revêtir une grande importance.\r\n\r\nLe sujet proposé a pour objectif de déterminer des communautés extraites\r\nà partir de données sociales et de rechercher les optimums de stabilité\r\net d\'équilibre tout en tenant compte de leur sémantique.\r\n\r\nLa signification et la stabilité de ces communautés ainsi constituées\r\nn\'est que peu abordée dans les travaux actuels. Les auteurs appliquent\r\nun algorithme unique d\'optimisation et observent ensuite les\r\nperformances.\r\n\r\nLe travail de stage aura les objectifs suivants à partir des travaux\r\ndéjà effectués au laboratoire :\r\n\r\n- Approfondir les travaux de recherche de stabilité dans la construction\r\n  de communautés recouvrantes.\r\n- Établir les fondements de la sémantique attachés à la construction de\r\n  communautés\r\n- Définir des procédures de validation de communautés\r\n- etc.\r\n\r\nPour plus de détails voir la description à l\'adresse suivante :\r\nhttp://www.lgi2p.ema.fr:8090/plantie/site/index.php/sujet-master-recherche\r\n\r\n*Direction de stage* (à contacter pour plus d\'informations)\r\n- Michel Plantié, LGI2P (michel.plantie@mines-ales.fr)\r\n- Michel Crampes, LGI2P (michel.crampes@mines-ales.fr)\r\n\r\n*Remarque importante :*\r\nUn support financier est possible pour une poursuite en thèse de\r\ndoctorat.\r\nSi les compétences et le niveau académique du (de la) candidat(e) le\r\njustifient, sa candidature sera notamment soutenue pour l\'obtention d\'un\r\ntel financement, afin qu\'il (elle) puisse accomplir une thèse à la suite\r\nde ce stage.'),
(189, '2013-11-27', 'Inbenta', 'Toulouse', '*Présentation société*\r\n ------------------------------\r\n\r\ninbenta est une société pionnière dans le *Traitement Automatique du\r\nLangage Naturel et la recherche sémantique*. Basée sur ces concepts\r\nnovateurs, inbenta développe depuis 2005 des solutions logicielles pour\r\nles sites internet de Grands Comptes.\r\n\r\n*Description de l\'offre*\r\n ------------------------------\r\n\r\nInbenta a développé un moteur de recherche intelligent appelé *Inbenta\r\nSemantic Search Engine* (ISSE). Les deux tâches principales de ce moteur\r\nsont d\'analyser les questions des utilisateurs et de trouver la réponse\r\nappropriée à la requête en effectuant une recherche dans une base de\r\nconnaissances.\r\n\r\n\r\nUn *module de désambiguïsation syntaxique et sémantique* est intégré\r\ndans notre moteur de recherche. Ce module est très important car il fait\r\npartie intégrante du bon fonctionnement de la solution. L\'objet du stage\r\nproposé par inbenta sera d\'améliorer le module de désambiguïsation.\r\n\r\n\r\nLes missions de stage seront :\r\n\r\n   - Gestion linguistique et éditoriale d\'un projet de FAQ dynamique\r\n     afin que le stagiaire s\'approprie l\'existant\r\n   - Enrichissement du module de désambiguïsation par l\'ajout de règles,\r\n     de descriptions lexicales et de grammaires locales + évaluation du\r\n     travail\r\n   - Réflexion d\'amélioration du module de désambiguïsation à un niveau\r\n     algorithmique\r\n\r\n\r\n*Profil recherché*\r\n ------------------------------\r\n\r\nNous recherchons une personne enthousiaste, organisée et sérieuse et\r\nayant l\'envie d\'intégrer une équipe internationale. Le stagiaire devra\r\négalement avoir les compétences suivantes :\r\n\r\n   - Études en Traitement Automatique du Langage Naturel\r\n   - Excellente maîtrise de la langue française et bonne communication\r\n     écrite et orale en espagnol, anglais ou catalan\r\n\r\nBonus :\r\n\r\n   - Maîtrise d\'au moins un langage de programmation (PHP de préférence)\r\n   - Maitrise des expressions régulières et du SQL\r\n\r\n\r\n*Modalités du poste*\r\n ------------------------------\r\n\r\n   - Stage de 5 à 6 mois (avec possibilité d\'embauche en CDI)\r\n   - Rémunération prévue: 30% du SMIC (+ prime en fonction des\r\n     résultats)\r\n   - Début : à partir de Février / Mars 2013\r\n   - Lieu : Toulouse\r\n\r\n\r\nMerci d\'adresser CV et lettre de motivation à Quintana Manon à l\'adresse\r\nmail suivante : *mquintana@inbenta.com*'),
(190, '2013-11-27', 'Vision Objects', 'Nantes', '*Stage en Traitement Automatique des Langues H/F :*\r\n\r\n*SUJET : Influence des types de corpus sur la reconnaissance d\'écriture*\r\n\r\n\r\n Avec plus de 90% de son CA à l\'international, et plus de 100 millions\r\nd\'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels\r\nleader mondial sur le marché des interfaces homme-machine basées sur la\r\nreconnaissance d\'écriture manuscrite.\r\n\r\n\r\n Disponible dans plus de 85 langues, ses produits concernent les marchés\r\nde la mobilité (saisie de texte, prise de notes, ...), de l\'éducation\r\n(apprentissage de l\'écriture, des mathématiques, de la géométrie, ...) de\r\nl\'entreprise (prise de notes et traitement de formulaires), et de\r\nl\'automobile (saisie de texte à partir d\'une surface tactile,\r\ninteraction avec GPS).\r\n\r\n\r\n Vision Objects est une entreprise d\'innovation et de hautes\r\ntechnologies.  Le c½ur de sa technologie MyScript est diffusé sous forme\r\nde kit de développement logiciel, de « Cloud service », de composants à\r\nintégrer ou sous forme d\'applications prêtes à l\'emploi.\r\n\r\nLe moteur de reconnaissance de Vision Objects se classe régulièrement\r\naux premières places des compétitions scientifiques internationales\r\n(cf., par exemple, ICDAR). Dans le cadre de sa forte croissance, Vision\r\nObjects (Nantes, France) est à la recherche d\'un:\r\n\r\n\r\n *Stagiaire Ingénieur Informaticien en Traitement Automatique des\r\nLangues (TAL)*\r\n\r\n\r\n Dans l\'équipe *Ressources Linguistiques*, vous serez amené à travailler\r\nsur la mission suivante :\r\n\r\n\r\n *SUJET : Influence des types de corpus sur la reconnaissance\r\n  d\'écriture*\r\n\r\n*Les nouveaux usages du Web ont fait émerger de nouveaux registres de\r\nlangue. On n\'écrit pas de la même façon un e-mail, un sms, un tweet ou\r\nun article plus formel.*\r\n\r\n*Le stage consiste à enrichir en diversité les corpus utilisés pour la\r\nconstruction des modèles de langue et à évaluer la façon de combiner ces\r\ncorpus. On s\'intéresse en particulier aux contenus extractibles des\r\nréseaux sociaux ainsi qu\'aux corpus disponibles dans de nombreuses\r\nlangues car notre solution est disponible dans 64 langues, dont\r\ncertaines peu dotées en termes de ressources.*\r\n\r\n\r\n Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.\r\n\r\n\r\n Au sein de VisionObjects, vous travaillerez sur des technologies à la\r\npointe de la recherche et pourrez identifier les applications directes\r\net concrètes de votre travail.\r\n\r\nUn ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à\r\nl\'élaboration de l\'application Android MyScript Calculator: une\r\ncalculatrice manuscrite utilisant la reconnaissance d\'équations de\r\nVisionObjects. Les applications réalisées et publiées par VisionObjects\r\nà partir du travail de ce stage ont depuis totalisé plus de 10 millions\r\nde téléchargements.\r\n\r\n\r\n Vous pouvez trouver gratuitement MyScript Calculator sur les stores\r\nAndroid et iOS.\r\n\r\n Contact : job@visionobjects.com'),
(191, '2013-11-27', 'Vision Objects', 'Nantes', '*STAGE EQUIPE TAL - VISION OBJECTS*\r\n\r\n Avec plus de 90% de son CA à l\'international, et plus de 100 millions\r\nd\'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels\r\nleader mondial sur le marché des interfaces homme-machine basées sur la\r\nreconnaissance d\'écriture manuscrite.\r\n\r\n\r\n Disponible dans plus de 85 langues, ses produits concernent les marchés\r\nde la mobilité (saisie de texte, prise de notes, ...), de l\'éducation\r\n(apprentissage de l\'écriture, des mathématiques, de la géométrie, ...) de\r\nl\'entreprise (prise de notes et traitement de formulaires), et de\r\nl\'automobile (saisie de texte à partir d\'une surface tactile,\r\ninteraction avec GPS).\r\n\r\n\r\n Vision Objects est une entreprise d\'innovation et de hautes\r\ntechnologies.  Le c½ur de sa technologie MyScript est diffusé sous forme\r\nde kit de développement logiciel, de « Cloud service », de composants à\r\nintégrer ou sous forme d\'applications prêtes à l\'emploi.\r\n\r\n\r\n Le moteur de reconnaissance de Vision Objects se classe régulièrement\r\naux premières places des compétitions scientifiques internationales\r\n(cf., par exemple, ICDAR).\r\n\r\n\r\n *Stagiaire - Développement d\'un outil d\'analyse de résultats*\r\n\r\n\r\n *Une problématique de la recherche en reconnaissance d\'écriture est\r\nd\'évaluer globalement les avantages et inconvénients de différents\r\nalgorithmes, tout en étudiant les comportements de ces algorithmes sur\r\nquelques cas spécifiques. Ce passage de la vérité générale au cas\r\nparticuliers, et inversement, peut être grandement facilité par un\r\noutillage adéquat.*\r\n\r\n*Dans ce stage, on s\'intéressera au développement d\'un nouvel outil de\r\ndétection de cas intéressants à partir de bases de test globales. Au\r\nsein du département R&D, le stagiaire aura l\'occasion de comprendre le\r\nfonctionnement du moteur de reconnaissance d\'écriture, tout en acquérant\r\ndes compétences de programmation utilisables dans bien d\'autres\r\ncontextes.  Le travail comprend des aspects algorithmiques et d\'analyse\r\nde données pour factoriser l\'information, ainsi que des aspects\r\ninterface graphique et intégration dans les outils existants pour la\r\nprésenter de façon optimale à l\'utilisateur.*\r\n\r\n\r\n Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.\r\n\r\n\r\n Rigoureux, dynamique et d\'un relationnel facile, vous saurez rapidement\r\nvous intégrer au sein d\'équipes de haut niveau et dans un environnement\r\nstimulant.\r\n\r\n\r\n Au sein de VisionObjects, vous travaillerez sur des technologies à la\r\npointe de la recherche et pourrez identifier les applications directes\r\net concrètes de votre travail.\r\n\r\nUn ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à\r\nl\'élaboration de l\'application Android MyScript Calculator: une\r\ncalculatrice manuscrite utilisant la reconnaissance d\'équations de\r\nVisionObjects. Les applications réalisées et publiées par VisionObjects\r\nà partir du travail de ce stage ont depuis totalisé plus de 10 millions\r\nde téléchargements.\r\n\r\nVous pouvez trouver gratuitement MyScript Calculator sur les stores\r\nAndroid et iOS.\r\n\r\n Contact : job@visionobjects.com'),
(192, '2013-11-27', 'Vision Objects', 'Nantes', '*Stage en Traitement Automatique des Langues H/F :*\r\n\r\n*SUJET : Détection automatique multilingue de sous-parties de mots\r\n(morphèmes)*\r\n\r\n\r\n Avec plus de 90% de son CA à l\'international, et plus de 100 millions\r\nd\'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels\r\nleader mondial sur le marché des interfaces homme-machine basées sur la\r\nreconnaissance d\'écriture manuscrite.\r\n\r\n\r\n Disponible dans plus de 85 langues, ses produits concernent les marchés\r\nde la mobilité (saisie de texte, prise de notes, ...), de l\'éducation\r\n(apprentissage de l\'écriture, des mathématiques, de la géométrie, ...) de\r\nl\'entreprise (prise de notes et traitement de formulaires), et de\r\nl\'automobile (saisie de texte à partir d\'une surface tactile,\r\ninteraction avec GPS).\r\n\r\nVision Objects est une entreprise d\'innovation et de hautes\r\ntechnologies.  Le c½ur de sa technologie MyScript est diffusé sous forme\r\nde kit de développement logiciel, de « Cloud service », de composants à\r\nintégrer ou sous forme d\'applications prêtes à l\'emploi.\r\n\r\n\r\n Le moteur de reconnaissance de Vision Objects se classe régulièrement\r\naux premières places des compétitions scientifiques internationales\r\n(cf., par exemple, ICDAR). Dans le cadre de sa forte croissance, Vision\r\nObjects (Nantes, France) est à la recherche d\'un:\r\n\r\n\r\n *Stagiaire Ingénieur Informaticien en Traitement Automatique des\r\nLangues (TAL)*\r\n\r\n\r\n Dans l\'équipe *Ressources Linguistiques*, vous serez amené à travailler\r\nsur la mission suivante :\r\n\r\n\r\n *SUJET : Détection automatique multilingue de sous-parties de mots\r\n(morphèmes)*\r\n\r\n*Les langues fortement agglutinantes posent des problèmes spécifiques en\r\nmodélisation statistique des langues, notamment le très grand nombre\r\nd\'unités lexicales possibles. Une approche est de découper ce qui est\r\ncouramment appelé mot en unités plus petites.*\r\n\r\n*Le stage consiste à étudier et implémenter des algorithmes non\r\nsupervisés (sans exemples de découpage dans la langue cible) de\r\ndécoupage de mots en morphèmes. Il s\'agit ensuite d\'appliquer ces\r\nalgorithmes dans un contexte fortement multilingue car notre solution\r\nest disponible en 64 langues.*\r\n\r\n*Une suite possible de ce travail sera l\'étude de techniques également\r\nnon supervisées et multilingues d\'analyse grammaticale (PoS tagging).*\r\n\r\n\r\n Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.\r\n\r\nRigoureux, dynamique et d\'un relationnel facile, vous saurez rapidement\r\nvous intégrer au sein des équipes.\r\n\r\n\r\n Au sein de VisionObjects, vous travaillerez sur des technologies à la\r\npointe de la recherche et pourrez identifier les applications directes\r\net concrètes de votre travail.\r\n\r\nUn ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à\r\nl\'élaboration de l\'application Android MyScript Calculator: une\r\ncalculatrice manuscrite utilisant la reconnaissance d\'équations de\r\nVisionObjects. Les applications réalisées et publiées par VisionObjects\r\nà partir du travail de ce stage ont depuis totalisé plus de 10 millions\r\nde téléchargements.\r\n\r\nVous pouvez trouver gratuitement MyScript Calculator sur les stores\r\nAndroid et iOS.\r\n\r\n\r\n Contact : job@visionobjects.com'),
(193, '2013-12-02', 'Trooclick', 'Paris', 'Trooclick France is a company that specializes in the development of web\r\napplications for the automatic processing of information. Our goal is to\r\ncreate services that rebuild the user\'s trust in digital content. Up to\r\nnow, Web players were able to enhance the relevance of this content; we\r\ngo a step further and contribute to improve its reliability.\r\n\r\nTrooclick was created in November 2012. Just a few months later, in\r\nApril 2013, it received financial support from the BPI (French public\r\ninvestment bank) and in June 2013 the French government granted it the\r\nStatus of \"Young Innovative Company\" (JEI), recognizing its innovative\r\nnature. It now counts twelve committed and passionate members in its\r\ntight-knit team.\r\n\r\nThe company carries out R&D projects in search of technical solutions in\r\nthe Artificial Intelligence field. Due to its growth, Trooclick is now\r\nlooking for candidates for a 6 month internship for its office in Paris\r\n(17ème).\r\n\r\n\r\nMissions:\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\nYou will turn ideas into well-documented and reliable linguistic\r\nresources (both dictionaries and extraction rules) to ensure efficiency,\r\nquality, performance and scalability.\r\n\r\nA great team player, you will interact with other departments to\r\nunderstand and fine tune specifications.\r\nYou will carry out unitary testing, create and maintain our test\r\nvalidation corpus and participate in editing technical documents. All\r\ndevelopments will be done in English.\r\n\r\nQualifications:\r\n\r\n   - BSc/MSc\r\n   - Experience with NLP tools such as Gate, Treetagger, NooJ, Stanford\r\n     for linguistic annotation, named entity recognition, relationship\r\n     and fact extraction, sentiment analysis, etc.\r\n   - Experience in scripting languages such as Perl or Python as well as\r\n     XML format to be autonomous in completing some technical tasks.\r\n   - Experience with basic database management operations (SQL language)\r\n     Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will\r\n     be a plus.\r\n   - Excellent communication skills in English and French\r\n   - We are open to new ideas that will significantly contribute to our\r\n     success. Our friendly team will provide the opportunity for\r\n     valuable collaboration.\r\n   - We offer you career perspectives in a young and dynamic company\r\n     with an interesting and diversified scope of duties at the cutting\r\n     edge of research. We welcome applications from highly motivated\r\n     individuals able to learn new techniques and share knowledge and\r\n     experience with the team.\r\n\r\nInterested? Then send your application to jobs@trooclick.com!'),
(194, '2013-12-04', 'IRIT', 'Toulouse', 'Prédiction automatique de relations d\'implication entre verbes\r\n\r\nEncadrement : Marta Abrusan (marta.abrusan@irit.fr), Stergos Afantenos\r\n(stergos.afantenos@irit.fr), Farah Benamara (farah.benamara@irit.fr)\r\n\r\nLieu : IRIT, Université Paul Sabatier\r\nFinancement : prime de stage\r\nDurée : 5 mois\r\n\r\nLa compréhension sémantique d\'un texte est l\'un des enjeux majeurs du\r\ntraitement automatique du langage (TAL). Cette tâche est primordiale\r\npour de très nombreuses applications telles que la génération\r\nautomatique de textes et de conversations, le résumé automatique, la\r\nparaphrase automatique d\'un texte ou encore la recherche\r\nd\'information. Le but de ce stage est de contribuer à ces recherches en\r\nse focalisant sur la prédiction de relations entre verbes.\r\n\r\nPrédire une relation entre verbes consiste à déterminer pour un couple\r\nde verbes (v1,v2), associé ou non à un contexte, le type de relations\r\nsémantiques qui les relient, cf. Chklovski and Pantel (2004), Tremper\r\nand Frank (2013). Celles ci peuvent être de différentes natures :\r\nrelations de synonymie, d\'antonymie, de causalité, d\'implication, etc.\r\nDans ce stage, nous nous focaliserons sur les relations\r\nd\'implication. Par exemple, les verbes \"se balader\" et \"bouger\" sont\r\nreliés par une relation d\'implication, ce qui permettra à un ordinateur\r\nde répondre à une requête du type Pierre s\'est-il baladé ?, sachant que\r\nla base de connaissances indique que Pierre a bougé.\r\n\r\nAfin d\'identifier ces relations, le stagiaire devra utiliser les\r\nméthodes d\'apprentissage automatiques les plus adéquates. Le but de ces\r\nméthodes est d\'apprendre une fonction f : X --> Y où X représente un\r\nensemble des features (ou traits) sur les paires des verbes et Y est un\r\nbooléen représentant le fait qu\'il existe ou non une relation\r\nd\'implication entre ces verbes. Différentes méthodes seront\r\nexplorées. Nous commencerons d\'abord par les méthodes supervisées qui\r\ngénéralisent des observations faites sur un corpus de\r\ndonnées. Cependant, cette approche présuppose que le nombre d\'instances\r\nd\'entraînement est suffisamment grand, ce qui n\'est malheureusement pas\r\ntoujours le cas pour de nombreuses tâches où le coût humain d\'annotation\r\ndes instances est élevé. La seconde étape sera alors d\'explorer les\r\nméthodes d\'apprentissage semi-supervisées afin de réduire ce coût.\r\n\r\nRéférences\r\n\r\nTimothy Chklovski and Patrick Pantel (2004) : VerbOcean : Mining the web\r\nfor fine-grained semantic verb relations. In Proceedings of the 2004\r\nConference on Empirical Methods in Natural Language Processing, pages\r\n33-40, Barcelona, Spain, 2004.\r\n\r\nTremper, G. and A. Frank (2013) : A Discriminative Analysis of\r\nFine-Grained Semantic Relations including Presupposition : Annotation\r\nand Classification. In : Dialogue and Discourse, 4 (2), Special Issue :\r\nBeyond Semantics. The Challenge of Annotating Pragmatic and Discourse\r\nPhenomena, edited by S. Dipper, H. Zinsmeister and B. Webber, 282-322.'),
(195, '2013-12-09', 'LIRMM', 'Montpellier', 'Bonjour,\r\n\r\nUn stage de M2 (Recherche) est disponible au LIRMM (U. Montpellier 2),\r\nentre le 20 janvier et mi-juin 2014.\r\n\r\n*Candidatures souhaitées le plus rapidement possible.*\r\n\r\nTitre : Combining Stochastic and Knowledge-based Modelling for Natural\r\nLanguage Understanding\r\n\r\nEncadrement : Jean-Philippe.Prost (Prost@lirmm.fr)\r\nLieu : LIRMM, Montpellier\r\nDurée : 5 mois\r\nFinancement : selon barèmes légaux\r\n\r\nPossibilité de poursuite en thèse, selon résultats (candidature soumise\r\nà sélection).\r\n\r\nCe sujet de stage concerne le Traitement Automatique du Langage naturel\r\n(TAL). L\'objet en est de se pencher sur une voie possible d\'hybridation\r\nentre modélisation logique et modélisation probabiliste pour la\r\nreprésentation de connaissances langagières.\r\nLe sujet porte plus particulièrement sur la dimension syntaxique.\r\n\r\n==============\r\n\r\nLes parseurs les plus performants du moment sont dits \"robustes\", pour\r\nleur capacité à produire un arbre syntaxique quelle que soit la phrase\r\nen entrée, y compris mal-formée. Ces analyseurs sont construits à base\r\nd\'algorithmes d\'apprentissage automatique qui permettent de construire\r\nl\'arbre le plus probable étant donné la phrase en entrée.\r\nCette robustesse est acquise au détriment d\'une perte d\'information\r\nconséquente. Par exemple, la question de la bonne-formation\r\n(grammaticalité) de l\'entrée est éludée, l\'analyse d\'une phrase\r\nbien-formée n\'ayant pas nécessairement une probabilité maximale.\r\nOr il est possible d\'apporter une réponse exacte à ce problème, en\r\nvenant simplement brancher un module à base de raisonnement logique sur\r\nla sortie non-déterministe d\'un analyseur stochastique. Mais ce qui\r\nserait souhaitable, serait de pouvoir intégrer ce processus de\r\nrésolution exacte dans le processus d\'analyse stochastique.\r\n\r\nL\'objet de ce stage est donc d\'explorer différentes pistes possibles sur\r\ncette question. On pourra, par exemple, intégrer un mécanisme de\r\nvérification de modèle (model checking, au sens de la théorie logique\r\ndes modèles) dans le procédé de reclassement (reranking) des n\r\ncandidat-modèles les plus probables que génère un analyseur\r\nstochastique.\r\n\r\nLe stage comportera une partie d\'état de l\'art, une partie d\'exploration\r\nthéorique, et une partie réalisation (programmation).\r\n\r\nJP. Prost'),
(196, '2013-12-09', 'LIGM & Lattice', 'Région parisienne', 'Sujet de stage M2 recherche en TAL : acquisition d\'un analyseur en\r\ndépendances du français médiéval\r\n\r\nDans le cadre du projet ANR Syntactic Reference Corpus of Medieval\r\nFrench (SRCMF, 2008-2011), un Treebank (une collection d\'arbres)\r\nd\'analyses en dépendances d\'énoncés du français médiéval a été\r\nconstitué. Il comprend 260 000 mots (parmi lesquels environ 27 000 têtes\r\nverbales) annotées en étiquettes morpho-syntaxiques et reliés par des\r\nrelations de dépendances étiquetées.\r\n\r\nL\'objectif du stage est d\'exploiter ce corpus par apprentissage\r\nautomatique afin d\'acquérir un analyseur en dépendances du français\r\nmédiéval, éventuellement couplé à un étiqueteur morpho-syntaxique. Ces\r\noutils pourront être exploités sur de nouveaux textes. Ils permettront\r\nd\'étudier précisément les spécificités grammaticales du français\r\nmédiéval, en comparaison avec celles du français contemporain.\r\n\r\nLe stage bénéficiera de l\'encadrement d\'une spécialiste du français\r\nmédiéval (Sophie Prévost) et de spécialistes du TAL et de\r\nl\'apprentissage automatique (Matthieu Constant et Isabelle Tellier).\r\n\r\nCompétences requises :\r\n- niveau M2 ou ingénieur en informatique ou en TAL\r\n- Connaissances (ou au minimum intérêt argumenté) en TAL et en\r\n  apprentissage automatique\r\n- Compétences en programmation\r\n\r\nConditions du stage :\r\n- Rémunération : prime de stage (1/3 du SMIC).\r\n- Durée : 4 à 6 mois en commençant dès que possible en 2014.\r\n- Lieu : le stage sera encadré en collaboration par le LIGM à\r\n  Marne-la-vallée (http://ligm.u-pem.fr) et le Lattice à Montrouge\r\n  (http://www.lattice.cnrs.fr), trajets à prévoir entre les deux lieux\r\n\r\nenvoyer CV + lettre de motivation à Matthieu Constant\r\n(Matthieu.Constant@u-pem.fr), Sophie Prévost (sophie.prevost@ens.fr),\r\nIsabelle Tellier (isabelle.tellier@univ-paris3.fr)');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(197, '2013-12-16', 'Stella Medica', 'Rueil-Malmaison', 'Stella Medica est un cabinet de recrutement bien implanté dans le milieu\r\nmédical.\r\n\r\nEn partenariat avec une société de conseil informatique, nous\r\ndéveloppons pour nos propres besoins et dans une optique de\r\ncommercialisation des outils de gestion de recrutement.\r\n\r\nDans le cadre de ce développement vous travaillerez sur un module de\r\ngestion d\'analyse des données candidat.\r\n\r\nLes algorithmes à intégrer ou développer porteront sur les éléments\r\nsuivants :\r\n\r\n- Dans le cadre de l\'analyse de CV :\r\n  o Identification de la nature et de la langue du document\r\n  o Détection des informations dans le texte tels que (exemples simples) :\r\n    Nom, prénom, date de naissance, adresse, métier et niveau\r\n    d\'expérience\r\n- Détection de documents similaires\r\n- Génération de résumé, dérivation de ce résumé en plusieurs langues\r\n  (anglais en particulier)\r\n- Amélioration du moteur de recherches multicritères existant\r\n- Recherche automatique dans les réseaux sociaux et mise en lumière de\r\n  points forts ou d\'incohérences\r\n\r\nVous travaillerez dans une équipe à dominante informatique et serez donc\r\nassez autonome. L\'équipe sera encadrée par un chef de projet\r\ninformatique expérimenté, dans une démarche de développement logiciel\r\nprofessionnel : démarche CMMI, outils de gestion de projet, de partage\r\ndes sources et de gestion des tests.\r\n\r\nLa plateforme de développement est principalement Microsoft : ASP.NET MVC en\r\nC#, composants C# ; SQL Server.\r\n\r\nVous cherchez idéalement un stage de fin d\'études Bac +5 en Traitement\r\nAutomatique de la Langue (TAL) ou Ingenierie Linguistique. Le résultat\r\nde votre travail devra être « convertible en programme informatique »,\r\nphase que vous pourrez vous-même éventuellement mettre en oeuvre.\r\n\r\nStage de longueur modulable de 4 à 6 mois à partir de février 2014 situé\r\nà Rueil-Malmaison.\r\nRémunération selon profil, tickets restaurants, remboursement de 50% du\r\npass Navigo.\r\n\r\nContactez Philippe Martin avec votre CV et en précisant votre période de\r\nstage attendue : philippe.martin@stella-medica.fr'),
(198, '2014-01-06', 'IDIAP', 'Martigny (CH)', 'Internship in Natural Language Processing and Machine Translation \r\n(OP-20131220-163254)\r\n\r\nNLP Group, Idiap Research Institute, Martigny, Switzerland\r\n\r\nDescription: 	\r\n\r\nApplications are invited for a 6-month internship at the Master level in\r\nthe field of natural language processing and statistical machine\r\ntranslation. The internship is offered in relation to the Swiss MODERN\r\nproject (www.idiap.ch/project/modern) aiming at modeling discourse\r\nentities and relations for improving MT. The intern will work within the\r\nNLP group at the Idiap Research Institute.\r\n\r\nThe goal of the internship is to integrate existing tools for anaphora\r\nresolution (in-house and third party ones) with phrase-based SMT models\r\n(mainly using the Moses open-source system). Following previous work,\r\nthe intern will examine whether statistical predictions about the\r\nfeatures of target pronouns (gender, number, grammatical function, and\r\nothers) can be used when training SMT and when translating (decoding)\r\nnew texts. The intern will implement methods to derive such features,\r\nwill use the features in an SMT model (e.g. a factored one), and will\r\nmeasure the variation in translation quality.\r\n\r\nThe applicants should have a background in computer science or\r\nlinguistics, with previous experience in SMT and NLP being a strong\r\nadvantage. The applicants should have demonstrable programming skills in\r\nat least one programming language such as Perl or Python, Java or C/C++.\r\nExperience with the Moses system and/or anaphora resolution systems\r\nwould be a plus. Good command of English is mandatory and knowledge of\r\nanother European language such as French, German or Dutch would be an\r\nadvantage.\r\n\r\nThe screening of the applications will start on February 1st, 2014 and\r\nwill continue until the position is filled. The intended starting date\r\nis in spring 2014. The appointment is for 6 months, with a gross\r\ninternship salary of 2000 CHF per month. Participation in the MODERN\r\nproject will entail interaction with project partners at the\r\nUniversities of Zurich, Geneva, and Utrecht.\r\n\r\nHow to apply:\r\n\r\nPlease fill in and submit your application through the Idiap online\r\nrecruitment system, by clicking on the position\'s title at\r\nhttp://www.idiap.ch/education-and-jobs.\r\n\r\nContact information:\r\n\r\nFurther information about this position can be requested via the Idiap\r\nonline recruitment system or by contacting Dr. Andrei Popescu-Belis,\r\nhead of the NLP group.\r\n\r\nAbout Idiap: 	\r\n\r\nIdiap is an independent, non-profit research institute recognized and\r\nsupported by the Swiss Government, and affiliated with the Ecole\r\nPolytechnique Fédérale de Lausanne (EPFL). It is located in the town of\r\nMartigny in Valais, a scenic region in the south of Switzerland,\r\nsurrounded by the highest mountains of Europe, and offering exciting\r\nrecreational activities, including hiking, climbing and skiing, as well\r\nas varied cultural activities. It is within close proximity to Geneva\r\nand Lausanne. Although Idiap is located in the French part of\r\nSwitzerland, English is the working language. Free French lessons are\r\nprovided.\r\n\r\nIdiap offers competitive salaries and conditions at all levels in a\r\nyoung, dynamic, and multicultural environment. Idiap is an equal\r\nopportunity employer and is actively involved in the \"Advancement of\r\nWomen in Science\" European initiative. The Institute seeks to maintain a\r\nprinciple of open competition (on the basis of merit) to appoint the\r\nbest candidate, provides equal opportunity for all candidates, and\r\nequally encourage both genders to apply.\r\n\r\nAndrei Popescu-Belis'),
(199, '2014-01-06', 'MarketScience', 'Orléans', 'Titre : \"Extraction d\'information dans la presse financière\"\r\n\r\nMarketScience est une start-up en finance, qui développe un centre de\r\nData-Mining intégré à une appli. Cette appli sera commercialisée sur la\r\nplateforme Bloomberg, à une clientèle de professionnels de la finance.\r\n\r\nMarketScience combine modélisation des séries financières et\r\nmedia-mining. L\'extraction d\'information financière spécifique à nos\r\nbesoins se fait en mobilisant des algos de TAL.\r\n\r\nCes algos permettent de\r\n\r\n1. déterminer la nature de l\'article et sa probabilité de contenir une\r\n   information pertinente pour notre analyse\r\n\r\n2. isoler l\'information nécessaire et la relier à l\'évolution sur\r\n   certains marchés\r\n\r\n3. catégoriser cette information au sein de facteurs économiques\r\n   pré-identifiés\r\n\r\nCe travail se faisant tout d\'abord en anglais (80% de la volumétrie\r\njournalière), mais aussi en français, allemand, italien, russe et\r\nchinois.\r\n\r\nVous travaillerez essentiellement avec les outils suivants : Python,\r\nUnitex et MySQL/ SQL.\r\n\r\nUne connaissance des techniques du TAL (Traitement Automatique des\r\nLangues) ou des techniques d\'apprentissage et de classification (SVM,\r\nCRF, etc.)  est considérée comme fortement souhaitable.\r\n\r\nCe stage se déroulera au sein d\'une équipe pluridisciplinaire composée\r\nde statisticiens, économistes, programmeurs et ingénieurs TAListes.\r\n\r\nDurée du Stage : 4 à 6 mois à partir de février 2014. Embauche à la clé.\r\nLieu du Stage : Orléans (45)\r\n\r\nRémunération : 1200 Eur net min.\r\n\r\nContactez-moi sur LinkedIn : Nicolas Boitout.'),
(200, '2014-01-08', 'Eptica Lingway', 'Boulogne-Billancourt', 'Début : Février/Mars 2014\r\n\r\nDurée : 4 à 6 mois\r\n\r\nLieu : Boulogne-Billancourt\r\n\r\nEptica Lingway, filiale du groupe Eptica, développe des produits\r\nd\'analyse automatique de CV et de recherche de documents RH à\r\ndestination des recruteurs (gamme LEA). Ces outils mettent en oeuvre des\r\ngrammaires d\'analyse, un réseau sémantique adapté pour le monde des RH\r\net des stratégies de recherche documentaire spécifiques.  L\'analyseur\r\nLeaCV est disponible en français, anglais, allemand, espagnol.\r\n\r\nDans le cadre des évolutions de l\'offre LEA, Eptica-Lingway propose des\r\nstages conventionnés niveau M2, basés à Boulogne-Billancourt.\r\n\r\nAu sein de l\'équipe R&D, le candidat participera aux tâches suivantes:\r\n- Adaptation de l\'analyseur de CV et d\'offres à de nouvelles langues ou\r\n  localisations,\r\n- Amélioration du réseau sémantique orienté RH utilisé pour la recherche\r\n  et le matching CV/offres,\r\n- Etude et implémentation de nouvelles stratégies de recherche de\r\n  documents,\r\n- Constitution de corpus de référence et validation des résultats\r\n \r\nCompétences requises :\r\n- Traitement Automatique des Langues (étude de corpus, moteur de\r\n  recherche, grammaires locales, techniques de « machine learning »)\r\n- Des connaissances en programmation/scripting (Java, Groovy, Perl, ...)\r\n  sont un plus ainsi que la maîtrise de plusieurs langues européennes\r\n- Bonnes capacités d\'analyse\r\n- Facilité à travailler en équipe\r\n\r\nContact:\r\nHugues de Mazancourt\r\nhugues.de-mazancourt@eptica.com'),
(201, '2014-01-13', 'LIMSI', 'Orsay', 'Proposition de stage Master  / Ecole d\'Ingénieur\r\nLIMSI-CNRS (Paris-Sud) et LI (Tours)\r\n\r\nRésumé\r\n\r\nProposition de stage de fin d\'études ou de Recherche de niveau Bac+5\r\n(Master, Ecole d\'Ingénieur) en Informatique appliquée au Traitement\r\nAutomatique des Langues d\'une durée de 4 mois minimum.\r\n\r\nContexte scientifique\r\n\r\nLe LIMSI-CNRS (Paris-Sud) et le LI (Tours) proposent un sujet de stage\r\ncommun dans le cadre du projet de recherche TMH (Télécommunications,\r\nMobilité et Handicap) financé par la société BAMSOO. Le sujet porte sur\r\nle Traitement Automatique des Langues (TAL) par utilisation de\r\ntechniques de fouille de données. La tâche concernée est la\r\nreconnaissance des entités nommées (REN), qui permet d\'extraire les noms\r\nde personnes, de lieux, d\'organisations, d\'unités monétaire ou\r\ntemporelles dans des textes. Pour cela, sont implémentés des systèmes\r\nplus ou moins supervisés (des automates aux CRF) qui s\'appuient sur\r\nd\'autres traitements TAL (morphologie, morpho-syntaxe) et/ou des\r\nlexiques à large couverture. Ces systèmes sont régulièrement mis en\r\ncompétition lors de campagne d\'évaluation.\r\n\r\nLe système que nous avons développé (mXS) met en ½uvre des techniques de\r\nfouille de données. Son originalité consiste à rechercher séparément les\r\nbalises de début et de fin de chaque entité nommée. Pour ce faire, le\r\nsystème énumère les motifs linguistiques (séquentiels hiérarchiques) qui\r\nforment le contexte de ces balises et filtrent les motifs d\'intérêt\r\ncomme \"règles d\'annotation\". mXS a obtenu de bonnes performances\r\n(3ème/8) dans le cadre de la campagne d\'évaluation ETAPE, en particulier\r\ndans des contextes bruités (transcriptions automatiques). Cependant,\r\npour améliorer encore les performances du système, il s\'agit de\r\ndéterminer si les choix de modélisation effectués avantagent ou\r\npénalisent le système. Ce stage a pour objectif de mener des travaux\r\nexpérimentaux permettant d\'apporter de nouvelles perspectives sur les\r\navantages et inconvénients de notre approche.\r\n\r\nTravail à réaliser\r\n\r\nEn préliminaire, la personne recrutée se familiarisera avec les\r\ndifférentes briques du système, dont en particulier :\r\n\r\n- les prétraitements (morpho-syntaxe, lexiques) qui enrichissent les\r\n  textes,\r\n- le programme d\'extraction de motifs séquentiels hiérarchiques (fouille\r\n  de données),\r\n- les modèles (symboliques et/ou statistiques) qui utilisent les motifs\r\n  pour annoter des textes.\r\n\r\nEnsuite, une étude approfondie sera menée sur l\'apport des techniques\r\nsupervisées par insertion des balises d\'annotation par rapport aux\r\napproches de classification mot-à-mot. Cette étude sera amorcée par une\r\ncomparaison des erreurs sur la campagne ETAPE commises par mXS avec\r\ncelles commises par un système à base de transducteurs et un CRF (voire\r\nà des version hybrides). Les expérimentations et études à mener par la\r\nsuite seront décidées selon déterminées selon les résultats de cette\r\nétude. A terme, l\'objectif est de déterminer quelles sont les\r\nperspectives d\'évolution les plus prometteuses pour les systèmes de REN.\r\n\r\nEn cas d\'avancée satisfaisante du travail, le stage pourra être élargi à\r\nl\'étude des méthodes utilisant les motifs séquentiels hiérarchiques pour\r\nle traitement du langage. Par exemple, cela pourra consister en\r\nl\'implémentation d\'outils qui permettent de caractériser des corpus\r\nselon les motifs qui en ont été extraits automatiquement. De manière\r\nplus générale, l\'idée est de découvrir de nouveaux liens possibles entre\r\nles méthodes formelles (motifs organisés au sein de treillis) et des\r\ntâches liées au TAL.\r\n\r\nProfil recherché\r\n\r\nLa personne recrutée sera en cycle terminal d\'études en informatique, de\r\nniveau Bac+5 (Master informatique professionnel, recherche ou\r\nindifférencié, école d\'ingénieur). Des compétences en Traitement\r\nAutomatique des Langues et/ou en Fouille de Données seront\r\nappréciées. Dans le cas d\'un(e) étudiant(e) en Master Recherche, le\r\nsujet de stage pourra être adapté aux attentes de\r\nl\'étudiant. Potentiellement, ce travail pourra donner lieu à\r\ncommunication dans des conférences scientifiques.\r\n\r\nRémunération\r\n\r\nRémunération maximale prévue par la réglementation à savoir 436,05¤ par\r\nmois, pour une durée de 4 mois de stage minimum (prolongation de la\r\ndurée du stage jusqu\'à 6 mois à la demande de l\'étudiant ou de son\r\nétablissement). Cette rémunération sera assurée dans le cadre d\'un\r\nprojet industriel financé par la société BAMSOO.\r\n\r\nLieu d\'exercice\r\n\r\nLe stage se déroulera dans les locaux du Laboratoire d\'Informatique pour\r\nla Mécanique et les Sciences de l\'Ingénieur (LIMSI-CNRS), Université\r\nParis-Sud, Rue John von Neumann, 91403 Orsay, au sein de l\'équipe ILES\r\n(Information, Langue Ecrite et Signée). Le stage sera encadré part\r\nDamien Nouvel, postdoc au LIMSI et Jean-Yves Antoine, professeur de\r\nl\'Université François Rabelais de Tours (équipe BDLTN).\r\n\r\nDépôts de candidature\r\n\r\nContact : damien.nouvel@limsi.fr\r\nMerci de déposer un CV détaillé de vos activités passées, accompagné\r\nd\'une lettre de motivation et de vos relevés de notes des deux dernières\r\nannées d\'études.\r\n\r\nLiens utiles\r\n\r\n- Système mXS : http://damien.nouvels.net/fr/mxs\r\n- Laboratoire LIMSI (groupes ILES et TLP) : http://www.limsi.fr\r\n- Laboratoire LI (équipe BDTLN) :\r\n  http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp\r\n- Campagne Etape : http://www.afcp-parole.org/etape.html'),
(202, '2014-01-13', 'Viseo', 'Grenoble', 'Début : Février/Mars 2014\r\n\r\nDurée : 4 à 6 mois\r\n\r\nLieu : Grenoble\r\n\r\nLe groupe VISEO est un des principaux acteurs multi-spécialiste des\r\nsystèmes d\'information. Ce positionnement stratégique soutenu par\r\nl\'innovation technologique a conduit la société à annoncer en décembre\r\n2011, la création de son centre de recherche et développement dans le\r\nbut d\'aider Viseo à accélérer le rythme de développement de son activité\r\nd\'édition de logiciels innovants et sectoriels ainsi que de positionner\r\nle groupe sur les axes stratégiques porteurs d\'avenir. La R&D réalisée\r\nau sein de Viseo, s\'articule autour des 3 thématiques de recherche\r\nsuivantes : l\'analyse de données, le génie logiciel, les interfaces et\r\nles usages.  De façon concrète, le pôle Recherche et Innovation recense\r\nun pool d\'ingénieurs-experts et de 6 chercheurs dédiés aux activités de\r\nR&D, et participe actuellement, conjointement à 1 projet de recherche\r\neuropéen TIER (autour de la prévention des risques chimiques) et 3\r\nprojets nationaux ITM Factory (FUI14 autour de la refonte des systèmes\r\nd\'information), MALTHY (ANR autour de la vérification de logiciels\r\nembarqués) et SYNODOS (ANR Tecsan autour de l\'analyse automatique de\r\ndossiers patients à des fins épidémiologiques).\r\n\r\nDans le cadre du projet SYNODOS (http://www.synodos.fr) Viseo propose un\r\nstage conventionné niveau M2, basé à Grenoble.\r\n\r\nAu sein de l\'équipe R&D, le candidat participera aux tâches suivantes:\r\n\r\n- développement d\'un métalangage d\'interrogation d\'une base de\r\n  connaissance au-dessus de SPARQL\r\n\r\n- écriture, en collaboration avec les médecins, de règles de transition\r\n  (entre règles experts et règles linguistiques)\r\n\r\n- modélisation des connaissances médicales à partir de l\'analyse\r\n  linguistique (en utilisant OWL)\r\n\r\nCompétences requises :\r\n\r\n- Traitement Automatique des Langues (syntaxe, rôles thématiques)\r\n\r\n- Web sémantique ( RDF,  OWL, Protégé, SPARQL)\r\n\r\n- Bonnes capacités de modélisation des connaissances\r\n\r\n- Facilité à travailler en équipe\r\n\r\nContact:\r\n\r\nFrédérique Segond\r\nfsegond@viseo.net\r\n\r\nDr Frédérique SEGOND\r\nLe Pulsar 4 av du Doyen Louis Weil 38000 GRENOBLE\r\nTél.  +33 (0)9 72 31 82 50\r\nMob. +33 (0)6 89 44 60 88\r\nfsegond@viseo.net\r\nResponsable Recherche et Développement\r\nResearch & Development Manager\r\nhttp://www.viseo.net/en/viseo-research-and-development\r\nhttp://www.viseo.net/en/members-center-research-and-development'),
(203, '2014-01-16', 'Telecom ParisTech', 'Paris', '*Modèle de dialogue multimodal pour recruteur virtuel*\r\n\r\nCatherine Pelachaud, Magalie Ochs\r\n\r\n*Résumé *\r\n\r\nLe sujet de stage s\'insère dans le projet européen Tardis « Training\r\nyoung Adult\'s Regulation of emotions and Development of social\r\nInteraction Skills » (tardis.project.eu).Le but du projet est de\r\nconstruire une plate-forme basée sur des scénarios de simulation de jeux\r\nsérieux pour les jeunes de 18-25 ans à risque d\'exclusion. Le jeu leur\r\npermettra d\'explorer, pratiquer et d\'améliorer leurs compétences\r\nsociales. Dans le jeu, l\'interaction avec les jeunes se fait par le\r\nbiais agents virtuels (AV) agissant à titre de recruteurs dans des\r\nscénarios d\'entretiens d\'embauche. Les AV sont conçus pour maintenir des\r\ninteractions socio-émotionnelles crédibles avec leurs interlocuteurs. En\r\nmanipulant les paramètres de l\'agent, il est possible de simuler\r\ndifférents styles de recruteur. Une telle plateforme permet aux jeunes\r\npersonnes de s\'exercer à passer des entretiens tout en faisant attention\r\nà leur attitude sociale. Le but principal de la plateforme Tardis est de\r\npermettre à des jeunes en difficulté de prendre conscience de\r\nl\'importance des comportements socio-émotionnels.\r\n\r\n*Objectifs*\r\n\r\nL\'agent, recruteur virtuel, peut rendre l\'entretien d\'embauche avec un\r\njeune stagiaire plus ou moins difficile. L\'agent peut le mettre à\r\nl\'aise, le provoquer, ou tout simplement lui demander des informations,\r\netc. En posant telle ou telle question, ou bien en choisissant tel ou\r\ntel comportement, l\'agent peut montrer diverses attitudes sociales au\r\njeune. Suivant la réaction du jeune au cours de l\'entretien, en\r\nparticulier suivant son niveau d\'anxiété, l\'agent peut se montrer\r\nréconfortant et rendre l\'interview plus facile ; ou bien déstabilisant\r\net rendre l\'interview plus difficile.Le type de question et la manière\r\nde les poser (au niveau sémantique et comportementale) traduisent\r\nl\'attitude de l\'agent recruteur.\r\n\r\nL\'objectif du stage est de développer un modèle de dialogue multimodal\r\npour un agent virtuel jouant le rôle d\'un recruteur. Le recruteur peut\r\navoir plusieurs attitudes sociales face au jeune. Le modèle de dialogue\r\ns\'appuiera sur un premier modèle existant qu\'il complètera suivant :\r\n\r\n- Difficulté de l\'entretien\r\n\r\n- Attitude sociale de l\'agent\r\n\r\n- Représentation des connaissances (CV du stagiaire et description de la\r\n  société pour le recrutement)\r\n\r\n- Détection des mots clés\r\n\r\n- Perception de l\'attitude sociale du jeune stagiaire\r\n\r\nLe modèle computationnel vise donc à définir quelle question posée et\r\ncomment la communiquer au jeune stagiaire. Il se basera sur des outils\r\nexistants :\r\n\r\n- DISCO for games D4G, modèle de dialogue (Rich & Sidner, 12)\r\n\r\n- Greta, plateforme d\'agent virtuel (Ochs et al, 13) qui inclue aussi un\r\n  module de détection de mots clés et un module de détection des\r\n  expressions émotionnelles du visage\r\n\r\n*Encadrant* : Catherine Pelachaud,\r\ncatherine.pelachaud@telecom-paristech.fr ; Magalie Ochs\r\n\r\n*Lieu du stage* : Telecom-ParisTech\r\n\r\n*Financement* : 6 mois de Master, 6* 1/3 du SMIC'),
(204, '2014-01-17', 'Xerox Research Centre Europe', 'Grenoble', 'Internship in NLP at Xerox Research Centre Europe, Grenoble, France\r\n\r\n\r\nTitle:  Discourse Structure Prediction of Email Replies\r\n\r\nDescription :\r\n\r\nThe goal of the internship is to learn and predict the structure of an\r\nemail reply. The internship will explore techniques for learning the\r\ndiscourse structure of email replies from an existing set of email\r\nconversations. It will also involve predicting the discourse structure\r\ngiven a new conversation and guiding the reply composer appropriately\r\nthrough a visually attractive interface.\r\n\r\n\r\nThe ideal candidate is a Computer Science student (preferably doing\r\nPh.D.) with background in Natural Language Processing and Machine\r\nLearning. Knowledge of Java or Python is a must, and experience of web\r\ntechnologies (javascript etc) is highly desirable.\r\n\r\nContacts : Sriram Venkatapathy  , Marc Dymetman\r\n\r\nMore information of the position and centre at :\r\n\r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/Discourse-Structure-Prediction-of-Email-Replies'),
(205, '2014-01-20', 'EDF R&D', 'Clamart', 'STAGE INGÉNIERIE LINGUISTIQUE\r\nSUJET 2014: ÉVALUATION D\'OUTILS TEXT MINING\r\nDURÉE : 6 MOIS ENVIRON\r\n\r\n1.  CONTEXTE\r\n\r\nLe volume des données numériques textuelles, disponibles sur l\'Internet\r\n(forums, twitters etc.) ou relatives à des contacts client (enquêtes,\r\ncentre d\'appel etc.), augmente chaque année. L\'analyse de ces\r\ninformations, structurées ou non, est, aujourd\'hui, un impératif\r\nstratégique pour une entreprise telle qu\'EDF. Dans ce cadre, et dans\r\nl\'objectif de toujours mieux connaître les besoins des clients,\r\nl\'exploitation de ces documents implique l\'utilisation de méthodes et\r\nd\'outils adaptés. Au coeur de ces problématiques les outils de Text\r\nMining sont de plus en plus nombreux et performants, ainsi nous\r\nsouhaitons étudier les principaux outils évoluant sur le marché\r\naujourd\'hui.\r\n\r\n2.  SUJET DU STAGE\r\n\r\nDepuis 2003, les données textuelles sont essentiellement traitées à la\r\nR&D via des solutions développées par l\'éditeur TEMIS (Text-Mining\r\nSolution).  Ce choix fait suite à différentes campagnes de veille sur\r\nles outils de Text Mining.  Un protocole de test d\'outils de Text Mining\r\navait été défini et appliqué à l\'étude approfondie de différents\r\nlogiciels.\r\n\r\nDans le cadre du suivi des évolutions des outils de Text Mining, nous\r\nsouhaitons effectuer une nouvelle évaluation des outils d\'analyse de\r\ndonnées contenant du texte.\r\n\r\nCe stage se décomposera en 3 parties :\r\n\r\n- Veille d\'outils de Text Mining : Il s\'agira de mener une étude de\r\n  marché des outils existants aujourd\'hui.\r\n\r\n- Evaluation : A partir des solutions émergentes du marché, il s\'agira\r\n  d\'évaluer une sélection d\'outils (entre 3 et 4) jugés à priori\r\n  intéressants par rapport aux besoins d\'EDF.\r\n\r\n- Perspectives : Dans un second temps, il s\'agira d\'identifier les\r\n  perspectives envisageables quant à l\'alliance du Text Mining et du Web\r\n  sémantique au regard des besoins EDF.\r\n\r\nINFORMATIONS PRATIQUES\r\n\r\nInterlocuteurs:\r\nDelphine Lagarde        01.47.65.39.75  delphine.lagarde@edf.fr\r\nAnne Peradotto  01.47.65.44.89  anne.peradotto@edf.fr\r\n\r\nLieu du stage: \r\nEDF R&D - Département ICAME\r\n1, avenue du Général de Gaulle\r\n92141 Clamart Cedex \r\n\r\nDate & Durée : Début 2014 - 6 mois environ\r\n\r\nRémunération: A définir (environ 1.000¤/mois)'),
(206, '2014-01-20', 'LIMSI', 'Orsay', 'Stage M2 : Analyse temporelle des dossiers électronique patient.\r\n[Analysis of temporal relations in Electronic Health Records]\r\n\r\nMots-clés : traitement automatique de la langue, classification, analyse\r\ntemporelle, domaine biomédical\r\nDurée : 5 mois\r\nNiveau : Master 2 Recherche\r\nLieu : LIMSI-CNRS, Orsay\r\n\r\nLe contenu et l\'ambition du stage pourront être modulés en fonction du\r\nniveau d\'étude et de la durée du stage du candidat.\r\n\r\nRésumé :\r\n\r\nL\'objectif de ce stage M2R est d\'analyser les dossiers électroniques\r\npatient du point de vue chronologique. À partir d\'un ensemble de\r\ndocuments contenus dans le dossier d\'un patient, ce travail permettra de\r\nrepérer les événements saillants de l\'historique médical du patient\r\nainsi que les marqueurs temporels associés afin de les agréger dans une\r\nchronologie synthétique.\r\n\r\nContexte :\r\n\r\nL\'analyse temporelle de textes d\'information a pour but général de mieux\r\nlocaliser dans le temps les événements décrits dans ces textes, et donc\r\nd\'alimenter de façon plus précise des moteurs de recherche ou des outils\r\nd\'extraction d\'information. Pour cela, la première étape est de détecter\r\ncorrectement les expressions temporelles de ces textes. Ces expressions\r\ntemporelles peuvent être des dates absolues, c\'est-à-dire que l\'on peut\r\nplacer sans ambiguïté sur l\'axe des temps (par exemple, \"le 14 janvier\r\n2008\"), mais aussi des dates relatives, qui nécessitent une phase de\r\nrésolution ou de normalisation (par exemple, \"le 14 janvier dernier\",\r\n\"dans 6 semaines\"). Dans le cadre du dossier électronique patient, des\r\nexpressions temporelles propres au domaine de spécialité, le domaine\r\nmédical, peuvent également être rencontrées (par exemple, \"à 18 semaines\r\nd\'aménorrhée\", \"à j+1\").\r\n\r\nLes techniques d\'analyse temporelle des textes ont fortement progressé\r\nces dernières années, mais s\'attachent en général au domaine\r\njournalistique et particulièrement au cadre des dépêches. Nous\r\nsouhaitons étudier un autre domaine de spécialité, le domaine médical,\r\nainsi qu\'un type de document particulier, le dossier électronique\r\npatient. Nous nous intéressons à la caractérisation et au repérage\r\nautomatique des expressions temporelles dans les dossiers électroniques\r\npatient afin de déterminer si un traitement spécifique au domaine\r\nmédical doit être mis en ½uvre ou si des outils développés pour un autre\r\ndomaine sont directement utilisables.\r\n\r\nTravail à réaliser :\r\n\r\nSelon le niveau d\'étude de la personne choisie, nous pourrons nous \r\nintéresser à une ou plusieurs des problématiques suivantes :\r\n\r\n- Utilisation et adaptation des outils d\'analyse temporelle sur les\r\n  documents cliniques\r\n\r\n- Réconciliation des expressions temporelles issues de documents\r\n  différents\r\n\r\n- Création d\'une ligne temporelle pour représenter l\'historique d\'un\r\n  patient\r\n\r\nOn utilisera un corpus de plusieurs centaines de documents cliniques\r\nde-identifiés en français.\r\n\r\nLe stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue, en terminologie\r\nbiomédicale et/ou en apprentissage automatique seront un plus.\r\n\r\nRémunération : gratifications (436.05 ¤ par mois + participation aux\r\nfrais de transports)\r\n\r\nDépôts de candidature : envoyez un CV accompagné d\'une lettre de \r\nmotivation et de relevés de notes récents à :\r\nAurelie.Neveol[at]limsi.fr\r\nXavier.Tannier[at]limsi.fr'),
(207, '2014-01-22', 'LIMSI', 'Orsay', 'Le groupe ILES du LIMSI-CNRS (Orsay) propose des stages pour différents\r\nniveaux d\'études dans les thématiques suivantes:\r\n\r\n- Traitement des Langues Signées\r\n- Recherche et Extraction d\'Information, Question-Réponse\r\n- Constitution de Ressources pour le TAL\r\n- Evaluation pour le TAL\r\n- Paraphrase et Traduction Automatique\r\n\r\nLa description des différentes propositions se trouve sur la page\r\nsuivante:\r\n\r\nhttp://www.limsi.fr/Scientifique/iles/propositions\r\n\r\nLes candidats devront contacter directement les responsables du/des\r\nstages, en joignant un descriptif de leur parcours sous forme d\'un court\r\nCV, des relevés de notes récents, et en précisant leur motivation pour\r\nles stages concernés.\r\n\r\nPage du groupe: http://www.limsi.fr/Scientifique/iles\r\nPage du laboratoire: http://www.limsi.fr'),
(208, '2014-01-22', 'STL', 'Lille', 'ÉVOLUTION ET VISUALISATION DES ÉMOTIONS\r\n\r\ncontact : Natalia Grabar (natalia.grabar@univ-lille3.fr)\r\n\r\n\r\nLes forums issus du domaine médical permettent à des internautes\r\nd\'échanger à propos de leur santé. Intermédiaires entre discours oral et\r\nécrit, les forums de discussion sont des espaces d\'échanges asynchrones\r\nde messages textuels. Ce nouveau mode de communication est très prisé\r\ndes patients car associé à une grande liberté du discours due notamment\r\nà l\'anonymat. Dans ce contexte éminemment subjectif, la caractérisation\r\net la compréhension des perceptions que les patients ont de leur maladie\r\net du suivi médical est difficile, mais néanmoins particulièrement\r\nintéressante pour les professionnels de santé. De nombreux verrous sont\r\nassociés à l\'analyse semi-automatique de ces forums, en particulier la\r\nvolumétrie des textes et leur hétérogénéité.\r\n\r\nDans le cadre du projet ANR TecSan Ravel et du projet MSHM Parlons de\r\nnous, nous proposons un stage de Master 2. Ce stage fait suite aux\r\ntravaux déjà réalisés dans l\'équipe sur la détection et l\'annotation de\r\nla subjectivité (incertitude, émotions...) dans les documents\r\nbiomédicaux (Grabar & Hamon, 2009, Périnet et al, 2011,\r\nChauveau-Thoumelin & Grabar, 2014).\r\n\r\nPlus particulièrement, le stage aura pour objectif de :\r\n\r\n- travailler avec les documents provenant de différents genres médicaux\r\n  (cliniques, scientifiques, forum, etc.)\r\n\r\n- exploiter et améliorer les annotations des documents avec différents\r\n  niveaux de spécificité\r\n\r\n- proposer une visualisation de l\'évolution des émotions et une\r\n  représentation adéquate des données\r\n\r\nL\'ensemble du travail sera effectué en collaboration avec les chercheurs\r\nen traitement automatique de langues (TAL), en linguistique (syntaxe et\r\nsémantique) et en informatique.\r\n\r\nLe stagiaire sera amené à utiliser des outils existants et à développer\r\nses propres programmes pour mieux analyser et visualiser les données.\r\n\r\nPrérequis:\r\n\r\n- connaissances en TAL, informatique et linguistique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et synthèse de la littérature scientifique\r\n\r\nLieu du stage : Lille, Paris ou Montpellier\r\n\r\nLe stage est rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.'),
(209, '2014-01-22', 'STL', 'Lille ou Paris', 'EXTRACTION D\'INFORMATIONS LIÉES AUX CONTROVERSES\r\n\r\ncontact : Natalia Grabar (natalia.grabar@univ-lille3.fr)\r\n\r\n\r\nLes méthodes du Traitement Automatique des Langues permettent\r\nd\'effectuer plusieurs tâches très coûteuses pour un utilisateur humain,\r\ncomme par exemple l\'extraction d\'information, les questions/réponses,\r\nl\'inférence textuelles et la fouille de textes de manière\r\ngénérale. Cette proposition de stage Master 2 concerne la détection\r\nautomatique du risque chimique, qui crée souvent des situations de\r\ncontroverse.\r\n\r\nLe risque chimique couvre les situations où les produits chimiques sont\r\nou peuvent être dangereux pour la santé humaine, animale et pour\r\nl\'environnement. Une des controverses actuelles concerne le risque\r\nchimique lié au bisphénol A et aux phtalates, qui affectent le système\r\nhormonal des individus. Dans les situations de controverse, la détection\r\nd\'informations objectives (risque chimique) peut être brouillée par des\r\ninformations subjectives propres aux controverses (incertitudes,\r\nopinions, etc.). L\'objectif du stage est d\'améliorer un système\r\nd\'extraction d\'information sur le risque chimique existant.\r\n\r\nPlus particulièrement, les tâches visées sont les suivantes :\r\n\r\n- travailler avec les documents produits dans le domaine de chimie\r\n  (chercheurs, institutions...)\r\n\r\n- améliorer les ressources linguistiques existantes\r\n\r\n- exploiter et améliorer les annotations des documents avec différents\r\n  niveaux de spécificité\r\n\r\n- ajuster les modèles d\'apprentissage automatique\r\n\r\nL\'ensemble du travail sera effectué en collaboration avec les chercheurs\r\nen traitement automatique de langues (TAL), en risque chimique et en\r\ninformatique.\r\n\r\nLe stagiaire sera amené à utiliser des outils existants et à développer\r\nses propres programmes pour mieux analyser et visualiser les données.\r\n\r\nPrérequis:\r\n\r\n- connaissances en TAL, informatique et linguistique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et synthèse de la littérature scientifique\r\n\r\nLieu du stage : Lille ou Paris\r\n\r\nLe stage est rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.'),
(210, '2014-01-31', 'Xerox Research Centre Europe', 'Grenoble', 'An open internship position on a mix of string algorithms, grammatical\r\ninference and statistical machine learning\r\n\r\n\r\nDescription\r\n\r\nWe are looking for a motivated intern for a project involving the use\r\nof sequential patterns for the inference of grammars.\r\n\r\nThe Smallest Grammar Problem is the problem of finding the smallest\r\ncontext-free grammars that generates exactly one given sequence. We\r\nplan to generalize this in order to find grammars which generate a set\r\nof natural language documents with a strong but hidden structure. This\r\nstructure will then be converted into additional features (through\r\ntree kernels for example) in our analytics pipeline or alternatively\r\nas a starting template for existing multilingual authoring tools.\r\n\r\nRequirements:\r\n\r\n    Research-oriented master student or PhD candidate in computer\r\n    science\r\n\r\n    Knowledge of standard text algorithms and data structures\r\n\r\n    Knowledge of formal grammars (a course covering the Hopcroft &\r\n    Ullman book or equivalent for example)\r\n\r\n    Knowledge in statistical machine learning applied to text is a\r\n    strong plus\r\n\r\n    Fluency in either C, C++ or Java is a plus\r\n\r\nThe intern will work closely with researchers in a very international\r\nenvironment, and will be strongly encouraged to produce scientific\r\npublications.\r\n\r\nDuration: 5-6 months\r\nStart Date: March-April 2014\r\n\r\nApplication instructions\r\n\r\nInformal inquiries are welcome and can be made at\r\nmatthias.galle@xrce.xerox.com .\r\n\r\nTo submit an application, please send your CV and cover letter to both\r\nxrce-candidates@xrce.xerox.com and matthias.galle@xrce.xerox.com .\r\n\r\nIdeally, you will also include in your CV people we can contact for\r\nletters of recommendation.\r\n\r\n\r\nlink: http://www.xrce.xerox.com/About-XRCE/Internships/Grammatical-Inference-with-sequential-motifs'),
(211, '2014-01-31', 'Lattice', 'Montrouge', 'Proposition de stage de Master 2e année :\r\n\r\nCréation de la maquette numérique d\'une série de documents traitant\r\nd\'archéologie\r\n\r\nDescriptif :\r\n\r\nLe stage s\'inscrit dans le domaine des humanités numériques, dans le\r\ncadre d\'un projet EITAB, PEPS PSL-CNRS, mettant en oeuvre une\r\ncollaboration entre le laboratoire Lattice (UMR8094, analyse\r\nlinguistique et traitement automatique des langues,\r\nhttp://www.lattice.cnrs.fr/) et le laboratoire AOROC (UMR 8546,\r\narchéologie, http://www.archeo.ens.fr/). Les deux laboratoires font\r\npartie de l\'Ecole normale supérieure et collaborent au sein du\r\nlaboratoire d\'excellence TransferS (http://www.transfers.ens.fr/).\r\n\r\nLe stage vise à créer, à partir d\'un document textuel traitant\r\nd\'archéologie, la maquette d\'un ebook. Il s\'agit de mettre en place un\r\naccès pertinent et convivial à un texte de spécialité à partir de\r\ndonnées extraites du texte (termes structurés en index, etc.). On\r\ns\'intéressera donc particulièrement aux outils de structuration (base\r\nde données, mise en place de liens entre termes, etc.) et de mise en\r\nforme (xml, html, css) des données. Une collaboration étroite avec les\r\ninterlocuteurs côté archéologie est indispensable. Le LATTICE dispose\r\nd\'un extracteur de termes et les outils classiques de structuration de\r\ndonnées et de création d\'ontologies pourront être utilisés.\r\n\r\nLe stage porte essentiellement sur l\'interaction entre texte et\r\nindex. En fonction des compétences du candidat retenu, on pourra aussi\r\ns\'intéresser à l\'interaction entre texte et cartes géographiques (pour\r\npermettre de visualiser les principaux sites archéologiques, créer des\r\nliens entre objets d\'étude et zones géographiques, et pouvoir répondre\r\nà des questions comme : « sur quels sites de la région tourangelle ont\r\nété trouvées des tuiles à rebord ? »). On pourra aussi, si le temps le\r\npermet, s\'intéresser à l\'adaptation du rendu final en fonction du\r\nsupport (ordinateur, tablette, etc.).\r\n\r\nLe stage a une finalité avant tout pratique : il s\'agit de mettre en\r\nplace une maquette opérationnelle montrant un exemple concret de\r\nréalisation possible. L\'archéologie se prête particulièrement bien à\r\nl\'enrichissement multimédia du texte numérique.\r\n\r\n\r\nMission du stage\r\n\r\nCréer la maquette numérique d\'une série de documents traitant\r\nd\'archéologie.\r\n\r\n- veiller à la cohérence des données (corriger et enrichir les index\r\n  existants)\r\n- structurer le document texte\r\n- créer index et requêtes dynamiques.\r\n- compléter des bases existantes qui génèrent des cartes en\r\n  automatique\r\n- intégrer les cartes aux requêtes et index.\r\n\r\n\r\nCompétences requises\r\n\r\n- connaissance d\'outils d\'édition électronique\r\n- connaissance des langages de structuration de document (xml, html,\r\n  css, etc)\r\n- intérêt pour la mise en place de solutions applicatives, prise en\r\n  compte des besoins utilisateurs\r\n- connaissance des bases de données\r\n- qualité de rédaction en français et en anglais\r\n- un intérêt pour l\'archéologie serait un plus\r\n\r\nInformations complémentaires sur EITAB :\r\nhttp://www.archeo.ens.fr/spip.php?article586\r\n\r\nConditions\r\n\r\nLe stage se déroulera au laboratoire Lattice (à Montrouge,\r\nhttp://www.lattice.cnrs.fr/) pendant 6 mois, à partir d\'avril 2014 en\r\nétroite collaboration avec le laboratoire AOROC (à l\'ENS, 45 rue d\'Ulm\r\nà Paris). Ce stage est indemnisé suivant les règles en vigueur grâce à\r\nun projet PEPS de site co-financé par le CNRS et PSL.\r\n\r\nLieu\r\n\r\nLaboratoire LATTICE à Montrouge.\r\n\r\nEncadrants\r\n\r\nFrédérique Mélanie Becquet et Thierry Poibeau pour le LATTICE et\r\nKatherine Gruel pour AOROC.\r\n\r\nComment postuler ?\r\n\r\nEnvoyer un CV et une lettre de motivation à Thierry Poibeau et\r\nFrédérique Mélanie <prenom suivi du nom séparé par un point arobase\r\nens.fr> dès que possible et, dans tous les cas, avant le 15 février\r\n2014.'),
(212, '2014-02-03', 'SNCF', 'Paris', 'Intitulé : Extraction d\'informations sur les pratiques de mobilité\r\n\r\nLa Direction Innovation et Recherche de la SNCF recherche un stagiaire\r\npour travailler sur un projet d\'étude de la mobilité des voyageurs à\r\ntravers l\'analyse de données textuelles.\r\n\r\n*Activités du stage*\r\n\r\n------------------------------\r\n\r\nRéalisation d\'une plateforme d\'étiquetage sémantique de données\r\ntextuelles pour l\'analyse des pratiques de mobilité.\r\n\r\n*Thème*\r\n------------------------------\r\n\r\nLa société connaît depuis quelques années des changements majeurs dans\r\nles pratiques de mobilité, du fait d\'autres formes d\'organisation du\r\ntravail, de l\'émergence de nouveaux modes de transport,... Les voyageurs\r\ns\'expriment sur le web social à propos leurs déplacements, aussi bien en\r\nsituation normale qu\'en situation perturbée. Les messages contiennent\r\ndes informations sur les activités des voyageurs, leurs particularités\r\nsociologiques ou encore leurs motivations.\r\n\r\nUne analyse sémantique en fonction de tels critères est susceptible\r\nd\'apporter une meilleure connaissance des comportements, des besoins et\r\ndes attentes. Elle permet une compréhension nuancée et différenciée de\r\nla mobilité.\r\n\r\nLe stage aura pour objectif de contribuer à la mise en place d\'une\r\nplateforme d\'analyse de données pour l\'extraction d\'informations sur les\r\npratiques de mobilité.\r\n\r\n*Description *\r\n------------------------------\r\n\r\nLe stagiaire devra :\r\n\r\n- prendre connaissance du contexte du stage (SNCF, Direction Innovation\r\n  & Recherche, objectifs du stage et cadre de réalisation, situation\r\n  actuelle et interlocuteurs sur les sujets concernés, ...)\r\n\r\n- faire un état de l\'art des outils disponibles sur le marché en\r\n  analysant leurs possibilités, leurs avantages et leurs inconvénients.\r\n\r\n- mettre en place une interface de gestion de la base de données\r\n  (collecte, structuration et interface).\r\n\r\n- Définir et implémenter des méthodes pour l\'étiquetage sémantique des\r\n  données, en fonction d\'une typologie qui lui sera préalablement\r\n  spécifiée\r\n\r\n- Exploiter les résultats d\'annotations et proposer des pistes\r\n  d\'amélioration\r\n\r\nPrésentations et rapports :\r\n\r\n- présentation de début de stage à la SNCF (au bout d\'un mois de stage) :\r\n  contexte de stage, planning de réalisation et premiers travaux\r\n  réalisés.\r\n\r\n- rapport final de stage complet comprenant : méthodologie retenue,\r\n  travaux réalisés, résultats obtenus et problèmes rencontrés...\r\n\r\n2 soutenances de fin de stage : une à l\'école et une à la SNCF.\r\nDes présentations en interne SNCF ou externes pourront être effectuées.\r\n\r\n*Profil recherché*\r\n------------------------------\r\n\r\nNiveau : De formation Bac+5 en Traitement Automatique du Langage Naturel\r\nou Informatique (ingénieur ou master 2).\r\n\r\nCompétences souhaitées :\r\n\r\n- Capacités d\'analyse, de rédaction et de synthèse\r\n\r\n- Autonomie, qualités relationnelles, qualité de présentation\r\n  (orale/écrite).\r\n\r\n- Manipulation et test des outils de TAL\r\n\r\n- Connaissances en TAL et linguistique\r\n\r\n- Bonnes compétences en informatique (programmation, gestion de bases de\r\n  données)\r\n\r\n- Des connaissances en statistiques seront appréciées.\r\n\r\n \r\n\r\nBonus :\r\n\r\n   - Maîtrise d\'au moins un langage de programmation (PHP de préférence)\r\n   - Maitrise des expressions régulières et du SQL\r\n\r\n*Modalités du poste*\r\n------------------------------\r\n\r\n   - Durée : 4 mois\r\n   - Rémunération prévue: indemnités de stage + carte de circulation SNCF\r\n   - Début : à partir de Juin 2014\r\n   - Lieu : Paris\r\n\r\nMerci d\'adresser CV et lettre de motivation à Coralie Reutenauer à\r\nl\'adresse mail suivante : coralie.reutenauer@sncf.fr'),
(213, '2014-02-04', 'CFH & CLLE-ERSS', 'Toulouse', 'Stage de Master / Ecole d\'ingénieur : paramétrage et évaluation d\'un\r\nsystème de classification automatique de rapports de sécurité.\r\n\r\nL\'entreprise : \r\n\r\nCFH (Conseil en facteurs humains)/SafetyDATA est une PME spécialisée\r\ndans le traitement automatique des langues dans le domaine de la\r\nsécurité. Elle travaille en collaboration avec CLLE-ERSS, un\r\nlaboratoire de linguistique, et plus particulièrement avec l\'équipe\r\nTAL (Traitement automatique des langues). Le stage sera co-encadré par\r\nCFH et le laboratoire CLLE.\r\n\r\nContexte : \r\n\r\nCFH a conçu un système de traitement automatique des\r\nlangues (TAL) dont le but est d\'analyser des rapports d\'incidents\r\nafin de proposer une ou plusieurs catégorie(s) pour leur\r\nindexation dans une base de données. Le système est actuellement\r\ndéployé et analyse chaque mois plusieurs centaines de documents (en\r\nfrançais et en anglais) à l\'aide de règles apprises automatiquement et\r\nbasées sur le repérage de certains termes dans les rapports\r\nanalysés. Voir plus de détails sur http://www.safety-data-analysis.com/\r\n\r\nLe stage vise l\'évolution de ce système de classification, notamment\r\nen envisageant l\'utilisation d\'un système d\'apprentissage supervisé\r\nstatistique. L\'objectif de ce stage est double :\r\n\r\n1/ Identifier et quantifier le gain apporté par l\'utilisation d\'un\r\nmodèle statistique (SVM, régression logistique, réseau bayésien,\r\netc.) par rapport au système actuel ;\r\n\r\n2/ Mesurer l\'impact sur les performances du système des différents\r\ntraitements linguistiques appliqués aux documents avant leur analyse\r\n(correction des erreurs, normalisation des formes de surface,\r\nidentification d\'expressions complexes, utilisation de classes\r\nsémantiques, etc.).\r\n\r\nProfil recherché :\r\n\r\nEtudiant en deuxième année de master ou dernière année d\'école\r\nd\'ingénieur, en informatique ou traitement automatique des langues.\r\n\r\nCompétences requises :\r\n\r\nSystèmes de classification automatique par apprentissage\r\nartificiel. L\'étudiant doit connaître le fonctionnement de ces\r\nsystèmes et être autonome quant à leur utilisation et évaluation (scripts, \r\ngestion de données volumineuses, etc.)\r\nOn attend également de l\'étudiant une capacité à observer les données et à \r\ns\'intégrer dans un environnement interdisciplinaire.\r\n\r\nDétails :\r\n\r\n- stage conventionné basé à Toulouse\r\n- durée : 4 à 6 mois à partir de mars \r\n\r\nContact :\r\n\r\nCéline Raynal raynal@conseil-fh.fr\r\nLudovic Tanguy tanguy@univ-tlse2.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(214, '2014-02-06', 'IRIT', 'Toulouse', 'Titre : Analyse des citations et des énumérations dans les fora de santé. \r\n \r\nLieu : Laboratoire IRIT (Institut de Recherche en Informatique de\r\nToulouse), Université Paul Sabatier, Equipe ELIPSE (Etude de\r\nL\'Interaction Personne SystèmE).\r\n \r\nContexte et problématique \r\n\r\nCe sujet du stage se situe dans le cadre d\'un projet national «\r\nParlons de nous »\r\n(http://www.msh-m.fr/programmes/programmes-2013/parlons-de-nous)\r\noù l\'on étudie des fora de santé pour tenter de répondre à la question\r\n« à quoi pensent les patients ? » et du projet interMSH qui lui fait\r\nsuite.  Les forums de santé sont des lieux où les patients échangent\r\nde nombreux points de vues, conseils, où ils s\'interrogent et\r\ndiscutent, et ce dans un contexte bien différent des têtes à têtes\r\nmenées avec les professionnels de santé, qui ont lieu dans une durée\r\net un lieu contraint. Le relatif anonymat des échanges, l\'implication\r\nrécurrente de certains dans les forums, les questions débattues\r\npeuvent être révélatrices de points de vue, de connaissances ou\r\nméconnaissances d\'informations médicales, d\'alertes, en provenance du\r\ngrand public. Dans ce contexte éminemment subjectif, la\r\ncaractérisation et la compréhension des perceptions dans les fils de\r\ndiscussions des forums est difficile, mais aussi particulièrement\r\nintéressante et instructive dans une perspective d\'amélioration des\r\nprogrammes de santé publique.\r\n \r\nObjectif du projet \r\n\r\nUn des objectifs du projet est de développer une plateforme pour aider\r\ndes chercheurs (linguistes, sociologues et psychologues) et des\r\nmédecins à observer certains comportements dans les fils de\r\ndiscussions dans des fora de santé. Dans le cadre d\'un travail de\r\nthèse en informatique lancé cette année sur le sujet du contexte et\r\ndes informations médicales, nous avons initié cette plateforme.  La\r\nplateforme vise à proposer une interface qui permet de représenter et\r\nvisualiser schématiquement les fils discussions (ou extraits de ces\r\nfils de discussions) de forums au travers de traits et critères que\r\nles chercheurs vont choisir. On espère ainsi pouvoir associer à\r\ncertains schémas de discussions une qualité informationnelle du fil\r\nétudié (exemple : une discussion qui diverge du thème initial et se\r\nrecentre entre 2 personnes habituées devient peut être un aparté hors\r\nsujet). Les critères actuellement pris en compte sont de nature\r\ncontextuelle (les profils des utilisateurs (âge, sexe), le temps,\r\nnombres d\'interventions, la longueur des échanges, les\r\nmicro-échanges...). Nous souhaitons travailler sur l\'exploration\r\nd\'autres critères qui prendront en considération des traitements\r\nlinguistiques des discussions afin de disposer d\'un jeu de vues sur\r\nles discussions. Nous souhaitons évaluer si ces informations\r\npermettent de répondre à notre hypothèse de caractérisation des fils\r\nde discussion.\r\n \r\nObjectif du stage \r\n\r\nCe stage vise deux objectifs :\r\n1. Explorer des pistes linguistiques pressenties comme \r\n\r\n- étudier l\'utilisation des citations : en effet les internautes se\r\ncitent et se répondent beaucoup au fil des discussions et visualiser\r\nces interconnections dans le fil de discussions nous permettraient\r\npeut être d\'en avoir une compréhension élargie ;\r\n\r\n- connaitre les énumérations dans les fils de discussions (quels\r\nindices discursifs et de mise en forme matérielle peut-on repérer et\r\nqu\'en déduire ?)\r\n\r\n- analyser en utilisant les terminologies médicales existantes, les\r\nproximités sémantiques entre les différents post de discussion dans un\r\nfil.\r\n\r\n2. élaborer des stratégies pour coupler les indices de l\'architecture\r\nde texte et ceux liés au contexte (profil de l\'usager, thématique\r\nabordée, statut du message dans la discussion, etc.). Ce travail se\r\nfera en collaboration avec le doctorant.\r\n \r\nNous souhaitons en effet dans cette plateforme, en manipulant des\r\njauges constituées par ces critères, observer et pouvoir caractériser\r\ncomment se construisent les réponses ? Est-ce que les réponses sont\r\nfournies par des habitués ou des béotiens ? Peut-on écarter\r\ncertaines discussions (vulgarité, éparpillement...), ou au contraire\r\nanticiper sur des contenus plutôt informatifs voire cruciaux ? Quels\r\nrebondissements ? Quels recentrages ?... Nous nous focaliserons sur un\r\nsous-­-ensemble de ces besoins.  La plate-forme « configurable »\r\nenvisagée doit permettre aux chercheurs / médecins de pouvoir observer\r\ndes comportements et des « histoires de discussion » stéréotypés.\r\n\r\nPerspectives \r\n\r\nDeux thèses possibles dans la continuité de ce sujet de master (1. sur\r\nl\'étude des énumérations dans les manuels scolaires d\'histoire\r\ngéographie 2. sur l\'amélioration de l\'accessibilité textuelle pour des\r\npersonnes non-voyantes).\r\n\r\nModalités du stage\r\n\r\nEncadrants : \r\n Lydia-Mai Ho-Dac, CLLE-ERSS, Université Toulouse le Mirail \r\n Nathalie Souf, IRIT-ELIPSE, Université Paul Sabatier et ISIS Castres \r\n Mustapha Mojahid, IRIT-ELIPSE, Université Paul Sabatier \r\nDurée : 5-6 mois. \r\nRémunération : celle prévue par la règlementation à savoir 436,05 ¤ par mois. \r\nDébut : à partir de Mars-Avril 2014. \r\n \r\nProfil du candidat \r\n\r\nLe candidat devra être inscrit dans un Master 2 en traitement\r\nautomatique des langues.\r\n\r\nCompétences demandées \r\n\r\n- compétences en traitement automatique des langues et/ou en\r\nlinguistique de corpus.\r\n\r\n- compétences de base en informatique et idéalement maîtrise d\'outils\r\npour l\'analyse de corpus et/ou de langages de programmation de type\r\nperl et python.\r\n\r\nComment candidater ? \r\n\r\nEnvoyer un CV (avec le détail des cours et notes des deux années de\r\nMaster) et une lettre de motivation à : Mustapha.Mojahid@irit.fr'),
(215, '2014-02-10', 'TrooClick', 'Paris', 'Trooclick France is a company that specializes in the development of web\r\napplications for the automatic processing of information. Our goal is to\r\ncreate services that rebuild the user\'s trust in digital content. Up to\r\nnow, Web players were able to enhance the relevance of this content; we\r\ngo a step further and contribute to improve its reliability.\r\n\r\nTrooclick was created in November 2012. Just a few months later, in\r\nApril 2013, it received financial support from the BPI (French public\r\ninvestment bank) and in June 2013 the French government granted it the\r\nStatus of \"Young Innovative Company\" (JEI), recognizing its innovative\r\nnature. It now counts twelve committed and passionate members in its\r\ntight-knit team.\r\n\r\nThe company carries out R&D projects in search of technical solutions in\r\nthe Artificial Intelligence field. Due to its growth, Trooclick is now\r\nlooking for candidates for a 6 month internship for its office in Paris\r\n(17ème).\r\n\r\n\r\nMissions:\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\nYou will turn ideas into well-documented and reliable linguistic\r\nresources (both dictionaries and extraction rules) to ensure efficiency,\r\nquality, performance and scalability.\r\n\r\nA great team player, you will interact with other departments to\r\nunderstand and fine tune specifications.\r\nYou will carry out unitary testing, create and maintain our test\r\nvalidation corpus and participate in editing technical documents. All\r\ndevelopments will be done in English.\r\n\r\nQualifications:\r\n\r\n   - BSc/MSc\r\n   - Experience with NLP tools such as Gate, Treetagger, NooJ, Stanford\r\n     for linguistic annotation, named entity recognition, relationship\r\n     and fact extraction, sentiment analysis, etc.\r\n   - Experience in scripting languages such as Perl or Python as well as\r\n     XML format to be autonomous in completing some technical tasks.\r\n   - Experience with basic database management operations (SQL language)\r\n     Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will\r\n     be a plus.\r\n   - Excellent communication skills in English and French\r\n   - We are open to new ideas that will significantly contribute to our\r\n     success. Our friendly team will provide the opportunity for\r\n     valuable collaboration.\r\n\r\n   - We offer you career perspectives in a young and dynamic company\r\n     with an interesting and diversified scope of duties at the cutting\r\n     edge of research. We welcome applications from highly motivated\r\n     individuals able to learn new techniques and share knowledge and\r\n     experience with the team.\r\n\r\n\r\nInterested? Then send your application to jobs@trooclick.com!'),
(216, '2014-02-10', 'LIPN', 'Villetaneuse', '(English version below)\r\n\r\nProposition de stage de master recherche\r\n\r\nAnnotation sémantique dynamique\r\n\r\nMots clefs : Traitement Automatique des Langues, annotation sémantique,\r\ngestion de contenus, ingénierie des connaissances, web sémantique\r\n\r\nEncadrants : Adeline Nazarenko et François Lévy (LIPN, Université Paris\r\n13 - Sorbonne Paris Cité & CNRS)\r\n\r\nDurée : 4 à 6 mois (printemps-été 2014)\r\n\r\nIndemnités : 430¤ /mois (Labex EFL)\r\n\r\nProblématique\r\n\r\nL\'annotation sémantique des documents joue aujourd\'hui un rôle clef pour\r\nbeaucoup d\'applications de gestion de contenus textuels (navigation\r\ntextuelle, recherche d\'information sémantique, restructuration de\r\ndocuments, etc.). L\'annotation sémantique consiste à apposer sur un\r\ntexte des informations, ou métadonnées, dont la sémantique est portée\r\npar un modèle sémantique formel (langage d\'indexation, thesaurus,\r\nontologie, par exemple) [13, 6, 14]. On associe ainsi au texte une\r\nreprésentation sémantique formelle et les moteurs de recherche ou agents\r\nlogiciels peuvent exploiter à la fois le contenu textuel (recherche en\r\nplain texte, calculs distributionnels) et la sémantique formelle qui lui\r\nest associée.\r\n\r\nLes outils d\'annotation de la première génération sont assez frustres,\r\nse contentant souvent de lier les mentions des entités nommées\r\nidentifiées dans les textes à des instances existantes ou à de nouvelles\r\ninstances de concepts dans une ontologie [10, 4].\r\n\r\nLe développement des applications spécialisées de gestion de contenus et\r\nl\'essor du web de données amènent aujourd\'hui à revoir les méthodes\r\nd\'annotation sémantique : on a besoin de méthodes et d\'outils qui\r\noffrent une expressivité d\'annotation plus riche (par ex. annoter des\r\ninstances de concepts mais aussi des concepts et des relations) tout en\r\nétant robustes, génériques et adaptables à différents domaines et\r\ncontextes d\'utilisation.\r\n\r\nObjectif du stage\r\n\r\nLe stage permettra de proposer une méthode d\'annotation sémantique qui\r\nintègre des mesures de qualité de l\'annotation et qui permette de\r\nréviser l\'annotation dynamiquement. On supposera que le modèle\r\nsémantique utilisé est de type ontologique.\r\n\r\nSi l\'on considère qu\'un système d\'annotation S=<O,T,A> est composé d\'une\r\nontologie O, d\'un texte T et d\'un ensemble d\'annotations ou de liens A\r\nassociant à des segments de T des entités de O, il faut réviser le\r\nsystème S si l\'un de ses composants est mis à jour (le texte est\r\nmodifié, l\'ontologie est enrichie ou restructurée) ou lorsque des\r\nincohérences ou défauts de couverture sont détectés.\r\n\r\nLe stage consistera à étudier les différents cas de figures dans\r\nlesquels un tel système d\'annotation doit être révisé et à proposer une\r\nméthode d\'annotation dynamique intégrant des processus de révision. La\r\nméthode d\'annotation dynamique doit 1) intégrer des critères de\r\ncohérence et des mesures de couverture pour identifier quand la révision\r\nd\'un système d\'annotation est nécessaire, 2) proposer des procédures de\r\nrévision adaptées aux différents cas de figure et 3) contrôler la\r\nconvergence du processus global de révision.\r\n\r\nEn commençant par les types d\'annotation les plus simples (par ex. un\r\ntexte annoté avec les instances et les concepts d\'une ontologie), le\r\nstagiaire devra proposer une méthode d\'annotation dynamique. Il pourra\r\ns\'appuyer sur les outils d\'annotation sémantique existants de l\'équipe\r\nRCLN, sur l\'expertise des membres de l\'équipe et sur des cas d\'usage\r\nréels pour évaluer l\'apport de cette dynamique de l\'annotation.\r\n\r\nIl est souhaitable que la méthode proposée soit directement intégrée à\r\nun outil d\'annotation existant mais elle pourra aussi être testée en\r\nsimulation si l\'intégration s\'avère trop coûteuse.\r\n\r\nDescription du travail\r\n\r\nLe stage comportera  différentes parties :\r\n\r\n1) état de l\'art sur l\'annotation sémantique et veille sur les outils\r\n   existants (outils de l\'équipe RCLN ou autres) ;\r\n\r\n2) description, modélisation et implémentation du processus d\'annotation\r\n   dynamique (pour les types d\'annotations les plus simples ; en\r\n   s\'appuyant sur les outils existants et/ou sur des technologies\r\n   sémantiques) ;\r\n\r\n3) analyse, test et évaluation de l\'approche proposée sur des cas\r\n   d\'usage réels simplifiés fournis par l\'équipe RCLN.\r\n\r\nEn outre et en prévision d\'une poursuite en thèse, le stagiaire pourra\r\nchercher à spécifier une méthode d\'annotation sémantique plus riche\r\nprenant en compte une palette étendue de types d\'annotations.\r\n\r\nContexte et informations pratiques\r\n\r\nLe stage sera encadré par Adeline Nazarenko et François Lévy.\r\n\r\nLe/la stagiaire sera intégré(e) à l\'équipe RCLN et bénéficiera de\r\nl\'expertise de celle-ci en matière de traitement automatique des\r\nlangues, d\'ingénierie des connaissances textuelles et de web\r\nsémantique. En particulier, l\'équipe RCLN a une solide expérience en\r\nmatière d\'annotation sémantique (annotation manuelle [2, 3] ou\r\nautomatique, par apprentissage [8], formalismes et ressources pour\r\nl\'annotation [9, 12]) et de construction d\'ontologies à partir de textes\r\n[1]. Elle a aussi l\'expérience de l\'intégration de ces méthodes\r\nd\'annotation et d\'acquisition dans les outils d\'analyse de contenus [7,\r\n5, 11].\r\n\r\nLe/la stagiaire travaillera au LIPN (Université Paris 13 - Sorbonne\r\nParis Cité & CNRS) où il/elle se verra attribuer un bureau. Il/elle aura\r\naccès à l\'ensemble des moyens techniques et des données nécessaires à\r\nson travail.\r\n\r\nLe stage est prévu pour une durée de 6 mois. Il devrait débuter au\r\nprintemps 2014.\r\n\r\nLe stage sera financé dans le cadre d\'une opération de recherche de\r\nl\'axe « Analyse sémantique computationnelle » du Labex « Fondements\r\nempiriques de la linguistique ».\r\n\r\nLes candidatures doivent être adressées à François Lévy (francois.levy à\r\nlipn.univ-paris13.fr) avant le 7 mars 2014 : envoyer une lettre de\r\nmotivation, un CV, les relevés de notes de master.\r\n\r\nRéférences\r\n\r\n[1] N. Aussenac-Gilles, S. Després, and S. Szulman. « The TERMINAE\r\nMethod and Platform for Ontology Engineering from texts ». In Paul\r\nBuitelaar and Philipp Cimiano, editors, Bridging the Gap between Text\r\nand Knowledge - Selected Contributions to Ontology Learning and\r\nPopulation from Text, pages 199-223. IOS Press, janvier 2008.\r\n\r\n[2] K. Fort. Les ressources annotées, un enjeu pour l\'analyse de contenu\r\n: vers une méthodologie de l\'annotation manuelle de corpus. Thèse\r\nd\'informatique, Université Paris 13 - Sorbonne Paris Cité, Villetaneuse,\r\nFrance, 2012.\r\n\r\n[3] K. Fort., A. Nazarenko, S. Rosset. « Modeling the Complexity of\r\nManual Annotation Tasks: a Grid of Analysis ». In Proceedings of the\r\n24th International Conference on Computational Linguistics (COLING\r\n2012), Mumbai, India, December 2012.\r\n\r\n[4] C. Giuliano, A. Gliozzo. « Instance-based ontology population\r\nexploiting named-entity substitution ». In Proceedings of the 22nd\r\nInternational Conference on Computational Linguistics (Coling 2008),\r\npages 265-272, Manchester, August 2008.\r\n\r\n[5] A. Guissé, F. Lévy, A. Nazarenko. Un moteur sémantique pour explorer\r\ndes textes réglementaires. In Actes des 22èmes journées francophones\r\nd\'Ingénierie des Connaissances, Chambéry, 2011.\r\n\r\n[6] A. Kiryakov, B. Popov, I. Terziev, D. Manov, and D. Ognyanoff.  «\r\nSemantic annotation, indexing, and retrieval ». Journal of Web\r\nSemantics, 2(1):49-79, 2004.\r\n\r\n[7] F. Lévy, A. Nazarenko, A. Guissé. « Annotation, indexation et\r\nparcours de documents numériques ». Revue des Sciences et Technologies\r\nde l\'Information, 13(3/2010):121-152, 2010.\r\n\r\n[8] Y. Ma, F. Lévy, A. Nazarenko. Annotation sémantique pour des\r\ndomaines spécialisés et des ontologies riches. In de la 20ème conférence\r\ndu Traitement Automatique du Langage Naturel (TALN 2013), pp 464-478,\r\n17-21 Juin 2013, Les Sables d\'Olonne.\r\n\r\n[9] Y. Ma, A. Nazarenko, L. Audibert. « Formal description of resources\r\nfor ontology-based semantic annotation ». In Proceedings of the\r\nInternational Conference on Language Resources and Evaluation (LREC\r\n2010), Malta, May 2010. ELRA.\r\n\r\n[10] B. Magnini, A. Pianta, O. Popescu, M. Speranza. « Ontology\r\npopulation from textual mentions: Task definition and benchmark ». In\r\nProceedings of the OLP2 workshop on Ontology Population and Learning,\r\nSidney, Australia, 2006.\r\n\r\n[11] A. Nazarenko, A. Guissé, F. Lévy, N. Omrane, S. Szulman. «\r\nIntegrating Written Policies in Business Rule Management Systems ». In\r\nRule-Based reasoning, Programming, and Applications, volume 6826 of\r\nLecture Notes in Computer Science, pages 99-113, Barcelona, Espagne,\r\n2011.\r\n\r\n[12] N. Omrane, A. Nazarenko, P. Rosina, S. Szulman, C. Westphal. «\r\nLexicalized ontology for a business rules management platform: An\r\nautomotive use case ». In Proceedings of the 5th International Symposium\r\non Rules, International Business Rules Forum (RuleMF@BRF), Ft\r\nLauderdale, Florida, USA, November 2011.\r\n\r\n[13] B. Popov, A. Kiryakov, D. Ognyanoff, D. Manov, A. Kirilov. « Kim -\r\na semantic platform for information extraction and retrieval ». Natural\r\nLanguage Engineering, 10(3-4):375-392, 2004.\r\n\r\n[14] V. Uren, P. Cimiano, J. Iria, S. Handschuh, M. Vargas-Vera,\r\nE. Motta, F. Ciravegna. « Semantic annotation for knowledge management:\r\nRequirements and a survey of the state of the art ». Journal of Web\r\nSemantics, 4, 2006.\r\n\r\n-------------------------------------------------------\r\n\r\n(French version above)\r\n\r\nProposal for a master internship \r\nDynamic semantic annotation\r\n\r\nKeywords: Natural Language Engineering, Semantic Annotation, Content\r\nManagement, Knowledge Engineering, Semantic Web\r\n\r\nSupervision: Adeline Nazarenko and François Lévy (LIPN, Université Paris\r\n13 - Sorbonne Paris Cité & CNRS)\r\n\r\nDuration: 4-6 months (spring-summer 2014)\r\n\r\nIndemnités: 430¤ /month (Labex EFL)\r\n\r\nProblem\r\n\r\nThe semantic annotation of documents plays a key role for many\r\napplications of textual content management (e.g. navigation, semantic\r\ninformation retrieval, publication). Semantic Annotation consists in\r\nenriching a text with metadata which semantics is given by a formal\r\nsemantic model (e.g. indexing language, thesaurus, ontology) [13, 6 ,\r\n14]. A formal semantic representation is thus associated with the text\r\nso that search engines or software agents can jointly exploit the\r\ntextual content (plain text search, distributional measures) and the\r\nformal semantics associated with it.\r\n\r\nThe first generation annotation tools are quite simple. They often\r\nmerely bind references to named entities identified in the texts to\r\nexisting instances or new instances of concepts in an ontology [10 ,\r\n4]. However, the development of specialized applications of content\r\nmanagement and linked data calls for renewed methods of semantic\r\nannotation: we need methods and tools that provide a richer\r\nexpressiveness of annotation (e.g. annotation wrt. concepts and\r\nrelations and not only instances) while being robust, generic and\r\nadaptable to different domains and use cases.\r\n\r\nGoal\r\n\r\nThe goal of the internship is to design a semantic annotation method\r\nincorporating annotation quality measures and enabling the dynamic\r\nrevision of annotations, assuming that the semantic model is\r\nontological.\r\n\r\nIf we consider that an annotation system S = <O,T,A> consists of an\r\nontology O, a text T and a set of annotations or links A associating\r\nsegments of with entities of O, one must revise the system S if one of\r\nits components is updated (the text is modified, the ontology is\r\nenriched or restructured ) or when inconsistencies or gaps in coverage\r\nare detected.\r\n\r\nThe Master student will study the different scenarios requiring the\r\nrevision of such an annotation system and propose a method of dynamic\r\nannotation integrating such a revision process. The dynamic annotation\r\nmethod must 1) integrate consistency criteria and coverage metrics to\r\nidentify when the revision of an annotation system is necessary, 2)\r\npropose revision procedures adapted to different use scenarios and 3)\r\ncontrol the convergence of the overall revision process.\r\n\r\nStarting with the simplest types of annotation (e.g. a text annotated\r\nwith instances and concepts of an ontology), the student will provide a\r\nmethod for dynamic annotation. It will rely on existing semantic\r\nannotation tools, on the expertise of RCLN team members and on real use\r\ncases to assess the contribution of this dynamic annotation.\r\n\r\nThe proposed method will be directly integrated into an existing\r\nannotation tool or tested through simulation if integration is too\r\ncomplex.\r\n\r\nDescription of work \r\n\r\nThe work will include several parts: \r\n- state of the art on semantic annotation and review of existing tools; \r\n\r\n- description, modeling and implementation of the dynamic annotation\r\n  process (for the simplest types of annotations and based on existing\r\n  tools and/or semantic technologies); \r\n\r\n- analysis, test and evaluation of the proposed approach on simple but\r\n  real use cases provided by the RCLN team. \r\n\r\nIn addition, and in anticipation of a PhD followup, the student may\r\nstart to specify a richer semantic annotation method taking into account\r\na wider range of annotation types.\r\n\r\nContext and Practical Information\r\n\r\nThe work will be supervised by Pr. Adeline Nazarenko and Pr. Francois\r\nLevy.\r\n\r\nThe intern will be integrated in the RCLN team and benefit from its\r\nexpertise in natural language processing, knowledge engineering and\r\nsemantic web. In particular, RCLN has a solid experience in semantic\r\nannotation (manual annotation [2, 3] or based on machine learning [8],\r\nformalisms and resources for annotation [9, 12]) and text-based ontology\r\ndesign [1]. It also knows how to integrate those methods of acquisition\r\nand annotation in content analysis tools [7 , 5, 11 ].\r\n\r\nThe intern will work at LIPN (University Paris 13 - Sorbonne Paris Cité\r\n& CNRS) where he/she will be assigned a desk. He/she will have access to\r\nlocal facilities and data resources.\r\n\r\nThe internship is for a period of 6 months. It should start in spring\r\n2014.\r\n\r\nIt will be funded by the Labex \"Empirical Foundations of Language\"\r\n(research strand \"computational semantic analysis\").\r\n\r\nApplications should be addressed to François Lévy (francois.levy to\r\nlipn.univ - paris13.fr) before March 7, 2014 : send a cover letter, a CV\r\nand transcripts.\r\n\r\nReferences\r\n\r\n[1] N. Aussenac-Gilles, S. Després, and S. Szulman. « The TERMINAE\r\nMethod and Platform for Ontology Engineering from texts ». In Paul\r\nBuitelaar and Philipp Cimiano, editors, Bridging the Gap between Text\r\nand Knowledge - Selected Contributions to Ontology Learning and\r\nPopulation from Text, pages 199-223. IOS Press, janvier 2008.\r\n\r\n[2] K. Fort. Les ressources annotées, un enjeu pour l\'analyse de contenu\r\n: vers une méthodologie de l\'annotation manuelle de corpus. Thèse\r\nd\'informatique, Université Paris 13 - Sorbonne Paris Cité, Villetaneuse,\r\nFrance, 2012.\r\n\r\n[3] K. Fort., A. Nazarenko, S. Rosset. « Modeling the Complexity of\r\nManual Annotation Tasks: a Grid of Analysis ». In Proceedings of the\r\n24th International Conference on Computational Linguistics (COLING\r\n2012), Mumbai, India, December 2012.\r\n\r\n[4] C. Giuliano, A. Gliozzo. « Instance-based ontology population\r\nexploiting named-entity substitution ». In Proceedings of the 22nd\r\nInternational Conference on Computational Linguistics (Coling 2008),\r\npages 265-272, Manchester, August 2008.\r\n\r\n[5] A. Guissé, F. Lévy, A. Nazarenko. Un moteur sémantique pour explorer\r\ndes textes réglementaires. In Actes des 22èmes journées francophones\r\nd\'Ingénierie des Connaissances, Chambéry, 2011.\r\n\r\n[6] A. Kiryakov, B. Popov, I. Terziev, D. Manov, and D. Ognyanoff.  «\r\nSemantic annotation, indexing, and retrieval ». Journal of Web\r\nSemantics, 2(1):49-79, 2004.\r\n\r\n[7] F. Lévy, A. Nazarenko, A. Guissé. « Annotation, indexation et\r\nparcours de documents numériques ». Revue des Sciences et Technologies\r\nde l\'Information, 13(3/2010):121-152, 2010.\r\n\r\n[8] Y. Ma, F. Lévy, A. Nazarenko. Annotation sémantique pour des\r\ndomaines spécialisés et des ontologies riches. In de la 20ème conférence\r\ndu Traitement Automatique du Langage Naturel (TALN 2013), pp 464-478,\r\n17-21 Juin 2013, Les Sables d\'Olonne.\r\n\r\n[9] Y. Ma, A. Nazarenko, L. Audibert. « Formal description of resources\r\nfor ontology-based semantic annotation ». In Proceedings of the\r\nInternational Conference on Language Resources and Evaluation (LREC\r\n2010), Malta, May 2010. ELRA.\r\n\r\n[10] B. Magnini, A. Pianta, O. Popescu, M. Speranza. « Ontology\r\npopulation from textual mentions: Task definition and benchmark ». In\r\nProceedings of the OLP2 workshop on Ontology Population and Learning,\r\nSidney, Australia, 2006.\r\n\r\n[11] A. Nazarenko, A. Guissé, F. Lévy, N. Omrane, S. Szulman. «\r\nIntegrating Written Policies in Business Rule Management Systems ». In\r\nRule-Based reasoning, Programming, and Applications, volume 6826 of\r\nLecture Notes in Computer Science, pages 99-113, Barcelona, Espagne,\r\n2011.\r\n\r\n[12] N. Omrane, A. Nazarenko, P. Rosina, S. Szulman, C. Westphal. «\r\nLexicalized ontology for a business rules management platform: An\r\nautomotive use case ». In Proceedings of the 5th International Symposium\r\non Rules, International Business Rules Forum (RuleMF@BRF), Ft\r\nLauderdale, Florida, USA, November 2011.\r\n\r\n[13] B. Popov, A. Kiryakov, D. Ognyanoff, D. Manov, A. Kirilov. « Kim -\r\na semantic platform for information extraction and retrieval ». Natural\r\nLanguage Engineering, 10(3-4):375-392, 2004.\r\n\r\n[14] V. Uren, P. Cimiano, J. Iria, S. Handschuh, M. Vargas-Vera,\r\nE. Motta, F. Ciravegna. « Semantic annotation for knowledge management:\r\nRequirements and a survey of the state of the art ». Journal of Web\r\nSemantics, 4, 2006.'),
(217, '2014-02-12', 'IRIT', 'Toulouse', 'Proposition de stage de M2(R)\r\n\r\nTitre : Analyse automatique de comptes-rendus de consultations médicales\r\n\r\nMots-clefs : traitement automatique des langues naturelles, extraction\r\nd\'information, apprentissage automatique, médecine\r\n\r\nRésumé :\r\n\r\nCe stage de M2 Recherche vise l\'analyse automatique de comptes-rendus de\r\nconsultations médicales pour en extraire certaines informations\r\nnécessaires à la réalisation d\'une étude épidémiologique. Les\r\ncompte-rendus sont constitués de texte libre résumant les données\r\nsociodémographiques, le diagnostic, les symptômes, et les résultats des\r\ntests éventuels réalisés chez ces patients.\r\nDeux objectifs principaux sont considérés : d\'une part classifier les\r\ncomptes rendus vis à vis de l\'existence ou non d\'une pathologie, d\'autre\r\npart extraire un certain nombre d\'informations précises en lien avec ces\r\nmaladies. Le stagiaire devra évaluer et comparer les stratégies\r\nclassiques d\'extraction d\'information en Traitement Automatique des\r\nLangues en domaine spécialisé, et l\'application de méthodes\r\nd\'apprentissage automatique pour les deux objectifs visés. Les données\r\nutilisées sont un corpus de compte-rendus de consultation déidentifiés,\r\nen français.\r\n\r\nEncadrement :\r\nCe stage sera effectué à l\'IRIT (Institut de Recherche en Informatique\r\nde Toulouse), en coopération avec l\'INSERM, et sera codirigé par\r\nPhilippe Muller (IRIT, équipe MELODI \"MEthodes et ingénierie des\r\nLangues, des Ontologies et du DIscours\") et Virginie Gardette (équipe\r\n\"Vieillissement et maladie d\'Alzheimer\" de l\'UMR INSERM 1027\r\n\"Epidémiologie et analyses en santé publique\").\r\n\r\nhttp://www.irit.fr/-Equipe-MELODI-\r\nhttp://www.u1027.inserm.fr/42537678/0/fiche___pagelibre/&RH=1303915788348\r\n\r\nCompétences requises :\r\nLe stagiaire devra avoir une formation en M2 informatique, idéalement\r\navec des compétences en apprentissage automatique et/ou traitement\r\nautomatique du langage naturel.\r\n\r\nDurée : 4-6 mois à partir de mars ou avril.\r\n\r\nRémunération :  436,05¤/mois, conformément à la réglementation.\r\n\r\nCandidature : Envoyez un CV (avec relevés de notes récents) et une\r\nlettre de motivation à philippe.muller@irit.fr et\r\nvirginie.gardette@univ-tlse3.fr'),
(218, '2014-02-17', 'Rebuz', 'Strasbourg', 'Sujet de stage en informatique\r\nPrétraitement de données textuelles pour un système d\'analyse sémantique\r\n\r\nEntreprise : Rebuz SAS, Strasbourg\r\nDurée : 2-5 mois\r\nNiveau : M1-M2\r\nRémunération : 436,05 euros/mois\r\nContact : Mme Yuliya Goncharova,  4arly@bk.ru\r\n\r\nDétails :\r\n\r\nRebuz est une société spécialisée dans l\'analyse de textes pour la\r\nveille économique. Le système original repose sur l\'analyse sémantique\r\népaulée par des principes de la linguistique cognitive.\r\n\r\nLe stage portera sur l\'amélioration du module de prétraitement\r\nexistant. Ce sujet sera particulièrement intéressant pour les étudiants\r\nsouhaitant en apprendre plus sur le Traitement Automatique de Langues\r\n(TAL) et sur la Recherche d\'Information (RI).\r\n\r\nLes tâches seront adaptées selon le niveau et les préférences du (de la)\r\ncandidat(e) sélectionné(e).\r\n \r\nObjectifs du stage\r\n* Révision du module actuel (écrit en Java)\r\n* Nettoyage et optimisation du code\r\n* Intégration de l\'étiqueteur morphosyntaxique MACAON [1]\r\n* Séries de tests et perfectionnement\r\n\r\nCompétences recherchées :\r\n- aisance dans la programmation en Java (un échantillon de code sera\r\n  demandé)\r\n- bonnes connaissances des tests unitaires (JUnit)\r\n- bonnes capacités de travail en équipe\r\n- rigueur\r\n- responsabilité\r\n- autonomie \r\n \r\n[1] http://macaon.lif.univ-mrs.fr/'),
(219, '2014-03-24', 'IRT SystemX', 'Palaiseau', 'Proposition de stage : Translittération des noms propres pour\r\nl\'extraction d\'entités nommées\r\n\r\nLieu du stage : IRT SystemX, 8 avenue de la Vauve, 91190 Palaiseau\r\n\r\nCONTEXTE :\r\n\r\nL\'IRT SystemX est un institut de R&D thématique interdisciplinaire\r\nrassemblant les compétences de l\'industrie et de la recherche publique\r\ndans une logique de co-investissement public-privé : Alstom, Bull,\r\nCampus Paris-Saclay, INRIA, Institut Mines Telecom, Kalray, OVH,\r\nRenault, Sherpa, Systematic Paris-Region en sont les fondateurs. Les IRT\r\ns\'inscrivent dans le cadre du Programme Investissements d\'Avenir.\r\n\r\nAu sein de SYSTEMX, vous serez intégré dans l\'équipe de l\'un des projets\r\nde recherche : Intégration Multimédia Multilingue (IMM).\r\n\r\nLe projet IMM réunit des acteurs du monde académique (CEA, CNRS-LIMSI,\r\nINRIA, LNE, UPMC-LIP6), des industriels (Bertin Technologie, CapGemini,\r\nExalead, OVH, Systran, Temis, Vecsys, Vocapia) et des utilisateurs de\r\nréférence dans le domaine de l\'analyse de contenus non structurés\r\n(texte, vidéo).\r\n\r\nL\'objectif du projet IMM est de développer de nouvelles fonctions ou\r\ncapacités pour des composants nécessaires pour des applications de\r\nveille sur les sources ouvertes (moteur de recherche, de transcription\r\nde la parole, de traduction...), de concevoir des environnements\r\nd\'exécution et d\'intégration de ces composants et de relever un certain\r\nnombre de défis comme par exemple réduire le temps d\'adaptation à un\r\ncontexte nouveau (sources, domaine, langue).\r\n\r\nSUJET DE STAGE :\r\n\r\nLa translittération consiste à substituer à chaque graphème d\'un système\r\nd\'écriture, un autre graphème ou un groupe de graphèmes d\'un autre\r\nsystème d\'écriture, indépendamment de la prononciation.\r\n\r\nLa translittération connait un essor important en raison du caractère de\r\nplus en plus multilingue du Web. De nombreuses approches ont été\r\nproposées pour développer des systèmes de translittération mais la\r\nmajorité des systèmes actuels ne prennent pas en compte la complexité\r\ndes problèmes de la transcription et de la translittération, lesquels\r\ntouchent autant à l\'oralité qu\'à la scripturalité des systèmes\r\nlinguistiques impliqués.\r\n\r\nL\'objectif de ce stage est de concevoir et de développer un outil de\r\ntranslittération automatique de noms propres de l\'arabe vers le script\r\nlatin et se déroulera selon les étapes suivantes :\r\n\r\n- Etude, analyse et évaluation de l\'existant. Cette étape permet\r\n  d\'identifier l\'approche à explorer.\r\n\r\n- Implémentation d\'un outil automatique de translittération de noms\r\n  propres de l\'arabe vers le latin.\r\n\r\n- Evaluation des résultats pour une généralisation à d\'autres alphabets.\r\n\r\nVos missions :\r\n\r\n- Faire un état de l\'art dans le domaine : approches existantes et\r\n  outils disponibles.\r\n\r\n- Choix de l\'approche et conception de l\'outil de translitération des\r\n  noms propres de l\'arabe vers le script latin.\r\n\r\n- Réaliser une évaluation des résultats.\r\n\r\nLe profil recherché :\r\n\r\n- Niveau : BAC+4 ou BAC +5, en Informatique ou Informatique Linguistique\r\n  (Ingénieur ou Master) pour un stage de 4 à 6 mois.\r\n\r\nVos Compétences sont :\r\n\r\nObligatoires :\r\n\r\n- Informatique : maîtrise d\'un langage de programmation (C++, Java,\r\n  Perl, Python).\r\n\r\n- Technologies d\'apprentissage.\r\n\r\nOptionnelles :\r\n\r\n- Technologies d\'apprentissage : clustering, HMM.\r\n\r\n- Traitement automatique des langues.\r\n\r\n- La connaissance de la langue arabe est un plus.\r\n\r\nBIBLIOGRAPHIE :\r\n\r\n- ALGHAMDI M. (2005). Alghorithms for Romanizing Arabic names. Journal\r\n  of King Saud University - Computer and Information Sciences,Volume 17,\r\n  Riyadh, 105-128.\r\n\r\n- AL-ONAIZAN Y., KNIGHT K. (2002). Translating named entities using\r\n  monolingual and bilingual resources. Proceedings of the 40th ACL\r\n  Conference, USA.\r\n\r\n- JIANG L., ZHOU M., CHIEN L. F., NIU C. (2007). Named entity\r\n  translation with web mining and transliteration. Proceedings of the\r\n  20th International Joint Conference on Artificial Intelligence,\r\n  1629-1634.\r\n\r\n- TAO T., YOON S. Y., FISTER A., SPROAT R., ZHAI C. (2006). Unsupervised\r\n  named entity transliteration using temporal and phonetic\r\n  correlation. Proceedings of the Conference on Empirical Methods in\r\n  Natural Language Processing (EMNLP\'06), 250-257.\r\n\r\n- YASER A. O., KNIGHT K. (2002). Translating named entities using\r\n  monolingual and bilingual resources. Proceedings of the 40th Annual\r\n  Meeting of the Association of Computational Linguistics (ACL\'02),\r\n  400-408.\r\n\r\nCONDITIONS DE CANDIDATURE :\r\n\r\nContact et envoi des candidatures (CV détaillé et lettre de motivation):\r\n\r\nNasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr'),
(220, '2014-04-02', 'IdexLab', 'Paris', '*Title*: Online semantic relations extraction from linguistic and\r\nstatistic patterns\r\n\r\n*Context*: The company ideXlab implements the process that is dedicated\r\nto the open innovation domain in order to connect experts and companies\r\nto easy establishing collaboration between them. The aim of such\r\ncollaboration is to bring solutions to technical challenges.\r\n\r\nFor more information please check : www.idexlab.com\r\n\r\n*Subject*: The student will analyze the extracted data from the\r\nscientific papers and identify the linguistic patterns that describe\r\nsemantic relationship between a given query and the suggested keywords\r\nobtained from the expert search tool. From this study, the student will\r\npropose a semantic relation extraction approach that fits with the kind\r\nof the used data and takes into account the constraints related to the\r\nexpert search tool performance. More specifically, it he/she propose an\r\nimplementation of the semantic relations extraction between a query and\r\nother terms by applying the patterns, identified in the first phase, on\r\nthe content of scientific papers.\r\n\r\n\r\n*Profil*: The desired profile is a student in a second year of Master or\r\nEngineering school having skills on Natural Language Processing and\r\nInformation Retrieval\r\n\r\n*Skills*:\r\n\r\nLanguages: C#, C++\r\n\r\nPeriod: 6 months from May 1 2014.\r\n\r\n*Location*: ideXlab, Immeuble Berlier - Halle B, 15, rue Jean-Baptiste\r\nBerlier 75013 PARIS\r\n\r\nSend CV and motivation letter  to:\r\n\r\n- Pierre Bonnard : pierre.bonnard@idexlab.com\r\n- Nouha Omrane : nouha@idexlab.com\r\n\r\n*Titre* : Extraction online des relations sémantiques à partir de\r\npatrons linguistiques et statistiques\r\n\r\n*Contexte* : La société ideXlab travaille dans le domaine de\r\nl\'innovation ouverte. Elle propose un service d\'intermédiation entre\r\nexperts et entreprises qui permet d\'initier une collaboration entre ces\r\npartenaires dans le but d\'apporter des solutions à des problématiques\r\nidentifiées.\r\n\r\n\r\nPour plus d\'information sur l\'activité : www.idexlab.com\r\n\r\n*Mission* : Le stagiaire aura à analyser les données extraites à partir\r\ndes publications scientifiques et à identifier les patrons linguistiques\r\nqui décrivent des relations sémantiques entre une requête donnée et des\r\nmots clés suggérés par l\'outil de recherche d\'experts. A partir de cette\r\nétude, l\'étudiant aura à proposer une approche d\'extraction de relations\r\nsémantiques adaptée aux types de données manipulées et aux contraintes\r\nliées à la performance de l\'outil de recherche d\'experts. Plus\r\nprécisément, il aura à proposer une implémentation pour l\'extractionde\r\nrelations sémantiques entre une requête et des d\'autres termes à partir\r\nde l\'application des patrons identifiés dans la première phase sur le\r\ncontenu des papiers scientifiques.\r\n\r\n*Profil* : Le profil recherché est un étudiant en 2ème année de Master\r\nou d\'école d\'ingénieur ayant des connaissances en Traitement Automatique\r\nde la Langue et Extraction d\'Information.\r\n\r\n*Compétences recherchées* :\r\n\r\nLangages de programmation : C#, C++\r\n\r\nDurée : 6 mois, à partir de 1 Mai 2014\r\n\r\n\r\n\r\n*Adresse du stage* : ideXlab, Immeuble Berlier - Halle B, 15, rue\r\nJean-Baptiste Berlier 75013 PARIS\r\n\r\n\r\nVeuillez adresser votre candidature (CV + lettre de motivation) à :\r\n\r\n- Pierre Bonnard : pierre.bonnard@idexlab.com\r\n- Nouha Omrane : nouha@idexlab.com'),
(221, '2014-10-20', 'LIUM', 'Le Mans', 'Le LIUM, Laboratoire dâ€™Informatique de lâ€™UniversitÃ© du Maine, propose un\r\nstage de Master 2 Recherche orientÃ© dialogue oral. Ce stage se fait en\r\ncollaboration avec lâ€™entreprise TÃ©lÃ©copolis basÃ©e au Mans, et est censÃ©\r\ndÃ©boucher sur une thÃ¨se en contrat CIFRE dans la mÃªme entreprise.\r\n\r\nLâ€™objectif du stage est de contribuer au dÃ©veloppement de YADE, un\r\nsystÃ¨me de dialogue existant Ã  base de rÃ¨gles. Les problÃ©matiques\r\nabordÃ©es seront dâ€™une part la robustesse, puisque lâ€™objectif final est\r\ndâ€™intÃ©grer YADE au sein dâ€™une plateforme de tÃ©lÃ©phonie professionnelle,\r\ndâ€™autre part lâ€™aide Ã  la conception des connaissance, puisquâ€™il sâ€™agit\r\nde sâ€™adresser Ã  des utilisateurs finaux.\r\n\r\nUn descriptif plus complet de ce stage est disponible Ã  lâ€™adresse\r\nsuivante :\r\n=> http://www-lium.univ-lemans.fr/~lehuen/stage_M2R_LIUM.pdf\r\n\r\nLes personnes intÃ©ressÃ©es doivent se manifester auprÃ¨s de JÃ©rÃ´me Lehuen\r\nÃ  lâ€™adresse suivante :\r\n=>  jerome.lehuen@univ-lemans.fr'),
(222, '2014-11-03', 'TrooClick', 'Paris', 'NLP Engineer Internship\r\n\r\nTrooclick France is a company that specializes in the development of\r\nweb applications for the automatic processing of information. Our goal\r\nis to create services that rebuild the userâ€™s trust in digital\r\ncontent. Up to now, Web players were able to enhance the relevance of\r\nthis content; we go a step further and contribute to improve its\r\nreliability with automated fact checking and controversy detection.\r\n\r\nTrooclick was created in November 2012. Just a few months later, in\r\nApril 2013, it received financial support from the BPI (French public\r\ninvestment bank) and in June 2013 was granted the Status of â€œYoung\r\nInnovative Companyâ€ (JEI), recognizing its innovative nature by the\r\nFrench government. It now counts fifteen committed and passionate\r\nmembers in its tight-knit team.\r\n\r\nThe company carries out R&D projects in search of technical solutions\r\nin the Artificial Intelligence field. Due to its growth, Trooclick is\r\nnow looking for candidates for its office in the â€œEspace Startupâ€ of\r\nBpifrance on Boulevard Haussmann in the heart of Paris.\r\n\r\nMissions:\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\n- You will turn ideas into well-documented and reliable linguistic\r\n  resources (both dictionaries and grammars) to ensure efficiency,\r\n  quality, performance and scalability\r\n\r\n- A great team player, you will interact with other departments to\r\n  understand and fine tune specifications\r\n\r\n- You will carry out unitary testing, create and maintain our test\r\n  validation corpus and participate in editing technical documents\r\n\r\n- Development will be done in English\r\n\r\nQualifications:\r\n\r\n- BSc/MSc\r\n\r\n- Experience with NLP tools such as NooJ, Unitex, Gate, or Stanford\r\n  for linguistic annotation, named entity recognition, relationship\r\n  and fact extraction, sentiment analysis, etc.\r\n\r\n- Experience in scripting languages such as Perl or Python as well as\r\n  XML format to be autonomous in completing several technical tasks\r\n\r\n- Experience with basic database management operations (SQL language)\r\n\r\n- Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will\r\n  be a plus\r\n\r\n- Excellent communication skills in English and French\r\n\r\nWe are open to new ideas that will significantly contribute to our\r\nsuccess. Our friendly team will provide the opportunity for valuable\r\ncollaboration. We offer you career perspectives in a young and dynamic\r\ncompany with an interesting and diversified scope of duties at the\r\ncutting edge of research. We welcome applications from highly\r\nmotivated individuals able to learn new techniques and share knowledge\r\nand experience with the team.\r\n\r\nInterested? Then send your application to jobs@trooclick.com!'),
(223, '2014-11-24', 'LIMICS', 'Paris', 'Le LIMICS (Laboratoire d\'Informatique Médicale et d\'Ingénierie des\r\nConnaissances en Santé) travaille sur les problématiques de l\'aide à la\r\ndécision et de la représentation et l\'utilisation des connaissances\r\n(deux branches de l\'intelligence artificielle) dans le domaine médical,\r\nafin de produire des applications et méthodes pour faciliter les\r\nprocessus de décisions médicaux et l\'interopérabilité entre différents\r\nservices ou systèmes de santé. Une grande partie de l\'équipe se focalise\r\nsur l\'utilisation des technologies du Web sémantique (graphes RDF,\r\nontologies, raisonneurs logiques, etc) dans des applications de santé.\r\n\r\nContexte du stage :\r\n--------------------------\r\n     Le stage, d\'une durée de 5 à 6 mois, se déroulera sur le site du\r\nCampus des Cordeliers (Odéon) sous la tutelle de Yves Parès (ingénieur\r\ndoctorant), Xavier Aimé (chercheur) et Marie-Christine Jaulent\r\n(directrice de recherche). L\'étudiant prendra part au projet ACCORDYS,\r\nqui vise à produire un système informatique évaluant la ressemblance de\r\ncas de dysmorphies prénatales (décrits dans des comptes rendus textuels)\r\nafin de fournir au médecin une réponse aux questions du type « quels\r\nfoetus malformés rencontrés dans le passé ressemblent le plus à celui-ci\r\n? ». Le but étant d\'aider le diagnostic et le suivi apporté aux parents.\r\nCe travail contribue à la caractérisation ce qu\'est une dysmorphie. On\r\ns\'intéresse donc à la sémantique et à l\'évaluation de mesures de\r\nsimilarités entre dysmorphie.\r\n\r\nObjet du stage :\r\n---------------------\r\n     Le but du stage sera d\'utiliser des outils de NLP et d\'indexation\r\nde documents textuels dans ce contexte, et d\'évaluer les résultats\r\nqu\'ils fournissent en termes de pertinence. Les méthodes à explorer\r\nseront les modèles vectoriels (tels qu\'utilisés dans les systèmes de\r\nrecommandation) et la construction de clusters de mots à partir de leurs\r\nco-occurences, afin de pouvoir évaluer la distance séparant deux comptes\r\nrendus. Le début du stage consistera donc à rechercher parmi les outils\r\nlogiciels existants ceux qui pourraient être adaptés. Le but final est\r\nde quantifier l\'intérêt de ces méthodes pour la tâche à résoudre et de\r\ncomparer leurs résultats à ceux des méthodes déjà en cours de\r\ndéveloppement au sein du LIMICS, ceci pouvant être pour l\'étudiant\r\nl\'objet d\'un article de recherche en fin de stage.\r\n\r\nGratification :\r\n------------------\r\n     La gratification sera de 436,05¤/mois, avec de plus un \r\nremboursement de 50 % du titre de transport.\r\n\r\nProfil recherché :\r\n-----------------------\r\n     Une grande partie du stage consistant à travailler sur des fichiers\r\ntexte, l\'étudiant d\'un niveau M2 devra avoir suivi des enseignements sur\r\nles méthodes de traitement automatique des langues et être intéressé par\r\nce domaine. Conjointement à cela, il est souhaitable que l\'étudiant ait\r\nquelques connaissances en machine learning. Il est nécessaire que\r\nl\'étudiant ait été formé à la programmation, et si possible qu\'il ait\r\ndéjà utilisé des langages de scripting, adaptés au prototypage (tels que\r\nPython, Ruby, Perl). Une connaissance de Java et des langages JVM\r\nalternatifs (Clojure, Groovy, JRuby...) est un plus. Pour finir, un\r\nintérêt de l\'étudiant pour le Web sémantique et les ontologies est\r\négalement appréciable mais pas obligatoire.\r\n\r\n     Selon le profil de l\'étudiant (plutôt linguistique ou plutôt\r\ndéveloppement informatique), le stage pourra être orienté différemment\r\nmais les problématiques restent les mêmes.\r\n\r\nContacts :\r\n-------------\r\n     yves <point> pares <at> gmail <point> com\r\n     xavier <point> aime <at> inserm <point> fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(224, '2014-11-24', 'INBENTA', 'Toulouse', '*Présentation société*\r\n------------------------------\r\n\r\nInbenta est une société pionnière dans le Traitement Automatique du\r\nLangage et la recherche sémantique. Basée sur ces concepts novateurs,\r\nInbenta développe depuis 2005 des solutions logicielles pour les sites\r\nweb de Grands Comptes. Inbenta est notamment le leader français des FAQ\r\nDynamiques pour site web de Grands Comptes.\r\n\r\n\r\n*Description de l\'offre*\r\n------------------------------\r\n\r\nInbenta a développé un moteur de recherche intelligent appelé *Inbenta\r\nSemantic Search Engine* (ISSE). Les deux tâches principales de ce moteur\r\nsont d\'analyser les questions des utilisateurs et de trouver la réponse\r\nappropriée à la requête en effectuant une recherche dans une base de\r\nconnaissances.\r\n\r\nL\'objectif de ce stage sera d\'évaluer ce moteur de recherche sémantique\r\nde façon scientifique.\r\n\r\nLes missions de stage seront les suivantes :\r\n\r\n   - Faire un état de l\'art des méthodes d\'évaluation dans le domaine de\r\n     la recherche d\'information\r\n\r\n   - Proposer et mettre en place une méthode d\'évaluation scientifique\r\n     du moteur de recherche sémantique d\'Inbenta\r\n\r\n   - Travailler en collaboration avec une université avec laquelle nous\r\n     mènerons des évaluations croisées\r\n\r\n   - En parallèle, l\'étudiant devra assurer la gestion linguistique et\r\n     éditoriale d\'un projet de FAQ dynamique afin qu\'il s\'approprie\r\n     l\'existant en vue d\'assurer, en cas d\'embauche après le stage, les\r\n     missions de production que nous attendons d\'un ingénieur linguiste\r\n     (20% du temps de travail)\r\n\r\n*Profil recherché*\r\n------------------------------\r\n\r\nNous recherchons une personne enthousiaste, organisée et sérieuse et\r\nayant l\'envie d\'intégrer une équipe internationale. Le stagiaire devra\r\négalement avoir les compétences suivantes :\r\n\r\n   - Etudes en Traitement Automatique du Langage Naturel / Linguistique\r\n     Informatique\r\n   - Connaissances dans le domaine de la Recherche d\'Information\r\n   - Excellente maîtrise de la langue française et bonne communication\r\n     écrite et orale en espagnol, anglais ou catalan\r\n\r\n\r\nBonus :\r\n\r\n   - Maîtrise d\'au moins un langage de programmation (PHP de préférence)\r\n   - Maîtrise des expressions régulières et du SQL\r\n   - Des compétences dans les méthodes statistiques serait un réel plus\r\n\r\n\r\n*Modalités du poste*\r\n ------------------------------\r\n\r\n   - Stage de 5 à 6 mois (avec *possibilité d\'embauche en CDI*)\r\n   - Rémunération prévue: 525 euros/mois (soit environ 36% du SMIC) +\r\n     prime en fonction des résultats\r\n   - Début : à partir de Février / Mars 2015\r\n   - Lieu : Toulouse\r\n\r\nMerci d\'adresser CV et lettre de motivation à Quintana Manon à l\'adresse\r\nmail suivante : *mquintana@inbenta.com*\r\n*--*\r\n*Manon Quintana*\r\nComputational linguist\r\n\r\n*IN**B**ENTA*\r\n+33 (0)5 31 54 94 97\r\nwww.inbenta.fr'),
(225, '2014-11-24', 'EPTICA', 'Boulogne-Billancourt', 'Sémantique de corpus : auto apprentissage de domaines sémantiques,\r\nregroupements et pondération de termes à partir d\'un parcours de réseau\r\nsémantique\r\n\r\nDébut : Février 2014\r\n\r\nDurée : 6 mois à 1 an\r\n\r\nLieu : Boulogne-Billancourt\r\n\r\nEptica est le leader français et international des solutions de réponse\r\nclient multi-canal (WCS). Principalement implanté en France, au Royaume\r\nUni et à Singapour, EPTICA édite une solution reconnue qui s\'adresse aux\r\ngrands comptes et au mid-market dans les secteurs du Retail, de la\r\nFinance, de l\'Assurance, du Secteur Public et des Services.\r\n\r\nEptica compte 400 clients, parmi lesquels la Société Générale, le Crédit\r\nAgricole, la CNAM, la MAAF, Darty, Pixmania, Carrefour, La Redoute..., en\r\nFrance et aussi à l\'international comme Air Asia, Panasonic...\r\n\r\nDepuis 2013, Eptica intègre le moteur de recherche sémantique et les\r\noutils d\'extraction de contenu issus de la société Lingway. Ces outils\r\nmettent en oeuvre des grammaires d\'analyse et d\'extraction\r\nd\'informations, un réseau sémantique adapté pour le monde de la relation\r\nclient, et des stratégies de recherche documentaire spécifiques.\r\n\r\nDans le cadre des évolutions de son offre, EPTICA propose un stage\r\nconventionné niveau M2, basé à Boulogne-Billancourt.\r\n\r\nAu sein de l\'équipe R&D, le candidat participera aux tâches\r\nd\'exploitation des ressources sémantiques du dictionnaire Eptica, à des\r\nfins de désambiguïsation et de regroupements syntaxiques de termes :\r\n\r\n   - Proposition de regroupements de termes extraits, sur la base du\r\n     parcours du réseau sémantique. Pondération sémantique des éléments\r\n     extraits\r\n\r\n   - Etude d\'enrichissement du réseau sémantique à partir de corpus (par\r\n     exemple Wikipedia)\r\n\r\n   - Ciblage des domaines sémantiques à exploiter, à partir de\r\n     probabilités calculées sur corpus d\'une application donnée\r\n\r\n\r\nCompétences requises :\r\n\r\n   - Traitement Automatique des Langues (étude de corpus, moteur de\r\n     recherche, grammaires locales, techniques de « machine learning »)\r\n   - Des connaissances en programmation/scripting (Java, Groovy, Perl,\r\n     ...)\r\n   - La maîtrise du français et de l\'anglais, la connaissance d\'autres\r\n     langues européennes serait un plus\r\n   - Bonnes capacités d\'analyse et autonomie\r\n   - Facilité à travailler en équipe\r\n\r\nContact:Cécile Potier\r\ncecile.potier@eptica.com\r\n\r\nCécile Potier\r\nChef de produit linguistique\r\n95 bis rue de Bellevue\r\n92100 Boulogne-Billancourt\r\nBureau : +33 (0)9 53 07 60 81\r\nFax : +33 (0)1 47 12 68 89\r\nEmail : cecile.potier@eptica.com\r\nhttp://www.eptica.com/?lang=fr\r\nhttp://epticaexpress.wordpress.com/\r\nhttp://www.linkedin.com/company/eptica?trk=cp_followed_name_eptica\r\nhttps://www.facebook.com/EpticaFrance?fref=ts\r\nhttps://twitter.com/EpticaFrance'),
(226, '2014-11-26', 'Solocal', 'Sèvres', 'clustering sémantique H/F\r\n\r\nDescriptif de l\'entreprise :\r\n\r\nSolocal Group est le nouveau nom de PagesJaunes Groupe depuis le 5 juin 2013.\r\n\r\nN°1 de la communication locale et 1er créateur de sites web à\r\ndestination des entreprises en France et en Espagne, Solocal Group\r\nétend avec succès son savoir-faire sur l\'internet mobile au service\r\ndes entreprises.\r\n\r\nIl fédère plus de 4900 collaborateurs - dont près de 2 200 conseillers\r\nen communication locale en France et en Espagne pour accompagner le\r\ndéveloppement numérique des entreprises (TPE/PME, Grands Comptes,\r\netc.) - 16 marques fortes et complémentaires (PagesJaunes, Mappy,\r\n123deal, A vendre A louer, Embauche.com, Keltravo, Chronoresto,\r\nZoomOn, Solocal Network, ComprendreChoisir, ClicRDV, PJMS, Horyzon\r\nMedia, Leadformance, QDQ, Editus et Solocal Group) et près de 650 000\r\nannonceurs.\r\n\r\nMissions confiées :\r\n\r\nSOLOCAL GROUP EST N° 1 DE LA COMMUNICATION LOCALE\r\n\r\nSe développant selon un business modèle de média, Solocal Group est\r\nprésent dans 3 métiers complémentaires : éditeur de contenus et\r\nservices, média et conseil et régie publicitaire.\r\n\r\nLe Groupe crée et met à disposition des services qui donnent accès à\r\nune mine d\'informations utiles et fiables. Adaptés en permanence aux\r\nmodes de consommation, ils accompagnent les citoyens partout et tous\r\nles jours pour leur faciliter la vie : localiser et contacter un\r\nprofessionnel, retrouver ses amis sur le net, obtenir un itinéraire,\r\nvisiter les boutiques des commerçants, repérer les bons plans...\r\n\r\nPour produire ces contenus et les diffuser, le Groupe compte plus de\r\n4900 collaborateurs en France, Espagne, Luxembourg et Autriche, dont\r\n2300 conseillers en communication locale et digitale et de très\r\nnombreux talents digitaux.\r\n\r\nMissions :\r\n\r\n- analyse de corpus d\'expressions clés\r\n\r\n- identification des variables de clusterisation sémantique\r\n  automatique\r\n\r\n- mise en oeuvre des tests / mesure du taux de couverture sémantique\r\n\r\nProfil recherché :\r\n\r\nmaster Ingénierie linguistique (RI)\r\n\r\n-- \r\n\r\nPour postuler :\r\n\r\nhttp://pages-jaunes.contactrh.com/jobs/440/7770386'),
(227, '2014-11-26', 'Lingua et Machina', 'Roquencourt ou télétravail', '- Lingua et Machina -\r\n\r\nL\'écrit multilingue dans l\'entreprise\r\nFiche de poste - stagiaires constitution de ressources\r\nlinguistiques, traduction et post-édition\r\n\r\nLa société\r\n\r\nLingua et Machina est un éditeur de logiciel français, spécialisé en\r\ntraitement automatisé des langues pour des applications\r\nindustrielles. L&M a été créé en 2002, a commercialisé le logiciel de\r\nmémoire de traduction Similis en 2005 et la plateforme de gestion\r\nlinguistique Libellex en 2010. Similis, réputé pour la qualité de son\r\nextraction terminologique bilingue, est téléchargeable gratuitement\r\nsur notre site Web depuis 2008.\r\n\r\nNos solutions répondent aux problématiques suivantes :\r\n\r\n- comment constituer et tenir à jour à faible coût des ressources\r\n  linguistiques spécialisées (lexiques, réseaux lexico-sémantiques,\r\n  mémoires de traduction, glossaires, etc.) pour en mutualiser l\'usage\r\n  dans l\'entreprise ;\r\n\r\n- comment améliorer la productivité d\'un ou de plusieurs traducteurs\r\n  et assurer la cohérence terminologique dans les traductions de\r\n  documentation technique de grands projets (centrales nucléaires,\r\n  aéronautique, chaînes de montage, etc.) ;\r\n\r\n- comment diminuer les coûts et les délais sur des systèmes\r\nmultilingues à grand e échelle (publication de catalogues, réseaux\r\nsociaux d\'entreprise déployés à l\'échelle mondiale, sites e-commerce,\r\netc.)\r\n\r\nLe produit\r\n\r\nLibellex est une plateforme d\'aide à la traduction, hébergée sur un\r\nserveur et accessible à l\'utilisateur via un navigateur web. Libellex\r\ndispose d\'un moteur interne de traduction automatique entraîné\r\npériodiquement à partir de ses mémoires. La traduction automatique est\r\ndonc spécialisée dans le domaine de l\'utilisateur et ses performances\r\ns\'améliorent au fur et à mesure de l\'alimentation des mémoires avec de\r\nnouvelles traductions.  Cette traduction automatique est contrôlée par\r\ndes glossaires, ce qui permet de garantir l\'homogénéité du texte\r\ntraduit par rapport aux couples de termes validés dans ces\r\nglossaires. L\'utilisation d\'un moteur de traduction interne garantit\r\nla confidentialité.  Deux modes d\'accès distincts sont proposés à\r\nl\'utilisateur : d\'une part une interface bureautique qui privilégie la\r\nsimplicité et l\'intuitivité d\'emploi pour tous (cadres, ingénieurs,\r\nassistantes, stagiaires) et d\'autre part des interfaces\r\nprofessionnelles qui privilégient la puissance et la richesse des\r\noutils et des informations proposées aux spécialistes de l\'écrit\r\n(traducteurs, terminologues, documentalistes).\r\n\r\nSujet de travail\r\n\r\nNous cherchons pour l\'année scolaire 2014-2015 (perlé) ou la saison\r\nprintemps-été 2014 (temps plein) des étudiants en traduction ou en\r\nlinguistique informatique de niveau 2 ème , 3 ème ou 4 ème année (L2,\r\nL3 ou M1) pour deux types de tâches : (i) recherche et validation\r\nterminologique bilingue (anglais, espagnol, portugais, allemand,\r\nchinois) pour nos projets sur les thèmes finance, tourisme, mode,\r\ncuisine, notamment à partir des jeux sérieux de notre partenaire\r\nJeuxDeMots et (ii) post-édition de phrases soumises à la traduction\r\nautomatique par nos clients, en vue d\'améliorer le corpus\r\nd\'entraînement des traducteurs automatiques.\r\n\r\n\r\nConditions de stage\r\n\r\nL\'ensemble de ces tâches se fera sur la base d\'un programme de travail\r\net d\'un suivi de progression. Un fort niveau d\'autonomie et de\r\nresponsabilité est attendu des candidats, en mode chef de projet en\r\nutilisant des logiciels avancés et en proposant des modifications des\r\ninterfaces et des fonctionnalités de ces logiciels.\r\n\r\nDates et lieu de travail\r\n\r\nLe stage perlé s\'effectue en télétravail lors des temps libres de\r\nl\'étudiant, à tout moment de l\'année.\r\n\r\nLe stage temps plein se déroulera pendant les mois de juin et juillet\r\nau sein de notre établissement de Rocquencourt sur le campus de\r\nl\'Inria, Domaine de Voluceau, Rocquencourt, Le Chesnay Cedex, 78153.\r\n\r\nGratification et avantages\r\n\r\nCes stages sont proposés sans gratification.\r\nTransport par navette gratuite entre Place de l\'Étoile, Porte Maillot,\r\nPorte d\'Auteuil ou Versailles et l\'Inria (voir les détails sur\r\nhttp://www.inria.fr/rocquencourt/ur/comment-venir/navettes).\r\nAccès gratuit aux équipements sportifs de l\'Inria (squash,\r\nmusculation, football, tennis, jogging).\r\nAccès à la cantine de l\'Inria avec participation à 50% du prix du\r\nrepas ou coin repas avec four micro-ondes.\r\n\r\nContact\r\n\r\nFrançois Brown de Colstoun - 06 80 95 94 39 - fbc@lingua-et-machina.com'),
(228, '2014-12-01', 'Eptica Lingway', 'Boulogne-Billancourt', 'Début : Février 2014\r\n\r\nDurée : 6 mois à 1 an\r\n\r\nLieu : Boulogne-Billancourt\r\n\r\nEptica est le leader français et international des solutions de réponse\r\nclient multi-canal (WCS). Principalement implanté en France, au Royaume\r\nUni et à Singapour, EPTICA édite une solution reconnue qui s\'adresse aux\r\ngrands comptes et au mid-market dans les secteurs du Retail, de la\r\nFinance, de l\'Assurance, du Secteur Public et des Services.\r\n\r\nDepuis 2013, Eptica intègre le moteur de recherche sémantique et les\r\noutils d\'extraction de contenu issus de la société Lingway. Ces outils\r\nmettent en oeuvre des grammaires d\'analyse et d\'extraction\r\nd\'informations, un réseau sémantique adapté pour le monde de la relation\r\nclient, et des stratégies de recherche documentaire spécifiques.\r\n\r\nLa filiale issue de cette fusion, EPTICA-LINGWAY, développe la gamme de\r\nproduits LeaCV destinée au recrutement (analyseurs de CV, d\'offres,\r\nmoteur sémantique dédié RH, etc.). LeaCV est utilisé par plus de 150\r\nclients.\r\n\r\n\r\nDans le cadre des évolutions de LeaCV, EPTICA-LINGWAY propose un stage\r\nconventionné niveau M2, basé à Boulogne-Billancourt. Au sein de l\'équipe\r\nR&D, le candidat participera explorera les différentes méthodes\r\nautomatiques d\'enrichissement du dictionnaire pour des langues\r\nnon-encore couvertes :\r\n\r\n- Utilisation de ressources ouvertes existantes généralistes (wikipedia,\r\n  wiktionnaire, ...) ou spécifiques au monde RH comme les ontologies\r\n  métier multilingues (ISCO, etc.)\r\n- Croisement avec les ressources existantes à Eptica-Lingway,\r\n- Prototypage d\'algorithmes d\'enrichissement,\r\n- Evaluation des ressources ainsi réalisées sur des tâches précises :\r\n  recherche d\'information, similarité documentaire\r\n\r\nCompétences requises :\r\n\r\n- Traitement Automatique des Langues (étude de corpus, moteur de\r\n  recherche, grammaires locales, techniques de « machine learning »)\r\n- Des connaissances en programmation/scripting (Java, Groovy, Perl, ...)\r\n- La maitrise du français et de l\'anglais\r\n- Bonnes capacités d\'analyse et autonomie\r\n- Facilité à travailler en équipe\r\n- La connaissance de langues d\'Europe du Nord ou de l\'Est est un véritable\r\n  plus\r\n\r\nContact: Hugues de Mazancourt, Directeur Technique EPTICA-LINGWAY\r\n\r\nhugues.de-mazancourt@eptica.com'),
(229, '2014-12-01', 'IRT System X', 'Palaiseau', 'STAGE M2: TAL, Extraction d\'information pour la veille géopolitique -\r\nIRT SystemX\r\n\r\ndurée 6 mois, démarrage février-avril 2015\r\n\r\nVous serez partie prenante d\'une équipe projet composée de 3 étudiants à\r\nqui nous proposons 3 stages:\r\n\r\n- Spécifications et modèle économique d\'une application de veille\r\n  géopolitique,\r\n\r\n- Design d\'une application de veille géopolitique et enfin\r\n\r\n- Extraction d\'information pour la veille géopolitique, qui est l\'objet\r\n  de cette annonce.\r\n\r\n\r\nLes technologies de traitement automatique de la langue (TAL) sont au\r\ncoeur de tous les métiers qui cherchent à exploiter plus efficacement\r\nles documents non structurés disponibles sur le web ou dans des bases de\r\ndocuments (articles de journaux, brevets, blogs, journaux télévisés,\r\narticles scientifiques). Le volume de ces données ne rend possible la\r\nconsultation manuelle que d\'une infime partie. Les outils de TAL vont\r\nservir à filtrer les documents pertinents, en extraire les informations\r\nessentielles, les structurer et les visualiser pour prendre les bonnes\r\ndécisions.\r\n\r\nAu sein de l\'IRT SystemX, Le projet de recherche intitulé IMM\r\n(Intégration Multimédia Multilingue), est un projet tri annuel démarré\r\nfin 2014. Il regroupe des industriels (Bertin Technologie, CapGemini,\r\nExalead, OVH, Systran, Temis, Vecsys, Vocapia) et des partenaires\r\nacadémiques (CEA-LIST, CNRS-LIMSI, INRIA-Saclay, LNE, UPMC-LIP6) ainsi\r\nque le Ministère de la Défense. Son objectif est de mettre en place une\r\nplateforme qui intègre les composants des partenaires (moteur de\r\nrecherche, de transcription de la parole, de traduction...) pour des\r\napplications de veille. L\'objectif commun est de relever un certain\r\nnombre de défis transverses: réduire le temps d\'adaptation à un contexte\r\nnouveau (sources, domaine, langue), en particulier la montée en\r\npuissance des réseaux sociaux, spécifier et développer des fonctions de\r\nhaut niveau pour améliorer la productivité d\'un professionnel de la\r\nveille, étudier et mettre en place des stratégies pour permettre le\r\npassage à l\'échelle des solutions envisagées. Dans le cadre de ce\r\nprojet, nous proposons à 3 étudiants de développer un cas d\'utilisation\r\ncivil de cette plate-forme.\r\n\r\nL\'objectif de l\'ensemble des 3 stages est de créer un démonstrateur\r\nd\'application de veille dans le domaine de la géopolitique et de la\r\ngéostratégie, à l\'usage des entreprises qui souhaitent investir ou\r\ndévelopper leurs ventes dans une région ou un pays, en s\'appuyant sur\r\nles technologies mises à disposition par la plate-forme IMM. Plus\r\nconcrètement, il s\'agit donc de mettre en oeuvre les fonctions de la\r\n\r\nplate-forme pour automatiser la collecte d\'informations et de documents,\r\npour ensuite les analyser et produire des synthèses. Les documents sont\r\ncollectés sur le web, aussi bien depuis des sites institutionnels que\r\ndepuis des réseaux sociaux. La collecte d\'information visera plus\r\nparticulièrement les textes de lois et les réglementations en cours, le\r\ncontexte plus général lié à la culture ou l\'histoire du pays (par\r\nexemple l\'impact de la loi islamique sur une région particulière), mais\r\naussi les projets de lois (par exemple les normes en cours d\'élaboration\r\nau niveau européen) ainsi que les réactions qu\'elles suscitent et les\r\nactivités de lobbying autour de ces projets.\r\n\r\nOn cherchera plus particulièrement à mettre en valeur les capacités\r\nsuivantes de la plate forme :\r\n\r\n- Recherche d\'information multilingue,\r\n- Extraction d\'information (entités nommées et relations),\r\n- Collecte et analyse des réseaux sociaux (Le lobbying est une activité\r\n  assez transparente et qui laisse des traces en particulier sur les\r\n  réseaux sociaux),\r\n- Analyse des contenus de vidéos (transcription de journaux télévisés\r\n  par exemple),\r\n- Visualisation innovante des données collectées analysées et indexées.\r\n\r\n\r\nVos missions seront les suivantes :\r\n- Vous familiariser avec les outils mis à disposition par la plate-forme\r\n  IMM,\r\n- En collaboration avec l\'étudiant des stages 1 et 3, contribuer à la\r\n  spécification d\'un prototype d\'application de veille géopolitique, et\r\n  en particulier élaborer la spécification fonctionnelle et technique en\r\n  tenant compte de la plate-forme existante.\r\n- Elaborer le modèle d\'extraction d\'information et en particulier\r\n  définir quelles entités nommées et quelles relations sont déjà\r\n  traitées par la plate-forme IMM et peuvent être réutilisées, quelles\r\n  entités plus spécifiques au domaine de la veille géostratégique sont\r\n  critiques pour réaliser un démonstrateur.\r\n- Sélectionner une partie de ce modèle et enrichir les outils\r\n  d\'extraction de la plate-forme (annotation, apprentissage, évaluation\r\n  de la qualité..)\r\n- Collecter des corpus, les traiter pour alimenter le prototype\r\n\r\nLe profil recherché : BAC +5, étudiant dans le domaine de l\'informatique\r\navec une spécialisation en traitement automatique des langues, en\r\nrecherche d\'information ou en apprentissage artificiel pour un stage de\r\n6 mois environ sur le site IRT SYSTEMX à Palaiseau.\r\n\r\nVos Compétences sont :\r\n- Programmation langage orienté objet (Java, C++),\r\n- Capacité à développer et utiliser un framework/middleware (comme\r\n  Apache Camel/ServiceMix)\r\n- Capacité à traiter des corpus (langages perl, python) ou des\r\n  ressources linguistiques en anglais\r\n\r\nVos aptitudes personnelles sont :\r\n- Rigueur, sens des responsabilités\r\n- Bon relationnel, capacités à travailler en collaboration\r\n\r\n\r\nRéférence : CREE_2015_IMM1_03_02_141029\r\nPour postuler : stages@irt-systemx.fr'),
(230, '2014-12-01', 'LIRMM', 'Montpellier', 'Vous trouverez ci-dessous la description de deux offres de stages de\r\nMaster 2 à diffuser auprès des étudiants en informatique avec une\r\nspécialisation en fouille de textes et traitement automatique de la\r\nlangue et intéressés par les applications à la santé.\r\n\r\nLes étudiants peuvent faire acte de candidature auprès de Jérôme Azé\r\n(Jerome.Aze@lirmm.fr) et Sandra Bringay (Sandra.Bringay@lirmm.fr).\r\n\r\n\r\n* Lutte contre le cyber-harcèlement -- Définition de métriques\r\n  permettant d\'évaluer l\'urgence des messages postés ? *\r\n\r\nContexte\r\n\r\nLe ministère de l\'éducation nationale a fait de la prévention du\r\nharcèlement entre élèves l\'une de ses priorités. Avec l\'utilisation\r\npermanente des nouvelles technologies de communication (télé- phones,\r\nréseaux sociaux numériques), le harcèlement entre élèves se poursuit en\r\ndehors de l\'enceinte des établissements scolaires. On parle alors de\r\ncyber-harcèlement1. \r\nLes victimes d\'une telle forme de harcèlement peuvent prendre contact\r\navec l\'association Arrêt Demandé en envoyant un email ou un message\r\nposté via Facebook. \r\nLes modérateurs de l\'association traitent les messages au fur et à\r\nmesure de leur arrivée. Sans remettre en cause l\'importance des messages\r\nd\'alerte reçu par l\'association, il est important d\'évaluer le \"degré\r\nd\'urgence\" de l\'alerte afin d\'y répondre le plus rapidement et le plus\r\nefficacement possible. \r\nActuellement, les modérateurs de l\'association réalisent manuellement la\r\ntâche d\'analyse des informations reçues (mails ou messages\r\nFacebook). Compte tenu du nombre limité de modérateurs, il est impératif\r\nde pouvoir répartir le plus efficacement possible la charge de travail\r\nque représente la prise en charge d\'une demande faite à l\'association.\r\n\r\nMissions\r\n\r\nL\'objectif du stage proposé est de pouvoir analyser automatiquement le\r\ncontenu de messages postés sur Facebook et de mettre en place une\r\napproche permettant de prédire l\'urgence du message. La prédiction devra\r\nêtre restituée aux modérateurs sous la forme d\'un score, mais également\r\nsous la forme d\'explications permettant de comprendre les informations\r\nutilisées pour attribuer le score. \r\nLes principales actions à réaliser dans ce stage sont : \r\n\r\n- collecter, structurer et prétraiter les messages envoyés par les\r\n  personnes victimes de harcèlement ; \r\n\r\n- comparer et combiner différents classifieurs permettant d\'associer un\r\n  score (ou une catégorie) à chaque message. Dans un premier temps, la\r\n  boîte à outils Weka 2 sera utilisée pour obtenir rapidement un\r\n  ensemble de classifieurs discrets ; \r\n\r\n- définir une métrique permettant d\'évaluer l\'urgence associée : \r\n\r\n- à un message (métrique centrée sur le contenu d\'un message)\r\n\r\n- à l\'ensemble des messages envoyés par une personne et également des\r\n  réponses déjà apportées par les modérateurs (métrique centrée sur\r\n  l\'individu) \r\n\r\n- adapter la métrique pour prendre en considération des informations\r\n  nouvelles obtenues dans les messages au fur et à mesure des échanges\r\n  (prise en considération du temps)\r\n\r\nUne étude bibliographique sera attendue sur les deux aspects suivants :\r\n1) la détection automatique des maladies mentales dans les réseaux\r\nsociaux [6][2][5] ; 2) les méthodes de fouille de données temporelles\r\nappliquées dans les réseaux sociaux [4]. \r\nÀ l\'issue de cette étude, nous retiendrons un type d\'approche de calcul\r\nde score qui sera formalisée, implémentée et évaluée pendant le stage.\r\n\r\nCompétences\r\n\r\n- traitement semi-automatique de textes libres\r\n- extraction de motifs syntaxiques\r\n- apprentissage de classifieurs\r\n- programmation et outils : Java, Weka, R, Python, Weka\r\n\r\nRéférences\r\n\r\n[1] Amayas Abboute, Yasser Boudjeriou, Gilles Entringer, Jérôme Azé,\r\nSandra Bringay, and Pascal Poncelet. Mining twitter for suicide\r\nprevention. In NLDB 2014, page to be publish, 2014. \r\n[2] Megan A. Moreno, Lauren A. Jelenchick, Katie G. Egan, Elizabeth Cox,\r\nHenry Young, Kerry E. Gannon, and Tara Becker. Feeling bad on facebook :\r\ndepression disclosures by college students on a social networking\r\nsite. Depression and Anxiety, 28(6) :447-455, 2011. \r\n[3] Loïc Paulevé, Gheorghe Craciun, and Heinz Koeppl. Dynamical\r\nProperties of Discrete Reaction Networks. Journal of Mathematical\r\nBiology, 69(1) :55-72, 2014. \r\n[4] Marian-Andrei Rizoiu, Julien Velcin, and Stéphane Lallich. How to\r\nuse temporal-driven constrained clustering to detect typical\r\nevolutions. International Journal on Artificial Intelli- gence Tools,\r\n23(4), 2014. \r\n[5] Adam Sadilek, Henry Kautz, and Vincent Silenzio. Modeling spread of\r\ndisease from social interactions. In In Sixth AAAI International\r\nConference on Weblogs and Social Media (ICWSM, 2012. \r\n[6] Xinyu Wang, Chunhong Zhang, Yang Ji, Li Sun, Leijia Wu, and Zhana\r\nBao. A depression detection model based on sentiment analysis in\r\nmicro-blog social network. 7867 :201-213, 2013. \r\n\r\n\r\n\r\n\r\n\r\n* Prévention du risque de suicide via les réseaux sociaux ? -- Détection\r\n  de points de rupture dans le comportement des personnes à risques *\r\n\r\nContexte \r\n\r\nLe suicide est l\'acte délibéré consistant à mettre fin à sa propre\r\nvie. Le suicide révèle de graves problèmes personnels, mais est\r\négalement souvent le reflet d\'une détérioration du contexte social dans\r\nlequel vit un individu. Les facteurs de risques sont multiples et\r\ncomplexes (bouleversements dans les relations personnelles, harcèlement,\r\naddiction, chômage, dépression clinique et bien d\'autres formes de\r\nmaladie mentale, etc.). Selon un rapport très récent et alarmant de\r\nl\'OMS (4 Septembre 2014)1, une personne dans le monde se suicide toutes\r\nles 40 secondes. On estime à 804 000 le nombre de suicides survenus dans\r\nle monde en 2012, ce qui représente un taux de suicide global\r\nstandardisé selon l\'âge de 11,4 pour 100 000 habitants (15 chez les\r\nhommes et 8 chez les femmes). \r\nDans le cadre du Plan d\'action pour la santé mentale 2013-2020, les\r\nétats membres de l\'OMS se sont engagés à atteindre la cible mondiale\r\nvisant à réduire de 10%% les taux de suicide dans les pays d\'ici 2020.\r\n\r\nMissions \r\n\r\nDans le cadre d\'un TER de M2Pro, une approche permettant d\'aller\r\nidentifier sur Twitter des messages à risques a été conçue et mise en\r\noeuvre par notre équipe [1]. Cette identification repose, entre autre,\r\nsur la prévalence de certains mots dans les tweets de personnes étant\r\npassées à l\'acte. À partir d\'un ensemble de tweets \"suspects\",\r\nl\'application développée dans le cadre de ce TER, permet de prédire si\r\nl\'auteur d\'un tweet suspect risque ou non de passer à l\'acte (prédiction\r\nbinaire). \r\n\r\nL\'objectif de ce stage est de reprendre les travaux existants et de les\r\naméliorer à différents niveaux : \r\n\r\n- définir un score permettant d\'évaluer la \"probabilité de passage à\r\n  l\'acte\", plus finement que sur la base d\'une simple prédiction binaire\r\n  en combinant les probabilités de prédiction de différents classifieurs;\r\n\r\n- concevoir et mettre en place une place une approche permettant de\r\n  détecter des points de rupture dans le comportement ou dans le\r\n  discours d\'un individu. \r\n\r\nLa notion de point de rupture correspond à la notion de transition à\r\ncaractère définitif entre deux états mentaux, avec dégradation du nouvel\r\nétat mental atteint. \r\n\r\nCes changements d\'états peuvent être associés à des changements de style\r\nd\'écriture, des changements de comportements : augmentation ou\r\ndiminution de la fréquence des messages, changement des heures d\'envoi,\r\nchangement des lieux d\'envoi, réduction ou augmentation du nombre\r\nd\'amis...\r\n\r\nLes différents états possibles d\'un individu devront être caractérisés\r\nen accord avec les spécialistes du domaines (psychiatres ou\r\npsychologues). Une modélisation de ces états et des changements entre\r\nces états pourra alors être proposée. L\'étude des données réelles\r\npermettra d\'associer du vocabulaire, des comportements ... à ces\r\ndifférents états et également d\'apprendre les probabilités de transition\r\nentre ces états. \r\nLa définition d\'un tel modèle spécifiquement orienté vers les médias\r\nsociaux permettra d\'affiner la détection des individus à risque. \r\nUne étude bibliographique sera attendue sur les deux aspects : 1) la\r\ndétection automatique des personnes suicidaires via les réseaux sociaux;\r\n[2],[4], [5] 2) les méthodes de détection de changement d\'état [3]. À\r\nl\'issu de cette étude, nous retiendrons un type d\'approche qui sera\r\naméliorée, formalisée, implémentée et évaluée pendant le stage.\r\n\r\nCompétences \r\n- traitement semi-automatique de textes libres\r\n- apprentissage de classifieurs\r\n- programmation et outils : Java, Weka, R, Python, API Twitter\r\n\r\nRéférences \r\n[1] Amayas Abboute, Yasser Boudjeriou, Gilles Entringer, Jérôme Azé,\r\nSandra Bringay, and Pascal Poncelet. Mining twitter for suicide\r\nprevention. In NLDB 2014, page to be publish, 2014. \r\n[2] Megan A. Moreno, Lauren A. Jelenchick, Katie G. Egan, Elizabeth Cox,\r\nHenry Young, Kerry E. Gannon, and Tara Becker. Feeling bad on facebook :\r\ndepression disclosures by college students on a social networking\r\nsite. Depression and Anxiety, 28(6) :447-455, 2011. \r\n[3] Loïc Paulevé, Gheorghe Craciun, and Heinz Koeppl. Dynamical\r\nProperties of Discrete Reaction Networks. Journal of Mathematical\r\nBiology, 69(1) :55-72, 2014. \r\n[4] Adam Sadilek, Henry Kautz, and Vincent Silenzio. Modeling spread of\r\ndisease from social interactions. In In Sixth AAAI International\r\nConference on Weblogs and Social Media (ICWSM, 2012. \r\n[5] Xinyu Wang, Chunhong Zhang, Yang Ji, Li Sun, Leijia Wu, and Zhana\r\nBao. A depression detection model based on sentiment analysis in\r\nmicro-blog social network. 7867 :201-213, 2013.'),
(231, '2014-12-01', 'Lattice/IRIT', 'Paris', '* Descriptif rapide\r\n-----------------------\r\n\r\nLe LATTICE, en collaboration avec l\'IRIT, propose un stage de M2 sur\r\nl\'analyse des paramètres d\'un modèle de réseau de neurones appliqué à\r\nl\'acquisition de restrictions de sélection. Un descriptif détaillé en\r\nanglais figure ci-dessous.\r\n\r\nLe stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à\r\n10 mn du métro Mairie de Montrouge et à 5 mn de l\'arrêt du Tram ligne 3\r\n« Jean Moulin »). Il sera co-encadré par Thierry Poibeau et Marco\r\nDinarelli au LATTICE et par Tim van de Cruys à l\'IRIT (les échanges avec\r\nToulouse se feront principalement par Skype).\r\n\r\nLe stage est prévu pour une durée de 6 mois à compter de mars ou avril\r\n2014. Il donnera obligatoirement lieu à la signature d\'une convention de\r\nstage et sera rémunéré suivant les règles en vigueur (523 euros / mois).\r\n\r\n* Profil recherché \r\n-----------------------\r\n\r\nM2 en informatique \r\nBonne connaissance de python ou, à défaut, de perl\r\nIntérêt pour le traitement automatique des langues\r\nBon niveau d\'anglais (écrit / oral)\r\nDes connaissances en matière de réseau de neurones seraient évidement un\r\nplus\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation\r\nà thierry.poibeau@ens.fr\r\n\r\n\r\n* Descriptif détaillé\r\n-----------------------\r\n\r\n\r\nAn Exploration of a Neural Network Model\'s Parameters for Selectional\r\nPreference Acquisition\r\n\r\nPredicates often have a semantically motivated preference for particular\r\narguments [1]. Compare for example the sentences in (1) and (2).\r\n\r\n(1) The vocalist sings a ballad.\r\n(2) The exception sings a tomato.\r\n\r\nWhile both sentences are grammatically correct, the second sentence is\r\nclearly ill-formed. This preference of a verb for particular arguments\r\nis known as the verb\'s selectional preference. Recently, a neural\r\nnetwork approach has been shown to perform well on the modeling of\r\nselectional preferences [2]. However, many parameters remain to be\r\ninvestigated. First of all, a neural network\'s parameters may be\r\ninitialized in a number of different ways. For example, the parameters\r\nmight be initialized randomly, or they may be initialized using\r\npreviously constructed word embeddings. Secondly, the neural network\'s\r\narchitecture leaves ample space for experiments. The neural network\'s\r\narchitecture might be more `deep\' or more `shallow\', the size of the\r\nnetwork\'s layers may be varied, and certain parameters within the\r\nnetwork might be shared.\r\n\r\nThis internship will investigate the influence of different network\r\nparameters on the performance of a neural network for the modeling of\r\nselectional preferences. The student will adapt and train an existing\r\nneural network implementation for selectional preference acquisition,\r\nand examine the role of various model parameters for the network\'s\r\nperformance.\r\n\r\nReferences:\r\n\r\n[1] Van de Cruys, Tim ; Rimell, Laura ; Poibeau, Thierry and Korhonen,\r\nAnna. 2012. Multi-way Tensor Factorization for Unsupervised Lexical\r\nAcquisition. In Proceedings of the 24th International Conference on\r\nComputational Linguistics (COLING), Mumbai, India.\r\n\r\n[2] Van de Cruys, Tim. 2014. A Neural Network Approach to Selectional\r\nPreference Acquisition. In Proceedings of the 2014 Conference on\r\nEmpirical Methods in Natural Language Processing (EMNLP), pp. 26-35,\r\nDoha, Qatar. Association for Computational Linguistics.'),
(232, '2014-12-01', 'Xerox Research Centre Europe', 'Grenoble', 'Title: Identification of discontinuous variants of compound terms\r\n\r\nDuration 5-6 months\r\n\r\nProposers:\r\n\r\nSalah Aït-Mokhtar\r\n\r\nVassilina Nikoulina\r\n\r\nStart date: January-February 2015\r\n\r\nDescription\r\n\r\nThe main theme of the internship is the identification of terms and\r\nconcepts in domain-specific texts, with a focus on medical texts in the\r\ncontext of the EURECA project (http://eurecaproject.eu/). We have a\r\ndictionary-based term identification system capable of identifying\r\noccurrences of terms in free texts, including non-listed term variants\r\n(e.g. inflected or misspelled terms). The task of the internship will\r\nconsist in contributing to the extension of types of variations that the\r\nterm identifier can handle. In particular, the intern will work on the\r\nidentification and normalization of discontinuous compound terms that\r\nare involved in specific syntactic structures (e.g. coordination), using\r\ndistant supervision with existing domain terminologies. An example of\r\ndiscontinuous compound terms is \"abdominal distention\" in the expression\r\n\"abdominal bloating or distention\".\r\n\r\nRequirements\r\n\r\nThe ideal candidate is a student (MSc or PhD) in computational\r\nlinguistics, or computer science with a good background in NLP. S/he has\r\na good knowledge of syntactic structures and parsing. Good programming\r\nskills, preferably in Java, are also required. Prior experience in NLP\r\nfor the healthcare domain or in terminologies/ontologies is a plus.\r\n\r\nDuring the internship the candidate will acquire a significant knowledge\r\nand practice in the use of hybrid methods for term identification,\r\nincluding distant supervision based on rich terminologies and\r\nontologies. As well, s/he will work closely with researchers and\r\nengineers in an international research environment.\r\n\r\nYou can find more details about this offer at\r\n\r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/Identification-of-discontinuous-variants-of-compound-terms'),
(233, '2014-12-03', 'Lattice', 'Montrouge', 'Proposition de stage M2 recherche en informatique/TAL au Lattice\r\n(http://www.lattice.cnrs.fr) à Montrouge (tout près de Paris)\r\n\r\n\r\nReconnaissance automatique des chaînes de coréférences\r\n\r\nLa reconnaissance des chaînes de coréférences dans les textes,\r\nc\'est-à-dire des portions de textes qui réfèrent à une même entité, est\r\nune tâche importante du TAL. Elle a des incidences sur de nombreuses\r\nautres tâches, comme la recherche et l\'extraction d\'information, le\r\nrésumé automatique, etc. Cette tâche a fait l\'objet de nombreux\r\nchallenges mais, faute de données de référence en français, ils\r\nportaient jusqu\'à présent principalement sur des textes en anglais. L\'an\r\ndernier, la diffusion du corpus ANCOR (ANaphore et Coréférence dans les\r\nCorpus ORaux, cf. Lefeuvre et al. 2014), constitué d\'un ensemble de\r\ntranscriptions du français parlé annotées en coréférences, a permis de\r\nlancer des premières expériences sur le français. Elles ont donné lieu à\r\nun premier système, CROC (Coreference Resolution for Oral Corpus),\r\nentraîné par apprentissage automatique sur ANCOR (Désoyer at al. 2015).\r\nMais ce système est encore rudimentaire : il fait l\'hypothèse que les\r\nmentions d\'entités ont été préalablement reconnues dans les textes et se\r\ncontente donc de prédire leur regroupement en entités coréférentes. Pour\r\nenrichir et améliorer ce système, plusieurs travaux sont envisagés :\r\n\r\n- reconnaître automatiquement les mentions référentielles, qui\r\n  coïncident plus ou moins avec les groupes nominaux présents dans les\r\n  textes,\r\n\r\n- reprendre les expériences qui ont donné lieu à CROC pour essayer\r\n  d\'améliorer ses performances.\r\n\r\nLa méthodologie employée fera dans tous les cas appel à de\r\nl\'apprentissage automatique supervisé (méthodes de classification ou\r\nd\'annotation).\r\n\r\nCompétences requises :\r\n\r\n- stage de niveau M2 en informatique ou en ingénierie linguistique ou\r\n  école d\'ingénieur,\r\n\r\n- compétences en informatique : programmation, langage de script,\r\n  manipulation de corpus,\r\n\r\n- intérêt pour le Traitement Automatique des Langues,\r\n\r\n- des compétences en apprentissage automatique seraient un plus.\r\n\r\nRéférences :\r\n\r\nDésoyer A, Landragin F, Tellier I, Lefeuvre A, Antoine J-Y, \"Les\r\ncoréférences à l\'oral : une expérience d\'apprentissage automatique sur\r\nle corpus ANCOR\", à paraître dans TAL en 2015.\r\n\r\nLandragin F, Schnedecker C (Eds.) \"Les chaînes de référence\", Langages\r\n195, numéro de septembre 2014.\r\n\r\nLefeuvre A, Antoine J-Y, Schang E, \"Le corpus ANCOR_Centre et son outil\r\nde requêtage : application à l\'étude de l\'accord en genre et en nombre\r\ndans les coréférences et anaphores en français parlé\", Actes 4éme\r\nCongrès Mondial de Linguistique Française (CMLF 2014), 2014.\r\n\r\n\r\nLe stage peut durer de 4 à 6 mois au sein du Lattice, à partir de\r\nfévrier/mars 2015. Il sera co-encadré par Frédéric Landragin, Isabelle\r\nTellier (http://www.lattice.cnrs.fr/sites/itellier/) et Marco Dinarelli,\r\net sera financé au tarif stage de 435 euros mensuels.\r\n\r\nEnvoyer CV + lettre de motivation à frederic.landragin@ens.fr,\r\nisabelle.tellier@univ-paris3.fr et marco.dinarelli@ens.fr'),
(234, '2014-12-08', 'LIA', 'Avignon', '------------------------------------------------------------------------\r\n\r\nStage recherche M2 : Modèles connexionnistes pour la génération \r\nautomatique dans le cadre de l\'interaction vocale\r\n\r\nDurée : 6 mois\r\nDémarrage : février-mars 2015\r\nLieu : Laboratoire Informatique d\'Avignon\r\nEncadrants: Bassam Jabaian, Stéphane Huet et Fabrice Lefèvre\r\n\r\nDescription du stage :\r\nLes systèmes d\'interactions vocales utilisés dans des applications comme\r\nla réservation de billets d\'avion ou d\'hôtels, ou bien encore le\r\ndialogue avec un robot, font intervenir plusieurs composants. Parmi\r\nceux-ci figurent le module de génération de texte qui produit la réponse\r\ndu système en langue naturelle à partir d\'une représentation sémantique\r\ninterne créée par le gestionnaire de dialogue.\r\n\r\nLes systèmes de dialogue actuels intègrent des modules de génération \r\nbasés sur des règles écrites à la main à partir de patrons.\r\nex : confirm(type=$U, food=$W,drinks=dontcare) -> Let me confirm, you are \r\nlooking for a $U serving $W food and any kind of drinks right ?\r\n\r\nCes modules gagneraient à se baser sur des méthodes d\'apprentissage \r\nautomatique afin de faciliter la portabilité des systèmes de dialogue \r\nvers d\'autres tâches et améliorer la diversité des échanges générés. \r\nParmi les méthodes d\'apprentissage automatique, figurent les réseaux de \r\nneurones qui ont vu un regain d\'intérêt depuis l\'utilisation du « /deep \r\nlearning/ ». Ces réseaux de neurones ont déjà été employés par Google \r\ndans une tâche similaire de génération de description d\'images \r\n(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html). \r\nL\'objectif de ce stage est d\'étudier l\'utilisation de ces modèles dans \r\nle cadre de l\'interaction vocale.\r\n\r\nSi un intérêt pour l\'apprentissage automatique et le traitement de la\r\nlangue naturelle est souhaitable, il est attendu surtout du stagiaire de\r\nbonnes capacités en développement logiciel.\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation \r\nà bassam.jabaian@univ-avignon.fr'),
(235, '2014-12-08', 'LIFO', 'Orléans', 'Proposition de stage M2 recherche en Informatique/Mathématiques\r\nAppliquées au LIFO (http://www.univ-orleans.fr/lifo/) à Orléans.\r\n\r\n=> Possibilités de poursuite en thèse (Informatique) <=\r\n\r\nTitre du stage : Apprentissage d\'espaces prétopologiques pour \r\nl\'extraction de taxonomies lexicales\r\n\r\nLe sujet du stage portera sur l\'extraction de connaissances structurées,\r\nc\'est-à-dire modélisées sous forme de graphes (arbres, DAG ou réseaux\r\nquelconques). Étant donné un ensemble partiel de relations déjà établi,\r\nl\'objectif est alors d\'apprendre -- dans un contexte semi-supervisé --\r\nles relations cachées structurant la globalité des éléments constitutifs\r\nde la connaissance. Nous avons développé une nouvelle approche (LPS)\r\nconsistant à apprendre un modèle de propagation à partir de relations de\r\nvoisinages et nous avons montré que, dans le contexte décrit\r\nprécédemment, cette méthode permet d\'atteindre des structurations\r\ncomplexes jusqu\'ici non accessibles par des méthodes classiques\r\nd\'apprentissage (statistique et/ou symbolique).\r\n\r\nL\'objectif du stage sera d\'exploiter la méthode LPS décrite ci-dessus\r\ndans un formalisme d\'apprentissage différent à savoir l\'apprentissage\r\nd\'une règle logique de combinaison de voisinages par une approche\r\ngloutonne. Nous envisagerons différentes stratégies de construction\r\nd\'une DNF positive (non nécessairement linéaire) en étudiant les\r\npropriétés des opérateurs logiques par rapport aux combinaisons de\r\nstructures qu\'ils induisent.\r\n\r\nL\'efficacité de cette nouvelle stratégie d\'apprentissage d\'un espace\r\nprétopologique sera étudiée tant en terme de coût d\'apprentissage qu\'en\r\nterme de qualité des structurations induites, sur une série de\r\ntaxonomies dans des domaines génériques et spécialisés.\r\n\r\n\r\nRéférences :\r\n\r\nP. Velardi, S. Faralli, R. Navigli: OntoLearn Reloaded: A Graph-Based\r\nAlgorithm for Taxonomy Induction. Computational Linguistics 39(3):\r\n665-707 (2013)\r\n\r\nG. Cleuziou, D. Buscaldi, V. Levorato, G. Dias : A pretopological\r\nframework for the automatic construction of lexical-semantic structures\r\nfrom texts.CIKM 2011: 2453-2456\r\n\r\nZ. Kozareva, E. H. Hovy: A Semi-Supervised Method to Learn and Construct\r\nTaxonomies Using the Web. EMNLP 2010: 1110-1118\r\n\r\nCh. Largeron, S. Bonnevay: A pretopological approach for structural\r\nanalysis. Inf. Sci. 144(1-4): 169-185 (2002)\r\n\r\n\r\nCompétences requises :\r\n\r\n- stage de niveau M2 ou école d\'ingénieur en informatique ou\r\n  mathématiques appliquées\r\n\r\n- compétences en : programmation, algèbre (espaces vectoriels, théorie\r\n  des ensembles)\r\n\r\n- intérêt pour la fouille de textes (Recherche d\'Information) et\r\n  l\'apprentissage automatique.\r\n\r\nLe stage peut durer de 4 à 6 mois au sein du LIFO, dans l\'équipe CA à\r\npartir de février/mars 2015. Il sera co-encadré par Guillaume Cleuziou\r\net Vincent Levorato et sera financé au tarif stage de 435 euros\r\nmensuels.\r\n\r\nEnvoyer CV + lettre de motivation à guillaume.cleuziou@univ-orleans.fr\r\net vlevorato@cesi.fr.'),
(236, '2014-12-08', 'LIPN & Lattice', 'Paris', '---------------------------------------------------------\r\n     PROPOSITION DE STAGE DE MASTER RECHERCHE REMUNERE\r\n---------------------------------------------------------\r\n\r\nCe stage de Master se déroulera au sein du PRES Sorbonne Paris Cité \r\nentre le LIPN (http://www-lipn.univ-paris13.fr/), dans l\'équipe \r\n«Représentation des Connaissances et Langage Naturel» (RCLN) et le \r\nLATTICE (http://www.lattice.cnrs.fr/).\r\n\r\nCe stage est rémunéré grâce au soutien du laboratoire d\'excellence\r\n\"Empirical Foundations of Linguistics\" (labex EFL,\r\nhttp://www.labex-efl.org/). Il fait partie d\'un projet plus large sur la\r\ndécouverte de patrons lexico-grammaticaux, mené en commun entre le LIPN\r\net le LATTICE dans le cadre du labex EFL (axe «Analyse sémantique\r\ncomputationnelle » (http://www.labex-efl.org/?q=fr/recherche/axe5). Le\r\nsujet est décrit ci-dessous.\r\n\r\nProfil recherché : étudiant Master Recherche en TAL ou en informatique \r\n(avec compétences en TAL).\r\n\r\nLes candidats doivent envoyer leur candidature (CV, Lettre de\r\nmotivation, relevés de notes,...) le plus rapidement possible par mail à\r\nThierry.Charnois@lipn.univ-paris13.fr\r\n\r\nCe stage sera déroulera à Paris, et sera co-encadré par Thierry Poibeau\r\n(LATTICE) et Thierry Charnois (LIPN), Dominique Legallois (Crisco,\r\nuniversité de Caen) participera également à l\'encadrement.\r\n\r\n*SUJET : Caractérisation des genres discursifs par la méthode des motifs\r\nséquentiels*\r\n\r\n\r\nL\'objectif de ce stage de Master 2 est l\'analyse d\'un genre discursif\r\nparticulier, le roman policier. Le point principal consistera à\r\nidentifier les motifs séquentiels spécifiques de ce genreen le\r\ncomparantau genre romanesque dit \"sérieux\". Les motifs sont des patrons\r\nlexico-grammaticaux, plus abstraits que les segments répétés ou n-grams.\r\nIls sont de taille variable, et peuvent comporter des \"gaps\" entre les\r\ndifférents éléments. Ils sont extraits de façon non supervisée.\r\n\r\nL\'approche défendue, en privilégiant des unités syntagmatiques, se veut\r\ncomplémentaire de laperspective morpho-syntaxique (Malrieu et Rastier\r\n2001) qui reste, dans le domaine de la caractérisation générique, la\r\nméthode traditionnellement adoptée après Biber (1991).\r\n\r\nL\'extraction des motifs sera réalisée à partir de l\'outil SDMC --\r\nhttp://sdmc.greyc.fr -- (des fonctionnalités supplémentaires pourront\r\nêtre proposées et implémentées durant le stage) ; les principales\r\nréflexions du stagiaire porteront sur les différences de granularité des\r\nmotifs, sur la pertinence de certaines annotations sémantiques\r\npossibles, ou sur la pertinence d\'une catégorisation morpho-syntaxiques\r\nplus fines des unités.\r\n\r\nMalrieu D. et Rastier F. (2001) Genres et variations morphosyntaxiques,\r\n/Traitements automatiques du langage/, 42, 2, pp. 547-577.\r\n\r\nBiber, D. (1991). /Variation Across Speech and Writing/. Cambridge \r\nUniversity Press, Cambridge, 1991.\r\n\r\nLongrée D. et Mellet S. (2013). « Le motif : une unité phraséologique\r\nenglobante ? Étendre le champ de la phraséologie de la langue au\r\ndiscours », /Langages/189 (D. Legallois & A. Tutin, coord.), p.68-80\r\n\r\nQuiniou S. ; P. Cellier ; T. Charnois et D. Legallois (2012). « What \r\nAbout Sequential Data Mining Techniques to Identify Linguistic Patterns \r\nfor Stylistics? ». Actes de la conférence CICLING. Springer.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(237, '2014-12-08', 'Lattice', 'Montrouge', 'Algorithme alternatif pour le calcul des probabilités dans des champs\r\naléatoires conditionnels (CRF)\r\n\r\nLes champs aléatoires conditionnels (CRF) sont actuellement un des\r\nmodèles les plus performants dans les tâches d\'étiquetage de séquences\r\net d\'analyse syntaxique [1,2]. Malgré des améliorations récentes [3],\r\napprendre ce modèle reste relativement coûteux, notamment à cause des\r\nalgorithmes utilisés pour le calcul des probabilités du modèle.\r\nCependant dans plusieurs tâches de Traitement Automatique de Langues\r\n(TAL), l\'information prédite automatiquement a une annotation assez\r\ncreuse. Ceci suggère des algorithmes alternatifs qui prennent en compte\r\ncette caractéristique pour réduire la complexité computationnelle dans\r\nles calculs des probabilités des CRF.\r\n\r\nAu cours de ce stage le candidat développera un algorithme alternatif\r\npour le calcul des probabilités des modèles CRF. Ceci apportant deux\r\navantages. D\'une part la possibilité d\'entraîner un modèle CRF plus\r\nrapidement. D\'autre part cette réduction du coût computationnel\r\npermettra d\'entraîner des modèles plus complexes, ce qui pourra mener à\r\nde meilleurs résultats sur une tâche donnée. Le candidat expérimentera\r\nl\'algorithme développé sur une tâche de TAL spécifique.\r\n\r\n[1] Lavergne, Thomas and Cappé, Olivier and Yvon, François. 2010\r\nPractical Very Large Scale CRFs.  Proceedings of the 46th Annual Meeting\r\nof the Association for Computational Linguistics (ACL)\r\n\r\n[2] Jenny Rose Finkel, Alex Kleeman, and Christopher D. Manning. 2008.\r\nEfficient, Feature-based, Conditional Random Field Parsing.  Proceedings\r\nof the 46th Annual Meeting of the Association for Computational\r\nLinguistics (ACL)\r\n\r\n[3] Naoaki Okazaki. 2007.  CRFsuite: a fast implementation of\r\nConditional Random Fields (CRFs).\r\n\r\nProfil recherché :\r\n- stage de niveau M2 en informatique ou école d\'ingénieur,\r\n- compétences en informatique : programmation (C), langage de script\r\n  (lua), manipulation de corpus,\r\n- intérêt pour le Traitement Automatique des Langues,\r\n- compétences en apprentissage automatique avec modèles probabilistes.\r\n\r\nLe stage peut durer de 4 à 6 mois au sein du Lattice\r\n(http://www.lattice.cnrs.fr), à partir de mars/avril 2015. Il sera\r\nencadré par Marco Dinarelli (www.marcodinarelli.it) et sera financé\r\nsuivant les règles en vigueur.\r\nEnvoyer CV + lettre de motivation à marco.dinarelli@ens.fr'),
(238, '2014-12-08', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage : Développeur Python (H/F)\r\n------------------------------------------------------------------------\r\n\r\nSyllabs est une start-up innovante dans le domaine de la sémantique et\r\ndu web. Grâce à un gros effort de R&D, nous avons développé des\r\ntechnologies de collecte, d\'analyse et de génération de données\r\ntextuelles sur le Web.\r\n\r\nLa génération automatique de données textuelles consiste à transformer\r\nune base de données en textes pour, par exemple, générer des articles de\r\npresse (comptes rendus de rencontres sportives, rapports de tremblements\r\nde terre...), des descriptifs de produits (appareils photo,\r\nchaussures...) ou de lieux (destinations touristiques, hôtels...), etc.\r\nLes utilisateurs de notre outil de génération sont nos ingénieurs\r\nlinguistes qui, via des fichiers de règles et de données structurées,\r\nengagent le processus de génération de textes. Leurs besoins évoluent\r\nrégulièrement, au fur et à mesure des demandes de nos clients.\r\nPossibilités d\'embauche à la fin du stage.\r\n\r\n------------------------------------------------------------------------\r\nDescription du stage\r\n------------------------------------------------------------------------\r\n\r\nLe stage s\'inscrit dans la continuité des travaux effectués sur notre \r\ntechnologie de génération et a un objectif triple :\r\n\r\n- L\'outil doit être enrichi de nouvelles fonctionnalités afin\r\n  d\'augmenter les capacités de notre génération,\r\n- L\'automatisation des tâches les plus redondantes des linguistes sera\r\n  menée afin d\'orienter l\'outil vers une autonomie et une flexibilité\r\n  accrues,\r\n- Aborder la mise en place d\'une version simplifiée de l\'outil de\r\n  génération, dotée d\'une interface intuitive et fonctionnelle.\r\n\r\nLes tâches concernent principalement :\r\n  - Prendre en main l\'outil de génération existant et son code,\r\n  - Interagir avec les utilisateurs afin de bien identifier leurs\r\n    besoins et usages,\r\n  - Mener à bien le développement de nouvelles fonctionnalités,\r\n  - Adapter l\'outil à l\'autonomie de la génération automatique de\r\n    textes,\r\n  - Redéfinir les spécifications d\'une version allégée de l\'outil, et\r\n    éventuellement l\'implémenter au travers d\'une interface graphique.\r\n\r\nCes travaux seront encadrés par l\'ingénieur R&D ayant développé l\'outil\r\nexistant.\r\n\r\n------------------------------------------------------------------------\r\nProfil recherché\r\n------------------------------------------------------------------------\r\n\r\nMaîtrise de la programmation Python\r\nAutonomie et capacité à travailler en équipe\r\nGoût pour la compilation et l\'optimisation de code\r\nMaîtrise de Linux\r\nNotions en interface utilisateur et interface Web\r\nAnglais technique, connaissance d\'autres langues appréciée\r\nExpérience en Traitement Automatique des Langues souhaitée\r\n\r\n------------------------------------------------------------------------\r\nDivers\r\n------------------------------------------------------------------------\r\n\r\nDurée : 6 mois\r\n\r\nBonne ambiance et équipe technique de grande qualité.\r\n\r\nStage conventionné, rémunération supérieure à la rémunération minimale +\r\ntickets resto + remboursement à moitié du passe Navigo.\r\n\r\nLieu de travail : 26 rue Notre-Dame-de-Nazareth, 75003 Paris\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en \r\nindiquant dans l\'objet du mail « Stage generation ».'),
(239, '2014-12-11', 'LIDILEM', 'Grenoble', 'Commanditaire : Thomas Lebarbé (LIDILEM - U. Grenoble - Alpes)\r\nLieu : Université de Grenoble ou MSH-Alpes\r\nCompétences requises : Ingénieur de développement Web\r\nDurée du stage : 4 mois\r\nRémunération : gratification réglementaire (désolé de ne pouvoir faire\r\nmieux)\r\n\r\nContexte :\r\nLe domaine des humanités numériques est en plein essor depuis quelques\r\nannées mais présente encore la faiblesse d\'être peu outillé pour la\r\nproduction de sources textuelles (transcription de manuscrits,\r\nenrichissement scientifique, annotation critique, intellectuelle,\r\netc.). L\'université Stendhal s\'est engagée depuis plusieurs années dans\r\nun certain nombre de projets de valorisation de patrimoines littéraires\r\net développe des collaborations avec différentes universités aussi bien\r\nau niveau national qu\'au niveau international. Le projet de stage\r\ns\'inscrit dans une collaboration entre l\'université Stendhal - Grenoble\r\nAlpes et l\'Université Paris VII.\r\n\r\nDescription du stage :\r\nLe stage se décompose en deux parties :\r\n\r\n1/ Développement d\'un environnement web de production WYSIWYM (what you\r\n   see is what you mean). Etant données une grammaire (DTD) et une\r\n   feuille de style (CSS), il s\'agit de donner un environnement de\r\n   production de documents XML qui à la fois accompagne et contraigne le\r\n   producteur : accompagner avec une mise en forme qui libère\r\n   l\'utilisateur des contraintes techniques et contraindre en pilotant\r\n   la production par le biais de la grammaire.\r\n2/ Développement d\'une plateforme encapsulant l\'environnement de\r\n   production. L\'objectif de l\'environnement de production est de\r\n   fournir à des équipes de recherche comme des équipes pédagogique, de\r\n   travailler de manière collaborative autour de projets distincts. La\r\n   plateforme devra donc permettre de gérer des utilisateurs (avec des\r\n   rôles), des projets, des fonds.\r\n\r\nIl ne s\'agit pas de développer ces deux éléments ex nihilo, mais\r\néventuellement de s\'appuyer sur des outillages existants pour les\r\nadapter aux besoins et à la littératie numériques des utilisateurs\r\nfinaux.\r\n\r\nCandidatures :\r\nLes candidatures doivent être envoyées par mail à\r\nthomas.lebarbe@u-grenoble3.fr avant le 31 janvier 2014 et feront l\'objet\r\nd\'un accusé de réception dans les deux jours ouvrés\r\n\r\nLe dossier de candidature contiendra :\r\n- un cv\r\n- une lettre de motivation\r\n- éventuellement la recommandation d\'un enseignant\r\n\r\nLe cas échéant, nous pourrons demander un entretien téléphonique ou en\r\nvisioconférence.\r\n\r\nLe début et la durée du stage pourront être modulée en fonction du\r\ncalendrier de formation du candidat sélectionné.\r\n\r\nThomas LEBARBÉ, Pr. \r\nhttp://www.u-grenoble3.fr/'),
(240, '2014-12-11', 'LIMSI', 'Orsay', 'Proposition de stage M1 ou M2 au LIMSI-CNRS\r\n\r\nResponsable du stage : Marianna Apidianaki\r\n\r\nTitre : Analyse sémantique de traductions automatiques\r\n\r\nLa qualité des traductions automatiquement produites ne cesse de\r\ns\'améliorer ces dernières années et les systèmes de Traduction\r\nAutomatique disponibles en ligne sont utilisés de manière régulière par\r\nun nombre croissant d\'utilisateurs. Néanmoins des problèmes sont\r\ntoujours repérés dans les textes traduits à des niveaux différents,\r\nallant de la morphologie et la grammaire jusqu\'aux choix lexicaux et\r\nl\'ordre des mots. Parmi ces sources d\'erreurs la sélection lexicale est\r\nidentifiée comme la plus importante, ayant un impact fort sur\r\nl\'adéquation et la fluidité des textes traduits (Popovic, 2012;\r\nWisniewski et al., 2013).\r\n\r\nL\'objectif de ce stage est d\'analyser d\'un point de vue sémantique les\r\nchoix lexicaux effectués par les systèmes de Traduction Automatique\r\nactuels. Cette analyse sera basée sur des données utilisées dans le\r\ndomaine de la Traduction Automatique et sera enrichie par des\r\nressources, des méthodes et des outils habituellement utilisés pour\r\nl\'analyse sémantique.\r\n\r\nLe stage est rémunéré et se déroulera au LIMSI-CNRS (Orsay) dans le\r\ngroupe Traitement du Langage Parlé (TLP, http://www.limsi.fr/tlp/mt/).\r\n\r\n\r\nProfil : \r\n- Master 1 ou 2 en Traitement Automatique des Langues ou Informatique\r\n- bonnes compétences en programmation (Perl et/ou Python, connaissances\r\n  en Java souhaitables mais pas nécessaires)\r\n- expérience avec des systèmes de Traduction Automatique n\'est pas\r\n  nécessaire mais serait un plus\r\n\r\nDurée : 4 à 6 mois (plein temps)\r\nDate de début : à partir de début février 2015, selon disponibilité\r\nGratification CNRS standard : 536¤ + 50¤ (frais de transport) =\r\n  586¤/mois de stage\r\nLieu : LIMSI-CNRS, Groupe TLP, rue John von Neumann, Université Paris\r\n  Sud, 91403 Orsay Cedex\r\n\r\nContact: Marianna Apidianaki (marianna@limsi.fr)'),
(241, '2014-12-15', 'LIMSI', 'Orsay', 'Proposition de stage M1 ou M2 au LIMSI-CNRS\r\n\r\nResponsables du stage : Aurélie Névéol et Xavier Tannier\r\n\r\nTitre : Analyse temporelle des dossiers électroniques patient.\r\n\r\nLe contenu et l\'ambition du stage pourront être modulés en fonction du\r\nniveau d\'étude et de la durée du stage du candidat.\r\n\r\nContexte\r\nL\'analyse temporelle de textes d\'information a pour but général de mieux\r\nlocaliser dans le temps les événements décrits dans ces textes, et donc\r\nd\'alimenter de façon plus précise des moteurs de recherche ou des outils\r\nd\'extraction d\'information. Pour cela, la première étape est de détecter\r\ncorrectement les expressions temporelles de ces textes. Ces expressions\r\ntemporelles peuvent être des dates absolues, c\'est-à-dire que l\'on peut\r\nplacer sans ambiguïté sur l\'axe des temps (par exemple, le 14 janvier\r\n2008), mais aussi des dates relatives, qui nécessitent une phase de\r\nrésolution ou de normalisation (par exemple, le 14 janvier dernier, dans\r\n6 semaines). Dans le cadre du dossier électronique patient, des\r\nexpressions temporelles propres au domaine de spécialité, le domaine\r\nmédical, peuvent également être rencontrées (par exemple, à 18 SA, à\r\nj+1). Une deuxième étape consiste à détecter les évènements liés aux\r\nexpressions temporelles.  Dans le domaine médical, il s\'agira\r\ntypiquement de maladies, de traitements médicamenteux, de procédures\r\nchirurgicales, etc.\r\n\r\nLes techniques d\'analyse temporelle des textes ont fortement progressé\r\nces dernières années, mais s\'attachent en général au domaine\r\njournalistique et particulièrement au cadre des dépêches. Nous\r\nsouhaitons étudier un autre domaine de spécialité, le domaine médical,\r\nainsi qu\'un type de document particulier, le dossier électronique\r\npatient. Nous nous intéressons au repérage automatique des expressions\r\ntemporelles et des évènements auxquels elles se rapportent dans les\r\ndocuments cliniques afin de construire automatiquement une chronologie\r\nmédicale pour chaque patient à l\'échelle d\'un document, puis d\'un\r\ndossier complet. L\'un des objectifs cliniques de ce travail est de\r\nfaciliter les études rétrospectives réalisées par des cliniciens en\r\npermettant une visualisation et une comparaison automatiques des\r\nparcours de soin de différents patients, ainsi qu\'une comparaison des\r\nparcours de soin des patients avec les protocoles de référence en\r\nvigueur.\r\n\r\nLe travail s\'appuiera sur un corpus de documents cliniques annoté en\r\nexpressions temporelles normalisées selon la norme TimeML, ainsi que sur\r\ndes outils d\'analyse temporelle et d\'analyse des documents cliniques en\r\nfrançais développés au sein du LIMSI.\r\n\r\nTravail à réaliser :\r\n\r\nSelon le niveau d\'étude de la personne choisie, nous pourrons nous\r\nintéresser à une ou plusieurs des problématiques suivantes :\r\n- Utilisation et adaptation d\'outils d\'extraction d\'évènement\r\n  biomédicaux dans les documents cliniques\r\n- Extraction automatique de relations temporelles dans les documents\r\n  cliniques\r\n- Réconciliation des expressions temporelles issues de documents\r\n  différents\r\n- Création d\'une ligne temporelle pour représenter l\'historique d\'un\r\n  patient\r\nOn utilisera un corpus de plusieurs centaines de documents cliniques\r\ndésidentifiés en français.\r\n\r\nProfil :\r\n- Master1, Master 2 (professionnel ou recherche) en traitement\r\n  automatique de la langue ou informatique, école d\'ingénieur\r\n- Bonnes compétences en programmation (Perl et/ou Python, connaissances\r\n  en Java souhaitables mais pas nécessaires)\r\n- Des connaissances en terminologie biomédicale et/ou en apprentissage\r\n  automatique seront un plus.\r\n\r\nDurée : 4 à 6 mois (plein temps)\r\nRémunération : Gratification CNRS standard : 536¤ + 50¤ (frais de\r\ntransport) = 586¤/mois de stage\r\nLieu : LIMSI-CNRS, Groupe ILES, rue John von Neumann, Université Paris\r\nSud, 91403 Orsay Cedex\r\n\r\nContacts :\r\nAurelie.Neveol[at]limsi.fr\r\nXavier.Tannier[at]limsi.fr'),
(242, '2014-12-15', 'Velvet Consulting', 'Paris', '*Sujet de stage*\r\nLe Big Data est aujourd\'hui une réalité pour nos clients. Leurs données\r\nsont de plus en plus volumineuses, variées et volatiles. Les approches\r\nclassiques demeurent inefficaces pour traiter ces données. *Velvet\r\nConsulting* travaille sur des approches innovantes pour répondre à ce\r\nbesoin. Le stage que nous vous proposons s\'inscrit dans ce cadre et\r\nporte sur la mise en place d\'un système d\'analyse de gros volume de\r\ndonnées textuelles dans un environnement Big Data.\r\n\r\n*Contexte*\r\nSystème de recommandation fonctionnant avec des techniques\r\ncollaboratives classiques.\r\n\r\n*Problématiques*\r\n- Comment migrer ce système en mode Big Data ?\r\n- Quel est l\'apport des données textuelles dans le processus de\r\n  recommandation ?\r\n\r\n*Étapes*\r\n- Étape 1 : État de l\'art et amélioration d\'un système de recommandation\r\n  existant ;\r\n- Étape 2 : Migration du système dans un environnement Big Data\r\n  (conception et implémentation) ;\r\n- Étape 3 : Évaluation des performances et comparaison des résultats.\r\n\r\n*Profil recherché*\r\nÉtudiant en dernière année d\'École d\'Ingénieur ou de Master 2 (BAC+5)\r\ndans le domaine de l\'informatique avec des compétences en traitement\r\nautomatique des langues et intelligence artificielle.\r\n\r\n*Compétences*\r\n- Programmation / Technologie : Java-Eclipse, XML, SQL, GATE\r\n- O/S : Linux, Shell, Windows Serveur\r\n- Capacité à traiter des corpus ou des ressources linguistiques en\r\n  anglais\r\n- Compétences en Big Data (Hadoop, Hive, Impala, Flume) appréciées\r\n\r\n*Qualités personnelles*\r\n- Rigueur, sens des responsabilités\r\n- Bon relationnel, capacité à travailler en équipe\r\n\r\n*Encadrant *\r\nPh D Computer Science - Direction Data Mining\r\n\r\n*Conditions*\r\nType de stage : stage de fin d\'études / pré-embauche\r\nDébut du stage : entre Janvier et Avril 2015\r\nDurée : entre 6 et 9 mois\r\nRémunération : 1000 nets / mois + Tickets Restaurant (9 euros / jour) +\r\n50 % Carte Navigo\r\nLieu : 10-12 rue du Général Foy 75008 Paris\r\n\r\n*Candidature*\r\n*CV & lettre de motivation* à Stéphane Martignon, Responsable\r\nRecrutement - smartignon@velvetconsulting.com *avant le 31 Décembre\r\n2014*\r\n\r\n\r\n*A propos de Velvet Consulting*\r\n\r\nVelvet est un cabinet de conseil en stratégie marketing.  Nos\r\nconsultants accompagnent nos clients sur l\'ensemble de leurs projets\r\nMarketing, de la définition de la stratégie à sa mise en oeuvre\r\nopérationnelle et technique.\r\n\r\nNotre Direction Datamining aide nos clients à maximiser l\'exploitation\r\nde leurs données et à renforcer rapidement l\'efficacité du marketing\r\nclient.  Nous combinons une expertise datamining, en termes d\'analyses &\r\nde modélisations statistiques complexes et une expertise marketing afin\r\nde conseiller les directions marketing grâce à nos analyses\r\nopérationnelles.\r\n\r\nNous vous proposons d\'intégrer une structure à taille humaine qui vous\r\npermettra de vous épanouir professionnellement & personnellement dans un\r\ncontexte dynamique & agréable. Vous développerez vos compétences\r\ntextmining, statistiques et marketing grâce à des projets d\'envergure\r\norientés sur de la modélisation statistique complexe appliquée au\r\nMarketing Client.\r\n\r\nNous favorisons les échanges entre Consultants & Managers et organisons\r\nrégulièrement des meetings axés sur le partage des connaissances.\r\n\r\nSur toutes vos missions, vous aurez également un lien direct avec nos\r\nclients, Directions Etudes & Directions Marketing de tous secteurs\r\nd\'activité et aurez la possibilité de présenter vos études et\r\nrecommandations appuyés par nos Managers.\r\n\r\nIntégrer Velvet, c\'est aussi intégrer un cabinet proche de ses\r\nconsultants et adopter une culture d\'entreprise forte. Vous partagerez\r\nnos activités et moments de détentes tels que nos cocktails dinatoires,\r\nnos afterworks, nos RDVs sportifs & nos séminaires annuels !'),
(243, '2015-01-05', 'Lattice', 'Paris', 'Titre: reconnaissance profonde d\'expressions polylexicales par\r\nétiquetage séquentiel supervisé\r\n\r\nContexte:\r\nLes expressions polylexicales, qui forment des combinaisons de mots avec\r\nun certain degré de non-compositionalité, posent de sérieux problèmes\r\npour les applications du traitement automatique des langues comme la\r\ntraduction automatique. L\'apparition de corpus annotés en expressions\r\npolylexicales a eu pour conséquence le développement de systèmes\r\nsupervisés de reconnaissance de telles expressions. Ces systèmes\r\nreposent en général soit sur des étiqueteurs séquentiels (Vincze et\r\nal. 2011; Constant et al. 2012; Schneider et al. 2014), soit sur des\r\nanalyseurs syntaxiques (Green et al. 2011, 2013; Kung 2014; Candito et\r\nConstant 2014; Le Roux et al. 2014), qui peuvent être alimentés par des\r\nlexiques. Les travaux sur le sujet sont souvent limités à une\r\nreconnaissance de surface, même s\'il existe des exceptions: par exemple,\r\nSchneider et al. (2014) font une classification binaire des expressions\r\nselon leur niveau d\'idiomaticité (strong vs. weak); Candito et Constant\r\n(2014) reconnaissent la structure syntaxique interne. \r\n\r\nSujet:\r\nL\'objectif de ce stage est de développer un système de reconnaissance\r\ndes expressions polylexicales dans le cadre de l\'étiquetage\r\nséquentiel. Ce système devra être capable de réaliser une analyse plus\r\nfine des expressions polylexicales que ce qui est en général réalisé. En\r\nparticulier, il devra repérer les imbrications d\'expressions\r\npolylexicales, qui sont relativement fréquentes dans les textes. Par\r\nexemple, la séquence \'ministre français des affaires étrangères\'\r\ncontient deux expressions polylexicales \'ministre des affaires\r\nétrangères\' et \'affaires étrangères\'. La construction \'faire faux bond\'\r\ncontient un nom composé imbriqué \'faux bond\' ayant une certaine\r\nautonomie. Ce phénomène est bien connu du domaine de la terminologie. Il\r\ns\'agira de s\'inspirer des travaux existants sur le sujet.\r\n\r\nLieu : Lattice, CNRS\r\nEncadrants: I. Tellier (Univ. Paris Sorbonne-Nouvelle) et M. Constant\r\n(Univ. Paris-Est Marne-la-Vallée)\r\n\r\nProfil du candidat:\r\n- Master 2 ou école d\'ingénieur en informatique ou TAL\r\n- bonnes compétences de programmation,\r\n- connaissance des outils d\'apprentissage\r\n\r\nDurée du stage : 6 mois\r\nRémunération : gratification réglementaire\r\nFinancement: projet AIM-WEST : http://aim-west.imag.fr\r\n\r\nLes candidatures doivent être envoyées par mail à\r\nisabelle.tellier@univ-paris3.fr avant le 31 janvier 2014. Le dossier de\r\ncandidature contiendra un cv, une lettre de motivation, et,\r\néventuellement, la recommandation d\'un enseignant.'),
(244, '2015-01-05', 'INaLCO', 'Paris', 'Stage M2 à l\'INaLCO\r\nDéveloppement d\'un outil de désambiguisation morpho-syntaxique pour le\r\nbambara\r\n\r\nLe bambara est une langue mandingue parlée en Afrique de l\'Ouest et dans\r\nla diaspora africaine. Elle fait partie des langues africaines les mieux\r\ndécrites (Dumestre 2003, Vydrine 2014). Comme pour toutes les langues et\r\nen particulier pour les langues peu dotées, l\'outillage du bambara est\r\nune nécessité afin de permettre aux bambarophones d\'utiliser leur langue\r\nnatale dans leurs interactions avec les nouvelles technologiques.\r\n\r\nÀ cet effet, le Corpus Bambara de Référence (CBR), été constitué ces\r\ndernières années (Vydrine 2013, Maslinsky 2014). Celui-ci contient\r\nactuellement plus d\'un million de mots et est géré au moyen du logiciel\r\nNoSketchEngine (Kilgarriff 2007). Il s\'appuie sur le lexique Bamadaba\r\nafin de proposer des possibilités de catégories morpho-syntaxiques pour\r\nles mots du corpus. Au sein de ce corpus, une sous-partie (300K mots) a\r\nété manuellement désambiguisée.\r\n\r\nDans le cadre du projet MANTAL conduit par les équipes ERTIM et LLACAN\r\nde l\'INaLCO, le stage que nous proposons a pour objectif de mettre en\r\noeuvre et d\'évaluer des approches pour désambiguiser automatiquement le\r\ncorpus. A cet effet, des modèles traditionnels à base, par exemple,\r\nd\'arbres de décision (Schmid 1995), de maximum d\'entropie (Denis 2009)\r\nou de champs aléatoires conditionnels (Lafferty 2001), seront\r\névaluées. D\'autres techniques seront mises à l\'épreuve, dont celles\r\nreposant sur l\'utilisation conjointe de réseaux de neurones et de\r\ntechniques de sélection de features itératives.\r\n\r\nProfil recherché :\r\n+ Master 2 en Informatique\r\n+ Bonnes compétences en programmation (Python, C++, Java)\r\n+ Compréhension des approches en apprentissage automatique\r\n+ Intérêt pour le traitement automatique des langues\r\n+ La connaissance des langues mandingues sera vivement appréciée\r\n\r\nDurée du stage : 5 mois à temps plein\r\nDate de début : février ou mars 2015\r\nGratification : 500,51¤/mois (et rbst de 50% des transports)\r\nLieu : INaLCO, 2 rue de Lille, 75007 Paris\r\nContact: Damien Nouvel ( damien.nouvel@inalco.fr )\r\n\r\nRéférences :\r\n(Denis 2009) Denis, Pascal, Sagot, Benoît. Coupling an annotated corpus\r\nand a morphosyntactic lexicon for state-of-the-art POS tagging with less\r\nhuman effort. In Proceedings of PACLIC 2009, Hong-Kong, China, 2009.\r\n(Dumestre 2003) Dumestre, Gérard. Dumestre, Gérard. Grammaire\r\nfondamentale du bambara. Paris : Karthala, 2003.\r\n(Kilgarriff 2007) A. Kilgarriff, P. Rychly, P. Smrz, D. Tugwell. The\r\nSketch Engine. Lexicology: Critical concepts in Linguistics Hanks,\r\neditor.  Routledge, 2007.\r\n(Lafferty 2001) Lafferty, John D., McCallum, Andrew, Pereira, Fernando\r\nC.  N.. 2001. Conditional random fields: Probabilistic models for\r\nsegmenting and labeling sequence data. ICML, pp 282-289.\r\n(Maslinsky 2014) Maslinsky, Kirill. Daba: a model and tools for Manding\r\ncorpora. Traitement Automatique des Langues Naturelles, 2014.\r\n(Schmid 1995) Schmid, Helmut. Improvements in Part-of-Speech Tagging\r\nwith an Application to German. Proceedings of the ACL\r\nSIGDAT-Workshop. Dublin, Ireland. , 1995\r\n(Vydrine 2013) Vydrin, Valentin. Bamana Reference Corpus (BRC) Procedia\r\n- Social and Behavioral Sciences, 95:25 October 2013, pp. 75-80.\r\nhttp://www.sciencedirect.com/science/journal/18770428\r\n(Vydrine 2014) Vydrin, Valentin. Projet des corpus écrits des langues\r\nmanding : le bambara, le maninka. In : Mathieu Mangeot, Fatiha Sadat\r\n(éd.).  Actes de l\'atelier sur le traitement automatique des langues\r\nafricaines TALAf 2014. http://jibiki.univ-savoie.fr/~mangeot/TALAf/2014/'),
(245, '2015-01-05', 'CEA LIST', 'Palaiseau', 'Dans le cadre du projet ANR Asfalda, le laboratoire LVIC du CEA LIST\r\nétend son moteur de recherche crosslingue AMOSE pour lui donner des\r\ncapacités d\'indexation et de recherche exploitant des informations\r\nsémantiques issues d\'outils de Semantic Role Labeling.\r\n\r\nL\'objectif premier du stage sera d\'évaluer l\'impact de l\'intégration de\r\nla sémantique sur les résultats de recherche. Le second objectif sera\r\nd\'améliorer le moteur de recherche au vu des premiers résultats\r\nd\'évaluation.\r\n\r\nAMOSE est un moteur de recherche crosslingue. Il repose sur l\'analyseur\r\nlinguistique libre Lima [1] qui reconnaît les termes nominaux complexes\r\n(Multi Word Expressions ou MWE en anglais). Ces termes complexes repérés\r\ndans les documents et les requêtes sont utilisés pour grouper les\r\ndocuments résultats en classes d\'équivalence en fonction des termes de\r\nla requête qu\'ils contiennent.\r\n\r\nLIMA a récemment été enrichi d\'un module effectuant de l\'annotation en\r\nrôles sémantiques (Semantic Role Labeling) et nous sommes en train de\r\nmodifier AMOSE pour indexer et utiliser dans la recherche les classes\r\nrepérées et leurs rôles.\r\n\r\nLe travail du stagiaire consistera à évaluer la nouvelle version d\'AMOSE\r\nsur les campagnes d\'évaluation classiques (CLEF, TREC) dont le\r\nlaboratoire possède les données et à rechercher quelles campagnes plus\r\nciblées sur la recherche sémantique pourraient exister et mettre en\r\nouvre AMOSE sur leurs données. Si une telle campagne a lieu durant le\r\nstage, le laboratoire y participera.\r\n\r\nCes évaluations fourniront des informations permettant de mettre à jour\r\ndes pistes d\'amélioration. Le stagiaire les documentera et en mettra\r\ncertaines en oeuvre.\r\n\r\nLe stage, de 4 à 6 mois, s\'adresse à des étudiants de Master 2 Recherche\r\nen informatique ou informatique linguistique. Une bonne connaissance de\r\nLinux et des outils de base de manipulation de corpus (bash, sed, awk,\r\nperl, python, etc.) est indispensable ainsi qu\'au moins la capacité de\r\ncomprendre du code C++.\r\n\r\nLe stage se déroulera à Nano Innov, à Palaiseau, dans les locaux du CEA\r\nLIST.\r\n\r\nMots clés: recherche d\'information, évaluation, C++, Linux, corpus,\r\nannotations\r\n\r\n\r\n[1] https://github.com/aymara/lima/wiki\r\n\r\nGael de Chalendar\r\nCEA LIST\r\nLaboratoire Vision et Ingénierie des Contenus\r\n(Vision and Content Engineering Laboratory)\r\n\r\nCEA SACLAY - NANO INNOV\r\nBAT. 861\r\nPoint courier 173\r\n91191 GIF SUR YVETTE\r\n\r\nTél.:+33.1.69.08.01.50 Fax:+33.1.69.08.01.15 \r\nEmail : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr'),
(246, '2015-01-05', 'Prolipsia', 'Besançon', '*Offre de stage : Développeur web full stack H/F - Prolipsia*\r\n\r\nDébut du contrat : printemps 2015\r\nDurée : 3 à 6 mois\r\nRémunération : gratification légale\r\nLieu : Prolipsia -  18 rue Alain Savary - Besançon (25)\r\nContact : candidature[at]prolipsia.com\r\n\r\nSite : www.prolipsia.com\r\n\r\n==================================================\r\n\r\nProlipsia est une jeune entreprise innovante spécialisée dans le\r\ndéveloppement de solutions web d\'aide à la rédaction (basées sur une\r\nexpertise en Traitement Automatique du Langage et en Langues\r\nContrôlées).  Nous venons de mettre sur le marché CAPTILO\r\n(www.captilo.com), un service logiciel d\'analyse de textes qui :\r\n\r\n   1. identifie, dans les documents (protocoles, manuels, fiches\r\n      techniques, consignes, contrats, etc.) les obstacles à la\r\n      transmission d\'information : ambigüités, expressions complexes,\r\n      imprécisions, informations manquantes, etc. ;\r\n   2. guide le rédacteur dans la correction, via des explications,\r\n      conseils et exemples.\r\n\r\n\r\nUtiliser CAPTILO permet de :\r\n\r\n   - produire des documents de qualité, plus faciles à lire, comprendre,\r\n     appliquer, et moins coûteux à mettre à jour et à traduire ;\r\n\r\n   - optimiser transmission des connaissances, prise de décisions,\r\n     respect de consignes, gestion des risques, etc.\r\n\r\n\r\n*Nous sommes aujourd\'hui à la recherche d\'un(e) stagiaire motivé(e) pour\r\nparticiper au développement du produit.*\r\n\r\n\r\n==================================================\r\n*Descriptif du poste*\r\n==================================================\r\n\r\nVous intégrerez l\'équipe R&D de Prolipsia. Dans un environnement agile\r\net un esprit startup, vous participerez aux différentes phases\r\ntechniques successives d\'un des projets de l\'écosystème CAPTILO.\r\n\r\nSuivant vos compétences et vos souhaits, vos principales missions\r\npeuvent porter sur :\r\n\r\n   - la mise en place de nouvelles fonctionnalités de l\'application web\r\n     (AngularJS / Symfony2) ;\r\n\r\n   - la réalisation d\'addons CAPTILO pour les suites bureautiques Cloud,\r\n     les éditeurs de contenu web et clients (Javascript / Java / .NET) ;\r\n\r\n   - la consolidation et la modularisation de l\'architecture technique\r\n     (API REST, micro-services, Job queue, Docker, etc.).\r\n\r\nVos tâches incluront également la veille technologique et la proposition\r\nde solutions techniques.\r\n\r\n==================================================\r\n*Profil recherché*\r\n==================================================\r\n\r\nIssu(e) d\'une formation informatique de niveau bac+3/5, vous êtes\r\npassionné(e) par le développement web, à l\'aise sur un large panel de\r\nsujets techniques et vous savez faire preuve d\'initiative. Vous cherchez\r\nun stage impliquant des challenges techniques.\r\n\r\nVous :\r\n\r\n   - connaissez les concepts des architectures web ;\r\n   - avez expérimenté un ou plusieurs frameworks PHP ;\r\n   - possédez des connaissances en développement front-end (HTML5, CSS3,\r\n     frameworks JS) ;\r\n   - êtes sensible aux bonnes pratiques du développement logiciel et de\r\n     la POO.\r\n\r\nAutres points appréciés :\r\n\r\n   - Vous avez des notions de DevOps.\r\n   - Vous avez une sensibilité pour le design et UX.\r\n   - Vous êtes familier(ère) avec les outils de gestion de code comme\r\n     Git.\r\n   - Vous avez une première expérience de mise en oeuvre/développement\r\n     de projet concret.\r\n\r\n*Si certaines de ces compétences vous manquent mais que vous avez les\r\ncapacités et l\'envie d\'apprendre, adressez-nous votre candidature !*'),
(247, '2015-01-05', 'CS', 'Le Plessis-Robinson', 'Référence : DEF/LPR/N°9\r\n    Date de parution : 23/12/2014\r\n    Localisation : Le Plessis Robinson, France\r\n    Type de contrat : Stage\r\n    Métier : Autre\r\n    Secteur : Défense\r\n\r\nAvec 1700 collaborateurs pour un chiffre d\'affaires de 173 millions\r\nd\'euros, CS se positionne parmi les premières sociétés de services en\r\ninformatique en France et s\'affirme comme un concepteur, intégrateur\r\net opérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense,\r\naéronautique, spatial, énergie, transport, secteur public et\r\nfinance. CS réalise environ 80% de ses projets au forfait.\r\nCS est coté sur le marché Euronext Paris.\r\n\r\nMissions\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs doivent\r\nen permanence se former. CS a développé pour ce besoin un simulateur\r\ncontenant des pseudo-pilotes qui interagissent avec les contrôleurs à\r\ntravers des échanges vocaux.  Pour assurer la sécurité des vols, les\r\ndialogues contrôleurs-pilotes sont standardisés et forment un\r\nsous-langage. Dans notre simulateur, nous utilisons un système de\r\nreconnaissance vocale Nuance capable d\'apprendre la grammaire de ces\r\ndialogues, ce qui simplifie le travail de la reconnaissance et\r\naméliore les performances.\r\n\r\nNous souhaitons évaluer d\'autres solutions de reconnaissance vocale,\r\nen particulier Open Source, et les comparer à la solution Nuance.\r\n\r\nLes langues utilisées pour la reconnaissance de la parole seront le\r\nfrançais et / ou l\'anglais.\r\n\r\n\r\nDurée du stage : 4 à 6 mois\r\n\r\nProfil\r\n\r\nMaster 2 ou élève ingénieur 2e ou 3e année\r\n\r\nCompétences techniques: C/C++, bash, xslt.\r\n\r\nCompétences linguistiques: Anglais Technique\r\n\r\nCV + LM à envoyer à l\'adresse recrutement@c-s.fr à l\'attention de\r\nGariné KELIJIAN en précisant la référence DEF/LPR/N°9.'),
(248, '2015-01-12', 'Orange', 'Lannion', 'Stage : en Web sémantique\r\n\r\nNotre équipe dispose d\'une Base de Connaissances alimentée par des\r\nentités nommées (EN : personnes, lieux, organisations, etc.) du Linked\r\nOpen Data (dbpedia, freebase, geonames, etc.) et utilisée pour enrichir\r\nnos données pour l\'extraction d\'informations du texte écrit.  Dans le\r\ncadre de ce stage :\r\n\r\n- vous participez à la découverte des libellés de ces EN, notamment des\r\n  variantes non standards (exemple : Paris/Paname/Villes Lumières...)\r\n\r\n- vous participez à la découverte et à la correction des gentilés\r\n  (St. Brieuc à briochin(e)(s))\r\n\r\n- vous utilisez et adaptez des technologies de l\'équipe ou open source\r\n  pour le Traitement Automatique des Langues et les Bases de\r\n  Connaissances\r\n\r\n- vous examinez des données Linked Open Data\r\n\r\n- vous vérifiez des échantillons des données découvertes\r\n\r\n- vous collaborez avec les membres de l\'équipe\r\n\r\n\r\nEquipe d\'accueil :\r\nL\'équipe CONTENT/FAST d\'Orange Labs a en charge des travaux de recherche\r\net développement dans le domaine du Traitement Automatique des Langues\r\n(TAL) appliquée aux documents écrits et au texte issu du vocal (analyse\r\nsémantique, extraction d\'information, requêtes en langage naturel,\r\netc.), et dans le domaine des Bases de Connaissances.\r\n\r\n\r\nProfil :\r\n\r\nMaster 2 en Traitement Automatique des Langues ou Informatique\r\n\r\nContact : http://orange.jobs/jobs/offer.do?do=fiche&id=43952\r\nPlus d\'info : Johannes Heinecke (Johannes.heinecke(at)orange.com)\r\n\r\nStage rémunéré, à Lannion, d\'une durée de 5 mois à partir de mars ou\r\navril 2015.\r\n\r\nJohannes Heinecke\r\nIMT/OLPS/OPENSERV/CONTENT/FAST\r\ncomputational linguist/ingénieur de recherche TALN\r\ntél. +33 (0)2 96 07 21 77'),
(249, '2015-01-12', 'STL', 'Lille', 'Proposition de stage de niveau Master 2\r\n\r\nAnalyse de la communication entre les patients et les médecins\r\n\r\nhttp://natalia.grabar.perso.sfr.fr/stage-equ-2.html\r\n\r\ncontact : natalia.grabar@univ-lille3.fr\r\n\r\nLe domaine médical a une terminologie spécifique, avec des termes comme\r\npar exemple sanguin, abdominoplastie, hépatique, dermabrasion ou\r\nhépatoduodénostomie, utilisée communément par le personnel médical.\r\nPour cette raison entre autre, la compréhension d\'information de santé\r\nest souvent compliquée pour les non spécialistes et pour les patients\r\n(Patel et al., 2002; Williams et al., 1995; Rudd et al., 1999; Berland\r\net al., 2001). La disponibilité des informations de santé en ligne peut\r\naussi modifier le modèle de communication entre ces catégories de\r\npersonnes (Tran et al., 2009; Jucks & Bromme, 2007).\r\n\r\nL\'objectif de ce stage consiste à étudier la communication entre les\r\npatients et les médecins. Le matériel traité provient des forums de\r\ndiscussion et des données collectées dans un contexte clinique. Il\r\ns\'agit en particulier d\'exploiter des méthodes de Traitement Automatique\r\nde la Langue pour mener une étude contrastive des propos émis par ces\r\ndeux catégories de personnes (patients et médecins) dans un dialogue.\r\n\r\nPlus spécifiquement, il s\'agit des objectifs suivants:\r\n\r\n- travailler avec les propos produits par les patients et les médecins\r\n  (contexte clinique et de l\'internet)\r\n- exploiter et améliorer les annotations des documents avec différents\r\n  niveaux de spécificité\r\n- effectuer une analyse contrastive au sein de ces documents\r\n- établir un lexique avec les correspondances entre les termes savants\r\n  et les expressions des patients (méthode, analyse et lexique final)\r\n- si nécessaire, transcrire des conversations téléphoniques entre les\r\n  patients et les médecins\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n\r\n     connaissances en TAL et en linguistique\r\n     manipulation et test des outils de TAL\r\n     habitude de Linux\r\n     capacité de travailler en équipe et individuellement\r\n     lecture et analyse de la littérature scientifique\r\n\r\nLe stage est rémunéré.\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nNiveau: Master 2\r\nDurée: 6 mois\r\nLieu: Lille, Paris (éventuellement)\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à\r\nnatalia.grabar@univ-lille3.fr.\r\n\r\nRéférences:\r\n\r\n1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as\r\n   procedures : The case of pharmaceutical labels, International journal\r\n   of medical informatics, vol. 65(3), p. 193-211, 2002\r\n\r\n2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,\r\n   Nurss J., Inadequate functional health literacy among patients at two\r\n   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995\r\n\r\n3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and\r\n   Literacy, ch 5, 1999\r\n\r\n4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,\r\n   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn\r\n   E., Health information on the Internet. Accessibility, quality, and\r\n   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,\r\n   2001\r\n\r\n5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un\r\n   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,\r\n   vol. 53, p. 34-43, 2009\r\n\r\n6. Jucks R., Bromme R., Choice of words in doctor-patient communication:\r\n   an analysis of health-related internet sites, Health Commun,\r\n   vol. 21(3), p. 267-77, 2007'),
(250, '2015-01-12', 'STL', 'Arras', 'Proposition de stage de niveau L3/M1\r\n\r\nSujet : Transcription des conversations téléphoniques entre les médecins\r\net les patients\r\n\r\nhttp://natalia.grabar.perso.sfr.fr/stage-equ-1.html\r\n\r\ncontact : natalia.grabar@univ-lille3.fr\r\n\r\nLe domaine médical a une terminologie spécifique, avec des termes comme\r\npar exemple sanguin, abdominoplastie, hépatique, dermabrasion ou\r\nhépatoduodénostomie, utilisée communément par le personnel médical.\r\nPour cette raison entre autre, la compréhension d\'information de santé\r\nest souvent compliquée pour les non spécialistes et pour les patients\r\n(Patel et al., 2002; Williams et al., 1995; Rudd et al., 1999; Berland\r\net al., 2001). La disponibilité des informations de santé en ligne peut\r\naussi modifier le modèle de communication entre ces catégories de\r\npersonnes (Tran et al., 2009; Jucks & Bromme, 2007).\r\n\r\nL\'objectif de ce stage consiste à préparer les données pour l\'étude de\r\nla communication orale entre les médecins et les patients.\r\n\r\nPlus spécifiquement, il s\'agit des objectifs suivants:\r\n\r\n- transcrire des conversations téléphoniques entre les patients et les\r\n  médecins\r\n- utiliser un outil de transcription existant : Transcriber (Barras et\r\n  al., 1998)\r\n- garder les traces des émotions lors de la transcription\r\n- effectuer l\'anonymisation des conversations\r\n\r\nUn guide détaillé de transcription sera fourni.\r\n\r\nPrérequis:\r\n\r\n     connaissances en linguistique\r\n     manipulation d\'un outil\r\n     capacité de travailler en équipe et individuellement\r\n\r\nLe stage est rémunéré.\r\n\r\nNiveau: L3/M1\r\nDurée: 3 mois\r\nLieu: Arras\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts d\'un référent à\r\nnatalia.grabar@univ-lille3.fr.\r\n\r\nRéférences:\r\n\r\n1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as\r\n   procedures : The case of pharmaceutical labels, International journal\r\n   of medical informatics, vol. 65(3), p. 193-211, 2002\r\n\r\n2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,\r\n   Nurss J., Inadequate functional health literacy among patients at two\r\n   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995\r\n\r\n3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and\r\n   Literacy, ch 5, 1999\r\n\r\n4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,\r\n   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn\r\n   E., Health information on the Internet. Accessibility, quality, and\r\n   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,\r\n   2001\r\n\r\n5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un\r\n   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,\r\n   vol. 53, p. 34-43, 2009\r\n\r\n6. Jucks R., Bromme R., Choice of words in doctor-patient communication:\r\n   an analysis of health-related internet sites, Health Commun,\r\n   vol. 21(3), p. 267-77, 2007\r\n\r\n7. Barras C., Geoffrois E., Wu Z., Liberman M., Transcriber: a free tool\r\n   for segmenting, labeling and transcribing speech. In: Conference on\r\n   Language Resources and Evaluation (LREC).  1373-1376, 1998');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(251, '2015-01-15', 'LI', 'Blois', 'Proposition de stage de niveau Master 2\r\n\r\nSUJET : Résolution des co-références pour la recherche d\'information\r\ndans des corpus de langage parlé\r\n\r\nProposition de stage de recherche ou de fin d\'études en Informatique en\r\nvue de la réalisation d\'un système de résolution des coréférences, outil\r\nutile tant dans le champ de la recherche d\'information que pour le\r\ntraitement automatique des langues, d\'une durée minimale de 5 mois.\r\n\r\nLIEU D\'EXERCICE : Laboratoire LI, équipe BDTLN (Blois)\r\n\r\nCONTACT : Jean-Yves Antoine  (http://www.info.univ-tours.fr/%7Eantoine/)\r\n                             (Jean-Yves.Antoine@univ-tours.fr)\r\n  	  Anaïs Lefeuvre     (https://sites.google.com/site/nlplefeuvreanais/home)  \r\n                             (Anais.Lefeuvre@univ-tours.fr)\r\n\r\nCONTEXTE\r\n\r\nLe Laboratoire d\'Informatique de l\'Université de Tours, antenne de Blois\r\npropose un sujet de stage dans le cadre du projet industriel financé par\r\nla société BAMSOO et faisant suite à un projet (ANCOR) réalisé en\r\ncollaboration avec le Laboratoire Ligérien de Linguistique de\r\nl\'Université d\'Orléans,\r\n\r\nLe projet (ANCOR) a pour objet l\'étude de toutes les formes de reprises\r\nanaphoriques et de coéréférence dans une optique pluridisciplinaire\r\nautour de l\'étude de la langue orale. La recherche d\'information et le\r\ntraitement automatique des langues sont étroitement liés, les requêtes\r\nformulées par les utilisateurs ainsi que la représentation des\r\ninformations d\'un document textuel en langue naturelle dépendant\r\nprécisément de la qualité de modélisation des phénomènes\r\nlinguistiques. Les technologies de traitement de l\'oral sont à un\r\ntournant du point de vue de ces applications : la reconnaissance vocale\r\nest accessible à la totalité des consommateurs de smartphones (ex :\r\nSIRI), mais la recherche d\'information dans des documents sonores\r\nn\'intègre pour le moment que la musique par similarité entre requête et\r\nréponse (ex : Shazam). Dans ce projet, nous nous intéressons ainsi à la\r\nprise en compte de la langue orale transcrite sous forme de documents\r\nnumériques.\r\n\r\nUn second aspect important de notre sujet se focalise sur la\r\nreprésentation fine du contenu des documents plutôt que de se limiter à\r\nune approche sac de mots. Plusieurs étapes sont nécessaires pour obtenir\r\nune représentation pertinente et fidèle d\'un document. Une de ces étapes\r\nest la résolution d\'anaphore et de co-référence, qui fait précisément\r\nl\'objet de ce stage.\r\n\r\nOn appelle co-référence, et plus généralement anaphore, la relation\r\nentre deux items langagiers telle que l\'interprétation de l\'un dépend de\r\nl\'autre. Considérons l\'exemple :\r\n\r\n\"Zoe est venue à la fête avec Isa. Elle ne voulait pas venir seule\".\r\n\r\nNous sommes en présence d\'une anaphore pronominale entre le pronom\r\n\"elle\" et son antécédent \"Zoe\", relation qu\'un système doit détecter\r\npour interpréter correctement la seconde phrase. Cette tâche n\'est\r\njamais triviale : par exemple, dans ce cas, le système pourrait\r\nrattacher de manière erronée le pronom à \"Isa\", voire même au nom commun\r\n\"fête\". Le développement d\'outils performants de recherche d\'information\r\ndans des flux langagiers passe par une modélisation efficace de ces\r\nrelations anaphoriques et/ou de co-référence.\r\n  \r\nL\'importance de la résolution des anaphores a conduit à l\'émergence de\r\ntravaux qui ont fait l\'objet de multiples campagnes d\'évaluation\r\ninternationales (MUC, SemEval, ACE). Ces recherches portent toutefois\r\nmajoritairement sur les documents électroniques, la parole\r\nconversationnelle faisant surtout l\'objet de travaux sur l\'anaphore\r\npronominale. Le projet ANCOR a permis précisément l\'annotation d\'un\r\ncorpus d\'envergure (488 000 mots) du français oral (transcrit) annoté en\r\nco-référence et anaphores. Ce corpus a déjà permis l\'apprentissage de\r\nCROC, le premier système francophone de résolution des coréférences\r\ndéveloppé par le laboratoire LATTICE à Montrouge (CROC : Coreference\r\nResolution for Oral Corpus :\r\nhttp://issuu.com/sfleury/docs/adele-desoyer-memoire-tal-rb-1314/1).\r\n\r\nOBJECTIFS\r\n\r\nLe stage qui vous est proposé a pour ambition de compléter le travail\r\ndéjà réalisé suivant 3 axes :\r\n\r\n1) Achever la création d\'ANCORQI, un outil de requêtage du corpus ANCOR\r\n   (codé suivant un format XML spécifique) afin de permettre à des\r\n   chercheurs linguistes de pouvoir extraire des statistiques utiles sur\r\n   cette ressources linguistique de grande envergure\r\n\r\n2) Participer à la transformation du corpus ANCOR suivant différents\r\n   formats de représentations utilisés par la communauté scientifique du\r\n   Traitement des Langues Naturelles.\r\n\r\n   Ces deux premières phases seront a priori réalisées dans un langage\r\n   de script (Python) et ne mobiliseront donc a priori pas des\r\n   compétences informatiques complexes. Elles constituent toutefois une\r\n   très bonne manière de s\'imprégner de la problématique scientifique\r\n   étudiée avant de passer à la troisième et principale phase du projet\r\n\r\n3) le développement d\'un système de résolution des coréférences et de\r\n   son évaluation. Ce travail consistera à intégrer et adapter au\r\n   français la plate-forme de développement BART\r\n   (http://www.bart-anaphora.org/). BART est une plateforme modulaire et\r\n   hautement adaptable proposant implémentée en Java et permettant la\r\n   mise en oeuvre de différentes techniques d\'apprentissage pour la\r\n   résolution des coréférences. Ce toolkit distribué en open source\r\n   intègre pour cela une large variété de classifieurs, parmi lesquels\r\n   l\'algorithme standard C4.5 et plusieurs noyaux pour machines à\r\n   vecteur support (SVM). Il permet le développement de systèmes du\r\n   moment où l\'on dispose d\'un corpus d\'entrainement de taille\r\n   suffisante. Il intègre également des modules de prétraitement qui ont\r\n   permis le développement de systèmes pour l\'anglais, l\'allemand, le\r\n   polonais et l\'italien. Notre objectif est précisément d\'arriver au\r\n   développement d\'un système adapté au français par entrainement sur le\r\n   corpus ANCOR.\r\n\r\n\r\nTRAVAIL A REALISER\r\n\r\nLa personne recrutée sera en charge d\'adapter BART au français.\r\n\r\n- Phase n°1 (T0 - T0+2) - Finalisation de l\'outil ANCORQI et préparation\r\n  des données (réalisation et applications d\'utilitaires de\r\n  transformation XML pour préparer le corpus ANCOR aux formats de\r\n  traitement attendus). En parallèle, veille technologie sur le sujet et\r\n  prise en main de BART\r\n\r\n- Phase n°2 (T0+2- T0+5) - Adaptation effective de BART au français :\r\n  Intégration de composants, test sur corpus,  et motivation des\r\n  pipelines\r\n\r\n- Phase n°3 (T0+5- T0+6) - Évaluation du système  : évaluation et\r\n  comparaison au système CROC.\r\n\r\nCe travail sera réalisé dans un contexte collaboratif marqué :\r\n\r\n- Laboratoire Ligérien de Linguistique (LLL, Orléans) pour les deux\r\n  premières phases du projet,\r\n\r\n- Laboratoire LATTICE (ENS, Montrouge) pour la partie principale\r\n  consacrée à BART, qui sera comparé à CROC.\r\n\r\nLa personne recrutée pourra donc être amenée à participer à des réunions\r\nde recherche chez ces partenaires. En cas d\'avancée significative, ce\r\ntravail pourra par ailleurs conduire à la rédaction de publication\r\nscientifique si le ou la stagiaire est intéressé(e).\r\n\r\nPROFIL RECHERCHE\r\n\r\nLa personne recrutée sera en cycle terminal d\'études en informatique, de\r\nniveau Bac+5 (Master en Informatique). Un intérêt pour le Traitement\r\nAutomatique des Langues est apprécié, sans être un pré-requis à\r\nrecrutement. Capacités expertes de développement Java exigé. Dans le cas\r\nd\'un(e) étudiant(e) en Master Recherche, le sujet de stage pourra être\r\nadapté aux attentes de l\'étudiant.\r\n\r\nREMUNERATION\r\n\r\n436,05 ¤ par mois.\r\n\r\nDUREE DU STAGE ET LIEU D\'EXERCICE\r\n\r\nLa personne recrutée travaillera au sein du laboratoire LI, dans les\r\nlocaux de l\'IUT de Blois Jean-Jaurès. Il s\'intégrera dans l\'équipe de\r\nrecherche BDTLN\r\n(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) et plus\r\nprécisément l\'axe TLN de cette équipe (http://tln.li.univ-tours.fr/).\r\n\r\nLa durée minimale de stage sera de 5 mois, 6 mois appréciés\r\n\r\nDEPOT DE CANDIDATURE\r\n\r\nDépôt des candidatures : auprès de Anaïs Lefeuvre. Merci de déposer un\r\nCV détaillé de vos activités passées, accompagné d\'une lettre de\r\nmotivation et de vos relevés de notes des deux dernières années\r\nd\'études. Un développement Java sera demandé pour la sélection du\r\ncandidat.'),
(252, '2015-01-15', 'EDF', 'Paris', 'INTITULE DE LA MISSION : Réalisation d\'un modèle de catégorisation\r\nautomatique pour l\'analyse automatique d\'une question ouverte d\'enquête\r\nde satisfaction.\r\n\r\nDate de début : entre avril et juin 2015\r\n\r\nDurée du stage : 6 mois\r\n\r\nNiveau de diplôme préparé : MASTER 2 spécialisé en Ingénierie \r\nLinguistique / Traitement automatique des langues\r\n\r\nSERVICES D\'ACCUEIL : EDF - Direction Commerce\r\n\r\n- Tête de Direction :   oui        non\r\n- Direction : Domaine Analyse Connaissance Client\r\n- Département : Département Analyse Client et Publication (ACP)\r\n\r\n\r\nCONTEXTE ET DESCRIPTION DU STAGE\r\n\r\nDepuis le 1er juillet 2007, le marché de l\'électricité est entièrement\r\nouvert à la concurrence et permet au consommateur de choisir librement\r\nson fournisseur d\'énergie. Dans ce contexte, il est d\'autant plus\r\nimportant pour EDF de comprendre les besoins de ses clients, mais\r\négalement d\'expliquer et de prédire leur comportement.\r\nLe département Analyse Client et Publication (ACP) a pour mission\r\nd\'analyser les données provenant des différents systèmes d\'information\r\net notamment les données textuelles.\r\nActuellement, nous utilisons des techniques de Text Mining à travers les\r\noutils de Temis pour analyser automatiquement des commentaires provenant\r\nde nos SI mais également les réponses aux questions ouvertes d\'enquêtes\r\nde satisfaction.\r\nLe stage que nous proposons est opérationnel et a pour objectif la mise\r\nen place d\'un modèle d\'analyse automatique des réponses à des questions\r\nouvertes issues d\'enquêtes de satisfaction.\r\n\r\nPrésentation de la mission\r\nLa mission se composera de quatre étapes :\r\n\r\n- L\'exploration de corpus avec des outils de classifications\r\n  automatiques\r\n- La définition d\'un plan de catégorisation en lien avec les équipes\r\n  opérationnelles\r\n- L\'annotation de données \r\n- La création d\'un modèle de catégorisation et de règles d\'extraction de\r\n  connaissances\r\n\r\nPROFIL RECHERCHE :\r\n\r\n- De formation Master II spécialisé en Traitement Automatique du Langage\r\n\r\n- Domaines de compétence requis :\r\n  - Linguistique et informatique\r\n  - Des connaissances en statistique seraient appréciées\r\n\r\n- Rigueur, autonomie et aisance rédactionnelle. \r\n\r\n\r\n\r\nles candidatures sont à adresser à Anne-Laure GUENET :\r\nanne-laure.guenet@edf.fr\r\n\r\nAnne-Laure GUENET\r\nChef de projet Text Mining\r\nEDF- Commerce - DSI\r\nDomaine ACC - Département Analyses Clients et Publications\r\n20, place de la défense\r\nBureau 9P06\r\n92050 PARIS LA DEFENSE CEDEX\r\n \r\nanne-laure.guenet@edf.fr\r\nTél. : 01.56.65.22.87'),
(253, '2015-01-19', 'CEA-LIST', 'Palaiseau', 'Proposition de stage de master 2\r\n\r\nIdentifier dans les textes les entités d\'une base de connaissances\r\n\r\nCONTEXTE\r\nLe stage se situe dans le contexte de l\'extraction d\'information, dont\r\nl\'objectif est d\'extraire des informations précises à partir de textes\r\nnon structurés. Parmi les nombreuses applications de ce domaine, en\r\nparticulier en contexte de veille, beaucoup nécessitent l\'identification\r\net le typage d\'entités spécifiques dans les textes, et plus précisément,\r\nd\'entités nommées, comme les noms de lieux, d\'organisations, de\r\npersonnes etc.\r\nCette tâche est traditionnellement réalisée en s\'appuyant principalement\r\nsur la forme d\'expression de ces entités. Avec l\'existence de larges\r\nbases de connaissances telles que DBpedia ou FreeBase, une nouvelle\r\nfaçon d\'aborder ce problème a émergé : l\' Entity Linking, développée en\r\nparticulier sous l\'impulsion la campagne d\'évaluation TAC-KBP, a pour\r\nobjectif de faire lien entre des entités présentes a priori dans une\r\nbase de connaissances et la façon dont elles apparaissent dans les\r\ntextes.\r\n\r\nOBJECTIF\r\nL\'objectif du stage est de mettre en place une procédure\r\nd\'identification dans des textes d\'entités nommées présentes dans une\r\nbase de connaissances existante.  Cette procédure s\'appuiera sur les\r\ntravaux importants qui existent dans le domaine. On cherchera en\r\nparticulier à répondre aux problèmes suivants :\r\n\r\n- variabilité des entités : la même entité peut être présente sous de\r\n  nombreuses formes. Par exemple, Bush, président George Bush, George\r\n  W. Bush, George Walker Bush ou le 43ème président des Etat-Unis sont\r\n  toutes des mentions faisant référence à la même personne ;\r\n\r\n- ambiguïté des entités : plusieurs entités peuvent être exprimées avec\r\n  la même forme. Par exemple, la mention George Bush peut désigner aussi\r\n  bien le 43ème président américain que le 41ème, son père. Elle peut\r\n  aussi faire référence au porte-avion ou à l\'aéroport du même nom.\r\n\r\nPour le premier problème, on utilisera une combinaison d\'acquisition\r\nautomatique de ressources contenant des formes connues de différentes\r\nmentions pour les mêmes entités (par exemple à partir des liens entrants\r\nsur les pages Wikipédia, ou de l\'extraction de patrons exprimant cette\r\nrelation de reformulation), et d\'une mise en correspondance automatique\r\nde formes nouvelles par une mesure de similarité avec les formes\r\nexistantes.\r\nPour le second problème, on cherchera à développer une méthode de\r\nrattachement combinant des critères généraux, comme la popularité d\'une\r\nentité, et des critères locaux, comme une mesure de la similarité entre\r\nle contexte textuel qui entoure la mention considérée et le texte\r\ndéfinissant l\'entité visée.\r\nUne part du travail du stagiaire sera aussi d\'explorer l\'état de l\'art\r\ndes méthodes et logiciels existants pour ce type de tâche, en\r\nparticulier dans le cadre de la campagne d\'évaluation TAC-KBP.\r\n\r\nLe stagiaire pourra s\'appuyer sur la plate-forme d\'analyse linguistique\r\nLIMA (https://github.com/aymara/lima) développée par le LVIC et sur les\r\ntravaux réalisés par le laboratoire en matière d\'extraction\r\nd\'information.\r\n\r\nMODALITÉS\r\nLe stage sera rémunéré et se déroulera pour une durée de 6 mois au sein\r\ndu Laboratoire Vision et Ingénierie des Contenus (LVIC) du CEA LIST,\r\nsitué sur le centre d\'intégration Nano-Innov, à Palaiseau.\r\n\r\nLes candidats intéressés par ce stage sont invités à prendre contact\r\navec Romaric Besançon (romaric.besancon@cea.fr) en envoyant un CV et une\r\nlettre de motivation.'),
(254, '2015-01-19', 'Syllabs', 'Paris', '--------------------------------------------------------\r\nOffre de stage M2 TAL : Génération automatique de textes\r\n--------------------------------------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en génération\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse de\r\ndonnées textuelles du Web : identification des pages pertinentes,\r\nextraction et catégorisation des informations clés. La génération est\r\nproposée au travers de sa solution Data2Content (data2content.fr) qui\r\npermet, à partir d\'une base de données structurées, de générer\r\nautomatiquement des textes de qualité humaine.\r\n\r\nC\'est dans le cadre de Data2Content que nous recherchons des ingénieurs\r\nlinguistes pour un stage dans le domaine de la création automatique de\r\ntextes en anglais, français, espagnol, néerlandais, portugais, italien\r\net allemand.\r\nL\'objet principal du stage est de travailler sur le paramétrage de notre\r\noutil de génération (écriture de règles) dans votre langue\r\nmaternelle. Les domaines d\'application peuvent par exemple être le\r\ne-commerce (descriptifs de produits) ou encore le tourisme.\r\n\r\n--------------------\r\nDescription du poste\r\n--------------------\r\nLes tâches principales concernent: \r\n- Génération automatique de descriptifs de produits : paramétrage de\r\n  l\'outil de génération en fonction du projet, participation aux tests\r\n  et à l\'amélioration de l\'outil\r\n- Extraction d\'information : création de bases de données structurées à\r\n  partir de données non structurées\r\n- Ecriture de scripts pour la manipulation des bases de données\r\n\r\n---------------\r\nProfil souhaité\r\n--------------- \r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail en\r\n  équipe\r\n- Programmation en Python\r\n\r\n---------------------\r\nDiplôme et expérience\r\n---------------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou\r\n  similaire\r\n- Compétences en rédaction web seraient un plus\r\n\r\nDurée de stage : 6 mois\r\n\r\nContrat : stage conventionné rémunéré en fonction du niveau d\'étude +\r\nqtickets resto + remboursement à moitié du pass Navigo (transport)\r\n\r\nLieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris (métro\r\nRépublique)\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage génération « langue »», par\r\nexemple, « stage génération espagnol ».'),
(255, '2015-01-19', 'LIMSI', 'Orsay', 'Aide à la rédaction pour l\'adaptation de textes à différents profils de\r\nlecteurs\r\n\r\n\r\nniveau : M2, dernière année d\'école d\'ingénieur\r\ndomaine : informatique\r\npériode : à partir de mars-avril 2015\r\ndurée : 5-6 mois\r\nURL : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2-2015.html\r\n\r\n\r\nContexte\r\n\r\nL\'accès à l\'information est primordial pour tous et celle-ci passe\r\nsouvent par l\'écrit. Il existe néanmoins très souvent un décalage entre\r\nla manière de s\'exprimer du rédacteur et les capacités de compréhension\r\nde certains lecteurs. Tout lecteur peut se trouver en situation de\r\ndifficulté, par exemple lorsqu\'un niveau de technicité d\'un texte n\'est\r\npas le sien, ou que la langue utilisée est trop complexe. Les\r\ndifficultés ressenties peuvent à l\'extrême couper certaines personnes de\r\nl\'accès à des informations importantes. Par exemple, des porteurs de\r\nTrisomie 21 auront des difficultés à comprendre de nombreux textes qui\r\ncontiennent des informations qui les concernent mais qui n\'ont pas été\r\nconçus pour eux.\r\n\r\nIl en est ainsi de leur dossier médical : il est légalement obligatoire\r\nque celui-ci puisse être consulté et compris par le patient, mais il\r\ncontient des textes parfois rédigés dans une langue de spécialité ou\r\ndans un niveau de langue relativement élevé. Il est donc nécessaire\r\nd\'apporter des aides efficaces pour l\'aide à l\'accès à l\'information\r\npour ce type de situation. Toutefois, il serait souhaitable qu\'existe\r\nune version de ces textes multi-niveau adaptable à l\'ensemble des\r\nprofils de lecteurs potentiels.\r\n\r\nDans le cadre d\'un projet commun avec la Fédération Trisomie 21 France,\r\nle laboratoire LIMSI-CNRS s\'intéresse à la définition d\'un nouveau type\r\nde documents qui serait accessible à plusieurs profils de lecteurs,\r\ncouvrant par exemple une personne atteinte de Trisomie 21, ses aidants\r\net ses médecins. De nouveaux types d\'aides à la rédaction sont donc\r\nnécessaires : il doit s\'agir d\'aider un rédacteur à anticiper des\r\ndifficultés de lecture, et à proposer des variantes pour des fragments\r\nnon adaptés. Pour cela, un corpus de textes issus de dossiers patients\r\nest en cours d\'annotation en fragments difficiles ainsi qu\'en\r\nréécritures possibles. Les données ainsi collectées pourront servir à\r\n(1) la détection automatique de fragments potentiellement non adaptés à\r\ncertains profils de lecteurs, et à (2) l\'aide à l\'écriture de variantes\r\npour ces fragments.\r\n\r\n\r\nTravail à réaliser\r\n\r\nLe stage proposé visera à obtenir un module opérationnel de détection de\r\nfragments non adaptés, et à proposer si possible des réécritures\r\ncandidates adaptées. Il faudra tout d\'abord faire une étude\r\nbibliographique sur les domaines de la réécriture (interactive) de\r\ntextes, et notamment la simplification automatique. Une analyse de\r\ncorpus sera ensuite menée afin de comprendre les caractéristiques des\r\ntextes manipulés et proposer des indices susceptibles de guider les\r\ndécisions sur l\'adéquation des fragments de textes aux profils de\r\nlecteurs considérés.\r\n\r\nL\'acquisition de fragments difficiles et de réécritures candidates sera\r\nmenée de deux manières : (1) par collecte manuelle auprès de volontaires\r\nde la fédération Trisomie 21 France; (2) par acquisition automatique\r\nfondée en particulier sur le repérage de termes et de leurs variantes\r\ndans des textes adaptés à différents profils. La dernière étape aura\r\npour objectif de développer un module d\'apprentissage automatique pour\r\nl\'annotation de fragments de texte en fonction des profils adaptés, dont\r\nles prédictions pourront ensuite être utilisées pour suggérer des\r\nréécritures candidates, qui seront soit issues du dictionnaire construit\r\nmanuellement lors de la collecte d\'annotations (faible rappel, mais\r\nforte précision), soit générées automatiquement par des techniques de\r\nparaphrase (fort rappel, précision plus faible).\r\n\r\nCe travail, qui pourra être poursuivi par un travail de thèse, aura\r\ncomme perspective de permettre la lecture d\'un document riche en\r\neffectuant un parcours dans un graphe de formulations possibles, en\r\ns\'adaptant (sur le long terme) au profil particulier de chaque lecteur.\r\n\r\n\r\nProfil recherché\r\n\r\nEtudiant(e) niveau M2, connaissances solides en informatique.\r\nIntérêt pour les domaines du traitement automatique des langues, de la\r\nlinguistique de corpus, et de l\'apprentissage automatique.\r\n\r\n\r\nContact\r\n\r\nToute personne intéressée par le stage peut prendre contact avec :\r\n\r\nGabriel Illouz (gabriel.illouz@u-psud.fr)\r\nAurélien Max (aurelien.max@limsi.fr)\r\n\r\nen utilisant comme titre de message \"[Candidature] Aide à la rédaction\", \r\net en joignant : (a) un CV à jour, (b) les résultats du M1 ou équivalent \r\net ceux du M2 déjà connus, (c) une description relative à l\'intérêt pour \r\nle sujet proposé.\r\n\r\nLe stage aura lieu au LIMSI-CNRS (Orsay, RER ligne B) à partir de \r\nmars-avril 2015 pour une durée de 5-6 mois.'),
(256, '2015-01-19', 'LIPN', 'Villetaneuse', '*Repérage automatique des usages des lexies en corpus, appliqué aux\r\nlexies verbales du français*\r\n\r\n_*Contexte:*_\r\n\r\nLe stage se situe dans la problématique de repérage des usages en\r\ncorpus.  Une première approche, linguistique, des usages associe à\r\nchaque sens un ou des schémas lexico-syntaxiques, selon différents\r\nmodèles (par exemple FrameNet) et cherche à les décrire\r\nmanuellement. Mais cette approche se heurte aux limitations des\r\napproches manuelles et notamment le temps prohibitif de développement\r\ndes ressources. Une autre approche, computationnelle, issue de\r\nl\'hypothèse distributionnelle (Harris, 1954; Firth,1957), se base sur la\r\nrépétition des séquences (n-grams avec fenêtre variable) pour extraire\r\nles différentes séquences signifiantes, d\'une part, et en déduire des\r\nregroupements d\'emplois en utilisant des métriques diversifiées. Les\r\nmétriques permettant de classer les répétitions sont nombreuses (Ramish,\r\n2015). A partir de l\'hypothèse distributionnelle initiale, les\r\nchercheurs ont proposé un certain nombre d\'alternatives au simple calcul\r\nde séquences répétées, afin de repérer différents phénomènes\r\nlinguistiques liés au sens des lexies (Turney et Pantel, 2010; Baroni et\r\nal., 2010 ; Clark, 2015). Il existe un certain nombre d\'outils et de\r\nplatefomes développant ces calculs (Dissect, SemanticVectors, Word2vec,\r\nSketchEngine, R...).\r\n\r\n_*Sujet du stage:*_\r\n\r\nLe stage portera sur la problématique de l\'usage et de son repérage\r\nautomatique sur corpus, en limitant l\'étude à une centaine de lexies\r\nverbales du français.\r\n\r\nL\'objectif du stage est :\r\n\r\n- de maîtriser la littérature TAL issue de l\'hypothèse\r\n  distributionnelle;\r\n\r\n- d\'utiliser les outils existants pour effectuer des calculs de n-grams\r\n  sur gros corpus du français, au niveau des formes, des informations\r\n  morphosyntaxiques, syntaxiques et d\'une combinaison de ces\r\n  informations;\r\n\r\n- tester différentes mesures permettant d\'affiner le comptage brut ;\r\n\r\n- aboutir, pour les cent lexies données, à des \"usages\" ;\r\n\r\n- de proposer différentes solutions afin d\'améliorer l\'existant et\r\n  d\'approcher du modèle plus linguistique de schéma\r\n  syntactico-sémantique.\r\n\r\n\r\nLieu : LIPN équipe RCLN, CNRS UMR 7130, Université Paris 13\r\n\r\nEncadrants: E. Cartier (Univ. Paris 13, LIPN-RCLN)\r\n\r\n\r\n_*Profil du candidat:*_\r\n\r\n- Master 2 TAL ou école d\'ingénieur en informatique ou TAL\r\n\r\n- bonnes compétences en programmation et en manipulation d\'outils de\r\n  TAL, notamment numériques (outils de la linguistique de corpus,\r\n  mesures de similarité...)\r\n\r\n- bonnes compétences en linguistique générale\r\n\r\nDurée du stage : 6 mois, à partir de mars 2015\r\n\r\nRémunération réglementaire\r\n\r\n\r\nLes candidatures doivent être envoyées par mail à\r\n\r\nemmanuel.cartier@lipn.univ-paris13.fr avant le 15 février 2015.\r\n\r\nMerci d\'envoyer un dossier contenant un cv, une lettre de motivation +\r\nautre(s) document(s) si jugé pertinent.\r\n\r\n\r\n_*Bibliographie indicative :*_\r\n\r\nBaroni, M., and Lenci A. (2010) \"Distributional Memory: A General\r\nFramework for Corpus-Based Semantics,\" /Computational Linguistics/, 36-4\r\n(2010), 50\r\n\r\nClark S. (2015) \"Vector Space Models of Lexical Meaning\", To appear in\r\nWiley-Blackwell /Handbook of Contemporary Semantics - second edition/,\r\nedited by Shalom Lappin and Chris Fox\r\n\r\nFirth, J. R. (1957). A synopsis of linguistic theory 1930-1955. In\r\n/Studies in Linguistic Analysis/, pp. 1-32. Blackwell, Oxford.\r\n\r\nHarris, Z. 1954. Distributional structure. /Word/, 10(2-3):1456-1162.\r\n\r\nKilgarriff, A., Rychly, P., Smrz, P., and Tugwell, D. (2004) The Sketch\r\nEngine. In: Williams G. and S. Vessier (eds.), /Proceedings of the XI\r\nEuralex International Congress/, July 6-10, 2004, Lorient, France, pp.\r\n105-111.\r\n\r\nRamisch C. (2015), \"Multiword Expressions Acquisition: A Generic and\r\nOpen Framework\", /Theory and Applications of Natural Language\r\nProcessing/series XIV, Springer, ISBN 978-3-319-09206-5, 230 p., 2015.\r\n\r\nTurney P. and Pantel P. (2010) \"From Frequency to Meaning: Vector Space\r\nModels of Semantics\". /Journal of Artificial Intelligence Research\r\n(JAIR)/, 37(1):141-188. AI Access Foundation.'),
(257, '2015-01-21', 'LIRMM', 'Montpellier', 'Stage de Master 2 Pro ou Recherche : Visualisation de trajectoires de patients\r\n\r\nLaboratoire : LIRMM  http://www.lirmm.fr/\r\nEquipe : ADVANSE http://www.lirmm.fr/recherche/equipes/advanse\r\nLieu du stage : Montpellier\r\n\r\nContexte\r\nLe Programme de médicalisation des systèmes d\'information (PMSI) est un\r\ndispositif faisant partie de la réforme du système de santé français\r\nayant pour but de mesurer l\'activité et les ressources des\r\nétablissements de soins. Ces derniers doivent renseigner des\r\ninformations quantifiées et standardisées sur les activités des\r\nprofessionnels de santé et son financés en retour. Dans le cadre d\'une\r\ncollaboration avec le CHU de Nimes, nous extrayons des trajectoires de\r\npatients à partir d\'une telle base.\r\n\r\nMission\r\nL\'objectif de ce stage est d\'extraire ces trajectoires (fouille de\r\ndonnées) et de définir des visualisations et des interactions pour\r\nfaciliter l\'interprétation des professionnels de la santé.  \r\nLe prototype de visualisation qui devra être mis en place sera basé sur\r\nla bibliothèque D3 (http://d3js.org/). Le candidat devra avoir une bonne\r\nconnaissance des langages Web (et en particulier de JavaScript). Dans\r\nl\'idéal, il aura aussi déjà manipulé la bibliothèque D3 et aura quelques\r\nconnaissances dans le domaine du dessin de graphes.\r\n\r\nCompétences\r\n- Fouille de données\r\n- JavaScript\r\n- Langage Web\r\n- Idéalement bibliothèque D3\r\n\r\nContacts\r\n- Jérôme Azé : jerome.aze@lirmm.fr\r\n- Sandra Bringay : sandra.bringay@lirmm.fr\r\n- Jessica Pinaire : jessica.pinaire@chu-nimes.fr'),
(258, '2015-01-28', 'CLLE', 'Toulouse', 'Proposition de stages en linguistique \"Annotations de l\'occitan\"\r\n\r\n- Descriptif : dans le cadre du projet RESTAURE soutenu par l\'Agence\r\n        Nationale de la Recherche, nous développons des outils de\r\n        Traitement Automatique de l\'Occitan, en particulier un OCR\r\n        (logiciel de reconnaissance de caractères) et un analyseur\r\n        morpho-syntaxique, dont les premières phases nécessitent\r\n        l\'annotation de textes par des linguistes\r\n\r\n- Niveau d\'études et discipline : L3 ou M1 en Linguistique, Sciences\r\n  du Langage ou Occitan\r\n\r\n- Durée : de 1 à 4 mois (possibilité mi-temps)\r\n\r\n- Rémunération : environ 500 euros par mois (à temps plein)\r\n\r\n- Période : avril-septembre 2015\r\n\r\n- Lieu : laboratoire CLLE-ERSS, Maison de la recherche, Université\r\n  Toulouse 2\r\n\r\n- Compétences en langue occitane (au moins compréhension), en\r\n  linguistique (au moins en morphologie et syntaxe), capacités travail\r\n  en équipe\r\n\r\n- Encadrement : Marianne Vergez-Couret, Myriam Bras, CLLE-ERSS\r\n\r\n- Candidature : envoyer CV + lettre motivation à myriam.bras@univ-tlse2.fr, vergez@univ-tlse2.fr'),
(259, '2015-01-29', 'INRA', 'Jouy-en-Josas', 'Offre de stage recherche Master 2 informatique ou 3ème année ingénieur\r\n\r\nAnnotation sémantique fine de textes par clustering\r\n\r\nNiveau : Master 2 informatique ou 3ème année ingénieur\r\nDate de début : mars, avril 2015\r\nDurée : 4-6 mois\r\nMots clefs: *informatique, apprentissage automatique non supervisé*, \r\nontologie, sémantique distributionnelle, traitement automatique de la\r\nlangue\r\n\r\nContexte :\r\n\r\nL\'annotation sémantique fine de textes identifie et catégorise\r\nautomatiquement des termes dans des documents par des concepts\r\nd\'ontologies de grandes tailles. Elle est utilisée par les moteurs de\r\nrecherche sémantique, les outils d\'extraction d\'information et\r\nQuestion-Réponse et par les méthodes de peuplement, de révision et\r\nd\'alignement d\'ontologies. Les équipes de recherche en informatique\r\nMaIAGE-Inra et LaHDAK-LRI développent des méthodes de modélisation de\r\nconnaissance à partir d\'ontologies multiples par alignement et à partir\r\nde textes pour l\'acquisition de connaissance. L\'objectif du stage est de\r\ndévelopper une méthode de sémantique distributionnelle appliquée au\r\ntexte pour (1) annoter sémantiquement des textes et (2) aligner des\r\nontologies en utilisant le texte.\r\n\r\nObjectif :\r\n\r\nL\'approche proposée pour le stage est d\'utiliser la sémantique\r\ndistributionnelle pour calculer une similarité sémantique entre les\r\ntermes à étiqueter et les concepts de l\'ontologie. La sémantique\r\ndistributionnelle regroupe par clustering les termes sémantiquement\r\nproches en fonction de leur contexte d\'apparition dans le texte. Deux\r\nvoies seront explorées pour obtenir des distances pertinentes. Tout\r\nd\'abord, les contextes des termes seront décrits par les dépendances\r\nsyntaxiques locales. Ensuite, pour que les classes sémantiques soient\r\ninterprétables à la lumière de la structure a priori des ontologies, une\r\nméthode de clustering semi-supervisé, comme celle de Lemaire &\r\nCornuejols [Ismaili et al., 2014] permettra de (1) guider la formation\r\ndes classes à l\'aide de la connaissance des ontologies pour qu\'elles\r\nsoient faciles à intégrer dans les ontologies et (2) d\'expliquer les\r\nclasses formées pour qu\'elles soient utilisables pour une éventuelle\r\nrévision de l\'ontologie. Le stage sera réalisé en collaboration avec\r\nl\'unité Inra MIA Paris (Antoine Cornuéjols et Juliette Dibie).\r\n\r\nExemple : \"[..] /endophytic bacteria isolated from roots of coastal sand\r\ndune plants/ [..]\"\r\n--> Le terme \"/coastal sand dune plants/\" doit être associé à la\r\ncatégorie \"/plant/\".\r\n\r\nDonnées et logiciels :\r\nLes données utilisées pour évaluer la méthode seront celles du domaine\r\ndes biotopes microbiens, développées par l\'équipe Bibliome. Les méthodes\r\nseront intégrées dans la suite AlvisNLP de l\'équipe. Elles contribueront\r\nà la préparation des données de la prochaine édition de la tâche BioNLP\r\nShared Task Bacteria Biotope.\r\n\r\nLieu : Unité MaIAGE, centre de recherche INRA, Jouy-en-Josas\r\n\r\nFinancement : Financement Labex DiGiCosme\r\n\r\nEncadrants : Claire Nédellec, Equipe Bibliome, unité INRA MaIAGE\r\n(http://bibliome.jouy.inra.fr) et Brigitte Safar, Equipe LahDAK, LRI,\r\nUniversité Paris-Sud (http://lahdak.lri.fr)\r\n\r\nContact : Merci d\'envoyer un CV et une lettre de motivation à\r\nclaire.nedellec[at]jouy.inra.fr et/ou brigitte.safar[at]lri.fr.\r\n\r\n\r\nRéférences :\r\n\r\nRobert Bossy, Wiktoria Golik, Zorana Ratkovic, Dialekti Valsamou,\r\nPhilippe Bessières, Claire Nédellec. An Overview of the Gene Regulation\r\nNetwork and the Bacteria Biotope Tasks in BioNLP\'13. BMC Bioinformatics,\r\nà paraître en 2015.\r\nGolik W., Warnier P., Nédellec C. \"Corpus-based extension of\r\ntermino-ontology by linguistic analysis: a use case in biomedical event\r\nextraction. \" Ontology and Lexicon: new insights. Actes du workshop TIA\r\n2011 : 9th International Conference on Terminology and Artificial\r\nIntelligence, M. Slodzian et al., (eds), Paris, novembre 2011.\r\nF. Hamdi, B. Safar, N. Niraula, C. Reynaud, TaxoMap alignment and\r\nrefinement modules: Results for OAEI 2010, Ontology Alignment Evaluation\r\nInitiative (OAEI) 2010 Campaign - ISWC Ontology Matching Workshop,\r\nShanghai International Convention Center, Shanghai, Chine, 7 novembre,\r\n2010.\r\nOumaima Alaoui Ismaili, Vincent Lemaire, and Antoine Cornuéjols. A\r\nSupervised Methodology to Measure the Variables Contribution to a\r\nClustering. C.K. Loo et al. (Eds.): ICONIP 2014, (21th International\r\nConference on Neural Information Processing), Kuching, Malaisie, Part I,\r\nLNCS 8834, pp. 159-166, Springer 2014.\r\nV. Lemaire, O. Allaoui and A. Cornuéjols, \"Supervised pretreatments are\r\nuseful for supervised clustering\", in Proc. of the Second Conf. on Data\r\nAnalysis (ECDA-2014), Breme, Allemagne, Juillet, 2014.'),
(260, '2015-02-02', 'LIMSI & CEA', NULL, 'Offre de stage recherche Master 2 informatique\r\n\r\nCombinaison de mÃ©thodes distributionnelle et d\'extraction terminologique\r\npour l\'adaptation de ressources terminologiques\r\n\r\nNiveau : Master 2 informatique \r\nDate de dÃ©but : avril, mai 2015\r\nDurÃ©e : 4-6 mois\r\n\r\nMots clefs: extraction terminologique, ressources linguistiques,\r\nmÃ©thodes distributionnelles\r\n\r\nContexte :\r\nL\'extraction d\'information mise en oeuvre sur des textes de spÃ©cialitÃ©\r\n(articles scientifiques biomÃ©dicaux, dossiers patients, textes de loi,\r\netc.) s\'appuie sur des corpus annotÃ©s fournissant des exemples d\'entitÃ©s\r\nÃ  retrouver. Pour amÃ©liorer leur couverture sur de nouveaux textes, il\r\nest possible d\'utiliser des ressources terminologiques recensant les\r\ntermes du domaine du corpus et des informations sÃ©mantiques associÃ©es\r\n[2, 7]. Cependant, ces ressources ne sont pas suffisantes [1, 6] et\r\nnÃ©cessitent un important travail d\'adaptation au corpus et aux types\r\nsÃ©mantiques des entitÃ©s devant Ãªtre identifiÃ©es. Pour rÃ©pondre Ã  cette\r\nphase de constitution de ressources adaptÃ©es, il est envisageable\r\nd\'exploiter des mÃ©thodes d\'extraction de termes et d\'analyse\r\ndistributionnelle [3, 4].\r\n\r\nObjectif :\r\nL\'objectif du stage est de proposer une approche visant Ã  combiner une\r\nmÃ©thode d\'extraction de termes avec une approche distributionnelle pour\r\nconstituer une ressource adaptÃ©e au corpus, associant des termes\r\nextraits automatiquement et des informations sÃ©mantiques correspondant\r\naux types des entitÃ©s sÃ©mantiques visÃ©es. L\'analyse des regroupements\r\ndistributionnels sera Ã©galement le moyen d\'identifier les termes pouvant\r\nÃªtre polysÃ©miques.\r\nLes contextes distributionnels exploitÃ©s pourront avoir des natures\r\ndiverses (fenÃªtres graphique [+/- n mots avant et aprÃ¨s un mot central],\r\nfenÃªtres syntaxiques [chemins partagÃ©s dans le graphe de dÃ©pendance] ou\r\nencore rÃ´les sÌemantiques issus d\'un systÃ¨me de SRL). Ils permettront de\r\nrapprocher des termes ou des schÃ©mas de termes prÃ©sentant des\r\nsimilaritÃ©s non immÃ©diatement explicites.  L\'apport de diffÃ©rentes\r\nreprÃ©sentations sÃ©mantiques dans un contexte distributionnel sera\r\nÃ©galement Ã©valuÃ©. Ces reprÃ©sentations sÃ©mantiques pourront Ãªtre des\r\nontologies ou bases de connaissances du domaine (UMLS dans le domaine\r\nmÌedical par exemple) ou des bases de connaissances plus gÃ©nÃ©rales\r\n(typiquement le rÃ©seau lexical WordNet).\r\nLes traitements linguistiques seront effectuÃ©s Ã  l\'aide des outils\r\ndisponibles dans les deux laboratoires (analyseur linguistique libre\r\nLIMA [5], extracteur de termes YaTeA [8], etc.).\r\n\r\nL\'Ã©valuation de l\'approche sera rÃ©alisÃ©e dans plusieurs langues\r\n(notamment anglais et franÃ§ais), et s\'appuiera sur des corpus\r\ndisponibles comme les corpus biomÃ©dicaux (I2B2, SemEval, Clef-eHealth).\r\n\r\nUne poursuite en thÃ¨se pourra Ãªtre envisagÃ©e en fonction de l\'obtention\r\nd\'un financement.\r\n\r\nLieu : dans l\'un ou l\'autre des laboratoires des encadrants, situÃ©s Ã \r\n       2 km l\'un de l\'autre,\r\nLIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann, Orsay\r\nou\r\nCEA LIST, LVIC, Centre d\'intÃ©gration Nano-INNOV, av. de la Vauve,\r\nPalaiseau\r\n\r\nFinancement : Financement Labex DiGiCosme\r\n              Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.\r\n\r\nEncadrants : Thierry Hamon (LIMSI/CNRS) et GaÃ«l de Chalendar (CEA LIST)\r\n\r\nProfil du candidat:\r\nLe stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 2\r\ninformatique.\r\n- IntÌerÃªt pour le TAL\r\n- Connaissance (ou sensibilisation)\r\n  - des mÃ©thodes d\'acquisition terminologiques\r\n  - des mÃ©thodes d\'analyse distributionnelle\r\n- Utilisation habituelle de Linux\r\n- GoÃ»t pour la recherche et l\'expÃ©rimentation\r\n\r\nContact : Merci d\'envoyer un CV, une lettre de motivation, les notes\r\n          de Master et les coordonnÃ©es de rÃ©fÃ©rents \r\n          Ã  thierry.hamon at limsi.fr et gael.de-chalendar@cea.fr\r\n          avant le 21 fÃ©vrier 2015\r\n\r\nRÃ©fÃ©rences :\r\n\r\n[1] Olivier Bodenreider, Thomas C. Rindflesch, and Anita\r\n    Burgun. Unsupervised, corpus-based method for extending a biomedical\r\n    terminology. In Workshop on Natural Language Processing in the\r\n    Biomedical Domain (ACL2002), pages 53-60, 2002.\r\n[2] Kevin Bretonnel Cohen and Dina Demner-Fushman. Biomedical Natural\r\n    Language Processing. John Benjamins publishing company, 2013.\r\n[3] James R. Curran. From distributional to semantic similarity. Phd\r\n    thesis, University of Edinburgh, 2004.\r\n[4] R. Grishman and Y. He. An information extraction customizer. In\r\n    P. Sojka et al., editor, Proceeedings of the conference Text, Speech\r\n    and Dialogue, number 8655 in LNAI, pages 3-10, 2014.\r\n[5] https://github.com/aymara/lima/wiki\r\n[6] Alexa T. McCray, Allen C. Browne, and Olivier Bodenreider. The\r\n    lexical properties of the gene ontology (GO). In Proceedings of the\r\n    AMIA 2002 Annual Symposium, pages 504-508, 2002.\r\n[7] S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and\r\n    J. F. Hurdle. Extracting information from textual documents in the\r\n    electronic health record: a review of recent research. IMIA Yearbook\r\n    of Medical Informatics, 42(5):923-936, 2008.\r\n[8] http://search.cpan.org/~thhamon/Lingua-YaTeA/'),
(261, '2015-02-04', 'MoDyCo', 'Nanterre', '*Proposition de stage\r\n\r\nTitre : *Construction d\'une chaine de traitements linguistiques pour la\r\nstructuration de textes non structurés\r\n\r\n*Contexte : *La \"mémoire\" est l\'un des lieux où semble se jouer le lien\r\nsocial contemporain. Nouvelle question sociale, elle constitue une\r\ncomposante officielle de l\'action municipale dans la plupart des grandes\r\nmétropoles. Qui posent ce que, dans leur diversité, l\'ensemble des\r\nacteurs qualifie de \"questions mémorielles\" ? De quels types de\r\nrégulation politique et de rapports sociaux ces \"questions mémorielles\"\r\nsont-elles la manifestation ? Comment et avec quels mots sont-elles\r\nformulées ? Ces interrogations sont à l\'origine du projet de recherche\r\n\"médiation de l\'histoire locale\" rattaché au labex \"Les passés dans le\r\nprésent\" (http://www.passes-present.eu). Il est piloté par Sarah\r\nGensburger de l\'Institut de Sciences politiques\r\n(http://isp.cnrs.fr/?GENSBURGER-Sarah) et le laboratoire Modyco de\r\nl\'université Paris-Ouest Nanterre La défense (www.modyco.fr) y collabore\r\npour tout ce qui touche aux traitements de corpus.\r\n\r\n*Objectif : *Pour avoir des éléments de réponse aux questions posées\r\nci-dessus, la construction d\'une base de données des annonces des\r\nassociations loi 1901, créées depuis 1947, parmi lesquelles se trouvent\r\nles associations qui s\'intéressent à la \"mémoire\" est requise. En fait,\r\nle Journal Officiel détient les archives de toutes ces déclarations qui\r\nsont disponibles sous divers formats, dont un format text brut des pages\r\nscannées puis océrisées de 1960 à 1984 et un format xml qui suit une DTD\r\ncommune pour la période de 1997 à 2014.\r\n\r\n*Travail à réaliser*\r\n\r\nPour constituer cette BD, il faudra :\r\n\r\n- construire une chaîne de traitements linguistiques permettant\r\n  d\'extraire de chaque page \"océrisée\" et de chaque annonce (environ 25\r\n  annonces par page), les données utiles à la constitution d\'une base de\r\n  données à des fins d\'analyse avec des outils de TDM (Text and data\r\n  mining).\r\n\r\n- construire une chaîne de traitements pour détecter des erreurs\r\n  générées par l\'OCR\r\n\r\n- construire une chaîne de traitement permettant d\'intégrer les fichiers\r\n  xml à cette base de données\r\n\r\nUne fois la base de données créée, il faudra développer une interface\r\nd\'interrogation pour extraire de cette BD, des déclarations\r\nd\'associations répondant à divers critères (dates, domiciliation des\r\nassociations, requêtes booléennes sur l\'objet des associations, etc.),\r\nconvertir les résultats extraits en fichier au format CSV\r\n\r\n*Qualifications requises*\r\n\r\n- Connaissances des techniques du TAL\r\n\r\n- Compétences informatiques : au moins un langage de programmation (PHP,\r\n  Java, Python), XML, bases de données\r\n\r\n*Modalités de recrutement*\r\n- Type de contrat : Stage\r\n- Durée : 3 à 4 mois à temps plein\r\n- Rémunération : à hauteur de 600¤ euros par mois\r\n- Date de prise de fonction : le plus tôt possible\r\n- Lieu : Université Paris-Ouest La Défense, laboratoire Modyco (200, \r\n  avenue de la République, Batiment A, 92 Nanterre)\r\n\r\n*Procédure de recrutement*\r\nLe dossier de candidature est à envoyer avant le 20 février 2015 à\r\nMathilde de Saint Leger (mdesaintleger at u-paris10.fr) Ce dossier\r\ncomprendra : un curriculum vitae détaillé et une lettre de motivation.\r\nPour toute précision, les candidats sont invités s\'ils le souhaitent, à\r\nprendre contact au préalable avec Mathilde de Saint Leger (mdesaintleger\r\nat u-paris10.fr) ou Sarah Gensburger (sgensburger at yahoo.fr)\r\n\r\nMathilde de Saint Leger'),
(262, '2015-02-10', 'Lattice', 'Paris', '======================================================================\r\nVisualisation d\'informations extraites de corpus sous forme de graphes\r\n======================================================================\r\n\r\n* Descriptif rapide\r\n-----------------------\r\n\r\nLe LATTICE propose un stage dans le domaine des humanités numériques. On\r\ndispose aujourd\'hui d\'outils efficaces pour analyser les corpus et en\r\nextraire l\'information pertinente. On peut ainsi repérer les entités\r\nnommées et les liens entre entités, puis produire des graphes à partir\r\ndes résultats de cette analyse. Cependant, les graphes obtenus sont\r\nfréquemment peu lisibles, voire carrément inexploitables, du fait de la\r\nmasse d\'informations à représenter. Le stage porte justement sur\r\nl\'amélioration de la visualisation, ainsi que sur l\'élaboration de\r\nnouvelles méthodes de filtrage des données en fonction des besoins des\r\nutilisateurs. On envisagera par exemple des représentations « à\r\nprofondeur variable » (ou « multi-échelle »), où des informations plus\r\nprécises peuvent apparaître dynamiquement en fonction des demandes des\r\nutilisateurs.\r\n\r\nLe domaine d\'application est celui des humanités numériques, et on\r\ntravaillera de manière privilégiée sur des corpus de sociologie et/ou de\r\nsciences politiques, en français et/ou en anglais.\r\n\r\nLe stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à\r\n10 mn du métro Mairie de Montrouge et à 5 mn de l\'arrêt du Tram ligne 3\r\n« Jean Moulin »).\r\n\r\nLe stage est prévu pour une durée de 4 à 6 mois à compter de mars ou\r\navril 2015. Il donnera obligatoirement lieu à la signature d\'une\r\nconvention de stage et sera rémunéré suivant les règles en vigueur.\r\n\r\n* Profil recherché \r\n-----------------------\r\n\r\n- Formation en informatique ou traitement automatique des langues (M2,\r\n  école d\'ingénieur, éventuellement M1 avec une bonne expérience de la\r\n  programmation)\r\n- Bonne connaissance de python ou, à défaut, de perl\r\n- Intérêt pour le traitement automatique des langues\r\n- Bon niveau d\'anglais (écrit / oral)\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation\r\nà thierry.poibeau@ens.fr'),
(263, '2015-02-10', 'Lattice', 'Paris', '========================================================================\r\nAnalyse de corpus littéraire au moyen d\'outils de traitement automatique\r\ndes langues\r\n========================================================================\r\n\r\n* Descriptif rapide\r\n-----------------------\r\n\r\nOn dispose aujourd\'hui de plus en plus de corpus numérisés, y compris\r\ndans des domaines littéraires ou philosophiques. Les outils de\r\ntraitement des langues permettent de les étudier sous différents\r\naspects, thématiques, rhétoriques ou stylistiques par exemple, sans que\r\nl\'apport des outils existants soit encore bien connu. Le stage visera à\r\nidentifier des outils pertinents pour la tâche, examiner leurs résultats\r\net voir comment ils font sens pour des experts du domaine\r\nconsidéré. Plusieurs corpus sont possibles : on déterminera au début du\r\nstage lequel semble le plus intéressant, en fonction des collaborations\r\nen cours au sein de l\'Ecole normale supérieure.\r\n\r\nLe stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à\r\n10 mn du métro Mairie de Montrouge et à 5 mn de l\'arrêt du Tram ligne 3\r\n« Jean Moulin »).\r\n\r\nLe stage est prévu pour une durée de 4 à 6 mois à compter de mars ou\r\navril 2015. Il donnera obligatoirement lieu à la signature d\'une\r\nconvention de stage et sera rémunéré suivant les règles en vigueur.\r\n\r\n* Profil recherché \r\n-----------------------\r\n\r\n- Formation en traitement automatique des langues (M2, éventuellement M1\r\n  avec une expérience de la programmation)\r\n- Bonne connaissance de python ou, à défaut, de perl\r\n- Intérêt pour le traitement automatique des langues\r\n- Bon niveau d\'anglais (écrit / oral)\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation\r\nà thierry.poibeau@ens.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(264, '2015-02-10', 'Lattice', 'Paris', '========================================================================\r\nStage sur les réseaux de neurones pour le traitement automatique des\r\nlangues\r\n========================================================================\r\n\r\n* Descriptif rapide\r\n-----------------------\r\n\r\nLe LATTICE, en collaboration avec l\'IRIT, propose un stage de niveau M2\r\nsur l\'analyse des paramètres d\'un modèle de réseau de neurones appliqué\r\nà l\'acquisition de restrictions de sélection. Un descriptif détaillé en\r\nanglais figure ci-dessous.\r\n\r\nLe stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à\r\n10 mn du métro Mairie de Montrouge et à 5 mn de l\'arrêt du Tram ligne 3\r\n« Jean Moulin »). Il sera co-encadré par Thierry Poibeau et Marco\r\nDinarelli au LATTICE et par Tim van de Cruys à l\'IRIT (les échanges avec\r\nToulouse se feront principalement par Skype).\r\n\r\nLe stage est prévu pour une durée de 6 mois à compter de mars ou avril\r\n2015. Il donnera obligatoirement lieu à la signature d\'une convention de\r\nstage et sera rémunéré suivant les règles en vigueur.\r\n\r\n* Profil recherché \r\n-----------------------\r\n\r\n- Formation en informatique ou traitement automatique des langues (M2,\r\n  école d\'ingénieur, éventuellement M1 avec une bonne expérience de la\r\n  programmation)\r\n- Bonne connaissance de python ou, à défaut, de perl\r\n- Intérêt pour le traitement automatique des langues\r\n- Bon niveau d\'anglais (écrit / oral)\r\n- Des connaissances en matière de réseau de neurones seraient évidement\r\n  un plus\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation\r\nà thierry.poibeau@ens.fr\r\n\r\n\r\n* Descriptif détaillé\r\n-----------------------\r\n\r\n\r\nAn Exploration of a Neural Network Model\'s Parameters for Selectional\r\nPreference Acquisition\r\n\r\nPredicates often have a semantically motivated preference for particular\r\narguments [1]. Compare for example the sentences in (1) and (2).\r\n\r\n(1) The vocalist sings a ballad.\r\n(2) The exception sings a tomato.\r\n\r\nWhile both sentences are grammatically correct, the second sentence is\r\nclearly ill-formed. This preference of a verb for particular arguments\r\nis known as the verb\'s selectional preference. Recently, a neural\r\nnetwork approach has been shown to perform well on the modeling of\r\nselectional preferences [2]. However, many parameters remain to be\r\ninvestigated. First of all, a neural network\'s parameters may be\r\ninitialized in a number of different ways. For example, the parameters\r\nmight be initialized randomly, or they may be initialized using\r\npreviously constructed word embeddings. Secondly, the neural network\'s\r\narchitecture leaves ample space for experiments. The neural network\'s\r\narchitecture might be more `deep\' or more `shallow\', the size of the\r\nnetwork\'s layers may be varied, and certain parameters within the\r\nnetwork might be shared.\r\n\r\nThis internship will investigate the influence of different network\r\nparameters on the performance of a neural network for the modeling of\r\nselectional preferences. The student will adapt and train an existing\r\nneural network implementation for selectional preference acquisition,\r\nand examine the role of various model parameters for the network\'s\r\nperformance.\r\n\r\nReferences:\r\n\r\n[1] Van de Cruys, Tim ; Rimell, Laura ; Poibeau, Thierry and Korhonen,\r\nAnna. 2012. Multi-way Tensor Factorization for Unsupervised Lexical\r\nAcquisition. In Proceedings of the 24th International Conference on\r\nComputational Linguistics (COLING), Mumbai, India.\r\n\r\n[2] Van de Cruys, Tim. 2014. A Neural Network Approach to Selectional\r\nPreference Acquisition. In Proceedings of the 2014 Conference on\r\nEmpirical Methods in Natural Language Processing (EMNLP), pp. 26-35,\r\nDoha, Qatar. Association for Computational Linguistics.'),
(265, '2015-02-10', 'LIMSI', 'Orsay', '------------------------------------------------------------------------\r\n\r\n2 offres de stages recherche TAL ukrainien, Master 1 ou 2\r\ninformatique ou linguistique informatique\r\n\r\n - Etiquetage morpho-syntaxique de l\'ukrainien\r\n - Extraction de termes Ã  partir de textes ukrainiens\r\n\r\n------------------------------------------------------------------------\r\n\r\nSujet: Etiquetage morpho-syntaxique de l\'ukrainien\r\n\r\nOffre de stage recherche Master 1 ou 2 informatique ou linguistique\r\ninformatique\r\n\r\nNiveau : Master 1 ou 2 informatique ou linguistique informatique\r\nDate de dÃ©but : avril, mai 2015\r\nDurÃ©e : 5 mois\r\n\r\nMots clefs : Ukrainien, Ã‰tiquetage morpho-syntaxique, langue peu dotÃ©e,\r\nCRF, Traitement Automatique des Langues\r\n\r\nContexte : Ce stage se situe dans le contexte d\'un projet de\r\ndÃ©veloppement d\'outils de Traitement Automatique de la Langue\r\nukrainienne.\r\n\r\nDu point de vue du TAL, l\'ukrainien est une langue peu dotÃ©e.  Ainsi,\r\nil existe trÃ¨s peu de travaux de TAL ou de ressources linguistiques\r\nsur cette langue: le jeu d\'Ã©tiquettes morpho-syntaxiques Multex-East\r\n[1] a intÃ©grÃ© l\'ukrainien en 2010 [2] ; un Ã©tiqueteur\r\nmorpho-syntaxique Ã  base de rÃ¨gles et de dictionnaires (UGtag) a Ã©tÃ©\r\nmis au point mais sans que la dÃ©sambiguÃ¯sation des Ã©tiquettes soit\r\nrÃ©alisÃ©e [3]; une mÃ©thode de reconnaissance des entitÃ©s nommÃ©es a Ã©tÃ©\r\nproposÃ©e [4] ; un corpus parallÃ¨le polonais-ukrainien a Ã©tÃ© constituÃ© [5].\r\n\r\n\r\nObjectif : L\'objectif du stage est de dÃ©velopper un Ã©tiqueteur\r\nmorpho-syntaxique dans une premier temps pour la langue gÃ©nÃ©rale, puis\r\npour les langues de spÃ©cialitÃ©, aprÃ¨s adaptation au domaine visÃ©.\r\n\r\nLa mÃ©thodologie d\'Ã©tiquetage morpho-syntaxique mise en oeuvre devra tenir\r\ncompte des particularitÃ©s de l\'ukrainien. En effet, comme les autres\r\nlangues slaves, il s\'agit d\'une langue morphologiquement riche : les\r\ninformations flexionnelles jouent un rÃ´le important tandis que la\r\nmorphologie dÃ©rivationnelle et compositionnelle est trÃ¨s frÃ©quente dans\r\nla formation des constructions grammaticales (par exemple, aspect,\r\ntemps) et lexicales. De plus, bien que l\'ordre canonique des phrases\r\nsoit sujet-verbe-objet (SVO), Ã©tant une langue Ã  cas, l\'ukrainien\r\nautorise un ordre des mots assez libre sans introduire pour autant\r\nd\'effets stylistiques particuliers.  Ces particularitÃ©s, communes Ã  la\r\nplupart des langues slaves, peuvent entraÃ®ner des difficultÃ©s pour les\r\nmÃ©thodes classiques d\'Ã©tiquetage.\r\n\r\nLa mise au point de l\'Ã©tiqueteur morpho-syntaxique de l\'ukrainien pourra\r\nconduire Ã  la dÃ©finition de modÃ¨les CRF Ã  travers le logiciel Wapiti [6]\r\net en utilisant les informations fournies par UGtag [3]. Cependant, elle\r\npourra Ã©galement s\'appuyer sur les travaux existants dans des langues\r\nproches telles que le tchÃ¨que [7] ou le polonais [8]. De mÃªme, la faible\r\nquantitÃ© de ressources disponibles ou de corpus annotÃ©s doit conduit Ã \r\ns\'inspirer des mÃ©thodes d\'Ã©tiquetage morpho-syntaxique dÃ©jÃ  proposÃ©es\r\npour des langues peu dotÃ©es, notamment en utilisant l\'existant (UGtag),\r\nen sÃ©lectionnant les exemples nÃ©cessaires Ã  l\'apprentissage du modÃ¨le\r\n[9,10,11] ou en utilisant des mÃ©thodes de transfert [12].\r\n\r\nLa mÃ©thode sera mise en oeuvre et Ã©valuÃ©e sur un corpus composÃ© de textes\r\nde la littÃ©rature ukrainienne et des collections de documents issus des\r\ndomaines de spÃ©cialitÃ© comme l\'informatique et la mÃ©decine.  Le stage\r\nbÃ©nÃ©ficiera de collaborations existantes avec des chercheurs en TAL\r\nparlant l\'ukrainien.\r\n\r\nLieu : LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann,\r\n       Orsay\r\n\r\nFinancement : Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.\r\n\r\nEncadrants : Thierry Hamon et Thomas Lavergne (LIMSI/CNRS)\r\n\r\nProfil du candidat:\r\nLe stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 1 ou 2\r\ninformatique ou linguistique informatique.\r\n\r\n- IntÃ©rÃªt pour le TAL\r\n- Connaissance (ou sensibilisation)\r\n  - des mÃ©thodes d\'Ã©tiquetage morpho-syntaxique\r\n  - des mÃ©thodes d\'apprentissage automatique\r\n- Connaissance de l\'ukrainien\r\n- Utilisation habituelle de Linux\r\n- GoÃ»t pour la recherche et l\'expÃ©rimentation\r\n\r\nContact : Merci d\'envoyer un CV, une lettre de motivation, les notes de\r\n          Master et les coordonnÃ©es de rÃ©fÃ©rents Ã  thierry.hamon at\r\n          limsi.fr et lavergne at limsi.fr avant le 21 fÃ©vrier 2015\r\n\r\nRÃ©fÃ©rences :\r\n\r\n[1] http://nl.ijs.si/ME/V4/\r\n\r\n[2] Erjavec (TomaÅ¾). -- MULTEXT-East: Morphosyntactic Resources for\r\n  Central and Eastern European Languages. Language Resources and\r\n  Evaluation, vol. 46 (1), 2012, pp. 131--142.\r\n\r\n[3] Kotsyba (Natalia), Mykulyak (Andriy) et Shevchenko (Ihor V.). --\r\n  UGTag: morphological analyzer and tagger for the Ukrainian language.\r\n  In: Proceedings of the international conference Practical Applications\r\n  in Language and Computers (PALC 2009).\r\n\r\n[4] Katrenko (Sophia) et Adriaans (Pieter). -- Named Entity Recognition\r\n  for Ukrainian: A Resource-Light Approach.  In: Proceedings of the\r\n  Workshop on Balto-Slavonic Natural Language Processing. pp. 88--93. --\r\n  Prague, Czech Republic, June 2007.\r\n\r\n[5] http://www.domeczek.pl/~polukr/\r\n\r\n[6] Lavergne (Thomas), Cappe (Olivier) et Yvon (Francois). -- Practical\r\n  Very Large Scale CRFs. In: Proceedings the 48th Annual Meeting of the\r\n  Association for Computational Linguistics (ACL). pp. 504--513. --\r\n  Association for Computational Linguistics.  http://wapiti.limsi.fr\r\n\r\n[7] Collins (Michael), Hajic (Jan), Ramshaw (Lance) et Tillmann\r\n  (Christoph). -- A Statistical Parser for Czech. In: Proceedings of the\r\n  37th Annual Meeting of the Association for Computational\r\n  Linguistics. pp.  505--512. -- College Park, Maryland, USA, June 1999.\r\n\r\n[8] [KobyliÅ„ski 2013]Kobylieski2013 KobyliÅ„ski (Åukasz). -- Improving\r\n  the Accuracy of Polish POS Tagging by Using Voting Ensembles. In:\r\n  Proceedings of the 6th Language Technology Conference: Human Language\r\n  Technologies as a Challenge for Computer Science and Linguistics,\r\n  ed. par Vetulani (Zygmunt). pp. 453--456.  -- PoznaÅ„, Poland, 2013.\r\n\r\n[9] Goldberg (Yoav), Adler (Meni) et Elhadad (Michael). -- EM Can Find\r\n  Pretty Good HMM POS-Taggers (When Given a Good Start). In: Proceedings\r\n  of ACL-08: HLT. pp. 746--754. -- Columbus, Ohio, June 2008.\r\n\r\n[10] Garrette (Dan), Mielens (Jason) et Baldridge (Jason). -- Real-World\r\n  Semi-Supervised Learning of POS-Taggers for Low-Resource\r\n  Languages. In: Proceedings of the 51st Annual Meeting of the\r\n  Association for Computational Linguistics (Volume 1: Long Papers). pp.\r\n  583--592. -- Sofia, Bulgaria, August 2013.\r\n\r\n[11] Duong (Long), Cohn (Trevor), Verspoor (Karin), Bird (Steven) et\r\n  Cook (Paul). -- What Can We Get From 1000 Tokens? A Case Study of\r\n  Multilingual POS Tagging For Resource-Poor Languages. In: Proceedings\r\n  of the 2014 Conference on Empirical Methods in Natural Language\r\n  Processing (EMNLP).  pp. 886--897. -- Doha, Qatar, October 2014.\r\n\r\n[12] Yarowsky (David), Ngai (Grace), Wicentowski (Richard). -- Inducing\r\n  Multilingual Text Analysis Tools via Robust Projection across Aligned\r\n  Corpora. In: Proceedings of the First International Conference on\r\n  Human Language Technology Research, HLT\'01, pages 1-8. -- Stroudsburg,\r\n  PA, USA.\r\n\r\n------------------------------------------------------------------------\r\n\r\nSujet: Extraction de termes Ã  partir de textes ukrainiens\r\n\r\nOffre de stage recherche Master 1 ou 2 informatique ou linguistique\r\ninformatique\r\n\r\nNiveau : Master 1 ou 2 informatique ou linguistique informatique\r\nDate de dÃ©but : avril, mai 2015\r\nDurÃ©e : 5 mois\r\n\r\nMots clefs : Ukrainien, Extraction de termes, langue peu dotÃ©e,\r\nTerminologie, Traitement Automatique des Langues\r\n\r\nContexte : Ce stage se situe dans le contexte d\'un projet de\r\ndÃ©veloppement d\'outils de Traitement Automatique de la Langue\r\nukrainienne.\r\n\r\nDu point de vue du TAL, l\'ukrainien est une langue peu dotÃ©e.  Ainsi, il\r\nexiste trÃ¨s peu de travaux de TAL ou de ressources linguistiques sur\r\ncette langue: le jeu d\'Ã©tiquettes morpho-syntaxiques Multex-East [1] a\r\nintÃ©grÃ© l\'ukrainien en 2010 [2] ; un Ã©tiqueteur morpho-syntaxique Ã  base\r\nde rÃ¨gles et de dictionnaires (UGtag) a Ã©tÃ© mis au point mais sans que\r\nla dÃ©sambiguÃ¯sation des Ã©tiquettes soit rÃ©alisÃ©e [3]; une mÃ©thode de\r\nreconnaissance des entitÃ©s nommÃ©es a Ã©tÃ© proposÃ©e [4] ; un corpus\r\nparallÃ¨le polonais-ukrainien a Ã©tÃ© constituÃ© [5].\r\n\r\n\r\nObjectif : L\'objectif du stage est de dÃ©velopper une extracteur de\r\ntermes pour des textes de spÃ©cialitÃ© rÃ©digÃ©s en ukrainien dans la\r\nperspective de la constitution de terminologie et de la fouille de\r\ntextes de spÃ©cialitÃ© [6].\r\n\r\nLa mise au point de l\'approche pour l\'extraction de termes pourra\r\ns\'appuyer sur des travaux en extraction terminologique [7] ou plus\r\nfondamentaux portant sur la terminologie en ukrainien [8,9]. Elle\r\nconduira Ã  la dÃ©finition de rÃ¨gles pouvant Ãªtre intÃ©grÃ©es dans\r\nl\'extracteur YaTeA [10] tout en tenant compte des particularitÃ©s de\r\nl\'ukrainien : comme les autres langues slaves, il s\'agit d\'une langue\r\nmorphologiquement riche ; les informatiques flexionnelles jouent un rÃ´le\r\nimportant tandis que la morphologie dÃ©rivationnelle et compositionnelle\r\nest trÃ¨s frÃ©quente.  Dans la mesure du possible, on envisagera\r\nd\'utiliser des mÃ©thodes d\'apprentissage notamment pour produire\r\nautomatiquement des rÃ¨gles d\'identification ou pour effectuer une\r\nadaptation de l\'extracteur au domaine.\r\n\r\nLa mÃ©thode sera mise en oeuvre et Ã©valuÃ©e sur un corpus de textes issus\r\ndes domaines de spÃ©cialitÃ© comme l\'informatique et la mÃ©decine.  Les\r\ntextes auront Ã©tÃ© Ã©tiquetÃ©s avec UGtag.  Le stage bÃ©nÃ©ficiera de\r\ncollaborations existantes avec des chercheurs en TAL parlant\r\nl\'ukrainien.\r\n\r\n\r\nLieu : LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann,\r\n       Orsay\r\n\r\nFinancement : Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.\r\n\r\nEncadrants : Thierry Hamon et Thomas Lavergne (LIMSI/CNRS)\r\n\r\nProfil du candidat:\r\nLe stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 1 ou 2\r\ninformatique ou linguistique informatique.\r\n\r\n- IntÃ©rÃªt pour le TAL\r\n- Connaissance (ou sensibilisation) des mÃ©thodes d\'acquisition\r\n  terminologiques\r\n- Connaissance de l\'ukrainien\r\n- Utilisation habituelle de Linux\r\n- GoÃ»t pour la recherche et l\'expÃ©rimentation\r\n\r\nContact : Merci d\'envoyer un CV, une lettre de motivation, les notes\r\n          de Master et les coordonnÃ©es de rÃ©fÃ©rents\r\n          Ã  thierry.hamon at limsi.fr et lavergne at limsi.fr\r\n          avant le 21 fÃ©vrier 2015\r\n\r\nRÃ©fÃ©rences :\r\n\r\n[1] http://nl.ijs.si/ME/V4/\r\n\r\n[2] Erjavec (TomaÅ¾). -- MULTEXT-East: Morphosyntactic Resources for\r\n  Central and Eastern European Languages. Language Resources and\r\n  Evaluation, vol. 46 (1), 2012, pp. 131--142.\r\n\r\n[3] Kotsyba (Natalia), Mykulyak (Andriy) et Shevchenko (Ihor V.). --\r\n  UGTag: morphological analyzer and tagger for the Ukrainian language.\r\n  In: Proceedings of the international conference Practical Applications\r\n  in Language and Computers (PALC 2009).\r\n\r\n[4] Katrenko (Sophia) et Adriaans (Pieter). -- Named Entity Recognition\r\n  for Ukrainian: A Resource-Light Approach.  In: Proceedings of the\r\n  Workshop on Balto-Slavonic Natural Language Processing. pp. 88--93. --\r\n  Prague, Czech Republic, June 2007.\r\n\r\n[5] http://www.domeczek.pl/~polukr/\r\n\r\n[6] Meystre (S. M.), Savova (G. K.), Kipper-Schuler (K. C.) et Hurdle\r\n  (J. F.). - Extracting information from textual documents in the\r\n  electronic health record : a review of recent research. IMIA Yearbook\r\n  of Medical Informatics, vol. 42 (5), 2008, p. 923-936.\r\n\r\n[7] Pazienza (MariaTeresa), Pennacchiotti (Marco) et Zanzotto\r\n  (FabioMassimo). - Terminology Extraction : An Analysis of Linguistic\r\n  and Statistical Approaches. In : Knowledge Mining, Ed. par Sir-\r\n  makessis (Spiros), pp. 255-279. - Springer Berlin Heidelberg, 2005.\r\n\r\n[8] Shyshkina (Nataliia), Zorko (Galina) et Lesko (Larisa). --\r\n  Terminology Work and Software Localization in Ukraine. In: The Third\r\n  International Conference Problems of Cybernetics and Informatics,\r\n  pp. 17--20. -- Baku, Azerbaijan, 2010.\r\n\r\n[9] Mentynska (Iryna). -- Lexical and genetic characteristics of modern\r\n  computer terminology, 2014.\r\n\r\n[10] Aubin (Sophie), Hamon (Thierry). -- Improving Term Extraction with\r\n  Terminological Resources. In Advances in Natural Language Processing\r\n  (5th International Conference on NLP, FinTAL 2006). pp. 380-387. LNAI\r\n  4139. Turku, Finland, August 2006.\r\n  http://search.cpan.org/~thhamon/Lingua-YaTeA'),
(266, '2015-02-12', 'LIA', 'Avignon', 'Stage recherche M2 : ModÃ¨les connexionnistes pour la gÃ©nÃ©ration\r\nautomatique dans le cadre de l\'interaction vocale\r\n\r\nDurÃ©e : 5 mois\r\nDÃ©marrage : le plus tÃ´t possible\r\nLieu : Laboratoire Informatique d\'Avignon\r\nEncadrants: Bassam Jabaian, StÃ©phane Huet et Fabrice LefÃ¨vre\r\n\r\nDescription du stage :\r\nLes systÃ¨mes d\'interactions vocales utilisÃ©s dans des applications comme\r\nla rÃ©servation de billets d\'avion ou d\'hÃ´tels, ou bien encore le\r\ndialogue avec un robot, font intervenir plusieurs composants. Parmi\r\nceux-ci figurent le module de gÃ©nÃ©ration de texte qui produit la rÃ©ponse\r\ndu systÃ¨me en langue naturelle Ã  partir d\'une reprÃ©sentation sÃ©mantique\r\ninterne crÃ©Ã©e par le gestionnaire de dialogue.\r\n\r\nLes systÃ¨mes de dialogue actuels intÃ¨grent des modules de gÃ©nÃ©ration\r\nbasÃ©s sur des rÃ¨gles Ã©crites Ã  la main Ã  partir de patrons.  ex :\r\nconfirm(type=$U, food=$W,drinks=dontcare) â†’ Let me confirm, you are\r\nlooking for a $U serving $W food and any kind of drinks right ?\r\n\r\nCes modules gagneraient Ã  se baser sur des mÃ©thodes d\'apprentissage\r\nautomatique afin de faciliter la portabilitÃ© des systÃ¨mes de dialogue\r\nvers d\'autres tÃ¢ches et amÃ©liorer la diversitÃ© des Ã©changes gÃ©nÃ©rÃ©s.\r\nParmi les mÃ©thodes d\'apprentissage automatique, figurent les rÃ©seaux de\r\nneurones qui ont vu un regain d\'intÃ©rÃªt depuis l\'utilisation du Â« /deep\r\nlearning/ Â». Ces rÃ©seaux de neurones ont dÃ©jÃ  Ã©tÃ© employÃ©s par Google\r\ndans une tÃ¢che similaire de gÃ©nÃ©ration de description d\'images\r\n(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html).\r\nL\'objectif de ce stage est d\'Ã©tudier l\'utilisation de ces modÃ¨les dans\r\nle cadre de l\'interaction vocale.\r\n\r\nSi un intÃ©rÃªt pour l\'apprentissage automatique et le traitement de la\r\nlangue naturelle est souhaitable, il est attendu surtout du stagiaire de\r\nbonnes capacitÃ©s en dÃ©veloppement logiciel.\r\n\r\nPour candidater : envoyer un mail avec un CV et une lettre de motivation\r\nÃ  bassam.jabaian@univ-avignon.fr'),
(267, '2015-02-12', 'Sinequa', 'Paris', '*Offre de stage chez Sinequa*\r\n\r\nSinequa (www.sinequa.com) propose une plateforme logicielle de Search et\r\nd\'Analyse du Big Data en temps réel aux entreprises du Fortune Global\r\n2000. Capitalisant sur 25 années d\'expérience en recherche linguistique,\r\nla puissance de la technologie Sinequa repose sur l\'analyse\r\nlinguistique, sémantique et statistique qui permet aux grandes\r\nentreprises et organisations d\'apprivoiser la complexité de leurs\r\ndonnées, structurées ou non structurées.\r\n\r\n\r\nSinequa cherche un/une stagiaire pour travailler sur la langue\r\nportugaise, essentiellement l\'extraction de concepts (groupes nominaux\r\ncourts) puis l\'extraction d\'entités nommées en cas de stage plus\r\nlong. Le travail se déroulera au siège de l\'entreprise à Paris pour une\r\ndurée de 3 à 6 mois durant le printemps et/ou l\'été 2015.\r\n\r\n\r\n::Compétences demandées::\r\n\r\n- Profil : Etudes de linguistique ou linguistique-informatique ou cursus\r\n  avec mention TAL\r\n\r\n- Langues : Excellente maîtrise du portugais et du français et/ou\r\n  l\'anglais\r\n\r\n- Connaissances en Recherche d\'information et Extraction d\'Entités\r\n  Nommées appréciées\r\n\r\n\r\nContact: Aurélia Marcus, marcus@sinequa.com'),
(268, '2015-02-12', 'Sinequa', 'Paris', '*Offre de stage chez Sinequa*\r\n\r\nSinequa (www.sinequa.com) propose une plateforme logicielle de Search et\r\nd\'Analyse du Big Data en temps réel aux entreprises du Fortune Global\r\n2000. Capitalisant sur 25 années d\'expérience en recherche linguistique,\r\nla puissance de la technologie Sinequa repose sur l\'analyse\r\nlinguistique, sémantique et statistique qui permet aux grandes\r\nentreprises et organisations d\'apprivoiser la complexité de leurs\r\ndonnées, structurées ou non structurées.\r\n\r\n\r\nSinequa cherche un/une stagiaire pour travailler sur la langue\r\nportugaise, essentiellement l\'extraction de concepts (groupes nominaux\r\ncourts) puis l\'extraction d\'entités nommées en cas de stage plus\r\nlong. Le travail se déroulera au siège de l\'entreprise à Paris pour une\r\ndurée de 3 à 6 mois durant le printemps et/ou l\'été 2015.\r\n\r\n\r\n::Compétences demandées::\r\n\r\n- Profil : Etudes de linguistique ou linguistique-informatique ou cursus\r\n  avec mention TAL\r\n\r\n- Langues : Excellente maîtrise du portugais et du français et/ou\r\n  l\'anglais\r\n\r\n- Connaissances en Recherche d\'information et Extraction d\'Entités\r\n  Nommées appréciées\r\n\r\n\r\nContact: Aurélia Marcus, marcus@sinequa.com\r\n\r\n---------------\r\n\r\n[Stage] Thaï - [Internship] Thai\r\n\r\n\r\n[English version follows]\r\n\r\n\r\nOffre de stage chez Sinequa\r\n\r\nSinequa (www.sinequa.com) propose une plateforme logicielle de Search et\r\nd\'Analyse du Big Data en temps réel aux entreprises du Fortune Global\r\n2000. Capitalisant sur 25 années d\'expérience en recherche linguistique,\r\nla puissance de la technologie Sinequa repose sur l\'analyse\r\nlinguistique, sémantique et statistique qui permet aux grandes\r\nentreprises et organisations d\'apprivoiser la complexité de leurs\r\ndonnées, structurées ou non structurées.\r\n\r\n\r\nSinequa cherche un/une stagiaire pour travailler sur la langue thaï,\r\nessentiellement la segmentation en phrases et mots. Le travail se\r\ndéroulera au siège de l\'entreprise à Paris pour une durée de 3 à 6 mois\r\ndurant le printemps et/ou l\'été 2015.\r\n\r\n\r\n::Compétences demandées::\r\n\r\n- Profil : Etudes de linguistique ou linguistique-informatique ou cursus\r\n  avec mention TAL\r\n\r\n- Langues : Excellente maîtrise du thaï et du français et/ou l\'anglais\r\n\r\n- Connaissances en morphosyntaxe\r\n\r\nContact: Aurélia Marcus, marcus@sinequa.com'),
(269, '2015-02-12', 'LORIA', 'Nancy', '=====================================\r\n\r\nOffre de stage de M2 :\r\n\r\nLieu : LORIA, Ã©quipe SÃ©magramme (INRIA, CNRS, U. de Lorraine), Nancy\r\n\r\nEncadrants : Maxime Amblard (UL) et Sylvain Pogodalla (INRIA)\r\n\r\nSujet : Grammaires CatÃ©gorielles Abstraites Ã  large couverture et\r\n	ingÃ©nierie grammaticale\r\n\r\nDurÃ©e : 6 mois\r\n\r\nContrat : stage conventionnÃ© rÃ©munÃ©rÃ©\r\n=======================================\r\n(version pdf : http://semagramme.loria.fr/lib/exe/fetch.php?media=projects:sujet-polymnie.pdf)\r\n\r\nLes Grammaires CatÃ©gorielles Abstraites (ACG) sont un formalisme dÃ©diÃ© Ã \r\nla description de la syntaxe et de la sÃ©mantique des langues\r\nnaturelles. FondÃ©es sur le fragment implicatif de la logique linÃ©aire,\r\nelles manipulent des Î»-termes linÃ©aires qui permettent de modÃ©liser\r\naussi bien les chaÃ®nes de caractÃ¨res que les arbres, deux notions\r\nomniprÃ©sentes en linguistique informatique. Les ACG permettent d\'encoder\r\ndiffÃ©rents formalismes grammaticaux, notamment les grammaires d\'arbres\r\nadjoints (TAG).\r\n\r\nUn environnement de test et de dÃ©veloppement des ACG, ACGtk[1], a Ã©tÃ©\r\ndÃ©veloppÃ© par l\'Ã©quipe SÃ©magramme. Il dÃ©finit un langage pour la\r\nspÃ©cification et l\'utilisation d\'ACG pour l\'analyse grammaticale. Il a\r\nÃ©tÃ© dÃ©veloppÃ© en Caml[2], un langage de programmation fonctionnel.\r\n\r\nL\'objectif gÃ©nÃ©ral de cette proposition de stage est de s\'appuyer sur\r\nune grammaire TAG Ã  large couverture et intÃ©grant la sÃ©mantique pour\r\nÃ©tudier la question de l\'ingÃ©nierie grammaticale pour les ACG Ã  l\'aide\r\nd\'ACGtk. Cela comporte des aspects d\'analyse et de conception liÃ©s aux\r\ncontraintes d\'un tel environnement de dÃ©veloppement, ainsi que des\r\naspects liÃ©s Ã  la modÃ©lisation grammaticale.\r\n\r\nIl s\'agira dans un premier temps de bien comprendre l\'utilisation qui\r\nest faite des grammaires et de saisir les similaritÃ©s existantes avec\r\nles langages de programmation. Pour ce faire, on s\'appuiera sur les\r\ntravaux thÃ©oriques d\'encodage dans les ACG des grammaires TAG. Cette\r\ntraduction conduira Ã  l\'identification de caractÃ©ristiques souhaitables,\r\ntant d\'un point de vue pratique (fonctionnalitÃ©s d\'ACGtk) que d\'un point\r\nde vue thÃ©orique (utilisation des structures de traits, rÃ©vision de\r\nl\'encodage).\r\n\r\nDans un deuxiÃ¨me temps, en s\'inspirant de travaux d\'environnements\r\nsemblables (comme GF[3]), il s\'agira de proposer des extensions au\r\nlangage de dÃ©veloppement prenant en compte les usages et prÃ©sentant les\r\nfonctionnalitÃ©s analysÃ©es. On mentionnera par exemple la combinaison de\r\nlexiques, la dÃ©finition d\'espaces de nommage pour les signatures et les\r\nlexiques, etc.\r\n\r\nEnfin, il s\'agira de mettre en oeuvre tout ou partie de ce qui aura Ã©tÃ©\r\ndÃ©fini prÃ©cÃ©demment et de l\'intÃ©grer Ã  ACGtk.\r\n\r\nCe travail sera rÃ©alisÃ© au sein de l\'Ã©quipe SÃ©magramme[4], notamment\r\ndans le cadre du projet ANR Polymnie[5] concernant l\'analyse et la\r\ngÃ©nÃ©ration avec les ACG.\r\n\r\n[1] http://www.loria.fr/equipes/calligramme/acg/#Software\r\n[2] http://caml.inria.fr/ \r\n[3] http://www.grammaticalframework.org/\r\n[4] http://semagramme.loria.fr/\r\n[5] http://semagramme.loria.fr/doku.php?id=projects:polymnie'),
(270, '2015-02-19', 'IRT SystemX', 'Palaiseau', 'STAGE M2: TAL, Extraction d\'information pour la veille géopolitique -\r\nIRT SystemX\r\n\r\ndurée 6 mois, démarrage février-avril 2015\r\n\r\nVous serez partie prenante d\'une équipe projet composée de 3 étudiants à\r\nqui nous proposons 3 stages:\r\n- Spécifications et modèle économique d\'une application de veille\r\n  géopolitique,\r\n- Design d\'une application de veille géopolitique et enfin\r\n- Extraction d\'information pour la veille géopolitique, qui est l\'objet\r\n  de cette annonce.\r\n\r\nLes technologies de traitement automatique de la langue (TAL) sont au\r\ncoeur de tous les métiers qui cherchent à exploiter plus efficacement\r\nles documents non structurés disponibles sur le web ou dans des bases de\r\ndocuments (articles de journaux, brevets, blogs, journaux télévisés,\r\narticles scientifiques). Le volume de ces données ne rend possible la\r\nconsultation manuelle que d\'une infime partie. Les outils de TAL vont\r\nservir à filtrer les documents pertinents, en extraire les informations\r\nessentielles, les structurer et les visualiser pour prendre les bonnes\r\ndécisions.\r\n\r\nAu sein de l\'IRT SystemX, Le projet de recherche intitulé IMM\r\n(Intégration Multimédia Multilingue), est un projet tri annuel démarré\r\nfin 2014. Il regroupe des industriels (Bertin Technologie, CapGemini,\r\nExalead, OVH, Systran, Temis, Vecsys, Vocapia) et des partenaires\r\nacadémiques (CEA-LIST, CNRS-LIMSI, INRIA-Saclay, LNE, UPMC-LIP6) ainsi\r\nque le Ministère de la Défense. Son objectif est de mettre en place une\r\nplateforme qui intègre les composants des partenaires (moteur de\r\nrecherche, de transcription de la parole, de traduction...) pour des\r\napplications de veille. L\'objectif commun est de relever un certain\r\nnombre de défis transverses: réduire le temps d\'adaptation à un contexte\r\nnouveau (sources, domaine, langue), en particulier la montée en\r\npuissance des réseaux sociaux, spécifier et développer des fonctions de\r\nhaut niveau pour améliorer la productivité d\'un professionnel de la\r\nveille, étudier et mettre en place des stratégies pour permettre le\r\npassage à l\'échelle des solutions envisagées. Dans le cadre de ce\r\nprojet, nous proposons à 3 étudiants de développer un cas d\'utilisation\r\ncivil de cette plate-forme.\r\n\r\nL\'objectif de l\'ensemble des 3 stages est de créer un démonstrateur\r\nd\'application de veille dans le domaine de la géopolitique et de la\r\ngéostratégie, à l\'usage des entreprises qui souhaitent investir ou\r\ndévelopper leurs ventes dans une région ou un pays, en s\'appuyant sur\r\nles technologies mises à disposition par la plate-forme IMM. Plus\r\nconcrètement, il s\'agit donc de mettre en oeuvre les fonctions de la\r\nplate-forme pour automatiser la collecte d\'informations et de documents,\r\npour ensuite les analyser et produire des synthèses. Les documents sont\r\ncollectés sur le web, aussi bien depuis des sites institutionnels que\r\ndepuis des réseaux sociaux. La collecte d\'information visera plus\r\nparticulièrement les textes de lois et les réglementations en cours, le\r\ncontexte plus général lié à la culture ou l\'histoire du pays (par\r\nexemple l\'impact de la loi islamique sur une région particulière), mais\r\naussi les projets de lois (par exemple les normes en cours d\'élaboration\r\nau niveau européen) ainsi que les réactions qu\'elles suscitent et les\r\nactivités de lobbying autour de ces projets.\r\n\r\nOn cherchera plus particulièrement à mettre en valeur les capacités\r\nsuivantes de la plate forme :\r\n\r\n- Recherche d\'information multilingue,\r\n- Extraction d\'information (entités nommées et relations),\r\n- Collecte et analyse des réseaux sociaux (Le lobbying est une activité\r\n  assez transparente et qui laisse des traces en particulier sur les\r\n  réseaux sociaux),\r\n\r\n- Analyse des contenus de vidéos (transcription de journaux télévisés\r\n  par exemple),\r\n\r\n- Visualisation innovante des données collectées analysées et indexées.\r\n\r\n\r\nVos missions seront les suivantes :\r\n- Vous familiariser avec les outils mis à disposition par la plate-forme\r\n  IMM,\r\n- En collaboration avec l\'étudiant des stages 1 et 3, contribuer à la\r\n  spécification d\'un prototype d\'application de veille géopolitique, et\r\n  en particulier élaborer la spécification fonctionnelle et technique en\r\n  tenant compte de la plate-forme existante.\r\n- Elaborer le modèle d\'extraction d\'information et en particulier\r\n  définir quelles entités nommées et quelles relations sont déjà\r\n  traitées par la plate-forme IMM et peuvent être réutilisées, quelles\r\n  entités plus spécifiques au domaine de la veille géostratégique sont\r\n  critiques pour réaliser un démonstrateur.\r\n- Sélectionner une partie de ce modèle et enrichir les outils\r\n  d\'extraction de la plate-forme (annotation, apprentissage, évaluation\r\n  de la qualité..)\r\n- Collecter des corpus, les traiter pour alimenter le prototype\r\n\r\nLe profil recherché : BAC +5, étudiant dans le domaine de l\'informatique\r\navec une spécialisation en traitement automatique des langues, en\r\nrecherche d\'information ou en apprentissage artificiel pour un stage de\r\n6 mois environ sur le site IRT SYSTEMX à Palaiseau.\r\n\r\nVos Compétences sont :\r\n- Capacité à traiter des corpus (langages perl, python) ou des\r\n  ressources linguistiques\r\n- Programmation langage orienté objet (Java, C++)\r\n- Capacité à utiliser un framework/middleware (comme Apache\r\n  Camel/ServiceMix)\r\n\r\nVos aptitudes personnelles sont :\r\n- Rigueur, sens des responsabilités\r\n- Bon relationnel, capacités à travailler en collaboration\r\n\r\n\r\nRéférence : CREE_2015_IMM1_03_02_141029\r\nPour postuler : stages@irt-systemx.fr'),
(271, '2015-02-23', 'IGN', 'Saint-Mandé', '===================================\r\n\r\nAnalyse des sentiments et des qualités sonores de lieux à partir de\r\ncartes et de photographies\r\nhttp://recherche.ign.fr/labos/cogit/\r\nhttp://www.u-cergy.fr/fr/laboratoires/labo-crtf.html\r\n\r\nMots-clés\r\ntraitement automatique du langage naturel, traitement d\'enquête,\r\ninteractions verbales\r\n\r\nContexte\r\nCe stage s\'inscrit dans le cadre du projet CartASUR : CARTographie des\r\nAmbiances Sonores URbaines. La directive européenne relative à\r\nl\'évaluation et à la gestion du bruit impose la mise en place de cartes\r\nde bruit pour de grosses agglomérations. Ces cartes établies pour les\r\nflux de circulation réguliers, ne reflètent pas l\'ambiance sonore\r\nressentie par les citadins. Pourtant ces cartes doivent servir d\'outil\r\nde communication avec le public. La directive propose donc aux\r\nétats-membres d\'utiliser des indicateurs qui prennent en compte des\r\nsources, des événements ou des périodes particuliers. Dans ce contexte,\r\nl\'objectif de ce projet est de publier sur un site web des cartes\r\nsonores construites sur des indicateurs adaptés au ressenti de la\r\npopulation (et en particulier, l\'indicateur agrégé d\'agrément sonore) et\r\naccessibles à tous les acteurs (aménageurs, décideurs et citadins). Les\r\nindicateurs de ressenti de la population sont construits à partir de\r\nmesures obtenues lors d\'une enquête (la zone d\'enquête couvre une partie\r\ndes 13ème et 14ème arrondissements parisiens).\r\nLes attendus de ce projet sont multiples, et en particulier montrer que\r\ncette nouvelle génération de cartes traduit le passage d\'une politique\r\nnormative à une politique constitutive en matière de gestion des\r\nnuisances sonores. Sur le plan opérationnel, le projet devra avoir pour\r\neffet de : i) mettre à la disposition du public des informations\r\npermettant une meilleure appropriation de la problématique du bruit dans\r\nl\'environnement ; ii) améliorer la connaissance de l\'environnement\r\nsonore et utiliser les résultats pour la mise en place de plans d\'action\r\n(préventifs et curatifs).\r\n\r\nAfin d\'évaluer la qualité des cartes sonores produites, une première\r\ncampagne d\'entretiens a été réalisée auprès d\'un échantillon de\r\npopulation. Le matériel de ces entretiens consiste en des cartes et des\r\nphotographies présentées sur support papier. L\'objectif est de : \r\n\r\n- valider les représentations associées aux cartes réalisées dans le\r\n  cadre du projet : ces cartes montrent différentes informations, dont\r\n  l\'agrément sonore, et doivent permettre aux usagers de se représenter\r\n  la qualité sonore des lieux ;\r\n\r\n- évaluer la validité de la symbolisation des lieux par les cartes à\r\n  travers le contraste d\'enquêtes cartes/photos.\r\n\r\nLes questions posées lors de ces entretiens consistent :\r\n- à évaluer des caractéristiques des cartes réalisées (densité\r\n  d\'information, utilité, etc.) sur une échelle graduée ;\r\n\r\n- à compter des symboles correspondant à certains types d\'objets\r\n  cartographiques sur ces cartes ;\r\n\r\n- à évaluer la qualité des symboles utilisés sur les cartes selon les\r\n  connotations mises en place par les lecteurs de la carte.\r\n\r\nCertaines questions appellent aussi des réponses libres qui sont\r\nenregistrées.\r\n\r\nMissions confiées :\r\nCe stage s\'intègre à cette dernière partie du projet qui concerne\r\nl\'évaluation des cartes produites. Cette évaluation se fait au travers\r\ndes résultats d\'une première enquête qu\'il sera nécessaire de compléter\r\npar des questions plus ouvertes afin de produire une analyse\r\nlinguistique et lexicométrique des réponses.\r\n\r\nLes missions contenues dans ce stage sont les suivantes :\r\n- analyse de cette première campagne d\'entretiens et réflexion sur les\r\n  questionnaires administrés ;\r\n\r\n- propositions de questions pour une nouvelle campagne d\'enquêtes (avec\r\n  des questions ouvertes dont les réponses seront enregistrées) ;\r\n\r\n- aide à la passation des enquêtes (importance des connaissances\r\n  linguistiques sur la mise en mots des données sensibles) ;\r\n\r\n- transcription et mise en forme des résultats d\'enquêtes : constitution\r\n  d\'un corpus conforme aux standards de l\'équipe ;\r\n\r\n- début des analyses sur les corpus : liens entre les cartes et les\r\n  photographies et le ressenti (en particulier celui de l\'agrément\r\n  sonore) ; connotations des cartes et de leur symbologie ; formes de\r\n  subjectivité dans la mise en mots des enquêtés ; sentiments et\r\n  opinions exprimées à travers des marques énonciatives et des indices\r\n  pragmatiques ; évaluation des cartes à travers notamment l\'analyse des\r\n  lexiques utilisés par les enquêtés.\r\n\r\nResponsables de stage	\r\nCatherine DOMINGUES\r\nIGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex\r\nmél : catherine.domingues@ign.fr	tél : 01 43 98 85 44\r\n\r\nJulien LONGHI\r\nIUT de Cergy-Pontoise, Dpt MMI, 34 Bd Bergson 95200 Sarcelles\r\nmél : julien.longhi@u-cergy.fr\r\n\r\nCompétences particulières et formation requise\r\nCe stage s\'adresse aux étudiants de master 2 (ou formation équivalente)\r\navec une spécialisation en TALN, en linguistique de corpus, en analyse\r\ndes interactions verbales ou en informatique.\r\n\r\nDurée, lieu du stage, rémunération\r\nLa durée prévue est de cinq mois, avec un début en avril/mai 2015.\r\nLe stage se déroulera au laboratoire COGIT de l\'IGN à Saint-Mandé et le\r\nstagiaire sera amené à se rendre régulièrement à l\'IUT de Cergy-Pontoise\r\n(site de Sarcelles), ou à l\'Université de Cergy-Pontoise (site de\r\nNeuville) où se trouve Catherine LAVANDIER, la responsable scientifique\r\ndu projet CartASUR.\r\n\r\nIGN/laboratoire COGIT\r\n73 avenue de Paris\r\n94160 Saint-Mandé \r\nmétro : Saint-Mandé - ligne 1 ou RER A : Vincennes\r\n\r\nIUT de Cergy-Pontoise (site de Sarcelles)\r\n34 boulevard Henri-Bergson\r\n95200 Sarcelles\r\nRER D arrêt Garges-Sarcelles \r\n\r\nIUT de Cergy Pontoise (site de Neuville sur Oise)-Laboratoire MRTE\r\n5 Mail Gay Lussac, Neuville sur Oise\r\n95 031 Cergy Pontoise Cedex\r\nRER A direction Cergy-le-haut, arrêt Neuville-Université\r\n\r\nrémunération mensuelle : environ 500 euros\r\n\r\nProlongements éventuels\r\nLes laboratoires proposent chaque année des sujets de thèse ainsi que\r\ndes stages de post-doctorant.\r\n\r\nPour candidater\r\nLe dossier de candidature sera envoyé par mail. Il devra se composer\r\nd\'un curriculum vitae et d\'une lettre de motivation, accompagnés des\r\nrelevés de notes des années de M1 et M2 (ou deux dernières années\r\nd\'école d\'ingénieurs) et d\'une description des enseignements suivis (un\r\nlien vers le site internet de la formation est le bienvenu).'),
(272, '2015-02-26', 'EDF', 'Clamart', 'STAGE INGÉNIERIE LINGUISTIQUE\r\nSUJET 2015: Catégorisation, Clustering\r\nDURÉE : 6 MOIS ENVIRON\r\n\r\n1.  CONTEXTE\r\n \r\nLe volume des données numériques textuelles, disponibles sur l\'Internet\r\n(forums, twitters etc.) ou relatives à des contacts client (enquêtes,\r\ncentre d\'appel etc.), augmente chaque année. L\'analyse de ces\r\ninformations, structurées ou non, est, aujourd\'hui, un impératif\r\nstratégique pour une entreprise telle qu\'EDF. Dans ce cadre, et dans\r\nl\'objectif de toujours mieux connaître les besoins des clients,\r\nl\'exploitation de ces documents implique l\'utilisation de méthodes\r\nd\'extraction d\'information, de classification supervisée, ainsi que des\r\nméthodes d\'analyse exploratoire. \r\n\r\n\r\n2.	 SUJET DU STAGE\r\n\r\nDepuis plusieurs années, EDF utilise l\'outil Luxid®, solution développée\r\npar l\'éditeur TEMIS (Text-Mining Solution). Cette technologie permet de\r\ngénérer des modèles de catégorisation et des clustering à partir\r\nd\'extraction de concepts métier. Les résultats obtenus sont aujourd\'hui\r\nsatisfaisants et permettent une analyse qualitative des données à\r\ntraiter. Malgré les bons résultats, nous aimerions tester des\r\nalgorithmes d\'analyse alternatifs et mettre en oeuvre une nouvelle\r\napproche grâce à des outils Open-source.\r\n\r\nDans le cadre de ce stage, nous aimerions mettre en place une chaîne de\r\ntraitement permettant d\'utiliser les concepts métier extraits par Luxid®\r\ncomme variables d\'entrée d\'un classifieur et d\'une méthode de\r\nclustering. L\'objectif est de valider la faisabilité tout en évaluant la\r\nqualité des résultats obtenus. Il s\'agirait aussi de mener un état de\r\nl\'art des algorithmes de classification supervisée et de clustering\r\nexistants permettant de répondre à la question : Quelle est la méthode\r\nstatistique la plus performante pour nos besoins ?\r\n\r\nAinsi, le stage se découpe en 3 étapes importantes :\r\n\r\n1- Faire un état de l\'art et une description précise des différents\r\n   algorithmes possibles pour la classification supervisée et le\r\n   clustering\r\n\r\n2- Tester des outils Open-source capable d\'utiliser les concepts métier\r\n   extraits par Temis\r\n\r\n   a. Avec un algorithme similaire à celui utilisé par EDF\r\n\r\n   b. Avec d\'autres algorithmes que ceux utiliser aujourd\'hui par EDF\r\n\r\n3- Mesurer la qualité des résultats et comparer les résultats avec ceux\r\n   de Temis\r\n \r\n\r\n3. INFORMATIONS PRATIQUES\r\n\r\nInterlocuteurs	\r\nDelphine Lagarde	01.47.65.39.75	delphine.lagarde@edf.fr \r\n\r\nLieu du stage	\r\nEDF R&D - Département ICAME\r\n1, avenue du Général de Gaulle\r\n92141 Clamart Cedex	\r\n\r\nDate & Durée \r\n2015 - 6 mois environ\r\n\r\nRémunération\r\nA définir (environ 1.000¤/mois)'),
(273, '2015-02-26', 'Grammatica', 'Arras', 'Stage de M2 Linguistique et informatique : « Constitution de corpus et\r\nextraction d\'unités lexicales »\r\n\r\nOffre de stage de M2 : Traitement de documents écrits et vidéos\r\n\r\nLieu : Equipe GRAMMATICA (EA4521), Université d\'Artois, Arras, France\r\n\r\nEncadrants : Luis Meneses-Lerín (MCF) & Jean-Marc Mangiante (PR)\r\n\r\nSujet : Traitement/constitution de corpus & extraction de collocations\r\net phraséologismes\r\n\r\nDurée : 5-6 mois\r\n\r\nDébut : mi-mars\r\n\r\nContrat : stage conventionné CNRS rémunéré (500¤/mois)\r\n\r\nDescriptif :\r\n\r\nL\'objectif du corpus est double : d\'une part, construire un référentiel\r\nde compétences langagières pour certains métiers dans l\'hôtellerie et\r\nrestauration pour l\'enseignement du français sur objectifs spécifiques\r\n(Mangiante, 2004) et, d\'autre part, extraire et analyser le cotexte de\r\ncollocations et phraséologismes (Meneses, 2014) du point de vue\r\nlinguistique.\r\n\r\nQualifications requises :\r\n\r\n- Compétences linguistiques : lexique et phraséologie\r\n\r\n- Compétences informatiques : PHP,Perl, Python, XML, bases de données\r\n\r\nProcédure de recrutement :\r\n\r\nLe CV de candidature est à envoyer avant le 2 mars 2015 à Luis\r\nMeneses-Lerín (luis_meneses_lerin@yahoo.fr). Pour toute précision, les\r\ncandidats sont invités s\'ils le souhaitent, à prendre contact au\r\npréalable avec Luis Meneses-Lerín (luis_meneses_lerin@yahoo.fr).'),
(274, '2015-02-26', 'L3i', 'La Rochelle', 'Dans le cadre d\'un travail commun entre le laboratoire L3i et\r\nCharente-Maritime Tourisme, en prolongement du projet Tourinflux, nous\r\nproposons un stage indemnisé de 10 semaines, intitulé \" *Outil de\r\nvisualisation de données de déplacements de touristes* \", et dont un\r\ndescriptif détaillé suit.\r\n\r\n*Résumé du travail proposé :*\r\n\r\nOrganiser les données de flux de déplacement issues d\'un opérateur\r\nmobile majeur au sein d\'une solution technique permettant de mieux\r\nvisualiser les données (sous forme de tableaux, graphiques, voire\r\ncartes) afin de définir les indicateurs en vue d\'une analyse plus\r\ndétaillée de la fréquentation touristique du département et des flux de\r\ndéplacement afférents.\r\n\r\n*Mots clés :*\r\n\r\nVisualisation de données (tableau, carte), data mining, recherche\r\nfacettée\r\n\r\n*Contexte de l\'étude:***\r\n\r\n*Zone d\'étude*:\r\n\r\n  * Périmètre spatial : 10 zones de Charente-Maritime (cf carte) + tests\r\n    sur 10 zones des Deux-Sèvres\r\n  * Périmètre Temporel : juillet 2014 à mars 2015\r\n\r\n*Livrables*:\r\n\r\n  * solution technique exploitable par CMT et ses partenaires (solution\r\n    open source)\r\n  * outil de visualisation et de rendu (tableaux, cartes, recherche\r\n    facettée, etc.)\r\n  * prévoir une prise en main de l\'outil par CMT\r\n\r\n*Déroulé du stage :*\r\n\r\n  * Lieu du stage : CMT au Conseil général / Université de La Rochelle\r\n    (en alternance)\r\n  * Période de stage : 20 avril - 26 juin (10 semaines)\r\n  * Indemnisation : réglementaire\r\n  * Encadrement : en plus de CMT et de l\'Université, l\'étudiant sera\r\n    amené à faire une présentation de l\'état d\'avancement devant les\r\n    représentants des collectivités (réunions de travail).\r\n\r\n**\r\n\r\n*Description du sujet :*\r\n\r\nRéaliser un outil de visualisation des données sous forme tabulaire et\r\ncartographique. Cet outil, open source, devra être flexible dans la\r\nmesure où il devra tenir compte des évolutions de segmentation des\r\ndonnées. Les données des Deux-Sèvres seront probablement également\r\nintégrées à cet outil, sous réserve que la structuration des données\r\nfournies par Orange soit identique à celles de la Charente-Maritime.Ce\r\nsera travail s\'inscrit dans le cadre d\'un prolongement du projet\r\ninvestissement d\'avenir Tourinflux.**\r\n\r\n**\r\n\r\n*Prérequis et contraintes particulières :*\r\n\r\n*Compétences techniques :*\r\n\r\n- Programmation :\r\n\r\n- Javascript et bibliothèque de visualisation de données (par ex. 3DJs)\r\n\r\n- API Google Maps ou Open Street Map\r\n\r\n- La connaissance d\'un ETL et d\'outils de traitement statistique serait\r\n  un plus.\r\n\r\n- Bonne aptitude au travail en équipe (Agilité, GIT) et à la\r\n  communication (présentation lors de réunion...).\r\n\r\n*Contacts - liens : *\r\n\r\n*Email *:\r\n\r\nCV + lettre de motivation à envoyer à : Antoine Doucet \r\n(antoine.doucet@univ-lr.fr), Cyril \r\nFaucher (cyril.faucher@univ-lr.fr),\r\nMickaël Coustaty (mickael.coustaty@univ-lr.fr)');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(275, '2015-03-05', 'LI', 'Blois', '===========================================================\r\nProposition de stage de Master ou de fin d\'études ingénieur\r\n===========================================================\r\n\r\nTitre : Extraction et caractérisation automatique d\'auteurs sur le Web\r\n\r\n\r\nResponsables\r\n-------------\r\n\r\nNicolas Labroche (LI, Nicolas.Labroche@univ-tours.fr)\r\nJean-Yves Antoine (LI, Jean-Yves.Antoine@univ-tours.fr)\r\nAgata Savary (LI, Agata.Savary@univ-tours.fr)\r\nJean-Christophe Lavocat (Elokenz, jice@elokenz.com)\r\n\r\nRésumé\r\n------\r\n\r\nDans un contexte où l\'information est massivement disponible et de mieux\r\nen mieux structurée, l\'extraction automatique de données n\'a jamais été\r\naussi importante. Faisant écho à de récentes évolutions des moteurs de\r\nrecherches classiques (Google, Bing), la détection de l\'auteur d\'une\r\npage devient un enjeux stratégique.\r\nL\'objet de ce stage consiste en la création d\'un algorithme d\'extraction\r\nautomatique de l\'auteur d\'une page web donnée. Les données structurées,\r\nlinguistiques et hiérarchiques seront utilisées dans un algorithme\r\nd\'apprentissage automatique pour déterminer si un nom extrait d\'une page\r\ncorrespond à son auteur. Le travail réalisé aura deux principaux\r\nobjectifs : (1) détecter automatiquement les auteurs d\'un texte à partir\r\ndu code source d\'une page web (si ils sont mentionnés) et, (2) de les\r\nidentifier (si possible) grâce à leurs profils sociaux qui pourraient\r\nêtre présents sur la même page.\r\n\r\nContexte scientifique\r\n----------------------\r\nLe Laboratoire d\'Informatique de l\'Université de Tours, et son équipe \r\nBase de Données et Traitement du Langage Naturel situé à l\'antenne de \r\nBlois (41) propose un sujet de stage dans le cadre du projet industriel \r\nfinancé par la société ELOKENZ (représentée en la personne de M. \r\nJean-Christophe LAVOCAT) située à Toulon (83) et adossée à l\'Incubateur \r\nPublic Paca EST et à la structure Toulon Var Technologie (TVT).\r\n\r\nTravail à réaliser\r\n------------------\r\n\r\nLe rendu de ce stage sera constitué d\'un algorithme prenant comme entrée \r\nune page HTML ou XML et renvoyant en sortie une liste des auteurs \r\ndétectés dans le texte, avec leur nom et si possible des liens vers des \r\nprofils sociaux les identifiant.\r\n\r\n- Phase n°1 - La première phase du projet consiste à prétraiter les\r\n  ressources pour en faire des documents valides XML et à en extraire\r\n  les noms propres. Pour ce dernier point, deux méthodes pourront être\r\n  évaluées et comparées : d\'une part, l\'utilisation de bibliothèque\r\n  d\'extraction d\'entités nommées (comme Balie ou Lingpipe) ou bien\r\n  utiliser des listes de noms. Pour simplifier le problème, dans un\r\n  premier temps on pourra ne considérer qu\'une seule langue pour la\r\n  liste de noms, mais l\'algorithme proposé devra à terme pouvoir\r\n  travailler indifféremment avec toute liste de noms fréquents passée en\r\n  argument.\r\n\r\n- Phase n°2 - La seconde phase du projet consiste en la création d\'un\r\n  ensemble d\'apprentissage suffisamment grand contenant pour un ensemble\r\n  de ressources la liste des noms y apparaissant et pour chacun, une\r\n  étiquette indiquant s\'il s\'agit d\'un nom d\'auteur ou pas. On pourra\r\n  créer un second ensemble d\'apprentissage avec les informations\r\n  sociales qui pourraient être présentes dans la page en vue du second\r\n  objectif.\r\n\r\n- Phase n°3 - La dernière phase du projet consiste à déterminer un\r\n  ensemble d\'attributs pour décrire chaque nom identifié dans la phase\r\n  précédente. On pourra s\'appuyer sur des travaux précédents dans le\r\n  domaine et enrichir cela à partir de connaissances linguistiques (pour\r\n  lesquelles un expert sera disponible). Il faudra ensuite évaluer\r\n  différents algorithmes d\'apprentissage automatique sur la base de\r\n  cette représentation parmi les arbres de décision, les forêts\r\n  aléatoires, les SVM, et les réseaux de neurones pour apprendre un\r\n  modèle. On favorisera en premier lieu une méthode interprétable (comme\r\n  les arbres de décision) de façon à pouvoir étudier les règles qui\r\n  définissent le modèle de classification et les confronter à la\r\n  connaissance que des linguistes pourront apporter au projet.\r\n\r\nProfil recherché\r\n-----------------\r\n\r\nLa personne recrutée sera en cycle terminal d\'études en informatique, de \r\nniveau Bac+5 (Master ou Ecole d\'ingénieur en Informatique).\r\nUn intérêt pour les techniques d\'apprentissage et de classification\r\nautomatiques, voire le Traitement Automatique des Langues est apprécié,\r\nsans être un prérequis à recrutement. Dans le cas d\'un(e) étudiant(e) en\r\nMaster Recherche, le sujet de stage pourra être adapté aux attentes de\r\nl\'étudiant.\r\n\r\nRémunération\r\n------------\r\n\r\n508 ¤ par mois. Cette rémunération sera assurée par la société ELOKENZ.\r\n\r\nDurée du stage et lieu d\'exercice\r\n---------------------------------\r\n\r\nLa personne recrutée travaillera au sein du laboratoire LI, dans les\r\nlocaux de l\'antenne universitaire de Blois.\r\nIl s\'intégrera dans une équipe projet de l\'équipe de recherche BDTLN\r\n(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) composée de\r\nNicols Labroche, Jean-Yves Antoine et Agata Savary.\r\nDes points de rendez-vous réguliers avec la société ELOKENZ seront\r\nprévus au cours du stage.\r\n\r\nLa durée minimale de stage sera de 5 mois (avril-août 2015).\r\n\r\nContact - Dépôts de candidature\r\n-------------------------------\r\n\r\nContact : Nicolas Labroche (nicolas.labroche@univ-tours.fr), Jean-Yves\r\nAntoine (jean-yves.antoine@univ-tours.fr)\r\n\r\nMerci de déposer par courrier électronique un CV détaillé de vos\r\nactivités passées, accompagné d\'une lettre de motivation et de vos\r\nrelevés de notes des deux dernières années d\'études.'),
(276, '2015-03-05', 'LIMSI & CEA', 'Orsay', 'Offre de stage recherche rÃ©munÃ©rÃ© Master 1 ou 2 ou ingÃ©nieur\r\nInformatique\r\n\r\nCombinaison de mÃ©thodes distributionnelle et d\'extraction terminologique\r\npour l\'adaptation de ressources terminologiques\r\n\r\nNiveau : Master 1 ou 2 ou ingÃ©nieur informatique \r\nDate de dÃ©but : avril, mai 2015\r\nDurÃ©e : 4-6 mois\r\n\r\nMots clefs: extraction terminologique, ressources linguistiques,\r\nmÃ©thodes distributionnelles\r\n\r\nContexte :\r\nL\'extraction d\'information mise en oeuvre sur des textes de spÃ©cialitÃ©\r\n(articles scientifiques biomÃ©dicaux, dossiers patients, textes de loi,\r\netc.) s\'appuie sur des corpus annotÃ©s fournissant des exemples d\'entitÃ©s\r\nÃ  retrouver. Pour amÃ©liorer leur couverture sur de nouveaux textes, il\r\nest possible d\'utiliser des ressources terminologiques recensant les\r\ntermes du domaine du corpus et des informations sÃ©mantiques associÃ©es\r\n[2, 7]. Cependant, ces ressources ne sont pas suffisantes [1, 6] et\r\nnÃ©cessitent un important travail d\'adaptation au corpus et aux types\r\nsÃ©mantiques des entitÃ©s devant Ãªtre identifiÃ©es. Pour rÃ©pondre Ã  cette\r\nphase de constitution de ressources adaptÃ©es, il est envisageable\r\nd\'exploiter des mÃ©thodes d\'extraction de termes et d\'analyse\r\ndistributionnelle [3, 4].\r\n\r\nObjectif :\r\nL\'objectif du stage est de proposer une approche visant Ã  combiner une\r\nmÃ©thode d\'extraction de termes avec une approche distributionnelle pour\r\nconstituer une ressource adaptÃ©e au corpus, associant des termes\r\nextraits automatiquement et des informations sÃ©mantiques correspondant\r\naux types des entitÃ©s sÃ©mantiques visÃ©es. L\'analyse des regroupements\r\ndistributionnels sera Ã©galement le moyen d\'identifier les termes pouvant\r\nÃªtre polysÃ©miques.\r\nLes contextes distributionnels exploitÃ©s pourront avoir des natures\r\ndiverses (fenÃªtres graphique [+/- n mots avant et aprÃ¨s un mot central],\r\nfenÃªtres syntaxiques [chemins partagÃ©s dans le graphe de dÃ©pendance] ou\r\nencore rÃ´les sÌemantiques issus d\'un systÃ¨me de SRL). Ils permettront de\r\nrapprocher des termes ou des schÃ©mas de termes prÃ©sentant des\r\nsimilaritÃ©s non immÃ©diatement explicites.  L\'apport de diffÃ©rentes\r\nreprÃ©sentations sÃ©mantiques dans un contexte distributionnel sera\r\nÃ©galement Ã©valuÃ©. Ces reprÃ©sentations sÃ©mantiques pourront Ãªtre des\r\nontologies ou bases de connaissances du domaine (UMLS dans le domaine\r\nmÌedical par exemple) ou des bases de connaissances plus gÃ©nÃ©rales\r\n(typiquement le rÃ©seau lexical WordNet).\r\nLes traitements linguistiques seront effectuÃ©s Ã  l\'aide des outils\r\ndisponibles dans les deux laboratoires (analyseur linguistique libre\r\nLIMA [5], extracteur de termes YaTeA [8], etc.).\r\n\r\nL\'Ã©valuation de l\'approche sera rÃ©alisÃ©e dans plusieurs langues\r\n(notamment anglais et franÃ§ais), et s\'appuiera sur des corpus\r\ndisponibles comme les corpus biomÃ©dicaux (I2B2, SemEval, Clef-eHealth).\r\n\r\nUne poursuite en thÃ¨se pourra Ãªtre envisagÃ©e en fonction de\r\nl\'obtention d\'un financement.\r\n\r\nLieu : dans l\'un ou l\'autre des laboratoires des encadrants, situÃ©s Ã \r\n       2 km l\'un de l\'autre,\r\nLIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann, Orsay\r\nou\r\nCEA LIST, LVIC, Centre d\'intÃ©gration Nano-INNOV, av. de la Vauve,\r\nPalaiseau\r\n\r\nFinancement : Financement Labex DiGiCosme\r\n              Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.\r\n\r\nEncadrants : Thierry Hamon (LIMSI/CNRS) et GaÃ«l de Chalendar (CEA LIST)\r\n\r\nProfil du candidat:\r\nLe stage de recherche est destinÃ© Ã  un Ã©tudiant niveau Master 1 ou 2 \r\nou ingÃ©nieur informatique.\r\n- IntÌerÃªt pour le TAL\r\n- Connaissance (ou sensibilisation)\r\n  - des mÃ©thodes d\'acquisition terminologiques\r\n  - des mÃ©thodes d\'analyse distributionnelle\r\n- Utilisation habituelle de Linux\r\n- GoÃ»t pour la recherche et l\'expÃ©rimentation\r\n\r\nContact : Merci d\'envoyer un CV, une lettre de motivation, les notes\r\n          de Master et les coordonnÃ©es de rÃ©fÃ©rents AUX DEUX ENCADRANTS :\r\n          thierry.hamon at limsi.fr ET gael.de-chalendar@cea.fr\r\n\r\nRÃ©fÃ©rences :\r\n\r\n[1] Olivier Bodenreider, Thomas C. Rindflesch, and Anita\r\n    Burgun. Unsupervised, corpus-based method for extending a\r\n    biomedical terminology. In Workshop on Natural Language Processing\r\n    in the Biomedical Domain (ACL2002), pages 53-60, 2002.\r\n[2] Kevin Bretonnel Cohen and Dina Demner-Fushman. Biomedical Natural\r\n    Language Processing. John Benjamins publishing company, 2013.\r\n[3] James R. Curran. From distributional to semantic similarity. Phd\r\n    thesis, University of Edinburgh, 2004.\r\n[4] R. Grishman and Y. He. An information extraction customizer. In\r\n    P. Sojka et al., editor, Proceeedings of the conference Text,\r\n    Speech and Dialogue, number 8655 in LNAI, pages 3-10, 2014.\r\n[5] https://github.com/aymara/lima/wiki\r\n[6] Alexa T. McCray, Allen C. Browne, and Olivier Bodenreider. The\r\n    lexical properties of the gene ontology (GO). In Proceedings of\r\n    the AMIA 2002 Annual Symposium, pages 504-508, 2002.\r\n[7] S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and\r\n    J. F. Hurdle. Extracting information from textual documents in the\r\n    electronic health record: a review of recent research. IMIA\r\n    Yearbook of Medical Informatics, 42(5):923-936, 2008.\r\n[8] http://search.cpan.org/~thhamon/Lingua-YaTeA/'),
(277, '2015-03-13', 'Xerox Research Centre Europe', 'Grenoble', 'Xerox Research Centre Europe, located in Grenoble, is offering the\r\nfollowing internship for Spring 2015:\r\n\r\n \r\n\r\n-------------------------------------------------------------------\r\n\r\nInternship: Modeling next sentence in a dialog using vector space\r\nmodels\r\n\r\n-------------------------------------------------------------------\r\n\r\n \r\n\r\nSee: http://www.xrce.xerox.com/About-XRCE/Internships/Modeling-next-sentence-in-a-dialog-using-vector-space-models\r\n\r\n \r\n\r\nContacts :\r\n\r\n                Dymetman, Marc             marc.dymetman@xrce.xerox.com  \r\n\r\n                Venkatapathy, Sriram    sriram.venkatapathy@xrce.xerox.com\r\n\r\n \r\n\r\nPlease mention \"Modeling next sentence in a dialog using vector space\r\nmodels\" in your subject line.\r\n\r\n \r\n\r\nDuration: 4.5 months\r\n\r\nStart Date: April - June 2015\r\n\r\n \r\n\r\nGiven the context of an observed dialog history up to a certain point,\r\nthe goal of this internship will be to develop predictive models for\r\nthe next utterance. A good model of the next utterance should\r\nsubstantially reduce its ``perplexity\'\' with respect to a baseline\r\nlanguage model. Based on a large collection of available chats in the\r\ncustomer-care domain, the feasibility of learning such models will be\r\nexplored. The perplexity score will be used to evaluate the\r\nperformance of various models that will be examined. The internship\r\nwill also involve using such models for the task of actually\r\npredicting the next utterance, up to some limited editing actions. The\r\nidea will be to retrieve the top candidates for the next sentence from\r\nall the sentences that have ever been uttered. One of the criteria for\r\nretrieval will be the perplexity of these sentences relative to the\r\nlearnt model.\r\n\r\n \r\n\r\nFor modelling, we will focus on models that represent the dialog\r\nhistory as a real vector. Such representations have been extensively\r\nused in recent years for encoding the semantics of words and\r\nsentences. Several ideas will be explored using frameworks such as\r\nTopic modelling and Deep Neural Networks.\r\n\r\n \r\n\r\nThe ideal candidate is a Computer Science student at the Master or\r\n(preferably) PhD level, with a background in Machine Learning and\r\nNLP. Strong programming skills are a requirement (Python, C++,\r\nJava...). Conference publication of the work will be strongly\r\nencouraged.'),
(278, '2015-03-16', 'ELDA', 'Paris', 'Descriptif\r\n-----------\r\n\r\n- Sujet : Développement d\'un outil générique d\'annotation des ressources\r\n  linguistiques\r\n\r\n- Niveau : M2 / dernière année d\'école d\'ingénieur\r\n\r\n- Domaine : informatique\r\n\r\n- Période : à partir de mars-avril 2015\r\n\r\n- Durée : 6 mois\r\n\r\nContexte\r\n--------\r\nActeur majeur des technologies de la langue, ELDA (Evaluations and\r\nLanguage resources Distribution Agency) est une PME dont les activités\r\ns\'articulent principalement autour de la distribution et de la\r\nproduction de ressources linguistiques.Dans le cadre des projets de\r\nproduction de ressources linguistiques dont elle est en charge, ELDA est\r\nsouvent amenée à des tâches de collecte, d\'annotation de contrôle\r\nqualité, de packaging, etc.).Afin de pouvoir gérer la grande variété des\r\ndifférents protocoles et formats d\'annotations, ELDA projette d\'intégrer\r\nen une seule plate-forme un ensemble d\'outils qui permettent la gestion\r\nhomogène et transparente des ressources linguistiques annotées.\r\n\r\nDans ce contexte, ELDA souhaite consolider sa plate-forme, qui devrait\r\npermettre :\r\n- d\'importer des ressources annotées déjà existantes ;\r\n- de créer de nouvelles ressources linguistiques, y compris l\'annotation\r\n  de nouveaux corpus ;\r\n- de naviguer dans une ressource linguistique recensée dans la\r\n  plate-forme, ou à travers plusieurs ressources ;\r\n- de récupérer et d\'effectuer des statistiques sur des éléments des\r\n  corpus et/ou des annotations.\r\n\r\nTravail à réaliser\r\n------------------\r\n\r\nAu sein de l\'équipe de développement informatique d\'ELDA, sous la\r\ntutelle d\'un ingénieur spécialiste du traitement automatique des\r\nlangues, vous serez amené à participer aux travaux suivants :\r\n\r\n- faire un état de l\'art sur les outils d\'annotation de ressources\r\n  linguistiques disponibles actuellement ;\r\n\r\n- spécifier / réviser l\'architecture de l\'outil d\'annotation à mettre en\r\n  place chez ELDA ;\r\n\r\n- réaliser des développements dans des outils d\'annotation, de concert\r\n  avec les autres membres de l\'équipe de développement informatique\r\n  d\'ELDA ;\r\n\r\n- développer des composantes logicielles d\'importation et d\'exportation\r\n  de données annotées depuis et vers des formats existants, autres que\r\n  le format utilisé par l\'outil d\'annotation.\r\n\r\nVos participerez également aux réunions périodiques de l\'équipe de\r\ndéveloppements logiciels d\'ELDA.\r\n\r\n\r\nProfil souhaité\r\n---------------\r\n\r\n- BAC + 4/5 / Dernière année d\'École d\'ingénieur ;\r\n- Bonnes connaissances pratiques de la programmation orientée objet ;\r\n- Connaissances de base en algorithmique ;\r\n- Connaissances de base des architectures des applications Web ;\r\n- Connaissance pratique d\'un système de gestion de bases de données ;\r\n- Anglais technique ;\r\n- La connaissance du langage Python sera appréciée ;\r\n- Des notions sur le langage JavaScript seront un plus.\r\n\r\n\r\nCandidature\r\n-----------\r\n\r\nCe stage, d\'une durée de 6 mois et basé à Paris dans le 13e\r\narrondissement (Les Gobelins), est à pourvoir au printemps 2015.\r\n\r\nLes candidatures (CV, lettre de motivation) doivent être adressées à\r\nVladimir Popescu (vladimir@elda.org).\r\n\r\nLe stage fait l\'objet d\'une rémunération, variable en fonction du niveau\r\nd\'études du candidat.\r\n\r\nwww.elda.org'),
(279, '2015-03-18', 'ODW', NULL, 'Nous sommes une agence spécialisée dans la communication et le community\r\nmanagement et recrutons un(e) stagiaire ou doctorant(e) sous contrat\r\npour une mission de 3 à 6 mois.\r\n\r\nLe/la candidat(e) retenu(e) sera responsable de la réalisation d\'un\r\nalgorithme d\'analyse sémantique et collaborera directement avec les\r\nfondateurs d\'ODW, un programmeur ainsi qu\'un consultant basé à\r\nLondres. Cette mission s\'inscrit dans le cadre du développement d\'un\r\noutil d\'analyse de segments d\'audience.\r\n\r\n\r\nObjectifs/responsabilités :\r\n\r\n 1. Développer un algorithme d\'extraction d\'entités nommées à partir de\r\n    texte non structuré - principalement conversations d\'utilisateurs de\r\n    réseaux sociaux :\r\n\r\n    a) sélection des modèles\r\n\r\n    b) Implémentation\r\n\r\n    c) Scalability assessment\r\n\r\n 2. Analyse des résultats produits par l\'algorithme:\r\n\r\n    a) catégorisation thématique des documents\r\n\r\n    b) conception et réalisation de graphs et autres méthodes de\r\n       présentation visuelle\r\n\r\n\r\n 3. Contribuer à la réalisation du prototype:\r\n\r\n    a) Planning et suivi des objectifs\r\n\r\n    b) Présentation de l\'outil à des utilisateurs non experts en\r\n       linguistique informatique\r\n\r\n\r\nCompétences:\r\n\r\n Requises:\r\n\r\n a) Maîtrise des principales méthodes de linguistique informatique\r\n\r\n b) Programmation Python (ou autre langage orienté objet)\r\n\r\n \r\n Recherchées mais non nécessaires pour candidater :\r\n\r\n a) Acquisition et stockage de données à travers des APIs (AWS, Twitter\r\n    Search, ...)\r\n\r\n b) Requêtes de données au format noSQL (notamment MongoDB)\r\n\r\n c) Software programming\r\n\r\nMerci d\'envoyer votre CV à bonjour@odw.fr en précisant vos dates de\r\ndisponibilité.'),
(280, '2015-04-01', 'Cantoche', 'Paris', 'Nous recherchons un stagiaire en traitement du langage.\r\n\r\nSociété : CANTOCHE\r\nIntitulé du poste : Stagiaire en développement sur le traitement du langage (TAL)\r\nLieu de travail : PARIS\r\nType de contrat : Stage conventionné\r\nRémunération : 30% du SMIC + chèques déjeuners\r\nDate de disponibilité : immédiate\r\n\r\n\r\nDescription du poste\r\n\r\nNous recherchons actuellement un Stagiaire en développement sur le\r\ntraitement du langage (TAL)\r\n\r\nAu sein d\'une équipe expérimentée et à taille humaine et en relation\r\navec directeur technique, vous serez amené(e) à réaliser une étude\r\ncomparative des solutions TAL existantes, et à implémenter/tester les\r\nplus pertinentes dans le but d\'enrichir le moteur sémantique du\r\nproduit d\'assistance virtuelle de Living ActorTM.\r\n\r\nFondée en 1999, Cantoche s\'est distingué comme l\'un des leaders\r\nmondiaux des agents virtuels intelligents et l\'animation des avatars\r\ndans tous types d\'applications Web et mobile. Cantoche a deux domaines\r\nd\'expertise unique : la partie artistique pour la création de\r\npersonnage et le développement logiciel avec sa suite logicielle\r\npropriétaire Living ActorTM.\r\n\r\nCantoche est basé en France et aux USA et plus de 1000 sociétés de\r\nplusieurs pays utilisent nos solutions telles que BNP, GDF, EDF,\r\nToshiba, Natixis, Airbus, Sanofi...\r\n\r\n\r\nProfil recherché\r\n\r\nVous avez un cursus TAL et vous maîtrisez les langages Java et\r\nLinux. Vous avez un bon niveau en Anglais et de bonnes qualités de\r\nrédaction.\r\n\r\nContact\r\n\r\nEnvoyer CV et lettre de motivation à : job [ chez ] cantoche.com'),
(281, '2015-04-16', 'Airbus', 'Toulouse', 'Nous proposons un stage dans le département de facteurs humains, section\r\nlinguistique à Airbus Toulouse.\r\n\r\nLe sujet du stage porterait sur la construction (amélioration de qualité\r\net précision) des alertes audio dans les cockpits des avions Airbus.\r\n\r\nLe sujet sera plutôt centré sur des recherches en linguistique : sur la\r\nfaçon de donner un ordre en plusieurs langues, les paramètres\r\nd\'intonation, accentuation etc. Les recherches s\'appuieront entre autre\r\nsur la phonétique, phonologie, psycholinguistique, syntaxe, sémantique\r\net pragmatique.\r\n\r\nDes connaissances en TAL seront appréciés, et une bonne maitrise de\r\nl\'anglais. \r\n\r\nLa durée du stage est de 6 mois.\r\nContact : CV + lettre de motivation à envoyer à\r\nemmanuelle.cannesson@airbus.com, nataly.n.jahchan@airbus.com,\r\nlaurent.spaggiari@airbus.com\r\n\r\n------------------------------------------------------------------------\r\n\r\nDescription of the job:\r\nAirbus (Toulouse) is looking for an intern for a 6-month internship.\r\n\r\nFlight crew alerting systems make use of aural alerts in order to warn\r\nthe crew of unexpected situations or incoming events.\r\nYou will be responsible for improving the quality and precision of aural\r\nalerts in different situations in Airbus civil aircraft.\r\n\r\nTasks & accountabilities:\r\nYour responsibilities will include:\r\n\r\n* Describing the different ways to express aurally, from a syntactical\r\n  and terminological point of view, in different languages:\r\n  - Order\r\n  - Prohibition\r\n  - Advice\r\n  - Questioning\r\n  - Normal vs. abnormal status\r\n  - Studying parameters such as intonation, accentuation, speed,\r\n    repetition, voice intensity.\r\n\r\nRequired skills:\r\nYou are completing a master degree or you are in the final year of an\r\nengineering school or of university (5th year), specialising in\r\nLinguistics, Phonetics/Phonology, Semantics/Syntax.\r\nYou ideally have initial experience in this field.\r\nYou have knowledge of:\r\n\r\n *   Linguistics\r\n *   Phonetics/phonology\r\n *   Pragmatics\r\n\r\nYou are a good team player and have excellent interpersonal skills.\r\nEnglish: Advanced level.\r\n\r\nLocalisation:\r\nAIRBUS France SAS\r\n316, route de Bayonne\r\n31060 Toulouse Cedex 03\r\n\r\nNataly JAHCHAN\r\nPhD Candidate, EYDNX\r\nHuman Factors Department\r\nPhone: +33 5 82 05 98 39\r\nNataly.n.jahchan@airbus.com'),
(282, '2015-08-19', 'Xerox Research Center Europe', 'Grenoble', 'Xerox Research Centre Europe, located in Grenoble, is offering the\r\nfollowing internship for Fall 2015:\r\n\r\n*----------------------------------------------------------------------*\r\n\r\n*Weighted tree-based transducers for natural language generation in the \r\ncontext of a dialogue system*\r\n\r\n*----------------------------------------------------------------------*\r\n\r\nSee: \r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/Weighted-tree-based-transducers-for-natural-language-generation-in-the-context-of-a-dialogue-system\r\n\r\nContact: Marc Dymetman marc.dymetman@xrce.xerox.com \r\n\r\n*Duration*: 4 to 5 months\r\n\r\n*Start Date*: As soon as possible after September 2015\r\n\r\nDescription:\r\n\r\nIn the context of a human-machine dialogue system being developed at\r\nXRCE, the internship will have aim of exploring the applicability of\r\nweighted/probabilistic finite-state tree transducers (and related\r\nformalisms such as tree-to-string transducers) to the problem of\r\ngenerating textual utterances from semantic representations produced by\r\na DM (dialogue manager).\r\n\r\nThe advantages of such transducers are that they support operations such\r\nas composition and intersection (in particular with language models),\r\nand are well-suited for reversible processing (parsing as the reverse of\r\ngeneration).\r\n\r\nThe internship will build on work done at XRCE with string-based\r\ntransducers, which it will attempt to adapt and extend towards\r\ntree-based machines, either based on external toolkits (such as Tiburon\r\n[May and Knight 2006]) or on specially developed software.\r\n\r\nThe ideal candidate should be a Computer Science student at the Master\r\nor (preferably) PhD level, with some experience of weighted tree-based\r\ntransducers (or at least string-based transducers), as well as of\r\nassociated software tools. Strong programming skills are a requirement\r\n(Python, C++, Java...). Conference publication of the work will be\r\nstrongly encouraged.\r\n\r\nPlease note that applicants must be registered students at a university\r\nor other academic institution and that this establishment will need to\r\nsign an \'Internship Convention\' with Xerox before the student is\r\naccepted.\r\n\r\nIf you would like to submit your application, please send it to\r\nmarc.dymetman@xrce.xerox.com <mailto:marc.dymetman@xrce.xerox.com> or to\r\nxrce-candidates@xrce.xerox.com <mailto:xrce-candidates@xrce.xerox.com>.\r\nPlease mention \"*Tree based transducers*\" in your subject line.'),
(283, '2015-08-19', 'EC\'s Joint Research Center', 'Ispra (Italie)', 'EUROPEAN COMMISSION JOINT RESEARCH CENTRE\r\n\r\nResources Recruitment and Training\r\n\r\n2015-IPR-G-000-5633\r\n\r\nPosition for: Trainee\r\n\r\nTerminology discovery in Disaster Risk Management for the UNISDR\r\n(Terminologist)\r\n\r\nShort description of activity:\r\n\r\nThe European Commission\'s Joint Research Centre (JRC) in Ispra,\r\nItaly, is looking for a trainee to work on a terminology project\r\nsupporting a world-wide team of specialists lead by the United\r\nNations Office for Disaster Risk Reduction (UNISDR). At the\r\nrecent UN world conference in Sendai, Japan, 187 UN member\r\nstates adopted a new 15-year framework for Disaster Risk\r\nReduction (DRR) with seven targets and four priorities of action.\r\nThe terms used in this framework must be defined clearly and\r\nunequivocally in order to achieve world-wide collaboration\r\nbetween scientists, policy makers, the private sector and\r\npractitioners in countries having a rather different DRR culture,\r\ndifferent administrative procedures and speaking different\r\nlanguages. The overall objective of this terminology project is\r\nthus to review and update the existing defining UNISDR\r\nvocabulary available at\r\nhttp://www.unisdr.org/we/inform/publications/7817.\r\n\r\nDuring the last year, the JRC has gathered and analysed DRR-\r\nrelated text collections, definitions and term usage statistics,\r\nallowing DRR specialists to understand how the terms are used in\r\nreal life in order to make informed decisions on how the terms\r\nshould be defined and how they should be distinguished from\r\nother, similar terms. The JRC did this by analysing the gathered\r\ndata using Language Technology tools and methods used in\r\nComputational Linguistics and Statistics. Results have been\r\npresented in text form, tables, using graphs and further methods\r\nfor visualisation.\r\n\r\nThe successful trainee is expected to:\r\n- continue and refine this work for English language;\r\n- to possibly expand it to Spanish and French language;\r\n- to use off-the-shelf software to automatically extract\r\nterms from the document collection and to manually\r\ncurate the results;\r\n- to produce various types of statistics on the usage of\r\nterms in different sub-corpora;\r\n- to prepare data and results for the DRR subject domain\r\nspecialists;\r\n- to prepare the meetings of expert teams;\r\n- to take minutes during the meetings;\r\n- to act upon the requests by the specialists of the expert\r\nteams and;\r\n- to summarise the discussions and the work carried out.\r\n\r\nQualifications:\r\n\r\nThe candidate should have a degree (or an almost completed\r\ndegree) somehow related to disaster risk management,\r\nterminology, computational linguistics or computer science; (b)\r\ngood knowledge of written and spoken English (B2 level); (c)\r\ngood communication skills, ability to work independently and as\r\npart of a team: and (d) good knowledge of Information\r\nTechnology-related tools and formats such as internet search\r\nengines, XML, word processing and spread sheets.\r\nFurther advantageous skills are (e) knowledge of other European\r\nlanguages, especially Spanish and French; (f) experience with\r\nterminology and the preparation of definitions; and (g)\r\nknowledge of the field of DRR, Disaster Risk Management or\r\nsimilar areas and (h) some programming skills to process and\r\nhandle large corpora, convert data formats, etc.\r\n\r\nIn your application, please state your interests and please\r\nprovide clear information on your skill set, by elaborating on the\r\nabove-mentioned list of requirements and by listing your level of\r\nlanguages and your computer / programming skills.\r\n\r\n\r\nThe Joint Research Centre (JRC; http://ec.europa.eu/dgs/jrc/) is the\r\nscientific-technical arm of the European Commission. The approximately\r\n2200 JRC employees working in Ispra are from all EU countries and\r\nthere are also some non-EU visitors. The working environment is\r\nmultilingual, multi-cultural and multi-disciplinary. The JRC\'s Europe\r\nMedia Monitor (EMM) team carries out research and development in the\r\nfield of highly multilingual text mining (Language Technology;\r\nComputational Linguistics) for the purposes of media monitoring.  EMM\r\ngathers an average of over 200,000 online news articles per day in\r\nover 70 languages and analyses them to help its large international\r\nuser community understand and use this enormous amount of media\r\ninformation. EMM is publicly accessible via\r\nhttp://emm.newsbrief.eu/overview.html.  See also\r\nhttps://ec.europa.eu/jrc/en/research-topic/internet-surveillance-\r\nsystems and https://ec.europa.eu/jrc/en/language-technologies.  For\r\ngeneral eligibility requirements, please read the rules governing the\r\ntraineeship scheme of the JRC:\r\nhttps://ec.europa.eu/jrc/en/working-with-us/jobs/temporary-positions/jrc-trainees \r\n\r\n\r\nduration 5 months \r\nPreferred starting date  As soon as possible \r\n\r\n\r\nApplication:\r\nhttp://recruitment.jrc.ec.europa.eu/'),
(284, '2015-09-16', 'Ecoles des Mines d\'Ales', 'Nîmes', 'Proposition de sujet de stage dans l\'équipe KID du laboratoire LGI2P à\r\nNîmes de l\'Ecole des Mines d\'Ales\r\n\r\nEXTRACTION DE COMMUNAUTÉS RECOUVRANTES PAR COMPLÉMENTARITÉ ET ÉQUILIBRE\r\nDE NASH DANS LES RÉSEAUX SOCIAUX\r\n\r\nEncadrants : Michel Plantié\r\n\r\nLaboratoire et équipe : LGI2P de l\'EMA, équipe KID (Knowledge and Image\r\nfor Decision making)\r\n\r\nLieu : Nîmes, site EERIE, parc Georges Besse, 30000 Nîmes\r\n\r\nSujet\r\n\r\nLes réseaux sociaux occupent une part de plus en plus importante dans\r\nl\'échange de données sur le web. La recommandation de produits et de\r\nservices, les modèles utilisateurs enrichis par des données sociales\r\npeuvent revêtir une grande importance.\r\n\r\nLa recherche de communautés dans les graphes est un problème ancien, et\r\nla grande majorité des techniques utilisées cherchent à optimiser les\r\ntemps de calcul de ces communautés et le meilleur arrangement possible\r\nde ces communautés selon des critères de cohésion ou de modularité,\r\netc.[1][2][3][4]\r\n\r\nLa signification et la stabilité de ces communautés ainsi constituées\r\nn\'est que peu abordée dans les travaux actuels. Les auteurs appliquent\r\nun algorithme unique d\'optimisation et observent ensuite les\r\nperformances.\r\n\r\nLe recouvrement revêtant des fondements sémantiques importants sont peu\r\nétudiés. Plusieurs auteurs dont Roth [5] en construisant des communautés\r\népistémiques ont abordé le sujet. De même la stabilité et la répartition\r\néquitable et équilibrée des personnes dans les communautés sont peu\r\nétudiés. Nos travaux récents montrent la possibilité d\'obtenir un\r\néquilibre de Nash dans les constructions des communautés [6].\r\n\r\nLa complémentarité est une problématique intéressante pour montrer la\r\ncouverture sémantique de communautés.\r\n\r\nNous nous intéressons à ce champ de recherche qui pose de nombreuses\r\nquestions théoriques et pratiques.\r\n\r\nLe sujet proposé a les objectifs suivants :\r\n\r\n- Après un état de l\'art, étudier et compléter les définitions de la\r\n  complémentarité adaptée à la détection de communautés dans des grands\r\n  volumes de données de graphes provenant des réseaux sociaux\r\n\r\n- Etudier la stabilité et la complémentarité de communautés extraites à\r\n  partir de données sociales\r\n\r\n- rechercher les optimums de stabilité et d\'équilibre tout en tenant\r\n  compte de leur sémantique.\r\n\r\n- Approfondir les travaux de recherche de complémentarité de communautés\r\n  recouvrantes.\r\n\r\n[1] Papadopoulos, Y. Kompatsiaris, A. Vakali, and P. Spyridonos,\r\n\"Community detection in Social Media,\" Data Mining and Knowledge\r\nDiscovery, no. June, pp. 1-40, 2011.\r\n\r\n[2] M. F. Porter, \"An algorithm for suffix stripping,\" Program, pp. pp\r\n130-137, 1980.\r\n\r\n[3] B. Yang, D. Liu, J. Liu, and B. Furht, Discovering communities from\r\nSocial Networks: Methodologies and Applications. Boston, MA: Springer\r\nUS, 2010, pp. 331-346.\r\n\r\n[4] S. Fortunato, \"Community detection in graphs,\" Physics Reports,\r\nvol. 486, no. 3-5, p. 103, Jun. 2009.\r\n\r\n[5] C. Roth and P. Bourgine, \"Epistemic Communities: Description and\r\nHierarchic Categorization,\" Mathematical Population Studies: An\r\nInternational Journal of Mathematical Demography, vol. 12, no. 2, pp.\r\n107-130, 2005.\r\n\r\n[6] Michel Crampes and Michel Plantié, \"A Unified Community Detection,\r\nVisualization and Analysis method. Advanced Complex Systems, World\r\nScientific Publishing, Imperial College Press, 2013.\r\n\r\n[7] Michel Crampes and Michel Plantié, Organisation de communautés et\r\nEquilibre de Nash, IC - 25èmes Journées francophones d\'Ingénierie des\r\nConnaissances, France (2014)\r\n\r\n=====================================================\r\nDr. Michel Plantié - +33 466387035\r\nEnseignant-Chercheur Laboratoire LGI2P\r\n\r\nEcole des Mines d\'Ales, Institut Mines-Télécom\r\nParc scientifique Georges Besse, 30035 Nîmes Cedex 1\r\nwww.socialnetworks.wp.mines-telecom.fr\r\n====================================================='),
(285, '2015-09-23', 'Syllabs', 'Paris', '---------------------------\r\nOffre de stage TAL : Analyse de tonalité\r\n---------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en création automatique\r\nde textes. Nos technologies sont le fruit d\'années de développement et\r\nmaîtrisent toutes les étapes du processus d\'analyse de données\r\ntextuelles du Web : identification des pages pertinentes, extraction et\r\ncatégorisation des informations clés.\r\nLe stage s\'inscrit dans le cadre d\'un projet de recherche portant sur\r\ntourisme. L\'objectif de ce projet est de produire un tableau de bord\r\npermettant aux professionnels du tourisme de s\'informer sur l\'état du\r\ntourisme sur leur territoire.\r\nL\'objet principal de ce stage sera de construire des modules\r\nd\'extraction d\'information à l\'aide d\'un langage développé en\r\ninterne. Ces modules seront destinés à l\'analyse de tonalité d\'objets\r\ntouristiques (monuments, musées) à partir d\'avis d\'internautes.\r\n\r\n---------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent:\r\n- Étude de corpus\r\n- Définition des caractéristiques des objets touristiques\r\n- Extraction d\'information (tonalité)\r\n- Scripts de manipulation des données\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Expérience en extraction d\'information\r\n- Connaissances en morphosyntaxe et syntaxe\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail\r\n  d\'équipe\r\n- Bon niveau en python serait un plus\r\n\r\n-----------------\r\nDiplôme et expérience\r\n-----------------\r\n- Formation en cours : Linguistique Informatique ou similaire\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage extraction tourisme»\r\nLieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris (métro\r\nRépublique)\r\nContrat : stage à temps partiel. Début : courant octobre'),
(286, '2015-10-05', 'DGLFLF', 'Paris', 'La Délégation générale à la langue française et aux langues de France\r\n(ministère de la Culture et de la Communication) propose un stage d\'une\r\ndurée de deux à trois mois entre octobre et décembre 2015, au sein de la\r\nmission des langues et du numérique.\r\n\r\nLe stagiaire participera à la rédaction, relecture et mise en page de\r\nplusieurs publications de la mission portant notamment sur les langues\r\nrégionales et les technologies du langage, et sur la saisie du français\r\nsur les claviers. Il participera à l\'animation d\'un réseau d\'experts sur\r\nces sujets et recueillera des contributions externes pour ces projets.\r\nIl contribuera à l\'organisation d\'un colloque sur la thématique du\r\ntraitement automatisé des langues régionales de France en 2016.\r\n\r\nSes autres missions consisteront, en lien avec le chef de la mission, à \r\nanimer les pôles \"technologies de la langue\" et \"diversité linguistique\" \r\nau sein de la mission des langues et du numérique, à suivre les projets \r\nréalisés en partenariat ou avec le soutien de la délégation dans ce \r\ndomaine et à produire de l\'information à ce sujet sur notre site internet.\r\n\r\nProfil recherché\r\n\r\n- Étudiant en Master 2 en linguistique, politiques linguistiques, TAL ou\r\n  traduction\r\n- Des compétences rédactionnelles de bon niveau sont requises ainsi que\r\n  des aptitudes à travailler en équipe.\r\n- Une première expérience professionnelle dans le domaine est un plus\r\n- Un intérêt pour les langues en général, la langue française et les\r\n  langues régionale en particulier est vivement conseillé.\r\n\r\nPoste à pourvoir immédiatement\r\nLieu de travail : Paris Palais Royal (1er arrdt.)\r\nStage conventionné à temps plein\r\nIndemnité de stage de 554,40 euros par mois\r\nCandidatures / informations : thibault.grouas@culture.gouv.fr\r\n\r\nà propos de la DGLFLF\r\n\r\nLa délégation générale à la langue française et aux langues de France\r\n(DGLFLF) est chargée d\'animer et de coordonner la politique linguistique\r\ndu Gouvernement et d\'orienter son évolution dans un sens favorable au\r\nmaintien de la cohésion sociale et à la prise en compte de la diversité\r\nde notre société.\r\n\r\nService à vocation interministérielle directement rattaché au ministre\r\nchargé de la culture, la DGLFLF est constituée d\'une trentaine d\'agents\r\net mobilise pour son action un ensemble de partenaires, publics ou\r\nprivés, impliqués dans la promotion du français et de la diversité\r\nlinguistique.\r\n\r\nà propos de la mission des langues et du numérique de la délégation\r\n\r\nhttp://www.culturecommunication.gouv.fr/Politiques-ministerielles/Langue-francaise-et-langues-de-France/Politiques-de-la-langue/Langues-et-numerique \r\n\r\n*Thibault GROUAS*\r\nChef de la mission des langues et du numérique\r\nDélégation générale à la langue française et aux langues de France\r\n6, rue des Pyramides\r\n75001 PARIS\r\ntél : 01 40 15 35 90\r\ntlc : 01 40 15 36 76\r\nwww.dglf.culture.gouv.fr'),
(287, '2015-10-05', 'Syllabs', 'Paris', '---------------------------\r\nOffre de stage TAL : Génération automatique de textes\r\n---------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en génération\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse de\r\ndonnées textuelles du Web : identification des pages pertinentes,\r\nextraction et catégorisation des informations clés. La génération est\r\nproposée au travers de sa solution Data2Content (data2content.fr) qui\r\npermet, à partir d\'une base de données structurées, de générer\r\nautomatiquement des textes de qualité humaine.\r\n\r\nC\'est dans le cadre de Data2Content que nous recherchons des ingénieurs\r\nlinguistes pour un stage dans le domaine de la création automatique de\r\ntextes en anglais, français, espagnol, néerlandais, portugais, italien\r\net allemand.\r\nL\'objet principal du stage est de travailler sur le paramétrage de notre\r\noutil de génération (écriture de règles) dans votre langue\r\nmaternelle. Les domaines d\'application peuvent par exemple être le\r\ne-commerce (descriptifs de produits), le tourisme (par exemple,\r\ndescriptif d\'un hôtel) ou les médias (brève sur les résultats des\r\nélections, etc.).\r\n\r\n---------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent:\r\n\r\n- Génération automatique de textes : paramétrage de l\'outil de\r\n  génération en fonction du projet, participation aux tests et à\r\n  l\'amélioration de l\'outil.\r\n- Ecriture de scripts pour la manipulation des bases de données en\r\n  entrée du moteur de génération.\r\n\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 ou Master 1 en Linguistique Informatique\r\n  ou similaire\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail en\r\n  équipe\r\n- Programmation en Python\r\n- Compétences en rédaction web seraient un plus\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 6 mois rémunéré en fonction du niveau d\'étude +\r\ntickets resto + remboursement à moitié du pass Navigo (transport)\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage génération + (langue) » (Ex: stage\r\ngénération anglais)\r\n\r\nLieu : Syllabs, 82 rue du Faubourg Saint-Martin, 75010 Paris (M°\r\nStrasbourg-Saint-Denis ou Gare de l\'Est)\r\nContrat : stage. Début : janvier-mars 2016.'),
(288, '2015-10-15', 'CEA', 'Saclay', 'Voici trois sujets de stage de M2 rÃ©munÃ©rÃ©s proposÃ©s par le Laboratoire\r\nVision et IngÃ©nierie des Contenus (CEA Tech, UniversitÃ© Paris Saclay) et\r\nportant sur:\r\n\r\n1. Ã‰valuation et amÃ©lioration d\'un moteur de recherche sÃ©mantique ;\r\n2. Ajout du support de nouvelles langues Ã  l\'analyseur linguistique LIMA ;\r\n3. Ã‰valuation d\'analyseurs linguistiques du Chinois.\r\n\r\nMerci de me contacter pour plus d\'informations.\r\n\r\nCordialement,\r\n\r\nGaÃ«l de Chalendar\r\n01.69.08.01.50\r\ngael.de-Chalendar@cea.fr\r\n\r\n\r\n=============================================\r\n1. Ã‰valuation et amÃ©lioration d\'un moteur de recherche sÃ©mantique\r\n\r\nDans le cadre du projet ANR Asfalda, le laboratoire LVIC du CEA LIST a\r\nÃ©tendu son moteur de recherche crosslingue AMOSE pour lui donner des\r\ncapacitÃ©s d\'indexation et de recherche exploitant des informations\r\nsÃ©mantiques issues d\'outils de Semantic Role Labeling.\r\n\r\nL\'objectif premier du stage sera d\'Ã©valuer l\'impact de l\'intÃ©gration de\r\nla sÃ©mantique sur les rÃ©sultats de recherche. Le second objectif sera\r\nd\'amÃ©liorer le moteur de recherche au vu des rÃ©sultats d\'Ã©valuation.\r\n\r\nAMOSE est un moteur de recherche crosslingue. Il repose sur l\'analyseur\r\nlinguistique libre Lima [1] qui reconnaÃ®t les termes nominaux complexes\r\n(Multi Word Expressions ou MWE en anglais). Ces termes complexes repÃ©rÃ©s\r\ndans les documents et les requÃªtes sont utilisÃ©s pour grouper les\r\ndocuments rÃ©sultats en classes d\'Ã©quivalence en fonction des termes de\r\nla requÃªte qu\'ils contiennent.\r\n\r\nLIMA a rÃ©cemment Ã©tÃ© enrichi d\'un module effectuant de l\'annotation en\r\nrÃ´les sÃ©mantiques (Semantic Role Labeling) et AMOSE a Ã©tÃ© modifiÃ© pour\r\nindexer et utiliser dans la recherche les classes repÃ©rÃ©es et leurs\r\nrÃ´les.\r\n\r\nLe travail du stagiaire consistera Ã  Ã©valuer la nouvelle version d\'AMOSE\r\nsur les campagnes d\'Ã©valuation classiques (CLEF, TREC) dont le\r\nlaboratoire possÃ¨de les donnÃ©es et Ã  rechercher quelles campagnes plus\r\nciblÃ©es sur la recherche sÃ©mantique pourraient exister et mettre en\r\noeuvre AMOSE sur leurs donnÃ©es. Si une telle campagne a lieu durant le\r\nstage, le laboratoire y participera.\r\n\r\nCes Ã©valuations fourniront des informations permettant de mettre Ã  jour\r\ndes pistes d\'amÃ©lioration. Le stagiaire les documentera et en mettra\r\ncertaines en oeuvre.\r\n\r\n=============================================\r\n2. Ajout du support de nouvelles langues Ã  l\'analyseur linguistique LIMA\r\n\r\nLe laboratoire LVIC a dÃ©veloppÃ© un analyseur linguistique multilingue\r\nnommÃ© LIMA (LIST Multilingual Analyzer) [2]. LIMA a Ã©tÃ© placÃ© sous\r\nlicence libre (AGPL) dÃ©but 2014 [1]. Ã€ cette occasion, des ressources\r\nlinguistiques libres ont Ã©tÃ© collectÃ©es et adaptÃ©es pour le franÃ§ais et\r\nl\'anglais [3]. Mais LIMA supporte bien d\'autres langues. Le laboratoire\r\ndispose par exemple de ressources propriÃ©taires qu\'il n\'a pas le droit\r\nde redistribuer sous licence libre pour des langues telles que chinois,\r\narabe, allemand, espagnol, italien, etc. L\'objectif de ce stage est de\r\ncollecter et adapter Ã  LIMA des ressources libres pour de nouvelles\r\nlangues. On commencera par des langues latines, en particulier le\r\nportugais (dans ses variantes portugaise et brÃ©silienne), l\'espagnol et\r\nl\'italien.\r\n\r\nLe travail du stagiaire consistera Ã  :\r\n- se familiariser avec LIMA, son fonctionnement, ses ressources\r\n  linguistiques et leur production ;\r\n- rechercher et sÃ©lectionner les ressources libres nÃ©cessaires pour les\r\n  langues sÃ©lectionnÃ©es ;\r\n- adapter les ressources choisies et les intÃ©grer au processus de\r\n  gÃ©nÃ©ration de LIMA.\r\n\r\nLes ressources concernÃ©es sont:\r\n- automate de tokenisation ;\r\n- jeu d\'Ã©tiquettes grammaticales ;\r\n- dictionnaire de lemmes ou full-form ;\r\n- dictionnaire \r\n- corpus annotÃ© pour l\'apprentissage de modÃ¨les de dÃ©sambiguÃ¯sation\r\n  morphosyntaxique ;\r\n- rÃ¨gles (grammaire) pour l\'analyse syntaxique ;\r\n- rÃ¨gles de reconnaissance d\'entitÃ©s nommÃ©es.\r\n\r\nBien entendu, il ne sera pas possible d\'obtenir Ã  l\'issue d\'un tel stage\r\nun ensemble complet de toutes les ressources pour toutes les langues\r\nenvisagÃ©es.  L\'objectif sera de fournir une base utilisable pouvant Ãªtre\r\nÃ©tendue par la suite.\r\n\r\n\r\n=============================================\r\n3. Ã‰valuation d\'analyseur linguistiques du Chinois\r\n\r\nLe laboratoire LVIC a dÃ©veloppÃ© un analyseur linguistique multilingue\r\nnommÃ© LIMA (LIST Multilingual Analyzer) [1,2,3]. Son support de la\r\nlangue chinoise n\'a pas Ã©tÃ© mis Ã  jour depuis de longues annÃ©es. Depuis,\r\nde nouveaux analyseurs ont Ã©tÃ© dÃ©veloppÃ©s et ont atteint des niveaux de\r\nperformance bien plus Ã©levÃ©s. Nous dÃ©sirons Ã©valuer un certains nombre\r\nde ces outils, aussi bien du point de vue de leur qualitÃ©s intrinsÃ¨ques\r\nque de leurs possibilitÃ©s d\'intÃ©gration avec LIMA. Le travail du\r\nstagiaire consistera Ã  mettre en oeuvre ces outils, les Ã©valuer Ã \r\ndiffÃ©rents niveaux (vitesse, qualitÃ© de segmentation, dÃ©sambiguÃ¯sation\r\nmorphosyntaxique, analyse syntaxique, entitÃ©s nommÃ©es, etc.) Ã  l\'aide de\r\ncorpus de rÃ©fÃ©rence et enfin Ã  expÃ©rimenter leur intÃ©gration.\r\n\r\nLIMA est dÃ©veloppÃ© en C++. Certains outils le sont aussi et\r\nl\'intÃ©gration peut alors se faire en adaptant les APIs. D\'autres sont en\r\nJava ou en Python. Il faudra alors choisir entre une intÃ©gration de bas\r\nniveau (JNI...) ou en tant que module externe. Les critÃ¨res de choix sont\r\nlÃ  la complexitÃ© de la mise en oeuvre vs. les performances.\r\n\r\n\r\n=============================================\r\nRÃ©fÃ©rences\r\n\r\n[1] https://github.com/aymara/lima/wiki\r\n[2] R. Besanc Ì§on, G. de Chalendar, O. Ferret, F. Gara, M. Laib,\r\nO. Mesnard, and N. Semmar. 2010. Lima: A multilingual framework for\r\nlinguistic analysis and linguistic resources development and\r\nevaluation. In Proceedings of LREC, Malta.\r\n[3] G. de Chalendar. 2014. The LIMA Multilingual Analyzer Made Free :\r\nFLOSS Resources Adaptation and Correction. In Proceedings of the Ninth\r\nInternational Conference on Language Resources and Evaluation\r\n(LREC-2014), Reykjavik, Iceland, May 26-31, 2014., pages 2932-2937.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(289, '2015-11-09', 'INALCO', 'Paris', 'Appel à candidature : stage TAL langues peu dotées, 4 à 6 mois\r\nObjet : recherche, inventaire et analyse d\'outils de TAL langues peu\r\ndotées\r\nEmployeur : Institut National des Langues et Civilisations Orientales\r\n(INALCO)\r\nContrat : Stage M1 ou M2 de 4 à 6 mois\r\nLieu de Travail : Paris 7e \r\nRémunération : Rémunération 554 euros + 35 de prise en charge partiel des\r\ntransport IdF\r\nDate de début : janvier ou avril suivant les échéances universitaires\r\n\r\nDESCRIPTION DU POSTE\r\n\r\nDans le cadre du projet MultiTAL (Plateforme de documentation et\r\nd\'expertise des outils et ressources pour le traitement automatique des\r\nlangues orientales et des langues peu dotées), l\'ERTIM (INALCO) recrute\r\ncinq stagiaires en TAL langues peu dotées.\r\n\r\nContexte : Il existe un nombre significatif d\'outils de traitement\r\nautomatique des langues peu dotées qui demeurent mal connus, mal\r\nréférencés, et dont la documentation est parfois lacunaire voire\r\ninexistante. Déjà difficiles d\'accès pour les TAListes avertis, ils sont\r\npratiquement inaccessibles à d\'autres utilisateurs pour lesquels ils\r\nconstitueraient des instruments utiles. L\'objectif du projet est de\r\nmettre à la disposition d\'une communauté de non-spécialistes des\r\ndocumentations actualisées et une expertise technique indépendantes\r\nrelatives aux ressources linguistiques et aux outils de fouille de\r\ntextes. A terme, la plateforme permettra de constituer une base de\r\nconnaissances structurée, évolutive et accessible en ligne qui\r\ns\'adressera non pas aux seuls linguistes, mais aux chercheurs,\r\nuniversitaires non spécialistes (sciences sociales, sciences politiques)\r\nou industriels (veilleurs, etc.) amenés à manipuler des données\r\ntextuelles massives ou complexes à des fins de fouille de textes.\r\n\r\nLes stagiaires recrutés auront pour mission d\'identifier, de tester, de\r\ndécrire et de documenter des outils pour le traitement automatique des\r\nlangues qu\'ils maîtrisent.\r\n\r\nPROFIL ATTENDU\r\n\r\n- M1 ou M2 en traitement automatique des langues\r\n\r\nCOMPÉTENCES REQUISES \r\n\r\n- compétence linguistique en une ou plusieurs langues du domaine INALCO\r\n  (par exemple : arabe(s), chinois, coréen, japonais, persan, thaï,\r\n  turque, etc.)\r\n- expériences des outils de TAL,\r\n- maîtrise des environnements : Linux et Windows\r\n- bonnes connaissances des mécanismes d\'installation, compilation,\r\n  gestionnaires de paquets,\r\n- familiarité avec des langages de programmation : Perl / Python, Java,\r\n  C++, etc.\r\n\r\nMODALITÉS DU PROJET\r\n\r\nLes stages peuvent commencer entre janvier et avril.\r\n\r\nLes travaux se dérouleront à la maison de la recherche de l\'INALCO : 2\r\nrue de Lille 75007 Paris.\r\nLe traitement comprend l\'indemnité de stage (554 ¤) et la prise en\r\ncharge partielle des frais de transport Ile-de-France (35 ¤).\r\n\r\nLes candidats sont invités à prendre contact à l\'adresse\r\nmvalette@inalco.fr ou à envoyer directement une lettre de motivation et\r\nun CV détaillé par mail.\r\n\r\n-------------------------------------------------------------------------'),
(290, '2015-11-12', 'LIRMM', 'Montpellier', 'Titre : Déploiement d\'une plate-forme web d\'analyse de documents pour\r\nidentifier les caractéristiques des réseaux d\'assainissement\r\n\r\nMots-clés : traitement automatique de la langue, fouille de données\r\n\r\nContexte : Le stage se déroulera dans le cadre du projet Cart\'eaux porté\r\npar le laboratoire HydroSciences Montpellier. Ce projet vise la fusion\r\nde données pour la cartographie de réseaux enterrés, notamment les\r\nréseaux d\'assainissement. Il s\'agit d\'une problématique importante à la\r\nfois dans de les pays développés et ceux en voie de développement car\r\nsouvent les réseaux sont mal identifiés.\r\n\r\nObjectifs : Internet recèle de nombreux documents, rapports publics et\r\nweb services susceptibles de contenir une description des interventions\r\nsur les réseaux d\'assainissement (e.g. travaux, entretien,\r\nréparation). L\'objectif de ce stage est de mettre en oeuvre des\r\ntechniques de fouille de données et recherche d\'information sur Internet\r\npour tout d\'abord découvrir des documents dans différents formats\r\n(textes html, pdf, images, plans numérisés) et successivement identifier\r\net extraire un maximum d\'informations expertes sous la forme d\'attributs\r\nliées aux objets du réseau d\'assainissement (e.g. retrouver dans un\r\nrapport d\'intervention, le diamètre d\'une bouche d\'égout, ou encore\r\nretrouver la position géographique d\'une intervention). Il sera\r\nimportant d\'associer à chaque information extraite des textes un indice\r\nde confiance qui aidera l\'expert à décider s\'il conserve ou non\r\nl\'information. Le lien ci-dessous illustre un exemple de rapport\r\ncontenant des attributs intéressants dans le cadre de nos travaux :\r\nhttp://www.a3w.fr/Donnees/Structures/81497/Upload/247221.pdf\r\n\r\nActions à mener : Dans le cadre de ce stage, l\'étudiant devra concevoir\r\nune plateforme permettant aux experts de récolter et d\'analyser des\r\ndocuments pour compléter leurs connaissances sur les réseaux\r\nd\'assainissement. Plusieurs aspects sont à considérer :\r\n\r\n1/ Récolter sur le Web différents types de documents de manière\r\n   automatique, qui parlent des bouches d\'égouts et des réseaux\r\n   d\'assainissement.\r\n2/ Catégoriser ces documents par type (e.g. rapport d\'interventions,\r\n   article de presse, appel d\'offre, forum techniques ou réactions à des\r\n   évènements).\r\n3/ Détecter dans les textes des informations géographiques (e.g. au nord\r\n   de la route R12 allant de Montpellier à Lunel), des dates\r\n   (e.g. l\'appel d\'offre signé du 12 mai), des caractéristiques sur les\r\n   bouches d\'égouts et sur les réseaux d\'assainissement (e.g. le\r\n   diamètre des plaques, la profondeur...). Il sera nécessaire\r\n   d\'associer les informations détectées avec un niveau de confiance.\r\n4/ Proposer une visualisation pour mettre en évidence ces informations\r\n   dans les textes.\r\n5/ Structurer de façon automatique, lorsque la confiance est forte, ces\r\n   informations dans un format utilisable (e.g. table attributaire) par\r\n   les experts.\r\n\r\nDéroulement du stage : Le stage d\'une durée de 4 à 6 mois se déroulera\r\ndans les locaux du LIRMM à Montpellier et sera amené à se déplacer dans\r\nle laboratoire HydroSciences de Montpellier pour discuter avec les\r\nexperts.\r\n\r\nCompétences requises : \r\n- Développement web (HTML, Javascript, webGL, java)\r\n- Notions de fouille de données\r\n- Outils de traitements automatiques de la langue\r\n- Développement d\'interfaces\r\n- Une bonne connaissance des API Google ou Yahoo est un plus\r\n\r\nEncadrement\r\n- Informatique\r\n  *Sandra Bringay - MCF Université de Montpellier 3 - sandra.bringay@lirmm.fr\r\n  *Maguelonne Teisseire, DR TETIS - maguelonne.teisseire@teledetection.fr\r\n- Hydrologie\r\n  *Nanée Chahinian - CR IRD - chahinian@msem.univ-montp2.fr\r\n  *Carole Delenne - MCF Université de Montpellier - carole.delenne@umontpellier.fr\r\n\r\nContacts\r\n* Sandra Bringay - MCF Université de Montpellier 3 - sandra.bringay@lirmm.fr\r\n* Maguelonne Teisseire, DR TETIS - maguelonne.teisseire@teledetection.fr'),
(291, '2015-11-12', 'LATTICE', 'Paris', 'Voici trois sujets de stage de M2 en TAL proposés par le laboratoire\r\nLattice (Langues, Textes, Traitements Informatiques, Cognition,\r\nhttp://www.lattice.cnrs.fr, Montrouge, tout près de Paris) dans le cadre\r\ndu projet ANR DEMOCRAT (description et modélisation des chaînes de\r\nréférence : outils pour l\'annotation de corpus et le traitement\r\nautomatique) en collaboration avec les laboratoires LILPA (Strasbourg)\r\net ICAR (Lyon) :\r\n\r\n1. Identification automatique de mentions référentielles\r\n2. Analyse en corpus de chaînes de référence\r\n3. Continuité référentielle et saillance : étude et modélisation\r\n\r\nLa durée est de 4 à 6 mois, à partir de février ou mars 2016, et la\r\nrémunération au tarif stage de 554 euros mensuels.  Merci deme contacter\r\npour plus d\'informations et pour candidater (CV + lettre de motivation) :\r\nmailto:frederic.landragin@ens.fr\r\n\r\nCordialement,\r\nFrédéric Landragin.\r\nhttp://www.lattice.cnrs.fr/Frederic-Landragin/\r\n\r\n________________________________________________________________________\r\n\r\n\r\n1. Identification automatique de mentions référentielles\r\n\r\nLa reconnaissance des chaînes de coréférences dans les textes,\r\nc\'est-à-dire des portions de textes qui réfèrent à une même entité, est\r\nune tâche importante du TAL. Elle a des incidences sur de nombreuses\r\nautres tâches, comme la recherche et l\'extraction d\'information, le\r\nrésumé automatique, etc. Cette tâche a fait l\'objet de nombreux\r\nchallenges mais, faute de données de référence en français, ils\r\nportaient jusqu\'à présent principalement sur des textes en anglais. L\'an\r\ndernier, la diffusion du corpus ANCOR (ANaphore et Coréférence dans les\r\nCorpus ORaux), constituéd\'un ensemble de transcriptions du français\r\nparlé annotées en coréférences, a permis de lancer des premières\r\nexpériences sur le français. Elles ont donné lieu à un premier système,\r\nCROC (Coreference Resolution for Oral Corpus), entraîné par\r\napprentissage automatique sur ANCOR (Désoyer at al. 2015). Mais ce\r\nsystème est encore rudimentaire : il fait l\'hypothèse que les mentions\r\nd\'entités ont été préalablement reconnues dans les textes et se contente\r\ndonc de prédire leur regroupement en entités coréférentes. Pour enrichir\r\net améliorer ce système, plusieurs travaux sont envisagés :\r\n\r\n- reconnaître automatiquement les mentions référentielles, qui\r\n  coïncident plus ou moins avec les groupes nominaux,\r\n- identifier automatiquement les données nécessaires en entrée de CROC,\r\n- reprendre les expériences qui ont donné lieu à CROC pour essayer\r\n   d\'améliorer ses performances.\r\n\r\nLa méthodologie employée fera dans tous les cas appel à de\r\nl\'apprentissage automatique supervisé (méthodes de classification ou\r\nd\'annotation). Le stage sera co-encadré par Frédéric Landragin, Isabelle\r\nTellier (isabelle.tellier@univ-paris3.fr) et Marco Dinarelli\r\n(marco.dinarelli@ens.fr).\r\n\r\nCompétences requises :\r\n- stage de niveau M2 en informatique ou en ingénierie linguistique ou\r\n  école d\'ingénieur,\r\n- compétences en informatique : programmation, langage de script,\r\n  manipulation de corpus,\r\n- intérêt pour le traitement automatique des langues,\r\n- des compétences en apprentissage automatique seraient un plus.\r\n\r\nRéférences :\r\nDésoyer A, Landragin F, Tellier I, Lefeuvre A, Antoine J-Y, \"Les\r\n   coréférences à l\'oral : une expérience d\'apprentissage automatique\r\n   sur le corpus ANCOR\", Traitement Automatique des Langues (TAL) 55(2),\r\n   http://www.atala.org/-Volume-55-, 2014.\r\nLandragin F, Schnedecker C (Eds.) \"Les chaînes de référence\", Langages\r\n   195, numéro de septembre 2014.\r\nLefeuvre A, Antoine J-Y, Schang E, \"Le corpus ANCOR_Centre et son outil\r\n   de requêtage : application à l\'étude de l\'accord en genre et en\r\n   nombre dans les coréférences et anaphores en français parlé\", Actes\r\n   4éme Congrès Mondial de Linguistique Française (CMLF 2014), 2014.\r\n\r\n________________________________________________________________________\r\n\r\n\r\n2. Analyse en corpus de chaînes de référence\r\n\r\nUne fois annotées en corpus, les chaînes de référenceconstituent des\r\nensembles de mentions - désignant le même objet ou le même personnage\r\nhumain - couvrant potentiellement toute la longueur du texte. Elles se\r\ndistinguent ainsi d\'autres objets linguistiques plus locaux : quand on\r\ntente de caractériser une chaîne de référence, on doit tenir compte non\r\nseulement des types de mentions qu\'elle regroupe, mais aussi de sa\r\ntendance à être présente dans tout le texte ou seulement dans quelques\r\npassages. Une analyse rationnelle des chaînes de références implique\r\ndonc, en plus des classiques décomptes et calculs de fréquences, des\r\ncalculs statistiques plus complexes. Le but de ce stage est de mettre en\r\nplace et de tester une méthodologie d\'analyse numérique des chaînes de\r\nréférence. Plusieurs travaux sont envisagés :\r\n\r\n- analyser deux corpus déjà annotés en chaînes de référence,\r\n- écrire des scripts pour calculer à partir des données annotées un\r\n  ensemble d\'indicateurs numériques (en partant d\'une spécification et\r\n  d\'une revue de travaux en statistique textuelle),\r\n- annoter un corpus de test et mettre à l\'épreuve la méthodologie\r\n  proposée.\r\n\r\nCompétences requises :\r\n- stage de niveau M2 en informatique ou en ingénierie linguistique ou\r\n  école d\'ingénieur,\r\n- compétences en informatique : programmation, langage de script,\r\n  manipulation de corpus,\r\n- intérêt pour le traitement automatique des langues,\r\n- des compétences en statistique seraient un plus.\r\n\r\nRéférences :\r\nLandragin F, \"Anaphores et coréférences : analyse assistéepar\r\n   ordinateur\", In: Fossard M, Béguelin M-J, Nouvelles perspectives sur\r\n   l\'anaphore. Points de vue linguistique, psycholinguistique et\r\n   acquisitionnel, Peter Lang, Berne, 2014.\r\nLandragin F, Tanguy N. & Charolles M, \"Références aux personnages dans\r\n   L\'occupation des sols : apport de la linguistique outillée\", Revue\r\n   Sciences/Lettres 3, http://rsl.revues.org/816, 2015.\r\n\r\n________________________________________________________________________\r\n\r\n\r\n3. Continuité référentielle et saillance : étude et modélisation\r\n\r\nLorsque plusieurs phrases consécutives d\'un texte parlent d\'un même\r\nréférent, par exemple un personnage humain, celui-ci en devient saillant\r\n: il occulte l\'attention du lecteur, ce qui a pour conséquence d\'en\r\nfaire un candidat idéal à l\'interprétation de pronoms tels que\r\n\"il\". Définie ainsi, la notion de saillance est en lien direct avec la\r\ncontinuité référentielle, c\'est-à-dire la \"domination\" d\'une chaîne de\r\nréférence sur l\'ensemble des chaînes présentes dans le texte (une chaîne\r\npar personnage mentionné). Le but de ce stage est d\'explorer ce lien et\r\nde proposer un modèle de la saillance tourné vers les références à des\r\nhumains dans des textes narratifs tels que des nouvelles de\r\nMaupassant. Pour ce faire, la méthodologie employée sera celle de la\r\nlinguistique de corpus. Plusieurs travaux sont envisagés :\r\n\r\n- expérimenter diverses propositions de schémas d\'annotation combinant\r\n  saillance et chaînes de référence,\r\n- annoter un corpus regroupant plusieurs nouvelles de taille comparable,\r\n- utiliser des outils d\'interrogation de corpus et écrire des scripts\r\n  pour extraire des annotations réalisées des observations qualitatives\r\n  et quantitatives.\r\n\r\nCompétences requises :\r\n- stage de niveau M2 en linguistique ou ingénierie linguistique,\r\n- compétences en linguistique : (co)référence, linguistique du discours,\r\n- des compétences en informatique (manipulation de corpus, langage de\r\n  script) seraient un plus.\r\n\r\nRéférences :\r\nLandragin F, Schnedecker C (Eds.) \"Les chaînes de référence\", Langages\r\n   195, numéro de septembre 2014.\r\nBoisseau M., Hamm A. (Eds.) \"Saillance. La saillance en langue et en\r\n   discours, Volume 2\", Annales Littéraires de l\'Université de\r\n   Franche-Comté n° 940, 2015.'),
(292, '2015-11-18', 'LIA', 'Avignon', '========================================================================\r\nModèles connexionnistes pour la génération automatique de texte dans le\r\ncadre de l\'interaction vocale\r\n\r\nEncadrants : Dr Stéphane Huet, Dr Bassam Jabaian, Prof. Fabrice Lefèvre\r\n\r\nDescriptif du stage :\r\nLes systèmes d\'interaction vocales utilisés dans des applications comme\r\nla réservation de billets d\'avion ou d\'hôtels, ou bien encore pour le\r\ndialogue avec un robot, font intervenir différents composants. Parmi\r\nceux-ci figure le module de génération de texte qui produit la réponse\r\ndu système en langage naturelle à partir d\'une représentation sémantique\r\ninterne créée par le gestionnaire de dialogue.\r\n\r\nLes systèmes de dialogue actuels intègrent des modules de génération\r\nbasés sur des règles ou patrons lexicaux définis manuellement, par ex :\r\n\r\nconfirm(type=$U, food=$W,drinks=dontcare)\r\n-> Let me confirm, you are looking for a $U serving $W food and any kind\r\nof drinks right ?\r\n\r\nCes modules gagneraient à se baser sur des méthodes d\'apprentissage\r\nautomatique afin de faciliter la portabilité des systèmes de dialogue\r\nvers de nouvelles tâches et améliorer la diversité des réponses\r\ngénérées. Parmi ces méthodes figurent les réseaux de neurones qui ont vu\r\nun regain d\'intérêt depuis l\'introduction de la notion de « deep\r\nlearning ». De tels réseaux de neurones ont déjà été employés par le\r\nlaboratoire de recherche de Google pour une tâche de génération de\r\ndescription d\'images\r\n(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html)\r\nproche de celle qui nous intéresse ici. Ainsi l\'objectif de ce stage est\r\nd\'étudier l\'utilisation de ces modèles précisément dans le cadre de\r\nl\'interaction vocale.\r\n\r\nSi un intérêt pour l\'apprentissage automatique et le traitement de la\r\nlangue naturelle est souhaitable, il est attendu surtout du stagiaire de\r\nbonnes capacités en développement logiciel. Le stagiaire travaillera\r\ndans le contexte d\'une plateforme d\'interaction vocale complète et\r\npourra élargir son champ d\'investigation aux autres composants.\r\nPlusieurs pistes pour une prolongation en thèse sont ouvertes.\r\n\r\n\r\nDurée du stage : 6 mois\r\nRémunération : Environ 529¤ / mois\r\nThématique associée au stage : Systèmes de dialogue homme-machine, \r\ngénération du langage naturelle, apprentissage automatique...\r\n\r\n========================================================================\r\nHumour et systèmes d\'interaction vocale\r\n\r\nEncadrants : Dr Bassam Jabaian, Dr Stéphane Huet, Prof. Fabrice Lefèvre\r\n\r\nDescriptif du stage : Automatisation de productions humoristiques.\r\n\r\nDes travaux précédents en linguistique ont permis d\'établir les bases\r\nd\'une taxonomie des mécanismes d\'humour interactionnels. En partant de\r\ncette base la question que nous souhaitons aborder dans ce travail est :\r\npeut-on automatiser la production de traits humoristiques dans un\r\ndialogue homme-machine finalisé et si oui quel est l\'impact sur les\r\nperformances du dialogue ?\r\n\r\nBien sur il ne peut s\'agir de reproduire exactement les capacités\r\ngénérales d\'un humain, qui sont très complexes à décrire et certainement\r\nimpossible à automatiser, mais plutôt d\'extraire certains mécanismes\r\nsuffisamment réguliers pour les formaliser et les faire exécuter en\r\nsituation de dialogue. Cela devrait permettre de produire un effet\r\ndécalé, donnant ainsi une dimension de sympathie au système\r\nd\'interaction dans la perception de l\'utilisateur.\r\n\r\nD\'un point de vue pragmatique plusieurs types de production (plus ou\r\nmoins indépendamment du mécanisme humoristique utilisé) sont déjà\r\nenvisagés, réactionnel ou générationnel :\r\n\r\n1. Dans le premier cas on détecte une opportunité (présence de\r\n   connecteurs), puis on réagit (génération de disjoncteurs). C\'est le\r\n   cas de l\'humour basé sur les mots polysémiques, i.e. on repère un mot\r\n   que le système fait semblant de comprendre dans son sens « gênant »\r\n   ou inadapté.\r\n\r\n2. Dans le second cas, on propose un trait d\'humour ex-nihilo ou après\r\n   détection d\'une nécessité de facilitation, par exemple lors de\r\n   l\'apparition d\'un désalignement (l\'évolution normale du dialogue est\r\n   gênée par une ou plusieurs incompréhensions). Il s\'agit alors de\r\n   calembours (« puns »), mots d\'esprits ou histoires drôles (« jokes\r\n   »). On pourra alors avoir recours à une base prédéfinie de blagues et\r\n   les sélectionner selon le contexte de dialogue (au moyen de technique\r\n   de recherche d\'information classique).\r\n\r\nL\'objectif est de pouvoir implémenter les solutions retenues sur les\r\nrobots NAO d\'Aldebaran, disponibles au laboratoire, dans le contexte\r\nd\'une tâche simple (jeux). Au-delà de l\'intérêt pour la thématique de\r\nl\'intelligence artificielle sous-jacente au sujet il est principalement\r\nattendu du stagiaire de très bonnes compétences en développement\r\nlogiciel. Ce stage ouvre sur plusieurs possibilités de poursuite en\r\nthèse dans le domaine de la communication Homme-Machine pour\r\nl\'intelligence artificielle.\r\n\r\nDurée du stage : 6 mois\r\nRémunération : Environ 529¤ / mois\r\nThématique associée au stage : Systèmes de dialogue homme-machine,\r\ncompréhension de la parole, gestion du dialogue, apprentissage\r\nautomatique.\r\n========================================================================\r\n\r\nLes étudiants intéressés sont invités à envoyer un email à\r\nfabrice.lefevreAtuniv-avignon.fr, bassam.jabaianAtuniv-avignon.fr et\r\nstephane.huetAtuniv-avignon.fr en indiquant le sujet visé (ou les 2) et\r\nen joignant un dossier d\'évaluation (avec au moins un CV, un relevé de\r\nnotes des 2 dernières années et une lettre de motivation).\r\n\r\nUne première sélection aura lieu le 24/11/15.'),
(293, '2015-11-19', 'LIRMM', 'Montpellier', 'Titre : Raisonnement multi-expertise (patient/médecin) pour un tâche de\r\nrecherche d\'information\r\n\r\nMots-clés : traitement automatique de la langue, fouille de données,\r\nvocabulaire patient/médecin\r\n\r\nDurée : 4-6mois\r\nLieu : LIRMM\r\n\r\nContexte : Le stage se déroulera dans le cadre du projet SFIR porté par\r\nle LIRMM (http://www.lirmm.fr/sifr/). Ce projet s\'intéresse aux défis\r\nscientifiques et techniques associés à la construction de services basés\r\nsur des ontologies et des terminologies biomédicales pour l\'indexation\r\net la fouille de données biomédicales françaises.\r\n\r\nObjectifs : L\'extraction d\'informations dans les médias sociaux de santé\r\n(forums, Facebook, Twitter...) est rendue difficile par la spécificité des\r\ntextes. Par exemple, l\'extrait de message suivant « jen peux + de ce\r\ncrabe... je pense a arreter le tamox », on trouve des fautes\r\nd\'orthographes « jen », « arreter » des graphies « + » pour « plus » des\r\nmots patients « crabe » pour « cancer », des abréviations « tamox » pour\r\n« tamoxifène ». Dans de précédent travaux [Tapi Nzali 2015], nous avons\r\nexploité l\'API Wikipédia pour rapprocher des termes patients de termes\r\nutilisés par les professionnels de santé et répertoriés dans le\r\nthésaurus MeSH.  Dans un premier temps, l\'objectif de ce stage est\r\nd\'étendre ces travaux en explorant d\'autres ressources du Web (Bing,\r\nYahoo, Google...). Dans un deuxième temps, il s\'agira d\'exploiter le\r\nvocabulaire produit pour un tâche de recherche d\'informations qui\r\nexploitera la structure de la ressource pour raisonner à la fois sur\r\nl\'expertise du patient et des professionnels de santé.\r\n\r\nActions à mener : \r\n1/ Utilisation de différentes ressources Web (Bing, Yahoo, Google...) pour\r\n   rapprocher des termes patients et des termes de professionnels de\r\n   santé \r\n2/ Comparaison des candidats obtenus grâce à différentes mesures\r\n   sémantiques (Harispe 2014)\r\n3/ Production d\'une autre version du vocabulaire formalisée (SKOS,\r\n   Lemon)\r\n4/ Raisonnement multi-expertise (patient/médecin) pour un tâche de\r\n   recherche d\'information\r\n4/ Visualisation pour mettre en évidence ces informations dans les\r\n   textes\r\n\r\nDéroulement du stage : Le stage d\'une durée de 4 à 6 mois se déroulera\r\ndans les locaux du LIRMM à Montpellier.\r\n\r\nCompétences requises : \r\n- Développement web (HTML, Javascript, webGL, java)\r\n- Notions de fouille de données\r\n- Outils de traitements automatiques de la langue\r\n- Développement d\'interfaces\r\n- Une bonne connaissance des API Google ou Yahoo est un plus\r\n\r\nEncadrement\r\n*Sandra Bringay - MCF Université de Montpellier 3 -\r\nsandra.bringay@lirmm.fr\r\n\r\n*Clément Jonquet  - MCF Université de Montpellier - jonquet@lirmm.fr\r\n\r\n*Mike Tapi Nzali, Doctorant, Université de Montpellier -\r\n Mike-Donald.Tapi-Nzali@lirmm.fr\r\n\r\nContacts\r\n* Sandra Bringay - MCF Université de Montpellier 3 -\r\n  sandra.bringay@lirmm.fr\r\n\r\nBibliographie\r\nMike Donald Tapi Nzali, Sandra Bringay, Christian Lavergne, Thomas\r\nOpitz, Jérôme Azé et Caroline Mollevi. Construction d\'un vocabulaire\r\npatient/médecin dédié au cancer du sein à partir des médias\r\nsociaux. Ingénierie des Connaissances - IC. 2015 [Best paper award -\r\nyoung researcher]\r\n\r\nSébastien Harispe, Sylvie Ranwez, Stefan Janaqi, Jacky Montmain: The\r\nsemantic measures library and toolkit: fast computation of semantic\r\nsimilarity and relatedness using biomedical ontologies. Bioinformatics\r\n30(5): 740-742 (2014)'),
(294, '2015-11-24', 'Xerox Research Center Europe', 'Grenoble', 'Xerox Research Centre Europe, located in Grenoble, France, is offering the following internship for early 2016:\r\n\r\n \r\n\r\n--------------------------------------------------------------------------------------------------------------\r\n\r\nDeep Recurrent Neural Networks for Dialogue Prediction and Response Generation\r\n\r\n---------------------------------------------------------------------------------------------------------------\r\n\r\n \r\n\r\nSee: http://www.xrce.xerox.com/About-XRCE/Internships/Deep-Recurrent-Neural-Networks-for-Dialogue-Prediction-and-Response-Generation\r\n\r\n \r\n\r\nContact :  Marc Dymetman   marc.dymetman@xrce.xerox.com  \r\n\r\n \r\n\r\nPlease mention \"RNNs for Dialogue and NLG\" in your subject line.\r\n\r\n \r\n\r\nDuration: around 5 months\r\n\r\nStart date: around January/February 2016\r\n\r\nThe application of Deep Learning techniques to conversational\r\ninteractions has recently emerged as an important research topic in\r\nthe Machine Learning community, and XRCE has started to be strongly\r\nengaged in this area.\r\n\r\nIn particular, we are actively working in the domain of task-oriented\r\ndialogues in relation to the customer call-centers Xerox manages, and\r\nhave access to significant amounts of interaction data in these\r\ndomains.\r\n\r\nWe are looking for an intern who will help us improve some of our\r\ncurrent Recurrent Neural Network models for dialogue prediction and\r\ngeneration for these task-oriented conversations.\r\n\r\nThe ideal candidate is Computer Science student at the Master or\r\n(preferably) PhD level, with a background in Machine Learning\r\n(preferably including Deep Learning techniques) and NLP. Strong\r\nprogramming skills are a requirement (Python, C++, Java...) and\r\nknowledge of such toolkits as Theano, Torch, TensorFlow would be a\r\nplus.\r\n\r\nConference publication of the work will be strongly encouraged.\r\n\r\nSee XRCE\'s page above for more details.'),
(295, '2015-11-30', 'Soyooz / LIMSI', 'Paris / Orsay', 'Recommandation de produits en langue naturelle\r\n\r\nDéveloppement d\'un modèle de profile utilisateur pour recommandation de\r\nproduits en langage naturel\r\n\r\nStage Master 2 de Recherche - Soyooz - LIMSI\r\n\r\nL\'objectif du stage est de concevoir un module d\'extraction de court\r\nextraits de textes issus des réseaux sociaux et du web qui illustre au\r\nmieux un type usage particulier du produit, pour un profile utilisateur\r\ndonné.  Ce module servira à alimenter automatiquement une base\r\nd\'extraits de textes illustratifs des usages à partir de la description\r\ndu produit, de la classe d\'usage et du profile utilisateur.\r\n\r\nPour plus de détails voir:\r\n\r\nhttps://perso.limsi.fr/pap/annonce_finale_stage_soyooz_2015_2016.pdf\r\nou\r\nhttps://www.limsi.fr/fr/formation/offres-de-stages/details/5/11\r\n\r\nDomaine: traitement du langage parlé, écrit et gestuel\r\nMots clés\r\n\r\n  * recherche et extraction d\'information\r\n  * constitution de ressources\r\n  * paraphrase et traduction automatique\r\n  * Apprentissage\r\n  * Traitement Automatique du Language Naturel Écrit\r\n\r\nNiveau M2\r\nDate de début 2016-01-04 (des aménagements sont possibles)\r\nDurée 5 mois\r\nRémunération: ~512 euros / mois (indemnités)'),
(296, '2015-11-30', 'Xerox Research Center Europe', 'Grenoble', 'Personal Language Analytics for Emotion, Sentiment and Personality Modelling\r\nUnit: MLDAT/PARSEM\r\n\r\nProposers : Caroline Brun & Scott Nowson\r\nDuration: 4-6 months\r\nStart Date: March 2016\r\n\r\n\r\nDescription\r\n\r\nPersonal Language Analytics (PLA) is an approach to text mining\r\nwhereby the focus is on the authors of texts rather than the texts\r\nthemselves. It is a computational field which combines aspects drawn\r\nfrom natural language processing, data mining, linguistics, psychology\r\nand sociology.\r\n\r\nAt XRCE we are interested in understanding how language can be used\r\nacross cultures to express mental states, like sentiment, emotion or\r\nmood; to convey a sense of an individual\'s personality.  This\r\ninternship will explore the intersection of these areas as part of a\r\nmuch larger project on customer modelling and personalisation.\r\n\r\nWe are particularly interested in the areas of:\r\n\r\n- textual expression of emotion in human dialogue; \r\n- grounding and focus of this emotion;\r\n- the relationship between the degree of emotional expression and\r\n    personality traits of the interlocutors.\r\n\r\nTasks/Responsibilities\r\n\r\n- Contribute to design of annotation schemes and corpora annotation\r\n  for complex PLA tasks using dedicated annotation platforms.\r\n\r\n- Work with and extend existing linguistic processing and text analytics tools\r\n\r\n- Develop prototype text classification models and design experimental\r\n  evaluation program.\r\n\r\nIdeal candidates are Masters or PhD students with: a strong background\r\nin natural language processing, experience in linguistics along with\r\ntext/data mining and machine learning; preferably an ability to script\r\n(i.e. python); and ideally an interest in human language use.\r\n\r\nApplication instructions\r\n\r\nInformal inquiries are welcome and can be made to\r\nscott.nowson@xrce.xerox.com or caroline.brun@xrce.xerox.com .\r\n\r\nTo submit an application, please send your CV and cover letter to all\r\nof: xrce-candidates@xrce.xerox.com ; caroline.brun@xrce.xerox.com and;\r\nscott.nowson@xrce.xerox.com .'),
(297, '2015-12-09', 'Xerox Research Center Europe', 'Grenoble', 'Conversational system on a robotic platform\r\n\r\nUnit: XTIN\r\n \r\nProposers:\r\nMatthias Galle (Matthias.Galle@xerox.com)\r\nChristophe Legras (Christophe.Legras@xerox.com)\r\n\r\nDuration: 4 - 6 months\r\nStart Date: Q1 2016\r\n\r\nDescription\r\n\r\nThe Xerox Research Centre Europe (XRCE) has a strong expertise in\r\nNatural Language Processing and Machine Learning. We have been\r\napplying these capabilities in many business applications and lately\r\nhave worked on developing conversational software to work in the\r\ncustomer care domain.\r\n\r\nThe internship proposal aims at integrating our conversational\r\nsoftware to a third party robotic platform and to experiment on how to\r\ntake advantage of the robot movements and postures capacities.\r\n\r\n In this internship, the intern will focus on some of the following\r\n tasks in collaboration with the other team members:\r\n\r\n- Integrate the current version of XRCE conversational software in the\r\n      robotic platform and test its usability\r\n- Tune the software components involved in the conversation (Automatic\r\n      Speech Recognition, Natural Language Understanding, Dialogue\r\n      Manager, Natural Language Generation and Speech Synthesis).\r\n\r\n- Use the features offered by the robotic platform to improve the user\r\n      experience\r\n\r\n- Publication of findings in the form of papers and/or intellectual\r\n      property is strongly encouraged\r\n\r\n \r\nThe intern will be part of a team of developers, researchers and\r\nmarketers. XRCE projects are managed with an agile methodology which\r\nallow interns to follow all the steps of software development,\r\nincluding research, design, implementation, test and integration.\r\n\r\n \r\n\r\nCandidates will be:\r\n\r\n - Students in Computer Sciences EngineeringBscMasters\r\n - Experience of Object Oriented Programming: Python and C++ in\r\n      particular\r\n - Knowledge in client/server architectures, web-services\r\n - Basic robotics knowledge\r\n - Knowledge in Agile methodologies and Test Driven Development is a\r\n      plus\r\n\r\nDuring her/his internship the candidate will acquire a significant\r\nknowledge in natural language processing, machine learning techniques\r\nand challenges linked to robotic platforms while working closely with\r\nresearchers and engineers. Her/his work will also be exposed to\r\nfeedback and suggestion from customer care experts and clients.'),
(298, '2015-12-09', 'LIRMM', 'Montpellier', 'SUJET 1 - Master 2 Informatique - Stage Professionnel \r\n\r\n- Titre : Intégration et visualisation de données issues du projet\r\n  Patrimoine Numérique Scientifique du Cirad\r\n- Encadrants : Sandrine Auzoux, Sophie Fortuno,  Mathieu Roche\r\n- Résumé : Le projet Patrimoine Numérique Scientifique (PNS) du Cirad\r\n  (Centre de coopération internationale en recherche agronomique pour le\r\n  développement) est un chantier d\'Etablissement lancé en 2013, qui vise\r\n  à gérer, conserver et valoriser les données scientifiques ou données\r\n  de la recherche produites par l\'établissement et ses partenaires. Dans\r\n  ce contexte, de nombreux groupes de travail ont permis de contribuer à\r\n  l\'identification des données et d\'experts pouvant porter/constituer\r\n  des cas d\'étude thématiques très prometteurs. Dans le cadre de ce\r\n  stage, quatre tâches principales devront être réalisées :\r\n\r\n  * Analyse et pré-traitement des données issues de l\'inventaire\r\n    Cirad. Le prétraitement sera essentiellement dédié à la normalisation\r\n    de certaines données et/ou meta-données.\r\n  * Mise en correspondance des données structurées et normalisées à\r\n    l\'étape précédente.  \r\n  * Visualisation des données via la bibliothèque javascript Ext JS\r\n    (https://www.sencha.com/products/extjs/).\r\n  * Rédaction d\'un rapport incluant la description détaillée du\r\n    protocole reproductible (workflow) sur d\'autres ensembles de données\r\n    et métadonnées.\r\n\r\n- Projet : Patrimoine Numérique Scientifique (Cirad)\r\n- Description complète du stage et contacts :\r\n  http://textmining.biz/Sujets/M2/stage_PNS2015.pdf\r\n\r\n==========================\r\n\r\nSUJET 2 - Master 2 Informatique - Stage Recherche \r\n\r\n- Titre : Nommage des clusters évoluant au cours du temps\r\n- Encadrants : Mathieu Roche, Pascal Poncelet, Julien Velcin\r\n- Résumé : Dans nos récents travaux menés entre l\'équipe ADVANSE (LIRMM\r\n  & TETIS) et le laboratoire ERIC (Lyon), nous nous sommes intéressés à\r\n  l\'identification conjointe des descripteurs (et en particulier le\r\n  vocabulaire) et des catégories. Ceci permet de prendre en compte\r\n  l\'évolution des descripteurs au fil du temps mais également d\'apporter\r\n  une solution à la sélection des meilleurs descripteurs parmi un très\r\n  grand nombre possible (par exemple, apparition de nouveaux termes,\r\n  prise en compte des entités nommées, etc.). L\'identification des\r\n  descripteurs pertinents peut s\'appuyer sur l\'utilisation de ressources\r\n  sémantiques, de systèmes d\'extraction de la terminologie ou de\r\n  méthodes probabilistes. Le stage proposé permettra de combiner les\r\n  différentes approches précédemment citées qui sont fondées sur des\r\n  méthodes symboliques et statistiques afin de proposer une approche\r\n  originale de nommage des clusters au cours du temps.\r\n- Projet : SONGES (Science des dOnnées hétéroGènES)\r\n- Description complète du stage et contacts :\r\n  http://textmining.biz/Sujets/M2/stage_clustering.pdf\r\n\r\n==========================\r\n\r\nSUJET 3 - Master 2 Informatique - Stage Recherche \r\n\r\n- Titre : Désambiguisation des Entités Spatiales par apprentissage actif\r\n- Encadrants : Mathieu Roche, Maguelonne Teisseire\r\n- Résumé : Dans le cadre de l\'identification des Entités Spatiales, un\r\n  problème difficile est en effet lié à la désambiguisation. Nos travaux\r\n  consisteront à adapter les systèmes classiques d\'apprentissage actif\r\n  pour traiter les deux types de désambiguisations, à savoir la\r\n  désambiguisation des toponymes (c\'est-à-dire, un même toponyme peut\r\n  correspondre à des lieux différents) et la désambiguisation entre\r\n  types d\'entités nommées (distinction Entités Spatiales /\r\n  Organisations). Pour cela, la complexité du contexte et les\r\n  descripteurs associés devront être pris en compte dans les modèles\r\n  d\'apprentissage actif à mettre en oeuvre. Ce contexte plus riche\r\n  permettra d\'améliorer le système de désambiguisation.\r\n- Projet : SONGES (Science des dOnnées hétéroGènES)\r\n- Description complète du stage et contacts : http://textmining.biz/Sujets/M2/stage_appA_ES.pdf'),
(299, '2015-12-09', 'LSIS', 'Marseille', 'Stage financé de Master de 4 à 6 mois - Marseille, DIMAG, LSIS,\r\nAix-Marseille Université.\r\n\r\n*Analyse automatique des signaux socio-emotionnels dans les interactions\r\nhumain-machine*\r\n\r\n/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)\r\n\r\n/Autres//encadrants/ : Thierry Chaminade, Institut de Neurosciences de\r\nla Timone\r\n\r\n/Partenariat/: Axel Boidin, entreprise Picxel\r\n\r\n/Contexte du stage /\r\n\r\nCe stage de Master se déroulera dans l\'équipe DIMAG au LSIS en\r\npartenariat avec l\'entreprise Picxel et l\'Institut de Neuroscience de la\r\nTimone (INT). Au sein de l\'équipe /DIMAG/, des recherches sont menées\r\npour développer des méthodes d\'extraction automatique d\'information\r\nsocio-affectives dans des corpus de données textuels ou\r\nvidéos. L\'entreprise /Pixcel /(http://www.picxel.fr/ ) travaille depuis\r\nplusieurs années sur un logiciel de détection automatique des émotions à\r\npartir des expressions faciales des individus.L\'INT s\'intéresse aux\r\nbases physiologiques des comportements sociaux\r\n(http://www.int.univ-amu.fr/_CHAMINADE-Thierry_?lang=fr)\r\n\r\n/Sujet de stage /\r\n\r\nLes ordinateurs sont aujourd\'hui pour la plupart socialement et \r\némotionnellement ignorants (Pentland, 2005). Or, les interactions \r\nhumain-machine sont intrinsèquement sociales et émotionnelles, \r\nimpliquant souvent une expérience affective de l\'utilisateur pouvant \r\nressentir de nombreuses émotions tant positives (joie, soulagement, \r\netc.) que négatives (frustration, énervement, etc.) lors de son \r\ninteraction avec un ordinateur (Picard, 1997). De plus, sous la forme de \r\npersonnages virtuels ou de robot humanoïde, ces systèmes interactifs \r\nsont de plus en plus utilisés pour incarner des rôles sociaux \r\nparticuliers tels que celui de tuteur, de compagnon, d\'assistant, de \r\nconseiller ou d\'acteur. Dans ces contextes d\'usages, les ordinateurs \r\ndoivent être dotés d\'une certaine forme d\'*intelligence sociale et \r\némotionnelle* (Kihlstorm et Cantor, 2000, Salovey et al., 2000) leur \r\npermettant d\'interagir et sociabiliser avec l\'utilisateur ainsi que \r\nd\'exprimer des émotions et gérer celles de l\'utilisateur afin \r\nd\'optimiser l\'interaction (perception, motivation, performance, \r\ndécision, autonomie, etc.).\r\n\r\nL\'objectif du stage s\'intègre dans la perspective de concevoir des\r\nsystèmes interactifs capables de détecter /l\'engagement de l\'utilisateur\r\net la qualité de l\'interaction/. Pour ce faire, un des enjeux\r\naujourd\'hui est d\'identifier,modéliser et détecter automatiquement les\r\nsignaux verbaux (e.g. vocabulaire) et non-verbaux(regards, expression\r\nfaciales, mouvements de tête, etc.) porteurs d\'informations\r\nsocio-émotionnelles (e.g. engagement, satisfaction) dans une\r\ninteraction.\r\n\r\nCe stage vise à explorer des techniques de fouilles de données pour\r\nanalyser automatiquement les signaux verbaux et non-verbaux\r\nsocio-émotionnels dans des interactions humain-humain médiatisées ou\r\nhumain-machine. Plus précisément, il s\'agira d\'analyser les séquences de\r\nsignaux (sourires, direction du regard, froncement des sourcils,\r\nmouvements de tête, etc.) impliquées dans les expressions d\'émotions et\r\nd\'attitudes (/e.g./ l\'engagement). Pour ce faire, des méthodes de «\r\nsequences mining » seront utilisées sur un corpus de données collectés\r\npar INT (Institut Neuroscience de la Timone). Ce corpus est composé\r\nd\'enregistrement vidéo d\'interaction naturelle humain-humain médiatisé\r\n(skype) et humain-machine (avec un personnage virtuel). Ce corpus\r\ncomporte déjà un certain nombre d\'annotations (mouvements du regard,\r\nmouvement de tête, etc.). Il sera complété par les signaux non-verbaux\r\ndes individus détectés automatiquement à partir du logiciel développé\r\npar la société Pixcel. De plus, une analyse automatique du comportement\r\nverbal (e.g. vocabulaire, dysfluences) dans différentes situations\r\nd\'interactions (e.g. interactions réussies versus non satisfaisantes)\r\npermettra d\'identifier des indices verbaux sur la qualité de\r\nl\'interaction.\r\n\r\nLe stage impliquera dans un premier temps une étude de la littérature en\r\nSciences Humaines et Sociales et dans le domaine de l\'Informatique\r\nAffective et du Traitement Automatique des signaux sociaux (Social\r\nSignal Processing) pour identifier les signaux verbaux et non-verbaux\r\npertinents et les émotions et attitudes associées. Le stage focalisera\r\nsur un sous-ensemble restreint d\'émotions et d\'attitudes qu\'il s\'agira\r\nde définir. Différents algorithmes de « sequences mining » et\r\nd\'apprentissage automatique seront explorés et testés sur le corpus de\r\ndonnées.Les résultats seront ensuite modélisés afin de concevoir un\r\nmodèle computationnel permettant de détecter automatiquement\r\ncertainesémotions et attitudes de l\'utilisateur suivant les séquences de\r\nsignaux non-verbaux ou des comportements verbaux détectées.Ce modèle\r\nsera testé sur des données réelles.\r\n\r\nLe stagiaire devra à la fois avoir des connaissances techniques (Matlab,\r\nPython, SQL), des connaissances en fouille de données, TAL et surtout\r\nune ouverture pluridisciplinaire.\r\n\r\nLes dossiers de candidatures doivent contenir un CV détaillé, les notes\r\nde Master, ainsi qu\'une lettre de motivation.\r\n\r\nLe dossier est à envoyé à magalie.ochs(at)lsis.org'),
(300, '2015-12-16', 'SNCF', 'Paris', 'Stage de master de 6 mois à la direction Innovation et Recherche SNCF,\r\nParis 12.\r\n\r\nIntitulé : Annotation riche de données web sur les itinéraires et\r\npratiques des voyageurs\r\n\r\nLa Direction Innovation et Recherche de la SNCF recherche un stagiaire\r\npour travailler sur un projet d\'étude de la mobilité des voyageurs à\r\ntravers l\'analyse de données textuelles.\r\n\r\n*Activités du stage*\r\n------------------------------\r\nAnnotation riche de données web sur les itinéraires et pratiques des\r\nvoyageurs\r\n\r\n*Thème*\r\n------------------------------\r\nLa société connaît depuis quelques années des changements majeurs dans\r\nles pratiques de mobilité, du fait d\'autres formes d\'organisation du\r\ntravail,  de l\'émergence de nouveaux modes de transport, de l\'impact des\r\nNTIC... Les voyageurs s\'expriment sur le web social à propos de leurs\r\ndéplacements, aussi bien en situation normale qu\'en situation\r\nperturbée. Les messages contiennent des informations sur les activités\r\ndes voyageurs, leurs particularités sociologiques ou encore leurs\r\nmotivations.\r\nSNCF dispose d\'un corpus de données web, d\'un premier modèle de\r\nreprésentation des connaissances (ontologies) ainsi que d\'outils\r\nfacilitant l\'exploration des données.\r\nLe stagiaire aura pour mission d\'annoter une base d\'exemples, puis\r\nd\'évaluer et de proposer des améliorations du modèle de représentation\r\ndes connaissances sur la base de ses observations. L\'annotation visera\r\nnotamment à identifier les modes de transport et autres indices relatifs\r\nà l\'itinéraire parcouru, ainsi que des indices relatifs aux activités,\r\ncontraintes ou ressentis du voyageur.\r\n\r\n*Description *\r\n------------------------------\r\nLe stagiaire devra :\r\n- prendre connaissance du contexte du stage (SNCF, Direction Innovation\r\n  & Recherche, objectifs du stage et cadre de réalisation, projet dans\r\n  lequel le stage s\'insère et interlocuteurs sur les sujets concernés)\r\n- annoter une base de messages du web selon les thématiques et sujets\r\n  spécifiés, à partir d\'ontologies et taxonomies\r\n- co-construire le modèle de représentation des connaissances, à partir\r\n  de ses premières annotations, de ses analyses et par interaction avec\r\n  la personne actuellement en charge de la réalisation du modèle\r\n- évaluer la pertinence du modèle et la qualité de l\'annotation\r\n\r\nPrésentations et rapports :\r\n- présentation de début de stage à la SNCF (au bout d\'un mois de stage) :\r\n  contexte de stage, planning de réalisation et premiers travaux\r\n  réalisés.\r\n- rapport final de stage complet comprenant : méthodologie utilisée,\r\n  travaux réalisés, résultats obtenus et problèmes rencontrés 2\r\n  soutenances de fin de stage : une à l\'école et une à la SNCF.\r\n\r\nDes présentations en interne SNCF ou externes pourront être effectuées.\r\n\r\n*Profil recherché*\r\n------------------------------\r\n\r\nNiveau : De formation Bac+5 en Sciences du langage/Traitement\r\nAutomatique du Langage Naturel ou Informatique (ingénieur ou master 2).\r\n\r\nCompétences attendues :\r\n\r\n- Capacités d\'analyse, de rédaction et de synthèse\r\n- Autonomie, qualités relationnelles, qualité de présentation\r\n  (orale/écrite).\r\n- Connaissances en TAL et linguistique\r\n\r\nCompétences additionnelles souhaitées :\r\n- Compétences en informatique (programmation, gestion de bases de\r\n  données)\r\n- Bonne connaissance du réseau de transport en Ile-de-France\r\n\r\n\r\n*Modalités du poste*\r\n------------------------------\r\n\r\n   - Durée : 6 mois\r\n   - Rémunération prévue: indemnités de stage (924 ¤ bruts mensuels) +\r\n     carte de circulation SNCF sur le réseau national\r\n   - Début : à partir d\'avril 2016\r\n   - Lieu : Paris\r\n\r\n\r\nMerci d\'adresser CV et lettre de motivation à Coralie Reutenauer et\r\nAmélie Martin aux adresses mail suivantes : coralie.reutenauer@sncf.fr,\r\namelie.martin2@sncf.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(301, '2015-12-16', 'IGN', 'Saint-Mandé', 'Stage M2 : Analyse de l\'emprise d\'une carte à partir des toponymes d\'un\r\ntexte (5 mois à placer entre avril et octobre 2016)\r\n\r\nMots clés\r\ninformatique, évaluation, entité nommée spatiale, géomatique, traitement\r\nautomatique du langage naturel\r\n\r\nContexte\r\nCe stage s\'insère dans un thème de recherche concernant la définition\r\nautomatique de l\'emprise d\'une carte illustrant un article\r\njournalistique. Une première version d\'un outil d\'extraction des\r\n\"toponymes importants\" d\'un texte, et de calcul et visualisation de\r\nl\'emprise de la carte correspondante a été réalisée. Cette version\r\ns\'appuie sur différentes ressources (gazetiers, patrons) et outils (de\r\nclassification, de visualisation) ; elle est à améliorer et différentes\r\npistes d\'amélioration ont été définies.\r\n\r\nSujet\r\nL\'objectif du stage est d\'approfondir une ou plusieurs des pistes\r\nd\'amélioration proposées. Le sujet est donc très ouvert et sera défini\r\nselon les compétences du candidat retenu.\r\n\r\nLes pistes d\'amélioration sont les suivantes :\r\n\r\n- le corpus et la typologie des paires. Un corpus de travail de dix\r\n  paires (texte, carte) a été défini à partir de différentes\r\n  configurations identifiées au préalable. Cette typologie est fondée\r\n  sur la maille de la carte (l\'emprise correspond à un ou plusieurs\r\n  continents, un ou plusieurs pays, une région, un ensemble de villes,\r\n  etc.) et le nombre d\'entités identifiées comme importantes. Il s\'agit\r\n  ici d\'augmenter la taille du corpus de travail et de préciser et/ou\r\n  enrichir la typologie déjà proposée pour pouvoir classer toutes les\r\n  paires du corpus augmenté ;\r\n\r\n- la définition d\'indicateurs permettant de caractériser les\r\n  paires. Différents indicateurs ont été définis qui tiennent compte des\r\n  caractéristiques lexicométriques du texte, de la répartition\r\n  géographique des toponymes, etc. Il s\'agit ici d\'analyser les\r\n  indicateurs par rapport à la typologie des paires. L\'objectif est de\r\n  disposer d\'indicateurs qui permettent de différencier les différentes\r\n  configurations, et le cas échéant de proposer et implémenter de\r\n  nouveaux indicateurs linguistiques ou spatiaux ;\r\n\r\n- l\'évaluation de l\'annotation des toponymes et de l\'emprise de la\r\n  carte. Le corpus textuel a été annoté (deux annotateurs) et l\'emprise\r\n  de la carte qui accompagne le texte mesurée. Une première version d\'un\r\n  outil qui mesure l\'accord entre les annotateurs a été mise en place,\r\n  ainsi qu\'une mesure de distance (distance surfacique) entre l\'emprise\r\n  calculée et celle de la référence (i.e. celle de la carte qui\r\n  accompagne le texte). Pour l\'évaluation des textes, il faudra mettre\r\n  en place un accord inter-annotateurs qui prennent en compte la nature\r\n  des étiquettes, les bornes des séquences, les enjeux des erreurs sur\r\n  les étiquettes et les bornes. Pour la distance entre emprises, il\r\n  faudra vérifier que les distances calculées sont cohérentes avec la\r\n  mesure intuitive des écarts, et éventuellement proposer une nouvelle\r\n  distance qui complète la distance surfacique pour évaluer la qualité\r\n  de la position respective des deux emprises ;\r\n\r\n- la prise en compte de toponymes géographiques. Pour le moment,\r\n  l\'identification des toponymes importants tient compte uniquement des\r\n  noms de continents et d\'entités administratives : pays, régions\r\n  administratives, villes. D\'autres toponymes pourraient être pris en\r\n  compte qui désignent des entités non administratives et/ou\r\n  d\'implantation linéaire : régions géographiques à l\'intérieur d\'un\r\n  pays ou qui chevauchent plusieurs pays, fleuves, chaînes de montagne,\r\n  etc. La difficulté est que ces toponymes et leur géométrie ne sont pas\r\n  toujours répertoriés dans les gazetiers utilisés. Il s\'agit ici\r\n  d\'élargir les ressources utilisées (toponymes et géométries\r\n  correspondantes) et d\'implémenter de nouvelles méthodes de calcul de\r\n  l\'emprise qui tiennent de ces nouveaux objets et des relations\r\n  topologiques correspondantes.\r\n\r\n\r\nResponsables du stage\r\nCatherine Dominguès\r\nIGN/SR/COGIT, 73 avenue de Paris, 94160 Saint-Mandé\r\ntél : +33 1 43 98 85 44\r\nmél : catherine.domingues@ign.fr\r\n\r\nMarie-Dominique Van Damme\r\ntél : +33 1 43 98 75 84\r\nmél : marie-dominique.vandamme@ign.fr\r\n\r\nPour candidater\r\nAdresser par courriel à Catherine Dominguès un curriculum vitae et une\r\nlettre de motivation ainsi que les notes obtenues dans les deux\r\ndernières années et une description des enseignements suivis (un lien\r\nvers le site internet de la formation est le bienvenu).'),
(302, '2015-12-16', 'Médecin Direct', 'Paris', 'STAGE de Master\r\n\r\nClassification des e-consultations médecin / patient\r\n\r\nMEDECIN DIRECT (www.medecindirect.fr) a développé son expertise dans\r\nla mise à disposition de ressources médicales, à titre de médecins\r\ngénéralistes ou spécialistes, par tout moyen utilisant les\r\ntechnologies de l\'information et des communications. Dans ce cadre,\r\nelle développe des services de télémédecine, téléconseil médicalisé,\r\ntélésuivi (SYMPAD®), téléexpertise et plus généralement tout type de\r\nservices dans lequel une ressource médicale est nécessaire. Elle a\r\ndéveloppé des outils spécifiques, une méthodologie et des procédures\r\ncomplexes pour respecter les conditions exigées par l\'environnement\r\nmédical, en accord avec les autorités compétentes françaises (CNOM,\r\nCNIL, HAS etc...).\r\n\r\nA ce titre MEDECIN DIRECT dispose de toutes les autorisations légales\r\net réglementaires d\'exercice médical.\r\n\r\nDeux types de e-consultations sont proposées : des interactions de\r\ntype questions/réponses (asynchrones) et des interactions\r\ntéléphoniques. Les premières sont archivées telles quelles dans une\r\nbase de données, les secondes y sont renseignées sour la forme d\'un\r\ncompte-rendu rédigé par le médecin à destination du patient.\r\n\r\nL\'objectif du stage est de proposer un système de classification des\r\ne-consultations afin d\'en faciliter l\'analyse soit dans un but\r\nd\'analyse globale des données, soit dans un but d\'accès à une\r\ninformation précise.\r\n\r\nLes axes envisagés sont les suivants :\r\n\r\n- Proposer une typologie opérationnelle des e-consultations basées sur\r\n  le contenu linguistique de celles-ci : types et modalités\r\n  d\'interactions, thématiques abordées, besoin exprimé par le patient,\r\n  types de réponses du médecin, etc.\r\n\r\n- Définir les différents types d\'e-consultations de façon\r\n  opérationnelle en identifiant des descripteurs associés à chaque\r\n  classe et mettre en place des techniques de classification\r\n  automatique\r\n\r\n- Tester l\'utilisabilité de la typologie pour l\'analyse globale :\r\n  quantifier la fréquence des e-consultations portant sur un\r\n  traitement/une maladie chronique, mesurer le aux de questions\r\n  concernant un tiers, etc.\r\n\r\n- Mettre en place des scénarios pour tester l\'utilisabilité de la\r\n  typologie dans des situations de besoin d\'accès à une information\r\n  précise. Cette partie se fera en lien avec les analystes du service\r\n  et les médecins participants.\r\n\r\nProfil\r\n\r\nCe stage s\'adresse à un étudiant de deuxième année de master en\r\ntraitement automatique des langues.\r\n\r\nCe travail nécessite de la rigueur, de la créativité et de l\'autonomie\r\ndans la manipulation des données langagières.\r\n\r\nPlus précisément, le stagiaire devra présenter :\r\n- des compétences en linguistique, indispensables pour identifier et qualifer les différents types d\'e-consultations.\r\n- une maîtrise des méthodes d\'analyse de corpus et de lingusitique\r\n  outillée est indispensable : approches guidées par les données,\r\n  annotation, utilisation de concordanciers\r\n- des compétences en informatique et en TAL : création de scripts,\r\n  annotation automatique de corpus, maniement d\'expressions\r\n  régulières, mise en place et évaluation d\'outils de classification\r\n  automatique\r\n- une connaissance dans la gestion et l\'exploitation de base de\r\n  données et dans l\'utilisation de mesures statistiques\r\n\r\nLe stage se déroule chez la Société Médecin Direct, Incubateur\r\nBoucicaut, 130 rue de Lourmel, 75015 PARIS\r\n\r\nDurée de stage envisagée : 5 à 6 mois.\r\nDébut de stage prévu en mars-avril 2016\r\nIndemnités conventionnelles\r\n\r\nPour contact et candidature : \r\nFrançois Lescure\r\nfrancois.lescure@medecindirect.fr'),
(303, '2016-01-04', 'LIMSI & INRIA', 'Orsay', 'Political Viewpoint Analysis from Social and Web Sources\r\n\r\nXavier Tannier (LIMSI/ U. Paris Sud, CNRS)\r\nIoana Manolescu (INRIA, U. Paris Sud)\r\n\r\nDuration: 5-6 months, the starting date is flexible (ideally March\r\n1st, 2016)\r\n\r\nLocation: Orsay, France\r\n\r\nKeywords: Natural Language Processing, Text Mining, Information\r\nExtraction, Information Retrieval, Social data management, Databases\r\n(the tasks will be adapted according to interest and level of\r\nqualification of the candidate).\r\n\r\nThe work is to be carried in close collaboration between the INRIA OAK\r\nteam, LIMSI-CNRS and the major French newspaper Le Monde. The work\r\nis supported by a Computational Research Journalism Award from Google\r\n\r\nContext\r\n\r\nThe French political arena comprises many political parties, spanning\r\nfrom the extreme left to the extreme right. In 2012, no less than 10\r\ncandidates ran for the presidential election (12 in 2007), with\r\nsensitivities such as communism, socialism, ecology, centre left,\r\ncentre right, right, far right, extreme right, or even one literally\r\ncalled \"hunting, fishing, nature and tradition\". Further, as in any\r\ndemocratic countries, ideas and values intertwine with group tactics,\r\npersonal ambitions, communication strategies, that make politicians\r\ntake stands which do not always directly copy those of their political\r\nparty.\r\n\r\nFor all these reasons, deciphering politician candidates\' positions\r\nand deciding which candidate is the closest to our own opinions is a\r\ncomplex task for citizens. Similarly, analyzing statements and facts\r\ninto perspective is complex work for journalists.  The goal of the\r\ninternship is to automatically build (from a variety of sources such\r\nas online news articles, Twitter feeds, structured databases etc.)\r\ntopical threads that will organize and visualize claims made by\r\npoliticians, in order to help journalists and citizens decode them and\r\ndistinguish between personal opinion, communication tools established\r\nby the parties, and voluntary distortions of the reality.\r\n\r\nData sources. \r\n\r\nWe will use different textual and/or structured data sources as input\r\nto our extraction process:\r\n\r\nâ€¢ Newspaper articles from Le Monde web site and printed version.\r\n\r\nâ€¢ Social network data, that comes already endowed with metadata\r\nspecifying e.g., the author and date of every information item\r\npublished in a social context, and possibly previously published items\r\nto which the new item refers e.g., re-tweets);\r\n\r\nâ€¢ The link structure (e.g., news articles citing each other, links\r\nappearing in tweets), from which we will extract information on a\r\nthread continuation;\r\n\r\nâ€¢ Background knowledge concerning political affiliations of people, as\r\nwell as their position in the political chessboard (importance and\r\nside), can be exploited to contextualize the social item content;\r\n\r\nâ€¢ Possibly, data such as voting intention polls, in order to track\r\nevents to have an influence on them.  Scientific areas. This project\r\ninvolves scientific fields such as Natural Language Processing,\r\nInformation Extraction, Information Retrieval, Social data management,\r\nDatabase, Data visualization.\r\n\r\n\r\nDescription\r\n\r\nDepending on the level of qualification and duration of the candidate\r\ninternship, (s)he will work on one or several of the following steps:\r\n\r\nâ€¢ Using existing metrics (such as mutual information, tf-idf, lexical\r\n  specificity) for extracting differences and similarities between\r\n  claims from different political sides, or different political\r\n  personalities.\r\n\r\nâ€¢ Implementing and adapting unsupervised algorithms such as topic\r\nmodels (e.g. LDA) on different types of claims.\r\n\r\nâ€¢ Building a unified framework for collecting, organizing and querying\r\nclaims from various sources.  \r\n\r\nRequired competencies are: good software development skills, strong\r\nqualification in one or several of the scientific areas involved in\r\nthe project (demonstrated e.g., by academic results or past successful\r\nprojects), good communication skills and willingness to work in a\r\nteam.  On a daily basis, work will take place in a collaborative team\r\ncomprising the internship supervisors, an INRIA engineer whose task it\r\nis to oversee and coordinate the development of our unified platform\r\nfor data-based fact checking, and probably other interns. The work is\r\nrelated to a longer scientific effort within the four-years ANR\r\nproject ContentCheck (Content Management Techniques for Fact-Checking:\r\nModels, Algorithms, and Tools); the project starts in January 2016.\r\n\r\nThe internship may lead to a PhD within the project.\r\n \r\nThe internship will take the form of a full-time INRIA employment\r\ncontract. The intern will be paid 1100 â‚¬/month.\r\n\r\nContacts\r\n\r\nâ€¢ Ioana Manolescu (ioana.manolescu@inria.fr),\r\n  http://pages.saclay.inria.fr/ioana.manolescu/\r\n\r\nâ€¢ Xavier Tannier (xavier.tannier@limsi.fr),\r\n  https://perso.limsi.fr/xtannier/en/'),
(304, '2016-01-04', 'LTCI', 'Orsay', 'TITRE : Gestion de l\'Intra-synchronie entre gestes et contenu verbal\r\npour la génération de comportements chez un Agent Conversationnel Animé\r\n\r\nENCADREMENT : Catherine Pelachaud et Chloé Clavel\r\n\r\nLaboratoire d\'accueil : LTCI, CNRS, Télécom ParisTech, Université\r\nParis-Saclay,\r\n\r\n75013, Paris, France\r\n\r\nDurée du stage : 6 mois à partir d\'avril 2016\r\n\r\nPROFIL DU CANDIDAT: étudiant titulaire d\'un master 2 recherche\r\n\r\n- Interaction humain/machine, agents conversationnels animés\r\n\r\n- Apprentissage statistique / reconnaissance des formes/ Traitement du\r\n  Langage Naturel\r\n\r\n- Bon niveau en programmation (Java, C/C++, Python)\r\n\r\n- Bon niveau d\'anglais\r\n\r\n\r\nCANDIDATURES : à envoyer à chloe.clavel@telecom-paristech.fr ,\r\ncatherine.pelachaud@telecom-paristech.fr\r\n\r\n- Curriculum Vitae\r\n\r\n- Lettre de motivation personnalisée expliquant l\'intérêt du candidat\r\n  sur le sujet *(directement dans le corps du mail)*\r\n\r\n- Relevés de notes des années précédentes\r\n\r\n- Contact d\'une personne de référence\r\n\r\n*Les candidatures incomplètes ne seront pas examinées.*\r\n\r\nSUJET DU STAGE : L\'utilisation des robots pour des services à la\r\npersonne (ex : assistance aux personnes âgées), ou plus largement des\r\nagents conversationnels animés pour la gestion de la relation client sur\r\nles sites de vente en ligne (voir par exemple l\'agent Yoko de Toshiba :\r\ngoo.gl/Q4wi0y) est un domaine en plein essor dans lequel l\'intégration\r\nde la composante socio-affective dans l\'interaction entre l\'humain et\r\nl\'agent virtuel joue actuellement un rôle central.\r\n\r\nLa plateforme GRETA développée au sein du LTCI-CNRS [Ochs et al., 2014]\r\nest dotée de composants socio-affectifs capables d\'intégrer des émotions\r\net des attitudes sociales dans le comportement d\'un agent\r\nconversationnel animé.  Le traitement des gestes de l\'agent [Lee et\r\nal. 2011] se fait à l\'aide de marqueurs temporels (time codes) utilisés\r\npour synchroniser les gestes et la parole et les différents\r\ncomportements communicatifs associés aux comportements\r\nsocio-affectifs. L\'encodage des gestes est réalisé au format FML-APML\r\n[Affective Presentation Markup Language [Mancini and Pelachaud, 2008]\r\nreposant sur le Functional Markup Language]. Un geste communicatif est\r\ndéfini par la trajectoire et la forme de la main dans l\'espace et par sa\r\nstructure temporelle [Kendon, 2004]. Il existe différents types de\r\ngestes [McNeill, 1992] comme les *deictiques* (e.g. indiquer un point\r\ndans l\'espace), les *iconiques* (e.g. mimer la grandeur d\'un objet), les\r\n*métaphoriques* (e.g. figurer une idée abstraite, comme un geste de\r\nmains circulaires pour signifier \"englober\" ) et les *battements* qui\r\nviennent appuyer le discours.\r\n\r\nL\'enjeu global du stage est de travailler sur la génération multimodale\r\ndes énoncés de l\'agent. Différentes modalités ont été étudiées au sein\r\nde l\'équipe Greta du LTCI : le geste [Le et al. 2011], la prosodie\r\n[Bawden et al., 2015], les expressions faciales [Ding et al., 2013]. Le\r\nstage portera sur les modalités verbale et gestuelle. En particulier,\r\nl\'objectif sera de mettre en place des méthodes de *machine learning*\r\npermettant d\'apprendre à partir d\'un corpus d\'enregistrements de\r\ncomportements humains les relations d\'intra-synchronie entre les gestes\r\net le contenu verbal : à quel moment générer un geste communicatif donné\r\nà partir des propriétés structurelles de la parole définies à partir des\r\ncontenus syntaxiques, sémantiques, prosodiques et pragmatiques? Les\r\ncorpus envisagés pour l\'apprentissage sont le corpus CID (Corpus of\r\nInteractional Data [Bertrand et al., 2008]) et le AMI meeting corpus\r\n[McCowan, 2005].\r\n\r\nLe stage s\'articulera autour des tâches suivantes :\r\n\r\n* définition des différentes unités de segmentation de la parole\r\n  pertinentes (segments prosodiques ou textuels);\r\n\r\n* analyse des corrélations entre les time codes des gestes et les time\r\n  codes des frontières de segments;\r\n\r\n* développement de méthodes de *machine learning* (Hidden Markov Models\r\n  ou Conditional Random Fields [Lee and Marsella, 2012], [Levine et al.,\r\n  2010], [Ding et al., 2013]) pour l\'apprentissage de l\'alignement du\r\n  geste sur le texte en vue d\'un modèle de génération de gestes\r\n  communicatifs pour les agents virtuels conversationnels.\r\n\r\n\r\n\r\nREFERENCES :\r\n\r\nR. Bawden, C. Clavel, F. Landragin, Towards the generation of dialogue\r\nacts in socio-affective ECAs: a corpus-based prosodic analysis\r\n(http://dx.doi.org/10.1007/s10579-015-9312-9), Language Resources and\r\nEvaluation, Springer Netherlands, 2015\r\n\r\nR. Bertrand, P. Blache, R. Espesser, G. Ferré, C. Meunier, Béatrice\r\nPriego-Valverde, and Stéphane Rauzy. \"Le CID-Corpus of Interactional\r\nData-Annotation et exploitation multimodale de parole\r\nconversationnelle.\"  Traitement automatique des langues 49, no. 3\r\n(2008): 1-30.\r\n\r\nY. Ding, M. Radenen, T. Artières, C. Pelachaud. Speech-Driven Eyebrow\r\nMotion Synthesis With Contextual Markovian Models International\r\nConference on Acoustics, Speech and Signal Processing (ICASSP), 2013.\r\n\r\nA. Kendon, Gesture: Visible Action as Utterance, Cambridge University\r\nPress, 2004.\r\n\r\nQ. A. Le, S. Hanoune and C. Pelachaud, Design and implementation of an\r\nexpressive gesture model for a humanoid robot. 11th IEEE-RAS\r\nInternational Conference on Humanoid Robots (Humanoids 2011), Bled,\r\nSlovenia on October 26th to 28th, 2011.\r\n\r\nJ. Lee and S. Marsella. Modeling speaker behavior: A comparison of two\r\napproaches. In IVA, pages 161-174. Springer, 2012.\r\n\r\nS. Levine, P. Krähenbühl, S. Thrun, and V. Koltun, \"Gesture\r\ncontrollers,\" ACM Trans. Graph., vol. 29, no. 4, 2010.\r\n\r\nM. Mancini and C. Pelachaud. \"The FML-APML language.\" In Proc. of the\r\nWorkshop on FML at AAMAS, vol. 8. 2008.\r\n\r\nI. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bourban, M. Flynn, M.\r\nGuillemot et al. \"The AMI meeting corpus.\" In Proceedings of the 5th\r\nInternational Conference on Methods and Techniques in Behavioral\r\nResearch, vol. 88. 2005.\r\n\r\nD. McNeill, Hand and Mind: What Gestures Reveal about Thought,\r\nUniversity of Chicago Press, Chicago, 1992.\r\n\r\nMagalie Ochs, Yu Ding, Nesrine Fourati, Mathieu Chollet, Brian Ravenet,\r\nFlorian Pecune, Nadine Glas, Ken Prepin, Chloé Clavel et Catherine\r\nPelachaud, Vers des Agents Conversationnels Animés Socio-affectifs, Journal\r\nd\'Interaction Personne-Système, JIPS, 3 (2), pp.1-23, Mars 2014'),
(305, '2016-01-04', 'LATTICE', 'Paris', '* Modélisation informatique de mécanismes d\'acquisition de constructions\r\n  lexico-syntaxiques\r\n\r\nDans le cadre d\'un projet européen (projet ERA-NET Atlantis), en\r\ncollaboration notamment avec le centre de recherche de Sony à Paris\r\n(Sony CSL), le Lattice propose un stage autour de la modélisation de\r\nl\'acquisition de constructions linguistiques. Le stage consistera, à\r\npartir d\'une micro-grammaire de l\'anglais ou de l\'allemand (la\r\nmicro-grammaire sera fournie), à élaborer des stratégies d\'extension et\r\nd\'acquisition de nouvelles constructions à partir de données extérieures\r\n(typiquement, de nouvelles phrases) et/ou de méta-connaissances sur la\r\ngrammaire elle-même. L\'étude portera sur les processus d\'acquisition et\r\nsur le type de connaissance impliqué davantage que sur la couverture de\r\nla grammaire finale.\r\n\r\nLe stagiaire devra être inscrit dans un Master 2, en informatique,\r\ntraitement automatique des langues, intelligence artificielle ou\r\nsciences cognitives. Tout profil présentant les compétences demandées\r\nsera pris en considération.\r\n\r\nCompétences exigées :\r\n- connaissances en programmation\r\n- maîtrise d\'un langage de scripts (perl ou python)\r\n- anglais technique\r\n- qualités de rédaction\r\n- aptitude au travail en équipe\r\n\r\nConditions\r\n\r\nStages normalement prévu pour 6 mois à partir du mois d\'avril 2016 et\r\nrémunéré au tarif réglementaire. Le stage devra faire l\'objet d\'une\r\nconvention de stage. Le lieu de travail est le laboratoire Lattice à\r\nMontrouge, près de Paris (métro Mairie de Montrouge)\r\n\r\n\r\nPour candidater, merci d\'envoyer un CV et un relevé de notes récent (M2\r\nen cours ou M1) à : thierry.poibeau@ens.fr, en précisant bien quel stage\r\nest visé.'),
(306, '2016-01-04', 'LATTICE', 'Paris', '* Acquisition de schÃ©mas prÃ©dicatifs verbaux en finnois\r\n\r\nL\'acquisition lexicale vise Ã  acquÃ©rir des informations de nature\r\nlexicale Ã  partir de l\'analyse automatique de grands corpus. Pierre\r\nMarchal a soutenu rÃ©cemment une thÃ¨se consacrÃ©e au dÃ©veloppement d\'un\r\ntel systÃ¨me pour le japonais. L\'acquisition de connaissances relatives\r\naux constructions verbales est en effet une question importante pour le\r\ntraitement automatique des langues, mais aussi pour la lexicographie qui\r\nvise Ã  documenter les nouveaux usages linguistiques. L\'approche repose\r\nsur un modÃ¨le original pour la notion d\'entrÃ©e lexicale et la\r\ndistinction entre arguments et circonstants : plutÃ´t qu\'adopter un\r\ndÃ©coupage binaire entre sens et antre arguments et circonstants, la\r\nmodÃ©lisation repose sur la notion de continuum. Enfin, le lexique obtenu\r\nn\'est pas figÃ© et il est possible de dÃ©river diffÃ©rents ressources, avec\r\ndiffÃ©rents degrÃ©s de granularitÃ© de description. Le but du stage\r\nconsiste Ã  reprendre la chaÃ®ne de traitement dÃ©veloppÃ©e dans le cadre de\r\ncette thÃ¨se et Ã  l\'adapter pour le traitement du finnois.\r\n\r\nLe stagiaire devra Ãªtre inscrit dans un Master 2, en informatique,\r\ntraitement automatique des langues, intelligence artificielle ou\r\nsciences cognitives. Tout profil prÃ©sentant les compÃ©tences demandÃ©es\r\nsera pris en considÃ©ration. Une connaissance mÃªme minimale du finnois\r\nest nÃ©cessaire.\r\n\r\nCompÃ©tences exigÃ©es :\r\n- connaissances en programmation\r\n- maÃ®trise d\'un langage de scripts (perl ou python)\r\n- connaissance du finnois\r\n- anglais technique\r\n- qualitÃ©s de rÃ©daction\r\n- aptitude au travail en Ã©quipe\r\n\r\nConditions\r\n\r\nStages normalement prÃ©vu pour 6 mois Ã  partir du mois d\'avril 2016 et\r\nrÃ©munÃ©rÃ© au tarif rÃ©glementaire. Le stage devra faire l\'objet d\'une\r\nconvention de stage. Le lieu de travail est le laboratoire Lattice Ã \r\nMontrouge, prÃ¨s de Paris (mÃ©tro Mairie de Montrouge)\r\n\r\n- qualitÃ©s de rÃ©daction\r\n- aptitude au travail en Ã©quipe\r\n\r\nConditions\r\n\r\nStages normalement prÃ©vu pour 6 mois Ã  partir du mois d\'avril 2016 et\r\nrÃ©munÃ©rÃ© au tarif rÃ©glementaire. Le stage devra faire l\'objet d\'une\r\nconvention de stage. Le lieu de travail est le laboratoire Lattice Ã \r\nMontrouge, prÃ¨s de Paris (mÃ©tro Mairie de Montrouge)\r\n\r\n\r\nPour candidater, merci d\'envoyer un CV et un relevÃ© de notes rÃ©cent (M2\r\nen cours ou M1) Ã  : thierry.poibeau@ens.fr, en prÃ©cisant bien quel stage\r\nest visÃ©.\r\n \r\n\r\nReferences\r\n* P. Marchal 2015. Acquisition de schÃ©mas prÃ©dicatifs verbaux en\r\njaponais. ThÃ¨se de l\'INALCO. \r\n* P. Marchal, T. Poibeau et Y. Lepage (2012). \"Representing the\r\nContinuum between Arguments and Adjuncts within\r\nPredicate-â€‹â€‹Frames\". NINJAL International Symposium on \"Valency Classes\r\nand Alternations in Japanese\", Tokyo, August 2012.'),
(307, '2016-01-04', 'LATTICE', 'Paris', '* Inférence de grammaire à partir de données en ancien français\r\n* Analyse statistique des particularités de l\'ancien français sur la\r\n  base de corpus annoté\r\n\r\nLe Lattice a contribué à développer des bases de données annotées de\r\nl\'ancien français (morphosyntaxe et syntaxe). Diverses projets utilisent\r\ndéjà ces corpus annotés pour inférer des analyseurs automatiques,\r\nétudier l\'évolution de la langue et les particularités du français en\r\nfonction de la période considérée. Dans la continuité de ces travaux, le\r\nLattice propose un stage visant à mieux exploiter les ressources\r\nexistantes et à étudier leur utilisation sur d\'autres corpus en\r\ncollaboration avec des laboratoires partenaires, notamment au sein de\r\nl\'Ecole Nationale des Chartes.\r\n\r\nLe stagiaire devra être inscrit dans un Master 2, en informatique,\r\ntraitement automatique des langues, intelligence artificielle ou\r\nsciences cognitives. Tout profil présentant les compétences demandées\r\nsera pris en considération. Une connaissance même minimale de l\'ancien\r\nfrançais serait un plus.\r\n\r\nCompétences exigées :\r\n- connaissances en programmation\r\n- maîtrise d\'un langage de scripts (perl ou python)\r\n- si possible connaissance et intérêt pour l\'ancien français\r\n- anglais technique\r\n- qualités de rédaction\r\n- aptitude au travail en équipe\r\n\r\nConditions\r\n\r\nStages normalement prévu pour 6 mois à partir du mois d\'avril 2016 et\r\nrémunéré au tarif réglementaire. Le stage devra faire l\'objet d\'une\r\nconvention de stage. Le lieu de travail est le laboratoire Lattice à\r\nMontrouge, près de Paris (métro Mairie de Montrouge)\r\n\r\n\r\nPour candidater, merci d\'envoyer un CV et un relevé de notes récent (M2\r\nen cours ou M1) à : thierry.poibeau@ens.fr, en précisant bien quel stage\r\nest visé. \r\n\r\nReferences\r\n* G. Guibon, I. Tellier, M. Constant, S. Prevost, K. Gerdes 15 :\r\nSearching for Discriminative Metadata on Heterogenous Corpora, 14th\r\nTreebank and Language Theory (TLT), Varsovie, 2015.\r\n* G. Guibon, I. Tellier, M. Constant, S. Prevost, K. Gerdes 14 : Parsing\r\nPoorly Standardized Language Dependency on Old French, 13th Treebank and\r\nLanguage Theory (TLT), Tubingen, 2014.\r\n* A. Simonenko, B. Crabbé, S. Prevost 15 : Morphological triggers of\r\nsyntactic changes: Treebank-based Information Theoretic approach, 14th\r\nTreebank and Language Theory (TLT), Varsovie, 2015.'),
(308, '2016-01-04', 'LIGM', 'Paris ou Marne-la-Vallée', 'Reconnaissance d\'expressions polylexicales verbales et apprentissage\r\nprofond\r\n\r\n    Domaine: traitement automatique des langues\r\n\r\n    Lieu du stage: Alpage, UniversitÃ© Paris-Diderot ou LIGM,\r\n    UniversitÃ© Paris-Est Marne-la-VallÃ©e\r\n\r\n    Encadrant principal: Matthieu Constant\r\n\r\n    DurÃ©e du stage: 6 mois\r\n\r\n    RÃ©munÃ©ration: gratification rÃ©glementaire\r\n\r\n    Financement: UniversitÃ© Paris-Est Marne-la-VallÃ©e\r\n\r\nContexte du stage\r\n\r\nUne des tÃ¢ches fondamentales du traitement automatique des langues est\r\nde dÃ©velopper des analyseurs produisant automatiquement une\r\nreprÃ©sentation linguistique d\'un texte donnÃ© en entrÃ©e:\r\nex. segmentation lexicale, Ã©tiquetage grammatical, analyse syntaxique,\r\nanalyse sÃ©mantique, â€¦ Les stages proposÃ©s ci-dessous concernent la\r\nsegmentation lexico-sÃ©mantique et, en particulier, l\'identification\r\ndes expressions polylexicales, qui forment des combinaisons de mots\r\navec un certain degrÃ© d\'idiomaticitÃ©. Ces expressions sont trÃ¨s\r\nfrÃ©quentes et extrÃªmement variÃ©es. Par exemple, pomme de terre,\r\nprendre en grippe, alors que, en effet, en dÃ©pit de, â€¦ Elles posent de\r\nsÃ©rieux problÃ¨mes pour les applications du traitement automatique des\r\nlangues comme la traduction automatique. Cette proposition de stage se\r\nplace dans le cadre du projet ANR PARSEME-FR qui vise Ã  intÃ©grer ce\r\ntype dâ€™expressions au sein dâ€™analyseurs syntaxiques Ã  grande\r\nÃ©chelle. Ce stage pourra Ã©ventuellement se poursuivre en thÃ¨se.\r\n\r\nObjectifs\r\n\r\nL\'objectif de ce stage est dâ€™incorporer dans un outil dâ€™identification\r\nd\'expressions polylexicales des techniques dâ€™apprentissage profond (ou\r\ndeep learning), afin dâ€™amÃ©liorer ses performances. Dans un premier\r\ntemps, les techniques seront mises au point pour le franÃ§ais, la\r\nlangue de travail du projet PARSEME-FR. Puis, elles seront adaptÃ©es Ã \r\nun certain nombre de langues europÃ©ennes avec, pour objectif, Ã  moyen\r\nterme de participer Ã  la compÃ©tition internationale sur la\r\nreconnaissance dâ€™expressions verbales qui se tiendra dans le cadre de\r\nlâ€™action europÃ©enne COST PARSEME entre 2016 et 2017. Lâ€™un des enjeux\r\nimportants du stage sera de mettre en oeuvre des mÃ©thodes\r\ndâ€™apprentissage profond tenant compte dâ€™informations linguistiques\r\nprovenant de lexiques.\r\n\r\nLe stagiaire recrutÃ© sera amenÃ© Ã  collaborer avec des chercheurs de\r\nlâ€™Ã©quipe Alpage de lâ€™INRIA et du laboratoire Lattice.\r\n\r\nCandidater\r\n\r\nProfil du candidat:\r\n\r\n    Master 2 ou Ã©cole d\'ingÃ©nieur en informatique ou TAL\r\n\r\n    trÃ¨s bonnes compÃ©tences de programmation objet (Java ou C++),\r\n\r\n    bonnes connaissances des techniques d\'apprentissage, notamment le\r\n    deep learning\r\n\r\nLes candidatures doivent Ãªtre envoyÃ©es par mail Ã \r\nMathieu.Constant@u-pem.fr. Le dossier de candidature contiendra un cv,\r\nune lettre de motivation, et, Ã©ventuellement, la recommandation d\'un\r\nenseignant.'),
(309, '2016-01-04', 'LIGM', 'Paris ou Marne-la-Vallée', 'Développement d\'outils d\'enrichissement d\'un lexique d\'expressions\r\npolylexicales du français\r\n\r\n    Domaine: traitement automatique des langues\r\n\r\n    Lieu du stage: Alpage, Université Paris-Diderot ou LIGM,\r\n    Université Paris-Est Marne-la-Vallée\r\n\r\n    Encadrant principal: Matthieu Constant\r\n\r\n    Durée du stage: 6 mois\r\n\r\n    Rémunération: gratification réglementaire\r\n\r\n    Financement: Université Paris-Est Marne-la-Vallée\r\n\r\nContexte du stage\r\n\r\nUne des tâches fondamentales du traitement automatique des langues est\r\nde développer des analyseurs produisant automatiquement une\r\nreprésentation linguistique d\'un texte donné en entrée:\r\nex. segmentation lexicale, étiquetage grammatical, analyse syntaxique,\r\nanalyse sémantique, ... Les stages proposés ci-dessous concernent la\r\nsegmentation lexico-sémantique et, en particulier, l\'identification\r\ndes expressions polylexicales, qui forment des combinaisons de mots\r\navec un certain degré d\'idiomaticité. Ces expressions sont très\r\nfréquentes et extrêmement variées. Par exemple, pomme de terre,\r\nprendre en grippe, alors que, en effet, en dépit de, ... Elles posent de\r\nsérieux problèmes pour les applications du traitement automatique des\r\nlangues comme la traduction automatique. Cette proposition de stage se\r\nplace dans le cadre du projet ANR PARSEME-FR qui vise à intégrer ce\r\ntype d\'expressions au sein d\'analyseurs syntaxiques à grande\r\néchelle. Ce stage pourra éventuellement se poursuivre en thèse.\r\n\r\nObjectifs\r\n\r\nL\'identification des expressions polylexicales passe en général par la\r\nconsultation de ressources lexicales riches. Il existe un certain\r\nnombre de telles ressources pour le français. Cependant, celles-ci\r\nsont souvent incomplètes en termes de couverture, de propriétés\r\nsyntaxico-sémantiques, et ne sont pas toujours directement\r\nexploitables pour les outils du TAL.\r\n\r\nL\'objectif du stage est de développer des outils permettant:\r\n    d\'agréger plusieurs lexiques dans un cadre unifié\r\n\r\n    de les enrichir (semi-)automatiquement en termes de propriétés\r\n    morphologiques, syntaxiques et sémantiques\r\n\r\nLe stagiaire recruté sera en collaboration étroite avec des linguistes\r\ndu LIGM. Il travaillera également en collaboration avec des chercheurs\r\nde l\'équipe BdTln du Laboratoire d\'informatique de l\'Université\r\nFrançois-Rabelais.  \r\n\r\nCandidater\r\n\r\nProfil du candidat:\r\n\r\n    Master 2 en TAL ou linguistique informatique\r\n    bonnes compétences d\'un langage de script (ex. python ou perl)\r\n\r\nLes candidatures doivent être envoyées par mail à\r\nMathieu.Constant@u-pem.fr. Le dossier de candidature contiendra un cv,\r\nune lettre de motivation, et, éventuellement, la recommandation d\'un\r\nenseignant.'),
(310, '2016-01-04', 'Talend & LIMSI', 'Paris & Orsay', 'Stage Master 2 de Recherche 2015-2016\r\n\r\nhttps://perso.limsi.fr/pap/talend_internship_2015/stage_limsi_talend_2015_2016.html\r\n\r\nTalend - LIMSI-CNRS\r\n\r\nLiaison Référentielle d\'Entités Nommées dans un contexte Big Data\r\n\r\nBig Data Referential Named Entity Linking\r\n\r\nDéveloppement d\'un logiciel permettant de lier l\'occurrence d\'une Entité\r\nNommée dans un extrait de texte à la représentation de l\'entité dans des\r\nbases de connaissances en contexte Big Data\r\n\r\n------------------------------------------------------------------------\r\nQui ?\r\n\r\nTalend est une société édititrice de logiciels (http://www.talend.com/)\r\nfondée en 2006, spécialisée dans l\'Open Source pour l\'intégration et la\r\ngestion des données. Son siège social est basé à Redwood City\r\n(États-Unis) et elle compte plus de 400 personnes, avec des bureaux dans\r\nplusieurs pays, dont la France (https://fr.talend.com/).\r\n\r\nAu sein du laboratoire pluridisciplinaire LIMSI-CNRS\r\n(https://www.limsi.fr/fr/), constitué d\'un département de mécanique des\r\nfluides et d\'un département Communication-Homme-Machine, le groupe\r\nInformation Langues Écrite et Signée - ILES\r\n(https://www.limsi.fr/fr/recherche/iles), effectue depuis de nombreuses\r\nannées des recherches en Traitement Automatique des Langues Naturelles\r\nsur l\'écrit et la Langue des Signes. Le groupe étudie entre autres\r\ndomaines, les corpus et leurs représentations, l\'apprentissage\r\nautomatique, l\'évaluation des technologies l\'analyse du langage naturel,\r\nle multilinguisme et les paraphrases, l\'extraction d\'information et les\r\nSystèmes Réponse aux Questions, la fouille d\'opinion et analyse de\r\nsentiments.\r\n\r\n------------------------------------------------------------------------\r\nQuoi ?\r\n\r\nLes Entités Nommées sont des objets informationnels à la frontière de la\r\nLinguistique, du Traitement Automatique des Langues et de la Recherche\r\nd\'Information issus des campagnes d\'évaluation Nord-américaines en\r\nExtraction d\'Information. Elément essentiel de la mise en relation du\r\ncontenu informationnel d\'un texte avec le monde réel, elles forment un\r\nensemble hétérogène, sur le plan lexical comme sur le plan sémantique et\r\nont connu des définitions de plus en plus riches et complexes au fur et\r\nà mesure que leur utilisation s\'est développée. Leur traitement par un\r\nsystème informatique suppose que celui-ci soit capable de les:\r\n\r\n1) détecter, c\'est à dire d\'identifier dans un document les empans de\r\n   texte représentant une Entité Nommée,\r\n\r\n2) classer selon leur type (personne, organisation, lieu géographique,\r\n   etc.),\r\n\r\n3) lier à leur \"referrent\", c\'est à dire de les associer à la dénotation\r\n   de l\'entité réelle associée, stockée dans une base de connaissances.\r\n\r\nLe sujet du stage sera de développer un système effectuant ces trois\r\ntâches sur des données textuelles (données non-structurées) dans un\r\ncontexte Big Data.\r\n\r\nLa société Talend dispose actuellement, d\'une part d\'un prototype de\r\nlogiciel d\'anonymisation de documents et d\'autre part, d\'un analyseur de\r\ndonnées structurées permettant de construire automatiquement des bases\r\nde connaissances. En partant du prototype d\'anonymiseur et des\r\nfonctionnalités d\'analyse de données structurée Talend et des ressources\r\nlinguistiques disponibles au LIMSI, le/la stagiaire fera une étude de\r\nl\'état de l\'art et des solutions existantes en logiciel libre pour\r\ndévelopper (prototype) un système réalisant les tâches (1), (2) et (3).\r\n\r\nLe résultat attendu est d\'une part l\'amélioration de l\'anonymisation et\r\nd\'autre part le peuplement de bases de connaissances sur les Entités\r\nNommées à partir de documents ou d\'extraits de documents dans un\r\ncontexte Big Data.\r\n\r\n------------------------------------------------------------------------\r\nComment ?\r\n\r\nLes prérequis. Le/la stagiaire devra être autonome en ce qui concerne la\r\nprogrammation dans des langages de haut niveau et avoir soit une\r\nexpérience minimale de l\'utilisation de ressources linguistiques\r\n(lexiques, grammaires, automates de reconnaissance), soit des\r\nconnaissances théoriques en langages formels.\r\n\r\nUne expérience des outils Big Data comme Hadhoop, Hive, SparkSQL ou au\r\nmieux SPARK ou Talend seront des facteurs déterminants dans la sélection\r\ndes candidats.\r\n\r\nEn outre des compétences Apprentissage Automatique ou Intelligence\r\nArtificielle ou bien encore en Statistiques seront des plus appréciés.\r\n\r\nBien entendu, il/elle devra disposer d\'une bonne maîtrise des langues\r\nfrançaise et anglaise pour pourvoir utiliser au quotidien la littérature\r\nscientifique.\r\n\r\n------------------------------------------------------------------------\r\nAdministratif\r\n\r\nLe stage sera indemnisé à hauteur de 1000¤ par mois par Talend.\r\n\r\nIl prendra place en alternance à Paris dans les locaux de Talend et à\r\nOrsay, sur le plateau de Saclay, dans l\'équipe ILES du LIMSI-CNRS.\r\n\r\nIl sera co-encadré par :\r\n- Sebastiao Correia (scorreia@talend.com) pour Talend et\r\n- Patrick Paroubek pour le LIMSI -CNRS (pap@limsi.fr).\r\n\r\nLes transports (mensuel ou annuel) seront pris en charge à 50% par\r\nTalend.\r\n\r\nLe stage se déroulera sur une période de 5 mois consécutifs.\r\n\r\nLa période initialement prévue pour le stage est de janvier à juin 2016,\r\nmais pourra être aménagée en fonction des besoins de chacun.\r\n------------------------------------------------------------------------'),
(311, '2016-01-04', 'SESAMm', 'Metz', 'Our team is looking for an intern in Natural Language Processing for\r\ntraditional and simplified Chinese for 6 months.\r\n\r\nSESAMm was founded in 2014 and is one of the most dynamic FinTech\r\nstartups in France and Luxembourg. SESAMm develops and commercializes\r\nstock market forecasting tools based on social media and other textual\r\ndata sources.These products are used by banks and hedge funds. The\r\ncompany provides financial trading indicators which have been created\r\nusing Big Data methods and allowing new approaches for trading\r\nstrategies. We develop many new products based on our clients\' needs.\r\n\r\nSESAMm aims at becoming the international leader of Big Data\r\ntechnologies for stock market professionals.\r\n\r\nInternship Goal: development of new text-analysis and sentiment analysis\r\nmethods to create financial trading indicators based on information from\r\nChinese social media and social trading platforms.\r\n\r\nMajor Duties:\r\n- Participate in existing and future research projects: analyze existing\r\n  methods, develop original solutions and evaluate them, present results\r\n- Identify relevant sources of information and extract data. Crawling &\r\n  scraping of several data sources.\r\n- Filter and prepare data\r\n- Develop NLP algorithms for traditional and simplified Chinese.\r\n- Write analysis reports\r\n\r\nEducation Requirements\r\n- Engineering school or university master student: Computer Science,\r\n  Natural Language Processing or similar.\r\n\r\nWork Experience and Skills Requirements\r\n- Work Experience: 0-1 year in NLP or computer science.\r\n- Knowledge in NLP, Machine Learning, crawling and scraping.\r\n- Demonstrate ability to create lexical semantic resources for NLP-based\r\n  applications.\r\n- Languages: native Mandarin, traditional and simplified Chinese\r\n  written.\r\n- Programming Skills : Java and scripting languages\r\n\r\nThe applicant should be able to work in a team and show high\r\nmotivation. This internship requires autonomy and curiosity toward a\r\nchanging environment. The intern will contribute to the company\'s most\r\nimportant technical decisions; thereby this internship will be a\r\nhigh-level entrepreneurial experience.\r\n\r\nWorking Conditions\r\n- Percent Time: 100%\r\n- Location: Metz (France)\r\n- Duration: 6 months, starting in February 2016.\r\n \r\n\r\nJoin SESAMm, an innovative and ambitious FinTech startup with high\r\npotential.\r\nMore information: www.sesamm.com\r\nPlease send your application to contact@sesamm.com\r\nApplication: resume, interview'),
(312, '2016-01-08', 'Inalco', 'Paris', 'Stage M2 TAL Ã  l\'Inalco\r\nDÃ©sambiguisation lexicale pour les langues mandingues\r\n\r\nLe stage proposÃ© vise Ã  dÃ©velopper des outils de dÃ©sambiguisation\r\nlexicale (tonalitÃ©s et gloses) en exploitant des corpus et des mÃ©thodes\r\nd\'apprentissage statistique. Il portera sur deux langues africaines, le\r\nbambara et le maninka, des langues mandingues parlÃ©es en Afrique de\r\nl\'Ouest et dans la diaspora africaine. Il s\'agit de dÃ©terminer, pour\r\nchaque token du corpus, l\'entrÃ©e lexicale concernÃ©e, en s\'appuyant sur\r\ndes mÃ©canismes liÃ©s Ã  la tonalisation (partiellement codÃ©es ou annotÃ©es\r\net au glosage (annotÃ©).\r\n\r\nDeux corpus sont collectÃ©s depuis plusieurs annÃ©es et continuellement\r\nalimentÃ©s : le Corpus Bambara de RÃ©fÃ©rence (CBR,\r\nhttp://cormand.huma-num.fr) et le Corpus Maninka de RÃ©fÃ©rence (Vydrine\r\n2013, Maslinsky 2014). Le premier est codÃ© avec un alphabet latin, le\r\nsecond avec le systÃ¨me d\'Ã©criture N\'ko. Une sous partie du CBR (425K\r\nmots) a Ã©tÃ© annotÃ© manuellement, ce qui permettra de faire appel Ã \r\ntechniques d\'apprentissage supervisÃ©. Ces deux corpus ayant des textes\r\nen commun (la Bible, le Coran), la construction d\'un corpus parallÃ¨le\r\nest Ã©galement envisagÃ©e.\r\n\r\nL\'objectif du stage est de dÃ©terminer la faisabilitÃ© d\'un systÃ¨me pour\r\nrÃ©aliser automatiquement la tonalisation et le glosage (de maniÃ¨re\r\nsÃ©quentielle ou jointe) sur ces corpus, en exploitant plusieurs critÃ¨res\r\nlinguistiques : morphologie des tokens, contextes et informations\r\ndistributionnelles, dictionnaires existants, etc. Il serait intÃ©ressant\r\nde mettre en Ã©vidence et d\'exploiter les proximitÃ©s entre ces deux\r\nlangues pour ces tÃ¢ches. Suite aux Ã©valuations, l\'approche donnant les\r\nmeilleurs rÃ©sultats sera dÃ©veloppÃ©e sous la forme d\'un module Ã  intÃ©grer\r\nÃ  la plateforme TAL en cours de dÃ©veloppement pour ces langues\r\n(Maslinsky 2014).\r\n\r\nProfil recherchÃ© :\r\n+ Master 2 en informatique et/ou en linguistique\r\n+ IntÃ©rÃªt pour le traitement automatique des langues\r\n+ CompÃ©tences en programmation (Python)\r\n+ Connaissance des approches utilisÃ©es en apprentissage automatique\r\n+ La connaissance des langues mandingues sera un plus\r\n\r\nPour candidater, merci d\'envoyer votre CV, vos relevÃ©s de notes, vos\r\nmotivations et tout autre Ã©lÃ©ment utile Ã  Damien Nouvel\r\n(damien.nouvel@inalco.fr).\r\n\r\nDurÃ©e du stage : 5 mois Ã  temps plein\r\nDate de dÃ©but : fÃ©vrier ou mars 2016\r\nGratification : 554â‚¬/mois (et rbst de 50% des transports)\r\nLieu : Inalco, 2 rue de Lille, 75007 Paris\r\nContact: Damien Nouvel (damien.nouvel@inalco.fr)\r\n\r\nRÃ©fÃ©rences :\r\n\r\n(Nouvel et. al. 2015) Traitement automatique du bambara - Objectifs et\r\npremiers rÃ©sultats. SÃ©minaire LIMSI-CNRS ILES, 2015.\r\n(Maslinsky 2014) Maslinsky, Kirill. Daba: a model and tools for Manding\r\ncorpora. Atelier TALAF, Traitement Automatique des Langues Naturelles,\r\n2014.\r\n(Vydrine 2013) Vydrin, Valentin. Bamana Reference Corpus (BRC) Procedia -\r\nSocial and Behavioral Sciences, 95:25 October 2013, pp. 75-80.\r\nhttp://www.sciencedirect.com/science/journal/18770428\r\n(Vydrine 2014) Vydrin, Valentin. Projet des corpus Ã©crits des langues\r\nmanding : le bambara, le maninka. Atelier TALAF, Traitement Automatique\r\ndes Langues Naturelles, 2014.'),
(313, '2016-01-08', 'INRA', 'Avignon', 'Le Pôle Gestion des connaissances (GeCo) de la DIST de l\'INRA propose un\r\nstage de 4 à 6 mois sur l\'amélioration du thésaurus VocINRA en utilisant\r\ndes outils et standards du web sémantique.\r\n\r\n\r\nLe thésaurus VocINRA sert à l\'indexation de l\'Archive Ouverte Prodinra\r\n(http://www.prodinra.fr), spécialisée en agronomie et domaines associés\r\ntels que l\' environnement, les sciences sociales, la génomique, les\r\nbiosciences, etc. Il est multilingue, principalement français et\r\nanglais.\r\n\r\nVocINRA a été constitué à partir de différentes sources et est en\r\nconstante évolution puisque les documentalistes de l\'Inra proposent de\r\nnouveaux mots clés selon un workflow de validation/enrichissement. Des\r\ntravaux d\'alignement de VocINRA avec des thésaurus de référence comme\r\nAgrovoc/GACS ont démarré et seront poursuivis, en particulier dans le\r\ncadre d\'une collaboration avec l\'Embrapa Brésil. La publication d\'une\r\nversion en Linked Open Data est également prévue. VocINRA est\r\nactuellement maintenu et exploité à l\'aide d\'un outil développé\r\nspécifiquement en interne et nous étudions la possibilité d\'utiliser\r\nVocBench (http://aims.fao.org/fr/vest-registry/tools/VocBench-2) pour le\r\nremplacer\r\n\r\nL\'objectif de ce stage est d\'améliorer VocINRA à l\'aide de VocBench :\r\n\r\n  * Réorganiser   l\'arborescence\r\n  * Regrouper les termes synonymes ou très proches autour du même\r\n    concept\r\n  * Enrichir les concepts avec des liens vers des concepts dans d\'autres\r\n    ressources (ex: Agrovoc)\r\n  * Rédiger des documents d\'accompagnement de l\'utilisation de VocINRA\r\n    sur VocBench.\r\n\r\nEn fonction de l\'avancement du stage et des motivations du stagiaire,\r\nd\'autres sujets pourront être abordés tels que :\r\n\r\n  * Etablir une démarche qualité pour la gestion de VocInra\r\n  * Accompagner la publication en Linked Open Data\r\n\r\n\r\n*Formation et profil requis*\r\n\r\n- Master 2 en cours (4 à 6 mois) avec une spécialité ingénierie\r\n  linguistique ou terminologique\r\n\r\n- Connaissances de la gestion des vocabulaires et des technologies du\r\n  web sémantique (format SKOS et RDF, Linked Open Data, Ontologies).\r\n\r\n- Capacité pour la prise d\'initiative\r\n\r\n- Autonomie\r\n\r\n- Créativité\r\n\r\n- Facilité relationnelle\r\n\r\n\r\n*Encadrement :*\r\n\r\nPascal Aventurier - Responsable de ERIST (Equipe Régionale d\'Information\r\nscientifique et Technique) du centre INRA Paca (Avignon).  Animateur du\r\npôle Technologies de l\'IST Pascal.Aventurier@paca.inra.fr tel 04 32 72\r\n20 13\r\n\r\nSophie Aubin - Animatrice du pôle GeCo (Gestion des Connaissances) DIST\r\nINRA Versailles sophie.aubin@versailles.inra.fr (tel 01 30 83 34 20)\r\n\r\n\r\n*Conditions du stage*\r\n\r\n- Stage conventionné (4 à 6 mois).\r\n\r\n- Gratification de stage : 554,50 euros  pour un temps plein\r\n\r\n- Prise en charge partielle du coût du repas de midi dans la cantine\r\n  d\'entreprise.\r\n\r\n- Participation aux frais de transport (trajet domicile/travail en\r\n  transport public).\r\n\r\n- possibilité éventuelle d\'hébergement en chambre de stagiaire\r\n\r\n- Lieu de travail : INRA Centre de Recherche PACA. Avignon, Domaine St \r\n  Paul - AgroParc');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(314, '2016-01-08', 'L3i', 'La Rochelle', 'Stage Master 2 au L3i\r\n\r\nModèle décisionnel basé sur un entrepôt de données au sein d\'un système\r\nd\'information stratégique\r\n\r\nContexte du stage :\r\n\r\nActuellement, les technologies décisionnelles permettent aux structures\r\nd\'organiser leurs masses de données et d\'en tirer le meilleur\r\nparti. Dans ce stage, l\'objectif est de construire un modèle décisionnel\r\nbasé sur un entrepôt de données au sein d\'un système d\'information\r\nstratégique. Ce modèle décisionnel porte sur les données du système de\r\ngestion de la scolarité.\r\n\r\n\r\nObjectif :\r\n\r\nLe système de gestion de la scolarité est une partie importante du\r\nsystème d\'information d\'un établissement d\'enseignement, en particulier\r\ndans le supérieur. Les processus métiers du système de gestion de la\r\nscolarité sont souvent une affaire de spécialistes dû à : \r\n\r\n- la complexité des données : elles sont thématiques, historisées et non\r\n  volatiles ; \r\n- la diversité des sources de données : Application Post-Bac (APB),\r\n  Campus France, bases de données locales, Open-Data, etc. ;\r\n- des processus métiers avec des règles précises : notamment celles\r\n  liées à des textes réglementaires ; \r\n- des processus métiers avec des règles utilisateurs : liées à des\r\n  usages et des procédures internes définies au sein de la structure. \r\n\r\nLes responsables de ces structures sont souvent amenés à extraire des\r\nindicateurs complexes portant sur différentes phases de la scolarité\r\n(candidature, inscription, validation de semestres, etc.). En général,\r\nces indicateurs sont formellement bien définis. On les retrouve dans\r\ndivers tableaux de bords, ou des rapports d\'activités pour un usage\r\ninterne à la structure, pour l\'université, pour des regroupements\r\nrégionaux ou lors de dossiers demandés par le Ministère de\r\ntutelle. Toutefois, les responsables des structures sont aussi\r\nconscients de la capacité expressive des données et souhaitent tirer\r\nplus d\'informations pertinentes en particulier celles qui sont liées au\r\nterritoire.\r\n\r\nLe schéma opérationnel de réalisation du travail demandé se résume comme\r\nsuit :\r\n\r\n- Concevoir un business model de la reprise de données des applications\r\n  de scolarité : il s\'agit d\'automatiser l\'ensemble des processus\r\n  constituant la reprise de données pour  l\'alimentation de l\'entrepôt. \r\n- Concevoir un modèle de vérification, de consolidation et d\'intégration\r\n  des données : modèle basé sur des procédures dites « data checking\r\n  tests ». \r\n- Concevoir le modèle décisionnel : il s\'agit en fait d\'une\r\n  instanciation du modèle décisionnel défini dans le système décisionnel\r\n  actuel. \r\n- Implanter les indicateurs métiers : cette phase nécessite une\r\n  connaissance approfondie du méta-modèle utilisé par le modèle\r\n  décisionnel. On s\'intéresse en particulier aux problèmes des mesures\r\n  semi-additives, et particulier les mesures dites KPI (key performance\r\n  indicators).  \r\n\r\nPrérequis :\r\n\r\nCe sujet d\'adresse aux étudiants en Master 2 Informatique, ou élève de\r\ndernière année d\'une école d\'ingénieur en informatique. Vous êtes\r\nrigoureux dans votre travail mais aussi créatif avec une forte envie\r\nd\'apprendre et de vous investir dans un projet décisionnel de taille\r\nréelle au sein d\'un environnement professionnel regroupant divers\r\nacteurs.\r\n\r\nLes technologies utilisées dans le cadre de la mise en oeuvre sont :\r\n\r\n- Programmation : Java - JEE (ejb, seam, jsf, xml, ajax, webservices, etc.) \r\n\r\n- Modélisation dimensionnelle : Mondrian - Données multidimensionnelles : \r\n  MDX, XQuery \r\n\r\n- Solution d\'informatique décisionnelle : Pentaho CE (Kettle, BI Server,\r\n  Report Designer, Shema Workbench ...)\r\n\r\n- Base de données : PostgreSQL (avec la cartouche spatiale) \r\n\r\n- Gestion et automatisation du projet : Maven, Redmine \r\n\r\nInformations complémentaires :\r\n\r\nEncadrant(s) : Jamal Malki*, Olivier Sauzet** et Patrice Joubert** \r\n\r\nCadre de coopération : L3i (*) - IUT La Rochelle (**) \r\n\r\nDate de début du stage : à partir du début de l\'année 2016 \r\n\r\nDurée du contrat : 5 mois (minimum) \r\n\r\nStage rémunéré\r\n\r\nCandidature :\r\n\r\nMerci d\'adresser votre dossier de candidature à : jamal.malki@univ-lr.fr\r\nLe dossier de candidature doit contenir : \r\n\r\n- le CV\r\n\r\n- les relevés de notes des 2 dernières années (M1 et M2)\r\n\r\n- la lettre de motivation\r\n\r\n- tout autres documents pouvant appuyer la candidature \r\n\r\n\r\nJamal MALKI\r\nLaboratoire L3i, Université de La Rochelle\r\nDépartement Informatique\r\nIUT La Rochelle \r\njmalki@univ-lr.fr <mailto:mickael.brasebin@ign.fr>'),
(315, '2016-01-08', 'ERIC', 'Lyon', 'Stage recherche de Master au laboratoire ERIC (université de Lyon)\r\n\r\nDétection de métaphores dans le discours scientifique\r\n\r\nCONTEXTE\r\n\r\nLa métaphore est une figure de rhétorique largement utilisée dans le\r\nlangage courant (par exemple « j\'y crois dur comme fer » ou « les\r\nacteurs de la politique de transport »).  Elle est fondée sur l\'analogie\r\n; elle permet à un mot de recevoir, dans une phrase, un sens différent\r\ndu sens courant en lui donnant le sens que l\'on attribue généralement à\r\nun autre mot.  La métaphore est également très utilisée dans le discours\r\nscientifique notamment en Sciences Sociales où elle est au coeur du\r\nraisonnement intellectuel. Nous pensons d\'abord par des images. Cela\r\nfait de la métaphore un domaine de recherche importante non seulement en\r\nsciences du langage, en sciences cognitives mais en géographie où elle\r\nest très utilisée par les chercheurs. \r\n\r\nLa détection et l\'interprétation automatique de métaphores est également\r\nune tâche critique pour le traitement automatique de la langue (TAL) et\r\nl\'extraction d\'information.\r\n\r\nLes travaux sur la détection et la modélisation de métaphores en  TAL et\r\nen intelligence artificielle ont certes commencé dans les années 80,\r\nnous fournissant une foule d\'idées sur la structure et les mécanismes du\r\nphénomène. La dernière décennie a été en revanche témoin d\'un saut\r\ntechnologique avec un nombre croissant d\'approches exploitant des\r\ntechniques statistiques. Par rapport aux approches plus traditionnelles\r\nissues des connaissances codées manuellement, ces méthodes plus récentes\r\ntendent à avoir une couverture plus large ; elles sont souvent moins\r\nprécises mais elles sont aussi plus efficaces et robustes. Ainsi,\r\nplusieurs approches de détection de métaphores ont été proposées\r\n(Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Shutova et al.,\r\n2010) et elles reposent sur l\'utilisation d\'une ressource lexicale de\r\ntype WordNet, TreeBank, etc. Ces ressources lexicales existent\r\nessentiellement pour l\'Anglais, le Français ou l\'Espagnol. Pour les\r\nautres langues, elles n\'existent pas ou elles sont de moindre qualité.\r\nYulia Tsvetkov et al., 2013 proposent  alors une méthode de détection\r\ndes métaphores sans utiliser de ressource lexicale.\r\n\r\nNous nous plaçons dans un cadre récent qui est celui de l\'utilisation de\r\nméthodes d\'apprentissage automatique pour la détection et\r\nl\'interprétation de métaphores. Dans le cadre du stage, nous nous\r\nintéressons à une science sociale particulière qui est la géographie car\r\nnous nous basons sur l\'hypothèse que le raisonnement scientifique\r\ngéographique s\'est en grande partie construit à partir de figures de\r\nrhétorique. \r\n\r\nOBJECTIF DU STAGE\r\n\r\nIl sera demandé au stagiaire de :\r\n\r\n- réaliser un état de l\'art sur les différentes méthodes de détection\r\n  automatique de métaphores,\r\n\r\n- mener une étude comparative sur les outils utilisables,\r\n\r\n- finaliser la construction d\'un corpus d\'articles scientifiques en\r\n  géographie,\r\n\r\n- tester les méthodes et outils existants sur le corpus d\'articles.\r\n\r\nCOMPETENCES\r\n\r\nLe sujet de stage s\'adresse à des étudiants de master en informatique\r\ndécisionnelle, en fouille de données, en intelligence artificielle ou en\r\ntraitement automatique des langues. Des compétences en statistique, en\r\napprentissage automatique et/ou en TAL seraient particulièrement\r\nappréciées.\r\n\r\nREFERENCES\r\n\r\nMatt Gedigian, John Bryant, Srini Narayanan, and Branimir\r\nCiric. Catching metaphors. Proceedings of the 3rd Workshop on Scalable\r\nNatural Language Understanding, pages 41-48. 2006.\r\n\r\nSaisuresh Krishnakumaran and Xiaojin Zhu. Hunting elusive metaphors\r\nusing lexical resources. Proceedings of the Workshop on Computational\r\napproaches to Figurative Language, pages 13-20. 2007\r\n\r\nShutova Lin Sun and Anna Korhonen. Metaphor identification using verb\r\nand noun clustering. Proceedings of the 23rd International Conference on\r\nComputational Linguistics, pages 1002-1010. 2010.\r\n\r\nYulia Tsvetkov, Elena Mukomel, Anatole Gershman. Cross-Lingual Metaphor\r\nDetection Using Common Semantic Features. First workshop on Metaphor in\r\nNLP (Meta4NLP). 2013.\r\n\r\n\r\nINFORMATIONS COMPLEMENTAIRES\r\n\r\nLieu : laboratoire ERIC (Lyon, France)\r\n\r\nEncadrants : Sabine Loudcher et Julien Velcin (laboratoire ERIC),\r\n             Isabelle Lefort (laboratoire EVS).\r\n\r\nDurée : 4 mois à partir de mars ou avril 2016\r\n\r\nRémunération : 554¤ par mois\r\n\r\nMerci d\'adresser votre candidature avec un CV, une lettre de motivation\r\nainsi que vos notes de l\'année universitaire en cours et de l\'année\r\ndernière à Sabine Loudcher (sabine.loudcher@univ-lyon2.fr) et Julien\r\nVelcin (julien.velcin@univ-lyon2.fr)'),
(316, '2016-01-11', 'Object\'ive', 'Paris', '== Titre ==\r\n\r\nStage R&D - Data Scientist : détection de tendances à partir d\'articles\r\nde presse en ligne.\r\n\r\n== Contexte ==\r\n\r\nObject\'ive est une entreprise spécialisée dans l\'intégration de solution\r\nd\'analyse avancée (sémantique, prédictif) et dans les migrations\r\narchitecturales complexes (http://www.object-ive.com/). Elle a notamment\r\ndéveloppé Cognit\'ive, une solution d\'analyse sémantique (\r\nhttp://www.object-ive.com/index.php?option=com_content&view=article&id=47&Itemid=109).\r\nVous serez recruté au sein d\'Object\'ive en tant que stagiaire Data\r\nScientist, rattaché à la Recherche et au Développement (R&D) pour les\r\nsolutions d\'analyse sémantique. Vous travaillerez dans une petite\r\nstructure avec une ambiance conviviale, au sein de nos locaux situés à\r\nParis, près de Nation.\r\n\r\nLa solution Cognit\'ive recherche, enrichit, et indexe des contenus texte\r\nde formats divers. Ces contenus proviennent de sources hétérogènes,\r\ncomme des articles de presse en ligne, ou des bases de données\r\ninternes. Les informations sont rassemblées dans un système de gestion\r\nde contenu, et consultables sous la forme d\'un site web. Les opérations\r\nd\'analyse sémantique réalisées par Cognit\'ive reposent sur des\r\nalgorithmes de Fouille de Données texte (text-mining), et utilisent des\r\nmodèles d\'Apprentissage Automatique (machine learning).\r\n\r\n== Mission ==\r\n\r\nNous cultivons un esprit d\'innovation, et nous travaillons constamment\r\nau développement de nouvelles solutions d\'analyse. Vous contribuerez à\r\ncette dynamique, en concevant un module d\'analyse sémantique pour la\r\ndétection de tendances à partir d\'articles de presse en ligne. Votre\r\nstage sera appliqué au domaine des architectures logicielles\r\n(frameworks) et des langages de programmation. Vous adopterez une\r\ndémarche R&D, et vous utiliserez des méthodes statistiques et des\r\nméthodes d\'apprentissage automatique. Vous serez encadré dans votre\r\ntravail par une Data Scientist ( scampano@object-ive.com) et un\r\nArchitecte Logiciel (fstepho@object-ive.com).\r\n\r\n== Objectifs ==\r\n\r\nAfin de mener à bien votre mission, vous suivrez des étapes\r\ncorrespondant à votre rôle de Data Scientist :\r\n\r\n- vous recueillerez et nettoierez des données sur des sites de presse en\r\n  ligne. Pour réaliser cette tâche, vous utiliserez la plate-forme\r\n  Cognit\'ive, qui dispose d\'un module de parcours de site web (crawling)\r\n  et d\'extraction de contenu (scraping).\r\n\r\n- vous réaliserez une analyse exploratoire des données collectées, pour\r\n  les décrire et proposer des premières hypothèses de modélisation de\r\n  tendance.\r\n\r\n- vous proposerez et implémenterez un modèle d\'analyse de tendances basé\r\n  sur des mesures statistiques et / ou de l\'Apprentissage Automatique\r\n  (Machine Learning). Vous travaillerez de façon itérative, en proposant\r\n  rapidement une première version, puis en améliorant progressivement\r\n  votre modèle.\r\n\r\n- vous concevrez et vous implémenterez la visualisation graphique des\r\n  tendances détectées par votre modèle.\r\n\r\nEn fonction de votre profil et de vos centres d\'intérêt, certaines\r\nétapes pourront être plus approfondies. Vous serez accompagné par vos\r\nencadrants dans chacune de ces étapes.\r\n\r\n== Profil attendu ==\r\n\r\nEn Master 2 ou en dernière année d\'école d\'Ingénieur, vous êtes\r\nintéressé par le domaine de la Data Science, et du Web Sémantique. Vous\r\nêtes autonome, vous aimez tester des hypothèses, et vous avez le sens de\r\nl\'analyse. Vous souhaitez apprendre, et partager vos connaissances.\r\n\r\nCompétences techniques attendues :\r\n\r\n- vous avez impérativement des connaissances en statistiques et en\r\n  Machine Learning, que vous avez déjà mis en pratique lors d\'un projet\r\n  d\'études ou en entreprise.\r\n\r\n- vous savez impérativement programmer en Python ou Java\r\n- si vous avez des connaissances en Traitement Automatique du Langage ou\r\n  Fouille de Données Texte, c\'est un plus\r\n- si vous avez une première expérience impliquant une démarche R&D\r\n  (stage R&D en entreprise ou stage de recherche en laboratoire), c\'est\r\n  un plus\r\n\r\n== Perspectives ==\r\n\r\nEn fonction des résultats obtenus, le stage aura la possibilité d\'être\r\npoursuivi par une thèse CIFRE, en partenariat avec Télécom ParisTech.\r\n\r\n== Durée du stage ==\r\n\r\nVous effectuerez un stage de 6 mois, avec la possibilité de commencer à\r\npartir de février 2016.\r\n\r\n== Lieu du stage ==\r\n\r\nObject\'ive\r\n96-98 rue de Montreuil\r\n75011 Paris\r\n\r\n== Gratification de stage ==\r\n\r\nVous recevrez une gratification définie selon votre profil et vos\r\ncompétences. Vous bénéficierez de tickets restaurant et d\'un\r\nremboursement partiel de votre titre de transport.\r\n\r\n== Processus de candidature ==\r\n\r\nVous êtes intéressé ? Nous serons ravis d\'étudier votre candidature.\r\nEnvoyez une lettre de motivation et un cv aux contacts suivants :\r\n\r\nSabrina Campano, Data Scientist\r\nObject\'ive\r\nscampano@object-ive.com\r\n\r\n\r\nFabien Stepho, Architecte Logiciel\r\nObject\'ive\r\nfstepho@object-ive.com\r\n\r\nMarion Huet, Assistante Ressources Humaines\r\nObject\'ive\r\nmhuet@object-ive.com'),
(317, '2016-01-13', 'LIMSI', 'Orsay', 'Stage Master 2 de Recherche en Traitement automatique des\r\nlangues/Extraction d\'information\r\n\r\nIntitulé : Reconnaissance des Entités Nommées MÉDicales dans l\'Oral\r\n(REMEDO)\r\n\r\nDurée : 5 mois\r\nLieu : LIMSI-CNRS, Orsay, France\r\nRémunération : 554¤ par mois plus participation aux frais de transport\r\nen commun\r\n\r\n\r\n*Contexte*\r\n------------------------------\r\nDevant l\'augmentation toujours croissante de la masse de documents\r\nproduits dans le domaine médical, il devient de plus en plus difficile\r\nd\'accéder aux informations nécessaires au traitement et à la prise en\r\ncharge des patients. Le recours à des méthodes automatiques pour accéder\r\naux informations contenues dans les textes devient alors inévitable. Les\r\nméthodes d\'extraction d\'information sont aujourd\'hui largement utilisées\r\nafin d\'identifier des données médicales comme des noms de patients, de\r\nmédicaments ou de maladies : \"La patiente <nom>Anne Onyme</nom> a été\r\nadmise pour une <symptome>réaction allergique</symptome> à la\r\n<traitement>pénicilline</traitement> le <date>21 janvier 2015</date>\".\r\n\r\nCette tâche se révèle toutefois particulièrement ardue lorsqu\'il s\'agit\r\nde traiter des textes transcrits par des systèmes de reconnaissance de\r\nla parole. La qualité variable des transcriptions automatiques et la\r\nvariation terminologique compliquent la reconnaissance des entités.\r\n\r\n\r\n*Description du stage*\r\n------------------------------\r\nNous posons l\'exploitation de la dimension multimodale comme une piste\r\nd\'amélioration des systèmes d\'extraction. Une hypothèse est que des\r\nparamètres acoustiques comme le rythme ou l\'intensité de la parole\r\npeuvent constituer des indices permettant d\'aider le repérage des\r\nentités nommées. Le but du stage sera d\'éprouver cette hypothèse.\r\n\r\nLe travail du stagiaire s\'appuiera principalement sur les données issues\r\nde la tâche 1a du challenge CLEF eHealth 2015, soit 200 enregistrements\r\nde dossiers de soins lus par une infirmière ainsi que leur transcription\r\nannotée. NB : ces données sont en anglais, une bonne connaissance de la\r\nlangue est donc attendue.\r\n\r\nLes tâches dévolues au stagiaire sont les suivantes :\r\n  - rédiger un état de l\'art sur la reconnaissance des entités nommées\r\n    dans la parole\r\n  - corriger les annotations préexistantes\r\n  - développer une chaîne d\'extraction d\'entités nommées multimodale\r\n    (qui s\'appuiera notamment sur le logiciel Wapiti)\r\n  - utiliser des outils TAL et de traitement du signal pour extraire des \r\n    traits multimodaux\r\n  - évaluer et analyser l\'influence des traits implémentés\r\n\r\n*Profil recherché*\r\n------------------------------\r\nM2 Informatique ou linguistique avec parcours TAL\r\n\r\nCompétences attendues :\r\n  - Connaissances en programmation (langages de script)\r\n  - Expérience avec des outils de TAL courants (étiqueteurs\r\n    morphosyntaxiques, analyseurs syntaxiques, ...) et avec des outils\r\n    de traitement du signal (Praat)\r\n  - Expérience des méthodes d\'apprentissage automatique\r\n  - Intérêt pour le traitement de l\'audio et du texte\r\n  - Compétences en anglais\r\n  - Familiarité avec l\'environnement Linux\r\n  - Créativité et autonomie\r\n\r\nNB : Aucune expérience du domaine médical n\'est attendue.\r\n\r\n\r\n*Encadrement*\r\n------------------------------\r\nEva D\'hondt\r\nFrançois Morlane-Hondère\r\nSophie Rosset\r\nPierre Zweigenbaum\r\n\r\n\r\n*Pour candidater*\r\n------------------------------\r\nMerci d\'adresser votre candidature avec un CV, une lettre de motivation\r\nainsi que vos notes de l\'année universitaire en cours et de l\'année\r\ndernière à Eva D\'hondt (eva.dhondt@limsi.fr) et François Morlane-Hondère\r\n(francois.morlane-hondere@limsi.fr)'),
(318, '2016-01-13', 'ELDA', 'Paris', 'Sujet: Développement d\'un moteur de recherche robuste pour naviguer dans\r\ndes collections de documents\r\n\r\nNiveau : L3 ou M1 / première ou deuxième année d\'école d\'ingénieur\r\n\r\nDomaine : informatique\r\n\r\nPériode : à partir de mi-janvier 2016\r\n\r\nDurée : 4-6 mois\r\n\r\n*Travail à réaliser*\r\n\r\nAu sein de l\'équipe de développement informatique d\'ELDA, sous la\r\ntutelle d\'un ingénieur spécialiste des technologies de la langue et du\r\ndéveloppement d\'applications Web, vous serez amené à participer aux\r\ntravaux suivants :\r\n\r\n  * faire un état de l\'art exhaustif sur les possibilités actuelles\r\n    offertes par les moteurs de recherche les plus puissants, tels que\r\n    Solr, Elastic, ou bien les facilités de recherche textuelle offertes\r\n    par des SGBD (Système de Gestion des Bases de Données) tels que\r\n    PostgreSQL.\r\n  * participer à la spécification des besoins de recherche textuelle\r\n    dans les actes de la conférence LREC ;\r\n  * participer au choix de la solution technique la plus appropriée pour\r\n    les actes de LREC ;\r\n  * participer à la conception de la structure d\'une base de données\r\n    (schéma de données) pour modéliser le contenu des sites Web\r\n    recensant les articles de la conférence LREC ;\r\n  * extraire les informations pertinentes des sites recensant les\r\n    articles de la conférence LREC et réaliser la mise en données de ces\r\n    informations, utilisant le schéma de données mentionné ci-dessus;\r\n  * implémenter un moteur de recherche exhaustive à travers tous les\r\n    actes de la conférence LREC, compte tenu des contraintes dégagées\r\n    lors des étapes antérieures ;\r\n\r\nVos participerez également aux réunions périodiques de l\'équipe de\r\ndéveloppements logiciels d\'ELDA.\r\n\r\n\r\n*Profil souhaité*\r\n\r\n  * Bac + 3 ou 4 / Première ou deuxième année d\'École d\'ingénieur ;\r\n  * Connaissances de base en algorithmique ;\r\n  * Connaissances de base des architectures des applications Web ;\r\n  * Connaissance pratique d\'un système de gestion de bases de données\r\n    (PostgreSQL de préférence) ;\r\n  * Anglais technique ;\r\n  * La connaissance d\'un moteur de recherche (Solr, Elastic, Lucene)\r\n    sera appréciée ;\r\n  * La connaissance des langages JavaScript et / ou Python sera un plus.\r\n\r\n\r\n*Candidature*\r\n\r\nCe stage, d\'une durée de 3 mois et basé à Paris dans le 13e \r\narrondissement (Les Gobelins), est à pourvoir en janvier 2016.\r\n\r\n*Les candidatures (CV, lettre de motivation) doivent être adressées à \r\nVladimir Popescu (vladimir@elda.org).*\r\n\r\nLe stage fait l\'objet d\'une rémunération, variable en fonction du niveau\r\nd\'études du candidat.\r\n\r\n-*-*-*-*-*-*-*-\r\n\r\nActeur majeur des technologies de la langue, ELDA (Agence pour la\r\ndistribution des ressources Linguistiques et l\'Evaluation) est une PME\r\ndont les activités s\'articulent principalement autour de la distribution\r\net de la production de ressources linguistiques.\r\n\r\nÀ ce titre, ELDA assure le fonctionnement opérationnel d\'ELRA (European\r\nLanguage Resource Association), association européenne à but\r\nnon-lucratif assurant la promotion des ressources linguistiques dans un\r\ncontexte européen.\r\n\r\nDepuis 1998, ELRA organise une conférence internationale bisannuelle,\r\nLREC (Language Resources and Evaluation Conference), qui réunit, à\r\nchaque édition, des centaines de chercheurs de premier rang du monde\r\nentier, qui y présentent des articles de recherche scientifique.\r\n\r\nAfin de faciliter la navigation dans ce thésaurus d\'articles\r\nscientifiques, ELDA a mis au point un ensemble de sites Web recensant\r\nces articles, ainsi que des informations les concernant (auteurs,\r\ntitres, résumés des articles, etc.).\r\n\r\nDans ce contexte, ELDA souhaite consolider ces sites, et notamment\r\npermettre aux utilisateurs d\'effectuer des recherches robustes et\r\nexhaustives à travers ses collections d\'articles correspondant à toutes\r\nles éditions de la conférence LREC.\r\n\r\nwww.elda.org'),
(319, '2016-01-13', 'MyScript', 'Nantes', 'Pionnier d\'une technologie permettant la reconnaissance d\'écriture \r\nmanuscrite et la gestion de l\'encre digitale, MyScript \r\n(http://myscript.com/) développe de nouvelles possibilités pour entrer \r\net modifier vos données. Notre technologie permet un niveau de \r\nperformance inégalé, une intégration sous toute plateforme ainsi qu\'une \r\nreconnaissance multi-domaines (100 langues, 200 symboles mathématiques, \r\n100 notations musicales, 25 formes géométriques). MyScript intègre déjà \r\ncette haute technologie dans des équipements tels que des tablettes, \r\nsmartphones, tableaux interactifs, système de commande du GPS, etc.\r\n\r\n\r\nStage - Moteur de reconnaissance d\'écriture pour des langues peu dotées\r\nH/F\r\nhttp://myscript.com/careers/internship-nlp-low-resourced-languages-support/\r\n\r\nLe développement de modèles de langues riches et robustes pour la\r\nreconnaissance d\'écriture nécessite de gros volumes de textes (plusieurs\r\ndizaines de millions de mots).\r\nLe nombre de langues dans lesquels de tels corpus sont disponibles étant\r\nlimité, MyScript souhaite expérimenter les méthodes alternatives de\r\nmodélisation pour les langues dites peu dotées.\r\n\r\nAu sein de l\'équipe Natural Language Processing, le stagiaire aura les\r\nmissions suivantes:\r\n\r\n- travailler au traitement de corpus pour une liste définie de langues\r\n  peu dotées ;\r\n- déployer le moteur de reconnaissance sur ces langues et mettre en\r\n  place des tests de qualité ;\r\n- expérimenter diverses techniques de modélisation de langues (notamment\r\n  au niveau caractères) pour améliorer les résultats.\r\n\r\nCe stage de 6 mois au niveau M2 est une bonne opportunité d\'acquérir une\r\npremière expérience de R&D en entreprise.\r\n\r\nProfil:\r\n- Etudiant en M2, option TAL, école d\'ingénieur ou assimilé\r\n- Connaissance d\'au moins un langage de programmation\r\n- Des expériences antérieures en NLP ou statistiques seraient un plus\r\n- Anglais courant\r\n\r\nStage de 6 mois basé à Nantes\r\n\r\nDans un contexte international, notre offre est la suivante: challenges\r\ntechniques, réalisations concrètes et convivialité.\r\n\r\nAu sein de MyScript, vous travaillerez sur des technologies à la pointe\r\nde la recherche et pourrez identifier les applications directes et\r\nconcrètes de votre travail.\r\nVous intégrerez une structure à taille humaine qui valorise et promeut\r\nla créativité, les initiatives, le partage d\'expérience et la\r\nconvivialité.\r\n\r\nContact: job@myscript.com'),
(320, '2016-01-18', 'Viseo R&D', 'Grenoble', 'Stage Master 2 de Recherche\r\nViseo R&D, à Grenoble (France)\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation\r\n\r\nSUJET : Normalisation de messages issus de la communication électronique\r\nmédiée\r\n\r\nCONTEXTE\r\nAu départ contraint par le nombre de caractères maximum utilisables pour\r\nla rédaction d\'un SMS et par la difficulté de maniement des claviers,\r\nl\'écriture SMS apparaît et se développe rapidement sur les supports de\r\ncommunication du Web (réseaux sociaux, fora, blogs, etc.). Par exemple,\r\nl\'écriture SMS se caractérise par la présence de formes scripturales\r\ntrès riches : squelettes consonantiques (\"slt\" (salut)), apocopes\r\n(\"ordi\" (ordinateur)), substitutions phonétisées (\"2m1\" (demain)),\r\nbinettes/emoji (\"^^\", \":)\", :)) - la liste est longue.\r\nCe non-respect des règles de la langue implique une réelle difficulté\r\nlorsqu\'il s\'agit d\'analyser ces textes avec des outils de traitement\r\nautomatique de la langue qui sont généralement conçus pour traiter du\r\ntexte correctement écrit, ce qui implique un impact négatif sur la\r\nqualité des résultats à l\'issue du traitement. Pour pallier à cette\r\ndifficulté, on peut envisager soit d\'adapter les outils d\'analyse, soit\r\nde normaliser le texte qui sera passé en entrée des outils\r\nd\'analyse. Nous choisissons cette deuxième approche dans le cadre de ce\r\nstage.\r\n\r\nOBJECTIF DU STAGE\r\nL\'objectif de ce stage est de développer un outil performant de\r\nnormalisation automatique de texte pour le français. Par exemple, «a2min\r\nlami» devra être normalisé en «à demain l\'ami».\r\n\r\nPour atteindre ce but, il sera demandé à l\'étudiant de :\r\n1) dresser une typologie des erreurs détectées dans les ressources\r\n   fournies, pour le français (Tweets, Messages de forums, SMS), en\r\n   s\'appuyant sur les typologies déjà existantes.\r\n2) proposer des méthodes automatiques de normalisation en fonction des\r\n   types d\'erreurs définis à la première étape, avec un intérêt\r\n   particulier porté sur les types d\'erreur les plus fréquents. On\r\n   s\'inspirera des méthodes déjà existantes (par exemple, fondées sur\r\n   les principes de la traduction automatique, de la reconnaissance de\r\n   la parole, la correction orthographique, ...).\r\n3) évaluer les méthodes proposées en fonction des différents types de\r\n   textes (Tweets, Messages de forums, SMS).\r\n\r\nPREREQUIS\r\nCe sujet est destiné aux étudiants de Master 2 Informatique ou de\r\ndernière année d\'une école d\'ingénieur en informatique, avec une\r\nspécialité ingénierie linguistique ou terminologique.  Profil recherché :\r\n\r\n- Traitement automatique des langues\r\n- Compétences en programmation (Java souhaité)\r\n- Expérience minimum de l\'utilisation de ressources linguistiques\r\n  appréciée\r\n- Bonne maîtrise du français et anglais\r\n\r\nINFORMATIONS COMPLEMENTAIRES\r\nUnité d\'accueil : Viseo R&D\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation\r\nLieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble\r\nEncadrant principal : Cédric Lopez\r\nhttp://www.viseo.com/fr/recherche/cedric-lopez\r\nDurée du stage : 6 mois\r\nStage rémunéré\r\n\r\nMerci d\'envoyer votre candidature à\r\ncedric.lopez@viseo.com<mailto:cedric.lopez@viseo.com> constituée du CV,\r\nde la lettre de motivation, des relevés de notes des 2 dernières années\r\n(M1 et M2)\r\n\r\nA PROPOS DE VISEO\r\nViseo est une entreprise française de services du numérique qui compte\r\n1200 employés en France, Allemagne, Etats Unis, Singapour, Hong Kong et\r\nMaroc. Son centre R&D est situé à Grenoble, à deux minutes à pieds de la\r\ngare. De nombreux projets de recherche collaboratifs y sont menés, avec\r\nun intérêt particulier pour l\'analyse de données textuelles : projet\r\nSMILK (LabCom ANR)\r\nhttp://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER\r\n(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)\r\nhttp://www.synodos.fr<http://www.synodos.fr/> , SOMA (EUROSTARS)\r\nhttp://www.viseo.com/fr/recherche/le-projet-soma, ...\r\nPour en savoir plus : www.viseo.com<http://www.viseo.com>,\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation\r\n\r\n\r\nCédric LOPEZ\r\n\r\nLe Pulsar 4 av du Doyen Louis Weil 38000 GRENOBLE\r\nTél.  +33 (0)9 72 31 82 46\r\nMob. +33 (0)6 72 64 25 77\r\ncedric.lopez@viseo.com\r\nResearch Scientist\r\nResearch & Development\r\nhttp://www.viseo.com/en/recherche/cedric-lopez\r\n\r\nSMILK (LabCom ANR) : Joint Laboratory between INRIA-Wimmics and Viseo :\r\nhttp://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk\r\nViseo is partner of the TIER Project (EU)\r\nhttp://www.viseo.com/en/offre/tier-project\r\nViseo is partner of the SYNODOS Project (ANR) :\r\nhttp://www.synodos.fr<http://www.synodos.fr/>'),
(321, '2016-01-18', 'STL', 'Lille ou Paris', 'Extraction d\'informations pour enrichir les guides touristiques\r\nhttp://natalia.grabar.perso.sfr.fr/stage2016t.html\r\n\r\nDe plus en plus de gens voyagent et sont consommateurs d\'informations\r\ntouristiques. Cependant, les intérêts touristiques varient en fonction\r\ndes personnes et des régions. Ils peuvent par exemple concerner la\r\ndécouverte de villes ou de paysages, la dégustation de nouveaux plats\r\nculinaires, la visite des vestiges historiques, les pèlerinages, la\r\nvisite des lieux liés à des personnalités ou événements, des objets ou\r\névénements endémiques, etc. Des informations associées sont aussi\r\nappréciées (hôtels, parkings, campings, auberges, chemins de randonnées,\r\nrestaurants, marchés...)\r\n\r\nCela offre une large palette d\'informations à proposer aux touristes\r\nafin de les aider dans l\'élaboration des voyages.\r\n\r\nL\'objectif de ce stage consiste à traiter les informations provenant de\r\ndifférentes sources afin d\'enrichir les guides existants. Plus\r\nparticulièrement, le cadre du stage est lié à la Via Francigena, qui est\r\nun des itinéraires les plus fréquentés. De plus, il passe par plusieurs\r\npays Européens, dont la France et bénéficie d\'une communauté de\r\nrandonneurs et touristes très active. Entre autre, l\'Association Via\r\nFrancigena coordonne les efforts de plusieurs contributeurs.\r\n\r\nPour la réalisation du stage, des méthodes de Traitement Automatique de \r\nla Langue et de fouille de textes seront utilisées.\r\n\r\nPlus spécifiquement, il s\'agit des objectifs suivants:\r\n\r\n- travailler avec des corpus de textes de différents types et provenant\r\n  de différentes sources\r\n- exploiter et améliorer les annotations des textes avec différents\r\n  niveaux de spécificité\r\n- exploiter, adapter ou développer des méthodes pour l\'extraction\r\n  d\'informations\r\n- faire le lien avec les guides existants\r\n- évaluer les méthodes et résultats\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n\r\n  - connaissances en TAL et en linguistique\r\n  - manipulation et test des outils de TAL\r\n  - habitude de Linux\r\n  - capacité de travailler en équipe et individuellement\r\n  - lecture et analyse de la littérature scientifique\r\n\r\nL\'encadrement sera assuré par des chercheurs de différentes disciplines\r\n(TAL, STIC, humanités numériques).\r\n\r\nLe stage est rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\n     Niveau: Master 2\r\n     Durée: 6 mois\r\n     Lieu: Lille, Paris (éventuellement)\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à\r\nnatalia.grabar@univ-lille3.fr'),
(322, '2016-01-18', 'STL', 'Lille', 'Vers la simplification de textes techniques\r\n\r\nLe domaine médical a une terminologie spécifique, avec des termes comme\r\npar exemple /sanguin, abdominoplastie, hépatique, dermabrasion ou\r\nhépatoduodénostomie/, utilisée communément par le personnel\r\nmédical. Pour cette raison entre autre, la compréhension d\'information\r\nde santé est souvent compliquée pour les non spécialistes et pour les\r\npatients [1-4]. La disponibilité des informations de santé en ligne peut\r\naussi modifier le modèle de communication entre ces catégories de\r\npersonnes [5-6].\r\n\r\nL\'objectif de ce stage consiste à proposer des méthodes pour simplifier\r\nles documents spécialisés et pour les \"traduire\" dans une langue plus\r\nfacilement compréhensible par les non spécialistes, et de tester ces\r\nméthodes. Le matériel traité est de différents types :\r\n\r\n- textes spécialisés qui proviennent des publications scientifique,\r\n  documents cliniques ou sites web spécialisés,\r\n- ressources linguistiques qui alignent les termes techniques avec des\r\n  expressions moins techniques (infarctus du myocarde/crise cardiaque)\r\n  [7],\r\n- éventuellement, des documents parallèles ou comparables contenant les\r\n  textes spécialisés et leurs équivalents moins spécialisés.\r\n\r\nEn utilisant des méthodes de Traitement Automatique de la Langue, il\r\ns\'agit plus spécifiquement des objectifs suivants :\r\n\r\n- travailler avec les documents produits par les médecins,\r\n- prendre en main les ressources linguistiques alignant les termes\r\n  avec différents niveaux de spécificité,\r\n- si les corpus parallèles/comparables sont disponibles, effectuer une\r\n  analyse contrastive de ces documents,\r\n- proposer des règles pour déclencher les modifications/substitutions\r\n  lexicales,\r\n- exploiter le lexique avec les correspondances entre les termes savants\r\n  et les expressions des patients pour effectuer les\r\n  modifications/substitutions lexicales.\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n- connaissances en TAL et en linguistique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique\r\n\r\nLe stage est rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nNiveau: Master 2\r\nDurée: 6 mois\r\nLieu: Lille, Paris (éventuellement)\r\n\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à\r\nnatalia.grabar@univ-lille3.fr\r\n\r\n\r\nBibliographie:\r\n1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as\r\n   procedures : The case of pharmaceutical labels, International journal\r\n   of medical informatics, vol. 65(3), p. 193-211, 2002\r\n2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,\r\n   Nurss J., Inadequate functional health literacy among patients at two\r\n   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995\r\n3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and\r\n   Literacy, ch 5, 1999\r\n4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,\r\n   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn\r\n   E., Health information on the Internet. Accessibility, quality, and\r\n   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,\r\n   2001\r\n5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un\r\n   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,\r\n   vol. 53, p. 34-43, 2009\r\n6. Jucks R., Bromme R., Choice of words in doctor-patient communication:\r\n   an analysis of health-related internet sites, Health Commun,\r\n   vol. 21(3), p. 267-77, 2007\r\n7. Grabar N., Hamon T. Extraction automatique de paraphrases grand\r\n   public pour les termes médicaux. TALN 2015: Traitement Automatique\r\n   des Langues Naturelles. 14 p.'),
(323, '2016-01-20', 'CEA LIST', 'Palaiseau', 'SUJET: Utiliser des contraintes discursives pour améliorer le résumé\r\nautomatique\r\n\r\nCONTEXTE:\r\n\r\nLe stage se focalise sur les systèmes de résumé automatique par\r\nextraction, c\'est-à-dire les systèmes réalisant des résumés en extrayant\r\ndes documents sources les unités, le plus souvent des phrases, les plus\r\nreprésentatives de leur contenu. Les approches les plus récentes dans ce\r\ndomaine posent ce problème comme un problème d\'optimisation consistant à\r\ntrouver le compromis le plus intéressant entre le respect d\'une\r\ncontrainte de taille maximale du résumé à produire et la maximisation du\r\ncontenu informationnel de ce dernier, représenté de façon non structurée\r\npar un ensemble de mots ou de séquences de mots [Gillick and Favre\r\n(2009)].\r\n\r\nOBJECTIFS:\r\n\r\nLa maximisation du contenu informationnel n\'est pas le seul critère\r\nintéressant à considérer pour produire un résumé. Elle intègre de façon\r\nindirecte une prise en compte de la redondance informationnelle mais\r\nn\'exploite pas la hiérarchisation des informations mise en avant par les\r\ndocuments. Savoir qu\'une phrase donne un exemple ou une justification en\r\nrelation avec le contenu d\'une autre phrase est dans cette optique un\r\nélément intéressant à exploiter pour sélectionner l\'information à faire\r\napparaître dans un résumé. Dans le cas de la phrase \"Most of our\r\nchildren are living in California now ; Judy, for instance, lives in\r\nBerkeley\" [Foster (1984)], la détection de la relation d\'exemplification\r\nunissant les deux propositions peut ainsi être mise à profit pour\r\nlaisser de côté la seconde proposition.\r\n\r\nSur un plan général, cette hiérarchisation des informations peut être\r\ncaractérisée au travers d\'une analyse discursive des documents. De ce\r\npoint de vue, la Rhetorical Structure Theory (RST) [Mann and Thompson\r\n(1988)] est l\'une des théories discursives parmi les plus connues et les\r\nmieux outillées. En outre, des travaux de recherche existants ont déjà\r\ndémontré la capacité de la RST à sélectionner les segments de textes les\r\nplus pertinents dans un contexte de résumé automatique [Marcu (1998,\r\n1997)].\r\n\r\nLe stage s\'inscrira donc dans ce cadre et se donnera les trois objectifs\r\nprincipaux suivants :\r\n\r\n- en s\'appuyant notamment sur [Marcu (1998, 1997)], faire une étude des\r\n  relations rhétoriques intéressantes du point de vue du résumé\r\n  automatique ;\r\n\r\n- analyser le repérage de ces relations pour les outils existants [Joty\r\n  et al. (2013); Feng and Hirst (2014)] et proposer le cas échéant des\r\n  stratégies permettant de pallier de façon ciblée certaines de leurs\r\n  insuffisances ;\r\n\r\n- proposer une méthode de prise en compte des relations rhétoriques\r\n  ciblées dans un cadre d\'optimisation de contraintes fondée sur la\r\n  programmation linéaire en nombres entiers (ILP) dédié au résumé\r\n  automatique, avec une extension possible vers les techniques de\r\n  décomposition (dual decomposition) [Rush and Collins (2012)].\r\n\r\nLes travaux s\'effectueront prioritairement dans un cadre de résumé\r\nmono-document pour des documents en anglais de type articles de\r\njournaux, avec une extension possible au multi-document. Ils seront\r\névalués en reprenant les protocoles et les données des campagnes\r\nd\'évaluation DUC (Document Understanding Conference) et TAC\r\nSummarization (Text Analysis Conference).\r\n\r\n- Domaine de spécialité requis: Informatique\r\n- Spécialité complémentaire: Linguistique\r\n- Langages de programmation: Python, bash, éventuellement Perl ; la\r\n  connaissance de C++ est un plus\r\n- Niveau souhaité: Master 2\r\n- Durée: 6 mois\r\n- Employeur: Laboratoire LVIC du CEA/LIST\r\n- Stage rémunéré : entre 700 et 1300 euros selon la formation + prise en\r\n  charge à 75% des transports en IdF.\r\n- Lieu du stage: dans les locaux du LVIC à Nano Innov à Palaiseau.\r\n\r\nLes candidatures sont à envoyer à Maâli Mnasri à l\'adresse :\r\nmaali.mnasri@cea.fr\r\nStage co-encadré par Gaël de Chalendar et Olivier Ferret.\r\n\r\nRÉFÉRENCES:\r\n\r\nDan Gillick and Benoit Favre. A Scalable Global Model for\r\nSummarization. In Proceedings of the Workshop on Integer Linear\r\nProgramming for Natural Langauge Processing, ILP \'09, pages 10- 18,\r\nBoulder, Colorado, 2009. ISBN 978-1-932432-35-0. URL\r\nhttp://dl.acm.org/citation.cfm?id=1611638.1611640.\r\n\r\nWilliam C. Mann and Sandra A. Thompson. Rhetorical Structure Theory :\r\nToward a functional theory of text organization. Text, 8(3) :243-281,\r\n1988.\r\n\r\nSusan H. Foster. Teun A. van Dijk, Studies in the Pragmatics of\r\nDiscourse. the hague : Mouton, 1981. pp. xii + 331. Language in Society,\r\n13 :369-375, 9 1984.  ISSN 1469-8013. doi : 10.1017/S0047404500010563.\r\n\r\nDaniel Marcu. Improving summarization through rhetorical parsing\r\ntuning. In Proceedings of The Sixth Workshop on Very Large Corpora,\r\npages 206-215, Montreal, Canada, August 1998.\r\n\r\nDaniel Marcu. The rhetorical parsing, summarization, and generation of\r\nnatural language texts. Technical Report CSRG-371, Computer Systems\r\nResearch Group, University of Toronto, 1997.\r\n\r\nShafiq Joty, Giuseppe Carenini, Raymond Ng, and Yashar Mehdad. Combining\r\nIntra- and Multi-sentential Rhetorical Parsing for Document-level\r\nDiscourse Analysis.  In Proceedings of ACL, 2013.\r\n\r\nVanessa Wei Feng and Graeme Hirst. A linear-time bottom-up discourse\r\nparser with constraints and post-editing. In Proceedings of the 52nd\r\nAnnual Meeting of the Association for Computational Linguistics, pages\r\n511-521, June 2014.  URL http://www.aclweb.org/anthology/P14-1048.'),
(324, '2016-01-25', 'LIA', 'Avignon', '======================================================\r\nUAPV - Laboratoire Informatique d\'Avignon\r\nSujet : Extraction et exploitation de l\'information des CV\r\nStagiaire :    Étudiant de M2\r\nCo-encadrement :\r\n   Juan-Manuel Torres-Moreno (juan-manuel.torres@univ-avignon.fr)\r\n   Marc El-Bèze (marc.elbeze@univ-avignon.fr)\r\n   Luis Adrián Cabrera Diego (luis-adrian.cabrera-diego@univ-avignon.fr)\r\n\r\nLes cabinets de recrutement doivent aujourd\'hui traiter des volumes de\r\ndonnées de plus en plus importants (candidatures électroniques, variété\r\ndes formats, des sources des candidatures, etc). Par ailleurs, le\r\nrapport entre toutes les candidatures et les candidats non qualifies a\r\naugmenté. Ceci rend évident l\'intérêt majeur d\'un système automatique\r\noffrant une aide efficace pour sélectionner, dans des masses de\r\ncandidatures celles qui méritent d\'être retenues en vue d\'un examen\r\napprofondi. Grâce à une convention CIFRE obtenue en 2005 et une autre en\r\n2012, le LIA s\'est déjà fortement impliqué dans des travaux de\r\nrecherches visant à proposer des algorithmes permettant de mettre au\r\npoint quelques-uns des composants d\'un tel système [1-5]. Dans la\r\nprolongation de ces travaux, nous projetons de nous intéresser aux\r\nproblèmes d\'extraction et de valorisation de l\'information provenant des\r\ncurriculums vitæ (CV).\r\n\r\nLa société Adoc Talent Management et le Laboratoire d\'Informatique\r\nd\'Avignon (LIA), partenaires pour l\'encadrement de ce stage de M2,\r\nproposent de traiter les questions fondamentales suivantes :\r\n\r\n     * Extraction automatique des termes (mono ou multi-mots) qui\r\n       contribuent le plus au processus de recrutement ;\r\n\r\n     * Impact des priorités données à certains de ces termes sur le\r\n       classement des candidatures ;\r\n\r\n     * Étude et mise en place des algorithmes pour la génération\r\n       automatisée de portrait-robots (ainsi que des anti\r\n       portrait-robots).\r\n\r\nPour la réalisation de ce stage de M2, l\'étudiant devra, a priori,\r\nutiliser les méthodes liées à l\'apprentissage automatique, la fouille de\r\ntexte (représentation des textes, classifications, distances, etc.), le\r\nrésumé automatique. Parmi les outils dont le développement est attendu,\r\nse trouve un extracteur de termes à partir des CV et des offres\r\nd\'emploi.  La liste des termes tels qu\'ils ont été extraits et ordonnés\r\nautomatiquement devra pouvoir être modifiée manuellement ou\r\nautomatiquement de telle sorte que l\'on se donne la possibilité\r\nd\'étudier l\'impact de cette nouvelle sélection dans le processus de\r\nrelevance feedback [1,4,6].\r\nLes outils pourront être implémentés dans différents langages, notamment\r\nPython, Perl et R. La partie recherche de ce stage est susceptible de\r\ndonner lieu à des publications dans un congrès international.\r\n\r\nCe stage se déroulera au LIA, à Avignon. Sera envisagée la possibilité\r\nde continuer en thèse ces travaux dans le cadre d\'une convention CIFRE,\r\nen fonction des résultats obtenus.\r\n\r\nDates : entre début février et fin juillet 2016\r\nDurée : entre 4 et 5 mois\r\nGratification mensuelle : 554 euros\r\n\r\nContact : Juan-Manuel Torres-Moreno (juan-manuel.torres@univ-avignon.fr)\r\n\r\n\r\nRéférences\r\n[1] R. Kessler, N. Béchet, M. Roche, J.-M. Torres-Moreno, and M.\r\n    El-Bèze, 2012. A hybrid approach to managing job offers and\r\n    candidates.  Information Processing & Management 48(6), 1124-1135.\r\n[2] R. Kessler, N. Béchet, J.-M. Torres-Moreno, M. Roche, and M.\r\n    El-Bèze, 2009. Job offer management: how improve the ranking of\r\n    candidates. In Foundations of Intelligent Systems, 431-441. Springer\r\n    Berlin Heidelberg.\r\n[3] R. Kessler, J. M. Torres-Moreno, and M. El-Bèze, 2008a. E-gen:\r\n    Profilage automatique de candidatures. TALN 2008, Avignon, France,\r\n    370-379.\r\n[4] L. A. Cabrera-Diego, B. Durette, M. Lafon, J.-M. Torres-Moreno, M.\r\n    El-Bèze, 2015. How Can We Measure the Similarity Between Résumés of\r\n    Selected Candidates for a Job? Proceedings of the 11th International\r\n    Conference on Data Mining (DMIN\'15), Las Vegas, 99-106.\r\n[5] L. A. Cabrera-Diego, J.-M. Torres-Moreno, M. El-Bèze, 2013. SegCV :\r\n    traitement efficace de CV avec analyse et correction d\'erreurs. TALN\r\n    2013, Les Sables d\'Olonne, France, 707-714\r\n[6] L. A. Cabrera-Diego, Automatic Methods for Assisting RH Recruitment,\r\n    Thèse UAPV 2015.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(325, '2016-01-28', 'LIMSI & INRA', 'Orsay ou Jouy', 'Normalisation : projection de termes médicaux vers un référentiel\r\n\r\n* Contexte *\r\n------------------------------\r\n\r\nLa quantité de documents textuels produits et utilisés dans les\r\norganisations et sur le web a explosé ces dernières décennies. Ces\r\ndocuments recèlent une grande quantité d\'informations et de\r\nconnaissances dont l\'exploitation et le partage nécessite la\r\nreprésentation sous une forme normalisée, appelée indexation sémantique\r\nou conceptuelle, selon un référentiel partagé tel qu\'un thésaurus ou une\r\nontologie. Ces référentiels recensent et structurent les concepts d\'un\r\ndomaine, qui y sont caractérisés par un identifiant, et sont associés à\r\nun ensemble de mentions (expressions linguistiques) qui y font référence\r\ndans un texte. La représentation normalisée sous forme d\'identifiants de\r\nconcepts rend possibles les opérations d\'agrégation (quelle est la\r\nproportion des décès par maladie cardiovasculaire en France) et rend\r\nplus pertinentes les opérations de recherche (quels articles dans\r\nMEDLINE portent sur des traitements antihypertenseurs) et plus\r\ngénéralement de fouille de données (quelles caractéristiques\r\nphénotypiques sont associées à une différence génétique donnée [1] -\r\nétudes PheWAS).\r\n\r\nLa normalisation constitue un verrou fondamental dans l\'analyse et la\r\ncompréhension de textes, car elle vise à passer d\'une expression en\r\nlangue, non formelle, avec sa plasticité (source d\'ambiguïté) et ses\r\nmultiples possibilités d\'expression d\'une même information (paraphrase),\r\nà une représentation normalisée et non ambiguë permettant des\r\ntraitements automatisés. De plus, la normalisation est rendue plus\r\ndifficile si le référentiel visé (thésaurus ou ontologie) possède un\r\ntrès grand nombre de classes (des dizaines de milliers dans le thésaurus\r\nMeSH utilisé pour indexer les articles scientifiques de la base MEDLINE\r\nou dans la Classification internationale des maladies CIM 10). Malgré\r\ncette taille considérable, les référentiels spécialisés ne couvrent pas\r\ndes concepts qui sont hors du domaine de spécialité concerné, et il faut\r\nalors en rendre compte.\r\n\r\nLa normalisation de concepts dans des textes biomédicaux repose\r\nmajoritairement sur deux grandes classes de méthodes : (a) la détection\r\napprochée d\'entrées de grands lexiques et terminologies en employant des\r\nconnaissances linguistiques ou un modèle de type recherche\r\nd\'information, et (b) l\'apprentissage supervisé à partir de corpus\r\nannotés, la combinaison des deux étant fréquente. Ce problème a été bien\r\nétudié dans le domaine biomédical sur des textes cliniques ou de la\r\nlittérature en anglais, notamment grâce à la disponibilité de ressources\r\nannotées permettant de développer et d\'évaluer diverses méthodes\r\n[2,3]. Pour le français, le LIMSI a contribué au développement d\'un\r\ncorpus annoté, utilisé dans le cadre de la campagne CLEF eHealth [4].\r\n\r\nDans ce contexte, nous prévoyons de confier au stagiaire de M2 une étude\r\nexploratoire utilisant cette nouvelle ressource pour faire une\r\névaluation systématique des méthodes de normalisation connues. De plus,\r\nla généralisation des méthodes pour la prise en charge de plusieurs\r\nlangues pourra également être étudiée.\r\n\r\n* Description du stage *\r\n------------------------------\r\n\r\nL\'objectif du stage est une analyse systématique des méthodes de\r\nnormalisation de concept dans le domaine biomédical. Il s\'agit\r\nd\'analyser un terme dans son contexte phrastique afin de le mettre en\r\ncorrespondance avec un concept normalisé présent dans un référentiel du\r\ndomaine biomédical - si un tel concept existe.\r\n\r\nCe stage abordera l\'analyse de termes du domaine biomédical sous l\'angle\r\nde la désambiguïsation. Il s\'agira d\'une analyse systématique et\r\ncomparative de méthodes à base de connaissances expertes et de méthodes\r\nd\'apprentissage afin de faire un état des lieux et de définir des lignes\r\nde recherche futures. Le résultat principal de ce stage sera un bilan\r\nexploratoire permettant de défricher le terrain et de décider des\r\nméthodes à développer pour la normalisation. Les méthodes suivantes\r\nseront notamment évaluées :1/ projection d\'un dictionnaire monolingue\r\nfrançais 2/ prise en compte de la variation terminologique dans le\r\ndictionnaire et le texte 3/ utilisation de ressources multilingues et\r\nd\'outils de traduction automatique 4/ adaptation de la méthode\r\nstatistique DNorm [5] et de la méthode d\'analyse terminologique ToMap\r\n[6] pour le français 5/ utilisation des représentations continues\r\napprises par des méthodes neuronales. Ce travail permettra de contribuer\r\nà l\'état de l\'art en normalisation de concepts du domaine biomédical.\r\n\r\nDurée : 5 mois\r\nLieu : LIMSI-CNRS, Orsay, France ou INRA, Jouy, France\r\nGratification mensuelle : 554¤ par mois plus participation aux frais de\r\ntransport en commun\r\n\r\n\r\n*Profil recherché*\r\n------------------------------\r\nM2 Informatique ou linguistique avec parcours TAL\r\n\r\nCompétences attendues :\r\n  - Connaissances en programmation (langages de script)\r\n  - Expérience avec des outils de TAL courants (étiqueteurs\r\n    morphosyntaxiques, analyseurs syntaxiques, ...)\r\n  - Expérience de l\'utilisation de méthodes d\'apprentissage automatique\r\n  - Familiarité avec l\'environnement Linux\r\n  - Créativité et autonomie\r\n\r\nAucune expérience du domaine médical n\'est attendue, mais une\r\nfamiliarité avec des ressources terminologiques sera un plus.\r\n\r\n*Encadrement*\r\n------------------------------\r\nLouise Deléger\r\nClaire Nédellec\r\nAurélie Névéol\r\nPierre Zweigenbaum\r\n\r\n*Pour candidater*\r\n------------------------------\r\nMerci d\'adresser votre candidature avec un CV, une lettre de motivation\r\nainsi que vos notes de l\'année universitaire en cours et de l\'année\r\ndernière à Aurélie Névéol (aurelie.neveol@limsi.fr) et Louise Deléger\r\n(louise.deléger@jouy.inra.fr)\r\n\r\n\r\nRéférences\r\n------------------------------\r\n[1] Neuraz A, Chouchana L, Malamut G, Le Beller C, Roche D, Beaune P,\r\n    Degoulet P, Burgun A, Loriot MA, Avillach P. Phenome-wide\r\n    association studies on a quantitative trait: application to TPMT\r\n    enzyme activity and thiopurine therapy in pharmacogenomics. PloS\r\n    Comput Biol.  2013;9(12):e1003405.\r\n[2] Pradhan, S., Elhadad, N., South, B.R., Martinez, D., Christensen,\r\n    L., Vogel, A., Suominen, H., Chapman, W.W., Savova, G. Evaluating\r\n    the state of the art in disorder recognition and normalization of\r\n    the clinical narrative. J. Am. Med. Inform. Assoc. 2014;22:143-154.\r\n[3] Leaman R, Khare R, Lu Z. Challenges in clinical natural language\r\n    processing for automated disorder normalization. J Biomed\r\n    Inform. 2015 Jul 14. pii:S1532-0464(15)00150-1.\r\n[4] Névéol A, Grouin C, Tannier X, Hamon T, Kelly L, Goeuriot L,\r\n    Zweigenbaum P. CLEF eHealth Evaluation Lab 2015 Task 1b: clinical\r\n    named entity recognition. CLEF 2015, Online Working Notes, CEUR-WS\r\n    1391. 2015.\r\n[5] Leaman R, Islamaj Dogan R, Lu Z. DNorm: disease name normalization\r\n    with pairwise learning to rank. Bioinformatics. 2013 Nov\r\n    15;29(22):2909-17.\r\n[6] Golik W, Warnier P, Nédellec C. Corpus-based extension of\r\n    termino-ontology by linguistic analysis: a use case in biomedical\r\n    event extraction. In 9th International Conference on Terminology and\r\n    Artificial Intelligence 2011 Nov 10 (p. 37)'),
(326, '2016-01-28', 'IGN', 'Saint-Mandé', 'Appariement spatial qualitatif pour la résolution d\'entités spatiales nommées\r\n\r\nMots-clés : Résolution d\'entités spatiales nommées, linked data,\r\ninterconnexion de données, relations spatiales, graphe RDF.\r\n\r\nContexte:\r\n\r\nDe plus en plus de sources de données sont publiées sur le Web des\r\ndonnées selon les recommandations du W3C comme DBpedia, Pleiades ou\r\ndes jeux de données des institutions comme la BNF, l\'INSEE ou l\'IGN\r\n(Atemezing et al., 2014).  \r\n\r\nAinsi publiées selon des standards facilitant leur réutilisation, ces\r\nsources peuvent être mises à profit notamment pour des applications de\r\nTraitement Automatique du Langage Naturel comme la résolution\r\nd\'entités nommées. En effet, la résolution d\'entités nommées consiste\r\nà associer à chaque mention d\'entité nommée, préalablement identifiée\r\ndans un texte, l\'identifiant de l\'entité du monde réel à laquelle elle\r\nfait référence, décrite par une ressource dans un jeu de données du\r\nWeb. Dans le cas de textes spécialisés, l\'absence de textes\r\npréalablement annotés conduit à adopter des approches non supervisées\r\nafin d\'identifier les ressources de référence adéquates. C\'est le cas\r\nnotamment de l\'approche implémentée par l\'application REDEN (Brando et\r\nal., 2015). Dans le cadre de ce stage, on s\'intéresse plus\r\nparticulièrement aux entités spatiales nommées qui peuvent être très\r\nnombreuses dans certains textes spécialisés comme des guides de\r\nvoyage, de randonnées, des descriptions de paysage, des textes\r\nhistoriques, etc.\r\n\r\nSujet :\r\n\r\nL\'objectif du stage est de proposer une extension de REDEN dédiée à la\r\nrésolution d\'entités spatiales nommées identifiées dans des textes\r\nspécialisés et préalablement tagués. Il s\'agira de s\'appuyer sur les\r\napproches de résolutions d\'entités spatiales nommées de la littérature\r\nafin de proposer et d\'implémenter des solutions pour:\r\n\r\n- constituer un dictionnaire d\'entités spatiales candidates à partir\r\nde ressources externes du Web des données,\r\n\r\n- mettre en correspondance les entités spatiales nommées identifiées à\r\npartir des textes avec ces entités candidates,\r\n\r\n- classer les entités candidates à l\'aide d\'une approche d\'appariement\r\nde graphes de relations entre entités spatiales (à définir).\r\n\r\nSelon l\'avancement des travaux on pourra envisager d\'étendre le sujet à la\r\ndésambiguisation des relations spatiales identifiées dans les textes.\r\n\r\nCompétences particulières et formation requises :\r\n\r\nInformatique (programmation Java), données géographiques, linked data.\r\nMaster 2 ou troisième année d\'école d\'ingénieur en informatique ou en\r\ngéomatique avec une forte composante informatique.\r\n\r\nDurée de stage : 5 mois\r\n\r\nPériode de stage: printemps/été 2016\r\n\r\nEncadrement de stage : Carmen Brando (Valilab), Nathalie Abadie\r\n(COGIT)\r\n\r\nLieu de stage : Service de la recherche de l\'Institut National de\r\nl\'Information Géographique et Forestière (IGN), à Saint-Mandé (métro\r\n1, station Saint Mandé).  Le COGIT est un des quatre laboratoires du\r\nservice de la recherche. Il est en charge des recherches liées à la\r\ngestion, la diffusion, la représentation et l\'utilisation de données\r\ngéographiques sous forme de référentiels vectorisés et à grande\r\néchelle.  Le Valilab est un service de la Direction de la Recherche et\r\nde l\'Enseignement de l\'IGN destiné à favoriser la collaboration entre\r\nutilisateurs d\'informations géographiques et les équipes de recherche\r\net d\'enseignement de l\'IGN.\r\n\r\nIndemnités de stage: Stage gratifié.\r\n\r\nModalités de candidature : Envoyer par email et au format PDF en un\r\nseul fichier :\r\n\r\n- CV\r\n- Lettre de motivation ciblée sur le sujet\r\n- Relevés de notes des deux dernières années d\'études\r\n- Liste des enseignements suivis et validés au cours des deux\r\ndernières années d\'études\r\n\r\nContacts: carmen.brando[at]ign.fr, nathalie-f.abadie[at]ign.fr\r\n\r\nBibliographie :\r\n\r\nAtemezing, G.A., N. Abadie, R. Troncy and B. Bucher (2014) Publishing\r\nReference Geodata on the Web: Opportunities and Challenges for IGN\r\nFrance. , Terra Cognita 2014, 6th International Workshop on the\r\nFoundations, Technologies and Applications of the Geospatial Web. In\r\nConjunction with the 13th International Semantic Web Conference,\r\nhttp://event.cwi.nl/terracognita2014/terra2014_1.pdf\r\n\r\nBrando, C., Frontini, F., Ganascia, J.G. (2015): Linked Data for\r\ntoponym linking in French Literary texts, in Proceedings of the 9th\r\nWorkshop on Geographic Information Retrieval, ACM, New York, NY, USA\r\n\r\nBrando, C., Frontini, F., Ganascia, J.G. (2015): Disambiguation of\r\nnamed entities in cultural heritage texts using linked data sets. In:\r\nProceedings of the First International Workshop on Semantic Web for\r\nCultural Heritage in Conjunction with 19th East-European Conference on\r\nAdvances in Databases and Information Systems, New Trends in Databases\r\nand Information Systems, Springer, 539, Poitiers, France,\r\nhttp://link.springer.com/chapter/10.1007%2F978-3-319-23201-0_51'),
(327, '2016-01-28', 'TEMIS / Expert System', 'Paris', 'Appel à candidature : Stage de lexicographie (Enrichissement de réseau\r\nsémantique)\r\n\r\nSujet : Evaluation, amélioration de la qualité et enrichissement d\'un\r\nréseau sémantique pour la langue française.\r\n\r\nEmployeur : TEMIS  / EXPERT SYSTEM\r\nContrat : Stage M1 ou M2 de 3 à 6 mois\r\n\r\nLieu de Travail : TEMIS / EXPERT SYSTEM France (Paris)\r\nTOUR MATTEI - 207 rue de Bercy\r\n75012 Paris\r\n\r\nRémunération : Oui, à discuter\r\n\r\nDate de début : dès que possible suivant les échéances universitaires\r\n\r\nDESCRIPTION\r\n\r\n\r\nLe réseau sémantique Sensigrafo est au coeur de la technologie sémantique\r\nmultilingue et brevetée Cogito (http://www.expertsystem.com/cogito/)\r\nd\'Expert System.\r\n\r\nSensigrafo est consitutée d\'une ontologie qui contient des millions de\r\nconcepts et de relations. Ces capacités conjointes offrent des\r\nfonctionnalités efficaces d\'analyse linguistique et de désambiguïsation\r\nautomatique qui sont à la base de moteurs de classification automatique\r\net d\'extraction d\'entités, de relations et de métadonnées.\r\n\r\nExpert System souhaite améliorer fortement la qualité de son réseau\r\nsémantique en langue française pour l\'amener au niveau de ses versions\r\nanglaises, italiennes et espagnoles.\r\n\r\nPour cela, sous la supervision de notre équipe de linguistes, vous serez\r\namenés à suivre une procédure d\'évaluation de la qualité sur divers\r\ncorpus généraux ou thématiques, qui permettront d\'identifier une\r\ntypologie des anomalies les plus fréquentes et d\'appliquer des\r\nstratégies d\'amélioration diverses (enrichissement lexical, pondération\r\nde sens en fonction de domaines, regroupement/séparation de sens, etc...)\r\n\r\nCe stage demande une parfaite connaissance de la langue française, de sa\r\ngrammaire et de sa syntaxe. Une bonne connaissance des théories et des\r\noutils de traitement automatique des langues naturelles est un plus.\r\n\r\nIl peut convenir à des élèves de type Master en lexicographie ou en\r\ntraitement des langues naturelles.\r\n\r\nLe stage est prévu pour une durée de 3 mois mais peut s\'adapter aux\r\ncontraintes de l\'étudiant.\r\n\r\nLe stage se déroule dans les locaux d\'Expert System à Paris.\r\n\r\nCANDIDATURE\r\n\r\nLes candidats sont invités à prendre contact par mail à l\'adresse :\r\nchristian.lautier@temis.com'),
(328, '2016-02-03', 'Syllabs', 'Paris', '---------------------------\r\nOffre de stage TAL M2 : Génération automatique de textes en français\r\n---------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en génération\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse de\r\ndonnées textuelles du Web : identification des pages pertinentes,\r\nextraction et catégorisation des informations clés. La génération est\r\nproposée au travers de sa solution Data2Content (data2content.fr) qui\r\npermet, à partir d\'une base de données structurées, de générer\r\nautomatiquement des textes de qualité humaine.\r\n\r\nC\'est dans le cadre de Data2Content que nous recherchons un(e)\r\ningénieur(e) linguiste pour un stage dans le domaine de la création\r\nautomatique de textes en français (langue maternelle).\r\nL\'objet principal du stage est de travailler sur le paramétrage de notre\r\noutil de génération (écriture de règles). Les domaines d\'application\r\npeuvent par exemple être le e-commerce (descriptifs de produits), le\r\ntourisme (par exemple, descriptif d\'un hôtel) ou les médias (brève sur\r\nles résultats des élections, etc.).\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent:\r\n- Génération automatique de textes : paramétrage de l\'outil de\r\n  génération en fonction du projet, participation aux tests et à\r\n  l\'amélioration de l\'outil.\r\n- Ecriture de scripts pour la manipulation des bases de données en\r\n  entrée du moteur de génération.\r\n\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou similaire\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail en\r\n  équipe\r\n- Programmation en Python\r\n- Compétences en rédaction web seraient un plus\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 6 mois rémunéré en fonction du niveau d\'étude +\r\ntickets resto + remboursement à moitié du pass Navigo (transport)\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage génération français ».\r\nLieu : Syllabs, 82 rue du Faubourg Saint-Martin, 75010 Paris\r\nContrat : stage. Début : mars-avril 2016.'),
(329, '2016-02-03', 'Airbus', 'Toulouse', 'Internship / Voice to Text, Text to Speech, Voice recognition (m/f)\r\n\r\nAirbus Toulouse\r\n\r\nAirbus Group is a global leader in aeronautics, space and related\r\nservices. In 2014, the Group - comprising Airbus, Airbus Defence and\r\nSpace and Airbus Helicopters - generated revenues of ¤ 60.7 billion\r\nand employed a workforce of around 138,600.\r\n\r\nDescription of the job\r\n\r\nAirbus (Toulouse) is looking for an intern for a 6-month internship.\r\n\r\nThis internship will start on 4th April 2016 (subject to some\r\nflexibility).\r\n\r\nTasks & accountabilities\r\n\r\nYour main tasks will include:\r\n\r\n- Performing a state of the art of the different industries which\r\n  develop Voice to Text, Text to Speech and Speech Recognition\r\n  software,\r\n\r\n- Investigating the use and reliability of existing Voice to Text,\r\n  Text to Speech and Speech Recognition software to help pilots in\r\n  operation (considering also, for example, the use of technical\r\n  terms, the ambient noise, the use of abbreviations/acronyms),\r\n\r\n- Defining interesting operational use-cases in which the use of such\r\n  software would be interesting,\r\n\r\n- Performing operational tests on a platform to prove the relevance of\r\n  using such software for pilots in operation.\r\n\r\nRequired skills\r\n\r\nYou are in the 2nd year of a master\'s degree or in the 5th year of\r\nuniversity, specialising in Phonetics or phonology.\r\n\r\nYou ideally have initial experience in this field and you have:\r\n\r\n    Knowledge of Natural Language processing,\r\n    Knowledge of Phonetics and phonology.\r\n\r\nYou are a good team player and have excellent interpersonal skills.\r\n\r\nEnglish: intermediate level,\r\nFrench: intermediate level.\r\n\r\n\r\nApply online:\r\n\r\nhttp://www.airbusgroup.com/int/en/people-careers/jobs-and-applications/search-for-vacancies~jobid=001A4B0A914A1ED59FC91E2B50CA460A~.html'),
(330, '2016-02-03', 'STL', 'Lille', 'Extraction d\'informations pour construire une base de connaissances sur\r\nle patrimoine industriel textile à partir de sources de données\r\nhétérogènes\r\n\r\n\r\nRiche d\'une histoire de plus de dix siècles, les différentes régions du\r\nterritoire français sont jalonnées de prestigieux monuments, de\r\nbâtiments industriels et d\'espaces naturels témoins de leurs influences\r\nhistoriques successives. Pour sauvegarder et valoriser ce patrimoine,\r\ndifférentes métropoles et notamment celle de Lille, particulièrement\r\ntouchée par les vicissitudes de l\'Histoire dans le domaine de\r\nl\'industrie textile au XXe siècle, développe une politique de\r\nrestauration ambitieuse. Nous assistons ainsi à un accroissement\r\nprodigieux des contenus numériques décrivant ce patrimoine et de la\r\npuissance des techniques de production et de diffusion, et ceci à\r\ndifférentes échelles du territoire et notamment à l\'échelle des\r\nrégions. Il s\'agit d\'un processus dont l\'importance et la rapidité sont\r\nprobablement sans précédent dans l\'histoire de l\'humanité. En effet, ce\r\nque promet la société du numérique et qui se dessine sous nos yeux,\r\nc\'est une toute autre façon de nous représenter et de concevoir\r\nl\'espace, le temps, et plus généralement l\'ensemble des connaissances\r\nrelatives au territoire. Dans ce sens, différents territoires telles que\r\nla Région Nord Pas de Calais (NPDC) ont engagé une démarche de réflexion\r\nsur le numérique et son impact sur les usages dans des domaines variés :\r\nl\'éducation, le transport, les infrastructures, le tourisme, la culture,\r\nles villes intelligentes.\r\n\r\nLe projet interdisciplinaire TECTONIQ s\'inscrit pleinement dans cette\r\ndémarche en proposant de définir une méthodologie semi-automatique\r\nreproductible permettant la diffusion, le partage et la valorisation des\r\nconnaissances patrimoniales présentes dans les nombreux documents\r\nnumériques hétérogènes mis à disposition dans les bases de données et/ou\r\nsur le Web par les acteurs locaux (centres documentaires tels que les\r\nmusées et médiathèques, collectivités territoriales, la presse, et les\r\ncitoyens eux-mêmes notamment par l\'intermédiaire des blogs). Ce\r\nmouvement, au coeur du domaine des Humanités Numériques et fédérant des\r\nchercheurs en Sciences de l\'Information et de la Communication (SIC), en\r\nLinguistique, en Histoire ainsi qu\'en Informatique et des experts des\r\ncollectivités territoriales, est l\'occasion d\'échanger sur la gestion et\r\nl\'appropriation des documents numériques pour répondre à une demande\r\nd\'accès rapide et simplifié à des contenus volumineux et\r\nhétérogènes. Les objectifs du projet sont tout d\'abord (1) de construire\r\nune base de connaissances pour valoriser le patrimoine industriel\r\ntextile (matériel et immatériel) disponible à l\'échelle des régions tout\r\nd\'abord, puis à l\'échelle nationale ensuite, et (2) d\'analyser finement\r\nles usages des données existantes par les différents acteurs (citoyens,\r\nentreprises, scientifiques, collectivités, etc.) afin de mettre en place\r\nun moteur de recherche d\'information adapté. Le territoire\r\nd\'expérimentation est composé pour 2016 des régions Nord Pas de Calais\r\n(NPDC) et Picardie, dans lesquelles sont localisés de nombreux acteurs\r\nimportants du domaine.\r\n\r\nL\'objectif de ce stage consiste à répondre au premier objectif du projet\r\nvisant à traiter les informations provenant de différentes sources afin\r\nde construire une base de connaissances relative au domaine\r\nd\'étude. Plus particulièrement, le cadre du stage est lié au patrimoine\r\nindustriel textile dans la région Nord Pas de Calais, qui est une des\r\nrégions les plus dynamiques dans le domaine. De plus, de nombreux\r\nacteurs régionaux (bibliothèques, musées, etc.) participant au projet\r\nmettent à disposition leurs compétences pour aider à la valorisation du\r\ntravail d\'annotation réalisé sur les corpus mis à disposition. \r\n\r\nPour la réalisation du stage, des méthodes de Traitement Automatique de\r\nla Langue, de fouille de textes et de construction d\'un vocabulaire\r\ncontrôlé de type ontologie seront utilisées. Plus spécifiquement, il\r\ns\'agit des objectifs suivants:\r\n\r\n- travailler avec des corpus de textes de différents types et provenant\r\n  de différentes sources ;\r\n\r\n- exploiter et améliorer les annotations des textes avec différents\r\n  niveaux de spécificité ;\r\n\r\n- exploiter, adapter ou développer des méthodes pour l\'extraction\r\n  d\'information. Les informations à extraire ici sont les thématiques\r\n  propres au domaine du patrimoine industriel textile. Des lexiques,\r\n  définis dans le cadre du projet, pourront être utilisés ;\r\n\r\n- Structurer les thématiques extraites dans une ontologie de domaine,\r\n  offrant une première représentation du domaine sur la base des\r\n  documents traités ;\r\n\r\n- évaluer les méthodes et résultats\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL et fouille de textes\r\nexistants et à développer ses propres programmes pour mieux analyser les\r\ndonnées. La base de connaissances sera formalisée selon le formalisme\r\nOWL CIDOC-CRM, défini pour structurer les connaissances liées au\r\npatrimoine. Il sera force de proposition tout au long du stage et\r\nparticipera aux différentes réunions plénières du projet.\r\n\r\nPrérequis:\r\n- connaissances en TAL, en fouille de textes et en structuration des\r\n  connaissances (thesaurus, ontologie OWL)\r\n- manipulation et test des outils de TAL & fouille de textes (exemple\r\n  GATE, Weka...)\r\n- des connaissances du langage ontologique OWL, et plus précisément du\r\n  formalisme CIDOC-CRM seront appréciés.\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique\r\n\r\nLe stage est rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nNiveau: Master 2\r\nDurée: 6 mois\r\nLieu: Lille\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à\r\nnatalia.grabar@univ-lille3.fr, eric.kergosien@univ-lille3.fr'),
(331, '2016-02-08', 'TrooClick', 'Paris', 'NLP Engineer Internship at Trooclick\r\n\r\n-----\r\nContext\r\n-----\r\n\r\nTrooclick France is a company that specializes in the development of web\r\napplications for the automatic processing of information.  Our goal is\r\nto rank news articles exclusively by quality, to help people find a\r\nvariety of high quality content quickly, easily, and transparently.\r\nMore generally, we want to create a new and better user experience for\r\nonline news consumption via text analysis and automated restructuring of\r\nthe news. By automatically extracting quotes and tweets around a story\r\nand generating short summaries we build a different, more engaging, view\r\nof news events.\r\n\r\nTrooclick was created in November 2012. Just a few months later, in\r\nApril 2013, it received financial support from the BPI (French public\r\ninvestment bank) and in June 2013 was granted the Status of \"Young\r\nInnovative Company\" (JEI), recognizing its innovative nature by the\r\nFrench government. It now counts fifteen committed and passionate\r\nmembers in its tight-knit team.\r\nThe company carries out R&D projects in search of technical solutions in\r\nthe Artificial Intelligence field. Due to its growth, Trooclick is now\r\nlooking for candidates for its office in the \"Incubateur Boucicaut\" on\r\nrue de Lourmel in Paris.\r\n\r\n-----\r\nMissions\r\n-----\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\n- You will turn ideas into well-documented and reliable linguistic\r\n  resources (both dictionaries and grammars) to ensure efficiency,\r\n  quality, performance and scalability\r\n- A great team player, you will interact with other departments to\r\n  understand and fine tune specifications\r\n- You will carry out unitary testing, create and maintain our test\r\n  validation corpus and participate in editing technical documents\r\n\r\nDevelopment will be done in English.\r\n\r\n-----\r\nQualifications\r\n-----\r\n\r\n- BSc/MSc\r\n- Experience with NLP tools such as NooJ, Unitex, Gate, or Stanford for\r\n  linguistic annotation, named entity recognition, relationship and fact\r\n  extraction, sentiment analysis, etc.\r\n- Experience in scripting languages such as Perl or Python as well as\r\n  XML format to be autonomous in completing several technical tasks\r\n- Experience with basic database management operations (SQL language)\r\n- Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.)  will be\r\n  a plus\r\n- Excellent communication skills in English and French\r\n\r\nWe are open to new ideas that will significantly contribute to our\r\nsuccess.\r\nOur friendly team will provide the opportunity for valuable\r\ncollaboration.\r\nWe offer you career perspectives in a young and dynamic company with an\r\ninteresting and diversified scope of duties at the cutting edge of\r\nresearch.\r\n\r\nWe welcome applications from highly motivated individuals able to learn\r\nnew techniques and share knowledge and experience with the team.\r\n\r\n-----\r\nContact\r\n-----\r\n\r\nInterested? Then send your application to jobs@trooclick.com !'),
(332, '2016-02-08', 'LIMSI', 'Orsay', '- Titre : Etude des représentations distribuées pour l\'extraction de\r\n  relations\r\n\r\n- Descriptif\r\n\r\nLe sujet proposé se focalise sur le problème de l\'extraction de\r\nrelations binaires au sein de phrases. La tâche considérée se définit\r\nplus précisément comme une forme de validation : partant d\'un type de\r\nrelation défini a priori et d\'une phrase au sein de laquelle deux\r\narguments possibles de la relation sont identifiés, l\'objectif est de\r\ndéterminer si une relation du type considéré est véritablement exprimée\r\ndans la phrase entre les deux arguments repérés. Dans le cadre du stage\r\nproposé, nous nous concentrons plus particulièrement sur les relations\r\ncorrespondant à des attributs de personnes (date de naissance, conjoint\r\n...) ou d\'organisations (siège, nombre d\'employés ...), à l\'instar des\r\nrelations considérées dans la tâche Slot Filling des évaluations TAC,\r\nmais aussi sur les relations correspondant aux rôles associés à un type\r\nd\'événement (par exemple la personne jouant le rôle d\'accusé dans un\r\nprocès) et sur les relations issues de bases de connaissances telles que\r\nDBPedia.\r\n\r\nCette tâche a fait l\'objet d\'un large ensemble de travaux explorant en\r\nparticulier les différents types d\'information pouvant être exploités\r\npar des classifieurs statistiques de différentes natures. Une vague\r\nencore récente de travaux en relation avec l\'apprentissage profond (Deep\r\nLearning) a mis sur le devant de la scène une perspective un peu\r\ndifférente. Dans ce contexte, l\'objectif n\'est plus de sélectionner des\r\ntraits fournis par des outils de traitement automatique des langues mais\r\nde construire ou d\'apprendre des représentations lexicales distribuées\r\ncaractérisant les relations de proximité des mots. Ces représentations\r\npeuvent être générales ou liées à la tâche particulière pour laquelle\r\nelles sont utilisées.\r\n\r\nL\'objectif du stage est d\'étudier l\'impact de telles représentations sur\r\nla tâche d\'extraction de relations considérée ici. Un premier travail\r\ntrès préliminaire a déjà été réalisé sur l\'utilisation de\r\nreprésentations neuronales pour l\'extraction de rôles événementiels. Le\r\nsujet se propose d\'étendre ce travail dans la perspective de l\'analyser,\r\nle généraliser et le systématiser. Plus précisément, les tâches\r\nsuivantes sont envisagées :\r\n\r\n- application de différents types de représentations lexicales\r\n  distribuées au problème considéré (représentations neuronales,\r\n  clusters de Brown, espaces issus de techniques de réduction de\r\n  dimensions, représentations distributionnelles) ;\r\n\r\n- analyse fine de l\'apport des représentations distribuées et de leurs\r\n  limites en fonction du type des relations et de leurs arguments ;\r\n\r\n- étude de l\'adéquation entre le type de représentation et le type de\r\n  classifieur l\'exploitant. Dans ce cadre, l\'intérêt de l\'utilisation de\r\n  réseaux de neurones profonds pour l\'adaptation de représentations\r\n  générales à un domaine particulier sera considéré.\r\n\r\nLe stage se déroulera au sein du laboratoire LIMSI et sera encadré\r\nconjointement par Brigitte Grau et Romain Beaumont du LIMSI ainsi\r\nqu\'Olivier Ferret du CEA LIST.\r\n\r\n\r\nDurée : 4-5 mois\r\nLieu : LIMSI-CNRS, Orsay\r\nGratification : 554¤ par mois plus participation aux frais de transport\r\nen commun\r\n\r\nProfil recherché\r\n- Niveau : Master 2 ou ingénieur dernière année\r\n- Domaine de spécialité requis: Informatique, avec connaissances en \r\n  apprentissage ou traitement automatique des langues\r\n- Langages de programmation: Python, Bash, éventuellement Perl, Java ou\r\n  C++\r\n- Environnement : Linux\r\n\r\nCandidature : envoi d\'un CV (en PDF) à brigitte.grau@limsi.fr et\r\nolivier.ferret@cea.fr accompagné d\'une lettre de motivation ainsi que\r\ndes notes de l\'année universitaire en cours et de l\'année dernière.'),
(333, '2016-02-08', 'Télécom Bretagne', 'Brest', '--------------\r\nOffre de stage TAL M2 : Étude de l\'apport des dépêches AFP à un corpus\r\nde textes de la presse écrite\r\n--------------\r\nStage financé par le Labex ICCA,  projet structurant «Plateformes» 2016\r\n--------------\r\n\r\nLe projet 2PI (Modèles économiques de la presse en ligne & pluralisme de\r\nl\'information) se propose de comparer, à différents niveaux\r\nlinguistiques, des textes provenant de l\'agence de presse AFP et\r\nd\'autres titres de presse.\r\n\r\nLes étapes d\'analyse des textes seront :\r\n- extraction terminologique\r\n- analyse morphosyntaxique\r\n- annotation sémantique\r\n- extraction d\'entités nommées\r\n- analyse rhétorique (selon la théorie des arbres discursifs de Marcu\r\n  [1,2]).\r\n\r\nSelon les outils à disposition, ces étapes seront automatiques ou\r\nsemi-automatiques.  L\'analyse rhétorique nécessitera le développement\r\nd\'outils ad hoc, basés sur des méthodes de machine learning détectant\r\ndes marqueurs syncatégorématiques et d\'autres propriétés du texte, à\r\nétablir. Les données étant temporalisées on étudiera également\r\nl\'évolution des propriétés des textes.\r\n\r\nEn représentant toutes les propriétés linguistiques extraites des textes\r\ndu corpus sous forme de graphes, il s\'agira de mesurer l\'apport des\r\ntextes de l\'AFP vis-à-vis de celui des textes des autres médias et de\r\ncaractériser/quantifier ainsi la notion de «pluralisme des médias».\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent :\r\n- Analyses et annotations automatiques ou semi-automatiques des textes.\r\n- Développement et évaluation de l\'outil d\'analyse rhétorique.\r\n- Modélisation des résultats sous forme de graphes et application de\r\n  différentes mesures de similarité entre les sous-graphes induits par\r\n  les données AFP et leurs compléments.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou\r\n  similaire.\r\n- Programmation en Python (principalement NLTK).\r\n- Curiosité et capacité d\'explorer des nouveaux domaines en linguistique\r\n  et/ou informatique.\r\n- Des connaissances en théorie des graphes seraient un plus\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 6 mois rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nyannis.haralambous@telecom-bretagne.eu\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : Département Informatique, Télécom Bretagne, Brest.\r\n\r\nEncadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285\r\n             Lab-STICC)\r\n             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)\r\n\r\nContrat : stage. \r\n\r\nDébut : mars-avril 2016.\r\n\r\n[1] MARCU Daniel, 2000. The Theory and Practice of Discourse Parsing and\r\n    Summarization, MIT Press.\r\n\r\n[2] ROZE, Charlotte, 2013. Vers une algèbre des relations du discours,\r\n    thèse de doctorat, université Paris VII.'),
(334, '2016-02-08', 'Voxygen', 'Rennes', 'Offre de Stage :\r\n\r\nVoxygen est une entreprise dédiée au développement et à la valorisation\r\ndes technologies de Synthèse Vocale, de Reconnaissance Vocale et\r\nd\'Identification de locuteur.\r\nIssue des laboratoires d\'Orange Labs, les solutions vocales de Voxygen\r\ns\'appliquent à de nombreux domaines, pour des besoins aussi spécifiques\r\nque variés : Télécoms, Transports, Accessibilité, Santé, Médias,\r\nFormation et Jeux, etc. Ces solutions sont déclinées dans plusieurs\r\nlangues dont les principales langues européennes, l\'anglais US, l\'arabe\r\nstandard et certaines langues subsahariennes comme le hausa, le zarma et\r\nle wolof.\r\n\r\nMots clés : traitement automatique de l\'arabe, synthèse vocale\r\n\r\nContexte:\r\nDans le cadre de ses activités de recherche et développement, Voxygen\r\ntravaille sans cesse à l\'amélioration des traitements linguistiques mis\r\nen oeuvre dans ses systèmes. Parmi ces travaux figure la langue arabe qui\r\nprésente une difficulté majeure en traitement automatique liée à\r\nl\'absence des signes diacritiques (voyelles brèves) dans la plupart des\r\ntextes écrits. Voxygen a développé un voyelleur automatique de textes\r\narabes basé sur un lexique de mots, une analyse morphologique et\r\nl\'application d\'un modèle de langue probabiliste. Néanmoins, et en\r\nraison de la complexité de cette tâche, des erreurs de voyellation\r\nsubsistent et impactent directement la prononciation des mots.\r\n\r\nSujet :\r\nAmélioration de la voyellation automatique de l\'arabe\r\n\r\nLe but de ce stage est l\'amélioration des traitements linguistiques mis\r\nen oeuvre pour la voyellation automatique de l\'arabe. En particulier :\r\n\r\n- Identifier les erreurs, déterminer leurs origines (analyse\r\n  morphologique, lexique, désambiguïsation, etc.)\r\n\r\n- Proposer des solutions d\'amélioration. Plusieurs pistes sont\r\n  envisagées :\r\n    *Optimisation du processus de génération du modèle de langue\r\n    *Mise en place d\'une stratégie pour le traitement des mots hors\r\n     lexique\r\n- Adapter la voyellation automatique de l\'arabe au contexte de la\r\n  synthèse vocale\r\n\r\nCompétences :\r\n- bonne connaissance de la langue arabe\r\n- traitement automatique de la langue écrite\r\n- morphologie, lexique, syntaxe\r\n- élaboration de scripts (Shell, Python ou Perl)\r\n\r\nDurée du stage : 4 à 6 mois, à partir de mars-avril 2016\r\n\r\nLieu du stage : Rennes\r\n\r\nMerci d\'adresser votre candidature (CV + motivations) à jobs@voxygen.fr'),
(335, '2016-02-12', 'Succeed Together', 'Paris', 'Proposition de stage\r\n\r\nSujet: Développement d\'une API de catégorisation de textes courts.\r\n\r\nType de poste : Stage 6 à 12 mois\r\nLieu de travail : Succeed Together, 60 bis rue de Rochechouart, 75009\r\n                  Paris\r\n\r\nContexte\r\n\r\nAu sein du pôle recherche et développement de l\'entreprise Succeed\r\nTogether, nous orientons nos recherches sur le regroupement sémantique\r\nultra rapide de messages courts.\r\n\r\nDans le domaine de l\'analyse de textes, Succeed Together recherche\r\nun/une stagiaire pour travailler sur des techniques de classification\r\n(supervisée et non supervisée ) de messages courts :\r\n\r\n   - classification par polarité : Il s\'agit pour des messages courts,\r\n     de juger de leur subjectivité dans un premier temps, et de détecter\r\n     leurs polarités (positive/négative) dans un second temps.\r\n\r\n   - classification par thématique : Il s\'agit ici pour des messages\r\n     courts d\'identifier leurs thématiques associées. C\'est l\'exemple de\r\n     messages \"être proche de son client\" et \"privilégier la proximité\"\r\n     qui appartiennent à la thématique \"proximité avec les clients\".\r\n\r\nObjectifs\r\n\r\nA partir de messages courts provenant de plusieurs sources (réponses à\r\ndes questions, réseaux sociaux, ...), pouvant être de langues\r\ndifférentes, l\'application visée a pour but de regrouper\r\nautomatiquement, de produire une classification par thématique et/ou par\r\npolarité.\r\n\r\nLa tâche du stagiaire consistera donc en particulier à :\r\n\r\n   - Étudier et tester les algorithmes de classification par thématique\r\n     (respectivement par polarité) des messages courts ;\r\n\r\n   - Assister les développeurs dans la mise en place de l\'API ;\r\n\r\n   - Évaluer les différentes solutions sur des données de référence ;\r\n\r\nProfil recherché:\r\n\r\n   - Compétences en traitement automatique des langues / recherche\r\n     d\'information / mesures de similarité textuelle\r\n\r\n   - Connaissances des techniques de clustering / classification\r\n\r\n   - Langage de programmation utilisé: python, java\r\n\r\n   - Compétences en statistique seraient un plus\r\n\r\nLes candidats intéressés doivent envoyer un email de candidature à\r\ngdurand@succeed-together.eu avec un CV détaillé (pdf) et une lettre de\r\nmotivation.'),
(336, '2016-02-17', 'LIGM', 'Marne-la-vallée', '--------------\r\nOffre de stage TAL M2 : POS tagging hybride avec Gate et Unitex/GramLab\r\n\r\n--------------\r\nStage financé par le projet CRC de la Hankuk University of Foreign \r\nStudies (HUFS, Corée du Sud)\r\n--------------\r\n\r\nLe LIGM est un laboratoire CNRS de recherche en informatique inclus dans\r\nle LabEx (Laboratoire d\'excellence) Bézout. Le LIGM a 70 membres\r\npermanents. La communauté des utilisateurs et développeurs du système\r\nUnitex/GramLab est coordonnée par le LIGM.\r\n\r\nLe projet de recherche CRC financé par le gouvernement coréen se propose\r\nentre autres de développer un POS tagger hybride en combinant Gate et\r\nUnitex/GramLab.\r\n\r\nGate et Unitex/GramLab sont deux systèmes open source complémentaires\r\nqui couvrent un large éventail de tâches du traitement automatique des\r\nlangues (TAL), qui sont documentés et réunissent chacun une communauté\r\nstructurée.\r\n\r\nLes étapes du tagging seront :\r\n- tokenisation et découpage en phrases sous Unitex/GramLab\r\n- génération d\'étiquetages candidats par analyse morphologique\r\n  symbolique sous Unitex/GramLab\r\n- transfert des candidats vers Gate\r\n- sélection du meilleur candidat par un modèle probabiliste entrainé sur\r\n  un corpus annoté\r\n- transfert vers Unitex.\r\nCette chaine de traitement convient pour toute langue nécessitant une\r\nanalyse morphologique, comme le coréen et l\'arabe.\r\n\r\nL\'objectif du stage est de développer les fonctionnalités nécessaires\r\npour mener à bien cette expérience.\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent :\r\n- Développement sous Unitex/GramLab de fonctionnalités d\'exportation de\r\n  corpus annotés vers Gate : d\'une part, corpus étiquetés à la main\r\n  (pour l\'apprentissage du tagger) et d\'autre part, étiquetages\r\n  candidats obtenus par analyse morphologique. Le format cible est le\r\n  format XML de sérialisation de Gate (C/C++, Java).\r\n- Développement sous Gate d\'un programme d\'entrainement du tagger à\r\n  partir d\'un corpus en coréen annoté à la main par l\'HUFS (Java).\r\n- Développement sous Gate d\'un programme d\'application du tagger aux\r\n  étiquetages candidats (Java).\r\n- Développement sous Unitex:GramLab d\'une fonctionnalité d\'import de\r\n  corpus annotés depuis Gate (C/C++, Java).\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou\r\n  similaire.\r\n- Programmation en Java et C/C++.\r\n- Intérêt pour le développement open source.\r\n- Curiosité et capacité d\'explorer de nouvelles méthodes statistiques en\r\n  TAL.\r\n- Une expérience d\'Unicode serait un plus.\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné de 4 à 5 mois, 554,40 euros/mois net.\r\n\r\nNombre de postes : 1 poste\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\neric.laporte@univ-paris-est.fr\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : LIGM, Université Paris-Est Marne-la-Vallée.\r\n\r\nEncadrants : Eric Laporte (Université Paris-Est Marne-la-Vallée et UMR\r\nCNRS 8049 LIGM)\r\nMatthieu Constant (INRIA Alpage)\r\nCristian Martinez (LIGM)\r\n\r\nContrat : convention de stage.\r\n\r\nDébut : mars ou avril 2016.'),
(337, '2016-02-23', 'Alkemics', 'Paris', 'Stage Ontologie\r\n\r\nParis, Île-de-France, France\r\n\r\nDescription\r\n\r\nÀ propos d\'Alkemics\r\n\r\nAlkemics connecte les marques (Unilever, Nestlé, P&G...) et les\r\ndistributeurs (Auchan, Casino...) à l\'aide d\'un service collaboratif\r\ndédié à la grande distribution.\r\n\r\nNous proposons Product Stream, une plateforme qui permet aux marques\r\nde grande consommation et aux distributeurs de centraliser et partager\r\ntoute l\'information produit sur un unique canal de\r\ncommunication. Grâce au réseau des clients d\'Alkemics (plus de 800\r\nmarques et 6 grandes enseignes distributeurs), Product Stream permet\r\naux marques d\'enrichir et d\'uniformiser les fiches produits sur\r\nl\'ensemble des sites e-commerce en un clic.\r\n\r\nAlkemics, start-up innovante et en pleine croissance (effectif triplé\r\nen 1 an, 50 personnes à date) recherche un étudiant en linguistique ou\r\nTAL afin de travailler sur la refonte de son ontologie.\r\n\r\n\r\nDescription de la mission\r\n\r\nVous serez intégré à l\'équipe R&D, et travaillerez en étroite\r\ncollaboration avec des personnes ayant une forte connaissance produit\r\ndans le cadre de la grande distribution. Le but du stage est de\r\nretranscrire dans notre ontologie les problématiques de classification\r\net de normalisation de l\'ensemble de l\'offre produit de grande\r\nconsommation afin d\'alimenter nos technologies applicatives qui\r\nproposent des solutions marketing intelligentes.\r\n\r\nUne analyse des différentes catégories de produits de la grande\r\nconsommation vous sera confiée : vous mènerez dans le cadre de votre\r\nmission une étude complète pour classifier et faire ressortir tous les\r\nattributs ontologiques indispensables pour modéliser chaque catégorie\r\nde produit dans le cadre des applications développées par Alkemics.\r\n\r\nCette étude aura un volet formel et un volet pratique :\r\n\r\n    Volet formel : en vous appuyant sur une version existante de notre\r\n    ontologie, vous proposerez un scénario d\'évolution de cette\r\n    dernière afin de mieux répondre aux besoins métiers en interne.\r\n\r\n    Volet pratique : vous participerez à des entretiens avec les\r\n    principaux acteurs de la grande consommation (marques et\r\n    distributeurs) et procéderez à des recherches documentaires\r\n    (connaissances marketing, réglementaire et encyclopédique du\r\n    produit) afin de consolider l\'aspect fonctionnel de la ressource.\r\n\r\nVous aurez à l\'issue de ce stage une excellente expérience en\r\n\"ontologie de terrain\" appliquée au monde de la grande distribution.\r\n\r\nRequirements\r\n\r\n- Vous avez des connaissances en ontologie(format OWL, logiques de description)\r\n- Vous savez utiliser Protégé, NeOn ou tout autre éditeur d\'ontologie.\r\n- Vous êtes autonome dans votre travail\r\n- Vous êtes pragmatique et savez prioriser vos missions\r\n- Vous arrivez à comprendre et décortiquer rapidement des informations\r\n  sur un domaine inconnu\r\n- Vous arrivez à modéliser et hiérarchiser un grand nombre de\r\n  connaissances relatives à un même concept\r\n- Un premier stage en ontologie ou concernant des produit grande\r\n  consommation serait un plus\r\n- Excellent niveau de français, bon niveau d\'anglais.\r\n\r\nBenefits\r\n\r\n - Rémunération en fonction du profil.\r\n - Pas de bureaucratie : vos contributions auront un véritable impact.\r\n - Vous ne serez pas oublié dans un coin : notre mode de\r\n     fonctionnement en petites équipes vous permettra de monter en\r\n     compétence rapidement, et de ne pas rester bloquer sur un\r\n     problème trop longtemps.\r\n - Notre start-up en phase de fort développement : si vous menez à\r\n     bien votre mission, il y aura une possibilité d\'embauche à\r\n     l\'issue du stage.\r\n - Nos bureaux sont en plein coeur du 9ème arrondissement\r\n - Extras : sessions de sport hebdomadaires, séances de méditation,\r\n     ateliers sur différents sujets, etc.\r\n\r\n\r\nCandidature en ligne sur :\r\n\r\nhttps://alkemics.workable.com/jobs/206262');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(338, '2016-02-23', 'SESAMm', 'Luxembourg & Metz', 'Hello,\r\n\r\nOur team is looking for an intern or a graduate in Natural Language\r\nProcessing for Japanese for 6 months (internship or 6 months contract\r\nbefore a permanent contract if results are satisfactory):\r\n\r\nhttp://www.sesamm.com/wp-content/uploads/2016/02/SESAMm_Internship-Description_NLP_Japanese.pdf\r\n\r\nSESAMm was founded in 2014 and is one of the most dynamic FinTech\r\nstartups in France and Luxembourg. SESAMm develops and commercializes\r\nstock market forecasting tools based on social media and other textual\r\ndata sources.These products are used by banks and hedge funds. The\r\ncompany provides financial trading indicators which have been created\r\nusing Big Data methods and allowing new approaches for trading\r\nstrategies. We develop many new products based on our clients\' needs.\r\n\r\nSESAMm aims at becoming the international leader of Big Data\r\ntechnologies for stock market professionals.\r\n\r\nInternship Goal: development of new text-analysis and sentiment analysis\r\nmethods to create financial trading indicators based on information from\r\nJapanese social media and social trading platforms.\r\n\r\nMajor Duties:\r\n- Participate in existing and future research projects: analyze existing\r\n  methods, develop original solutions and evaluate them, present results\r\n- Identify relevant sources of information and extract data. Crawling &\r\n  scraping of several data sources.\r\n- Filter and prepare data\r\n- Develop NLP algorithms for Japanese\r\n- Write analysis reports\r\n\r\nEducation Requirements\r\n- Engineering school or university master student: Computer Science,\r\n  Natural Language Processing or similar.\r\n\r\nWork Experience and Skills Requirements\r\n- Work Experience: 0-1 year in NLP or computer science.\r\n- Knowledge in NLP, Machine Learning, crawling and scraping.\r\n- Demonstrate ability to create lexical semantic resources for NLP-based\r\n  applications.\r\n- Languages: native japanese, French or Enhlish spoken\r\n- Programming Skills : Java and scripting languages\r\n\r\nThe applicant should be able to work in a team and show high\r\nmotivation. This internship requires autonomy and curiosity toward a\r\nchanging environment. The intern will contribute to the company\'s most\r\nimportant technical decisions; thereby this internship will be a\r\nhigh-level entrepreneurial experience.\r\n\r\nWorking Conditions\r\n- Percent Time: 100%\r\n- Location: Luxembourg (Boulevard Royal, City Center) and Metz (France)\r\n- Duration: 6 months, starting in April 2016.\r\n\r\n\r\nJoin SESAMm, an innovative and ambitious FinTech startup with\r\nhigh potential.\r\nMore information: www.sesamm.com\r\nPlease send your application to contact@sesamm.com\r\nApplication: resume, interview'),
(339, '2016-02-23', 'MoDyCo', 'Nanterre', 'Bonjour,\r\n\r\nUn sujet de stage est proposé dans le cadre plus large d\'un projet de\r\nrecherche réunissant plusieurs laboratoires : LORIA (Nancy), GREYC\r\n(Caen) - LIPN (Paris 13), INSERM (Paris) et MoDyCo (Paris 10). Ce projet\r\na pour objectif d\'extraire des informations à partir de textes\r\nbiologiques et médicaux sur les maladies orphelines (dites aussi\r\nmaladies rares) pour apporter une aide automatique à l\'enrichissement\r\nd\'une base de connaissances, notamment du site d\'information Orphanet\r\ndédié à ce type de maladies. Pour une présentation générale du projet et\r\nde quelques résultats en particulier, on pourra consulter le site dédié :\r\nhttp://hybride.loria.fr/\r\n\r\nLe stage portera plus précisément sur le repérage des symptômes liés à\r\nces maladies dans des textes scientifiques en anglais. Plusieurs\r\ntechniques ont été déjà développées dans le cadre du projet, notamment\r\nla fouille de données, l\'analyse syntaxique et les CRF (Conditionnal\r\nRandom Fields). Les programmes informatiques développés et des jeux de\r\ncorpus seront fournis.  Il s\'agira de les expérimenter afin de comparer\r\nleurs avantages et leurs défauts, puis on cherchera à améliorer les\r\nrésultats en proposant une combinaison de ces techniques.\r\n\r\nQuelques références bibliographiques :\r\n\r\nLaure Martin, Delphine Battistelli, Thierry Charnois (2014). Symptom\r\nrecognition issue, in Proceedings BioNLP 2014 (13th Workshop on\r\nBiomedical Natural Language Processing), held in conjunction with\r\nACL\'2014 (52nd Annual Meeting of the Association for Computational\r\nLinguistics), 26-27 juin 2014, p.107-111, Baltimore, USA.\r\n\r\nLaure Martin, Delphine Battistelli, Thierry Charnois (2014). Mise en\r\nplace d\'une méthode de reconnaissance des symptômes dans le contexte des\r\nmaladies rares, in Actes Atelier Ingénierie des Connaissances et Santé,\r\nIC 2014 (25es Journées francophones d\'Ingénierie des Connaissances), 13\r\nmai 2014, 8 pages, Clermont-Ferrand.\r\n\r\nJean-Philippe Métivier, Laurie Serrano, Thierry Charnois, Bertrand\r\nCuissart and Antoine Widlöcher (2015). Automatic symptom extraction from\r\ntexts to enhance knowledge discovery on rare diseases, in proceedings of\r\nthe Conference on Artificial Intelligence in Medicine (AIME 2015),\r\nLecture Notes in Computer Science 9105, Springer 2015, pp.  249-254,\r\nPavia, Italy, June 17-20, 2015.\r\n\r\nEncadrement : Delphine Battistelli (Laboratoire MoDyCo, Université Paris\r\n10) et Thierry Charnois (Laboratoire LIPN, Université Paris 13)\r\n\r\nRémunération : selon la réglementation en vigueur, soit environ 540\r\neuros mensuel, plus prise en charge partielle des frais de transport\r\n(50% de l\'abonnement navigo entre la résidence et le lieu du\r\nstage). Durant le stage, des réunions de travail pourront avoir lieu sur\r\nle site des partenaires du projet. Ces déplacements seront entièrement\r\npris en charge financièrement.\r\n\r\nDurée : 4-5 mois\r\n\r\nProfil recherché :\r\n- Niveau : Master 2 ou ingénieur dernière année\r\n- Domaine de spécialité requis: TAL ou Informatique avec connaissances\r\n  en  apprentissage ou TAL\r\n\r\nCandidature : envoi d\'un CV à delphine.battistelli@u-paris10.fr et\r\nThierry.charnois@lipn.univ-paris13.fr accompagné d\'une lettre de\r\nmotivation ainsi que des notes de l\'année universitaire en cours et de\r\nl\'année dernière.'),
(340, '2016-03-07', 'CS', 'Le Plessis Robinson', 'Dans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les contrôleurs à travers d\'échanges vocaux. Dans ce\r\ncontexte, CS conçoit et réalise une gamme de produits : systèmes de\r\ncommunication vocale (VCS), enregistreurs et simulateurs. Pour d\'autres\r\napplications comme la recherche d\'informations de parole dans des\r\nenregistrements, les services de communication multilingue pour les\r\ncompagnies aériennes ou la traduction multilingue de grosses\r\ndocumentations techniques (Rafale pour l\'Inde/l\'Égypte..., par exemple),\r\nil est nécessaire de traiter non seulement la voix (signal audio) mais\r\naussi la parole, c\'est à dire le contenu sémantique du signal audio, ou\r\nle texte écrit.\r\n\r\nDans ce but, nous souhaitons étudier la faisabilité d\'un enconvertisseur\r\ndu français, c\'est-à-dire un analyseur produisant des graphes UNL\r\n(Universal Networking Language) à partir de textes en français. Cet\r\nenconvertisseur nous permettra par la suite d\'évaluer la pertinence des\r\ngraphes UNL à la fois comme représentation source pour générer du texte\r\ndans plusieurs langues (déconversion) ou pour faire des inférences\r\n(ontologies) et aussi comme interlingua pour de la traduction\r\nautomatique (enconversion + déconversion).\r\n\r\nPour transformer des phrases en graphes UNL, nous suivons la méthode du\r\nGETA : utiliser un transducteur générique  qui produit les graphes UNL à\r\npartir des représentations profondes (« structures  multiniveaux de\r\nVauquois », ou plus simplement « arbres de Vauquois ») obtenues par des\r\nanalyseurs existants. Plusieurs tels analyseurs produisant des\r\nstructures de Vauquois ont été développés sous Ariane  et sont\r\ndisponibles en sources ouvertes.\r\n\r\nTravail à réaliser :\r\n\r\nNota : Le sujet est composé de deux parties principales indépendantes\r\nqui pourront être traitées par deux stagiaires différents, selon la\r\ndurée du(des) stage(s) et le profil du(des) stagiaire(s).\r\n\r\n1) Transducteur générique « arbre de Vauquois -> graphe UNL »\r\n\r\nAprès une phase de prise de connaissance des principes d\'UNL et des\r\nstructures multiniveaux de Vauquois, le stagiaire étudiera l\'algorithme\r\nsimplifié du transducteur actuellement utilisé pour transformer les\r\nstructures multilniveaux en graphes UNL dans l\'enconvertisseur du\r\nfrançais. Il  l\'étendra ensuite :\r\n\r\n- en intégrant un traitement actuellement réalisé sous Ariane\r\n  (transfert),\r\n- en prenant en compte les scopes, qui sont des entités sémantiques\r\n  autonomes actuellement non prises en compte .\r\n\r\nle stagiaire clarifiera les éventuelles contraintes que doivent\r\nrespecter les structures multiniveaux présentées en entrée du\r\ntransducteur arbre-graphe puis il programmera l\'algorithme spécifié.\r\n\r\n2) Génération automatique d\'un analyseur du français à partir d\'un\r\ndictionnaire français-UNL\r\n\r\nD\'importantes ressources bilingues NL-UNL, avec NL = anglais (83507\r\nentrées), russe (63287 entrées), français (51352 entrées),  hindi (50391\r\nentrées),  malais (31406 entrées),  espagnol (21874 entrées), vietnamien\r\n(10150 entrées) sont maintenues par Vyacheslav Dikonov, au laboratoire\r\nLCL de l\'institut IPPI de l\'Académie des Sciences de Moscou . Dans le\r\nbut de tirer le meilleur parti de ces dictionnaires, le stagiaire\r\nétudiera un programme générant automatiquement les fichiers source d\'un\r\nanalyseur morphologique Ariane du français cohérent avec ces données en\r\ncroisant les dictionnaires français-UNL de l\'IPPI avec (1) des\r\nressources lexicales libres telles que Lexique 3.81\r\n(http://www.lexique.org/) et (2) les mots présents dans des corpus\r\ntechniques de CS. Pour cela, il pourra s\'appuyer sur des programmes déjà\r\nexistants, générant des analyseurs morphologiques Ariane à partir de\r\nbases de données lexicales.\r\n\r\n3) Expérimentations (selon le temps disponible)\r\n\r\nLe stagiaire testera ensuite la chaîne d\'analyse intégrant (1) l\'analyse\r\nmorphologique qu\'il aura produite, (2) l\'analyse structurale qui produit\r\nles structures de Vauquois (phase existante) et (3) la transformation\r\narbre-graphe qui produira les graphes UNL des phrases soumises à\r\nl\'analyseur.\r\n\r\n Résultats attendus :\r\n- Rapport d\'étude sur l\'algorithme du transducteur arbre-graphe.\r\n- Programme implémentant l\'algorithme du transducteur arbre-graphe.\r\n- Base lexicale extraite des corpus techniques de CS.\r\n- Programme de génération de l\'analyseur morphologique.\r\n- Rapport d\'évaluation de la chaîne français-UNL (selon le temps\r\n  disponible).\r\n\r\nDurée du stage: 4 à 6 mois\r\n\r\nDe formation Master 2 ou élève ingénieur en 2e ou 3e année, vous\r\nrecherchez un stage en développement avec les langages suivants:\r\n- C/C++.\r\n- Java.\r\n- Sqlite3.\r\nLa maîtrise de l\'anglais est indispensable pour ce stage.\r\n\r\nPour postuler: CV + LM à envoyer à l\'adresse recrutement@c-s.fr à\r\nl\'attention de Gariné Kelijian'),
(341, '2016-03-07', 'XRCE', 'Grenoble', 'Internship on \"CV Mining for Selection in Hiring Processes\" at XRCE\r\n-------------------------------------------------------------------\r\nUNIT: XRCE/ADL/TPI\r\n\r\nPROPOSERS: Caroline Privault, Fabien Guillot\r\n\r\nDURATION: 6 months - Dates confirmed after interview based on \r\navailability of the candidate\r\n\r\nSTART DATE: April 2016- Date confirmed after interview based on \r\navailability of the candidate\r\n\r\nREFERENCE : \r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/CV-Mining-for-Selection-in-Hiring-Processes\r\n\r\nThe Text processing & Interaction group in ADL brings together\r\ncompetencies in text mining, user interaction & design, and advanced\r\nengineering, in order to prototype and transfer technologies to Xerox\r\nbusiness groups and customers. The main focus for this internship is on\r\nthe development of specific language resources and tools for application\r\nto CV mining in the Human Resources domain: the goal is to contribute to\r\nthe development of a system for supporting recruiters in the review of\r\napplicants\' CVs received for a published job vacancy. The candidate will\r\nhave the possibility to work on some of the following tasks in\r\ncollaboration with other team members:\r\n\r\n** Generating Linguistic Resources\r\n\r\n- generate linguistic resources for semantic relatedness such as\r\n  semantic taxonomy\r\n- exploit public corpora and free databases, to build linguistic\r\n  resources\r\n\r\n*** Mining Candidate Personality Traits\r\n- investigate the state of the art in related fields such as\r\n  psycho-linguistics or social linguistics to understand possible\r\n  relationships between specific personal expressions (syntax, word\r\n  usage, etc) and personality traits of the candidates\r\n- develop tools for parsing resume text contents to detect specific\r\n  personal expressions such as usage of pronouns, passive/active form,\r\n  etc\r\n\r\nThe candidate will contribute to the design of annotation schemes and\r\ncorpora annotation as part of the above tasks. You will be part of a\r\nteam of developers and researchers, on a project managed with an agile\r\nmethodology.\r\n\r\nREQUIREMENTS:\r\n- Master Student or PhD\r\n- Knowledge/practice of an Annotation Tool e.g. Brat or other\r\n- Experience in developing linguistic resources\r\n- Experience in using scripting languages (e.g. Python, Perl). Practice\r\n  of JAVA is a plus\r\n- Knowledge of some Natural Language Processing tools, (e.g. Named\r\n  Entity Recognizers, Syntactic Parsers, POS Taggers, CRF, etc.)\r\n- Verbal and written communication skills in English\r\n- Knowledge of XML, or other structured format is a plus\r\n- Knowledge in Machine Learning (e.g. Deep learning), Ontology/Semantic\r\n  web are a plus\r\n\r\nTo submit an application:\r\nPlease send your CV and cover letter to xrce-candidates@xrce.xerox.com. \r\nPlease specify \"CV Mining for Selection in Hiring Processes\" in your \r\nsubject line.\r\n\r\nFull proposal at:\r\nhttp://www.xrce.xerox.com/About-XRCE/Internships/CV-Mining-for-Selection-in-Hiring-Processes\r\n\r\n~~~~~~~~~~\r\nAbout XRCE:\r\n\r\nXerox Research Centre Europe (XRCE) is a young, dynamic research\r\norganization, which creates innovative technologies to support growth in\r\nXerox business process outsourcing and document management services\r\nbusinesses.\r\n\r\nOur domains of research stretch from the social sciences to computer\r\nscience. We have renowned expertise in machine learning, natural\r\nlanguage processing, computer vision, ethnography and services\r\ncomputing.\r\n\r\nXRCE is part of the Xerox Innovation group made up of 650 researchers\r\nand engineers in four world-renowned research and technology centres.\r\nOur goal is to make Xerox a great place to work. Through a comprehensive\r\nset of employee-focused initiatives, we promote diversity by nurturing a\r\nculture of inclusion and opportunity, and through measurable actions.'),
(342, '2016-03-09', 'INALCO', 'Paris', 'CADRE DU STAGE\r\n\r\nDans le cadre d\'une collaboration entre les équipes ERTIM et CERMOM de\r\nl\'Inalco autour du projet ALIENTO, nous proposons une offre de stage à\r\nl\'intersection entre la linguistique et l\'informatique.\r\n\r\nSUJET DU STAGE\r\n\r\nLe projet ANR ALIENTO vise à apparier par calcul des énoncés sapientiels\r\nbrefs (proverbes, sentences, maximes, aphorismes...) médiévaux\r\nmultilingues (arabe, hébreu, latin et espagnol) à partir des annotations\r\nstandardisées trilingues (français, anglais et espagnol) portant sur\r\nleur sens (sens propre, sens figuré, leçon ou morale, mots-clés\r\nconceptuels) et sur leur forme (lemmatisation, structure type ou\r\npattern, structure linguistique, structure formelle, type de discours,\r\nfigures de style).\r\n\r\nLe stage portera sur deux aspects de l\'exploitation du corpus, présentés\r\nci-dessous.\r\n\r\n1/ Fouille de motifs sapientiels\r\n\r\nLes corpus collectés et annotés à divers niveaux linguistiques et\r\nsémantiques permettent d\'envisager l\'utilisation de techniques de\r\nfouille de texte afin d\'isoler des motifs lexicaux-grammaticaux\r\nreprésentatifs des énoncés sapientiels. Il s\'agit de conduire plusieurs\r\nanalyses :\r\n- des motifs peuvent-ils être extraits sur le corpus dans sa globalité,\r\n  en retenant à la fois des critères liés à leur fréquence et à leur\r\n  spécificité (il pourra être utile de confronter les motifs concernant\r\n  les énoncés sapientiels à la totalité des textes),\r\n- par comparaison entre les langues des énoncés : présentent-ils les\r\n  mêmes caractéristiques d\'une langue à une autre, peut-on les\r\n  rapprocher ou les contraster ?\r\n\r\n2/ Mécanismes pour la translittération arabe\r\n\r\nLa plateforme disponible pour mener le projet ALIENTO permet la saisie\r\net la consultation de documents dans leur forme d\'origine. Cependant,\r\nles utilisateurs qui y accèdent peuvent avoir besoin de comparer les\r\nrythmes (phonétiques) des énoncés sans nécessairement savoir lire\r\nl\'écriture arabe.\r\n\r\nDans ce contexte, la base de données permet la saisie des\r\ntranslittérations des textes vers un alphabet latin (système de\r\nromanisation simplifié pour Aliento ou norme Arabica). Ce travail, long\r\net fastidieux lorsqu\'il est réalisé manuellement, peut être grandement\r\nfacilité par l\'utilisation d\'un logiciel de translittération automatique\r\nà la plateforme.\r\n\r\nIl s\'agira donc d\'établir une liste d\'outils capables de réaliser une\r\ntranslittération automatique, de les évaluer, et de déterminer dans\r\nquelle mesure ils peuvent être intégrés à l\'architecture logicielle du\r\nprojet. Il sera vraisemblablement nécessaire de réaliser des\r\ndéveloppements spécifiques et des adaptations selon les attentes et les\r\ntypes de textes (médiévaux) fournis en entrée.\r\n\r\nCOMPÉTENCES REQUISES\r\n\r\n- Connaissance des outils TAL\r\n- Connaissance de l\'arabe\r\n- Maîtrise des environnements : Linux et Windows\r\n- Familiarité avec des langages de programmation : Perl / Python / Java\r\n\r\nMODALITÉS\r\n\r\nDémarrage du stage : avril 2016\r\nEmployeur : Institut National des Langues et Civilisations Orientales\r\n(INALCO)\r\nContrat : Stage M1 ou M2 de 4 mois\r\nLieu de Travail : Maison de la recherche de l\'INALCO, 2 rue de Lille,\r\n75007 Paris\r\nRémunération : 554¤ + prise en charge partielle des transport IdF\r\n\r\nCONTACT\r\n\r\nMerci d\'envoyer votre CV et vos motivations à damien.nouvel@inalco.fr et\r\nvarol@noos.fr'),
(343, '2016-03-09', 'Akio', 'Paris', 'Titre: Interprétation sémantique de la relation client\r\n\r\nDescriptif: \r\nLe sujet proposé traite de l\'interprétation sémantique des informations\r\néchangées entre une entreprise et ses clients. Le mode opératoire est\r\nomnicanal dans le sens où quelque soit le moyen choisi par le client,\r\nl\'entreprise doit pouvoir faire le lien entre le contact présent et\r\nl\'historique des interactions passées, même si elles sont de nature\r\ndifférente, que ce soit la voix, un tchat, le courriel ou les réseaux\r\nsociaux.  La chaîne de traitement actuelle comporte plusieurs étapes\r\nallant de l\'analyse morphosyntaxique, le redressage orthographique, le\r\nchunking statistique, l\'analyse syntaxique suivies de l\'interprétation\r\nsémantique. Le stage portera essentiellement sur la partie sémantique\r\ndes composants logiciels de calcul des thématiques, des opinions et des\r\nmodalités d\'expression.\r\n\r\nDescription du poste:\r\nL\'objectif du stage est d\'apporter un regard extérieur sur la chaîne de\r\ntraitement actuelle afin de l\'améliorer à la fois en français et en\r\nanglais, via une qualification quantitative. Nous sommes ouverts à de\r\nnouvelles idées qui peuvent contribuer à notre succès au sein d\'une\r\néquipe dynamique.\r\n\r\nProfil recherché:\r\n- Niveau Master 2 ou ingénieur dernière année.\r\n- Spécialité requise: traitement automatique de la langue.\r\n- Bonne expérience des mails et des réseaux sociaux.\r\n- Langage de programmation Java. \r\n- Bonne connaissance du français et de l\'anglais.\r\n- Créativité, esprit d\'équipe.\r\n\r\nDurée: \r\n3 mois, de manière préférentielle en juin, juillet et août.\r\nDes adaptations (avant/après/plus long) sont possibles.\r\n\r\nLieu:\r\nBureaux Parisiens d\'Akio.\r\n43 rue de Dunkerque, 75010 Paris.\r\nwww.akio.com\r\n\r\nGratification:\r\nIndemnité légale de stage en vigueur.\r\n\r\nEncadrement:\r\nLe stage sera encadré par Gil Francopoulo.\r\n\r\nCandidature:\r\nMerci d\'envoyer un CV à gil.francopoulo arobase akio.com \r\naccompagné des notes de l\'année universitaire en cours \r\net de l\'année dernière.'),
(344, '2016-03-15', 'LIPN', 'Villetaneuse', 'Offre de stage : Réingénierie du site web de l\'association pour le\r\nTraitement Automatique des Langues\r\n\r\nCONTEXTE\r\n\r\nL\'Association pour le Traitement Automatique des Langues (ATALA) est une\r\nassociation savante fondée en 1959 et qui fédère la communauté\r\nscientifique du Traitement Automatique des Langues (TAL). À ce titre,\r\nelle dispose d\'un site web pour faire la promotion de ses\r\nactivités. Parmi celles-ci figurent : la conférence TALN, la revue TAL,\r\nles journées d\'étude, les inscriptions, la gestion de liste de\r\ndiffusion, le recensement d\'outils, de formations et d\'équipes de\r\nrecherche, etc.\r\n\r\nLe site actuel, réalisé il y a plusieurs années avec le système de\r\ngestion de contenus SPIP, n\'est plus adapté aux besoins actuels de\r\nl\'ATALA. Il a donc été décidé de migrer vers un nouveau CMS afin de\r\nsatisfaire aux besoins de l\'association et de faciliter le plus possible\r\nles opérations courantes. Parmi les fonctionnalités à améliorer ou\r\nmettre en place figurent : la gestion des activités scientifiques\r\n(articles, annonces de séminaires, etc.) la gestion fine des\r\nutilisateurs (visiteurs, membres, responsable d\'activités de l\'ATALA,\r\nwebmestres), l\'intégration d\'une interface de paiement en ligne pour les\r\ninscriptions. Pour cela, la migration vers le nouveau CMS devra\r\nrécupérer aussi automatiquement que possible les données présentes dans\r\nle CMS actuel (par requêtes SQL), puis en les insérant dans le nouveau\r\nCMS (par API). Le renouvellement de la charte graphique n\'est pas un\r\nbesoin prioritaire, mais une adaptation du rendu graphique à la nouvelle\r\nplate-forme technologique sera bienvenue.\r\n\r\nOBJECTIFS\r\n\r\nLe premier objectif du stage est de mieux recenser et qualifier les\r\nbesoins en gestion collaborative du site afin d\'évaluer quels systèmes\r\nde gestion de contenu (CMS) répondent le mieux à ces exigences. Une\r\nétude des données à migrer de l\'ancienne base de données SPIP devra être\r\nmenée, pour estimer quelles données peuvent facilement être importées\r\nvers le nouveau CMS. Un premier prototype sera présenté au CA de\r\nl\'association pour valider les fonctionnalités, le rendu visuel sur des\r\ndifférents supports (écran d\'ordinateur et mobile). Il s\'agira ensuite\r\nde conduire la migration à proprement parler et les tests nécessaires\r\nafin de s\'assurer que le nouveau CMS soit opérationnel. Enfin, de\r\nnouvelles fonctionnalités seront progressivement ajoutées au site\r\n(connexions aux réseaux sociaux, espaces dédiés aux évènements liés à\r\nl\'association, gestion fine des droits utilisateurs, etc.). Un accent\r\nsera mis sur la fluidité de l\'interface et l\'évolutivité des\r\nfonctionnalités proposées par le site.\r\n\r\nRéférence : actuel site web de l\'ATALA: http://www.atala.org/\r\n\r\nCOMPÉTENCES\r\n\r\nCompétences requises :\r\n- Expérience en développement de sites web\r\n- Bootstrap, React, node.js\r\n- Linux, Mysql, Apache, PHP.\r\n\r\nCompétences souhaitées :\r\n- Expérience avec des plate-formes de gestion de contenu (CMS)\r\n- Connaissances de SPIP\r\n\r\nMODALITÉS\r\n\r\nLieu du stage: LIPN, 99 avenue Jean-Baptiste Clément, Villetaneuse\r\nDurée : 6 mois (avril - septembre 2016)\r\nRémunération : 546¤ par mois\r\nContexte administratif : Le stage sera directement encadré par Jorge\r\nGarcia Flores (LIPN) et suivi par Damien Nouvel (INaLCO) et Cyril Grouin\r\n(LIMSI), responsables web du conseil d\'administration de l\'ATALA.\r\n\r\nCONTACT\r\n\r\nMerci d\'envoyer CV et motivations à : jgflores@lipn.univ-paris13.fr'),
(345, '2016-03-21', 'Telecom Bretagne', 'Brest', '--------------\r\nOffre de stage TAL M2 : Pluralisme des médias : analyse comparée de\r\ntextes de la presse écrite et de dépêches AFP\r\n--------------\r\nStage de 4 mois, financé par le Labex ICCA,  projet structurant\r\n«Plateformes» 2016\r\n--------------\r\n\r\nLe projet 2PI (Modèles économiques de la presse en ligne & pluralisme de\r\nl\'information) se propose de comparer, à différents niveaux\r\nlinguistiques, des textes provenant de l\'agence de presse AFP et\r\nd\'autres titres de presse.\r\n\r\nLes étapes d\'analyse des textes seront :\r\n- extraction terminologique\r\n- analyse morphosyntaxique\r\n- annotation sémantique\r\n- extraction d\'entités nommées\r\n\r\nSelon les outils à disposition, ces étapes seront automatiques ou\r\nsemi-automatiques.\r\n\r\nEn représentant toutes les propriétés linguistiques extraites des textes\r\ndu corpus sous forme de graphes, il s\'agira de mesurer l\'apport des\r\ntextes de l\'AFP vis-à-vis de celui des textes des autres médias et de\r\ntenter de caractériser/quantifier ainsi la notion de «pluralisme des\r\nmédias».\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent :\r\n- Analyses et annotations automatiques ou semi-automatiques des textes.\r\n- Modélisation des résultats sous forme de graphes et application de\r\n  différentes mesures de similarité entre les sous-graphes induits par\r\n  les données AFP et leurs compléments.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Master 2 en Linguistique Informatique ou similaire (en cours, ou plus\r\n  ancien).\r\n- Programmation en Python (principalement NLTK).\r\n- Curiosité et capacité d\'explorer des nouveaux domaines en linguistique\r\n  et/ou informatique.\r\n- Des connaissances en théorie des graphes seraient un plus\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 4 mois rémunéré.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nyannis.haralambous@telecom-bretagne.eu\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : Département Informatique, Télécom Bretagne, Brest.\r\n\r\nEncadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285\r\n             Lab-STICC)\r\n             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)\r\n\r\nContrat : stage. \r\n\r\nDébut : avril 2016.'),
(346, '2016-04-11', 'INALCO', 'Paris', 'Offre de stage : stage TAL arabizi tunisien, 4 à 6 mois \r\n\r\nObjet : normalisation de l\'écriture de l\'arabe tunisien sur les réseaux\r\nsociaux\r\n\r\nEmployeur : Institut National des Langues et Civilisations Orientales\r\n(INALCO)\r\n\r\nContrat : stage M1 ou M2 de 4 à 6 mois\r\n\r\nLieu de Travail : Maison de la recherche de l\'INALCO, 2 rue de Lille\r\n75007 Paris\r\n\r\nRémunération : 554 ¤ / mois + prise en charge partielle des transports\r\nIdF\r\n\r\nDate de début : dès que possible\r\n\r\nCONTEXTE \r\n\r\nLe projet a pour cadre général le traitement automatique de l\'arabe\r\ntunisien, langue peu dotée et non codifiée dont l\'écriture sur les\r\nréseaux sociaux est diverse (arabizi, alphabet arabe, emprunts,\r\netc.). Le tunisien est peu étudié malgré une quantité grandissante de\r\ndonnées disponibles notamment grâce à l\'essor des réseaux sociaux.\r\n\r\nOBJECTIF \r\n\r\nLe stage vise à effectuer :\r\n- un état de l\'art approfondi sur la standardisation de l\'arabizi, \r\n- la normalisation d\'un corpus issu des réseaux sociaux en arabe\r\n  tunisien (arabizi) : définition d\'une norme orthographique de\r\n  l\'arabizi, identification des formes les mieux attestées, correction\r\n  du corpus en fonction de la norme établie,\r\n- l\'implémentation d\'un algorithme de correction orthographique. \r\n\r\nPROFIL ATTENDU \r\n\r\n- M1 ou M2 en Traitement Automatique des Langues, linguistique ou\r\n  informatique, - maîtrise de l\'arabe tunisien (arabizi), \r\n- connaissances en sciences du langage (morphologie, lexicologie), -\r\n  connaissances des problématiques du TAL,\r\n- maîtrise d\'un langage de programmation (de préférence Python). \r\n\r\nPour des raisons pratiques, le/la candidat-e doit déjà être en France ou\r\ndoit avoir le droit de travailler en France.\r\n\r\nLa convention de stage est obligatoire.\r\n\r\nCANDIDATURE \r\n\r\nPour candidater, merci d\'envoyer un CV et une lettre de motivation à\r\nasma.zamiti@inalco.fr et mathieu.valette@inalco.fr'),
(347, '2016-05-26', 'Lexis Nexis', 'Paris', 'STAGE LINGUISTE\r\n\r\nLexisNexis France (650 collaborateurs, 150 M¤ de CA), filiale du groupe\r\nReed Elsevier (30000 collaborateurs, 6,7 milliards de CA et leader de\r\nl\'information professionnelle) est un acteur majeur dans les services\r\nd\'informations professionnelles. Ses activités couvrent cinq domaines :\r\nl\'information et l\'édition juridiques, la diffusion de la presse et de\r\nl\'information économique et financière sur internet, les formations et\r\nconférences, les logiciels professionnels et les solutions de gestion du\r\nrisque, de veille et d\'analyse stratégique de l\'information.\r\n\r\nL\'entreprise s\'appuie sur une expertise professionnelle centenaire, un\r\nfonds documentaire inégalé et une technologie de pointe pour apporter au\r\nmonde du droit et aux professionnels une vaste gamme de produits et\r\nservices réputés : JurisClasseur, Litec, Bottin Administratif, D.O et\r\nles services en ligne LexisNexis.\r\n\r\nMISSION :\r\nIntégré(e) à l\'équipe « Management de l\'information»  votre mission\r\nconsistera à participer aux activités relatives au textmining, qui\r\ntraitent de l\'extraction d\'information juridique à valeur ajoutée.\r\n\r\nPROFIL :\r\n\r\nMaster en linguistique informatique, avec une forte composante TAL\r\n\r\nCompétences requises : \r\n\r\n- Traitement automatique des langues (étude et constitution de corpus,\r\n  moteur de recherche, grammaires locales ...)\r\n- Des connaissances en programmation serait un plus (perl, python)\r\n- Aptitude pour le travail en équipe\r\n- Vous arrivez à comprendre et décortiquer rapidement des informations\r\n  sur un domaine inconnu.\r\n- Vous êtes d\'une nature rigoureuse et méticuleuse. Une sensibilité pour\r\n  l\'étude du langage juridique serait un plus.\r\n \r\nLIEU : \r\n141 rue de Javel\r\n75015 PARIS\r\n\r\nDUREE : \r\n4 mois\r\n\r\nMODALITES:\r\nIndemnité mensuelle de 436,05 euros \r\n50% du titre de transport\r\nTicket restaurant\r\nConvention de stage obligatoire\r\n\r\nCONTACT :\r\nMerci d\'envoyer votre candidature (CV + lette de motivation) ainsi que\r\nvos disponibilités par mail à Pascaline BOISSAY :\r\npascaline.boissay@lexisnexis.fr'),
(348, '2016-10-03', 'Viseo R&D', 'Grenoble', 'Stage Master 2 (ou équivalent) de Recherche 2016-2017\r\n\r\nViseo R&D, à Grenoble (France)\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation\r\n\r\nSUJET\r\nNormalisation de messages issus de la communication électronique médiée\r\n\r\nCONTEXTE\r\nAu départ contraint par le nombre de caractères maximum utilisables pour\r\nla rédaction d\'un SMS et par la difficulté de maniement des claviers,\r\nl\'écriture SMS apparaît et se développe rapidement sur les supports de\r\ncommunication du Web (réseaux sociaux, fora, blogs, etc.). Par exemple,\r\nl\'écriture SMS se caractérise par la présence de formes scripturales\r\ntrès riches : squelettes consonantiques (\"slt\" (salut)), apocopes\r\n(\"ordi\" (ordinateur)), substitutions phonétisées (\"2m1\" (demain)),\r\nbinettes/emoji (\"^^\", \":)\", :)) - la liste est longue.\r\nCe non-respect des règles de la langue implique une réelle difficulté\r\nlorsqu\'il s\'agit d\'analyser ces textes avec des outils de traitement\r\nautomatique de la langue qui sont généralement conçus pour traiter du\r\ntexte correctement écrit, ce qui implique un impact négatif sur la\r\nqualité des résultats à l\'issue du traitement. Pour pallier à cette\r\ndifficulté, on peut envisager soit d\'adapter les outils d\'analyse, soit\r\nde normaliser le texte qui sera passé en entrée des outils\r\nd\'analyse. Nous choisissons cette deuxième approche dans le cadre de ce\r\nstage.\r\n\r\nOBJECTIF DU STAGE\r\nL\'objectif de ce stage est de développer un outil performant de\r\nnormalisation automatique de texte pour le français. Par exemple, «a2min\r\nlami» devra être normalisé en «à demain l\'ami».\r\n\r\nPour atteindre ce but, il sera demandé à l\'étudiant de :\r\n\r\n1) dresser une typologie des erreurs détectées dans les ressources\r\n   fournies, pour le français (Tweets, Messages de forums, SMS), en\r\n   s\'appuyant sur les typologies déjà existantes.\r\n2) proposer des méthodes automatiques de normalisation en fonction des\r\n   types d\'erreurs définis à la première étape, avec un intérêt\r\n   particulier porté sur les types d\'erreur les plus fréquents. On\r\n   s\'inspirera des méthodes déjà existantes (par exemple, fondées sur\r\n   les principes de la traduction automatique, de la reconnaissance de\r\n   la parole, de la correction orthographique, ...).\r\n3) évaluer les méthodes proposées en fonction des différents types de\r\n   textes (Tweets, Messages de forums, SMS).\r\n\r\nPROFIL\r\nCe sujet est destiné aux étudiants de Master 2 (ou équivalent) ayant une\r\ndouble compétence en Informatique et en Linguistique.\r\n\r\nINFORMATIONS COMPLEMENTAIRES\r\nUnité d\'accueil : Viseo R&D\r\n  http://www.viseo.com/fr/offre/recherche-et-innovation\r\nLieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble\r\nEncadrant principal : Cédric Lopez\r\n  http://www.viseo.com/fr/recherche/cedric-lopez\r\nDurée du stage : 6 mois\r\nStage rémunéré\r\n\r\nMerci d\'envoyer votre candidature à\r\ncedric.lopez@viseo.com constituée du CV,\r\nde la lettre de motivation, des relevés de notes des 2 dernières années\r\n(M1 et M2)\r\n\r\nA PROPOS DE VISEO\r\nViseo est une entreprise française de services du numérique qui compte\r\n1200 employés en France, Allemagne, Etats Unis, Singapour, Hong Kong et\r\nMaroc. Son centre R&D est situé à Grenoble, à deux minutes à pied de la\r\ngare. De nombreux projets de recherche collaboratifs y sont menés, avec\r\nun intérêt particulier pour l\'analyse de données textuelles : projet\r\nSMILK (LabCom ANR)\r\nhttp://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER\r\n(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)\r\nhttp://www.synodos.fr, SOMA (EUROSTARS)\r\nhttp://www.viseo.com/fr/recherche/le-projet-soma, ...\r\nPour en savoir plus :\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation'),
(349, '2016-10-24', 'TETIS', 'Montpellier', 'Stage de Master Recherche 2016-2017 :\r\nDétermination des itinéraires migratoires contextualisés à partir de récits de vies\r\n\r\nResponsables de stage locaux (TETIS) : Mathieu Roche, Maguelonne Teisseire\r\nAutre encadrant (MIGRINTER) : Nelly Robin\r\n\r\nLocalisation :\r\nUMR TETIS (AgroParisTech, Cirad, Cnrs, Irstea)\r\n500, rue J.F. Breton, 34093 Montpellier Cedex 5, France\r\n\r\nContact :\r\nmathieu.roche@cirad.fr\r\nmaguelonne.teisseire@irstea.fr\r\nnelly.robinsn@orange.fr\r\n\r\n\r\nContexte du projet QDoSSI\r\n\r\nLes migrations internationales ont pris dans le monde contemporain une\r\nampleur inédite. Cela pose de nouveaux défis à la communauté\r\nscientifique en terme d\'analyse et de compréhension des phénomènes\r\nmigratoires. Le premier est celui des données et de leurs qualités. En\r\neffet, nombreuses sont les bases de données statistiques sur les\r\nmigrations internationales.  Pour aller plus loin dans l\'analyse de ce\r\nphénomène complexe et multidimentionnel, la mise en synergie d\'autres\r\ntypes de données est nécessaire. Le projet QDoSSI 1 propose d\'étudier\r\nles parcours migratoires d\'un point de vue du migrant, considéré comme\r\nun acteur clé dont les droits doivent être respecter et la protection\r\nassurée en toutes circonstances Notre champ d\'analyse porte sur\r\ndifférents types de données collectées par le laboratoire MIGRINTER :\r\n(1) affaires judiciaires (100 000 enregistrements par an sur 10 ans),\r\n(2) corpus juridique des pays d\'Afrique de l\'Ouest et des Balkans,\r\ncarrefours important des circulations migratoires vers l\'Europe, (3)\r\nrécits de vie (plus de 300), notamment des mineurs en mobilité et des\r\nmigrants de Calais, (5) recensement effectué récemment auprès des\r\npersonnes déplacées en Syrie (200 000/ 250 000 individus).\r\n\r\n\r\nContexte du stage et état de l\'art\r\n\r\nDans le cadre du stage, le travail se concentrera sur l\'identification\r\nautomatique d\'\"itinéraires contexualisés\" à partir des corpus de\r\nrécits de vie par des méthodes de fouille de textes.  De nombreuses\r\nméthodes permettent de reconnaitre les Entités Nommées (EN) en général\r\net les Entités Spatiales (ES) en particulier (Nadeau & Sekine,\r\n2007). On trouve des approches statistiques consistant généralement à\r\nétudier les termes co-occurrents par analyse de leur distribution dans\r\nun corpus (Agirre et al., 2000) ou par des mesures calculant la\r\nprobabi- lité d\'occurrence d\'un ensemble de termes (Velardi et al.,\r\n2001). On trouve également des méthodes de fouille de données fondées\r\nsur l\'extraction de motifs. Ces derniers permettent de déterminer des\r\nrègles de transduction utilisant des informa- tions syntaxiques\r\npropres aux phrases pour repérer les ENs (Nouvel et al., 2011). La\r\nplupart des méthodes d\'extraction et de désambiguisation d\'entités\r\nspatiales exploitent des méthodes mixtes (symboliques et statistiques)\r\n(Kergosien et al., 2014).  Plusieurs travaux se sont intéressés à\r\nl\'étude des trajectoires (Yuan & Raubal, 2012) mais peu se concentrent\r\nsur leur identification automatique à partir de données textuelles,\r\ntâche éminemment difficile. Un tel processus s\'appuie sur\r\nl\'identification de descripteurs linguistiques, en particulier les\r\nverbes (Talmy, 2000) et les indicateurs spatiaux (Zenasni et al.,\r\n2015) et également l\'utilisation de connaissances et ressources\r\nexternes (gazetteers, ontologies, etc.) (Lieberman & Sa- met,\r\n2012). Dans ce cadre, les travaux de (Moncla, 2015) utilisent ces\r\ndifférents éléments pour identifier les itinéraires à partir des\r\ntextes. L\'approche proposée consiste à identifier les informations qui\r\ndécrivent les itinéraires dans les textes (entités spatiales,\r\nexpressions de déplacement ou de perception) afin de les reconstruire\r\nautomatiquement en exploitant des informations géographiques\r\n(latitude/longitude, altitude) et les informations contenues dans les\r\ntextes (par exemple, l\'ordre d\'apparition des entités spatiales)\r\n(Moncla et al., 2016).\r\n\r\n\r\nTravail à réaliser\r\n\r\nLe travail de stage qui sera effectué dans le cadre des projets QDoSSI\r\net Songes 2 (Science des Données Hétérogènes) s\'articulera autour des\r\ntâches suivantes :\r\n\r\n1. Il s\'agira, dans un premier temps, de compléter l\'état de l\'art des\r\napproches les plus récentes ayant adopté une démarche similaire.\r\n\r\n2. Dans un deuxième temps, une évaluation des approches de l\'état de\r\nl\'art appliquées aux données des récits de vies sera conduite.\r\n\r\n3. Puis des informations thématiques liées à chaque parcours (par\r\nexemple, \"parcours dangereux\", intervention d\'une dimension familiale,\r\nfinancière, etc.) seront extraites à partir des textes et intégrés aux\r\nitinéraires.\r\n\r\n4. Enfin, une représentation et une visualisation cartographique des\r\n\"itinéraires contexualisés\" sera alors mise en oeuvre.\r\n\r\nRéférences\r\n\r\nAGIRRE E.,  ANSA O.,  HOVY E. H. &  MARTÍNEZ D. (2000). Enriching\r\nvery large ontologies using the www. In ECAI Workshop on Ontology\r\nLearning.\r\n\r\nKERGOSIEN E., LAVAL B., ROCHE M. & TEISSEIRE M. (2014). Are opinions\r\nexpressed in land-use planning documents ? International Journal of\r\nGeographical Information Science, 28(4), 739-762.\r\n\r\nLIEBERMAN M. D. &  AMET H. (2012). Adaptive context features for\r\ntoponym resolution in streaming news. In Proceedings of the 35th\r\nInternational ACM SIGIR Conference on Research and Development in\r\nInformation Retrieval, SIGIR \'12, p. 731-740, New York, NY, USA : ACM.\r\n\r\nMONCLA L. (2015). Automatic reconstruction of itineraries from\r\ndescriptive texts. (Reconstruction automatique d\'itinéraires à partir\r\nde textes descriptifs). PhD thesis, University of Pau and Pays de\r\nl\'Adour, France.\r\n\r\nMONCLA L., GAIO M., NOGUERAS -ISO J. & MUSTIÈRE\r\nS. (2016). Reconstruction of itineraries from annotated text with an\r\ninformed spanning tree algorithm. International Journal of\r\nGeographical Information Science, 30(6), 1137-1160.\r\n\r\nNADEAU D. & SEKINE S. (2007). A survey of named entity recognition\r\nand classification. Lingvisticae Investigationes, 30(1), 3-26.\r\n\r\nNOUVEL D., ANTOINE J.-Y., F RIBURGER N. & SOULET\r\nA. (2011). Recognizing named entities using automatically extracted\r\ntransduction rules. In (LTC\'2011).\r\n\r\nTALMY L. (2000). Toward a Cognitive Semantics. Number vol. 1 in\r\nBradford book. MIT Press.\r\n\r\nVELARDI P., FABRIANI P. & MISSIKOFF M. (2001). Using text\r\nprocessing techniques to automatically enrich a domain ontology. In\r\nFOIS, p. 270-284.\r\n\r\nYUAN Y. & RAUBAL M. (2012). Extracting Dynamic Urban Mobility Patterns\r\nfrom Mobile Phone Data, In N. XIAO , M.-P. KWAN , M. F. GOODCHILD &\r\nS. SHEKHAR , Eds., Geographic Information Science : 7th International\r\nConference, GIScience 2012, Columbus, OH, USA, September 18-21,\r\n2012. Proceedings, p. 354-367. Springer Berlin Heidelberg : Berlin,\r\nHeidelberg.\r\n\r\nZENASNI S., KERGOSIEN E., ROCHE M. & TEISSEIRE M. (2015). Discovering\r\ntypes of spatial relations with a text mining approach. In Foundations\r\nof Intelligent Systems - 22nd International Symposium, ISMIS 2015,\r\nLyon, France, October 21-23, 2015, Proceedings, p. 442-451.'),
(350, '2016-10-24', 'TETIS', 'Montpellier', 'Stage de Master Recherche 2016-2017 :\r\nTitrage automatique des thématiques identifiées dans les corpus\r\n\r\nResponsables de stage locaux (TETIS & LIRMM) : Mathieu Roche, Pascal\r\nPoncelet\r\n\r\nAutres encadrants (ERIC & Hubert Curien) : Julien Velcin, Christophe\r\nGravier\r\n\r\nLocalisation :\r\n\r\nUMR TETIS (AgroParisTech, Cirad, Cnrs, Irstea) 500, rue J.F. Breton,\r\n34093 Montpellier Cedex 5, France\r\n\r\nContact :\r\nmathieu.roche@cirad.fr\r\npascal.poncelet@lirmm.fr\r\njulien.velcin@univ-lyon2.fr\r\nchristophe.gravier@univ-st-etienne.fr\r\n\r\n\r\nContexte\r\n\r\nDe nombreux travaux de fouille de textes permettent (i) de faire\r\némerger les descripteurs linguistiques les plus significatifs (mots,\r\nsyntagmes) à partir d\'un corpus puis (ii) de les regrouper. Ceci\r\npermet de mettre en exergue, de manière automatique, les thématiques\r\nabordées dans les textes facilitant l\'organisation et l\'indexation des\r\ndocuments, la recherche d\'information, la compréhension et l\'analyse\r\ndes textes, ou même les résumer.  La réalisation du premier point\r\ns\'appuie, en grande partie, sur l\'utilisation de méthodes d\'extraction\r\nde la terminologie à partir de textes (Hasan & Ng, 2014). Les\r\napproches de la littérature combinent des méthodes linguistiques et\r\nstatistiques (Frantzi et al., 2000; Pazienza et al., 2005). De tels\r\ntravaux ont récemment été proposés dans le cadre d\'une collabora- tion\r\nde quatre laboratoires : ERIC (Lyon), Laboratoire Hubert Curien\r\n(Saint-Etienne), LIRMM (Montpellier) et TETIS (Montpellier) (Velcin et\r\nal., 2016).  La deuxième étape du processus consiste à regrouper les\r\ndescripteurs linguistiques permettant de mettre en relief les\r\ndifférentes thématiques abordées dans les textes. Pour découvrir des\r\nstructures thématiques \"cachées\" dans les corpus, les méthodes\r\nappelées \"topic models\" sont largement utilisées comme le modèle\r\nprobabiliste génératif LDA, i.e. Latent Dirichlet Allocation (Blei et\r\nal., 2003).  Une fois les thématiques identifiées, une des\r\nproblématiques aujourd\'hui réputée difficile consiste à leur attribuer\r\nun titre à partir de l\'ensemble des descripteurs linguistiques\r\nidentifiés. Une telle tâche a des similitudes avec les travaux sur le\r\ntitrage automatique de textes qui s\'appuie sur des méthodes\r\nd\'extraction de la terminologie et de génération de textes (Lopez et\r\nal., 2014).\r\n\r\n\r\nTravail à réaliser\r\n\r\nLe travail de stage qui sera effectué dans le cadre du projet Songes 1\r\n(Science des Données Hétérogènes) s\'articulera autour des tâches\r\nsuivantes :\r\n\r\n1. Compléter l\'état de l\'art des approches les plus récentes ayant adopté une démarche similaire.\r\n\r\n2. Proposer et mettre en oeuvre une approche qui se déclinera selon les 4 étapes suivantes :\r\n\r\n- Identifier les descripteurs linguistiques (mots, syntagmes) propres\r\n  à chaque topic obtenus avec différentes approches de l\'état de l\'art ;\r\n\r\n- Sélectionner les descripteurs les plus pertinents par filtrage\r\n  statistique et/ou sémantique ;\r\n\r\n- Identifier les phrases les plus pertinentes au regard des\r\n  descripteurs sélectionnés à l\'étape précédente (approche de\r\n  Recherche d\'Information) ;\r\n\r\n- Extraire les syntagmes les plus pertinents à partir des phrases\r\n  identifiées à l\'étape précédente.\r\n\r\n3. Expérimenter les propositions sur des données réelles issues de\r\ndivers domaines (actualités, agriculture, etc.). Dans ce contexte, un\r\nprotocole d\'évaluation devra être défini et mis en oeuvre.  Notons que\r\nla méthodologie proposée pourrait avoir des applications directes pour\r\nd\'autres tâches comme le titrage de clusters ou le titrage de nuages\r\nde mots.\r\n\r\nRéférences\r\n\r\nBLEI D. M., NG A. Y. & JORDAN M. I. (2003). Latent dirichlet\r\nallocation. Journal of Machine Learning Research, 3, 993-1022.\r\n\r\nFRANTZI K. T., ANANIADOU S. & MIMA H. (2000). Automatic recognition of\r\nmulti-word terms : the c-value/nc-value\r\nmethod. Int. J. on Digital Libraries, 3(2), 115-130.\r\n\r\nHASAN K. S. & NG V. (2014). Automatic keyphrase extraction : A survey\r\nof the state of the art. In Proceedings of the 52nd Annual Meeting of\r\nthe Association for Computational Linguistics (Volume 1 : Long\r\nPapers), p. 1262-1273, Baltimore, Maryland : Association for\r\nComputational Linguistics.\r\n\r\nLOPEZ C., PRINCE V. & ROCHE M. (2014). How can catchy titles be\r\ngenerated without loss of informativeness ?  Expert Syst. Appl.,\r\n41(4), 1051-1062.\r\n\r\nPAZIENZA M. T., PENNACCHIOTTI M. & ZANZOTTO F. M. (2005). Terminology\r\nExtraction : An Analysis of Linguistic and Statistical Approaches, In\r\nS. S IRMAKESSIS , Ed., Knowledge Mining : Proceedings of the NEMIS\r\n2004 Final Conference, p. 255-279. Springer Berlin Heidelberg :\r\nBerlin, Heidelberg.\r\n\r\nVELCIN J., ROCHE M. & PONCELET P. (2016). Shallow text clustering does\r\nnot mean weak topics : How topic identification can leverage bigram\r\nfeatures. In Proceedings of the Workshop on Interactions between Data\r\nMining and Natural Language Processing, DMNLP 2016, co-located with\r\nthe European Conference on Machine Learning and Principles and\r\nPractice of Knowledge Discovery in Databases, ECML-PKDD 2016, Riva del\r\nGarda, Italy, September 23, 2016., p. 25-32.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(351, '2016-10-24', 'Cirad', 'Montpellier', 'Stage de Master et d\'Ingénieur 2016-2017 :\r\n\r\nIntégration et visualisation de données issues du projet Patrimoine Numérique\r\nScientifique du Cirad\r\n\r\nSandrine Auzoux, Sophie Fortuno, Mathieu Roche\r\n\r\nCirad - Campus de Lavalette\r\n\r\nsandrine.auzoux@cirad.fr, sophie.fortuno@cirad.fr, mathieu.roche@cirad.fr\r\n\r\n\r\nContexte\r\n\r\nLe projet Patrimoine Numérique Scientifique (PNS) du Cirad 1 est un\r\nchantier d\'Établissement lancé en 2013, qui vise à gérer, conserver et\r\nvaloriser les données scientifiques ou données de la recherche\r\nproduites par l\'établissement et ses partenaires. Dans ce contexte, de\r\nnombreux groupes de travail ont permis de contribuer à\r\nl\'identification des données et d\'experts pouvant porter/constituer\r\ndes cas d\'étude thématiques très prometteurs (Roche et al., 2015).  De\r\nmanière concrète, les unités de recherche du Cirad 2 se sont fortement\r\nmobilisés pour constituer un inventaire précis de données importantes\r\ndu Cirad (cf. Figure 1). Les jeux de données inventoriés contiennent\r\nun certain nombre d\'informations (meta-données), par exemple, type de\r\ndonnées, pays d\'exécution, couverture temporelle, thématiques Cirad,\r\nauteurs, etc.\r\n\r\nFIGURE 1: Interface de l\'inventaire des données du Cirad.\r\n\r\n\r\nTravail à réaliser\r\n\r\nLe travail demandé dans le cadre de ce stage, détaillé en section 2,\r\nconsiste à (a) intégrer et normaliser les données structurées issues\r\nde l\'inventaire et de fournir des visualisations adaptées (Liu et al.,\r\n2014), (b) mettre en relation les données de l\'inventaire avec les\r\npublications scientifiques issues d\'Agritrop 3 via plusieurs entrées :\r\ninformations thématiques (mots-clés), auteurs, informations spatiales,\r\ninformations temporelles.\r\n\r\nDans le cadre de ce stage, quatre tâches principales devront être\r\nréalisées :\r\n\r\n- Analyse et pré-traitement des données issues de l\'inventaire\r\nCirad. Le prétraitement sera essentiellement dédié à la normalisation\r\nde certaines données et/ou meta-données (par exemple, les mots-clés).\r\n\r\n- Mise en relation des données de l\'inventaire avec les publications\r\n  d\'Agritrop (cf. Figure 2).\r\n\r\n- Visualisation des données via les bibliothèques javascript Ext JS 4\r\n  et D3.js (https ://d3js.org/ - cf. Figure 3).\r\n\r\n- Rédaction d\'un rapport incluant la description détaillée du\r\nprotocole reproductible (workflow) sur d\'autres en- sembles de données\r\net métadonnées.\r\n\r\nFIGURE 2: Exemple de publication issue d\'Agritrop (archive ouverte des\r\npublications scientifiques du Cirad).\r\n\r\nL\'application sera développée à partir des données de l\'inventaire, en\r\nparticulier les données de UPR AIDA (Agroécologie et intensification\r\ndurable des cultures annuelles) 5 qui a recensé 146 jeux de\r\ndonnées. La généralisation aux autres unités de recherche sera\r\négalement effectuée. Une réflexion pour intégrer ces propositions dans\r\nle cadre du projet étendard S TRADIV (System approach for the\r\nTRAnsition to bio-DIVersified agroecosystems) sera également menée.\r\n\r\nRéférences\r\n\r\nLIU S., CUI W., WU Y. & LIU M. (2014). A survey on information\r\nvisualization : recent advances and challenges. The Visual Computer,\r\n30(12), 1373-1393.\r\n\r\nROCHE M., FORTUNO S., LOSSIO -VENTURA J. A., AKLI A., BELKEBIR S.,\r\nLOUNIS T. & TOURE S. (2015). Ex- traction automatique des mots-clés à\r\npartir de publications scientifiques pour l\'indexation et l\'ouverture\r\ndes données en agronomie. Cahiers Agricultures, 24(5), 313-320.\r\n\r\n\r\nFIGURE 3: Librairie javascript D3.js.'),
(352, '2016-11-14', 'Storyzy', 'Paris', 'NLP Engineer Internship at Storyzy\r\n\r\n-----\r\nContext\r\n-----\r\n\r\nStoryzy (http://storyzy.com/) is a startup based in Paris that creates\r\nstructured data from the text of news articles by extracting all\r\ninformation linked to influencers in the news. It is the first 100%\r\nautomated content technology driven by what people say thru quotes.\r\n\r\nStoryzy (previously Trooclick) was created in November 2012.  Just a few\r\nmonths later, in April 2013, it received financial support from the BPI\r\n(French public investment bank) and in June 2013 was granted the Status\r\nof \"Young Innovative Company\" (JEI), recognizing its innovative nature\r\nby the French government. Storyzy has invested $3 million in R&D, raised\r\n$900k in August 2016, and employs 12 people (6 engineers).\r\n\r\nDue to its growth, Storyzy is now looking for candidates for its office\r\nin the \"Incubateur Boucicaut\" on rue de Lourmel in Paris.\r\n\r\n-----\r\nMissions\r\n-----\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\n- You will turn ideas into well-documented and reliable linguistic\r\n  resources & code to ensure efficiency, quality, performance and\r\n  scalability\r\n- A great team player, you will interact with other departments to\r\n  understand and fine tune specifications\r\n- You will carry out unitary testing, create and maintain our test\r\n  validation corpus and participate in editing technical documents\r\n\r\nDevelopment will be done in English.\r\n\r\n-----\r\nQualifications\r\n-----\r\n\r\n- Experience with NLP tools such as NooJ, Unitex or Stanford for\r\n  linguistic annotation, named entity recognition, relationship and fact\r\n  extraction, sentiment analysis, etc.\r\n- Experience in scripting languages such as Perl or Python and with\r\n  database management\r\n- Knowledge of Java and Semantic Web technologies (RDF, OWL, etc.)  will\r\n  be a plus\r\n- Excellent communication skills in English and French\r\n\r\nWe are open to new ideas that will significantly contribute to our\r\nsuccess.  Our friendly team will provide the opportunity for valuable\r\ncollaboration.  We offer you career perspectives in a young and dynamic\r\ncompany with an interesting and diversified scope of duties at the\r\ncutting edge of research.\r\n\r\nWe welcome applications from highly motivated individuals able to learn\r\nnew techniques and share knowledge and experience with the team.\r\n\r\n-----\r\nContact\r\n-----\r\n\r\nInterested? Then send your application to jobs@storyzy.com!\r\n\r\n*Audrey Champeau *\r\n*NLP Engineer *\r\n------------------------------\r\n+33 6 86 61 36 50\r\naudrey.champeau@storyzy.com\r\n*Storyzy *Incubateur Boucicaut\r\n130 rue de Lourmel 75015 PARIS storyzy.com (http://www.storyzy.com/)'),
(353, '2016-11-14', 'Telecom Bretagne', 'Brest', '--------------\r\nOffre de stage TAL M2 : Étude de l\'apport des dépêches AFP à un corpus\r\nde textes de la presse écrite\r\n--------------\r\nStage financé par le Labex ICCA, projet structurant «Plateformes» 2016\r\n--------------\r\n\r\nLe projet 2PI (Modèles économiques de la presse en ligne & pluralisme de\r\nl\'information) se propose de comparer, à différents niveaux\r\nlinguistiques, des textes provenant de l\'agence de presse AFP et\r\nd\'autres titres de presse.\r\n\r\nLes étapes d\'analyse des textes seront :\r\n- extraction terminologique,\r\n- analyse morphosyntaxique,\r\n- annotation sémantique,\r\n- extraction d\'entités nommées,\r\n- analyse rhétorique (selon la théorie des arbres discursifs de Marcu).\r\n\r\nSelon les outils à disposition, ces étapes seront automatiques ou\r\nsemi-automatiques.  L\'analyse rhétorique nécessitera le développement\r\nd\'outils ad hoc, basés sur des méthodes de machine learning détectant\r\ndes marqueurs syncatégorématiques et d\'autres propriétés du texte, à\r\nétablir. Les données étant temporalisées on étudiera également\r\nl\'évolution des propriétés des textes.\r\n\r\nEn représentant toutes les propriétés linguistiques extraites des textes\r\ndu corpus sous forme de graphes, il s\'agira de mesurer l\'apport des\r\ntextes de l\'AFP vis-à-vis de celui des textes des autres médias et de\r\ncaractériser/quantifier ainsi la notion de «pluralisme des médias».\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent :\r\n- Analyses et annotations automatiques ou semi-automatiques des textes.\r\n- Développement et évaluation de l\'outil d\'analyse rhétorique.\r\n- Modélisation des résultats sous forme de graphes et application de\r\n  différentes mesures de similarité entre les sous-graphes induits par\r\n  les données AFP et leurs compléments.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou\r\n  similaire.\r\n- Programmation en Python (principalement NLTK).\r\n- Curiosité et capacité d\'explorer des nouveaux domaines en linguistique\r\n  et/ou informatique.\r\n- Des connaissances en théorie des graphes seraient un plus.\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 6 mois rémunéré\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\n<yannis.haralambous@telecom-bretagne.eu>\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : Département Informatique, Télécom Bretagne (à partir du 1er\r\njanvier 2017 : IMT Atlantique), Brest.\r\n\r\nEncadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285 Lab-STICC)\r\n             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)\r\n\r\nContrat : stage. \r\n\r\nDébut : 1er février ou 1er mars 2017, selon les disponibilités du\r\ncandidat.'),
(354, '2016-11-14', 'ELDA', 'Paris', 'ELDA recherche un stagiaire (H/F) pour le *Développement d\'un moteur de\r\nrecherche robuste pour naviguer dans des collections de documents, *à\r\npartir de janvier 2017 pour une durée de 6 mois.\r\n\r\n*Profil souhaité*\r\n\r\n  * BAC + 5 / Dernière année d\'École d\'ingénieur ;\r\n  * Connaissances de base en algorithmique ;\r\n  * Connaissances de base des architectures des applications Web ;\r\n  * Maîtrise d\'au moins un des langages Python et / ou JavaScript ;\r\n  * Connaissance pratique d\'un système de gestion de bases de données\r\n    (PostgreSQL de préférence) ;\r\n  * Anglais technique ;\r\n  * La connaissance d\'un moteur de recherche (Solr, Elasticsearch,\r\n    Lucene) sera appréciée.\r\n\r\n*Travail à réaliser*\r\n\r\nAu sein de l\'équipe de développement informatique d\'ELDA, sous la\r\ntutelle d\'un ingénieur spécialiste des technologies de la langue et du\r\ndéveloppement d\'applications Web, vous serez amené à participer aux\r\ntravaux suivants :\r\n\r\n  * faire un état de l\'art exhaustif des possibilités offertes\r\n    aujourd\'hui par les moteurs de recherche les plus puissants, tels\r\n    que Solr, Elasticsearch, ou bien les facilités de recherche\r\n    textuelle offertes par des SGBD (Système de Gestion des Bases de\r\n    Données) tels que PostgreSQL ;\r\n  * participer à la spécification des besoins de recherche textuelle\r\n    dans les actes de la conférence LREC ;\r\n  * participer au choix de la solution technique la plus appropriée pour\r\n    les actes de LREC ;\r\n  * participer à la conception de la structure d\'une base de données\r\n    (schéma de données) pour modéliser le contenu des sites Web\r\n    recensant les articles de la conférence LREC ;\r\n  * extraire les informations pertinentes des sites recensant les\r\n    articles de la conférence LREC et réaliser la mise en données de ces\r\n    informations, utilisant le schéma de données mentionné ci-dessus ;\r\n  * implémenter un moteur de recherche exhaustive à travers tous les\r\n    actes de la conférence LREC, compte tenu des contraintes dégagées\r\n    lors des étapes antérieures ;\r\n\r\nVos participerez également aux réunions périodiques de l\'équipe de\r\ndéveloppements logiciels d\'ELDA.\r\n\r\n*Candidature*\r\n\r\nCe stage, d\'une durée de 6 mois et basé à Paris dans le 13e\r\narrondissement (Les Gobelins), est à pourvoir en*janvier 2017*.\r\n\r\nLes candidatures (CV, lettre de motivation) doivent être adressées à\r\nVladimir Popescu (vladimir@elda.org).\r\n\r\nLe stage fait l\'objet d\'une rémunération, variable en fonction du niveau\r\nd\'études du candidat.\r\n\r\nhttp://www.elra.info/en/opportunities/internships/\r\nhttp://www.elda.org'),
(355, '2016-11-21', 'Airbus', 'Toulouse', 'Internship on \"Natural Language & Speech processing for Virtual\r\nAssistants\"\r\n\r\nAirbus Human Factor\'s department is offering an internship on the\r\ntopic of \"Natural Language & Speech processing for Virtual Assistants\"\r\n(6 months between February and September 2017, located in Toulouse,\r\nFrance).\r\n\r\nWe are targeting 2nd- year master students with knowledge and prior\r\nexperience in one or several of these domains: natural language\r\nprocessing, artificial intelligence, human-computer interaction,\r\npsycholinguistics, cognitive science, applied linguistics, computer\r\nscience.\r\n\r\nExpected soft skills are: multidisciplinarity, scientific rigor,\r\nautonomy, English spoken - fluent French is not required.\r\n\r\nThe final topic will be decided with the candidate depending on\r\nhis/her skills and interests. Possible topics may be (non-exhaustive):\r\n\r\n· Definition of test protocols to measure maturity of on-the-shelf\r\n          solutions;\r\n\r\n· Comparative study of human-human vs human-machine communications;\r\n\r\n· Dialog modelization and creation of resources for human-machine\r\n          dialog systems.\r\n\r\nTo apply for the position, the candidate should both apply online at\r\nairbus job portal and send an email to Emmanuelle CANNESSON\r\n(Emmanuelle.cannesson@airbus.com) and Estelle DELPECH\r\n(estelle.e.delpech@airbus.com) before end of December 2016.\r\n\r\nLink to airbus job portal:\r\n\r\nhttp://www.airbusgroup.com/int/en/people-careers/jobs-and-applications/search-for-vacancies~lang=en~jobid=001A4B0A914A1ED6AAE68925418D010B~.html'),
(356, '2016-11-23', 'LSIS', 'Marseille', 'Stage financé de Master de 4 à 6 mois - Marseille, DIMAG, LSIS, \r\nAix-Marseille Université.\r\n\r\n*/De la fouille de données d\'interaction médecin-patient à un modèle\r\ncomputationnel des feedbacks pour un patient virtuel /*\r\n\r\n/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)\r\n(LSIS, DIMAG), Roxane Bertrand (LPL http://www.lpl-aix.fr/), Grégoire de\r\nMontcheuil (LPL), et Philippe Blache (LPL).\r\n\r\n/Financement /: Projet ANR Acorformed \r\n(http://www.lpl-aix.fr/~acorformed/index.html)\r\n\r\n/Contexte du stage /\r\n\r\nLe stage se déroule dans le cadre du projet ANR /Acorformed/qui vise à\r\ndévelopper une plateforme de réalité virtuelle pour former les médecins\r\nà l\'annonce d\'évènements indésirables graves avec un patient virtuel. Un\r\ndes enjeux majeurs de ce projet est de développer un patient virtuel\r\ncapable de simuler le comportement d\'un patient réel auquel on annonce\r\nune mauvaise nouvelle. Dans ce contexte, le comportement non-verbal du\r\npatient virtuel (mouvements de tête, expressions faciales, postures,\r\ngestes, directions du regard, etc.) joue un rôle prépondérant pour\r\napporter de la crédibilité au personnage virtuel. L\'objectif de ce stage\r\nest de développer un modèle qui permettrait de déterminer à quel moment\r\nle personnage virtuel devrait exprimer quel comportement non-verbal en\r\nréponse au comportement du médecin.\r\n\r\n/Sujet de stage /\r\n\r\nL\'objectif du stage est de développer un */modèle computationnel de\r\nfeedbacks pour un personnage virtuel/* qui permettrait de calculer\r\nautomatiquement et en temps réel les feedbacks que devait exprimer le\r\npersonnage virtuel suivant le comportement de l\'utilisateur\r\n(automatiquement détecté dans la plateforme de réalité virtuelle) et le\r\ncontexte de l\'interaction. Les feedbacks se définissent comme des\r\nréponses multimodales de celui qui écoute suite au message de\r\nl\'interlocuteur. Les feedbacks peuvent être verbaux (e.g. humhum, oui)\r\nou non-verbaux (e.g. mouvements de tête, sourire). Plusieurs travaux de\r\nrecherche dans le domaine des personnages virtuels montrent que les\r\nfeedbacks permettent d\'améliorer la satisfaction et l\'engagement de\r\nl\'utilisateur. Les feedbacks dépendent du contexte de l\'interaction.\r\nDans le cadre de ce projet, il s\'agira de déterminer automatiquement à\r\nquel moment durant l\'interaction avec le médecin, le patient virtuel\r\ndoit exprimer quel type de feedback.\r\n\r\n/Méthodologie/\r\n\r\nLa méthodologie utilisée pour construire ce modèle reposera sur une\r\nanalyse de données réelles. En effet, un corpus de données\r\naudiovisuelles a été collecté dans le cadre du projet ANR Acorformed. Ce\r\ncorpus regroupe 2 heures d\'interaction entre un médecin et un acteur\r\njouant le rôle d\'un patient à qui on annonce un évènement indésirable\r\ngrave. Ce corpus a été entièrement retranscrit et le comportement\r\nnon-verbal du médecin et du patient ont été annotés.L\'objectif est\r\nd\'explorer ce corpus, et en particulier les relations temporelles entre\r\nles signaux verbaux et non-verbaux du médecin (e.g. mouvements de tête,\r\ndirection du regard, vocabulaire médical complexe)et les signaux\r\nnon-verbaux du patient. Il s\'agira par cette analyse de comprendre ce\r\nqui déclenche les feedbacks (signaux verbaux et non-verbaux) du patient\r\n(e.g. est-ce que un changement de direction de regard du médecin\r\nimplique un changement de regard du patient ?). Différents algorithmes\r\nde « sequences mining » pourront être explorés pour extraire du corpus\r\nles relations temporelles entre les signaux. Les mesures de qualité des\r\nrègles extraites pourront être exploitées pour développer un modèle\r\nstochastique de génération de feedbacks.\r\n\r\n/Compétences requises /\r\n\r\nLe stagiaire devra à la fois avoir des connaissances techniques (Python,\r\néventuellement Java), des connaissances en fouille de données et en TAL,\r\net surtout une ouverture pluridisciplinaire.\r\n\r\n\r\nLes dossiers de candidatures doivent contenir un CV détaillé, les notes\r\nde Master ainsi qu\'une lettre de motivation.\r\n\r\nLe dossier est à envoyé à magalie.ochs(at)lsis.org'),
(357, '2016-11-23', 'Orange labs', 'Lannion', 'Stage sur l\'évaluation de librairies open-sources\r\ndans le domaine du Deep-Learning pour le\r\ntraitement des séquences ou des textes\r\n\r\nref : 0014352 | 19 oct. 2016\r\n\r\ndate limite de candidature : 16 déc. 2016\r\n\r\n2 avenue Pierre Marzin 22300 LANNION - France\r\n\r\nvotre rôle\r\n\r\nLes récents progrès des techniques d\'apprentissage artificielles dites\r\n\"Deep Learning\" ont été largement relayés dans les média\r\nrécemment. Citons rapidement à titre d\'exemple, hors application de\r\nreconnaissance d\'image : Watson, pour lequel IBM intègre de nombreuses\r\ntechniques différentes dans sa technologie d\'assistant intelligent;\r\nles assistants orientés smartphone ou OS de type SIRI, Cortana...; le\r\nnouvel assistant pour mail \"Allo\" de Google, etc... Ces différents\r\nsuccès reposent en partie sur de nouveaux composants d\'apprentissage\r\nartificiels, et pour une autre partie sur les très grandes bases\r\nd\'apprentissage maintenant disponibles chez les grands acteurs de\r\nl\'internet pour entraîner ces systèmes. Parmi les nouveaux composants,\r\nla classe des LSTM networks (Long Short-Term Memory Networks) et leurs\r\nvariantes (GRU...) nous intéressent ici tout particulièrement.\r\n\r\nNous souhaitons répondre à certaines questions quant à la mise en oeuvre\r\ndes composants de type LSTM et/ou variantes et leur intérêt à Orange :\r\nQuelles sont les librairies de type LSTM qui pourraient être utilisées\r\nchez Orange ? Quel est le degré de maturité de ces librairies ? Quelles\r\nsont les difficultés de mise en oeuvre ? Comment se comportent les LSTM\r\nsur quelques tâches simples de prédiction de séquences, de Q/A, et\r\nd\'extraction d\'information ? Pour chaque problème type, et selon les\r\ntypes de LSTM, comment évoluent les courbes des performances en fonction\r\ndu nombre d\'exemples ? Peut-on entraîner des LSTM sur des bases de\r\ntaille limitées ou moyennes ? Si oui quels types de LSTM le permettent,\r\navec quels paramètres et quelles performances ?\r\n\r\nNous souhaitons à l\'issu de ce stage avoir un premier retour sur\r\nexpérience sur l\'utilisation de composants de type LSMT, des avantages\r\net inconvénients des librairies disponibles, leur facilité de mise en\r\noeuvre, les performances qu\'on peut en escompter avec un investissement\r\nde quelques mois (nous ne visons pas l\'exhaustivité dans cette étude :\r\nla liste des tâches de tests sera adaptée au format du stage et aux\r\ncontraintes techniques rencontrées au fur et à mesure).\r\n\r\nCe stage de 6 mois (durée impérative) sera donc composé des étapes\r\nsuivantes :\r\n\r\n1. Prises en main et compréhension des LSTM : 1,5 mois.\r\n\r\nUn premier compte-rendu sur la prise en main sera effectué à la fin de\r\ncette étape.\r\n\r\n2. Construction du benchmark des tâches de test : 1,5 mois.\r\n\r\nA partir des jeux de données et des tâches précisées en entrée,\r\nconcevoir et coder les scripts d\'enchaînement des traitements et\r\nintégrer les composants nécessaires à chaque tâche.\r\n\r\nEffectuer les tests unitaires.\r\n\r\nUn document technique présentant le code développé sera effectué à la\r\nfin de cette étape.\r\n\r\n3. Passage des tests et variations itératives sur le benchmark : 2 mois.\r\n\r\nUne fois le benchmark bien rôdé, les campagnes de tests, en faisant\r\nvarier les paramètres et les tailles des jeux de données, seront\r\nlancées. Tous les résultats seront consignés et analysés tout au long de\r\ncette étape.\r\n\r\n4. Rédaction finale du rapport : 1 mois.\r\n\r\nLe rapport compilera les livrables intermédiaires et un bilan des études\r\neffectuées.\r\n\r\nLe rapport devra entre autres contenir les points suivants :\r\n\r\n- Présentation pédagogiques des LSTM et/ou variantes vues et les\r\n  librairies utilisées,\r\n\r\n- Synthèse des difficultés rencontrées aux différentes étapes, synthèse\r\n  des résultats obtenus.\r\n\r\nvotre profil\r\n\r\nElève ingénieur en 3ème année ou Master recherche en informatique ou\r\ntraitement du signal ou équivalent.\r\n\r\nUne spécialisation en machine learning sera un plus appréciable.\r\n\r\nVous avez de bonnes connaissances en développement, notamment en Java et\r\nPython.\r\n\r\nle plus de l\'offre\r\n\r\nAfin de gagner du temps, seront donnés dès le début du stage :\r\n\r\n- une courte bibliographie sur les LSTM et leurs principales variantes.\r\n\r\n- la short-list des librairies à évaluer.\r\n\r\n- la description des tâches de tests pour le benchmark.\r\n\r\n- pour les tâches portant sur du texte, les éventuels outils de\r\n  prétraitement nécessaires.\r\n\r\nentité\r\n\r\nOrange Labs Products and Services (OLPS) mobilise désormais l\'expertise\r\nde plus de 3300 personnes réparties sur 14 villes en France et à\r\nl\'international dans 11 pays.  Elles porteront la responsabilité\r\ntechnique globale des produits et services proposés par notre Groupe, de\r\nla stratégie à la maintenance des solutions mises en oeuvre partout dans\r\nle monde.\r\n\r\nUn challenge de taille que nous relevons tous ensemble dans une logique\r\nde maîtrise des coûts et des délais, avec un environnement de travail\r\ncentré autour du client et de l\'innovation au service des pays.\r\n\r\nProche de la mer, vous serez dans l\'équipe de traitement des données\r\nd\'Orange Labs directement en lien avec des problématiques\r\nopérationnelles d\'Orange sur le CRM et l\'Audience.  Vous évoluerez dans\r\nun contexte très recherche sur un sujet porteur. Vous serez intégré-e au\r\nsein d\'une équipe recherche.\r\n\r\ncontrat\r\n\r\nStage\r\n\r\nDurée du stage : 6 mois\r\n\r\nNiveau d\'études préparées pendant ce stage : Bac+5\r\n\r\nCandidatez sur Orange Jobs :\r\n\r\nhttps://orange.jobs/jobs/offer.do?joid=57292&lang=FR'),
(358, '2016-11-23', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\n  Offre de stage : Modélisation d\'une base de connaissances (H/F)\r\n------------------------------------------------------------------------\r\n\r\nSyllabs est une start-up innovante en plein développement dans le\r\ndomaine de la sémantique et du Web. Grâce à un gros effort de R&D et à\r\nune expertise dans le domaine du traitement de l\'information, nous avons\r\ndéveloppé un ensemble technologique unique au monde comprenant des\r\nsolutions de collecte (web mining), d\'analyse (text mining) et de\r\ngénération de textes (robots rédacteurs). Syllabs développe actuellement\r\nune offre verticale dans le domaine des médias permettant la collecte,\r\nl\'agrégation et l\'enrichissement de contenus issus de différentes\r\nsources.\r\nNous développons des outils pour plusieurs acteurs médias (Les Echos, Le\r\nMonde, Slate, Radio France...) dans leur stratégie d\'innovation et de\r\ngestion des contenus de même que des sites leaders de l\'e-commerce et du\r\ntourisme en France.\r\nSyllabs recrute un(e) stagiaire(e) dont le rôle sera d\'organiser les\r\ndonnées d\'une base de connaissances afin de mutualiser les données\r\nréutilisées à travers les projets actuels. Les projets de Syllabs étant\r\nde plus en plus complexes, l\'organisation des connaissances est un enjeu\r\nfondamental pour nos futurs projets.\r\n\r\n--------------------------------\r\n  Description du stage\r\n--------------------------------\r\n\r\nLa base de connaissance s\'appuiera sur un modèle de graphes :\r\nl\'information n\'est pas seulement portée par des noeuds mais aussi par\r\nles liens.\r\n\r\nPlusieurs tâches sont considérées afin de constituer une base de\r\nconnaissances fiable :\r\n\r\n- Prise en main de la base de connaissances existante, apprentissage des\r\n  bases de graphes,\r\n- Définition des besoins utilisateurs avec les ingénieur linguistes de\r\n  Syllabs\r\n- Identification des domaines et sujets pertinents dans le cadre des\r\n  travaux menés par Syllabs,\r\n- Analyse des données existantes, annotation des sources en domaine,\r\n  sujet, etc.\r\n- Modélisation d\'une base de connaissance,\r\n- Intégration des données dans la base de connaissance avec des\r\n  perspectives d\'automatisation et/ou d\'interfaces d\'aide à\r\n  l\'intégration\r\n- Éventuellement, collecte de données et cas d\'usages avec du datamining.\r\n\r\n--------------------------\r\n Profil recherché\r\n--------------------------\r\n\r\n- Méthodique et rigoureux\r\n- Une première expérience de modélisation de base de données est\r\n  souhaitable\r\n- Connaissance d\'un langage de script, de préférence Python\r\n- Capacité d\'organisation\r\n- Curiosité\r\n- Bonne culture générale et bon sens\r\n- La connaissance des bases de graphes serait un plus\r\n\r\n------------\r\n  Divers\r\n------------\r\n\r\n- Durée : 6 mois\r\n- Stage conventionné, rémunération supérieure à la rémunération minimale\r\n  + tickets resto + remboursement de la moitié du passe Navigo.\r\n- Télétravail possible le mercredi.\r\n- Bonne ambiance, coin canapé et équipe technique de grande qualité.\r\n- Nos locaux sont situés dans le très agréable quartier de Charonne,\r\n  entre Bastille et Nation, au 35 rue Chanzy (75011), que nous\r\n  partageons avec d\'autres start-ups innovantes.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant le titre du stage.'),
(359, '2016-11-23', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage : Ingénieur R&D (H/F) - Recherche d\'informations sur le\r\nWeb\r\n------------------------------------------------------------------------\r\n\r\nSyllabs est une start-up innovante en plein développement dans le\r\ndomaine de la sémantique et du Web. Grâce à un gros effort de R&D et à\r\nune expertise dans le domaine du traitement de l\'information, nous avons\r\ndéveloppé un ensemble technologique unique au monde comprenant des\r\nsolutions de collecte (web mining), d\'analyse (text mining) et de\r\ngénération de textes (robots rédacteurs). Syllabs développe actuellement\r\nune offre verticale dans le domaine des médias permettant la collecte,\r\nl\'agrégation et l\'enrichissement de contenus issus de différentes\r\nsources.  Nous développons des outils pour plusieurs acteurs médias (Les\r\nEchos, Le Monde, Slate, Radio France...) dans leur stratégie\r\nd\'innovation et de gestion des contenus de même que des sites leaders de\r\nl\'e-commerce et du tourisme en France.\r\n\r\nSyllabs recrute un(e) ingénieur(e) R&D en stage afin de réaliser un\r\noutil de recherche d\'informations sur le Web. Possibilité d\'embauche à\r\nla fin du stage.\r\n\r\n--------------------------------\r\n  Description du stage\r\n--------------------------------\r\n\r\nLe stage a pour principal objectif le développement d\'un outil qui, à\r\npartir d\'une information donnée, ira collecter sur le Web des\r\ninformations complémentaires afin de créer une base de connaissance.\r\n\r\nLes tâches concerneront principalement :\r\n- la définition d\'informations structurées pertinentes par rapport aux\r\n  travaux à Syllabs,\r\n- le déployement d\'un outil de collecte de données sur le Web à partir\r\n  de l\'existant,\r\n- le développement d\'un outil d\'extraction d\'informations,\r\n- l\'analyse et la représentations des informations obtenues,\r\n- les travaux se font sur du français, mais pourraient, si le temps le\r\n  permet, être adaptés à une ou plusieurs autres langues.\r\n\r\nVous intégrerez une équipe dynamique dans un environnement et une\r\nméthodologie de travail structurés : intégration continue (Jenkins),\r\npull requests via BitBucket, code review, méthodologie Scrum avec des\r\nstand-ups quotidiens.\r\n\r\n--------------------------\r\n Profil recherché\r\n--------------------------\r\n\r\n- Bon niveau en programmation Python\r\n- Connaissance de Linux\r\n- Expérience en Traitement Automatique des Langues ou goût pour les\r\n  langues serait un plus\r\n\r\n------------\r\n  Divers\r\n------------\r\n\r\n- Durée : 6 mois\r\n- Stage conventionné, rémunération supérieure à la rémunération minimale\r\n  + tickets resto + remboursement de la moitié du passe Navigo.\r\n- Télétravail possible le mercredi.\r\n- Bonne ambiance, coin canapé et équipe technique de grande qualité.\r\n- Nos locaux sont situés dans le très agréable quartier de Charonne,\r\n  entre Bastille et Nation, au 35 rue Chanzy (75011), que nous\r\n  partageons avec d\'autres start-ups innovantes.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en indiquant\r\nle titre du stage.'),
(360, '2016-11-23', 'Tracksens', 'Metz', 'Offre de stage Ingénieur NLP / Linguistique\r\n\r\nPrésentation de la société :\r\n\r\nTrackSens est une start-up lancée en 2016 qui se spécialise dans le\r\ndéveloppement d\'outils de traitement automatique du langage à\r\ndestination du grand public et des PME. Elle a aujourd\'hui identifié\r\ndes besoins spécifiques, et doit augmenter ses compétences en\r\nlinguistique et en informatique pour pouvoir y répondre.\r\n\r\nDomaine de formation recherché :\r\nLinguistique, linguistique informatique.\r\n\r\nMission :\r\n\r\nParticiper au développement d\'outils de traitement automatique du\r\nlangage, qui devront permettre l\'analyse et la classification\r\nautomatique de documents textes aux formats HTML et PDF. Vous\r\ntravaillerez en collaboration directe avec un développeur\r\ninformatique.\r\n\r\nDéroulement du stage :\r\n\r\n- Etat de l\'art autour de la thématique de la fouille de texte et de\r\n  l\'extraction des descripteurs linguistiques d\'un corpus de\r\n  documents,\r\n- Evaluation des solutions techniques proposées par les outils\r\n  existants tels que Solr,\r\n- Développement d\'un outil de filtration et d\'un outil de\r\n  classification automatique de documents,\r\n- Validation sur un corpus de test,\r\n- Programmation en Java et JavaScript,\r\n- Participation aux développements de bases de données.\r\n\r\nLe stage permettra d\'intégrer une start-up innovante et de participer\r\nà son développement, ainsi que de travailler suivant une méthodologie\r\nAgile avec des outils de gestion de projets informatiques (Jira, SVN\r\net Maven).\r\n\r\nRésultats attendus : \r\n\r\nUne synthèse exhaustive des méthodologies existantes de\r\nclassification. Et le développement d\'un d\'outil simple permettant de\r\nprésenter, à termes, un prototype fonctionnel.\r\n\r\nProfil recherché : \r\n\r\nMaster 2 en Linguistique/Informatique\r\n\r\nCompétences en :\r\no Analyse sémantique et syntaxique\r\no Statistique\r\no Algorithmique\r\no Connaissance de XML, OWL, RDF et SKOS\r\nBon niveau d\'anglais,\r\nMaitrise des outils de bureautique\r\nConnaissance en développement informatique (Java ou C++, base de\r\ndonnées, JavaScript)\r\n\r\nEncadrant : Sébastien Albouze, Ingénieur Civil des Mines - fondateur\r\nde TrackSens\r\n\r\nDivers : \r\n\r\nDate : à partir du 1er février 2017 (date exacte à définir selon\r\nconvenance),\r\n\r\nStage de 6 mois rémunéré (800 ¤ brut/mois)\r\n\r\nLieu : Metz, au sein du tiers-lieu de création et d\'innovation de\r\nMetz-Blida (lien),\r\n\r\nStage proposé dans l\'objectif d\'une embauche.\r\n\r\nContact\r\n\r\nCV + lettre de motivation à envoyer à :\r\nSébastien Albouze\r\nTrackSens SAS\r\nE-mail : sebastien.albouze@orange.fr\r\nTel : 06-17-07-30-42'),
(361, '2016-11-28', 'ELDA', 'Paris', 'ELDA recherche un stagiaire pour travailler à la mise en place et au\r\ndéploiement d\'un framework de services Web pour le TAL. D\'une durée de 6\r\nmois, le stage commence en janvier 2017.\r\n\r\n*Profil*\r\n\r\n * Niveau : M2 / dernière année d\'école d\'ingénieur\r\n * Domaine : informatique\r\n * Période : à partir de janvier 2017\r\n * Durée : 6 mois\r\n\r\n*Travail à réaliser*\r\n\r\nAu sein de l\'équipe de développement informatique d\'ELDA, sous la\r\ntutelle d\'un ingénieur spécialiste des technologies de la langue et du\r\ndéveloppement d\'applications Web, vous serez amené à participer aux\r\ntravaux suivants :\r\n\r\n * faire un état de l\'art rapide sur les solutions de déploiement de\r\n   services Web de traitement du langage naturel ;\r\n * faire un état de l\'art sur les gestionnaires de flux de traitement ;\r\n * participer à la mise en production et au déploiement chez ELDA d\'une\r\n   solution à base de services Web orientée traitement des langues ;\r\n * participer à la spécification d\'un ensemble de services Web\r\n   réunissant des traitements spécifiques à certaines plates-formes de\r\n   production d\'ELDA ;\r\n * implémenter les connecteurs entre ces plates-formes de production et\r\n   la solution de déploiement de services Web mise en production chez\r\n   ELDA ;\r\n * implémenter un moteur de recherche exhaustive à travers tous les\r\n   actes de la conférence LREC, compte tenu des contraintes dégagées\r\n   lors des étapes antérieures ;\r\n * exposer les plates-formes de production choisies sous forme de\r\n   services Web ;\r\n * documenter rigoureusement toutes les étapes de ce processus.\r\n\r\nVos participerez également aux réunions périodiques de l\'équipe de\r\ndéveloppements logiciels d\'ELDA.\r\n\r\n*Profil souhaité*\r\n\r\n * BAC + 5 / Dernière année d\'École d\'ingénieur ;\r\n * Connaissances solides en algorithmique ;\r\n * Connaissances de base des architectures des applications Web ;\r\n * Intérêt pour le domaine du Traitement automatique des langues (TAL) ;\r\n * Connaissances pratiques de programmation en Java (ou Scala, Clojure)\r\n   et / ou Python ;\r\n * Connaissance pratique d\'un logiciel de gestion de versions (Git,\r\n   Mercurial ou SVN) ;\r\n * Capacités rédactionnelles en anglais technique ;\r\n * Nationalité d\'un pays membre de l\'Union Européenne ou droit au\r\n   séjour en France pendant toute la durée du stage.\r\n\r\n*Candidature*\r\n\r\nCe stage, d\'une durée de 6 mois et basé à Paris dans le 13e\r\narrondissement (Les Gobelins), est à pourvoir en*janvier 2017*.\r\n\r\nLes candidatures (CV, lettre de motivation) doivent être adressées à\r\nVladimir Popescu (vladimir@elda.org).\r\n\r\nLe stage fait l\'objet d\'une rémunération, variable en fonction du niveau\r\nd\'études du candidat.\r\n\r\nwww.elda.org\r\n\r\n*-*-*-*-*-*-*-*-*\r\n\r\nActeur majeur des technologies de la langue, ELDA (« Agence pour la\r\nDistribution des ressources Linguistiques et l\'Evaluation ») est une PME\r\ndont les activités s\'articulent principalement autour de la distribution\r\net de la production de ressources linguistiques. ELDA prend en charge\r\nces activités pour le compte d\'ELRA, l\'Association européenne pour les\r\nressources linguistiques, association européenne à but non-lucratif\r\nassurant la promotion des ressources linguistiques dans un contexte\r\neuropéen.\r\n\r\nAinsi, ELDA apporte son soutien à ELRA pour l\'organisation de LREC, la\r\nconférence pour les ressources linguistiques et l\'évaluation. Depuis\r\n1998, cette conférence bisannuelle de portée internationale réunit, à\r\nchaque édition, des centaines de chercheurs de premier rang du monde\r\nentier, qui soumettent et présentent des articles de recherche\r\nscientifique.\r\n\r\nAfin de faciliter la navigation dans ce thésaurus d\'articles\r\nscientifiques, ELDA a mis en place un ensemble de sites Web recensant\r\nces articles-mêmes, ainsi que des informations les concernant (auteurs,\r\ntitres, résumés des articles, etc.).\r\n\r\nDans ce contexte, ELDA souhaite consolider ces sites, en permettant à\r\nl\'utilisateur d\'effectuer des recherches exhaustives au moyen d\'un\r\nmoteur robuste dans la totalité des collections d\'articles correspondant\r\nà toutes les éditions de la conférence LREC.'),
(362, '2016-11-28', 'Lab-STICC', 'Brest', '--------------\r\nOffre de stage M2 : Extraction de connaissances dans un corpus de\r\npublications scientifiques et modélisation ontologique des contextes de\r\ncitation\r\n--------------\r\nStage financé par le Lab-STICC UMR CNRS 6285\r\n--------------\r\n\r\nLe Lab-STICC (http://www.lab-sticc.fr/) est une UMR CNRS de grande\r\ntaille. Ses effectifs atteignent les 600 personnes, reparties dans toute\r\nla Bretagne Océane. Les publications des membres du Lab-STICC ont un\r\nimpact important dans un grand nombre de disciplines scientifiques.\r\n\r\nLe présent stage vise à modéliser et à qualifier cet impact à travers\r\nles citations des publications des membres du Lab-STICC dans la\r\nlittérature scientifique.\r\n\r\nIl s\'agira donc, dans un corpus de publications tel que ACM Digital\r\nLibrary ou IEEE Explore, ou HAL/arXiv (en consultant également DBLP,\r\nGoogle Scholar, etc.), de détecter les publications d\'une personne\r\ndonnée dans les listes de références bibliographiques, d\'accéder au\r\ntexte intégral des articles citant la personne en question, d\'analyser\r\npar des techniques du traitement automatique de langue (en anglais ou\r\nfrançais) les contextes de citation et de s\'en servir pour alimenter une\r\nontologie ad hoc.\r\n\r\nEn particulier, il s\'agira d\'évaluer l\'appréciation (explicite ou\r\nimplicite) de la citation par l\'auteur de l\'article.\r\n\r\nDifférentes mesures seront appliquées à une représentation sous forme de\r\ngraphe conceptuel de l\'ontologie en question, et permettront d\'obtenir\r\nune vision plus riche de l\'impact de la recherche des membres du\r\nlaboratoire, à divers niveaux de granularité : ils sera possible de\r\nformer des requêtes concernant une ou des personne(s), des termes, des\r\nthématiques ou des domaines, et d\'obtenir des résultats métrologiques\r\nconcrets sur les activités de recherche correspondantes.\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent :\r\n- Développement de l\'outil d\'extraction des contextes de citation.\r\n- Analyse linguistique des contextes de citation :\r\n   - morphosyntaxe, \r\n   - entités nommées, \r\n   - résolution d\'anaphores,\r\n   - alignement avec des ontologies spécifiques au domaine scientifique\r\n     en question,\r\n   - alimentation d\'une ontologie ad hoc,\r\n   - détection de sentiment.\r\n- Modélisation des résultats sous forme de graphes contextuels avec\r\n  possibilité de formation de requêtes.\r\n- Comparaison de différentes mesures de graphes pour caractériser\r\n  l\'impact scientifique d\'une publication, d\'une personne ou d\'une\r\n  équipe du Lab-STICC.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique, Ingénierie\r\n  linguistique, ou similaire.\r\n- Bonnes connaissances en Python (notamment NLTK).\r\n- Curiosité et capacité d\'explorer des nouveaux domaines en linguistique\r\n  et/ou informatique.\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nStage conventionné 6 mois rémunéré\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nyannis.haralambous@telecom-bretagne.eu\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : Département Informatique, Télécom Bretagne (à partir du 1er\r\njanvier 2017 : IMT Atlantique), Brest.\r\n\r\nEncadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285\r\n             Lab-STICC)\r\n             Gilles Coppin (Télécom Bretagne et UMR CNRS 6285 Lab-STICC)\r\n             Emmanuel Boutillon (Université de Bretagne-Sud et UMR CNRS\r\n             6285 Lab-STICC)\r\n\r\n\r\nContrat : stage. \r\n\r\nDébut : 1er février ou 1er mars 2017, selon les disponibilités du\r\ncandidat.\r\n\r\n-------------------------------------------------------------------------\r\nMessage diffuse par la liste Langage Naturel <LN@cines.fr>\r\nInformations, abonnement : http://www.atala.org/article.php3?id_article=48\r\nEnglish version       : \r\nArchives                 : http://listserv.linguistlist.org/archives/ln.html\r\n                                http://liste.cines.fr/info/ln\r\n\r\nLa liste LN est parrainee par l\'ATALA (Association pour le Traitement\r\nAutomatique des Langues)\r\nInformation et adhesion  : http://www.atala.org/\r\n\r\nATALA décline toute responsabilité concernant le contenu des\r\nmessages diffusés sur la liste LN\r\n-------------------------------------------------------------------------'),
(363, '2016-11-28', 'Meteojob', 'Paris', 'Meteojob est une société en forte croissance devenue l\'un des leaders du\r\nrecrutement sur internet en France. Meteojob a pour ambition de\r\nrévolutionner la recherche d\'emploi en mettant en oeuvre les technologies\r\nles plus avancées dans les domaines du matching, du big data, des\r\nentretiens vidéo différés... Notre vocation est de créer des\r\napplications remarquables qui permettent à des millions de personnes de\r\ntrouver plus rapidement un emploi.\r\n\r\nFort de 2,7 millions d\'inscrits, et de plus de 600 000 offres d\'emploi\r\npar an, le site meteojob.com compte 1 million de VU par mois.\r\n\r\nNous recrutons aujourd\'hui de nouveaux talents qui veulent participer à\r\nune aventure humaine et être les moteurs d\'un développement important\r\ndans les années à venir.\r\n\r\nhttp://bfmbusiness.bfmtv.com/mediaplayer/video/la-vidaco-va-complatement-transformer-les-processus-de-recrutement-marko-vujasinovic-0405-807438.html\r\n\r\nDurée: 6 mois, à commencer suivant disponibilité\r\nStage conventionné niveau M2\r\nLes travaux s\'effectueront au siège de la société, à Paris (M°\r\nMiromesnil)\r\n\r\nCe stage pourra se poursuivre par une embauche dans le pôle\r\nsémantique/big-data de Météojob.\r\n\r\nLe candidat participera aux tâches suivantes :\r\n- étude du référentiel existant,\r\n- extraction linguistique à partir des offres d\'emploi de compétences\r\n  potentielles,\r\n- mise en correspondance avec les éléments à extraire des offres,\r\n- comparaison/extension avec les données ouvertes (linked-data)\r\n- amélioration des chaînes d\'extraction,\r\n- validation\r\n\r\nLe référentiel visé est en français mais la méthodologie suivie doit\r\nl\'être dans une optique multilingue.\r\n\r\nCompétences requises :\r\n- TAL (étude de corpus, moteur de recherche, grammaires locales,\r\n  apprentissage)\r\n- Programmation Java\r\n- Maîtrise de l\'anglais\r\n- Des connaissances en langage de scripts (Perl, Groovy), en Spark en\r\n  UIMA ou en bases de données sont des plus\r\n- Facilité à travailler en équipe\r\n\r\nMerci d\'envoyer votre candidature à juliette.naux@m-executives.com'),
(364, '2016-11-29', 'Université de Cergy-Pontoise', 'Cergy-Pontoise', 'Analyses sémantiques, linguistiques et statistiques de tweets\r\npolitiques : création d\'un outil d\'analyse lors de campagnes\r\npolitiques\r\n\r\nOffre de stage de 6 mois (à partir de janvier 2017) en informatique,\r\nlinguistiqueinformatique, fouille de données, constitution de corpus,\r\nbases de données\r\n\r\nCe stage se situe dans le cadre du projet de recherche \"#Idéo2017 :\r\ncontribution à la création d\'un outil d\'analyse des tweets politiques\r\nlors de campagnes politiques\" \r\n\r\nhttp://ideo2017.ensea.fr/\r\n\r\nfinancé par la Fondation de l\'université de Cergy-Pontoise\r\n\r\nDescription :\r\n\r\nTwitter est un medium incontournable dans la communication\r\npolitique. Dans ce contexte, le projet #Idéo2017 souhaite (1) mieux\r\nconnaître et décrire les messages politiques envoyés sur Twitter, mais\r\naussi (2) rendre ces résultats disponibles pour les citoyens.\r\n\r\nCe projet consiste en la création d\'une application web en ligne qui\r\npermettrait de traiter, avec des délais relativement courts, les\r\nmessages produits en lien avec l\'actualité politique (meetings,\r\ndébats, émissions télévisées, etc.). Cet outil s\'appuiera sur la\r\nméthodologie de constitution de corpus élaborée dans un précédent\r\nprojet (corpus Polititweets) et l\'implémentation d\'outils de\r\nstatistique textuelle et de visualisation de données. Les citoyens ou\r\njournalistes pourraient ainsi effectuer leurs propres requêtes et\r\nobtenir des résultats compréhensibles grâce à cette interface qui\r\nrendra accessible des analyses et critères linguistiques et\r\ninformatiques complexes.\r\n\r\nObjectifs : \r\n\r\nLes objectifs de se projet concernent deux axes de travail. Dans le\r\npremier axe, l\'étudiant devra faire une étude sur les analyses qui\r\npeuvent être réalisées sur des tweets politiques, et éventuellement en\r\nsuggérer des nouvelles. Dans le deuxième axe, l\'étudiant devra mettre\r\nen place ces analyses sélectionnées dans le cadre d\'un site web. Pour\r\ncela, un ensemble de compétences sont requises.\r\n\r\nLes objectifs se décrivent de la manière suivante :\r\n\r\n1. Etudier l\'ensemble d\'analyses linguistiques qui existent dans la\r\nlittérature et faire une étude comparative.\r\n\r\n2. Choisir parmi les analyses étudiées en point 1 celles qui\r\ns\'intégreraient dans le futur système d\'analyse.\r\n\r\n3. Proposer de nouvelles analyses basées sur des techniques de fouille\r\nde données ou apprentissage automatique.\r\n\r\n4. Travailler sur la mise en place du système (site web) en suivant les étapes\r\nsuivantes :\r\n\r\na. Faire une veille sur tous les frameworks CSS responsive design\r\n(bootstrap, skeleton, Isilex ...) et réaliser une grille comparative\r\npour expliquer le choix de la solution retenue ;\r\n\r\nb. Utiliser l\'architecture REST (Representational State Transfer) pour\r\nconstruire une application type Web Service avec mise à disposition\r\nd\'une API vers des partenaires extérieurs ;\r\n\r\nc. Installation du serveur elasticsearch et d\'un gestionnaire de BD\r\nSQL et NoSql type mysql, mongodb ;\r\n\r\nd. Relier dynamiquement les résultats d\'Elasticsearch avec des outils\r\nde visualisation, de cartographie, d\'analyse de graphes comme Gephi,\r\net de reporting sous formes de dashboards, de graphiques et de\r\nstatistiques comme kibana.\r\n\r\n5. Participer à la constitution d\'un corpus de tweets #Idéo2017 qui\r\nsera mis en ligne sur un site spécifique du projet hébergé par l\'UMR\r\nETIS http://ideo2017.ensea.fr/ (corpus au format tei-cmc).\r\n\r\nCompétences souhaitées :\r\n\r\nCompétences dans l\'usage des services de Twitter, des notions de\r\ndataviz et de machine learning\r\n\r\nConnaissances en fouille de données et bases de données\r\n\r\nUsage d\'outils de fouille de données textuelles et/ou textométrie\r\n\r\nAdaptabilité, curiosité, esprit d\'initiatives pour acquérir les\r\ncompétences non déjà acquises\r\n\r\nProfil : étudiant de M2 en informatique, TAL, fouille de données, ou d\'autres\r\ndomaines qui couvriraient une partie des compétences attendues.\r\n\r\nResponsables de l\'encadrement\r\n\r\nJulien Longhi, AGORA, julien.longhi@u-cergy.fr (porteur du projet)\r\n\r\nClaudia Marinica, ETIS, claudia.marinica@u-cergy.fr\r\n\r\nBoris Borzic, ETIS, boris.borzic@u-cergy.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(365, '2016-11-30', 'HumanRoads / LIA', 'Avignon ou Paris', 'Offre de sujet Master 2\r\n===\r\n\r\nSujet Stage Master 2 / PFE IngÃ©nieur 2017\r\n\r\nHumanRoads / Laboratoire d\'Informatique d\'Avignon (LIA)\r\n\r\nData mapping d\'itinÃ©raires de formation et d\'Ã©volution \r\nprofessionnelleSystÃ¨mes de recommandations\r\n\r\nBenoÃ®t Bonteâ€‹ (HumanRoads), Marc El-BÃ¨ze (LIA), Juan-Manuel Torresâ€‹ (LIA)\r\n\r\nHumanRoads (â€‹ http://www.humanroads.comâ€‹ ) cartographie les itinÃ©raires\r\nd\'Ã©tudes et d\'Ã©volutions professionnelles en se basant sur l\'analyse de\r\nmillions de CV. Cette carte interactive permet de dÃ©couvrir ses propres\r\npossibilitÃ©s d\'emploi ou de formation grÃ¢ce Ã  l\'expÃ©rience des autres,\r\npar exemple de voir ce que les autres ont fait aprÃ¨s une formation ou\r\ncomment ils sont arrivÃ©s Ã  exercer un mÃ©tier.\r\n\r\nEncadrement\r\n\r\nLe stage est rÃ©alisÃ© au sein de la sociÃ©tÃ© MillionRoads, Ã©ditrice de la\r\nsolution Saas HumanRoads et est encadrÃ© par deux chercheurs du\r\nLaboratoire d\'Informatique d\'Avignon (â€‹ http://lia.univ-avignon.frâ€‹ ). Il\r\npeut Ãªtre rÃ©alisÃ© de prÃ©fÃ©rence Ã  Avignon mais aussi Ã  Paris.  Un des\r\nobjectifs du stage peut-Ãªtre la cartographie des itinÃ©raires des Ã©lÃ¨ves\r\net anciens Ã©lÃ¨ves de l\'Ã©tablissement oÃ¹ l\'Ã©lÃ¨ve est inscrit.\r\n\r\nExposÃ© du sujet\r\n\r\nLes trajectoires se rÃ©partissent le plus souvent en 2 tronÃ§ons, celui\r\nconcernant la formation (label Â« diploma Â») et celui relatif aux\r\nexpÃ©riences professionnelles (label Â« job Â»). Il se peut que pour\r\ncertaines personnes un de ces 2 tronÃ§ons soit manquant.  Chaque tronÃ§on\r\ns\'il est prÃ©sent peut Ãªtre composÃ© d\'une ou plusieurs Ã©tapes. Une Ã©tape\r\nest dÃ©crite par deux champs (le contenu et le lieu) auxquels se\r\nrajoutent des Ã©tiquettes temporelles (â€‹ timestamps ) qui sont censÃ©es\r\nindiquer les dates de dÃ©but et fin de l\'Ã©tape.  En s\'inspirant du\r\nfonctionnement des systÃ¨mes de recommandations (SR), on voudrait Ãªtre\r\ncapable de proposer automatiquement une liste courte de propositions Ã \r\nune personne qui cherche Ã  complÃ©ter sa formation voire Ã  entamer ou\r\nprolonger son parcours professionnel.\r\n\r\nIl n\'est pas Ã©vident d\'Ã©valuer les performances d\'un tel SR dans le\r\ndomaine des ressources humaines tant qu\'il n\'est pas encore utilisÃ© sur\r\nune longue pÃ©riode par des milliers de personne. On se contentera de\r\nvÃ©rifier â€‹ a posteriori Ã  quel point on peut prÃ©dire ce qu\'une personne a\r\npu faire Ã  chaque Ã©tape de son parcours.Le problÃ¨me n\'est pas simple.\r\n\r\nAussi, pour tenir compte de la durÃ©e impartie Ã  un stage, on se limitera\r\nau dÃ©veloppement de mÃ©thodes que l\'on peut qualifier\r\nd\'Ã©lÃ©mentaires. Nous allons comparer et combiner plusieurs points de vue\r\npour tenter d\'amÃ©liorer les rÃ©sultats obtenus.  La premiÃ¨re mÃ©thode Ã \r\nlaquelle on pense consiste Ã  ne faire Ã  chaque Ã©tape qu\'une proposition,\r\ntoujours la mÃªme quelle que soit la personne Ã  laquelle on s\'adresse et\r\nquelle que soit sa demande de conseil (job ou diploma). Dans ce cas, il\r\nest clair que pour maximiser les chances de retrouver la bonne Ã©tape, il\r\nfaut proposer l\'Ã©tape la plus frÃ©quente. On peut d\'ailleurs en dÃ©duire\r\nque le taux de succÃ¨s est (avec ou sans biais?)  exactement Ã©gal au\r\npourcentage d\'apparition de cette Ã©tape dans le corpus global.  Pour\r\nengager la responsabilitÃ© des utilisateurs, l\'usage s\'est plus ou moins\r\nimposÃ© de faire une liste de plusieurs propositions ordonnÃ©es (et non\r\npas une seule). Si l\'Ã©tape rÃ©ellement effectuÃ©e est positionnÃ©e en rang\r\n1 de cette liste on marque un point.  Si elle se trouve en rang 2, on\r\nmarque un demi point, en rang 3 un tiers, et ainsi de suite, en suivant\r\nla loi d\'une sÃ©rie harmonique. Pour ne pas surcharger l\'utilisateur les\r\nlistes seront bornÃ©es par une taille maximale (20 par exemple).\r\n\r\nLa premiÃ¨re idÃ©e qui vient Ã  l\'esprit pour amÃ©liorer cette premiÃ¨re\r\nmÃ©thode consiste Ã  trouver un critÃ¨re pour dÃ©couper la population\r\nÃ©tudiÃ©e en plusieurs segments (par exemple deux dans un premier temps :\r\nS1 et S2).\r\n\r\nPour les Ã©tapes de S1, un histogramme plus appropriÃ© que celui de S2 est\r\nutilisÃ© et vice versa. Il s\'agit donc de trouver comment subdiviser au\r\nmieux la population des Ã©tapes ou des utilisateurs pour optimiser le\r\nfonctionnement des SR. â€‹ Pour cela, on pourra tenir compte Ã©ventuellement\r\ndes indices temporels, et surtout on tentera de s\'appuyer sur des\r\nÃ©lÃ©ments clefs (Ã  dÃ©terminer) qui figurent dans les descriptifs du\r\npassÃ©. â€‹ On cherchera par la suite Ã  subdiviser la population en un plus\r\ngrand nombre de segments (en veillant Ã  maintenir une taille minimale\r\ndans chaque segment).\r\n\r\nDernier objectif : si dans les stades prÃ©cÃ©dents on a pu employer des\r\nmÃ©thodes qui tiennent compte du passÃ© (par exemple KMeans, Arbres de\r\ndÃ©cision) pour prÃ©dire le prÃ©sent, on veut Ã  prÃ©sent imaginer une\r\napproche qui s\'appuie toujours sur l\'historique du cursus mais Ã©galement\r\nsur une ou 2 intentions futures. Il conviendra de proposer une mÃ©thode\r\npour abstraire un point clef du futur, et observer Ã  quel point cette\r\ninformation additionnelle malgrÃ© ses aspects gÃ©nÃ©riques et donc flous\r\npermet d\'amÃ©liorer les performances.\r\n\r\nNB : Une Ã©tape de prÃ©-traitement s\'avÃ¨re nÃ©cessaire afin d\'uniformiser\r\n(normaliser) les multiples variantes de l\'information disponible\r\n(majuscules, acronymes, chiffres, dates, etc). Ce prÃ©traitement fera\r\nappel Ã  un nombre limitÃ© de ressources linguistiques, en s\'appuyant\r\nsurtout sur des techniques statistiques de traitement de l\'information.\r\n\r\nRÃ©fÃ©rences\r\nChris Manning and â€‹ Hinrich SchÃ¼tzeâ€‹ , â€‹ Foundations of Statistical \r\nNatural Language\r\nProcessing, MIT Press. Cambridge, MA: May 1999.\r\nhttp://nlp.stanford.edu/fsnlp/\r\n\r\nContact candidatures\r\n\r\nbenoit@humanroads.com\r\nmarc.elbeze@univ-avignon.fr\r\njuan-manuel.torres@univ-avignon.fr'),
(366, '2016-12-06', 'IGN', 'Saint-Mandé', 'Annotation automatique en noms de lieux d\'un corpus de récits de vie de\r\nmigrants\r\n\r\nMots clés\r\nInformatique, TAL, entité nommée spatiale, nom de lieu, apprentissage\r\nautomatique\r\n\r\nContexte\r\nCe stage s\'intègre au projet Matriciel : \"Lieux des migrants à travers\r\ndes récits de vie : perceptions, émotions, mots, cartes\". Le Réseau\r\naquitain pour l\'histoire et la mémoire de l\'immigration (RAHMI) dispose\r\nd\'un corpus sonore de nombreux récits de vie de migrants arrivés en\r\nAquitaine à des époques différentes. Les récits des Espagnols arrivés au\r\nmoment de la guerre civile, et ceux des Portugais venus en France pour\r\ntravailler à partir de la fin des années 50, ont été regroupés en deux\r\ncorpus. Ces entretiens ont été transcrits et l\'objectif est de fournir\r\ndes outils automatiques pour aider à leur analyse. Dans cette analyse,\r\nl\'accent est mis sur l\'articulation entre le singulier (le récit d\'un ou\r\nquelques individus) et le commun (un lieu, éventuellement associé à un\r\névénement, qui a concerné un ou plusieurs groupes de population), et la\r\nmise en évidence d\'éventuels régularités dans les corpus et contrastes\r\nentre les corpus, dans les lieux, les événements, les conditions\r\nd\'intégration. Pour cela, un des objectifs du projet Matriciel est de\r\nsegmenter le texte sous forme d\'épisodes. Les résultats seront ensuite\r\nrestitués dans un format cartographique qui permettra de présenter sous\r\nforme synoptique les épisodes dispersés dans les différents récits.\r\nL\'analyse s\'attache au texte des récits de vie pour y identifier les\r\nlieux et les perceptions associées. Le lieu est ici compris dans un sens\r\nlarge : le lieu désigné par un toponyme répertorié dans un dictionnaire\r\nde toponymes (le plus souvent un nom propre, par exemple France) mais\r\naussi celui désigné par un nom générique, éventuellement précisé par un\r\nnom propre et qui permet par exemple d\'évoquer les lieux d\'arrivée, de\r\ntransit, d\'asile ; le type d\'habitation : la maison, l\'appartement, le\r\nmeublé, le garni, etc. ; les noms donnés aux lieux de résidence : le\r\nquartier, la cité, etc. La perception associée est, pour le moment, vue\r\ncomme une polarité (deux valeurs : positive ou négative) qu\'il faut\r\nattacher à un lieu ou à un segment de texte.\r\n\r\nSujet\r\nLe sujet du stage est d\'avancer dans l\'identification automatique des\r\ndésignations des lieux dans les récits transcrits, ainsi que des\r\nsentiments associées à ces lieux. Une première tâche (Brando et\r\nal. 2016) dans ce sens a été fondée sur l\'apprentissage supervisé à\r\nl\'aide de l\'outil Stanford Named Entity Recognition (approche fondée sur\r\nles champs aléatoires conditionnels ou CRF) . Des modèles pour cet outil\r\nont été entrainés à partir de corpus annotés traitant de thématiques\r\ndiverses. Les résultats ont été mesurés à l\'aide des mesures de rappel,\r\nprécision et F-mesure.\r\nL\'objectif du stage est d\'améliorer ces résultats. Pour cela, deux\r\npistes sont envisagées qui conduiront le stagiaire à implémenter deux\r\ntypes d\'expérimentation (il est souhaité que l\'ensemble des outils\r\ndéveloppés au cours de ce stage soit intégré à l\'environnement GATE ) :\r\n\r\n- dans l\'identification des lieux : le modèle d\'apprentissage pourrait\r\n  être amélioré grâce à la personnalisation et la meilleure utilisation\r\n  des différents paramètres de l\'apprentissage : étiquettes\r\n  grammaticales, largeur de la fenêtre d\'observation, prise en compte\r\n  des variantes orthographiques ;\r\n\r\n- dans l\'identification des sentiments : des outils fondés sur la\r\n  syntaxe ont été conçus pour l\'anglais (Andreevskaia & Bergler 2007 ;\r\n  Ozdemir & Bergler 2015) afin d\'identifier automatiquement des termes à\r\n  prendre en compte pour définir la polarité de segments de textes. Ces\r\n  outils seront testés et adaptés pour le français.\r\n\r\nCompétences particulières et formation requise\r\nCe stage s\'adresse aux étudiants de master 2 ou de 3ème année d\'école\r\nd\'ingénieurs avec une spécialisation en informatique (avec un intérêt\r\nréel pour le TAL) ou en TAL (avec une compréhension approfondie du point\r\nde vue informatique des outils de TAL).\r\n\r\nLieu du stage\r\nInstitut national de l\'information géographique et forestière\r\n73 avenue de Paris\r\n94165 Saint-Mandé Cedex\r\nmétro : Saint-Mandé - ligne 1 ou RER A - Vincennes\r\n\r\nDurée et rémunération\r\ndurée : 5 à 6 mois\r\ndébut : mars 2017\r\nrémunération : environ 550 euros mensuels\r\n\r\nProlongements éventuels\r\nLe COGIT propose chaque année des sujets de thèse ainsi que des stages\r\nde post-doctorant. Un projet de l\'université Concordia à Montréal sur la\r\nthématique de la représentation cartographique des récits de vie de\r\nmigrants a débuté en 2016.\r\n\r\nEncadrement du stage\r\nCatherine Dominguès\r\nIGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex\r\nmél : catherine.domingues@ign.fr\r\n\r\nCarmen Brando\r\nEHESS, 190-198 Avenue de France, 75013 Paris\r\nmél : carmen.brando@ehess.fr\r\n\r\nSabine Bergler\r\nConcordia University, 1455 de Maisonneuve Blvd., Montreal, Canada\r\nmél : bergler@cse.concordia.ca\r\n\r\nPour candidater\r\nLe dossier de candidature sera envoyé par mail à Catherine Dominguès. Il\r\ndevra se composer d\'un curriculum vitae et d\'une lettre de motivation,\r\naccompagnés des relevés de notes des années de M1 et M2 (ou deux\r\ndernières années d\'école d\'ingénieurs) et d\'une description des\r\nenseignements suivis (un lien vers le site internet de la formation est\r\nle bienvenu).\r\n\r\nRéférences\r\nAndreevskaia A., Bergler S. (2007) CLaC and CLaC-NB: Knowledge-based and\r\ncorpus-based approaches to sentiment tagging, In: Proceedings of\r\nSemEval-2007: 4th International Workshop on Semantic Evaluations at ACL\r\n2007, Prague\r\nhttp://www.aclweb.org/anthology/S/S07/S07-1022.pdf\r\nBrando C., Dominguès C., Capeyron M. (2016) Evaluation of NER systems\r\nfor the recognition of place mentions in French thematic corpora, In:\r\nProceedings of the 10th Workshop on Geographic Information Retrieval\r\n(GIR \'16). ACM, New York, NY, USA, article 7, 10 pages\r\nDOI: 10.1145/3003464.3003471\r\nOzdemir C., Bergler S. (2015) A Comparative Study of Different Sentiment\r\nLexica for Sentiment Analysis of Tweets. In: Proceedings of the\r\nInternational Conference on Recent Advances in Natural Language\r\nProcessing (RANLP 2015), Hissar, Bulgaria\r\nhttps://www.aclweb.org/anthology/R/R15/R15-1064.pdf'),
(367, '2016-12-07', 'INIST', 'Nancy', 'L\'INIST - INstitut de l\'Information Scientifique et Technique du CNRS -\r\nrecherche un stagiaire (H/F) pour le ** Test d\'outils d\'exploration de\r\ncorpus textuels **\r\n\r\nMission\r\n\r\nAu sein d\'une équipe projet, vous participerez à l\'exploration et à\r\nl\'évaluation de la qualité de corpus textuels issus du fonds\r\ndocumentaire ISTEX, en testant et en comparant différents outils dédiés\r\n(TXM, TextObserver, Iramuteq, ezvis, etc.).\r\n\r\nProfil\r\n\r\nDe formation documentaire ou TAL, vous êtes à l\'aise dans la\r\nmanipulation de documents XML et vous êtes intéressé par les méthodes de\r\nstatistiques appliquées aux données textuelles (pour aider au\r\nparamétrage des outils et à l\'interprétation des résultats).\r\n\r\nDynamique et motivé, vous souhaitez participer à des projets utilisant\r\ndes méthodes et des technologies innovantes.\r\n\r\nVous avez le sens du service, une bonne capacité d\'assimilation et\r\nd\'adaptation, un bon relationnel et l\'aptitude à vous intégrer\r\nrapidement dans une équipe préexistante réunissant informaticiens,\r\ndocumentalistes & utilisateurs.\r\n\r\nVous êtes prêt à travailler en forte interaction au sein d\'une équipe\r\nagile selon la méthode Scrum.\r\n\r\nModalités\r\n\r\nStage de 4 à 6 mois, gratification prévue.\r\n\r\nLieu\r\n\r\nCNRS - Inist  - http://www.inist.fr/\r\n2, allée du parc de Brabois\r\nCS 10310\r\nF-54519 Vandoeuvre-lès-Nancy\r\nTél : +33 (0)3 83 50 46 00\r\n\r\nContact\r\n\r\nEnvoyer CV et lettre de motivation à tania.sourdot@inist.fr'),
(368, '2016-12-07', 'Synapse Développement', 'Toulouse', 'Offre de stage TAL - Ingénieur / M2R\r\nSujet: Détection d\'incohérences liées à la pragmatique dans un texte\r\n\r\nLieu : Synapse Développement - Toulouse centre\r\nContact : camille.pradel@synapse-fr.com\r\nDurée : 6 mois\r\nRémunération conventionnelle + prime sur objectifs\r\n\r\n---------------\r\nContexte\r\n---------------\r\n\r\nLa société Synapse Développement est leader sur le marché du logiciel\r\nd\'analyse de la langue française. Société innovante d\'une dizaine de\r\npersonnes, Synapse travaille pour le grand public et les grands comptes\r\ncomme Microsoft ou Amazon.\r\n\r\nDepuis plusieurs années, les activités de R&D de Synapse Développement\r\ns\'orientent naturellement vers la compréhension du texte écrit. La\r\nsociété est notamment identifiée comme un acteur majeur des systèmes de\r\nquestion-réponse en français et en anglais. Son savoir-faire a récemment\r\nété illustré au cours de la campagne d\'évaluation Entrance Exams, dans\r\nlaquelle les systèmes sont soumis au test de compréhension de l\'anglais\r\npour l\'entrée à l\'Université au Japon. Aux deux dernières éditions de la\r\ncompétition, la Reading Machine de Synapse a occupé la première\r\nposition, à la fois pour le test original en anglais et pour son\r\nadaptation en français (pour laquelle textes et questions ont été\r\ntraduits à la main) ; elle est la seule à dépasser la moyenne dans les\r\ndeux langues et est donc admise à l\'Université !\r\n\r\nAu cours des dernières décennies, les travaux de recherche visaient à\r\nsurmonter le caractère informel et donc ambigu de la langue\r\nnaturelle. On peut considérer que ce verrou a désormais sauté, même si,\r\nsur le plan pratique, le problème est toujours présent lors de\r\nl\'implémentation d\'un système analysant le langage (la récente\r\nbanalisation de l\'argot, du langage sms, et la multiplication des\r\nerreurs dans les écrits n\'aident pas à la tâche).\r\n\r\nUne approche combinant une analyse syntaxique performante, des\r\nressources linguistiques de qualité et des outils statistiques permet\r\ndonc d\'extraire de façon efficace la sémantique de ce texte. Cependant,\r\ncertains mécanismes cognitifs mis en oeuvre lors de la lecture d\'un texte\r\npar un humain sont encore mal imités par la machine, ce qui rend la\r\nlecture automatique d\'un texte moins performante d\'un point de vue\r\nqualitatif.\r\n\r\nLa principale limite à la compréhension de textes par la machine est\r\nmaintenant pour nous liée au mode d\'expression du locuteur humain,\r\ncelui-ci ayant tendance à se dispenser de communiquer explicitement des\r\ninformations qui sont soit déjà connues du destinataire, soit inférables\r\npar celui-ci.  Il est donc nécessaire pour une machine d\'identifier et\r\nde mobiliser ces informations implicites.\r\n\r\n---------------\r\nObjectifs\r\n---------------\r\n\r\nDans le cadre du projet DIT (Détection d\'Incohérences Textuelles),\r\nSynapse veut concevoir, mettre en place et évaluer une méthode de\r\ndétection des incohérences liées à la pragmatique dans un texte. Dans ce\r\ncontexte, nous appelons une incohérence liée à la pragmatique une\r\ncontradiction entre une assertion d\'un texte et des informations issues\r\nd\'une base de connaissance considérées comme vraies (ground truth).\r\n\r\nCette base de connaissances sera exprimée selon un formalisme de graphes.\r\nElle peut être :\r\n - externe et établie a priori (par exemple DBpedia),\r\n - ou construite par Machine Reading, soit sur une grande quantité de\r\n   textes selon des approches statistiques, structurant alors des\r\n   connaissances de fonds (background knowledge), soit au fur et à\r\n   mesure de la lecture du texte, ce qui permettrait d\'identifier des\r\n   contradictions entre plusieurs assertions d\'un même texte.\r\n\r\n---------------\r\nVerrous\r\n---------------\r\n\r\nNous identifions deux difficultés majeures dans le travail demandé. La\r\nconstruction d\'une base de connaissances de fond uniquement par Machine\r\nReading sur de gros volumes de texte soulève le problème de la gestion\r\nde la masse de données et celui de la prise en compte de données\r\ncontradictoires et leur fusion dans la base de connaissances. Le premier\r\nproblème est déjà en partie résolu par l\'utilisation de la base de\r\ndonnées orientée graphe Neo4j, supportant une optimisation verticale.\r\n\r\nAu niveau pragmatique, le risque tient à la complexité de la tâche\r\ncognitivo-linguistique d\'élaboration d\'un schéma de représentation du\r\ntexte à des fins de comparaison sémantique. L\'analyse du discours se\r\nsitue à la frontière de plusieurs disciplines, entre autres de la\r\npsycholinguistique et de l\'intelligence artificielle, et la stratégie et\r\nles heuristiques utilisées sont cruciales pour des résultats\r\npertinents. Une approche agile (succession d\'itérations intégrant des\r\ntests et améliorant progressivement l\'ensemble du process développé)\r\npermettra de limiter les conséquences de cette difficulté.\r\n\r\n---------------\r\nDéroulement\r\n---------------\r\n\r\nIntégré-e à l\'équipe R&D, le/la stagiaire portera ces thématiques de\r\nrecherche en tirant parti des technologies et savoir-faire Synapse. Un\r\ndécoupage prospectif du travail demandé a permis de définir les tâches\r\nsuivantes :\r\n\r\n1. Etat de l\'art sur la détection d\'incohérences liées à la pragmatique.\r\n2. Contributions scientifiques :\r\n    a. Identification ou proposition d\'un format pivot de représentation\r\n       d\'une base de connaissances.\r\n    b. Proposition du modèle d\'intégration des connaissances issues du\r\n       Machine Reading vers le format pivot.\r\n    c. Proposition d\'une méthode d\'identification de contradictions.\r\n3. Contributions pratiques :\r\n    a. Export d\'une base de connaissances externe type DBpedia vers le\r\n       format pivot.\r\n    b. Constitution d\'une base de connaissances de fonds par Machine\r\n       Reading.\r\n    c. Implémentation du module de détection d\'incohérences\r\n       pragmatiques.\r\n    d. Tests qualitatifs des résultats sur un corpus restreint annoté.\r\n\r\nUn article scientifique sera rédigé avec l\'équipe R&D et soumis en\r\natelier ou en conférence, selon l\'avancement des travaux.'),
(369, '2016-12-14', 'LATTICE', 'Paris', 'Veuillez trouver ci-dessous plusieurs sujets de stages proposés par le\r\nlaboratoire LATTICE.\r\n\r\nPour postuler sur un des stages, merci d\'envoyer un CV, un relevé de\r\nnotes récent (de préférence M1) et une lettre de motivation (quelques\r\néléments disant pourquoi vous postulez sur un stage donné dans le corps\r\ndu mail suffisent) directement aux personnes indiquées comme\r\ncontacts. Tous les stages commenceront début 2017 (entre février et\r\navril 2017) : il est donc conseillé de postuler rapidement et en tout\r\nétat de cause avant la fin décembre 2016. \r\n\r\nLes stages se dérouleront au laboratoire LATTICE, à Montrouge (à 5 mn à\r\npied de la station de métro Mairie de Montrouge, sur la ligne 4).\r\n\r\nCordialement, \r\n\r\nThierry Poibeau\r\n\r\n-----\r\n\r\n\r\n- Analyse et suivi de la présidentielle 2017 sur Twitter\r\n\r\nLe stage concerne la participation à un projet de suivi de l\'actualité\r\npolitique, essentiellement à travers le suivi de messages émis sur\r\nTwitter. Le stagiaire sera plus particulièrement en charge de l\'analyse\r\nsémantique (en premier lieu à travers les entités nommées) du fil\r\nTwitter (a priori plutôt en français). Les données (tweets) seront\r\nfournies et le travail se concentrera sur les aspects linguistiques et\r\ninformatiques. A plus long terme, on s\'intéressera aux flux\r\nd\'information entre médias sociaux et médias traditionnels.\r\n\r\nStage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant\r\nles règles en vigueur\r\nCompétences en programmation (scripts) et en TAL nécessaires\r\nContact : Clément Plancq (clement.plancq@ens.fr) et Isabelle Tellier\r\n(isabelle.tellier@sorbonne-nouvelle.fr)\r\n\r\n\r\n- Annotation d\'un corpus de français médiéval au format « Universal\r\n  Dependencies »\r\n\r\nLe corpus SRCMF (Syntactic Reference Corpus of Medieval French) est un\r\ncorpus arboré en dépendances (Stein & Prevost 2013). Il contient des\r\nphrases annotées en parties du discours et analysées syntaxiquement,\r\nextraites de différents textes en français médiéval datant du 10ème au\r\n13ème siècles. Des expériences d\'apprentissage automatique ont commencé\r\nà être menées sur ce corpus pour étudier sa variabilité suivant\r\ndifférents critères (date d\'écriture, domaine, dialecte, forme) : dans\r\nces expériences, une partie du corpus servait de donnés d\'apprentissage\r\npour un étiqueteur POS et un parser, une autre partie servait de données\r\nde test (Guibon et al. 2014, 2015, 2016). L\'objectif de ce stage est\r\nd\'abord de transformer ce corpus au format désormais plus standard des «\r\nuniversal dependencies » (UD : http://universaldependencies.org/\r\n<http://universaldependencies.org/>). Les distinctions prises en compte\r\ndans SRCMF sont en général plus fines que celles requises par les UD, la\r\ntransformation ne devrait donc pas poser trop de difficultés. Le stage\r\nse poursuivra en reprenant les expériences d\'apprentissage automatique\r\nsur ce nouveau format, pour mesurer son impact sur les résultats.\r\n\r\nStage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant\r\nles règles en vigueur\r\nCompétences en programmation (scripts) et en TAL nécessaires\r\ncontact : Isabelle Tellier (isabelle.tellier@sorbonne-nouvelle.fr) et\r\nSophie Prévost (sophie.prevos@ens.fr) \r\n\r\n\r\n- Recherche de motifs pour la caractérisation de corpus\r\n\r\nPlusieurs outils de recherche de motifs (ou séquences) dans les textes\r\npar des méthodes non ou peu supervisées ont été mis au point ces\r\ndernières années. Leurs résultats sont souvent difficiles à évaluer car\r\nchaque outil fournit des résultats différents et surtout fournit une\r\nquantité de motifs en général extrêmement volumineuse. Le stage\r\nconsistera à partir d\'un de ces outils d\'extraction de motifs, à\r\nl\'appliquer à un ensemble de trois corpus différents (romans\r\nsentimentaux vs romans policiers vs romans contemporains classiques)\r\npour essayer de proposer une méthodologie permettant d\'extraire de la\r\nmanière la plus automatique possible les caractéristiques des différents\r\ncorpus (caractéristiques propres de chaque corpus, traits communs entre\r\ndeux corpus, etc.). Le stage vise à faire des propositions allant dans\r\nle sens d\'une stylistique appliquée. On pourra aussi, le cas échéant,\r\ns\'intéresser à la représentation des données (cartographie du corpus,\r\nmodélisation de liens de proximité entre genres textuels ou entre les\r\ndifférents romans considérés, etc.)\r\n\r\nStage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant\r\nles règles en vigueur\r\n\r\nCompétences en programmation (scripts) et en TAL nécessaires\r\nIntérêt pour la stylistique et la littérature\r\nContact : Frédérique Mélanie (frederique.melanie@ens.fr) et Thierry\r\nPoibeau (thierry.poibeau@ens.fr)\r\n\r\n\r\n- Analyse automatique de langues à morphologie riche (komi ou oudmourte)\r\n\r\nLe Lattice s\'intéresse depuis de nombreuses années aux langues\r\nfinno-ougriennes, pour lesquels peu d\'outils automatiques sont\r\ndisponibles à l\'heure actuelle. C\'est en particulier le cas de langues\r\ncomme le komi ou l\'oudmourte (votiak) parlées en Russie. On dispose\r\nactuellement de données relativement volumineuse pour ces langues, de\r\ndictionnaires mais il n\'y a pas encore d\'analyseurs automatiques (en\r\nparticulier de taggeurs), mis à part des outils assez partiels à base de\r\nrègles mises au point manuellement. Ces langues posent en outre des\r\nproblèmes particuliers dans la mesure où leur morphologie est\r\nparticulièrement riche. Le stage vise donc à développer un taggeur pour\r\nune de ces langues (komi ou oudmourte) en reprenant le logiciel SEM\r\nconçu au LATTICE pour l\'analyse du français (Dupont et Tellier,\r\nhttp://apps.lattice.cnrs.fr/sem/).\r\n\r\nStage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant\r\nles règles en vigueur\r\nCompétences en programmation (scripts) et en TAL nécessaires\r\nConnaissance d\'une langue finno-ougrienne, si possible komi ou oudmourte\r\nContact : Thierry Poibeau (thierry.poibeau@ens.fr)\r\n\r\n\r\n\r\n- Modélisation automatique de l\'évolution des langues (et application\r\n  aux langues finno-ougriennes)\r\n\r\nLe Lattice s\'intéresse depuis de nombreuses années aux langues\r\nfinno-ougriennes et plus récemment à la modélisation de l\'évolution des\r\nlangues et des relations entre langues au sein de la famille\r\nfinno-ougrienne. Le stage consistera à utiliser des modèles connus, en\r\nparticulier le modèle MDL (Minimum Description Length (Grünwald,\r\n2007). On s\'inspirera aussi de travaux récents dans le domaine comme\r\nceux de Nouri et Yangarber (\"Modeling language evolution with codes that\r\nutilize context and phonetic features\", CoNLL 2016) et ceux du groupe\r\nBedlan (http://kielievoluutio.uta.fi/doku.php?id=en:start\r\n<http://kielievoluutio.uta.fi/doku.php?id=en:start>). Le stage vise à\r\nrepartir des travaux mentionnés ci-dessus afin de proposer de nouveaux\r\nmodes d\'analyse et de visualisation des relations entre ces langues.\r\n\r\n\r\nStage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant\r\nles règles en vigueur\r\nCompétences en programmation (scripts) et en TAL nécessaires\r\nConnaissance d\'une langue finno-ougrienne\r\nContact : Thierry Poibeau (thierry.poibeau@ens.fr) et Benjamin Fagard\r\n(benjamin.fagard@ens.fr)'),
(370, '2016-12-14', 'ALPAGE', 'Paris', 'RÉSOLUTION D\'ENTITÉS SCIENTIFIQUES POUR LE TEXT MINING\r\n\r\nType d\'offre : Stage M2/Ingénieur en informatique, 6 mois,\r\navril-septembre 2017, environ 512¤ par mois.\r\n\r\nLieu de travail: INRIA Paris, 2 rue Simone Iff, 75012 Paris\r\n\r\nMots-clés : résolution d\'entités, text mining, machine learning,\r\ninformation scientifique.\r\n\r\nÀ propos d\'Inria : INRIA, institut de recherche dédié au numérique,\r\npromeut « l\'excellence scientifique au service du transfert\r\ntechnologique et de la société ». INRIA emploie 2700 collaborateurs\r\nissus des meilleures universités mondiales, qui relèvent les défis des\r\nsciences informatiques et mathématiques. Son modèle ouvert et agile\r\nlui permet d\'explorer des voies originales avec ses partenaires\r\nindustriels et académiques. INRIA répond ainsi efficacement aux enjeux\r\npluridisciplinaires et applicatifs de la transition numérique. INRIA\r\nest à l\'origine de nombreuses innovations créatrices de valeur et\r\nd\'emplois.\r\n\r\nDescription du stage :\r\n\r\nCe stage a pour cadre un projet retenu dans les « chantiers d\'usage »\r\nd\'ISTEX au sein du groupe de Laurent Romary (équipe INRIA\r\nAlpage). Notre projet vise à enrichir à grande échelle les corpus\r\nscientifiques ISTEX à l\'aide de techniques d\'extraction et\r\nd\'annotations de documents que nous développons, basées sur des\r\nalgorithmes d\'apprentissage automatique. Le but de ces traitements est\r\nd\'utiliser la littérature scientifique comme une base de connaissance\r\npermettant la génération automatique d\'hypothèses scientifiques et\r\nd\'assister les scientifiques dans leur travail de recherche.\r\n\r\nLes extractions d\'information réalisées sur les corpus scientifiques\r\nISTEX nous permettent d\'identifier de façon fiable un volume très\r\nimportant de métadonnées telles que le nom des auteurs, leurs\r\naffiliations ou encore des mentions de concepts ou de nomenclatures\r\nscientifiques (substances, procédés, etc.). Cependant, au delà de\r\nl\'extraction automatique de telles informations brutes, la valeur\r\najoutée devient maximale en identifiant de façon univoque à quelles\r\nentités il est fait référence, c\'est-à-dire en les liant à des bases\r\nde connaissance faisant autorité (souvent nommées « référentiels » :\r\nbase d\'auteurs, bases d\'institutions, bases de composés chimiques,\r\netc.).\r\n\r\nNotre groupe développe une bibliothèque générique de résolution\r\nautomatique d\'entités basée sur de l\'apprentissage automatique,\r\nimpliquant matching flou, graphe, et distances entre structures\r\nhétérogènes. Le travail proposé consiste à appliquer et optimiser\r\ncette bibliothèque sur certaines données extraites du corpus ISTEX et\r\nde l\'archive scientifique nationale HAL.\r\n\r\nLe stage s\'effectuera au sein de l\'équipe Alpage de l\'Inria Paris.\r\n\r\nFormation et expérience souhaitées :\r\n\r\n    Dernière année master ou école d\'ingénieur en informatique\r\n    Compétences en programmation Java\r\n    Intérêt pour le machine learning\r\n    Capacité à travailler en équipe\r\n    Bon niveau d\'anglais \r\n\r\nContacts : Luca Foppiano - luca.foppiano@inria.fr \r\nPatrice Lopez - patrice.lopez@inria.fr'),
(371, '2016-12-14', 'ALPAGE', 'Paris', 'TEXT MINING APPLIQUEÌ AUX ACCORDS D\'ENTREPRISE\r\n\r\nType d\'offre : Stage M2/IngeÌnieur en informatique, 6 mois,\r\navril-septembre 2017, environ 500â‚¬ par mois\r\n\r\nLieu de travail: INRIA Paris, 2 rue Simone Iff, 75012 Paris\r\n\r\nMots-cleÌs : text mining, recherche d\'information, entiteÌs nommeÌes,\r\naccords d\'entreprise\r\n\r\nAÌ€ propos d\'Inria : INRIA, institut de recherche deÌdieÌ au numeÌrique,\r\npromeut Â« l\'excellence scientifique au service du transfert\r\ntechnologique et de la socieÌteÌ Â». INRIA emploie 2700 collaborateurs\r\nissus des meilleures universiteÌs mondiales, qui releÌ€vent les deÌfis des\r\nsciences informatiques et matheÌmatiques. Son modeÌ€le ouvert et agile\r\nlui permet d\'explorer des voies originales avec ses partenaires\r\nindustriels et acadeÌmiques. INRIA reÌpond ainsi efficacement aux enjeux\r\npluridisciplinaires et applicatifs de la transition numeÌrique. INRIA\r\nest aÌ€ l\'origine de nombreuses innovations creÌatrices de valeur et\r\nd\'emplois.\r\n\r\nDescription du stage :\r\n\r\nCe stage a pour cadre une collaboration avec la DARES (Direction de\r\nl\'animation de la recherche, des eÌtudes et des statistiques) du\r\nministeÌ€re du travail, de la formation professionnelle et du dialogue\r\nsocial. La DARES dispose d\'un corpus national exhaustif d\'accord\r\nd\'entreprise d\'environ 1 million de documents, qui s\'enrichit de\r\n80.000 nouveaux documents par an. Cette base documentaire offre donc\r\nla possibiliteÌ d\'analyser et de mieux comprendre les meÌcanismes et\r\neÌvolutions du dialogue sociale en France sur une base quantitative, et\r\ndans un contexte d\'eÌvolution leÌgislatif important. Exploiter au mieux\r\nun tel volume de documents suppose cependant l\'utilisation de\r\ntechniques de fouille et d\'analyse automatiques de textes aÌ€\r\nrelativement grande eÌchelle.\r\n\r\nL\'objectif du stage est d\'expeÌrimenter des outils de text mining et de\r\nrecherche d\'information deÌveloppeÌs par notre eÌquipe INRIA Alpage sur\r\nun sous-ensemble de ce corpus. Nos outils se basent sur des techniques\r\nd\'apprentissage automatiques et ne sont pas deÌpendantes d\'un domaine\r\nparticulier. Cette collaboration est l\'opportuniteÌ d\'eÌvaluer\r\nl\'application de ces outils geÌneÌriques sur le domaine speÌcifique des\r\naccords d\'entreprise, ceci recouvrant en particulier la reconnaissance\r\nd\'entiteÌs nommeÌes, la disambiguisation et la reÌsolution d\'entiteÌs par\r\nrapport aÌ€ un reÌfeÌrentiel comme Wikipedia, l\'extraction automatique de\r\ntermes et cateÌgories clefs et l\'indexation du sous-corpus annoteÌ pour\r\nune interface de recherche seÌmantique. IdeÌalement ce travail mettra en\r\neÌvidence les capaciteÌs et les limites de nos algorithmes, et donc les\r\nbesoins en customisation et reconnaissances d\'entiteÌs plus\r\nspeÌcifiques.\r\n\r\nLe stage s\'effectuera au sein de l\'eÌquipe Alpage dans les locaux de\r\nl\'Inria Paris.\r\n\r\nFormation et expeÌrience souhaiteÌes :\r\n\r\n    DernieÌ€re anneÌes master ou eÌcole d\'ingeÌnieur en informatique\r\n    CompeÌtences en programmation, Java eÌtant un plus\r\n    InteÌreÌ‚t pour l\'apprentissage automatique et la recherche d\'information\r\n    CapaciteÌ aÌ€ travailler en eÌquipe\r\n    Bon niveau de francÌ§aise et d\'anglais technique \r\n\r\nContacts : Patrice Lopez - patrice.lopez@inria.fr'),
(372, '2016-12-14', 'LIMSI', 'Orsay', 'Stage de master 2 / Graduate internship\r\nDistant supervision for event extraction from a\r\nnewswire corpus\r\n\r\nKeywords: natural language processing, text mining, machine learning, distant\r\nsupervision.\r\nIdeal starting date: March/April 2017\r\nDuration: 4-6 months\r\nAdvisor: Xavier Tannier (LIMSI-CNRS), Olivier Ferret (CEA-LIST)\r\nLocation: LIMSI, Orsay, Univ. Paris-Saclay\r\n\r\n1 Context\r\n\r\n1.1 ANR Project ASRAEL\r\n\r\nInformation and communication society led to the production of huge volumes\r\nof content. This content is still generally non-structured (text, images, videos)\r\nand the promises of a \"Web of Knowledge\" are still long ahead. This situation evolves with the development of Open Data portals or resources such as\r\nDBPedia, that have made easier the access to information stored in databases\r\n(economic or demographic statistics, world knowledge contained in Wikipedia\r\ninfoboxes, etc). However, most of the knowledge is still produced by textual\r\ndata. Among the information concerned by the difficulty of accessing textual\r\ndata, those related to events are of great interest, notably in the context of\r\nthe emergence of data journalism. Data journalism has been fed until now by\r\npublicly available, statistical data, but it has paradoxically made only little use\r\nof the very journalistic materials that are events. The project ASRAEL aims\r\nat bridging this gap.\r\nOur proposal comes within the scope of the general scientific framework of\r\ninformation extraction (IE). We aim at extracting events from a large set of\r\ntextual documents, without prior knowledge about them, and at populating\r\nand publishing a knowledge base of events. This knowledge base will be the\r\nsupport of a dedicated event search engine.\r\n\r\n1.2 Event extraction\r\n\r\nWe define event in a traditional information extraction way. An event\r\nis a structured representation of something that happens, with a\r\nnucleus, a spatiotemporal context and some arguments. The \"event type\"\r\ngathers comparable instances of events, as \"earthquake\", \"election\" or\r\n\"car race\". Arguments are attribute/value pairs that characterize an\r\nevent type (for an earthquake, its location, date, magnitude,\r\ncasualties...). A template is the set of arguments that can describe\r\nan event type (earthquake template, election template). The generic\r\nrepresentation of an event is based on the rule of the \"5 Ws\" (What,\r\nWho, Where, When, Why) that prevails in the \"Anglo-Saxon\" way of\r\nwriting articles. This rule stipulates that a good description of an\r\nevent must make these five elements explicit.\r\n\r\nIn automatic information extraction, the information about \"Who\",\r\n\"Where\" and \"When\" are extracted by a traditional and quite generic\r\nnamed entity recognition approach. On the other hand, the \"What\" is\r\nvery domain-specific.  For this reason, traditional IE systems lean on\r\ntemplates predefined by experts and identify events in texts with\r\neither rule-based systems or statistical models.\r\n\r\nHowever, in the general domain, where the huge number of possible\r\nevents makes the manual definition of these templates impossible,\r\ninformation retrieval (\"bag of words\") methods take over, but do not\r\nprovide a structured answer.\r\n\r\n2 Description\r\n\r\nThe global aim of the ASRAEL project is to build a fully-unsupervised\r\nevent extraction system. However, the goal of this proposed internship\r\ncan be seen as an intermediate goal, seeking at reducing the amount of\r\nnecessary supervision in event extraction.\r\n\r\nAgence France Presse (AFP) is one of the partners of the project. They\r\nprovide us with their newswire article corpus from 2004 to present, as\r\nwell as textual chronologies of events and a few structured datasets\r\ncontaining the attributes of events of the same kinds (for example, a\r\nlist of plane crashes, together with their date, location, plane type,\r\ncasualties, cause, etc.).\r\n\r\nThe intern will work on a distantly supervised system aiming at\r\nconsolidating and updating such datasets. The different steps of such\r\na system will be the following:\r\n\r\n1. Use structured instances of events as described in the existing\r\ndatasets as seed for a bootstrapping approach;\r\n\r\n2. Find textual descriptions of these events in the newswire corpus;\r\n\r\n3. Build a classifier from these descriptions;\r\n\r\n4. Run the classifier on the entire corpus to find new instances or\r\nnews descriptions of existing instances;\r\n\r\n5. Build an update procedure for the analysis of new articles.\r\n\r\nTwo main differences exist between the proposed approach and existing distant\r\nsupervision approaches [1, 3]:\r\n- The eventive nature of the relations, making them temporally constrained\r\nand not always true (also explored in [2]);\r\n- The fact to some attributes may not been named entities (e.g. the cause\r\nof a crash).\r\n\r\n3 Application\r\n\r\nWe are particularly interested in candidates with a solid background\r\nin computer science and strong programming skills, having a good\r\nknowledge of machine learning and/or natural language processing.\r\nAs most of the data are in French, knowledge of French basics is a plus.\r\nApplications should include:\r\n- Cover letter outlining interest in the position\r\n- Names of two referees\r\n- Curriculum Vitae (CV)\r\nThe intern will be given a \"bonus\" (was 546,01 e in 2016) + half a \"Navigo\"\r\n(or \"Imagine R\") pass.\r\n\r\nContact for questions and applications:\r\nXavier.Tannier[at]limsi.fr\r\n\r\n3 References\r\n[1] Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. Distant supervision\r\nfor relation extraction without labeled data. In Proceedings of the Joint\r\nConference of the 47th Annual Meeting of the ACL and the 4th International\r\nJoint Conference on Natural Language Processing of the AFNLP: Volume\r\n2 - Volume 2, pages 1003-1011, Suntec, Singapore, 2009. Association for\r\nComputational Linguistics.\r\n[2] Kevin Reschke, Martin Jankowiak, Mihai Surdeanu, Christopher Manning,\r\nand Daniel Jurafsky. Event Extraction Using Distant Supervision. In\r\nProceedings of the 9th International Language Resources and Evaluation\r\n(LREC\'2014), Reykjavik, Iceland, May 2014.\r\n[3] Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. Distant Supervision\r\nfor Relation Extraction via Piecewise Convolutional Neural Networks. In\r\nLluis Marquez, Chris Callison-Burch, and Jian Su, editors, Proceedings of\r\nthe Conference on Empirical Methods in Natural Language Processing, Lisbon, Portugal, September 2015. Association for Computational Linguistics,\r\nMorristown, NJ, USA.'),
(373, '2016-12-14', 'LIMSI', 'Orsay', 'Stage de master 2 / Graduate internship\r\n\r\nAutomatic Classification of Claims from Political Debates and\r\nDeclarations\r\n\r\nKeywords: natural language processing, text mining, machine learning,\r\ncomputational journalism, fact-checking.\r\n\r\nIdeal starting date: March/April 2017\r\nDuration: 4-6 months\r\nAdvisor: Xavier Tannier (LIMSI-CNRS)\r\nLocation: LIMSI, Orsay, Univ. Paris-Saclay1\r\n\r\nContext (ANR Project ContentCheck)\r\n\r\nFact checking is the task of assessing the factual accuracy of claims,\r\ngenerally made by public figures such as politicians, entrepreneurs,\r\netc. Fact-checking is part and parcel of journalists\' everyday work,\r\neither while working independently on an article, or as part of\r\nvetting done in the newsroom before publication, to prevent the\r\npublication of innacurate information. Modern factchecking is faced\r\nwith a triple revolution in terms of scale, complexity, and\r\nvisibility: many more claims are made and disseminated through Web and\r\nsocial media, they represent a complex reality and their investigation\r\nrequires using multiple heterogeneous data source. Our project\r\n(https://team.inria.fr/cedar/contentcheck/) brings together academic\r\nlabs with expertise in data management, natural language processing,\r\nautomated reasoning and data mining, and a fact-checking team of\r\njournalists from a major French Web media.\r\n\r\nIn recent years, journalists and the computer scientists started\r\ntalking to each other in order to identify which technologies could\r\nhelp journalists\' everyday work. This space of exchanges is known as\r\nComputational Journalism [1]. At this level, it encompasses very\r\ndiverse uses and tools such as learning how to correctly or better use\r\na database, producing simple spreadsheet-based visuali1 sations that\r\nare however personalized or better adapted to Web format, optical\r\ncharacter recognition for scanned texts in order to conduct\r\ncomputer-based keyword search or using statistics to analyse public\r\ndata from an interesting point of view, thus highlighting interesting\r\ntrends. These latter uses are referred to by the term Data Journalism\r\n[2].\r\n\r\nDescription\r\n\r\nThe process of fact checking requires many challenging steps; one of\r\nthem is to separate factual claims from opinions, beliefs, hyperboles,\r\nquestions, etc. and to discern which are \"check-worthy\", i.e. deserve\r\nto be considered and checked by the journalists [3].\r\n\r\nThe intern will work on this particular task: (s)he will build a tool\r\nextracting automatically the check-worthy claims and classifying them\r\nbetween different predefined classes (such as \"doubtful number\",\r\n\"doubtful fact\", \"opinion\", \"contextualization needed\", etc.), in\r\norder to make the watch easier for the journalist.\r\n\r\nExamples of claims to classify could be:\r\n\r\n- \"40 % de la taxe ont été détourné pour rémunérer le capital d\'une\r\nsociété italienne privée\" (number to check)\r\n\r\n- \"25 % du chiffre d\'affaires d\'Amazon se fait le dimanche.\" (number\r\nto check) \"On peut continuer à ne vouloir laisser travailler que les\r\nmultinationales anglo-saxonnes qui paient peu d\'impôts dans notre pays\r\nle dimanche mais ça n\'est pas la bonne solution.\" (opinion, need for\r\ncontextualization)\r\n\r\n- \"J\'ai été le premier avec Wolfgang Schäuble à signer une lettre pour\r\nque nous soyions capables de mettre en place cette coopération\r\nrenforcée à onze.\" (fact to check)\r\n\r\n- \"Je veux abroger le droit du sol\" (possible contradiction with a\r\nformer claim by the same person)\r\n\r\n- \"Je ne peux pas accepter que les Etats-Unis soient devenus du point\r\nde vue de l\'énergie indépendants grâce au gaz de schiste et que la\r\nFrance ne puisse pas profiter de cette nouvelle énergie\" (opinion,\r\nneed for contextualization)\r\n\r\n2 Dataset\r\n\r\nA labeled dataset in French will be provided by our partners from the newspaper\r\nLe Monde. It will contains political claims coming from different sources:\r\n- Newspaper articles\r\n- Debates\r\n- Speeches\r\n- Twitter and other social networks\r\n- etc.\r\n\r\nApproach\r\n\r\nWe will model this problem as a classication task and follow a\r\nsupervised learning approach to tackle it.\r\n\r\nApplication\r\n\r\nWe are particularly interested in candidates with a solid background\r\nin computer science and strong programming skills, having a good\r\nknowledge of machine learning and/or natural language processing.\r\n\r\nAs most of the data are in French, knowledge of French basics is a plus.\r\nApplications should include:\r\n- Cover letter outlining interest in the position\r\n- Names of two referees\r\n- Curriculum Vitae (CV)\r\nThe intern will be given a \"bonus\" (was 546,01 e in 2016) + half a \"Navigo\"\r\n(or \"Imagine R\") pass.\r\nContact for questions and applications:\r\nXavier.Tannier[at]limsi.fr\r\n\r\n3 References\r\n[1] Sarah Cohen, James T. Hamilton, and Fred Turner. Computational Journalism. Communications of the ACM, 54(11):66-71, 2011.\r\n[2] Jonathan Gray, Lucy Chambers, and Liliana Bounegru. The Data Journalism Handbook. O\'Reilly, 2012.\r\n[3] Naeemul Hassan, Chengkai Li, and Mark Tremayne. Detecting Checkworthy Factual Claims in Presidential Debates. In Proceedings of the 24th\r\nACM International Conference on Information and Knowledge Management\r\n(CIKM 2015), Melbourne, Australia, October 2015.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(374, '2016-12-14', 'LIMSI', 'Orsay', 'Stage de master 2\r\n\r\nRetrouver la source des trending topics sur les réseaux sociaux ou sur le web\r\n\r\nMots-clés : traitement automatique des langues, extraction d\'information,\r\npropagation d\'information, graphes, Twitter, réseaux sociaux.\r\nDate de démarrage : Mars/avril 2017\r\nDurée : 4-6 months\r\nEncadrant : Xavier Tannier (LIMSI-CNRS)\r\nLieu : LIMSI, Orsay, Univ. Paris-Saclay1\r\n\r\nContexte \r\n\r\nLes réseaux sociaux tels que Twitter ou Facebook, mais également\r\ncertains sites web, sont devenus des sources d\'information et de\r\ndésinformation massive. De nombreuses rumeurs y sont lancées, des\r\nfaits y sont déformés ou manipulés, et ce dans de nombreux domaines,\r\ndans le but de nuire à des personnes ou à des organisations, mais\r\négalement de servir des idées politiques.  Le \"fact-checking\" est une\r\ndiscipline consistant à vérifier la véracité des déclarations faites\r\npar des personnalités publiques ou des rumeurs qui se propagent,\r\nnotamment sur les réseaux sociaux. Une tâche importante est de\r\nremonter jusqu\'à la source d\'une information, pour vérifier si cette\r\nsource est unique ou multiple et si elle est digne de confiance ou\r\npas.\r\n\r\nDescription\r\n\r\nLe travail proposé consiste à réaliser un système semi-automatique\r\npermettant, a partir d\'un thème ou d\'un document fourni par\r\nl\'utilisateur, de remonter dans la mesure du possible jusqu\'à la\r\nsource de cette information (un tweet, un blog, etc.).  Il s\'agira\r\ndonc de construire un graphe de citation et de référence basé sur le\r\ncontenu textuel des documents (principalement, issus de réseaux\r\nsociaux et de pages web). Des outils déjà existants, comme un\r\nextracteur de citations et de sources dans les articles, pourront être\r\nutilisés.  L\'automatisation complète d\'un tel système étant un\r\nproblème très complexe, nous considérons que la construction de ce\r\ngraphe pourra être guidée par l\'utilisateur, qui validera ou\r\ninvalidera les propositions du système, guidant ainsi la progression\r\nvers la source supposée de l\'information.\r\n\r\nProfil\r\n\r\nNous recherchons un(e) étudiant(e) intéressé(e) par le traitement de\r\ncontenu en langage naturel et par la manipulation de données issue des\r\nréseaux sociaux.  La personne retenue devra avoir des compétences\r\nsolides en programmation et la volonté d\'apprendre de nouveaux outils\r\net de nouvelles approches. Elle manipulera les API d\'interrogation\r\nTwitter et/ou Facebook ainsi que des outils de traitement automatique\r\ndes langues. Les compétences en programmation ne sont cependant pas le\r\nseul critère, et la personne retenue devra également faire preuve de\r\ncréativité et d\'esprit d\'analyse.\r\n\r\nLes candidatures doivent comporter :\r\n- Une lettre de motivation\r\n- Le nom de deux personnes référentes\r\n- Un curriculum citae (CV)\r\nLe stagiaire retenu recevra une \"gratification\" (qui était de 546,01 ¤ en 2016)\r\nainsi que le remboursement de la moitié du pass \"Navigo\" ou \"Imagine R\".\r\nPour toute question ou candidature: Xavier.Tannier[at]limsi.fr'),
(375, '2016-12-14', 'EDF R&D', 'Chatou', 'OFFRE DE STAGE : Text-mining (TALN/Analyse sémantique) pour la\r\nmaintenance d\'éoliennes\r\n\r\nSUJET : Fouille de Textes non structurés pour constituer des bases de\r\ndonnées d\'événements de maintenance et d\'exploitation avec des\r\ntechniques de text-mining Traitement Automatique du Langage Naturel\r\n(TALN) et Analyse sémantique.\r\n\r\nCONTEXTE\r\nSur les éoliennes des paramètres issus de capteurs permettent de réguler\r\net de surveiller le fonctionnement des différents composants de\r\nl\'installation et sont historisés dans des entrepôts de données. Lors de\r\nl\'observation d\'un phénomène inhabituel ou d\'un paramètre proche des\r\nlimites prévues de fonctionnement, l\'exploitant consulte notamment ces\r\nséries de données numériques pour établir un diagnostic et un pronostic\r\nsur le phénomène sous-jacent et ses conséquences prévisibles. Son\r\nobjectif est de déterminer si l\'exploitation doit être adaptée ou\r\ninterrompue pour maintenance ou si elle peut continuer jusqu\'à la\r\nprochaine période de maintenance prévue. Pour interpréter les évolutions\r\nde ces paramètres dans le temps, il a besoin de prendre en compte des\r\ninformations de contexte sur les opérations de maintenance (c\'est-à-dire\r\névénements de maintenance) qui ont été réalisées sur l\'installation\r\nainsi que les événements d\'exploitation subis par l\'installation. Une\r\ngrande partie de ces événements sont présents dans des documents\r\ntextuels non structurés ou dans du texte libre d\'outils de maintenance.\r\n\r\nL\'objectif du stage est de contribuer à la reconstitution de bases\r\nd\'événements de maintenance et d\'exploitation à partir de corpus\r\ntextuels non structurés. Il s\'agit de mettre en oeuvre des techniques de\r\nfouille de données textuelles ou text-mining non pas statistiques (ou\r\npas uniquement) mais de traitement automatique du langage naturel (TALN)\r\net d\'analyse sémantique afin de retrouver ces évènements présents dans\r\nles textes pour reconstituer ces bases d\'évènements de maintenance et\r\nd\'exploitation des installations.\r\n\r\nUn événement est une combinaison d\'informations, comme par exemple pour\r\nla maintenance, une date, un composant d\'un matériel, un type\r\nd\'opération de maintenance et une action (prescription, réalisation,\r\n...). Certaines de ces informations peuvent être corroborées par des\r\ninformations structurées disponibles dans d\'autres parties du système\r\nd\'information (base de données de pièces de rechange...). Des documents\r\npeuvent ne contenir aucune des informations recherchées alors que\r\nd\'autres documents peuvent en contenir plusieurs qu\'il ne faudra pas\r\nmélanger.\r\n\r\nOBJECTIF ET DESCRIPTIF DU STAGE\r\nL\'objectif est de réaliser un démonstrateur d\'extraction d\'informations\r\ncomplexes (événements, ou combinaisons d\'informations) à partir de\r\ndocuments textuels non structurés de maintenance et d\'exploitation pour\r\nconstituer des bases de données en utilisant des techniques de fouille\r\nde texte de type TALN et d\'Analyse Sémantique.\r\n\r\nLe travail de stage consiste à :\r\n- modéliser le domaine, la structure des textes, la structure cible des\r\n  données à trouver dans les textes pour constituer les bases.\r\n\r\n- mettre en oeuvre les éléments nécessaires dans un ou des outils et\r\n  notamment de réaliser des pré-traitements sur les corpus à analyser,\r\n  d\'utiliser des ressources, modèles, annexes, ontologies et notamment\r\n  d\'écrire des règles dans le formalisme du logiciel utilisé (logiciel\r\n  de text mining TALN/analyse sémantique).\r\n\r\n- positionner la solution mise en oeuvre dans l\'étude vis-à-vis des\r\n  autres solutions déjà mises en oeuvre par EDF sur d\'autres projets.\r\n\r\nETUDIANTS CONCERNES : MASTER, ou Fin d\'études ingénieur.\r\n\r\nCOMPETENCES SOUHAITEES : La réalisation de cette étude nécessite des\r\ncompétences en modélisation des connaissances, en techniques de fouille\r\nde textes, en text-mining de type Traitement Automatique du Langage\r\nNaturel et d\'Analyse Sémantique, ainsi que des techniques et outils du\r\nweb sémantique, notamment RDF).\r\n\r\nINFORMATION ET CANDIDATURE :\r\nEn postulant sur cette offre sur le site internet edf recrute :\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres\r\nLa référence de cette offre est : ST-16-8884-SME\r\nLien vers cette offre :\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-16-8884-SME\r\n\r\nCONDITIONS DU STAGE : Le stage se déroulera au sein des locaux d\'EDF R&D\r\nà Chatou et sera rémunéré.\r\n\r\nDUREE : 5 mois.'),
(376, '2016-12-14', 'Forma Libre / LIG', 'Grenoble', 'Sujet de stage Master 2 / PFE ingénieur\r\nProlongement possible avec thèse en contrat CIFRE\r\n\r\nClaroline.com http://claroline.com/ / Laboratoire d\'Informatique de\r\nGrenoble\r\n\r\nÉtude et usages d\'un système de gestion lexicale intégré à une\r\nplateforme d\'apprentissage des langues et acquisition du lexique\r\n\r\nMathieu Mangeot (LIG), Mathieu Loiseau (LIDILEM), Pauline Ballot (Forma Libre)\r\n\r\nEncadrement\r\n \r\nLe stage est réalisé à Grenoble :\r\n- 1 jour par semaine dans l\'entreprise Forma Libre\r\n  (http://claroline.com), éditrice de la plateforme http://claroline.net\r\n\r\n- 4 jours par semaine au laboratoire LIG, sur le campus de St Martin\r\n  d\'Hères.\r\n\r\nIl sera encadré par un chercheur du LIG et un chercheur du LIDILEM ;\r\nUne réunion mensuelle de tous les acteurs sera planifiée. Des réunions\r\nsupplémentaires pourront être programmées en fonction de l\'avancement\r\ndes travaux.\r\n\r\nContexte\r\n\r\nLe projet de recherche LexInnova est né d\'un constat dans le cadre du\r\nprojet IDEFI Innovalangues initié en 2012 : le besoin de lexiques dans\r\nles environnements d\'apprentissage en ligne. En effet, de nombreux\r\nusages des lexiques ont émergé au cours du projet. Dans le cadre de jeux\r\noù les informations morphologiques sont primordiales, les informations\r\nsémantiques comme la définition ont également été utilisées. Dans\r\ncertaines approches, la progression des étudiants est strictement\r\nindexée sur l\'acquisition du lexique (Goudin et Lê, 2016). En outre, les\r\napprenants de langues consultent fréquemment des dictionnaires et, au\r\nfur et à mesure de leurs apprentissages, ils se constituent également un\r\nlexique personnel sur des supports disparates (flash cards, bristol) ou\r\nsur support dématérialisé (Quizzlet, Anki). En classe, des enseignants\r\ndistribuent des listes de vocabulaire et créent des exercices à partir\r\nde ces listes. Le lexique apparaît ainsi comme un élément central de\r\ntout environnement d\'apprentissage des langues. Par conséquent, la mise\r\nen place d\'un lexique commun offrirait des avantages considérables. Les\r\noutils de lexique peuvent être également utilisés par des apprenants\r\npour toute activité d\'apprentissage de manière générale. En effet, la\r\ndécouverte d\'un nouveau domaine est facilitée par la création d\'une\r\nterminologie appropriée (Yassine-Diab, Alazard-Guiu et Loiseau,\r\n2016). Par ailleurs, la prise en charge du lexique par l\'environnement\r\nd\'apprentissage permet à l\'apprenant de se focaliser sur d\'autres\r\nopérations beaucoup plus fonctionnelles que le recensement du\r\nvocabulaire à des fins d\'évaluation sommative. Enfin, un tel outil\r\npermet à la communauté enseignante et apprenante de mutualiser et\r\nréutiliser les données antérieures et/ou partagées.\r\n\r\nEnjeux de recherche\r\n\r\nCe constat, effectué dans un premier temps par Emmanuelle Eggers,\r\nenseignante d\'espagnol, a donné lieu à la création d\'un chantier\r\némergent au sein du projet Innovalangues et a regroupé une équipe\r\nd\'enseignants et chercheurs des laboratoires LIDILEM et LIG travaillant\r\nsur les thématiques de la didactique des langues, des jeux sérieux et\r\ndes bases lexicales.\r\n\r\nDans le paradigme institutionnel de la généralisation et de la\r\nmassification des apprentissages en ligne, l\'enseignement-apprentissage\r\ndes langues demeure le parent pauvre comme l\'illustre remarquablement\r\nl\'existence d\'un modeste glossaire sur les plateformes telles que\r\nMoodle. Un tel outil est conçu pour recenser et définir la terminologie\r\nassociée à un cours donné, mais pas pour les réutiliser dans d\'autres\r\nformations et encore moins pour constituer un lexique systématique dans\r\nle cadre de l\'apprentissage d\'une langue. Et c\'est d\'autant plus\r\ndommageable au regard des enjeux de la formation des étudiants à leur «\r\nlangue de spécialité »\r\n\r\nLa mise en oeuvre d\'un lexique intégré à une plateforme d\'apprentissage\r\npermet d\'obtenir un module central au coeur des enjeux et des usages\r\naussi bien de la communauté apprenante qu\'enseignante. En se basant sur\r\nl\'observation des pratiques relevées ci-dessus, l\'analyse des outils\r\nexistants et les premiers résultats du chantier déjà lancé depuis\r\nl\'automne 2014, il s\'agirait de valider l\'hypothèse selon laquelle la\r\nmise à disposition des étudiants d\'un outil intégré faciliterait le\r\ndéveloppement de la compétence lexicale en langue-cible et\r\nl\'autonomisation de l\'apprentissage.\r\n\r\nQuelques premiers scénarios d\'utilisation ont été établis. Ceux-ci ont\r\ndonné lieu à la définition de plusieurs concepts liés aux ressources\r\nlexicales : le dictionnaire de référence, somme des informations\r\nvalidées de la base lexicale ; le lexique institutionnel qui synthétise\r\nle point de vue sur le lexique d\'une institution ; le lexique de groupe,\r\nun lexique dynamique qui peut être modifié par un ensemble\r\nd\'utilisateurs (groupe d\'apprenants) ; le lexique personnel, lexique\r\nd\'un apprenant, qui seul pourra modifier son contenu et décider de sa\r\nvisibilité.\r\n\r\nÀ la suite de ces réflexions, un premier prototype fonctionnel2 a été\r\ndéveloppé en utilisant la plateforme Jibiki (Zhang et\r\nal. 2014). L\'interface homme-machine reprend pour l\'instant celle de\r\nl\'environnement en cours de développement dans le projet\r\nInnovalangues. Seules les fonctionnalités de consultation du\r\ndictionnaire de référence et d\'accès au lexique personnel (consultation,\r\najout, modification) ont été implantées. Une démonstration a été\r\neffectuée lors du comité de pilotage du projet Innovalangues de janvier\r\n2016. Les réactions du public ont été très encourageantes.\r\n\r\nUne publication décrivant ces travaux (Mangeot et al., 2016) a été\r\négalement acceptée à l\'atelier ELTAL 2016 (Enseignement des Langues et\r\nTraitement Automatique des Langues).\r\n\r\nLe projet est maintenant à un tournant : il a montré son intérêt\r\nscientifique à travers une publication et sa faisabilité avec un premier\r\nprototype. Il a ouvert de nombreuses pistes de réflexion pour la\r\nsuite. Pour les approfondir dans une démarche de\r\nrecherche-développement, il faut intégrer ce prototype à une plateforme\r\nafin d\'en observer les usages et de les lier aux retombées en termes\r\nd\'acquisition. Pour ce faire, nous nous sommes adressés à l\'entreprise\r\nForma-Libre (dont une antenne a été établie à Grenoble) assurant le\r\ndéveloppement et le maintien de la plateforme Claroline Connect utilisée\r\nau sein d\'Innovalangues. L\'Université Grenoble Alpes (UGA) est également\r\nmembre du consortium Claroline Connect.\r\n\r\nIntérêt des industriels pour l\'outil et l\'usage\r\n\r\nSi notre problématique majeure ici est celle de l\'apprentissage des\r\nlangues, la gestion d\'un lexique d\'apprentissage dépasse largement le\r\ncadre de la didactique des langues. En effet, la généricité de la base\r\nlexicale Jibiki permettra de créer des glossaires techniques pour\r\nn\'importe quel domaine de compétence.\r\n\r\nPour l\'entreprise Forma-Libre, il s\'agit d\'une opportunité d\'intégrer à\r\nses produits des outils issus de la recherche de différents laboratoires\r\nde l\'UGA, qui bénéficieront ainsi d\'une communautés\r\nd\'usagers. Forma-Libre pourra ainsi se positionner en tant qu\'acteur\r\nmajeur du e-learning à travers des outils nettement plus avancés que la\r\nconcurrence. Toutefois, le recours exclusif à des technologies libres\r\npermet de ne pas limiter les possibilités de transfert à l\'entreprise en\r\nquestion (il est imaginable que Moodle intègre nos technologies).\r\n\r\nL\'obtention de financements pour ce projet permettrait de conforter la\r\ndynamique qui s\'est mise en place dans le cadre d\'Innovalangues et\r\ndonnerait un cadre à une collaboration plus poussée sur ces thématiques\r\nentre le LIDILEM, le LIG et des acteurs industriels tels que le\r\nconsortium Claroline Connect à travers Forma-Libre.\r\n\r\nTravail envisagé\r\n\r\nLe travail envisagé dans le contexte du stage de master 2 de 6 mois est\r\nle suivant :\r\n\r\n- consolidation et extension du prototype actuel pour une utilisation\r\n  dans des conditions réelles en classe de langue. Emmanuelle Eggers a\r\n  lancé une expérimentation de création de lexique collaboratif avec ses\r\n  étudiants de L2. Celle-ci se fait actuellement avec des fichiers\r\n  Excel. L\'objectif est d\'utiliser le prototype consolidé pour la\r\n  rentrée de septembre 2017. A des fins comparatives, un relevé\r\n  similaire de ces données - augmentées d\'une granularité plus fine avec\r\n  les sinogrammes - est effectué en parallèle en L0 de\r\n  mandarin. Certaines fonctionnalités telles que la gestion des lexiques\r\n  de groupe, la recherche multicritères, les exports de sélections de\r\n  données pour impression, etc. sont indispensables. Pour cette partie,\r\n  il est nécessaire de recueillir les besoins des utilisateurs\r\n  principaux (enseignants de langue) avant l\'implémentation.\r\n\r\n- réimplémentation du prototype actuel comme module de la plateforme\r\n  Claroline Connect. Dans les deux cas, le langage utilisé est\r\n  PHP. Cette partie pourra se faire dans les locaux de l\'entreprise\r\n  Format Libre pour plus de proximité avec les développeurs de la\r\n  plateforme.\r\n\r\n- expérimentation : l\'utilisation en classe de langue dans les groupes\r\n  d\'Emmanuelle Eggers et dans le cadre des cours de mandarin permettra\r\n  le recours à des groupes contrôles pour mesurer les acquisitions (le\r\n  partenariat fort avec des enseignants permettra également d\'estimer la\r\n  pérennité des dites acquisitions en réeffectuant nos post-tests de\r\n  manière longitudinale).\r\n\r\nCe travail pourra éventuellement être poursuivi et élargi dans le cadre\r\nd\'un doctorat en contrat CIFRE entre l\'entreprise Forma Libre et les\r\nlaboratoire LIG et LIDILEM (en co-encadrement).\r\n\r\nRéférences\r\nGoudin, Y. et Lê, T.M. (2016). « Jouer avec le sacré ? Le sinogramme à\r\nl\'ère du jeu sérieux » Haydée Silva et Mathieu Loiseau (dir.),\r\nRecherches et applications, n°59, pp. 145-160.\r\n\r\nLoiseau, M., Zampa, V. et Rebourgeon, P. (2015). « Magic Word : premier\r\njeu développé dans le cadre du projet Innovalangues », ALSIC, vol. 18,\r\nn°2. DOI :10.4000/alsic.2828. Disponible en ligne :\r\nhttp://alsic.revues.org/2828.\r\n\r\nMangeot, M., Bellynck, V., Eggerss, E., Loiseau, M. et Goudin,\r\nY. (2016). « Exploitation d\'une base lexicale dans le cadre de la\r\nconception de l\'ENPA Innovalangues » Ivan Smilauer et Jovan Kostov\r\n(dir.), Actes de la conférence conjointe JEP-TALN-RECITAL 2016, vol. 9 :\r\nELTAL, pp. 48-64. Disponible en ligne :\r\nhttps://jep-taln2016.limsi.fr/actes/Actes%20JTR-2016/V09-ELTAL.pdf.\r\n\r\nZhang Y., Mangeot M., Bellynck V. et Boitet C. (2014). Jibiki-LINKS : a\r\ntool between traditional dictionaries and lexical networks for modelling\r\nlexical resources. Proceedings of the 4th Workshop on Cognitive Aspects\r\nof the Lexicon (CogALex) 2014 (Eds. Michael Zock, Reinhard Rapp, Chu-Ren\r\nHuang), Dublin, Ireland, 23 August 2014, 12 p.\r\n\r\nContact candidatures\r\n\r\nMathieu.Mangeot@imag.fr'),
(377, '2016-12-19', 'Cirad', 'Montpellier', '(Version PDF disponible sur http://textmining.biz/Staff/Roche/STAGES/Stages2017/PADI-web_Stage_Master_2017.pdf)\r\n\r\nStage Professionnel de Master 2 (Informatique) - 2017 :\r\n\r\nExtension de PADI-Web1\r\n\r\nExtension d\'un logiciel de veille sanitaire pour analyser\r\nl\'émergence et la propagation de maladies animales\r\n\r\nResponsables Inra et Cirad : Sylvain Falala, Mathieu Roche\r\nEncadrants liés au projet : Alizé Mercier, Jocelyn de Goër de Hervé\r\nCirad, Campus de Baillarguet, Montpellier\r\nsylvain.falala@cirad.fr, mathieu.roche@cirad.fr, alize.mercier@cirad.fr,\r\njocelyn.degoer@inra.fr\r\n\r\n1) Contexte\r\n\r\nLa veille en santé animale, et notamment la détection précoce\r\nd\'émergences au niveau mondial d\'agents pathogènes, est l\'un des\r\nmoyens permettant de prévenir l\'introduction en France de dangers\r\nsanitaires.\r\n\r\nDans le cadre de la thématique \"Veille sanitaire internationale\" de la\r\nPlateforme nationale d\'épidémiosurveillance en santé animale\r\n(Plateforme ESA)4, le Cirad, l\'Anses5 et la DGAl6 développent depuis\r\n2013 un système de veille automatique du Web qui effectue : (1) le\r\nrecueil quotidien de dépêches épidémiologiques provenant de sources\r\nnon officielles, incluant les médias électroniques, (2) l\'extraction\r\nautomatique d\'informations (nom de maladie ou symptômes, lieu, date et\r\nespèce touchée) issues de ces dépêches et (3) une restitution\r\nsynthétique et agrégée de l\'information : cartes, séries\r\nspatiotemporelles.\r\n\r\nActuellement, cinq maladies animales exotiques sont ainsi surveillées,\r\nmais d\'autres pourraient l\'être aisément, car l\'outil est développé de\r\nfaçon générique. Ce système sera utilisé par la Plateforme ESA pour la\r\nFrance et par le réseau de vétérinaires CaribVet situé dans les\r\nCaraibes.\r\n\r\n2) Approche et technologies utilisées\r\n\r\nLe recueil des dépêches s\'appuie sur des requêtes constituées de\r\nmots-clés de maladies, d\'hôtes et de symptômes pour collecter, avec un\r\nscript PHP, des articles issus de Google News. Ces mots-clés ont été\r\ndéfinis par des experts et/ou par des méthodes de fouille de textes\r\n(Arsevska et al., 2016).  Chaque article est prétraité et normalisé\r\n(suppression de balises HTML, reconnaissance de la langue, etc.) avant\r\nd\'être stocké dans une base de données MySQL.  L\'extraction\r\nd\'information dans les dépêches collectées identifie les éléments clés\r\n(noms de maladies, lieux, dates, nombres et espèces d\'animaux\r\ntouchées). Elle repose sur des dictionnaires dédiés et des règles\r\npréalablement construites par un processus de fouille de données. La\r\ntechnologie utilisée est Java.  Une interface Web (développée avec\r\nPHP, HTML, CSS, JavaScript et Ajax) permet de paramétrer le processus\r\nde recueil, de consulter les articles collectés et de récupérer sous\r\nforme de tableaux les informations extraites (cf. Figure 1 et 2).\r\n\r\nFigure 1 : interface de recherche multicritères (nom de maladie,\r\nsymptôme, hôte, source, période...) pour consulter les articles\r\nrecueillis\r\n\r\nFigure 2 : interface de consultation d\'une dépêche avec identification\r\nautomatique des informations clés (lieu, date, maladie, espèce, nombre\r\nde cas...)\r\n\r\n3) Travail à réaliser\r\n\r\nPlusieurs tâches de différentes natures sont à effectuer, par ordre de\r\npriorité :\r\n\r\n1-Gestion des langues (Technologies à utiliser : PHP, Java)\r\nIntégration du français et de l\'espagnol au niveau des requêtes et de\r\nl\'extraction d\'information.\r\n\r\n2-Extension de l\'interface (Framework Bootstrap, PHP, HTML, CSS,\r\nJavaScript, Ajax) \r\nAjout d\'outils visuels, notamment une carte mondiale\r\ndynamique indiquant les foyers émergents en temps réel.\r\n\r\n3-Classification automatique des documents (Java) \r\nIntégration de briques logicielles de méthodes de classification\r\nautomatique afin d\'identifier les documents pertinents à traiter.\r\n\r\n4-Optimisation du recueil des documents (PHP)\r\nParallélisation du moteur de webscraping.\r\nExtensions de la collecte via des réseaux sociaux, en particulier Twitter.\r\n\r\n4) Cadre et environnement de travail\r\n\r\nLe stage se déroulera au Cirad, sur le campus de Baillarguet, à\r\nMontferrier-sur-Lez, dans l\'Unité Animal, Santé, Territoires, Risques\r\net Ecosystèmes (ASTRE). Le site est accessible depuis Montpellier par\r\n2 lignes de bus.  Le (la) stagiaire sera encadré(e) par des\r\ninformaticiens du Cirad et de l\'Inra, ainsi que des épidémiologistes\r\ndu Cirad et de l\'Anses.  Une gratification mensuelle sera attribuée au\r\nstagiaire. Un restaurant d\'entreprise sera à sa disposition.\r\n\r\nRéférence sur la plateforme de veille PADI\r\nhttp://www.cirad.fr/nos-recherches/resultats-de-recherche/2016/veille-sanitairesur-le-web-un-outil-pour-prevenir-la-propagation-des-maladies-animales\r\n\r\nRéférences\r\n\r\nARSEVSKA E., ROCHE M., HENDRIKX P., CHAVERNAC D., FALALA S., LANCELOT\r\nR. & DUFOUR B. (2016). Identification of terms for detecting early\r\nsignals of emerging infectious disease outbreaks on the web. Computers\r\nand Electronics in Agriculture, 123, 104 - 115.\r\n\r\nFALALA S., DE GOER DE HERVE J., ARSEVSKA E., ROCHE M., RABATEL J.,\r\nCHAVERNAC D., HENDRIKX P., DUFOUR B., LANCELOT R., LEFRANCOIS T.\r\n(2016). Système de veille sanitaire pour analyser l\'émergence et la\r\npropagation de maladies animales. Atelier IN-OVIVE 4ème édition,\r\nConférence IC2016, 7 juin 2016, Montpellier.'),
(378, '2016-12-19', 'LATTICE', 'Paris', 'Offre de stage en TAL (M1 ou M2) : développement d\'un chunker propre à\r\nl\'oral à partir d\'un corpus de référence corrigé manuellement.\r\n\r\n----------------------------------\r\n\r\nAu cours des dernières décennies, un nouveau système, les shallow\r\nparsers (analyseurs peu profonds) a été développé pour l\'analyse\r\nsyntaxique. Aussi appelés chunkers, l\'objectif de ces parseurs est de\r\nsegmenter l\'énoncé en constituants minimaux (chunks) tout en analysant\r\nleur structure interne. Il s\'agit d\'une analyse syntaxique qui se base\r\nsur les parties du discours, donc sur un étiquetage morphosyntaxique\r\npréalable.\r\n\r\n \r\n\r\nObjectif : développer un nouveau chunker par apprentissage automatique\r\navec les CRFs.\r\n\r\nLes données de référence : transcriptions de l\'oral annotées en chunks\r\npar TreeTagger, corrigées et adaptées à de nouvelles conventions\r\n\r\nLes informations (features) qui peuvent être exploitées pour\r\nl\'apprentissage sont :\r\n\r\n- mot (token) : Moti-2, Moti-1, Moti , Moti+1, Moti+2\r\n\r\n- étiquette POS non corrigée attribuée par un étiqueteur le plus récent\r\n  propre à l\'oral :\r\n\r\nPOSi-2, POSi-1, POSi, POSi+1, POSi+2\r\n\r\n- chunk correct : Chunki-2, Chunki-1, Chunki, Chunki+1, Chunki+2\r\n\r\nD\'autres propriétés seront définies au cours du stage.\r\n\r\n---------------------------\r\n\r\nEncadrement du stage : Isabelle Tellier (LaTTiCe) et Iris\r\nESHKOL-TARAVELLA (LLL)\r\n\r\nFinancement : Projet ANR franco-allemand SegCor\r\n\r\nDurée : 6 mois\r\n\r\nDébut du stage : avril\r\n\r\nLieu : laboratoire LaTTiCe, Paris\r\n\r\n------------------------------\r\n\r\nLes CV sont à envoyer à isabelle.tellier@univ-paris3.fr et\r\niris.eshkol@univ-orleans.fr'),
(379, '2016-12-19', 'IRSTEA / LIPN', 'Clermont-Ferrand ou Villetaneuse', 'Deux stages M2 en Ingénierie des Connaissances et Traitement Automatique\r\ndes Langues sont proposés par l\'équipe COPAIN de l\'IRSTEA\r\n(http://www.irstea.fr/la-recherche/unites-de-recherche/tscf/systemes-information-communicants-agri-environnementaux)\r\net l\'équipe RCLN du LIPN (https://lipn.univ-paris13.fr/fr/rcln-3). Ils\r\nse dérouleront au choix soit à l\'IRSTEA à Clermont Ferrand, soit au LIPN\r\nà Villetaneuse (banlieue de Paris).\r\n\r\nAu moins une thèse financée démarrera en septembre 2017 sur ces sujets.\r\n\r\nLes stages doivent durer 6 mois au maximum. Ils seront conventionnés et\r\nindemnisés suivant les règles en vigueur. Les stages commenceront entre\r\nfévrier et avril 2017, la sélection se fera courant janvier.\r\n\r\nPour postuler sur un des stages, merci d\'envoyer un CV, un relevé de\r\nnotes récent et des éléments de motivation à Catherine Roussey ET Haïfa\r\nZargayouna.\r\n\r\nContacts : catherine.roussey@irstea.fr et\r\nhaifa.zargayouna@lipn.univ-paris13.fr\r\n\r\nContexte des stages: En France, le Grenelle de l\'environnement et le\r\nplan Ecophyto ont renforcé les réseaux nationaux de surveillance sur les\r\ncultures et les pratiques agricoles. Les Bulletins de Santé du Végétal\r\nsont une des modalités mises en place par ces réseaux de\r\nsurveillance. Le Bulletin de Santé du Végétal (BSV) est un document\r\nd\'information à la fois technique et réglementaire, qui présente une\r\nsynthèse interprétée des observations effectuées sur les cultures. Les\r\ninformations contenues dans les BSV intéressent les experts en agronomie\r\npour suivre l\'évolution de l\'état sanitaire des cultures en France. Dans\r\nle projet VESPA (2012-2016), l\'équipe COPAIN a travaillé sur la collecte\r\ndu corpus des BSV disséminé sur le Web, puis leur annotation semi\r\nautomatique pour permettre de rechercher facilement des BSV répondant à\r\ncertains critères (culture, lieu, période, etc.). Le corpus, un\r\nthésaurus des cultures, un jeux de données représentant les régions de\r\nFrance et des annotations spatio-temporelles ont déjà été publiés sur le\r\nWeb des données liées (http://ontology.irstea.fr/).\r\n\r\nSujet 1 : Annotation sémantique de BSV\r\n\r\nLe but de ce stage est d\'enrichir la base d\'annotations existante en\r\ns\'aidant d\'outils d\'annotations automatiques (ou semi-automatiques)\r\ntravaillant sur le contenu des BSV. Il s\'agit, dans un premier temps, de\r\ndéterminer les différents types d\'annotations nécessaires, puis de les\r\nclasser, par exemple, selon le nombre d\'arguments (unaire, binaire,\r\nternaire), la portée (locale, globale) et la difficulté (en fonction du\r\ntraitement/raisonnement requis). En fonction de cette première analyse,\r\ndes traitements sur le corpus seront à implémenter afin d\'identifier les\r\nstructures utiles pour la génération des annotations.\r\n\r\nDans un deuxième temps, il faudra tester des outils de l\'état de l\'art\r\n(tel que l\'outil OMTAT développé au LIPN\r\nhttp://tal.lipn.univ-paris13.fr/omtat/). Ces tests ont un double\r\nobjectif : d\'une part, repérer les types d\'annotations traités par ces\r\noutils et d\'autre part évaluer la couverture des référentiels dont nous\r\ndisposons. \r\nLa phase de test sera suivie par une phase d\'enrichissement\r\nsemi-automatique des annotations.\r\n\r\n\r\nSujet 2 : Alignement de référentiels agricoles fondé sur les textes\r\n\r\nLe but du stage est de développer des bases de connaissances intégrant\r\ndes référentiels déjà disponibles sur le LOD. \r\nIl s\'agit, dans un premier temps, d\'extraire des relations de\r\ncorrespondance (autres que l\'équivalence) entre les référentiels\r\nsémantiques existants (thésaurus des cultures, plant trait ontology, ..)\r\nau regard du corpus BSV. \r\n\r\nCe travail s\'appuiera sur les méthodes et outils développés au LIPN et\r\nplus particulièrement la méthode d\'alignement d\'ontologies à partir de\r\ntextes (TOM : Text-based Ontology Mapping) proposée dans le cadre de la\r\nthèse de Sarra Ben Abbes [Ben Abbes, 2013].\r\n\r\nDans un deuxième temps, il s\'agit de s\'appuyer sur les correspondances\r\nproduites pour proposer des transformations de sources en s\'aidant de\r\npatrons de conception ontologique du domaine (thèse de Fabien Amarger\r\n[Amarger, 2015]) ainsi que des anti-patrons destinés à détecter les\r\nerreurs et anomalies dans les ressources.'),
(380, '2017-01-03', 'IRIT', 'Toulouse', 'Offre de stage M2 :\r\n\r\nDétection automatique de comportements dépressifs dans les réseaux\r\nsociaux\r\n\r\nEncadrement : Farah Benamara (benamara@irit.fr), Josiane Mothe \r\n(josiane.mothe@irit.fr),\r\nVéronique Moriceau (moriceau@limsi.fr) & Faneva Ramiandriosa \r\n(r.faneva.mahery@gmail.com)\r\n\r\nLocalisation : IRIT, Toulouse\r\n\r\nLa dépression est une affection courante qui concerne environ 350\r\nmillions de personnes dans le monde selon les estimations de l\'OMS\r\n(Organisation Mondiale de la Santé). La détection de ce trouble est donc\r\nun enjeu majeur de santé publique.  Plusieurs recherches ont démontré\r\nl\'existence d\'un lien fort entre l\'état dépressif d\'un individu et son\r\nexpression langagière, comme l\'usage excessif de pronoms personnels,\r\nl\'expression d\'émotions négatives ou encore le changement brusque dans\r\nla communication [1][2]. Nous proposons dans ce stage de repérer\r\nautomatiquement ces indices dans le but de détecter les comportements\r\ndépressifs à partir de messages postés sur les réseaux sociaux. Les\r\ndonnées utilisées seront issues de collections existantes en particulier\r\nen lien avec le challenge CLEF [3].\r\nUn des enjeux est de détecter le moment à partir duquel la personne peut\r\nêtre reconnue comme dépressive si elle l\'est. Une soumission à la tâche\r\ncorrespondant du programme international CLEF sera envisagée, en\r\nfonction des résultats obtenus.\r\n\r\nContact : envoyer CV à josiane.mothe@irit.fr, benamara@irit.fr,\r\nmoriceau@limsi.fr\r\n\r\n\r\nRéférences\r\n[1] J. W. Pennebaker, M. R. Mehl, and K. G. Niederho er. Psychological\r\naspects of natural language use: Our words, our selves. Annual Review of\r\nPsychology, 54(1):547--577, 2003.\r\n[2] Munmun De Choudhury, Michael Gamon, Scott Counts, Eric Horvitz:\r\nPredicting Depression via Social Media. Proceedings of the Seventh\r\nInternational AAAI Conference on Weblogs and Social Media. 2013\r\n[3] David Losada, Fabio Crestani, A Test Collection for Research on\r\nDepression and Language Use, Conference and Labs of the Evaluation\r\nForum, 2016.'),
(381, '2017-01-03', 'LIPN', 'Villetaneuse', 'Stage M2: Entraînement LASO pour l\'analyse en dépendances \"easy-first\"\r\n------------------------------------------------------------------------\r\n\r\n1 Contexte scientifique\r\n-------------------------\r\n\r\n  L\'algorithme /easy-first/ pour l\'analyse en dépendances [1]est un\r\n  algorithme glouton qui construit les arbres d\'analyse de manière\r\n  ascendante en prenant les décisions les plus faciles, celles qui\r\n  nécessitent le moins de contexte, en premier de façon à donner plus\r\n  d\'informations aux décisions ultérieures. Durant la phase\r\n  d\'apprentissage, on cherche des séquence d\'actions de construction qui\r\n  soit en accord avec les arbres observés dans le corpus\r\n  d\'entraînement. Si l\'une des actions génère un sous-arbre invalide,\r\n  alors le modèle est mis à jour (par exemple par une mise à jour de\r\n  type perceptron). L\'algorithme d\'apprentissage proprement dit\r\n  (ex. perceptron) se combine donc à une exploration des différentes\r\n  possibilités de construction incrémentale des structures.\r\n\r\n  Dans ce stage, on propose de reformuler le problème de l\'apprentissage\r\n  pour ce type de problème en suivant le paradigme LaSO (/learning as\r\n  search optimization/)[2] qui modélise précisément les problèmes\r\n  d\'apprentissage structuré nécessitant la recherche d\'une structure\r\n  intermédiaire avant sa validation par une observation, ici la séquence\r\n  d\'actions permettant de construire un arbre d\'analyse. le stage aura\r\n  aussi pour but de mesurer l\'apport de l\'utilisation d\'un réseau de\r\n  neurones récurrent pour la prédiction de la séquence d\'actions à\r\n  effectuer.\r\n\r\n  Profil recherché: Niveau M2, bonne connaissance d\'un langage de\r\n                    programmation (python ou c++ idéalement), un intérêt\r\n                    fort pour l\'apprentissage automatique appliqué au\r\n                    traitement automatique des langues.\r\n\r\n\r\n2 Administratif\r\n-----------------\r\n\r\n  Le stage aura lieu au LIPN (CNRS - Université Paris13 - Paris Sorbonne\r\n  Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le Roux\r\n  et/ou Nadi Tomeh.  Le/La stagiaire fera partie de l\'équipe de\r\n  recherche RCLN, membre du labex EFL (axe \"sémantique\r\n  computationnelle\"), dans la structure de recherche fédérative MathSTIC\r\n  de CNRS/Paris 13 (axe \"Optimisation et Apprentissage pour les contenus\r\n  numériques\").\r\n\r\n  Les candidatures (CV et lettre de motivation) doivent être adressées à\r\n  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17.'),
(382, '2017-01-03', 'LIPN', 'Villetaneuse', 'Stage M2: Paramétrisation CRF neuronal pour les analyseurs en\r\ndépendances de type graphe\r\n\r\n\r\n1 Contexte scientifique\r\n-------------------------\r\n\r\n  L\'analyse syntaxique en dépendances est une tâche essentielle en\r\n  traitement automatique des langues. Récemment, l\'utilisation de\r\n  réseaux de neurones récurrents a permis un regain d\'intérêt pour les\r\n  modèles d\'analyse structurellement plus simples, par exemple le\r\n  système de Kiperwasser et Goldberg[3]. la notion de contexte étendu\r\n  est très bien gérée par les réseaux, et le système grammatical n\'a\r\n  plus à prendre en compte ces contextes en interne, puisqu\'ils lui sont\r\n  donnés via les plongements lexicaux (/word embeddings/).\r\n\r\n  Le but de ce stage est d\'étudier la paramétrisation d\'un analyseur en\r\n  dépendances projectives par un modèle probabiliste de type CRF (champs\r\n  de Markov aléatoire), où les potentiels sont calculés par des réseaux\r\n  de neurones. Un tel système a déjà été proposé pour les grammaires\r\n  syntagmatiques. D\'autre part des systèmes neuronaux ont déjà été\r\n  proposés pour l\'analyse syntaxique en dépendances mais jamais avec un\r\n  modèle probabilistes global.\r\n\r\n  Profil recherché: Niveau M2, bonne connaissance d\'un langage de\r\n                    programmation (python ou c++ idéalement), un intérêt\r\n                    fort pour l\'apprentissage automatique appliqué au\r\n                    traitement automatique des langues.\r\n\r\n\r\n2 Administratif\r\n---------------\r\n\r\n  Le stage aura lieu au LIPN (CNRS - Université Paris13 - Paris Sorbonne\r\n  Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le Roux\r\n  et/ou Nadi Tomeh.  Le/La stagiaire fera partie de l\'équipe de\r\n  recherche RCLN, membre du labex EFL (axe \"sémantique\r\n  computationnelle\"), dans la structure de recherche fédérative MathSTIC\r\n  de CNRS/Paris 13 (axe \"Optimisation et Apprentissage pour les contenus\r\n  numériques\").\r\n\r\n  Les candidatures (CV et lettre de motivation) doivent être adressées à\r\n  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17.'),
(383, '2017-01-03', 'LIPN', 'Villetaneuse', 'Stage M2 : Réseaux de neurones avec attention pour la correction\r\nd\'orthographe et de grammaire\r\n\r\n\r\n1 Contexte scientifique\r\n-------------------------\r\n\r\n  La correction automatique d\'orthographe et de grammaire est un\r\n  problème difficile et important en traitement automatique des\r\n  langues. Elle facilite la construction de logiciels d\'aide à\r\n  l\'apprentissage de langues étrangères, comme elle permet de réduire le\r\n  bruit dans l\'entrée des outils de TAL ainsi améliorant leurs\r\n  performance, notamment sur les textes non-édités que l\'on peut trouver\r\n  sur le web. La difficulté de cette tâche provient de la grande\r\n  variabilité dans les types d\'erreur ainsi que leur dépendance\r\n  syntaxique et sémantique vis-à-vis du contexte.\r\n\r\n  Étant donné une phrase potentiellement erronée en entrée, certaines\r\n  approches utilisent des classifieurs (à base de règles ou appris\r\n  automatiquement) pour générer des corrections, en modélisant leurs\r\n  interactions avec, par exemple, un modèle de langue N-gram ou un\r\n  CRF. Les systèmes de traduction automatique statistique dits\r\n  phrase-based ont été utilisés avec succès dans ce contexte, notamment\r\n  grâce à la disponibilité croissante de données corrigées\r\n  manuellement. Néanmoins, leur défaut majeur est la difficulté de\r\n  modéliser proprement des corrections à différentes granularités\r\n  (caractères/mots/etc.) qui s\'avère nécessaire pour réduire le taux de\r\n  mots inconnus nuisibles à leur bon fonctionnement. Plus récemment,\r\n  l\'utilisation de réseaux de neurones a entraîné des gains\r\n  significatifs pour les tâches de \"mapping\" entre paires de séquences,\r\n  y compris celles de la traduction et de la correction d\'orthographe,\r\n  ceci grâce à leur capacité d\'apprendre une meilleure représentation\r\n  des données ainsi qu\'une meilleur prise en compte du contexte.\r\n\r\n  Dans ce stage, on propose d\'étudier une nouvelle architecture de\r\n  réseau de neurones combinant des informations au niveau des caractères\r\n  et des mots grâce à la possibilité d\'empiler facilement différents\r\n  réseaux. En particulier, un réseau convolutif peut être utilisé pour\r\n  apprendre des embeddings à partir des caractères, que l\'on combine\r\n  avec des embeddings de mots pour alimenter une ou plusieurs couches de\r\n  réseaux récurrents de type encodeur-décodeur. On propose également de\r\n  comparer différents modèles d\'attention (global, local, etc.)  pour\r\n  mieux modéliser le contexte.\r\n\r\n  Profil recherché: Niveau M2, bonne connaissance d\'un langage de\r\n                    programmation (python ou c++ idéalement), un intérêt\r\n                    fort pour l\'apprentissage automatique appliqué au\r\n                    traitement automatique des langues.\r\n\r\n\r\n2 Administratif\r\n---------------\r\n\r\n  Le stage aura lieu au LIPN (CNRS - Université Paris 13 - Sorbonne\r\n  Paris Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le\r\n  Roux et Nadi Tomeh. Le/La stagiaire fera partie de l\'équipe de\r\n  recherche RCLN, membre du labex EFL (axe \"sémantique\r\n  computationnelle\"), dans la structure de recherche fédérative MathSTIC\r\n  de CNRS/Paris 13 (axe \"Optimisation et Apprentissage pour les contenus\r\n  numériques\").\r\n\r\n  Les candidatures (CV et lettre de motivation) doivent être adressées à\r\n  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17.'),
(384, '2017-01-03', 'IDIAP', 'Martigny (CH)', 'Internship in Natural Language Processing: DNN-based coreference models\r\n\r\nNLP Group, Idiap Research Institute, Martigny, Switzerland\r\n\r\n\r\nApplications are invited for a 6-month internship at the Master level in\r\nthe field of natural language processing with neural networks, in the\r\nNLP group of the Idiap Research Institute (www.idiap.ch/nlp).\r\n\r\nThe goal of this internship is to explore new data structures that would \r\nenable a better modeling of co-reference by using (deep) neural networks \r\n(DNNs).  Co-reference is the relation between words or phrases in a text \r\nthat refer to the same entity.  DNNs have been successfully applied to a \r\nvariety of NLP tasks, but for coreference resolution such approaches \r\nhave shown limited improvement and a suitable model remains to be found. \r\n  The goal of this internship is to go beyond classifiers that decide \r\nwhether a pair of phrases is co-referent or not, and instead learn to \r\nrepresent, in the output layer, each of the entities of a text.  In \r\ncollaboration with a PhD student and a postdoc, the model will be \r\napplied to document-level machine translation.  The work will thus \r\nrelate to the EU SUMMA and SNSF MODERN projects.\r\n\r\nThe applicants should have a background in natural language processing,\r\nmachine learning, or computer science. They should have demonstrable\r\nprogramming skills in at least one language such as Perl, Python, Java\r\nor C/C++.  Previous experience with coreference or anaphora resolution\r\nwould be a plus. Good command of English is mandatory and knowledge of\r\nanother European language such as French, Spanish, or German would be\r\nappreciated.\r\n\r\nThe screening of the applications will start on January 15, 2017, and\r\nwill continue until the position is filled.  The preferred starting time\r\nis in spring 2017.  The appointment is for 6 months, with a gross\r\ninternship salary of 2000 CHF per month.\r\n\r\n\r\n*How to apply*\r\n\r\nPlease fill in and submit your application through the Idiap online \r\nrecruitment system, by clicking on the position\'s title at \r\nhttp://www.idiap.ch/education-and-jobs.\r\n\r\n\r\n*Contact information*\r\n\r\nFurther information about this position can be requested via the Idiap\r\nonline recruitment system or by contacting Dr. Andrei Popescu-Belis,\r\nhead of the NLP group (Andrei.Popescu-Belis@idiap.ch).\r\n\r\nIdiap Research Institute\r\nRue Marconi 19 - CP 592\r\nCH-1920 Martigny, Switzerland\r\n\r\n\r\n*About the host institution*\r\n\r\nIdiap is an independent, non-profit research institute recognized and \r\nsupported by the Swiss Government, and affiliated with the Ecole \r\nPolytechnique Fédérale de Lausanne (EPFL) and the University of Geneva. \r\nIdiap is located in the town of Martigny in Valais, a scenic region in \r\nthe south of Switzerland, surrounded by the highest mountains of Europe, \r\nand offering exciting recreational activities, including hiking, \r\nclimbing and skiing, as well as varied cultural activities. It is within \r\nclose proximity to Geneva and Lausanne. Although Idiap is located in the \r\nFrench part of Switzerland, English is the working language. Free French \r\nlessons are provided.\r\n\r\nIdiap offers competitive salaries and conditions at all levels in a \r\nyoung, dynamic, and multicultural environment. Idiap is an equal \r\nopportunity employer and is actively involved in the \"Advancement of \r\nWomen in Science\" European initiative. The Institute maintains a \r\nprinciple of open competition (on the basis of merit) to appoint the \r\nbest candidate, provides equal opportunities for all candidates, and \r\nequally encourages both genders to apply.\r\n\r\nKeywords: natural language processing, machine learning, coreference \r\nresolution, machine translation.'),
(385, '2017-01-03', 'Sewote', 'Paris', 'Sewote est une start-up spécialisée dans la R&D en ingénierie\r\nlinguistique. Nous développons des logiciels applicatifs sémantiques\r\ndans l\'optique de proposer des solutions clés en main aux structures\r\nsouhaitant perfectionner leurs processus métier. Notre équipe est\r\ncomposée d\'experts du traitement de l\'information et du Traitetement\r\nAutomatique des Langues.\r\n\r\nNous sommes à la recherche d\'un linguiste pour un stage de 6 mois en vue\r\nde travailler à l\'élaboration de ressources électroniques en anglais et\r\nen français.\r\n\r\n- Début de stage : 1er mars 2017\r\n- Indemnités de stage : 554 ¤ + remboursement de 50% du ticket de\r\n  transport\r\n- Compétences requises :\r\n  o Technologie : NOOJ et/ou UNITEX\r\n  o TAL et Machine Learning\r\n  o Langage Python et/ou Java\r\n  o OS : Linux et Windows\r\n  o Langues : anglais courant (anglais des affaires) et français courant\r\n\r\nSi vous êtes intéressé par cette offre, merci d\'envoyer votre\r\ncandidature à info@sewote.com .'),
(386, '2017-01-03', 'IRIT', 'Toulouse', 'Titre du stage : Réseaux de neurones et plongements de mots pour la\r\ndétection automatique de l\'ironie\r\n\r\n*\r\n*\r\n\r\n*Encadrement :*Farah Benamara (benamara@irit.fr),Véronique Moriceau\r\n (moriceau@limsi.fr), Tim Van de Cruys (tim.vandecruys@irit.fr)\r\n\r\n*Lieu de stage : *IRIT-UPS 118 Route de Narbonne\r\n*Durée : *5 mois\r\n*Financement :* prime de stage\r\n\r\nL\'ironie est un phénomène linguistique complexe qui peut être défini\r\ncomme une incongruité entre le sens littéral d\'un énoncé et son sens\r\nvoulu. Ainsi, une opinion visiblement positive peut s\'avérer négative en\r\ncontexte, comme dans le cas d\'un locuteur qui prononce la phrase \'\'\r\n/Merci les bleus pour ce super match/\'\' alors que l\'équipe de France\r\nvient de perdre un match. La détection de l\'ironie est un sujet\r\nd\'actualité en traitement automatique des langues en raison de son\r\nimportance pour une analyse efficace des opinions et sentiments (Ghosh\r\net al., 2015). La plupart des travaux se concentrent sur la détection de\r\nce phénomène sur les réseaux sociaux tels que Twitter, où les\r\nutilisateurs ont tendance à utiliser des hashtags spécifiques (#ironie,\r\n#sarcasme, #sarcastique) pour aider les lecteurs à comprendre que leur\r\nmessage est ironique. Ces hashtags sont utilisés comme une étiquette de\r\nréférence pour la détection de l\'ironie dans un cadre d\'apprentissage\r\nsupervisé.\r\n\r\nCe stage se focalise sur la détection de l\'ironie dans des tweets écris\r\nen français et en anglais. L\'objectif est de développer un modèle fondé\r\nsur les réseaux de neurones afin d\'identifier des expressions ironiques\r\nde manière automatique. On étudiera l\'utilité de diverses\r\nreprésentations de mots (word embeddings ou plongements de mots ;\r\nMikolov et al. 2013), et on examinera leur utilisation dans les réseaux\r\nde neurones récurrents (Mikolov et al. 2010). Une telle approche permet\r\nde construire une représentation de la phrase globale à partir de\r\nreprésentations de mots individuelles, qui peut ensuite être utilisé\r\npour la classification de tweets ironiques. L\'approche sera comparée à\r\nun modèle de classification supervisé déjà développé au sein de l\'équipe\r\nMELODI (Karoui et al, 2015).\r\n\r\n*Compétences requises*\r\n\r\nBases de l\'apprentissage automatique.\r\n\r\n\r\n*Contact : *envoyer CV (+ relevés de notes du master) à Farah Benamara\r\n(benamara@irit.fr), Véronique Moriceau (moriceau@limsi.fr), Tim Van de\r\nCruys (tim.vandecruys@irit.fr)\r\n\r\n\r\n*Références*\r\n\r\n/G/HOSHA., LIG., VEALET., ROSSOP., SHUTOVAE., BARNDENJ. & REYESA.\r\n(2015). Semeval-2015 task 11 : Sentiment Analysis of Figurative Language\r\nin Twitter. In Proceedings of SemEval 2015, Co-located with NAACL , p.\r\n470-478 : ACL.\r\n\r\nJihen Karoui, Farah Benamara, Véronique Moriceau, Nathalie\r\nAussenac-Gilles, Lamia Hadrich Belguith: Towards a Contextual Pragmatic\r\nModel to Detect Irony in Tweets. ACL (2) 2015: 644-650\r\n\r\nMikolov, Tomas, et al. \"Recurrent neural network based language model.\"\r\n/Interspeech/. Vol. 2. 2010.\r\n\r\nMikolov, Tomas, et al. \"Distributed representations of words and phrases\r\nand their compositionality.\" /Advances in neural information processing\r\nsystems/. 2013.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(387, '2017-01-05', 'Viseo', 'Grenoble', 'Stage master 2 (ou équivalent) professionnel 2016-2017\r\n\r\nViseo R&D, à Grenoble (France)\r\nhttp://www.viseo.com/fr/offre/recherche-et-innovation\r\n\r\nSujet : création d\'une plateforme de démonstration d\'outils\r\nlinguistiques.\r\n\r\nContexte\r\n\r\nL\'équipe R&D produit plusieurs outils basés sur l\'analyse de données\r\ntextuelles : reconnaissance d\'entités nommées, classification,\r\nstructuration de données... Ces outils sont hétérogènes, ils prennent la\r\nforme de bibliothèques logicielles, web service, site web... Ils sont\r\nécrits en Java ou en Python.\r\n\r\nPour montrer son savoir-faire et ses domaines de compétences ; l\'équipe\r\nsouhaite se doter d\'une plateforme de démonstration de ses outils. Cette\r\nplateforme prend la forme d\'un site web au sein duquel un visiteur peut\r\ninteragir avec les outils, en soumettant ses propres jeux de données.\r\n\r\nObjectif du stage\r\n\r\nL\'objectif de ce stage est de réaliser un site web vitrine permettant\r\nd\'interagir avec les outils produits par l\'équipe.\r\n\r\nPour atteindre cet objectif, il est demandé à l\'étudiant de :\r\n\r\n- modifier les outils pour les mettre sous forme de services web\r\n  facilement déployables. Si nécessaire, produire des propositions\r\n  d\'évolution comprenant une analyse d\'impact.\r\n\r\n- proposer des maquettes du site web permettant d\'interagir avec les\r\n  différents outils de manière ergonomique,\r\n\r\n- développer le site web (front et back).\r\n\r\nProfil\r\n\r\nCe sujet est destiné aux étudiants de master 2 (ou équivalent) en\r\ninformatique.\r\nEnvironnement technique : Java, Maven, git, Jenkins, Docker, Linux,\r\nAngular, Spring, Python\r\n\r\nInformations complémentaires\r\nUnité d\'accueil : Viseo R&D http://www.viseo.com/fr/offre/recherche-et-innovation\r\nLieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble\r\nEncadrant principal : Pierre-Alain Avouac\r\nDurée du stage : 6 mois\r\nStage rémunéré\r\n\r\nMerci d\'envoyer votre candidature à pierre-alain.avouac@viseo.com\r\nconstituée du CV, de la lettre de motivation, des relevés de notes des 2\r\ndernières années (M1 et M2)\r\n\r\nÀ propos de Viseo\r\nViseo est une entreprise française de services du numérique qui compte 1\r\n200 employés en France, Allemagne, États-Unis, Singapour, Hong Kong et\r\nMaroc. Son centre R&D est situé à Grenoble, à deux minutes à pied de la\r\ngare. De nombreux projets de recherche collaboratifs y sont menés, avec\r\nun intérêt particulier pour l\'analyse de données textuelles : projet\r\nSMILK (LabCom ANR)\r\nhttp://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER\r\n(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)\r\nhttp://www.synodos.fr, SOMA (EUROSTARS)\r\nhttp://www.viseo.com/fr/recherche/le-projet-soma, ...\r\n\r\nPour en savoir plus :\r\n\r\n- www.viseo.com \r\n\r\n- www.viseo.com/fr/offre/recherche-et-innovation'),
(388, '2017-01-09', 'LIGM', 'Marne-la-Vallée', '--------------\r\nOffre de stage de M2 de linguistique : Étude et documentation de \r\npropriétés syntaxiques d\'expressions verbales figées\r\n--------------\r\nStage financé par le projet PARSEME-FR de l\'Agence nationale de la\r\nrecherche (ANR)\r\n--------------\r\n\r\nLe projet PARSEME-FR (Syntactic Parsing and Multiword Expressions in\r\nFrench) http://parsemefr.lif.univ-mrs.fr/doku.php vise à améliorer la\r\nreprésentativité linguistique, la précision, la robustesse et\r\nl\'efficacité informatique des applications du traitement automatique des\r\nlangues (TAL), notamment l\'analyse syntaxique du français. Il cible un\r\ndes principaux défis que rencontrent ces applications : les expressions\r\npolylexicales (EPL), c\'est-à-dire les groupes de mots qui doivent être\r\ntraités comme des unités à un niveau ou à un autre du traitement\r\nlinguistique, comme \"coup de pouce\", \"disque dur\", \"sauter le pas\",\r\n\"Nations unies\" et \"faire attention\". Le projet vise à concilier\r\nprécision linguistique et efficacité informatique dans les applications\r\ndu TAL, en travaillant, entre autre choses, sur la représentation\r\nsyntaxique et sémantique des EPL dans les dictionnaires. Ce projet se\r\nrattache à PARSEME, une action européenne de type COST sur le même\r\nsujet.\r\n\r\n--------------\r\nDescription du poste\r\n---------------\r\nLes tâches principales concernent les tables de lexique-grammaire des\r\nexpressions figées verbales. Ces tables listent des entrées lexicales\r\nd\'expressions et leur attribuent des propriétés. Les objectifs seront\r\nles suivants :\r\n\r\n1) mettre en place une documentation sur les propriétés codées,\r\n   notamment une formalisation des constructions syntaxiques, tout en\r\n   harmonisant les notations sur toutes les tables ;\r\n\r\n2) sélectionner des entrées en fonction des critères définis dans les\r\n   directives de PARSEME-FR.\r\n\r\nLa recherche se fera en équipe avec deux chercheurs du LIGM, et en\r\nparallèle avec un projet équivalent de l\'Institute for Language and\r\nSpeech Processing (ILSP, Athènes) sur le grec moderne.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n- Formation en cours : Master 2 en Linguistique Informatique ou similaire.\r\n- Curiosité et capacité d\'explorer de nouveaux domaines en linguistique.\r\n- Des connaissances en lexicologie et syntaxe seraient un plus.\r\n\r\n-----------------\r\nConditions\r\n-----------------\r\nContrat : stage conventionné 6 mois rémunéré.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\neric.laporte@univ-paris-est.fr\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevé de notes.\r\n\r\nLieu : LIGM, Université Paris-Est Marne-la-Vallée, Champs-sur-Marne.\r\n\r\nEncadrant : Eric Laporte (Université Paris-Est Manre-la-Vallée)\r\n\r\nDébut : mars ou avril 2017.'),
(389, '2017-01-13', 'Evea Cognitive', 'Saint-Cloud', 'Offre de stage : Mise en place de solutions cognitives \r\n \r\nIngénieur Linguiste Junior\r\n\r\nContexte du stage :\r\n \r\nEVEA COGNITIVE est la filiale du Groupe Evea technologies, notre\r\nmétier est d\'accompagner les entreprises dans leur transformation\r\ndigitale. Nous réalisons 28M¤ de CA ; 95 salariés ; Siège à Saint\r\nCloud 92 - 2 Agences en France : Lille - Nantes - Partenaires\r\ncertifiés IBM depuis plus de 10 ans sur les technologies AS400/ Power\r\net stockage de données.\r\n \r\nNous sommes la filiale SSII spécialisée dans la Business Intelligence\r\net les technologies cognitives. Depuis 2015 EVEA COGNITIVE a commencé\r\nune collaboration avec IBM sur la plateforme cognitive Watson : un\r\nensemble de technologies de pointe du traitement de données\r\ntextuelles. Afin de renforcer ses équipes linguistiques EVEA COGNITIVE\r\nrecrute un(e) stagiaire dont le rôle sera de contribuer à la mise en\r\nplace des solutions cognitives.\r\n\r\nVous participerez dans la collaboration avec nos partenaires et\r\ndévelopperez vos compétences dans ce domaine en pleine croissance.\r\n\r\n\r\nDescription du stage :\r\n\r\nVous participerez au développement de projets ou d\'expérimentations\r\nsur les technologies WATSON et autres technologies cognitives. Vous\r\nserez intégré(e) au sein de l\'équipe de EVEA COGNITIVE et\r\ninterviendrez sur les missions suivantes :\r\n\r\n- Récupération de données textuelles de sources hétérogènes (fichiers,\r\n  bases de données, emails, pages web).\r\n\r\n-Normalisation, nettoyage et extraction de métadonnées de documents\r\n collectés, création de scripts (en Perl et/ou Python) pour faciliter\r\n le traitement de données textuelles.\r\n\r\n- Analyse sémantique de données textuelles, création et gestion de\r\n  ressources linguistiques : dictionnaires, expressions régulières,\r\n  graphes UNITEX, grammaires locales, règles de parsing.\r\n \r\n- Analyse de catalogues, préparation des bases de connaissances\r\n  structurées pour l\'analyse (ontologies etc)\r\n\r\n- Acquisition d\'une expertise technologique sur Watson et sur les\r\nautres produits d\'IBM, développement d\'un savoir-faire méthodologique\r\net technique\r\n\r\nStage proposé dans l\'objectif d\'une embauche.\r\n\r\nProfil recherché :\r\n\r\n- Formation en cours : Master 2 en Linguistique Informatique ou\r\n  similaire.\r\n- Méthodique et rigoureux, capacité d\'organisation\r\n- Compétences en analyse sémantique et syntaxique, bonne connaissance\r\n  d\'outils et logiciels TAL\r\n- Connaissance d\'un langage de script (de préférence Python) et de\r\n  XML, XPath, XSLT\r\n- Capacité d\'explorer de nouvelles méthodes statistiques en TAL serait\r\n  un plus\r\n- Connaissance en programmation orientée objet (Java, C#, C++, etc.)\r\n  et en programmation Web (node.js) appréciée\r\n\r\nDivers : \r\n\r\n- Début du stage : entre février 2017 et avril 2017 (date exacte à\r\n  définir selon convenance)\r\n- Stage de 6 mois rémunéré ( 800  mois)\r\n- RIE et remboursement de la moitié du passe Navigo.\r\n- Nos locaux sont situés à Saint Cloud (92213)\r\n- Bonne ambiance et équipe technique de grande qualité.\r\n- Contrat : convention de stage\r\n\r\nContact :\r\n\r\nCV + lettre de motivation à envoyer à :\r\n\r\nyulia.koloskova@3ws.fr'),
(390, '2017-01-16', 'SNCF', 'Paris', 'La Direction Innovation et Recherche de la SNCF recherche un stagiaire\r\npour travailler sur l\'étude des solutions d\'agents conversationnels\r\n(chatbots) disponibles sur le marché et le test de certaines d\'entre\r\nelles.\r\n\r\n*Activités du stage*\r\n------------------------------\r\n\r\n- Veille et état de l\'art sur les chatbots\r\n\r\n- Test et évaluation de plateformes permettant d\'implémenter des agents\r\n  conversationnels\r\n\r\n*Thème*\r\n------------------------------\r\nLes agents conversationnels existent depuis longtemps. Ils déferlent\r\naujourd\'hui sur le marché sous la désignation de chatbots. Les grands\r\nacteurs tels que Facebook, IBM ou Microsoft favorisent aujourd\'hui leur\r\ndiffusion massive en ouvrant des plateformes pour les développeurs. Les\r\nindustriels s\'en emparent massivement et misent sur leur potentiel pour\r\naméliorer la relation client.\r\nLa Direction Innovation et Recherche cherche à faire un état des lieux\r\nsur la diffusion de ces solutions, leurs usages et leurs limites.\r\n\r\n*Description *\r\n------------------------------\r\nLe stagiaire devra :\r\n\r\n- prendre connaissance du contexte du stage (SNCF, Direction Innovation\r\n  & Recherche, objectifs du stage et cadre de réalisation)\r\n\r\n- réaliser un état de l\'art et du marché sur les chatbots (agents\r\n  conversationnels)\r\n\r\n- tester et évaluer des solutions disponibles en interne ou open-source\r\n  sur un cas d\'usage simple (solution bluemix, wit.ai, pandorabots,\r\n  solutions sur étagère dont startups, ...)\r\n\r\n\r\nPrésentations et rapports :\r\n- Présentation de début de stage à la SNCF (au bout d\'un mois de stage) :\r\n  contexte de stage, planning de réalisation et premiers travaux\r\n  réalisés.\r\n- Etat de l\'art et du marché sur les chatbots\r\n- Rapport final de stage complet comprenant : méthodologie utilisée,\r\n  travaux réalisés, résultats obtenus et problèmes rencontrés\r\n\r\n2 soutenances de fin de stage : une à l\'école et une à la SNCF.\r\nDes présentations en interne SNCF ou externes pourront être effectuées.\r\n\r\n*Profil recherché*\r\n------------------------------\r\n\r\nNiveau : en dernière année d\'école d\'ingénieur ou en Master 2\r\nInformatique spécialisé dans le domaine du traitement automatique de la\r\nlangue ou de l\'intelligence artificielle.\r\n\r\nCompétences attendues :\r\n\r\n- Capacités d\'analyse, de rédaction et de synthèse\r\n- Curiosité\r\n- Autonomie, qualités relationnelles, qualité de présentation\r\n  (orale/écrite).\r\n- Connaissances en intelligence artificielle, traitement du langage\r\n  naturel\r\n- Bon niveau en programmation (Java, C/C++, php, Python, Node.js, Linux)\r\n- Bon niveau d\'anglais\r\n- Une expérience sur les agents conversationnels et/ou systèmes de\r\n  dialogue homme/machine est un plus\r\n\r\n*Modalités du poste*\r\n------------------------------\r\n\r\n- Durée : 6 mois\r\n- Rémunération prévue: indemnités de stage (924 ¤ bruts mensuels) +\r\n  carte de circulation SNCF sur le réseau national\r\n- Début : souhaité à partir d\'avril 2017. Envisageable dès février 2017.\r\n- Lieu : Paris\r\n\r\n\r\nMerci d\'adresser CV et lettre de motivation à Coralie Reutenauer à\r\nl\'adresse mail suivante : coralie.reutenauer@sncf.fr'),
(391, '2017-01-16', 'MoDyCo / IRISA', 'Nanterre ou Vannes', 'Offre de stage de M2 de linguistique : Étude des descripteurs\r\nlinguistiques à l\'oeuvre dans la perception de registres de langue\r\ndifférents en français\r\n\r\n--------------\r\n\r\nStage financé par le projet ANR TREMoLo (/Tr//ansformation de Registres \r\npar Extraction de Motifs Langagiers/)\r\n\r\n--------------\r\n\r\nLe projet TREMoLo étudie l\'emploi de différents registres dans la\r\nlangue française et vise à développer des méthodes automatiques de\r\ntransformation de textes d\'un registre vers un autre. La notion de\r\nregistre ou niveau de langue [1, 2] renvoie à la façon dont, au sein\r\nd\'une même communauté linguistique - celle du français par exemple -,\r\ndes locuteurs évaluent et catégorisent des productions linguistiques.\r\nC\'est ainsi que l\'on est intuitivement amené à distinguer différents\r\nregistres, souvent considérés sur une échelle de niveaux (soutenu,\r\nstandard, familier, populaire...). Le projet TREMoLo propose de\r\ns\'appuyer sur l\'extraction de motifs langagiers spécifiques à\r\ndes registres donnés et sur l\'intégration de ces motifs dans un\r\nprocessus probabiliste de production automatique de paraphrases. Le\r\nprojet se situe dans une optique de recherche exploratoire visant la\r\nproduction de connaissances fondamentales en linguistique française et\r\nune ouverture à terme vers d\'autres types de variations stylistiques.\r\n\r\nMots-clés : Registres de langue, Linguistique française, Traitement \r\nautomatique des langues (TAL), Fouille de données\r\n\r\n--------------\r\n\r\nDescription du poste\r\n\r\n---------------\r\n\r\nL\'objectif de ce stage est de répertorier les descripteurs, c\'est-à-dire\r\nles traits ou phénomènes linguistiques, qui permettent de distinguer\r\nentre eux des textes de registres différents. Sans exclure l\'approche\r\nparadigmatique, nous privilégions une approche syntagmatique pour\r\naborder - mais aussi renouveler - la problématique. En considérant des\r\ncorpus textuels de registre familier, courant ou soutenu (fournis par\r\nles encadrants), il s\'agira de commencer par exploiter les résultats des\r\ntravaux issus de la linguistique [3, 4] et de l\'étude des styles en TAL\r\n[5, 6]. Les faits grammaticaux seront plus particulièrement étudiés dans\r\nla mesure où ils peuvent être discriminants par rapport à ce qui relève\r\nde l\'analyse thématique d\'un texte, elle-même directement liée à\r\nl\'analyse du lexique /strico sensu/. Certains faits grammaticaux non\r\nsollicités par un registre mais susceptibles de l\'être dans un autre\r\nseront ainsi considérés (par exemple, les nominalisations déverbales ou\r\nl\'adjonction du préfixe autonome de pluriel à une racine comme dans «\r\nzyeuter ») ; puis les faits remarquables par leur absence ou leur\r\nsurreprésentation (par exemple, l\'emploi de « on » dans le registre\r\nfamilier, celui de la conjonction de coordination « car » et du passé\r\nsimple dans le registre soutenu...). Sur le plan plus strictement lexical,\r\nà titre d\'exemple, le phénomène d\'emprunt à des langues étrangères, les\r\nmétaphores ou encore le verlan [7] seront intéressants à prendre en\r\ncompte.\r\n\r\nDans une moindre mesure, le stage a également pour objectif\r\nd\'identifier, parmi les nombreux outils existants en TAL, ceux\r\npermettant l\'annotation automatique de textes en français pour les\r\ndifférents descripteurs retenus au fil du stage. La fiabilité des outils\r\npourra être étudiée et prise en compte pour leur sélection mais il ne\r\ns\'agit pas ici de développer de nouveaux outils.\r\n\r\n---------------\r\n\r\nProfil souhaité\r\n\r\n---------------\r\n\r\n- Formation en cours : Master 2 en Linguistique ou linguistique\r\n  informatique.\r\n\r\n- Curiosité et capacité d\'explorer de nouveaux domaines en linguistique.\r\n\r\n- Des connaissances en TAL seront un plus, mais ne sont\r\n  aucunement prérequises. Un soutien sera assuré par les encadrants an\r\n  cas d\'absence de connaissances en TAL. Du reste, le sujet sera adapté\r\n  en fonction du niveau et des types de compétences en TAL du (de la)\r\n  candidat(e).\r\n\r\n-----------------\r\n\r\nConditions\r\n\r\n-----------------\r\n\r\nContrat : stage conventionné 6 mois rémunéré.\r\n\r\nDébut : mars ou avril 2017.\r\n\r\nLieu : laboratoire MoDyCo (site : Université de Paris Ouest Nanterre) ou\r\nlaboratoire IRISA (site : Université de Bretagne Sud)\r\n\r\nEncadrants : Delphine Battistelli (MoDyCo), Nicolas Béchet (IRISA),\r\nGwénolé Lecorvé (IRISA)\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nMerci d\'envoyer votre candidature aux trois adresses suivantes :\r\n\r\ndelphine.battistelli@u-paris10.fr\r\n\r\nnicolas.bechet@irisa.fr\r\n\r\ngwenole.lecorve@irisa.fr\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevés de notes M1 et\r\n                      M2.\r\n\r\n\r\n    Bibliographie\r\n\r\n[1] D. Biber et E. Finegan. /Sociolinguistic Perspectives on Register/,\r\nOxford University Press, 1994.\r\n\r\n[2] G. Petiot. Langue Française. N°33, sur les exercices de grammaire,\r\npp. 68-78, Armand Colin, 1977.\r\n\r\n[3] D. Biber, /Variation across speech and writing/, Cambridge\r\nUniversity Press, 1988.\r\n\r\n[4] F. Gadet. Niveaux de langue et variation intrinsèque, dans\r\nPalimpseste « Niveaux de langue et registres dans la traduction », vol.\r\n10, 1996.\r\n\r\n[5] E. Stamatatos. /A survey of modern authorship attribution methods/,\r\nJournal of the American Society for information Science and Technology,\r\n60(3), 2009.\r\n\r\n[6] M. Koppel et J. Schler. /Exploiting stylistic idiosyncrasies for\r\nauthorship attribution/, dans Proceedings of IJCAI\'03 Workshop on\r\nComputational Approaches to Style Analysis and Synthesis, 2003.\r\n\r\n[7] F. Gadet. /Is there a French theory of variation?/, dans\r\nInternational Journal of the Sociology of Language, vol. 160, 2003.'),
(392, '2017-01-27', 'SNCF', 'Paris', 'Stage ingénieur ou M2 : fouille de textes appliquée à des documents\r\nmétiers SNCF\r\n\r\nContexte : SNCF dispose actuellement d\'une base documentaire de\r\nréférentiels métiers. La Direction Innovation et Recherche souhaite\r\nappliquer des méthodes de fouille de texte pour améliorer la gestion des\r\ndocuments, l\'accès aux contenus et la navigation dans cette base\r\ndocumentaire.\r\n\r\nActivités du stage :\r\nLe stagiaire devra :\r\n\r\n- prendre connaissance du contexte du stage (SNCF, Direction Innovation\r\n  & Recherche, objectifs du stage et cadre de réalisation)\r\n- Préparer les données en vue de leur réutilisation dans différents\r\n  outils (adapter le format, structurer les contenus)\r\n- Appliquer des traitements de data et text mining pour classer,\r\n  visualiser et enrichir les documents.\r\n\r\n\r\nPrésentations et rapports :\r\n- Présentation de début de stage à la SNCF (au bout d\'un mois de stage) :\r\n  contexte de stage, planning de réalisation et premiers travaux\r\n  réalisés.\r\n\r\n- Rapport final de stage complet comprenant : méthodologie utilisée,\r\n  travaux réalisés, résultats obtenus et problèmes rencontrés\r\n\r\n2 soutenances de fin de stage : une à l\'école et une à la SNCF.\r\nDes présentations en interne SNCF ou externes pourront être effectuées.\r\n\r\nProfil souhaité :\r\n\r\nNiveau : dernière année d\'école d\'ingénieur ou M2 en traitement\r\nautomatique des langues ou en informatique spécialisé en ingénierie des\r\nconnaissances ou fouilles de données (text mining).\r\n\r\nCompétences requises :\r\n\r\n- Traitement automatique des langues\r\n- Apprentissage statistique / Machine learning\r\n- Maîtrise de R\r\n- Développement informatique (Java, Python...)\r\n- Autonomie\r\n- Capacités d\'analyse, de rédaction, de synthèse\r\n\r\nHoraires : 35 h hebdomadaires\r\n\r\nLieu de travail : Paris 12ème\r\n\r\nDurée : 6 mois\r\n\r\nDate de début : à partir du 20/02/2016\r\n\r\nRémunération prévue : indemnités de stage (924 ¤ bruts mensuels) + carte\r\nde circulation sur le réseau national\r\n\r\nVeuillez adresser votre CV et lettre de motivation à\r\ncoralie.reutenauer@sncf.fr'),
(393, '2017-01-30', 'LIMSI', 'Orsay', 'Offre de stage de niveau Master 2\r\n\r\nFouille de bases bibliographiques pour extraire les interactions entre\r\nl\'alimentation et les médicaments\r\n\r\nGrâce aux avancées de la recherche, l\'activité des professionnels et la\r\nparticipation de la communauté, les informations et les connaissances\r\nconcernant une question donnée sont actuellement distribuées entre\r\ndifférentes sources, comme par exemple les bases bibliographiques, les\r\nbases de connaissances ouvertes, les réseaux sociaux, etc. Il se pose\r\nalors la question de l\'accès efficace et rapide à ces informations et\r\nconnaissances et à leur croisement [1].\r\n\r\nLe contexte du travail s\'inscrit dans le domaine médical. L\'intérêt\r\ncentral concerne l\'extraction des informations sur les interactions\r\nentre l\'alimentation et les médicaments. Les aliments peuvent en effet\r\navoir des interactions avec les médicaments et cela peut mener à des\r\nconséquences malheureuses pour le patient. Ces interactions sont très\r\npeu étudiées. DrugBank [2], qui est la base de connaissances la plus\r\ncomplète sur cette question, propose des informations textuelles sur les\r\ninteractions pour moins de 10 % de médicaments. De plus, ces\r\ninformations concernent essentiellement le moment de prise des\r\nmédicaments (par exemple, pendant le repas).\r\n\r\nDe manière générale, il peut exister trois types d\'interactions: (1)\r\ndiminution ou suppression de l\'action du médicament sous l\'effet d\'un\r\naliment ; (2) augmentation de l\'effet du médicament ; (3) apparition de\r\nnouveaux effets indésirables du médicament.\r\n\r\nLe pomelo, qui est un exemple bien connu, a des interactions avec\r\nplusieurs médicaments à cause de son principe actif qui inhibe les\r\nenzymes des médicaments, ce qui peut causer le surdosage de ces\r\nmédicaments [3,4]. D\'autres aliments peuvent avoir des interactions,\r\ncomme par exemple l\'alcool, les cranberries, les tomates, le thé vert,\r\nles épinards ou le curcuma.\r\n\r\nCe stage s\'inscrit dans le projet ANR MIAM (Maladies, Interactions\r\nAlimentation-Médicaments). Pour la réalisation du stage, des méthodes de\r\nTraitement Automatique de la Langue et de fouille de textes seront\r\nutilisées.\r\n\r\nPlus spécifiquement, il s\'agit des objectifs suivants:\r\n- travailler avec des corpus de textes de différents types et\r\n  provenant de différentes sources\r\n- exploiter et améliorer les annotations des textes avec différents\r\n  niveaux de spécificité\r\n- exploiter, adapter ou développer des méthodes pour l\'extraction\r\n  d\'informations\r\n- faire le lien avec les bases de données et de connaissances\r\n  existantes\r\n- évaluer les méthodes et les résultats\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n- connaissances en TAL et en informatique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique\r\n- maîtrise de l\'anglais\r\n- autonomie\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourra être\r\nenvisagée.\r\n\r\nNiveau: Master 2\r\nDurée: 6 mois\r\nLieu: Orsay\r\nDébut du stage : Mars ou avril 2017\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de\r\nmotivation, le relevé de notes et les contacts de deux référents à\r\nthierry.hamon@limsi.fr et natalia.grabar@univ-lille3.fr\r\n\r\n\r\nREFERENCES\r\n\r\n1. J. Kozák, M. Necaský, J. Dedek, J. Klímek, and J. Pokorný. Linked\r\nopen data for healthcare professionals. In Proceedings of\r\nInternational Conference on Information Integration and Web-based\r\nApplications & Services, IIWAS\'13, pages 400:400-400:409, New York,\r\nNY, USA, 2013. ACM.\r\n2. http://www.drugbank.ca/\r\n3. Duke Med Health News. Grapefruit: enemy of many medications. in\r\nsome patients, the interaction of fruit and drug may put their life\r\nand health at risk. Duke Med Health News, 19(2):1-2, 2013.\r\n4. D. Greenblatt and H. Derendorf. Grapefruit-medication\r\ninteractions. CMAJ, 185(6):507, 2013.'),
(394, '2017-01-31', 'Wiidii', 'Bordeaux', 'WIIDII RECRUTE !\r\n\r\nStage durée de 6 mois - début : 13/03/2017\r\nDate limite de candidature le 20/02/2017\r\nOffre publiée le 02/02/2017\r\nRéférence de l\'annonce : SLI022017\r\n\r\nQui est Wiidii ?\r\n\r\nNom : Wiidii\r\nAdresse : 56 rue de Tivoli 33000 BORDEAUX\r\nSite Web : www.wiidii.com\r\nWiidii est une jeune start-up bordelaise créée\r\nen 2014 qui commercialise une application de\r\nconciergerie combinant l\'intelligence artificielle\r\net le savoir-faire humain.\r\nLa conciergerie privée propose à ses clients de gérer et\r\nsimplifier leur quotidien, tel un assistant personnel.\r\n\r\nMissions détaillées\r\n\r\nAu sein d\'une équipe d\'une dizaine de personnes, et encadré par la\r\nchef de projet, nous proposons un stage de linguiste\r\ninformaticien. Vos missions seront de deux natures :\r\n\r\nConception de base de données\r\n\r\n- Mener une étude sur la création d\'une base de données (BDD)\r\nalimentant le moteur de l\'application : recherche de sources de\r\nBDD. Au-delà des données pures, il s\'agit d\'élaborer une BDD dynamique\r\nautour du langage sur des schémas syntaxiques (combinaison de mots sur\r\ndes principes de AND, OR, NOT).\r\n- Architecturer et construire la BDD\r\n- Importer et tester la BDD dans le moteur de l\'application\r\n\r\nSuivi client\r\n\r\n- Prendre en charge les demandes* des clients en français et en\r\n  anglais, via l\'application\r\n- Poursuivre et améliorer l\'envoi des notifications aux clients\r\n- Gérer le suivi des bugs\r\n- Créer, envoyer et suivre les campagnes d\'emailing\r\n- Analyser l\'activité cliente : profil des clients, nature des\r\ndemandes et en sortir des données statistiques\r\n\r\n*Les demandes sont de toutes sortes : conseiller des\r\nlieux à visiter, organiser des voyages, réserver des\r\nrestaurants, prendre des rendez-vous chez le coiffeur,\r\nmédecin, trouver un garagiste...\r\n\r\nWiidii : comprendre la demande du client afin de lui apporter la\r\nréponse la plus pertinente possible.\r\n\r\n\r\nProfil et Compétences\r\n\r\n- Wiidii cherche un(e) candidat(e), maîtrisant les tableurs (Excel) et\r\npossédant une très forte agilité en informatique et sur Internet. La\r\nstructuration du langage vous passionne et vous connaissez les\r\nprincipes de base des langages SQL, Script, HTML. Rigueur,\r\norganisation, innovation, implication et adaptation sont les qualités\r\nrequises pour occuper ces missions.\r\n- L\'anglais écrit est un atout supplémentaire.\r\n- De formation en langue et informatique, sur les sciences du langage ou\r\nen ingénierie des langues.\r\n\r\n\r\nRémunération & Avantages\r\n\r\n- Gratification conventionnelle\r\n- Participation au titre de transport, tickets restaurant\r\n\r\nTemps de travail\r\n\r\n35 heures du lundi au samedi en horaire variable (8h - 22h)\r\n\r\nPersonne à contacter\r\n\r\nEnvoyez CV et lettre de motivation en français par mail\r\nà Johanna PICAUD, Responsable administrative et financière :\r\njohanna.picaud@wiidii.com'),
(395, '2017-02-01', 'INALCO', 'Paris', 'Stage M2 au laboratoire ERTIM (INALCO)\r\nTraitements TAL pour le bambara et le maninka\r\n\r\nLe projet MANTAL vise à implémenter des traitements TAL aux langues\r\nmandingues (bambara et maninka) qui disposent déjà d\'assez conséquents\r\nvolumes de données annotées (Vydrine 2013, 2014 et 2016) : 3M de mots\r\npour chaque langue annotés automatiquement en morpho-syntaxe,\r\ntonalisation et gloses, dont 500K ont été désambiguisés manuellement\r\npour le bambara. Le bambara s\'écrit avec des caractères latins, tandis\r\nque le maninka utilise le système d\'écriture écrit en N\'ko, qui se\r\ntranscrit assez facilement en caractères latins.\r\n\r\nCes travaux sont essentiels pour apporter une existence numérique à ces\r\nlangues parlées par 20 à 30 millions de locuteurs en Afrique et dans la\r\ndiaspora africaine. L\'objectif du stage est d\'améliorer les traitements\r\nTAL pour ces langues dans plusieurs directions.\r\n\r\n1/ En collaboration avec un partenaire allemand, nous souhaitons étendre\r\nles travaux à la construction d\'analyseurs syntaxiques pour ces langues\r\nselon un format interopérable du web sémantique (NIF). Ce travail pourra\r\nêtre exploité pour des applications de plus haut niveau, comme la\r\ntraduction.\r\n\r\n2/ Les corpus pour ces deux langues sont aujourd\'hui hébergés sur une\r\ninfrastructure technique identique, et tout traitement fonctionnel pour\r\nune langue peut potentiellement être porté à l\'autre. La constitution de\r\ncorpus parallèles bamara / français (et éventuellement maninka /\r\nfrançais) apportera ressource supplémentaire à forte valeur ajoutée pour\r\nle projet.\r\n\r\n3/ Le corpus maninka ayant été constitué récemment, un travail est\r\nnécessaire afin d\'en contrôler la qualité et de l\'enrichir. Cette tâche\r\nsera réalisé par extraction de textes en maninka depuis internet\r\n(crawling) et par une vérification automatique de la cohérence des\r\ncorpus avec les ressources linguistiques existantes (corpus et\r\ndictionnaires), ce qui permettra aussi d\'apporter aux linguistes des\r\nsuggestions de mots à ajouter aux dictionnaires ou de segments à\r\ncorriger dans les corpus.\r\n\r\nProfil recherché :\r\n+ Master 2 en TAL\r\n+ Bonnes compétences en programmation (Python)\r\n+ Compréhension des approches en apprentissage automatique\r\n+ La connaissance du bambara / maninka est bienvenue mais pas\r\n  obligatoire\r\n\r\nContexte\r\n+ Durée du stage : 4 ou 5 mois à temps plein\r\n+ Date de début : mars ou avril 2017\r\n+ Rémunération : tarif en vigueur (510¤/mois, rbst de 50% navigo)\r\n+ Lieu : INaLCO, 2 rue de Lille, 75007 Paris\r\n\r\nMerci d\'envoyer votre CV et de faire part de vos motivations à Damien\r\nNouvel ( damien.nouvel@inalco.fr ).\r\n\r\nRéférences :\r\n(Maslinsky 2014) Kirill Maslinsky. Daba: a model and tools for Manding\r\ncorpora. TALAf 2014. http://talaf.imag.fr/2014\r\nhttp://talaf.imag.fr/2014/Actes/MASLINSKY%20-%20Daba%3B%20a%20model%20and%20tools%20for%20Manding%20corpora.pdf\r\n\r\n(Vydrine 2013) Valentin Vydrin. Bamana Reference Corpus (BRC) Procedia -\r\nSocial and Behavioral Sciences, 95:25, pp. 75-80.\r\nhttp://www.sciencedirect.com/science/journal/18770428\r\n\r\n(Vydrine 2014) Valentin Vydrin. Projet des corpus écrits des langues\r\nmanding : le bambara, le maninka. TALAf 2014. http://talaf.imag.fr/2014\r\nhttp://talaf.imag.fr/2014/Actes/MASLINSKY%20-%20Daba%3B%20a%20model%20and%20tools%20for%20Manding%20corpora.pdf\r\n\r\n(Vydrine 2016) Valentin Vydrin, Andrij Rovenchak, Kirill Maslinsky. Maninka\r\nReference Corpus: A Presentation. TALAf 2016. http://talaf.imag.fr/2016'),
(396, '2017-02-01', 'LATTICE', 'Paris', 'Proposition de stage de 6 mois au laboratoire LATTICE : adaptation au\r\nfrançais d\'un outil d\'analyse des chaînes de coréférence \r\n\r\nDans le cadre d\'un projet d\'analyse d\'un corpus de presse en français\r\ncouvrant plusieurs dizaines d\'années, le LATTICE souhaite recruter un\r\nstagiaire (niveau M2 en Informatique ou IA ou TAL avec une forte\r\ncomposante informatique) pour une durée de 6 mois à partir de mars ou\r\navril 2017. Plusieurs tâches sont envisageables mais le thème privilégié\r\nsera l\'analyse de chaînes de coréférence (afin par exemple d\'identifier\r\ndes informations importantes dans des phrases où le nom des acteurs ne\r\nserait  pas immédiatement reconnaissable). \r\n\r\nUne piste permettant d\'avancer sans avoir à développer un système\r\ncomplètement nouveau serait d\'essayer d\'adapter au français la chaîne de\r\ntraitement BART (http://www.bart-coref.org/) qui est largement utilisée\r\ndans divers cadres. Ce stage demande un bon niveau en informatique.\r\n\r\nLe stage se déroulera au LATTICE, à Montrouge (à 10mn de la station de\r\nmétro « Mairie de Montrouge », ligne 4)\r\n\r\n- Stage de 6 mois maximum, de niveau M2 (Informatique ou IA ou TAL avec\r\n  une forte composante informatique), conventionné et indemnisé suivant\r\n  les règles en vigueur\r\n\r\n- Très bon niveau en programmation (scripts et programmation pure) et en\r\n  TAL nécessaire\r\n\r\n- Contact : Thierry Poibeau (thierry.poibeau@ens.fr) et Frédéric\r\n  Landragin (frederic.landragin@ens.fr)'),
(397, '2017-02-01', 'LLL', 'Orléans', 'Offre de stage pour trois mois (mars/avril-mai 2017)\r\n\r\nPrise en main et utilisation d\'une base de données et d\'un logiciel de\r\nrepérage automatique d\'opérations de réécriture\r\n\r\nContexte\r\n\r\nCe stage s\'intègre dans les recherches menées par des laboratoires des\r\nuniversités d\'Orléans (LLL) et de Bordeaux, en lien avec la Maison\r\nInterdisciplinaire des Systèmes Complexes (universités d\'Orléans et de\r\nTours) dans le cadre du projet régional ECRISA (MSH Val de Loire) \r\n(En savoir plus sur http://ecrisa.msh-vdl.fr).\r\n\r\nÀ partir de l\'analyse d\'expérimentations en cours, l\'objectif central\r\nde ces recherches, qui s\'inscrit dans le champ des littéracies\r\nuniversitaires, est de montrer comment des outils conceptuels élaborés\r\ndans le cadre d\'une didactique de l\'écrit(ure) référée à des\r\ndisciplines scolaires peuvent permettre de construire, dans\r\nl\'enseignement supérieur, des dispositifs d\'accompagnement des\r\npratiques littéraciées visant la construction de savoirs, et\r\nd\'envisager un transfert didactique dans les disciplines scolaires,\r\nlorsque le public visé est constitué de (futurs) enseignants. L\'étude\r\ns\'appuie sur l\'analyse de déclarations et de productions d\'écrits\r\nd\'étudiants insérés dans des contextes de formation différents, tant\r\nsur le plan des systèmes universitaires (France, Québec) que sur celui\r\ndes filières (technologique, linguistique, formation des maitres,\r\netc.). Pour faciliter l\'analyse des écrits recueillis sous la forme de\r\ndeux versions, une base de données a été constituée dans le cadre du\r\nprojet « Prise en compte de la complexité dans les pratiques\r\nlittéraciées de l\'enseignement supérieur » soutenu par la Maison\r\nInterdisciplinaire des Systèmes Complexes des universités d\'Orléans et\r\nde Tours (http://www.univ-orleans.fr/misc-orleans-tours/projets).\r\n\r\nEn savoir plus sur\r\nhttp://ecrisa.msh-vdl.fr/index.php/lecrit-comme-produit-derivepratiques-litteraciees-de-haut-niveau-et-prise-en-compte-du-sujet/\r\n\r\nStructure d\'accueil : Laboratoire Ligérien de Linguistique, université\r\nd\'Orléans ; des missions à Bordeaux sont à prévoir.\r\n\r\nResponsable de la recherche : Jacqueline Lafont-Terranova -\r\nLaboratoire Ligérien de linguistique, Université d\'Orléans\r\n(jacqueline.lafont@univ-orleans.fr)\r\n\r\nMissions\r\n\r\nAméliorer et alimenter une base de données de textes produits et\r\nenregistrés sous forme de deux versions (V1/ Version définitive) ;\r\nutiliser le logiciel Medite (qui repère automatiquement les opérations\r\nde réécriture qui font passer d\'un texte à un autre).  (Une formation\r\nau maniement de ce logiciel sera assurée).\r\n\r\nLe/la stagiaire devra :\r\n\r\n- Vérifier les fiches présentes dans la base de données (41 mémoires\r\nde recherche V1/Version définitive),\r\n- Effectuer des tests de repérage des opérations de réécriture au\r\nniveau textuel (remplacements, suppressions, ajouts, déplacements) sur\r\nun échantillon,\r\n- Affiner le paramétrage en fonction des tests,\r\n- Repérer des opérations de réécriture au niveau textuel sur\r\nl\'ensemble du corpus,\r\n- Réaliser des statistiques à partir des résultats obtenus,\r\n- Effectuer une étude qualitative des effets des opérations de\r\nréécriture repérées sur un mémoire,\r\n- Ajouter des nouveaux corpus dans la base de données.\r\n\r\nProfil recherché\r\n\r\n-Étudiant(e) en M2 professionnel ou recherche en sciences du langage,\r\nsciences de l\'éducation, MEEF\r\n\r\n- Bonne connaissance des logiciels bureautiques,\r\n\r\n- Formation ou sensibilisation à la didactique souhaitable\r\n\r\nStructure de recrutement : Maison des Sciences de l\'Homme Val de\r\nLoire, Tours\r\n\r\nDurée : 3 mois\r\n\r\nCompensation : selon les normes en vigueur\r\n\r\nPrise de fonction : à partir de mars 2017\r\n\r\nEncadrement : Jacqueline Lafont-Terranova, Flora Badin, Guillaume Chevrot\r\n\r\nCandidature :\r\n\r\nEnvoyer CV et lettre de motivation avant le 25 février 2017 à\r\nJacqueline Lafont-Terranova - Maitre de conférences au Laboratoire\r\nLigérien de linguistique (Université d\'Orléans) :\r\njacqueline.lafont@univ-orleans.fr et Giulia Ventrella-Proust - Chargée\r\nde la gestion du projet ECRISA à la Maison des Sciences de l\'Homme Val\r\nde Loire : giulia.ventrella@univ-tours.fr'),
(398, '2017-02-08', 'Prosodie', 'Boulogne-Billancourt', 'Filiale du groupe Capgemini depuis juillet 2011, Prosodie conçoit et\r\nhéberge les services Front Office des grands comptes. Elaborées à partir\r\nde technologies propriétaires innovantes, les solutions de Prosodie\r\nrépondent à chacune des étapes du parcours numérique de leurs\r\nutilisateurs. Proposés en mode cloud, les services fournis en  temps\r\nréel s\'appuient sur une plate-forme technique hautement disponible et\r\nsécurisée. Grâce à la dimension internationale de Capgemini,  Prosodie\r\nest en mesure de déployer son offre à l\'international aux côtés des\r\nautres entités du Groupe. Prosodie est déjà présente en France, en\r\nEspagne, en Italie et au Benelux.\r\n\r\n« Le groupe Capgemini est signataire de la Charte de la diversité en\r\nentreprise »\r\n\r\nNous recherchons un(e) :\r\nStagiaire Linguiste H/F\r\nBoulogne-Billancourt\r\nVotre mission\r\nAu sein de la Direction du Développement, vous participez à\r\nl\'amélioration des services notamment en reconnaissance vocale (langage\r\nnaturel, langage dirigé) sur les aspects ergonomie vocale, traitements\r\nlinguistiques (analyse et constitution de corpus (catégorisation de\r\nphrases), préconisation afin d\'optimiser des services existants, ...). \r\n\r\n\r\nProfil recherché\r\n\r\nDe formation Bac + 4/5 en ingénierie linguistique, sciences du langage\r\nou en sciences cognitives, vous recherchez un stage d\'une durée de 6\r\nmois.\r\n\r\nVous maîtrisez :\r\n- Les logiciels de la suite Microsoft Office (word, excel, powerpoint).\r\n\r\nDoté(e) de bonnes capacités à communiquer, votre sens de l\'organisation,\r\nvotre esprit d\'analyse, votre rigueur et votre créativité seront autant\r\nd\'atouts qui vous permettront d\'être performant et de réussir votre\r\nstage. \r\n\r\nEn nous rejoignant vous serez intégré(e) aux équipes projets de Prosodie\r\nbasées à Boulogne-Billancourt, qui vous permettront de développer vos\r\ncompétences autour des process et méthodologies de développement, les\r\nbonnes pratiques dans un contexte professionnel motivant.\r\n\r\nMerci beaucoup pour votre aide.'),
(399, '2017-02-20', 'LI & LIFO', 'Blois ou Orléans', '------------------------------------------------------------------------\r\nPROPOSITION DE STAGE : Techniques de classification pour la résolution \r\ndes coréférences\r\n------------------------------------------------------------------------\r\n\r\nRESUME\r\n------\r\n\r\nStage à connotation recherche sur la réalisation d\'un système de\r\nrésolution des coréférences à l\'aide de techniques de classification\r\nautomatique.\r\n\r\nDurée : 4 mois minimum (stage de fin d\'études)\r\n\r\nLieu d\'exercice : Blois (LI) ou Orléans (LIFO)\r\n\r\nProfil recherché : stagiaire en Master 2 informatique ou\r\nlinguistique-informatique, voire, à des étudiants de Licence 3\r\ninformatique d\'excellent niveau académique.\r\n\r\nCONTEXTE\r\n--------\r\n\r\nLe Laboratoire d\'Informatique de l\'Université de Tours (LI) et le\r\nlaboratoire LIFO (Université d\'Orléans) proposent un stage financé par\r\nla fédération Informatique Centre Val de Loire (LIFO), portant sur\r\nl\'utilisation de techniques de classification et d\'apprentissage\r\nautomatique pour la résolution automatique des coréférences. Le travail\r\nproposé par ces deux laboratoires fait suite au projet régional ANCOR\r\nréalisé en collaboration avec le Laboratoire Ligérien de Linguistique\r\n(LLL) de l\'Université d\'Orléans, et est réalisé en marge du projet ANR\r\nDEMOCRAT (porté par le LATTICE) sur un sujet proche, auquel participent\r\négalement les laboratoires LI et LIFO.\r\n\r\nLa résolution de la coréférence constitue une barrière technologique\r\nimportante pour la recherche d\'information, alors même que les moteurs\r\nde recherche essaient de représenter de plus en plus finement le contenu\r\ndes documents textuels indexés qu\'ils interrogent . On appelle\r\ncoréférence, et plus généralement anaphore, la relation entre deux items\r\nlangagiers telle que l\'interprétation de l\'un dépend de\r\nl\'autre. Considérons l\'exemple : Zoe est venue à la fête avec Isa. Elle\r\nne voulait pas venir seule. Nous sommes en présence d\'une anaphore\r\npronominale entre le pronom elle et son antécédent Zoe, relation qu\'un\r\nsystème doit détecter pour interpréter correctement la seconde\r\nphrase. Cette tâche n\'est jamais triviale : par exemple, dans ce cas, le\r\nsystème pourrait rattacher de manière erronée le pronom à Isa, voire\r\nmême au nom commun fête. Le développement d\'outils performants de\r\nrecherche d\'information dans des flux langagiers passe par une\r\nmodélisation efficace des anaphores.\r\n\r\nL\'importance de la résolution des anaphores a conduit à l\'émergence de\r\ntravaux qui ont fait l\'objet de multiples campagnes d\'évaluation\r\ninternationales (MUC, SemEval, ACE). Le projet ANCOR, porté par le LI, a\r\npermis récemment la création d\'un corpus d\'envergure (488 000 mots) du\r\nfrançais oral (transcrit) annoté en coréférence et anaphores. Sans\r\néquivalent au niveau mondial pour l\'oral, ce corpus constitue une\r\nressource incontournable pour des approches par apprentissage (machine\r\nlearning) de résolution.  Il a ainsi déjà permis l\'apprentissage de\r\nCROC, le premier système francophone de résolution des coréférences\r\ndéveloppé par le laboratoire LATTICE à Montrouge\r\n(http://issuu.com/sfleury/docs/adele-desoyer-memoire-tal-rb-1314/1).\r\n\r\nLe stage qui vous est proposé a pour ambition de réaliser un travail\r\ncomparable de développement d\'un système de résolution, qui tiendra lieu\r\nde système de référence (baseline) pour la comparaison des recherches\r\nfrancophones sur le sujet. En particulier, il vous sera demandé de\r\ndévelopper un système de résolution des coréférences par apprentissage\r\nsur le corpus ANCOR. Ce travail consiste à appliquer sur ce corpus\r\nfrancophone des techniques d\'apprentissage automatique (classifieurs SVM\r\nen particulier) afin d\'identifier automatiquement les paires de mentions\r\n(termes) co-référentes. On utilisera pour cela une plate-forme générique\r\nde classification automatique (Weka).\r\n\r\nTRAVAIL A REALISER\r\n------------------\r\n\r\nPHASE 1 - Développement d\'un système francophone de référence de \r\nrésolution des coréférences (T0 - T0+3)\r\n\r\nLe système sera basé sur l\'utilisation d\'un classifieur SVM disponible\r\nsur la plate-forme Weka et entrainé sur le jeu de traits d\'apprentissage\r\nprésents dans le corpus annoté ANCOR. Ce travail s\'inspirera des\r\nrecherches menées avec le système CROC et se concentra sur la question\r\nde la détection de relations de coréférence entre mentions préalablement\r\nidentifiées. On pourra toutefois viser la réalisation d\'un système\r\ncomplet (end-to-end) par intégration des travaux récents menés au\r\nLATTICE sur la détection automatique des mentions.\r\n\r\nPHASE 2 - Amélioration et évaluation du système (T0+3 - T0+4 ou T0+5)\r\n\r\nEvaluation et optimisation du système : on étudiera l\'influence de\r\ndifférents classifieurs (SVM, arbre de décisions, classifieur bayésien\r\nnaïf...), des méthodes de classification (mention-pair, twin-candidate,\r\nentity mention), des différents traits d\'apprentissage, le tout\r\npermettant une comparaison avec le système CROC.\r\n\r\nRESULTATS ATTENDUS\r\n------------------\r\n\r\n*    Système de résolution des coréférences, qui sera diffusé en open source\r\n*    Evaluation expérimentale du système\r\n\r\nL\'étape d\'évaluation comparative avec le système CROC devrait donner\r\nlieu à une publication scientifique à laquelle participera la personne\r\nrecrutée. L\'ensemble du code développé sera diffusé en open source.\r\n\r\nENCADRANTS\r\n----------\r\n\r\nJean-Yves Antoine (Jean-Yves.Antoine@univ-tours.fr) LI, U.\r\nFrançois-Rabelais Tours\r\nAnaïs Lefeuvre-Halftermeyer (anais.halftermeyer@univ-orleans.fr) LIFO,\r\nU. Orléans\r\n\r\nAutre participants au projet :\r\n\r\nNicolas Labroche     LI, U. François-Rabelais Tours\r\nSylvie Billot        LIFO, U. Orléans\r\nMarcilio de Souto    LIFO, U. Orléans\r\n\r\nPROFIL RECHERCHE\r\n----------------\r\n\r\nIdéalement, la personne recrutée terminera des études de niveau Master\r\n(Master 2) et disposera de connaissances théoriques et pratiques sur les\r\ntechniques de classification automatique. Un intérêt pour la langue et\r\nson traitement automatique serait apprécié, sans être un pré-requis à\r\nrecrutement.\r\nCependant, ce stage est également proposé à des étudiants en fin d\'étude\r\nde Licence (Licence 3) qui disposeraient d\'un excellent niveau\r\nacadémique (mention B en licence au minimum) et désireraient découvrir\r\nla problématique du TALN et de l\'apprentissage automatique.  Date et\r\nlieu de stage\r\n\r\nLa personne recrutée travaillera, à sa convenance, au sein du\r\nlaboratoire LI (antenne universitaire de Blois) ou du LIFO (Campus de la\r\nSource, Orléans). Il s\'intégrera à la fois dans l\'équipe BDTLN\r\n(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) du LI, et\r\nplus précisément dans l\'axe TLN de cette équipe\r\n(http://tln.li.univ-tours.fr/) ainsi que dans l\'équipe Contraintes et\r\nApprentissage (http://www.univ-orleans.fr/lifo/equipes/CA/) du LIFO.\r\n\r\nDUREE ET PERIODE DE STAGE\r\n-------------------------\r\n\r\nLa durée minimale du stage sera de 4 mois et pourra être prolongée à 5\r\nmois si l\'étudiant le désire. Début de stage possible à partir du\r\n27/02/2017.\r\n\r\nREMUNEREE\r\n---------\r\n\r\nLa personne recrutée recevra une gratification mensuelle correspondant à\r\nla réglementation, à savoir 15% du plafond horaire de la sécurité\r\nsociale, soir 3,66 euros par heure de stage. A titre d\'exemple, cette\r\ngratification représente un montant de 554 ¤ pour un mois avec 22 jours\r\nouvrés, et 504 ¤ pour un mois avec seulement 20 jours ouvrés (jours\r\nfériés, par exemple). Pourra également se rajouter une indemnité de\r\ntransports en commun correspondant à 50% d\'un abonnement mensuel\r\nétudiant.\r\n\r\nLa personne recrutée participera aux réunions de l\'équipe projet. Les\r\nfrais de mission induits par ces déplacements seront remboursés.\r\n\r\nCONTACT - DEPOTS DE CANDIDATURES\r\n--------------------------------\r\n\r\nDépôt des candidatures par courrier électronique auprès de Jean-Yves\r\nAntoine et Anaïs Lefeuvre-Halftermeyer, avant le 2 mars 2017 inclus,\r\ndélai de rigueur. Merci de déposer :\r\n\r\n* Un CV détaillé de vos activités passées\r\n* Une lettre de motivation\r\n* Vos relevés de notes des deux dernières années d\'études\r\n* Lettres de recommandation (2 lettres minimum appréciées)\r\n\r\nLe cas échéant, un développement Java et/ou une lecture critique\r\nd\'article scientifique pourront être demandé pour la sélection.\r\n\r\nNous restons à votre écoute pour tout renseignement sur ce stage.\r\n\r\nLIENS UTILES\r\n------------\r\n\r\nCorpus ANCOR : \r\nhttp://www.info.univ-tours.fr/~antoine/parole_publique/ANCOR_Centre/index.html\r\nPlate-forme Weka : http://weka.wikispaces.com/\r\n\r\n\r\nRéférences\r\n\r\nDesoyer A., Landragin F., Tellier I., Lefeuvre A., Antoine J.-Y. (2014)\r\nLes coréférences à l\'oral : une expérience d\'apprentissage automatique\r\nsur le corpus ANCOR, Traitement Automatique des Langues, TAL, vol. 55,\r\n55(2), pp.97-121. [http://www.atala.org/Les-coreferences-a-l-oral-une]\r\n\r\nDésoyer A., Landragin F., Tellier I., Lefeuvre A., Antoine J.-Y.,\r\nDinarelli M. (2016) Coreference Resolution for French Oral Data: Machine\r\nLearning Experiments with ANCOR. Proc. 17th International Conference on\r\nIntelligent Text Processing and Computational Linguistics, CICLing\'2016.\r\nKonya, Turkey. [https://hal.archives-ouvertes.fr/hal-01344977]\r\n\r\nMuzerelle J., Lefeuvre A., Schang E., Antoine J.-Y., Pelletier A.,\r\nMaurel D., Eshkol I., Villaneau J. (2014) ANCOR_Centre, a Large Free\r\nSpoken French Coreference Corpus: Description of the Resource and\r\nReliability Measures. Proc. LREC\'2014, Reykjavik, Islande.\r\n[https://halshs.archives-ouvertes.fr/hal-01075679]');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(400, '2017-02-20', 'Geriico & TVES', 'Lille', '************************************************************************\r\nOFFRE DE STAGE MASTER 1ère ou 2ème - OHM-Littoral Méditerranéen - LabEx\r\nDRIIHM, RATTACHÉ A LA MESHS de Lille (USR 3185 CNRS) \r\n************************************************************************\r\n\r\n************************************************************************\r\nINTITULÉ DU STAGE : EXTRACTION ET ANALYSE D\'INFORMATION A PARTIR DES\r\nRESEAUX SOCIAUX : APPLICATION AUX DONNEES DU PARC NATIONAL DES\r\nCALANQUES.\r\n************************************************************************\r\n\r\nCONTEXTE SCIENTIFIQUE : Ce stage de Master 1 ou 2 s\'inscrit dans le\r\nprojet de recherche intitulé « Les réseaux numériques : un tournant pour\r\nl\'analyse des relations homme-milieux ? Application au parc national des\r\ncalanques » RENUROHM. Ce projet a été sélectionné dans le cadre de\r\nl\'Appel à Projets de Recherche 2016 du LabEx DRIIHM (Dispositif de\r\nRecherche Interdisciplinaire sur les Interactions Hommes-Milieux), au\r\ntitre de l\'Observatoire Hommes-Milieux Littoral\r\nMéditerranéen. L\'Observatoire Hommes-Milieux \"Littoral méditerranéen\"\r\nest un dispositif de recherche interdisciplinaire du CNRS (INEE et\r\nINSHS). Son projet scientifique est l\'étude de l\'urbanisation et de\r\nl\'anthropisation côtière en Méditerranée. Dans un contexte de changement\r\ndes modes de gestion du littoral (GIZC), il s\'intéresse à quatre\r\nsystèmes socio-écologiques littoraux inégalement soumis à\r\nl\'artificialisation et aux fréquentations touristiques et récréatives :\r\nle littoral marseillais, le Golfe d\'Aigues-Mortes et les rivages corses\r\nde Balagne et du sud Bastia. Depuis une quinzaine d\'années, on constate\r\nun développement des humanités numériques provoquant l\'émergence d\'un\r\nnouveau champ de recherche interdisciplinaire, la création de nouveaux\r\ncorpus de données numérisées et la reconfiguration des pratiques ou des\r\nobjets de recherche sous l\'impact des contenus numériques diffusés sur\r\nle web et les réseaux sociaux numériques. La mobilisation des corpus de\r\ndonnées numériques rassemblées sur le web et les réseaux sociaux peut\r\nreprésenter une nouvelle approche de recherche des relations entre\r\nl\'environnement et la société. Des recherches récentes ont analysé le\r\nprocessus de création du Parc national des calanques (Deldrève et\r\nDeboudt, 2012 ; Deboudt et Deldrève, 2015). Dans le cadre du projet\r\nRENUROHM, un premier travail est en cours pour réaliser la cartographie\r\ndes acteurs en lien avec le Parc national des calanques afin\r\nd\'identifier les acteurs qui s\'expriment sur des blogs, sites web ainsi\r\nque sur les réseaux sociaux, à propos de différents sujets en lien avec\r\nce territoire. Nous nous appuyons pour cela sur une méthodologie pour la\r\ncartographie semi-automatisée des acteurs de domaine (Berthelot et al.,\r\n2016). Ce premier travail permettra de produire une première liste\r\nd\'acteurs qui sera utilisée pendant le stage pour réaliser des tâches de\r\nfouille textuelle (Text Mining).\r\n\r\n\r\n************************************************************************\r\nOBJECTIFS : TRAVAUX ATTENDUS : A partir d\'un corpus déjà constitué\r\n(sites web et tweets), il s\'agit de réaliser une analyse\r\nsemi-automatique des contenus des tweets afin d\'identifier les entités\r\nnommés (organisation, personnes et lieux) et les thématiques abordées\r\ndans le texte des tweets. Plus précisément, le stage consistera à\r\nintégrer et enrichir des chaines traitement automatique pour : \r\n\r\n- Extraire des entités nommées à partir de listes préalablement fournies\r\n  d\'acteurs et de lieux et en se basant sur la méthode décrite dans\r\n  (Zenasni et al., 2016) qui permet l\'extraction de nouvelles formes de\r\n  lieux dans les messages courts ;\r\n- Extraire des thématiques en se basant sur des approches fouilles de\r\n  textes (Pak et al. 2014) ;\r\n- Evaluer les résultats obtenus ;\r\n- Réaliser différentes analyses qualitatives et quantitatives sur les\r\n  résultats obtenus et notamment répondre aux questions suivantes :\r\n  Quels sont les acteurs qui s\'expriment sur ces lieux/sujets ? Quelles\r\n  sont les relations entre ces acteurs ? Quelles sont les évolutions\r\n  observées selon différentes temporalités ?\r\n- Participer au travail de valorisation des résultats en enrichissant le\r\n  site Web du projet (en cours de construction).  \r\n\r\nINDEMNISATION, DURÉE ET LIEUX DE TRAVAIL :\r\n- Gratification : 554,40 euros par mois ;\r\n- Ce stage d\'une durée de 4 mois (1er avril 2017 - 31 juillet 2017) se\r\n  déroulera de manière partagée à l\'Université Lille 3 et à l\'Université\r\n  Lille 1, dans les locaux du laboratoire Geriico (Lille 3 ;\r\n  http://geriico.recherche.univ-lille3.fr/) et du laboratoire TVES\r\n  (Lille 1 ; http://tves.univ-lille1.fr/)\r\n\r\n************************************************************************\r\nPROFIL DU CANDIDAT : \r\n\r\n- Master 1ère ou 2ème année en cours ;\r\n\r\n- Formation, compétences et qualités requises : Linguistique ;\r\n  Traitement Automatique des Langues (TAL); Fouille de textes ; la\r\n  maîtrise d\'un langage de programmation est indispensable (java) ; la\r\n  maîtrise du logiciel R serait un plus. Capacité à travailler en équipe\r\n  et à distance. Une connaissance préalable de l\'outre mer ou du Brésil\r\n  sera appréciée.\r\n\r\nCONTACTS ET CALENDRIER : Envoyer un CV détaillé, par mail (1 fichier\r\nPDF), avant le lundi 6 mars 2017 à Eric Kergosien\r\n(eric.kergosien@univ-lille3.fr) et Amel Fraisse\r\n(amel.fraisse@univ-lille3.fr).\r\n\r\n\r\nBibliographie : \r\n\r\n- Arsène S., 2013, Vers une recomposition des pouvoirs : Internet et\r\n  réseaux sociaux, CERISCOPE Puissance, ; \r\n- Deldrève V., Deboudt P. (dir.), 2012, Le parc national des calanques :\r\n  construction territoriale, concertation et usages, QUAE, 231 p. ; \r\n- Deboudt P., Deldrève V., 2015, Inégalités et concertation « encastrée\r\n  » : le projet du parc national des calanques, in L. Mermet et\r\n  D. Salles (dir.), Environnement et transition écologique, De Boeck\r\n  éd., coll. Ouvertures Sociologiques, p. 151-166.\r\n- Berthelot M.-A., Severo M., Kergosien E., 2016, , Cartographier les\r\n  acteurs d\'un territoire : une approche appliquée au patrimoine\r\n  industriel textile du Nord-Pas-de-Calais, In 3ème colloque\r\n  international du CIST (CIST 2016), pp.6, Grenoble.\r\n- Zenasni S., Kergosien E., Roche M., Teisseire M., 2016, Extracting new\r\n  Spatial Entities and Relations from Short Messages, In the 8th\r\n  International ACM Conference on Management of Digital EcoSystems\r\n  (MEDES\'2015), pp. 8, Hendaye (France).\r\n- Alexander Pak and Patrick Paroubek and Amel Fraisse and Gil\r\n  Francopoulo (2014). Normalization of Term Weighting Scheme for\r\n  Sentiment Analysis. Book Chapter, Human Language technology Challenges\r\n  for Computer Science and Linguistics. Series: Lecture Notes in\r\n  Artificial Intelligence, Springer, Vol. 8387. ISBN\r\n  978-3-319-08957-7. Vetulani, Zygmunt, Mariani, Joseph (Eds.). May 27,\r\n  2014. \r\n- Amel Fraisse and Patrick Paroubek (2014). Twitter as a Comparable\r\n  Corpus to build Multilingual Affective Lexicons. In proceedings of the\r\n  7th International Workshop on Building and Using Comparable Corpora at\r\n  LREC 2014 (BUCC 2014), pages 17-21. May 26-31, 2014. Reykjavik,\r\n  Iceland.'),
(401, '2017-02-20', 'EDF', 'Paris', 'INTITULE DE LA MISSION : Déterminer la polarité de données textuelles\r\nissues de réseaux sociaux.\r\n\r\nDate de début : à partir d\'avril 2017\r\n\r\nDurée du stage : 6 mois\r\nNiveau de diplôme préparé : MASTER 2 spécialisé en Traitement\r\nautomatique des langues / Ingénierie Linguistique\r\n\r\nCONTEXTE ET DESCRIPTION DU STAGE\r\n\r\nLe volume des données numériques textuelles, disponibles sur l\'Internet\r\n(forums, twitter etc.) augmente chaque année. L\'analyse de ces\r\ninformations, structurées ou non, est, aujourd\'hui, un impératif\r\nstratégique pour une entreprise telle qu\'EDF.\r\n\r\nA l\'ère du tout numérique, il devient stratégique d\'exploiter\r\nl\'expression spontanée issue des réseaux sociaux dans des délais de plus\r\nen plus courts. Ces derniers sont d\'autant plus importants aujourd\'hui\r\nqu\'ils représentent une mine de précieuses informations.  Etre à\r\nl\'écoute de ses clients, est un des enjeux majeurs de la Direction\r\nCommerce d\'EDF. Dans cette optique, que l\'équipe Text Mining collecte,\r\nanalyse et restitue l\'expression des réseaux sociaux sur EDF.\r\n\r\nLe stage que nous proposons est opérationnel est a pour objectif de\r\nconstituer une classification en polarité (positif, neutre, négatif) de\r\ndonnées textuelles issues du réseau social Twitter.\r\n\r\nLes objectifs de la mission seront de :\r\n\r\n* Constituer un état de l\'art rapide sur la classification en polarité.\r\n* Prendre en main l\'outil d\'extraction de connaissance XIP de Xerox qui\r\n  sera utilisé pour classifier les données.\r\n* Elaborer le modèle de classification et évaluer ses performances.\r\n* Intégrer le modèle dans les chaines de traitement existantes.\r\n\r\nPROFIL RECHERCHE :\r\n\r\n* De formation Master II spécialisé en Traitement Automatique du Langage\r\n* Domaines de compétence requis :\r\n  - Linguistique et informatique\r\n  - Bonnes connaissances en Python\r\n  - Des connaissances en statistique seraient également appréciées\r\n* Rigueur, autonomie et aisance rédactionnelle.\r\n\r\nCONDITIONS DU STAGE :\r\n\r\nLe stage se déroulera au sein des locaux d\'EDF à La Défense et sera\r\nrémunéré.\r\n\r\nLes candidatures sont à adresser à Sofiane KERROUA :\r\nmohamed-sofiane.kerroua@edf.fr'),
(402, '2017-02-23', 'XiKO', NULL, 'XiKO développe un outil d\'analyse de données textuelle robuste que nous\r\néprouvons quotidiennement sur le web. Nous sommes confrontés à de\r\nmultiples problématiques techniques (performance, passage à l\'échelle,\r\nqualité, testabilité) et scientifiques (traitement automatique des\r\nlangues, apprentissage automatique).\r\n\r\nDans le cadre d\'un nouveau projet de traitement automatique des langues,\r\nnous cherchons un stagiaire afin d\'appuyer l\'équipe R&D sur des\r\nproblématiques d\'inférence et de Machine Learning.\r\n\r\nEn collaboration avec l\'équipe R&D le travail du stagiaire consiste à :\r\n\r\n   - Comprendre les enjeux du projet.\r\n   - Effectuer un travail de recherche bibliographique afin de situer le\r\n     problème par rapport à l\'état de l\'art en traitement automatique\r\n     des langues.\r\n   - Choisir les outils adaptés afin de résoudre le problème.\r\n   - Implémenter et tester la solution retenue.\r\n\r\nNotre environnement technique est celui proposé par la boite à outil du\r\nCloud Google. Nous codons en Java, nous déployons nos applications dans\r\nGoogle AppEngine et nous faisons un usage intensif des bases de données\r\nBigQuery et Datastore. Ce stage est donc une opportunité de s\'initier\r\naux technologies du cloud Google.\r\n\r\nNous cherchons un stagiaire avec un goût pour les statistiques et le\r\nMachine Learning. Une expérience avec un outil d\'analyse de donnée\r\n(Matlab, Octave, R) et/ou une librairie de machine learning\r\n(scikit-learn, Torch, TensorFlow) serait très appréciée.\r\n\r\nVous intégrerez une startup innovante, en plein développement et avec\r\nune hiérarchie aussi horizontale que possible. La rémunération mensuelle\r\nest de 1 200¤ net par mois (à négocier en fonction du profil) avec\r\nTicket Restaurant à 10¤/j. Une réelle opportunité d\'emploi pourra être\r\nproposé à l\'issu du stage.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse contact@xiko.fr ou\r\ngael.patin@xiko.fr'),
(403, '2017-03-01', 'Softlaw', NULL, 'Softlaw développe un logiciel à destination des professionnels du\r\ndroit. Cet outil permet l\'analyse et l\'extraction automatisée de données\r\nà partir de documents juridiques. \r\n\r\nDans le cadre d\'un projet de traitement automatique des langues, nous\r\ncherchons un stagiaire afin de consolider l\'équipe R&D sur des\r\nproblématiques d\'extraction de texte, de classification et de Machine\r\nLearning.\r\n\r\nEn collaboration avec l\'équipe technique le travail du stagiaire\r\nconsiste à :\r\n\r\n   - Comprendre les enjeux du projet.\r\n   - Effectuer un travail de veille technologique afin de résoudre un\r\n     problème en suivant l\'état de l\'art en matière de traitement\r\n     automatique des langues.\r\n   - Choisir les outils adaptés afin de résoudre le problème.\r\n   - Implémenter et tester la solution retenue.\r\n\r\nNotre environnement technique s\'articule aujourd\'hui principalement\r\nautour des technologies .NET C# et Sql Server. Nous prévoyons également\r\ndes développements autour des technologies ElasticSearch et React.\r\n\r\nNous cherchons un stagiaire avec un goût pour les challenges techniques\r\net le Machine Learning ayant utiliser au moins un des languages de\r\nprogrammation suivant (Python, R). Une expérience avec un outil NLP\r\n(Gate, Unitex ou Rake) et/ou une des librairies suivantes (scikit-learn,\r\nword2vec, nltk) serait très appréciée.\r\n\r\nVous intégrerez une startup innovante, en plein développement et avec de\r\nmultiples opportunités pour la suite.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse suivante\r\na.labrousse@softlaw.digital.'),
(404, '2017-03-07', 'Advanced Decision', 'Paris', 'Advanced Decision est une startup spécialisée en intelligence\r\nartificielle.\r\n\r\nNous développons une plateforme de composition d\'offre sur mesure dans\r\nle domaine du tourisme.\r\n\r\nElle intègre un module d\'enrichissement sémantique des données d\'une\r\nontologie.\r\n \r\nLe stage a pour but d\'annoter les corpus sociaux :\r\n- Définition d\'étiquettes thématiques \r\n- Segmentation et annotation des corpus\r\n- Réalisation d\'une maquette \r\n- Modélisation pour la phase d\'apprentissage\r\n \r\nNiveau : \r\n- Minimum M1 de TAL, outils d\'annotation\r\n- Connaissances requises en ontologies\r\n- Ingénierie linguistique\r\n  \r\nDurée : entre 3 et 6 mois\r\nDate de début : dès que possible\r\nIndemnité : 554 ¤ / mois\r\nLieu : Paris\r\n \r\nMerci de fournir un CV et une lettre de motivation ainsi que vos relevés\r\nde notes à isabelle.tellier@sorbonne-nouvelle.fr'),
(405, '2017-03-07', 'Expert system', 'Paris', 'Expert System (ex Temis) est une société spécialisée dans l\'extraction\r\nd\'information.\r\n\r\nExpert System propose d\'extraire des textes des informations structurées\r\npour alimenter différents flux de données des entreprises comme le\r\nroutage de mails, la detections de molecules pour de nouveau\r\ntraitements, l\'anonymisation des personnes dans les décisions de\r\njustice.\r\n\r\nMission\r\n\r\nAu sein d\'une équipe R&D, vous allez pouvoir travailler sur :\r\n\r\n- l\'anonymisation des personnes au sein des décisions de justice. Il\r\n  s\'agit de detecter les personnes impliquées dans une décision en\r\n  séparant d\'un côté les personnes de la cours (avocats, juges etc) des\r\n  personnes impliquées dans les faits.\r\n\r\n- l\'identification des données chiffrées des décisions de justice. Il\r\n  s\'agira de détecter par exemple les personnes et les renseignements\r\n  qui les caractérisent comme les revenus, la situation géographique,\r\n  matrimoniale afin d\'aider les personnes à homogénéiser les jugements\r\n  en fonction de la jurisprudence.\r\n\r\nLa base consistera en premier lieu à bâtir un prototype basé sur la\r\nboite à outil maison basée sur des CRF et si le temps le permet, bâtir\r\nd\'autres prototypes à base de réseau de neurones.\r\n\r\nLes responsabilités\r\n\r\nTraitement et analyse des données\r\nVeille sur les différents algorithmes (CRF, NN)\r\n\r\n\r\nProfil\r\n\r\nDiplômé en informatique avec une option Traitement du langage Naturel :\r\n\r\nConnaissances en Java\r\nConnaissances en [CL] machine learning CRF (Wapiti), en reseau de\r\n  neurones (Torch)\r\nConnaissances en python\r\n\r\nDurée : entre 4 et 6 mois\r\nDate de début : dès que possible\r\nIndemnité : 554 ¤ / mois\r\nLieu : Paris\r\n \r\nMerci de fournir un CV et une lettre de motivation ainsi que vos relevés\r\nde notes à isabelle.tellier@sorbonne-nouvelle.fr et\r\nchristian.lautier@temis.com.'),
(406, '2017-03-08', 'Université de Paris 13', 'Villetaneuse', 'Dans le cadre du projet ADADA (Analyse Diachronique Automatique du\r\nDiscours sur les jeux d\'Argent), nous proposons un stage de 4 mois.\r\n\r\nSujet : Analyse Diachronique de Corpus\r\n\r\nLieu du stage : Université Paris XIII (Villetaneuse)\r\n\r\nDébut du stage : Avril/Mai 2017\r\n\r\nMots clés : Analyse Diachronique, Analyse d\'Opinion, Classification \r\nTemporelle, Traitement Automatique des Langues\r\n\r\nDétails :\r\n\r\n  Le projet ADADA est financé par le GIS \"Jeu et Sociétés\" et la\r\nFrançaise des Jeux. Le stage concerne le suivi dans le temps de\r\nl\'actualité concernant les jeux de Hasard et d\'Argent (JHA).\r\n\r\n  Il s\'agit d\'étudier le regard de la société sur les jeux d\'argent et\r\nsur la communauté des personnes qui les pratiquent.\r\n\r\n  Nous souhaitons comparer l\'évolution du discours (polarité,\r\nintensité...) autour des JHA à la réalité des pratiques (quantité d\'argent\r\nparié, évolution de la législation, disparition de certains jeux...).\r\n\r\n  Nous recherchons un candidat niveau Master, informaticien ou linguiste\r\npossédant des connaissances en TAL et ayant une expérience de l\'analyse\r\nde corpus. Des compétences en sociolinguistique, classification ou\r\napprentissage automatique seraient un plus.\r\n\r\nContacts :\r\nGaël Lejeune (LIPN) : gael.lejeune@lipn.univ-paris13.fr\r\nLichao Zhu (LLSHS) : lichao.zhu@univ-paris13.fr'),
(407, '2017-03-14', 'Ixxo', 'Lyon', 'Descriptif de stage\r\n\r\nAméliorations d\'un outil d\'extraction d\'entités nommés et de relations\r\n\r\nLe Stage\r\n\r\nLa société édite et commercialise une solution en mode SaaS (Software as\r\na Service) chargée de collecter de l\'information pertinente sur le\r\nweb. Des traitements d\'analyse sont réalisés sur cette masse\r\nd\'information collectée, et en particulier des traitements d\'extraction\r\nd\'entités nommées (Named Entity Recognition).\r\n\r\nLe but du stage est de contribuer à améliorer et enrichir le modèle\r\nd\'extraction existant et à proposer des solutions pour l\'extraction de\r\nrelations.\r\n\r\nLe stage comprend plusieurs phases :\r\n\r\n- Prise en compte de l\'existant, analyse du besoin\r\n- Propositions fonctionnelles\r\n- Développement des améliorations\r\n\r\nLes compétences\r\n\r\nUne formation informatique en traitement automatique des langues est\r\nexigée (bac +4, ou +5), avec les compétences techniques suivantes :\r\n\r\n- Traitement automatique des langues\r\n- Machine learning\r\n- Programmation Orientée Objet (JAVA)\r\n\r\nConnaissance HTML\r\n\r\nLe candidat devra être capable d\'intégrer des besoins exprimés par\r\nl\'entreprise, et de les traduire en étant force de proposition dans les\r\nsolutions envisagées.\r\n\r\nBien que le stage soit encadré pendant toute sa durée, le candidat devra\r\nfaire preuve d\'une capacité d\'autonomie dans le travail cadré qui lui\r\nsera confié. Il devra également faire preuve d\'organisation et de\r\nrigeur.\r\n\r\nLa compréhension de l\'anglais technique est indispensable.\r\n\r\nL\'entreprise\r\n\r\nLa société ixxo est une entreprise innovante dans le domaine de\r\nl\'Intelligence Economique et de la Gestion des Connaissances située à\r\nLyon.\r\n\r\nDurée du stage : 3 mois\r\n\r\nContact :\r\n  Email : cv@ixxo.fr'),
(408, '2017-03-20', 'CEA-LIST', 'Gif-sur-Yvette', 'Proposition de stage : Utilisation d\'un réseau de neurones récurrent\r\npour la réévaluation des n-meilleures hypothèses d\'un moteur de\r\ntraduction à base d\'exemples\r\n\r\nLieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie\r\ndes Contenus (LVIC), 91 191 Gif sur Yvette\r\n\r\nCONTEXTE :\r\n\r\nLe stage s\'appuiera sur le moteur de traduction à base d\'exemples\r\ndéveloppé au CEA LIST dans le cadre du projet ANR WEBCROSSLING (Semmar\r\net al., 2016). Ce moteur utilise la recherche d\'information interlingue\r\net ne nécessite qu\'un corpus de textes en langue cible. Il est composé\r\nd\'un moteur de recherche interlingue, d\'un reformulateur bilingue et\r\nd\'un générateur de traductions. Le rôle du moteur de recherche\r\ninterlingue est d\'extraire pour chaque phrase à traduire (la requête de\r\nl\'utilisateur) des phrases ou des sous-phrases depuis un corpus\r\nmonolingue indexé dans la langue cible. Ces phrases ou sous-phrases\r\ncorrespondent à une traduction totale ou partielle de la phrase à\r\ntraduire. Le reformulateur bilingue consiste, d\'une part, à produire\r\npour chaque phrase à traduire un ensemble d\'hypothèses de traduction en\r\ntransformant dans la langue cible la structure syntaxique de la phrase à\r\ntraduire, et, d\'autre part, à traduire les mots de cette phrase. Le rôle\r\ndu générateur de traductions est de produire les n-meilleures\r\ntraductions en utilisant les traductions candidates fournies par le\r\nmoteur de recherche interlingue, les hypothèses de traduction produites\r\npar le reformulateur bilingue et le modèle de langue appris à partir du\r\ncorpus en langue cible.\r\n\r\nSUJET DE STAGE :\r\n\r\nLe stage consistera à développer un module basé les réseaux de neurones\r\nrécurrents LSTM (Jozefowicz et al., 2015) pour la réévaluation des\r\nn-meilleures hypothèses produites par le générateur de traductions.\r\n\r\nLe stage comportera les étapes suivantes:\r\n\r\n- Appropriation du moteur de traduction à base d\'exemples développé au\r\n  CEA LIST.\r\n\r\n- Développement d\'un module basé les réseaux de neurones récurrents pour\r\n  la réévaluation des n-meilleures hypothèses produites par le\r\n  générateur de traductions.\r\n\r\n- Intégration du module de réévaluation des n-meilleures hypothèses dans\r\n  le moteur de traduction à base d\'exemples.\r\n\r\n- Evaluation du moteur de traduction à base d\'exemples anglais-français\r\n  en comparant ses résultats avec les résultats produits par le système\r\n  de traduction libre Moses (Koehn et al., 2007).\r\n\r\n- Réalisation d\'une interface graphique pour l\'utilisation du moteur de\r\n  traduction à base d\'exemples.\r\n\r\nBIBLIOGRAPHIE :\r\n\r\n- N. Semmar, O. Zennaki, M. Laib. Etude de l\'impact d\'un lexique\r\n  bilingue spécialisé sur la performance d\'un moteur de traduction à\r\n  base d\'exemples. TALN 2016, Paris, France, 2016.\r\n\r\n- R. Jozefowicz, W. Zaremba, I. Sutskever. An Empirical Exploration of\r\n  Recurrent Network Architectures. 32nd International Conference on\r\n  Machine Learning, Lille, France, 2015.\r\n\r\n- P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico,\r\n  N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar,\r\n  A. Constantin, E. Herbst. 2007. Moses: Open source toolkit for\r\n  statistical machine translation. ACL 2007, demo session, Prague, Czech\r\n  Republic, 2007.\r\n\r\nCONDITIONS DE CANDIDATURE :\r\n\r\nBac+5, stage de fin d\'étude dans le domaine du Traitement Automatique de\r\nla Langue (TAL).\r\n\r\nCompétences en informatique et en TAL.\r\n\r\nProgrammation : C/C++, Python, Perl, Java.\r\n\r\nLangues : Maîtrise de l\'anglais et du français.\r\n\r\nDurée : entre 4 et 6 mois.\r\n\r\nContact et envoi des candidatures (CV détaillé, lettre de motivation et\r\nrelevé de notes de la dernière année d\'études):\r\n\r\nNasredine SEMMAR, Email: nasredine.semmar@cea.fr, \r\nTél: +33 (0)1 69 08 01 46'),
(409, '2017-03-23', 'Université de Lille', 'Lille', 'Stage: Perception de villes et objets intelligents\r\n\r\nhttp://natalia.grabar.free.fr/stage2017vi.php\r\n\r\nLes villes et objets intelligents font doucement leur émergence dans\r\nnos vies. Un des objectifs poursuivi par leurs créateurs consiste à\r\naméliorer la qualité du service mais aussi à réduire les coûts. Par\r\nexemple, dans les villes intelligentes, on cherche à optimiser et à\r\nréduire la consommation d\'eau et d\'électricité, à améliorer et à\r\noptimiser le système de transport, à rendre des objets et services\r\nplus ergonomiques et plus facilement utilisables, sans oublier\r\nl\'aspect esthétique (voir les références). Différentes technologies\r\nsont alors de rigueur, allant de l\'ingénierie et la construction,\r\nnécessaires par exemple pour l\'installation et la maintien de\r\ncapteurs, vers les sciences de l\'information et de la communication,\r\nnécessaires pour la transmission et analyse des informations.\r\n\r\nIl s\'agit d\'un domaine d\'activité récent et nos connaissances sur\r\nl\'acception et la perception des objets et villes intelligents par le\r\ngrand public ne sont pas très évoluées. Nous supposons cependant que\r\nles informations disponibles en lignes (forums de discussion, réseaux\r\nsociaux, instagrammes, tweets...) peuvent fournir ce type\r\nd\'information.\r\n\r\nL\'objectif de ce stage consiste donc à explorer différentes sources\r\nd\'informations disponibles en ligne afin d\'étudier différents\r\naspects. Parmi les questions que l\'on pourrait se poser, mentionnons\r\npar exemple :\r\n\r\n- Comment sont perçus les objets et les villes intelligents ?\r\n- Que pensent les citoyens et les consommateurs de ces objets ?\r\n- Quels sentiments et opinions ces objets provoquent auprès de la population ?\r\n- Quelles sont les pistes d\'amélioration potentielles ?\r\n\r\nPlus spécifiquement, les tâches abordées lors du stage sont :\r\n\r\n- travailler avec des corpus de textes de différents types et\r\n  provenant de différentes sources\r\n- constituer et faire évoluer le corpus\r\n- exploiter et améliorer les annotations des textes avec différents\r\n  niveaux de spécificité\r\n- exploiter, adapter ou développer des méthodes pour l\'extraction\r\n  d\'informations\r\n- évaluer les méthodes et les résultats\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n\r\n- connaissances en TAL et en informatique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique\r\n- maîtrise de l\'anglais\r\n\r\nLe stage est rémunéré.\r\n\r\nNiveau: Master 1, Master 2 ou niveau ingénieur\r\nDurée: 6 mois\r\nLieu: Lille\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de\r\nmotivation, le relevé de notes et les contacts de deux référents à\r\nNatalia Grabar (natalia.grabar@univ-lille3.fr) et Isam Shahrour\r\n(isam.shahrour@univ-lille1.fr)\r\n\r\nRÉFÉRENCES\r\n\r\n    Leyla Zhuhadar, Evelyn Thrasher, Scarlett Marklin, Patricia\r\n    Ordóñez de Pablos. The next wave of innovation - Review of smart\r\n    cities intelligent operation systems. Computers in Human Behavior\r\n    66: 273-281 (2017)\r\n    http://www.sciencedirect.com/science/article/pii/S0747563216306574\r\n\r\n    Albert Meijer, Manuel Pedro Rodríguez Bolívar. Governing the smart\r\n    city: a review of the literature on smart urban\r\n    governance. International Review of Administrative Sciences 82(2)\r\n    (2016)\r\n    http://journals.sagepub.com/doi/pdf/10.1177/0020852314564308\r\n\r\n    Annalisa Cocchia. Smart and Digital City: A Systematic Literature\r\n    Review.\r\n    http://www.springer.com/cda/content/document/cda_downloaddocument/9783319061597-c2.pdf?SGWID=0-0-45-1464919-p176692586\r\n\r\n    Tim Smedley. Top-down or bottom-up? Two visions of smart\r\n    cities. New Scientist, 4 December 2013.\r\n    https://www.newscientist.com/article/mg22029465-000-top-down-or-bottom-up-two-visions-of-smart-cities/\r\n\r\n    Shannon Mattern. A City Is Not a Computer. Places February 2017\r\n    https://placesjournal.org/article/a-city-is-not-a-computer/?gclid=CMqjwcOw29ICFawW0wodx00IRg'),
(410, '2017-03-27', 'E Motion Analysis', 'Paris', 'ENTREPRISE\r\n\r\nE Motion Analysis est une jeune entreprise innovante, composée de jeunes\r\ndiplômés, passionnés d\'analyse sémantique de données textuelles dans le\r\nsecteur de l\'hôtellerie, santé et recrutement.\r\nNotre métier consiste à mettre en place une plateforme d\'annotation,\r\nd\'analyse et de visualisation de données pour aider les professionnels à\r\nprendre les bonnes décisions en innovant sans cesse.\r\n\r\nPOSTE\r\n\r\nNous recherchons actuellement un(e) stagiaire Ingénieur(e) linguiste\r\nmaîtrisant l\'arabe (lu, parlé, écrit).\r\n\r\nVous souhaitez participer à l\'aventure E Motion Analysis,\r\nAllier votre appétence pour la linguistique et vos compétences\r\ntechniques ?\r\nRejoignez-nous ! \r\n\r\nAu sein de notre Pôle R&D et rattaché au Manager Data Scientist, vous\r\naurez l\'occasion de :\r\n- Développer des règles sémantiques \r\n- Enrichir le lexique métier\r\n- Valider les résultats (précision et rappel).\r\n- Formé à nos produits et aux méthodes de création de règles\r\n  sémantiques, vous évoluerez au sein d\'une équipe à taille humaine,\r\n  dans un environnement dynamique et challengeant.\r\nVous bénéficierez d\'un accompagnement au quotidien.\r\nVotre manager s\'engage à ce que vous disposiez des outils nécessaires\r\npour atteindre vos objectifs.\r\n\r\nPROFIL\r\nVous justifiez idéalement d\'une formation de traitement automatique du\r\nlangage naturel\r\nVous maîtrisez le français, l\'anglais et l\'arabe \r\nVous maitrisez un langage de programmation : Python, PHP, Perl...\r\nCe Stage est à pourvoir dès que possible au sein de nos bureaux situés\r\ndans le 15ème arrondissement de Paris.\r\n\r\nCONTACT\r\n\r\ncontact@e-motion-analysis.com'),
(411, '2017-04-18', 'RégionsJob', 'Paris', '*Ingénieur Linguiste Stagiaire H/F*\r\nEntreprise RegionsJob.\r\n\r\nEn 16 ans, nous sommes devenus un acteur incontournable du monde digital\r\nfrançais de l\'emploi.\r\nN°2 français, notre croissance continue dans un marché en perpétuel\r\nmouvement repose sur trois fondamentaux :\r\n\r\n- Notre vision d\'un marché de l\'emploi fragmenté qui rend chaque\r\n  personne unique.\r\n  Chacune de nos marques (Regionsjob, Parisjob, Cadreo, le Blog du\r\n  Modérateur) est la référence auprès de ceux qui cherchent à bouger\r\n  professionnellement.\r\n\r\n- Notre accompagnement terrain au plus près des entreprises.\r\n  Notre équipe commerciale de 95 personnes accompagne, partout en\r\n  France, les entreprises pour trouver les meilleures solutions pour\r\n  recruter toujours dans une logique forte de ROI.\r\n\r\n- Notre forte agilité technologique qui nous permet d\'innover\r\n  constamment et de proposer en permanence des solutions adaptées à\r\n  l\'évolution des usages.\r\n\r\nL\'organisation interne : un fonctionnement en mode startup.  Nous sommes\r\nplus de 170 collaborateurs mais nous avons conservé notre esprit et\r\nnotre agilité propre aux startup.\r\nLes niveaux hiérarchiques sont réduits à leur minimum, notre\r\ncommunication est transparente, notre curiosité est continuellement\r\nstimulée et notre envie d\'être meilleur est notre moteur.  Poste\r\n\r\nAu sein de l\'équipe technique et R&D, vous serez en charge d\'étudier et\r\nde définir des méthodes permettant d\'enrichir nos différents\r\nréférentiels : compétences, métiers, écoles, diplômes, entreprises.\r\n\r\nEn collaboration avec notre chef de produit, vous identifiez, analysez\r\net proposez les différentes sources disponibles : données ouvertes et/ou\r\ndonnées issues de nos bases.\r\nVotre travail sera donc consacré à la conversion de données brutes ou\r\nbalisées (CSV, XML) vers des données sémantiques liées entre elles\r\n(RDF).\r\nCette mission implique de :\r\n\r\n- Comprendre l\'organisation des données existantes.\r\n- Identifier les jeux de données ouverts intéressants à exploiter ainsi\r\n  que les outils/librairies/plateformes qui pourraient être utilisés.\r\n- Définir les types d\'enrichissement possibles et réfléchir aux\r\n  problèmes éventuels qui peuvent être rencontrés (travail de\r\n  normalisation préalable avant conversion, gestion des doublons, etc.).\r\n- Proposer et mettre en place des solutions d\'enrichissement à partir\r\n  des sources de données qui ont été préalablement identifiées.\r\n  En fonction de vos compétences et intérêts, vous pourrez également\r\n  participer :\r\n- À la mise à jour des interfaces qui permettent de consulter ce\r\n  référentiel ou à la définition d\'usages potentiels permis par l\'ajout\r\n  de nouveaux types d\'information fournis.\r\n- Aux différents travaux effectués par l\'équipe technique concernant\r\n  l\'extraction de données au sein de CV, offres d\'emploi ou offres de\r\n  formation.\r\n\r\nTechnologies utilisées : XML, Linked Data (SKOS, RDF, SPARQL,\r\ntriplestore).  Profil recherché\r\n\r\nVous êtes actuellement en formation d\'ingénieur linguiste ou ingénieur\r\nen traitement automatique des langues open data ou en ingénierie des\r\nconnaissances et vous souhaitez compléter votre formation par un stage\r\nrésolument tourné vers l\'opérationnel.\r\nNotre chef de produit vous permettra de monter en compétences et de\r\ntravailler ainsi en autonomie sur un sujet majeur pour notre business.\r\n\r\nCe poste est basé à Rennes au sein de notre siège social. Stage de 3 à 6\r\nmois.\r\n\r\nSalaire : Non précisé.\r\nAnnonce en ligne\r\n\r\nhttp://www.ouestjob.com/emplois/offre-1291242.html\r\nContactCécile bagot (cbagot@regionsjob.com)'),
(412, '2017-05-09', 'Playbots', 'Paris', 'Stage Linguiste\r\n\r\nPlayBots personnalise l\'expérience client grâce à l\'intelligence\r\nartificielle. Nous créons pour des marques prestigieuses (Fnac, Bouygues\r\nImmobilier...) des assistants personnels dotés d\'une véritable personnalité\r\net capables de nouer des relations durables avec les utilisateurs. PlayBots\r\na été fondé par 2 experts du mobile et du divertissement : Jonathan Stock\r\n(ex Studio Manager Gameloft Toronto) et Charles-Antoine Gabrielli (ex Game\r\nDesigner Ubisoft).\r\n\r\nMission\r\n\r\nPour le développement de notre plateforme de création de chatbots, nous\r\nrecherchons un/une linguiste passionné(e) par les nouvelles technologies\r\net l\'intelligence artificielle. Véritable pilier de l\'équipe, vous\r\ntravaillerez en étroite collaboration avec les fondateurs et serez\r\nimpliqué sur tous les aspects du projet. Les tâches seront nombreuses :\r\n- Développement de modèles grammaticaux\r\n- Construction de lexiques sur des sujets spécifiques\r\n- Automatisation de la construction de dialogues en langage naturel\r\n\r\nProfil\r\n\r\nIl est indispensable que vous maitrisiez les domaines suivants :\r\n- Français et anglais : connaissance professionnelle de la grammaire et\r\n  de la sémantique\r\n- Sémantique formelle\r\n- Linguistique structurale\r\n- Langages formels\r\n\r\nOutre vos réalisations et projets personnels, des connaissances dans un\r\nou plusieurs des domaines suivants seront un vrai plus :\r\n\r\n- Expérience avec les services de NLP : api.ai, wit.ai, MS LUIS, Nuance\r\n  Mix, Amazon LEX\r\n- Fouilles de texte\r\n- Expression rationnelle\r\n\r\nNos locaux se situent dans l\'incubateur Paris&Co du CARGO (75019),\r\nvéritable centre d\'accélération des jeunes entreprises innovantes autour\r\ndes contenus numériques et des industries créatives.\r\nParticiper à l\'aventure PlayBots, c\'est la garantie de rejoindre une\r\néquipe talentueuse et ambitieuse dans une startup en croissance !\r\n\r\nDate de début et durée : Dès que possible, pour 4 à 6 mois\r\nRémunération : selon profil\r\nContact : adresser CV + quelques lignes sur vos motivations à\r\njonathan@playbots.io'),
(413, '2017-05-30', 'I3S', 'Sophia Antipolis', 'M2 internship offer: Design of an interface for the visualization of argumentation graphs to explore argumentative structures in natural language.\r\n\r\nArgument mining involves the automatic identification of the\r\nargumentative structures in text, such as premises, conclusions and\r\nthe argumentation patterns, as well as the relations between the\r\narguments (support, attack). To date, researchers have studied methods\r\nfor extracting arguments in areas such as legal documents, online\r\ndebates, product reviews, academic literature, user reviews and\r\nnewspaper articles.\r\n\r\nGiven the output of an argument mining system, the goal of this\r\ninternship is to design and implement an interactive visualization\r\ntool for argument graphs with textual arguments as nodes of the graph,\r\nand the relations between the arguments as edges.\r\n\r\nCandidate\'s profile\r\n---------------\r\n\r\n- Current curriculum: Master 2 in Computer Science, Human Computer\r\n  Interaction or similar.\r\n- Programming skills\r\n- French is not mandatory\r\n\r\nConditions\r\n-----------------\r\nPaid internship of a duration of three months\r\nDeadline for applications: June 15, 2017.\r\nTo apply, please contact: elena.cabrio@unice.fr ; villata@i3s.unice.fr\r\n\r\nNeeded documents: CV, statement of intention, marks.\r\n\r\nHosting team:\r\n \r\nWIMMICS (http://wimmics.inria.fr/) is a research team of Université\r\nCôte d\'Azur (UCA). The research fields of this team are graph-oriented\r\nknowledge representation, reasoning and operationalization to model\r\nand support actors, actions and interactions in web-based epistemic\r\ncommunities.\r\n\r\nLocation: I3S laboratory, Sophia Antipolis, France.\r\n\r\nContract type: internship.\r\n\r\nStart: July-August 2017'),
(414, '2017-06-26', 'Softlaw', 'Paris', 'Offre de stage : Ingénieur Data Science / Machine Learning\r\n\r\nSOFTLAW est une jeune start-up dans le secteur des legaltech. Nous\r\ndéveloppons un logiciel de revue automatique de documents juridiques\r\nutilisant l\'intelligence artificielle pour extraire automatiquement les\r\ninformations clés des documents juridiques et les analyser.\r\n\r\nMISSIONS :\r\n\r\nDans le cadre d\'un projet de traitement automatique des langues et de\r\nMachine Learning, le stagiaire participera avec l\'équipe technique à\r\nplusieurs des travaux et activités suivantes :\r\n\r\n- Développement Machine Learning en Python : collecte, nettoyage,\r\n  classification des données grâce aux algorithmes ML supervisé/non\r\n  supervisé, analyse des métriques, recherche et développement des\r\n  techniques de détection de similarité;\r\n\r\n- Création, implémentation et tests d\'algorithmes de Machine Learning et\r\n  d\'analyse sémantique en langage naturel et traitement automatique de\r\n  la langue;\r\n\r\n- Réalisation d\'outils de text mining utilisant des techniques NLP;\r\n\r\n- Création, implémentation et tests de modèles d\'extraction et d\'analyse\r\n  de données + mesure de la qualité de ces modèles;\r\n\r\nCe poste est basé à Paris 13 (proche 14ème). \r\nStage de 3 à 6 mois\r\n\r\n\r\nAxel Labrousse <a.labrousse@softlaw.digital>\r\n\r\nhttp://www.softlaw.digital/'),
(415, '2017-06-26', 'Sewote', 'Paris', 'Offre de stage « ingénieur linguiste junior »\r\n\r\nCréée en avril 2016, Sewote est une start-up spécialisée dans la R&D en\r\nlinguistique informatique. Nous développons des logiciels applicatifs\r\nsémantiques dans l\'optique de proposer des solutions clés en main aux\r\norganisations souhaitant perfectionner leurs processus métier. Notre\r\néquipe est composée d\'experts et de professionnels de l\'information et\r\nde la linguistique informatique.\r\nNous sommes à la recherche d\'un ingénieur linguiste un stage de 6 mois\r\nafin de travailler à l\'élaboration de ressources électroniques en langue\r\nanglaise.\r\n\r\nDébut de stage : 1er octobre 2017\r\n\r\nCompétences requises :\r\nTraitement Automatique des Langues \r\nOS : Linux et Windows\r\nTechnologie : NOOJ et/ou UNITEX\r\nLangages informatiques : Perl/Python/Java\r\nLangues : anglais courant (anglais des affaires)\r\n\r\nLieu du stage : Pépinière 27 - 27 rue du Chemin Vert 75011 Paris\r\nIndemnités de stage : 554 ¤ + remboursement de 50% du ticket de\r\ntransport\r\n\r\nSi vous êtes intéressé par cette offre, merci d\'envoyer votre\r\ncandidature à julien.letailleur@sewote.com'),
(416, '2017-08-16', 'EDL', 'Berre L\'étang (13)', '*Analyse de fonctionnement de la reconnaissance vocale*\r\n\r\n(TAL ou Linguistique avec des compétences informatiques)\r\n\r\n*Mots clés :* *reconnaissance vocale, correction orthographique et\r\nsyntaxique, transcription phonétique, recherche textuelle avec REGEX*\r\n\r\nSociété leader des solutions informatiques pour les services d\'Imagerie\r\nMédicale publics et privés recherche un(e) stagiaire niveau M1 ou M2.\r\n\r\nLe stage consiste en l\'analyse des erreurs textuelles de la\r\nreconnaissance vocale. Le stagiaire effectuera la comparaison des\r\nrésultats issus du moteur de la reconnaissance avec les fichiers son. Le\r\nrésultat de l\'analyse aboutit en un feedback avec une typologie\r\nd\'erreurs récurrentes.\r\n\r\n*Compétences requises : *\r\n\r\n- linguistique (phonétique, orthographe et syntaxe),\r\n\r\n- très bonne maitrise de la grammaire française\r\n\r\n- rigueur et attention aux détails\r\n\r\n- compétences informatiques\r\n\r\n- maitrise de REGEX ainsi que d\'un langage de programmation serait un\r\n  plus\r\n\r\n- la connaissance du domaine médical serait un plus\r\n\r\n\r\n*Début de stage :* dès que possible\r\n\r\n*Durée de stage :* 6 mois\r\n\r\n*Lieu de stage :* Berre L\'Etang\r\n\r\nRémunération selon profil\r\n\r\n\r\nAdresser CV + lettre de motivation à : mtaranina@edl.fr'),
(417, '2017-10-16', 'Inalco', 'Paris', '*Ingénierie R&D pour une BDD web de textes historiques en quechua et en\r\nguarani*\r\nStage au laboratoire ERTIM (INALCO)\r\n\r\n*Contexte*\r\n\r\nLe projet ANR LANGAS (http://www.langas.cnrs.fr, 2014-2017) a permis la\r\nconstitution d\'une volumineuse base de textes (125 documents, ~290K\r\nmots) en quechua et en guarani, liés à la colonisation espagnole et\r\nportugaise de l\'Amérique du Sud.\r\n\r\nCette base documentaire a été constituée par des anthropologues à l\'aide\r\nd\'un site web adapté à leurs besoins, notamment en proposant\r\nd\'enregistrer les textes alignés en trois versions : paléographique,\r\ntranslittérée et traduite en espagnol. Ces enregistrements ont\r\nl\'avantage d\'être correctement stockés et alignés, mais des\r\naméliorations de la BDD sont nécessaires, avec en prolongement un\r\npossible travail en appui à la recherche.\r\n\r\nEn collaboration avec l\'équipe LANGAS du laboratoire CREDA UMR 7227,\r\nl\'équipe ERTIM propose un stage de 3 mois sur le sujet, qui vise à\r\nrépondre à ces besoins, prioritairement en développement, mais avec\r\naussi des perspectives en matière de recherche, selon l\'avancement.\r\n\r\n*Objectifs principaux*\r\n\r\n1/ Ré-encodage cohérent de la BDD pour faciliter son interrogation\r\n2/ Adaptation des scripts Angular pour les recherches (classes de\r\n   caractères, prise en charge de diacritiques, collations)\r\n3/ Implémentation d\'un script de pré-translittération automatique (par\r\n   règles de transduction, par ex. extraites semi-automatiquement)\r\n4/ Fouille des données (text mining) en interaction avec les\r\n   anthropologues dans une perspective socio-linguistique.\r\n\r\n*Profil recherché*\r\n\r\n- Informatique avec des connaissance web (idéalement Angular)\r\n- Connaissance des BDD (MySQL) et des encodages (UTF8)\r\n- Un intérêt pour le TAL et pour les sciences humaines est un plus\r\n- La connaissance de l\'espagnol ou de langues sudaméricaines est un plus\r\n\r\n*Contexte*\r\n\r\n- Durée du stage : 3 mois à temps plein\r\n- Date de début : dès que possible\r\n- Rémunération : tarif en vigueur (510¤/mois, rbst de 50% navigo)\r\n- Lieu : INALCO, 2 rue de Lille, 75007 Paris\r\n\r\n*Candidature*\r\n\r\nMerci d\'envoyer votre CV et de faire part de vos motivations à Damien\r\nNouvel (damien.nouvel@inalco.fr), Marie-Anne Moreaux\r\n(marie-anne.moreaux@inalco.fr), Capucine Boidin\r\n(capucine.boidin@univ-paris3.fr.'),
(418, '2017-10-23', 'Clesthia & Lidilem', 'Paris et Grenoble', '************************************************************************\r\n\r\nOffre de stage\r\n\r\nDans le cadre d\'un financement CORLI-Ortolang obtenu conjointement par\r\nles laboratoires CLESTHIA et LIDILEM, nous recherchons 2 stagiaires pour\r\nla période de décembre 2017 à Février 2018 (durée 2 mois et demi,\r\ngratification de 1800¤/brut au total). L\'un des stagiaires sera rattaché\r\nau laboratoire CLESTHIA (Paris Sorbonne), l\'autre au laboratoire LIDILEM\r\n(Campus de Grenoble).\r\n\r\nContexte\r\n\r\nLes deux laboratoires ont constitué et continuent d\'alimenter des corpus\r\nd\'écrits d\'élèves :\r\n\r\n- pour Lidilem, un corpus longitudinal couvrant l\'ensemble de l\'école\r\n  élémentaire (du Cours Préparatoire au Cours Moyen 2) : corpus Scoledit\r\n  ; ce corpus est constitué de productions suscitées par la recherche ;\r\n\r\n- pour Clesthia, un corpus reflétant le développement des compétences\r\n  scripturales du début de l\'école primaire à l\'université : corpus\r\n  Ecriscol ; ce corpus est constitué de productions écologiques.\r\n\r\nCes deux corpus sont déjà en partie accessibles, avec les\r\nenrichissements disponibles :\r\n\r\n- Ecriscol : http://syled.univ-paris3.fr/ecriscol/CORPUS-TEST/\r\n- Scoledit : http://otus.u-grenoble3.fr/scoledit\r\n\r\nLes caractéristiques des corpus réunis ainsi que les objets de recherche\r\nprivilégiés par les équipes ont conduit à élaborer des procédures de\r\ntraitement différentes dont les résultats sont dans des formats\r\nspécifiques que l\'on veut faire converger vers un format partagé\r\n(XML-TEI).\r\n\r\nMissions\r\n\r\n- Analyse des spécificités du corpus Ecriscol (stagiaire Clesthia) ou du\r\n  corpus Scoledit (stagiaire Lidilem).\r\n- Mise en commun de ces analyses\r\n- Étude du standard XML-TEI\r\n- Proposition d\'un format commun, pour les deux corpus\r\n  Ecriscol/Scoledit, aux normes TEI\r\n- Conception et développement de routines de conversion ou d\'aide à la\r\n  conversion pour le passage des formats actuels des corpus au format\r\n  commun.\r\n\r\nProfil demandé\r\n\r\n- Niveau master 2 en Traitement Automatique des Langues\r\n- Compétences XML\r\n- Compétences en développement informatique (langage non défini mais\r\n  adapté au développement de routines d\'extraction et de conversion du\r\n  type Python, Perl, Java...).\r\n- Une connaissance de la TEI serait un plus.\r\n\r\nContacts\r\n\r\n- CLESTHIA : Serge Fleury (sergefleury@gmail.com)\r\n- LIDILEM : Claude Ponton (claude.ponton@univ-grenoble-alpes.fr)');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(419, '2017-10-24', 'LIDILEM', 'Grenoble', 'Offre de stage - Master 2 - Industries de la langue, TAL, linguistique\r\ninformatique, Technologies du langage\r\n\r\n\r\nNom du projet  : Projet LaST : Lexique aligné Scientifique Transdisciplinaire.\r\n\r\nVers l\'élaboration d\'une ontologie interlingue pour le Lexique\r\nScientifique Transdiciplinaire (LST) à partir d\'un lexique bilingue\r\naligné avec des techniques de traitement automatique du langage.\r\n\r\n\r\nCompétences requises : La/le candidat.e devra être titulaire d\'un\r\nmaster 1 en Industries de la langues ou Traitement automatique des\r\nlangues (ou domaine voisin : linguistique informatique, humanités\r\nnumériques, etc.) et suivre un M2 correspondant. Elle/il aura des\r\ncompétences en traitement de corpus au format XML, ainsi que des\r\ncompétences en programmation (Perl ou Python) afin de mettre en oeuvre\r\ndes chaînes de traitement complexes (étiquetage, alignement,\r\nprojection d\'un lexique sur un corpus, etc.).\r\n\r\n\r\nDurée du stage : 3 mois et demi\r\n\r\n\r\nGratification : 554,4 euros mensuels (Financement Neurocog/Pôle cognition)\r\n\r\n\r\nObjectifs du projet\r\n\r\nLe discours scientifique intègre un lexique relevant de catégories\r\nsémantiques et épistémologiques spécifiques, le lexique scientifique\r\ntransdisciplinaire (Pecman 2004, Paquot 2010, Hatier et al. 2016). Ce\r\nlexique intègre des unités lexicales comme hypothèse, montrer,\r\nquantitatif mais aussi des expressions polylexicales et des routines\r\nplus larges comme obtenir des résultats encourageants, comme on l\'a vu\r\nprécédemment, les résultats montrent que ... La constitution d\'un tel\r\nlexique est particulièrement utile pour plusieurs types\r\nd\'applications. En traitement automatique des langues, il peut être\r\nexploité dans plusieurs types d\'applications comme l\'indexation\r\nautomatique et la fouille de données. Les applications didactiques\r\nsont également nombreuses : aide à la rédaction scientifique, outils\r\nd\'aide à la lecture de textes scientifiques, outil d\'aide à la\r\ntraduction, entre autres.\r\n\r\nDans le cadre du projet ANR Termith (2012-2016), le LIDILEM a élaboré\r\nun lexique sémantique de ce type discours intégrant des étiquettes\r\nsémantiques et une organisation ontologique, à partir d\'informations\r\nobtenues à partir de techniques distributionnelles appliquées à des\r\ncorpus du français (Hatier et al. 2016). Dans le cadre du présent\r\nprojet, nous souhaitons étendre ce lexique à une version anglaise, en\r\nexploitant des techniques d\'alignement de corpus (Schulz et al. 2016,\r\nKraif, 2015, Och et al. 1999) et des méthodes d\'analyse\r\ndistributionnelle sémantique, permettant de caractériser le sens des\r\nmots à partir de leurs contextes phrastiques (Mikolov et al. 2013,\r\nltszyler et al., 2016). Le lexique constitué pourra servir de base à\r\nun projet d\'aide à la rédaction scientifique (projet de soumission de\r\nthèse dans le cadre de l\'IDEX IRS).\r\n\r\n\r\nMissions\r\n\r\nLa/le stagiaire partira du corpus existant afin de mettre en place une\r\nchaîne de traitement permettant l\'alignement des textes\r\nparallèles. Elle/il effectuera une évaluation préalable de deux\r\naligneurs (Yasa et Hunalign) sur les textes du corpus, afin de\r\nsélectionner le plus adapté des deux. Elle/il effectuera dans un\r\nsecond temps un alignement au niveau lexical (avec Giza++) et un\r\nétiquetage des parties françaises et anglaises du corpus.\r\n\r\nPartant de ces alignements, elle/il effectuera une projection du LST\r\ndu français vers l\'anglais (mots simples mais aussi collocations), et\r\nétudiera les meilleurs critères pour effectuer le filtrage des\r\ncandidats à la traduction. Les résultats seront comparés à\r\nl\'interlexique élaboré par F. Gilles dans sa thèse.\r\n\r\nLa chaîne de traitement devra être conçue pour autoriser le traitement\r\nrapide de nouveaux textes alignés (un autre stagiaire se chargera de\r\nl\'augmentation du corpus, en parallèle).\r\n\r\nLes questions de recherches liées au stage auront trait à la\r\ndescription et à la structuration sémantique de ce lexique\r\ninterlingue.\r\n\r\nPour candidater :\r\n\r\nEnvoyer un CV et une lettre de motivation à\r\nolivier.kraif@univ-grenoble-alpes.fr avant le 10 novembre 2017.\r\n\r\nRéférences\r\n\r\nGilles, F. (2017) Valorisation des analogies lexicales entre l\'anglais\r\net les langues romanes : étude prospective pour un dispositif\r\nplurilingue d\'apprentissage du FLE dans le domaine de la santé, Thèse\r\nde doctorat, sous la dir. de C. Degache et O. Kraif, Université\r\nGrenoble Alpes\r\n\r\nHatier, S., Augustyn, M., Tran, T. T. H., Yan, R., Tutin, A., Jacques,\r\nM.-P. (2016). \"French Cross-disciplinary Scientific Lexicon:\r\nExtraction and Linguistic Analysis\", Euralex 2016, Tbilissi, Géorgie,\r\n6-10 September 2016.\r\n\r\nAltszyler, E., Ribeiro, S., Sigman, M., Fernández Slezak, D. (2016)\r\n\"Comparative study of LSA vs Word2vec embeddings in small corpora: a\r\ncase study in dreams database\". arXiv:1610.01520\r\n\r\nOch, F.J. and Tillmann, C. and Ney, H. and others (1999) Improved\r\nalignment models for statistical machine translation, Proc. of the\r\nJoint SIGDAT Conf. on Empirical Methods in Natural Language Processing\r\nand Very Large Corpora\r\n\r\nMikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean J. (2013)\r\nDistributed representations of words and phrases and their\r\ncompositionality, Advances in neural information processing systems.\r\n\r\nPaquot, M. (2010). Academic vocabulary in learner writing: From\r\nextraction to analysis. London: Continuum.\r\n\r\nPecman M. (2004). Phraséologie contrastive anglais-français : analyse\r\net traitement en vue de l\'aide à la rédaction scientifique, Thèse en\r\nSciences du Langage, Université Sophia Antipolis, UFR Lettres, Arts et\r\nSciences Humaines\r\n\r\nSchulz, P., Wilker A. and Sima\'an, K. (2016): Word Alignment without\r\nNULL Words, Proceedings of the 54th Annual Meeting of the Association\r\nfor Computational Linguistics (Volume 2: Short Papers)'),
(420, '2017-10-30', 'Météojob', 'Paris', '*Infolinguiste (stage de fin d\'études) H/F*\r\n\r\nVous connaissez le groupe Meteojob? Nous sommes une entreprise en forte\r\ncroissance dont la vocation est d\'aider les recruteurs et les candidats\r\nà se rencontrer plus rapidement, et plus efficacement. Notre groupe,\r\nc\'est notamment le site internet Meteojob.com avec 3.2 millions\r\nd\'inscrits, 1.5 million d\'offres d\'emploi par an et VisioTalent, une\r\nplateforme d\'entretiens video différés qui change la vie des candidats\r\net des recruteurs. Mais notre groupe c\'est bien plus encore : Notre\r\nvocation est de créer des applications remarquables qui permettent à des\r\nmillions de personnes de (re)trouver un emploi.\r\n\r\nNous recrutons aujourd\'hui de nouveaux talents qui veulent rejoindre\r\nnotre aventure humaine et être les moteurs d\'un développement important\r\ndans les années à venir.\r\n\r\n\r\nDescription du poste :\r\n\r\nPour alimenter son processus de matching, Meteojob développe des outils\r\nd\'analyse sémantique avancée des contenus des CV et offres ainsi que des\r\nréférentiels métiers. Pour renforcer son équipe, Meteojob propose un\r\nstage de fin d\'études en traitement automatique des langues, basé à\r\nParis, au sein du pôle sémantique/big data.\r\n\r\nVos principales missions seront:\r\n\r\n- Le développement et la maintenance des composants d\'analyse des CV et\r\n  offres (basés sur des grammaires locales et de l\'apprentissage\r\n  machine)\r\n\r\n- Le portage de ces composants sur des langues étrangères (à commencer\r\n  par l\'anglais)\r\n\r\n- Le maintien de la cohérence des référentiels existant\r\n\r\n- L\'enrichissement (multilingue) de ces référentiels\r\n\r\n- La validation des composants produits\r\n\r\n\r\nVous travaillerez en relation étroite avec les autres membres du pôle\r\nsémantique/big data et serez intégré(e) à l\'ensemble de l\'équipe de\r\ndéveloppement de Meteojob.\r\n\r\nDescription du profil :\r\n\r\nCompétences requises:\r\n\r\n- TAL (étude de corpus, moteur de recherche, grammaires locales,\r\n  apprentissage)\r\n\r\n- Exploitation de données ouvertes (open data)\r\n\r\n- Connaissance du developpement Java et des outils de développement en\r\n  équipe (gestion de versions, d\'anomalies, développement agile, etc...)\r\n\r\n- Maîtrise de l\'anglais (la connaissance d\'autre langues européennes est\r\n  un plus)\r\n\r\n- Des connaissances en language de scripts (Perl, Groovy, Python),\r\n  Spark, UIMA ou bases de données sont des plus\r\n\r\n- Facilité à travailler en équipe\r\n\r\n\r\nN\'hésitez pas à envoyer votre candidature à benedicte.buchet@meteojob.com'),
(421, '2017-11-06', 'Sewote', 'Paris', 'Offre de stage \r\n« Ingénieur linguiste junior »\r\n\r\nCréée en avril 2016, Sewote est une start-up spécialisée dans la R&D en\r\nlinguistique informatique. Nous développons des logiciels applicatifs\r\nsémantiques dans l\'optique de proposer des solutions BtoB de traitement\r\nautomatique des données écrites. Notre équipe est composée de\r\ndéveloppeurs informatiques, de professionnels de l\'information et de\r\nlinguistes informaticiens.\r\n\r\nNous sommes à la recherche d\'un ingénieur linguiste pour un stage de 6\r\nmois afin de travailler à la réalisation de nos projets sémantiques\r\nainsi qu\'à l\'élaboration de nos différentes ressources électroniques en\r\nlangue française et anglaise.\r\n\r\n\r\nDébut de stage : 1er janvier 2018\r\n\r\nCompétences requises :\r\nTraitement Automatique des Langues\r\nGestion de projet \r\nOS : Linux et Windows\r\nTechnologie : NOOJ et/ou UNITEX\r\nLangages informatiques : Perl/Python/Java\r\nLangues : anglais courant (anglais des affaires)\r\n\r\nLieu du stage : Pépinière 27 - 27 rue du Chemin Vert 75011 Paris\r\nIndemnités de stage : 554 ¤ + remboursement de 50% du ticket de\r\ntransport\r\n\r\nSi vous êtes intéressé par cette offre, merci d\'envoyer votre\r\ncandidature à julien.letailleur@sewote.com'),
(422, '2017-11-09', 'GREYC', 'Caen', 'Proposition de stage de recherche M2\r\nLaboratoire GREYC - Equipe HULTECH - UniversitÃ© Caen Normandie\r\n\r\nDÃ©sambiguÃ¯sation des structures prÃ©dicatives basÃ©es sur \"devoir\" ou\r\n\"pouvoir\" : constitution d\'un corpus, apprentissage et Ã©valuation\r\n\r\nLe stage proposÃ© se situe dans le cadre d\'un projet en cours menÃ© par\r\ndes membres de l\'Ã©quipe HULTECH du GREYC avec l\'entreprise Noopsis\r\n(Caen, essaimage du GREYC) sur la recherche et l\'extraction\r\nd\'informations dans des textes de `news\' de type journalistique. Plus\r\nspÃ©cifiquement, notre collaboration concerne des constructions\r\nlinguistiques dans lesquelles un verbe (conjuguÃ© en gÃ©nÃ©ral, le coverbe)\r\ncommande un verbe Ã  l\'infinitif (le prÃ©dicat). Le coverbe apporte une\r\ninformation importante, une Â« qualification Â» sur l\'Ã©vÃ©nement exprimÃ©\r\npar le prÃ©dicat, telle que : temporalitÃ© ou phase (exemple 1), intention\r\n(2), modalitÃ© d\'exÃ©cution (3), obligation ou possibilitÃ© (4), etc.\r\n\r\n(1) Jean va/vient de/commence Ã ...travailler \r\n(2) Jean espÃ¨re/ redoute de/ veut/ne veut pas...travailler\r\n(3) Jean se hÃ¢te de/s\'efforce de/peine Ã ...travailler\r\n(4) Jean doit/devrait/devait/peut/pourra/n\'a pas pu...travailler\r\n\r\nDans ce cadre gÃ©nÃ©ral, on s\'intÃ©ressera dans le stage aux deux derniers\r\ncoverbes : devoir et pouvoir : extrÃªmement frÃ©quents dans nos corpus,\r\nils reprÃ©sentent une fraction trÃ¨s importante (jusqu\'Ã  un tiers) des\r\nconstructions Ã  infinitive. Or ils sont l\'un comme l\'autre\r\nfondamentalement ambigus, avec chacun deux pÃ´les de signification,\r\nillustrÃ©s par les exemples ci-dessous (extraits de nos corpus).\r\n\r\n- Pour devoir : valeurs d\'obligation (dÃ©ontique) (5) et de plausibilitÃ©\r\n  (Ã©pistÃ©mique) (6).\r\n  \r\n- Pour pouvoir : valeurs de capacitÃ© - matÃ©rielle, juridique,\r\n  logique...- (dite aussi radicale) (7) et Ã©pistÃ©mique (8) les deux\r\n  pouvant facilement coexister (9)\r\n  \r\n(5) Il s\'agirait d\'un vÃ©hicule conÃ§u pour le marchÃ© nord-amÃ©ricain;\r\ncependant, avant de passer Ã  l\'Ã©tape de la commercialisation, il devra\r\npasser les tests de collision du gouvernement des Etats-Unis.\r\n\r\n(6) Les premiers vÃ©hicules de ce modÃ¨le, Ã©quipÃ©s de moteurs Ã©lectriques\r\nSiemens, devraient commencer les premiers essais sur route Ã  la fin de\r\nl\'annÃ©e 2011\r\n\r\n(7) D\'autre part, elle peut aller jusqu\'Ã  205 km/h avec une batterie au\r\nnickel-cadmium.\r\n\r\n(8) L\'essence peut monter en bourse, Ã§a ne fera qu\'augmenter le prix du\r\ncarburant.\r\n\r\n(9) Sur la durÃ©e de vie de la voiture, un conducteur pourrait Ã©conomiser\r\nplus de 22.000 litres d\'essence.\r\n\r\n\r\nCe phÃ©nomÃ¨ne a de longue date fait l\'objet de recherches en sÃ©mantique\r\nlinguistique [Fuchs, 1989] mais pas Ã  notre connaissance en termes de\r\ntraitements automatiques visant une dÃ©sambiguÃ¯sation en contexte. Tel\r\nest a contrario l\'objet de ce stage.\r\nUne prÃ©-Ã©tude a permis d\'identifier un certain nombre de traits,\r\nmorphosyntaxiques ou autres, aiguillant de maniÃ¨re plus au moins marquÃ©e\r\nvers un sens ou un autre. A titre d\'exemple : le conditionnel et\r\nl\'imparfait de devoir (devrait, devait) orienterait trÃ¨s fortement vers\r\nun sens Ã©pistÃ©mique, le futur et le passÃ© composÃ© (devra, a dÃ» vers un\r\ndÃ©ontique. De mÃªme le conditionnel de pouvoir (pourrait) tire fortement\r\nvers l\'Ã©pistÃ©mique et les temps autres que le prÃ©sent (pourra, pouvait,\r\na pu) vers la capacitÃ©, le prÃ©sent peut Ã©tant plus indÃ©terminÃ©.\r\n\r\n\r\nNotre objectif dans ce stage sera de valider, prÃ©ciser,\r\nsystÃ©matiser... ces premiÃ¨res analyses Â« manuelles Â» en appliquant des\r\nmÃ©thodes d\'apprentissage automatique. Pour ce faire, deux Ã©tapes sont\r\nnÃ©cessaires :\r\n\r\n1. Ã‰tablissement d\'un Gold Standard\r\nPour mener Ã  bien l\'Ã©valuation d\'un tel systÃ¨me, il sera nÃ©cessaire de\r\ndisposer d\'un corpus annotÃ© de rÃ©fÃ©rence (Gold Standard) auquel\r\nconfronter les productions de ce dernier. La constitution de ces\r\nannotations de rÃ©fÃ©rence pourra s\'appuyer, de faÃ§on assez classique, sur\r\ndes annotations manuelles multiples (plusieurs annotateurs annotent\r\nmanuellement et indÃ©pendamment le mÃªme corpus) en vÃ©rifiant, grÃ¢ce Ã  une\r\nmesure d\'accord inter- annotateurs, qu\'un consensus entre annotateurs se\r\ndÃ©gage, et que les annotations de ces derniers peuvent servir (moyennant\r\nun Ã©ventuel ajustement) de rÃ©fÃ©rence. Ce stage pourra Ã©ventuellement\r\nconstituer un premier pas vers une thÃ¨se concernant la constitution\r\nd\'annotations et les mesures d\'accord inter-annotateurs, notamment\r\nautour des travaux actuellement menÃ©s au GREYC [Mathet et al., 2015,\r\n2016, 2017].\r\n\r\n2. Application de technique(s) d\'apprentissage automatique\r\nUne fois le corpus annotÃ© de rÃ©fÃ©rence (Gold Standard) Ã©tabli, celui-ci\r\nsera exploitable par des techniques d\'apprentissage (en tant\r\nqu\'Ã©chantillon d\'apprentissage). Pour reprÃ©senter chaque exemple de\r\nl\'Ã©chantillon, des attributs pertinents seront Ã  dÃ©finir (temps du\r\ncoverbe, mode, type de prÃ©dicat...) et Ã  extraire automatiquement des\r\ntextes. Diverses techniques d\'apprentissage [CornuÃ©jols et Miclet, 2010]\r\npourront Ãªtre exploitÃ©es - tÃ¢che pour laquelle des procÃ©dures ont dÃ©jÃ \r\nÃ©tÃ© dÃ©veloppÃ©es au GREYC [Alec et al., 2014, 2016, Govind et Spaniol,\r\n2017] -, aussi bien du type Â« boÃ®tes noires Â» (telles que les SVM) que\r\ndes techniques plus lisibles pour un Ãªtre humain (telles que les arbres\r\nde dÃ©cision).\r\n\r\nCe stage est susceptible de bÃ©nÃ©ficier d\'un financement, en fonction\r\nnotamment de la qualitÃ© de la candidature.\r\n\r\nContact : yann.mathet@unicaen.fr'),
(423, '2017-11-20', 'LIUM', 'Le Mans', 'Le Laboratoire d\'Informatique de l\'UniversitÃ© du Mans (LIUM) recherche\r\nun stagiaire de Master (6 mois) pour un projet en lien avec l\'indexation\r\net la fouille de documents d\'un corpus mÃ©tier SNCF.\r\n\r\n*Sujet *: Apprentissage automatique et TAL pour l\'indexation de\r\ndocumentation technique\r\n\r\n*Contexte du stage* : Au Mans, laboratoire LIUM, Ã©quipe LST, financement\r\nsur projet encollaboration avec la SNCF\r\n\r\n*Mots-clÃ©s :* Apprentissage supervisÃ©, traitement automatique de la\r\nlangue naturelle, indexation, lexique technique, documentation mÃ©tier\r\n\r\n------------------------------------------------------------------------\r\n\r\nSujet de stage recherche Master 6 mois\r\n\r\nTitre : Apprentissage automatique et TAL pour l\'indexation de\r\ndocumentation technique\r\n\r\nEncadrant(s) : Nathalie Camelin nathalie.camelin@univ-lemans.fr, Nicolas\r\n               DuguÃ© nicolas.dugue@univ-lemans.fr\r\n\r\nContexte du stage : Au Mans, laboratoire LIUM, Ã©quipe LST, financement\r\nsur projet en collaboration avec la SNCF\r\n\r\nMots-clÃ©s : Apprentissage supervisÃ©, traitement automatique de la langue\r\nnaturelle, clustering\r\n\r\nSujet du stage\r\n\r\nLe groupe SNCF connaÃ®t actuellement une transformation digitale et se\r\ntourne de plus en plus vers des technologies susceptibles de faire appel\r\nÃ  de l\'intelligence artificielle appliquÃ©e au traitement d\'informations\r\nÃ©crites ou orales. La documentation mÃ©tier est aujourd\'hui en pleine\r\nmutation, avec des mÃ©tiers qui se digitalisent, plus mobiles et de\r\nnouveaux modes de consommation de l\'information. Divers projets internes\r\nont permis d\'enclencher une transition vers le numÃ©rique, pour trouver\r\nla juste information au bon moment. Au-delÃ  de la numÃ©risation des\r\ndocuments se pose la question de nouveaux systÃ¨mes intelligents d\'accÃ¨s\r\naux contenus, d\'aide Ã  l\'interprÃ©tation et Ã  la saisie. L\'objectif du\r\nprojet dans lequel s\'inscrit ce stage est ainsi d\'identifier, de\r\nmaquetter et d\'Ã©valuer des solutions capables d\'enrichir les initiatives\r\nactuelles de documentation numÃ©rique. Les champs d\'application sont\r\nl\'aide Ã  la rÃ©daction, la recherche d\'information et la navigation dans\r\nles contenus textuels.\r\n\r\nDans ce contexte, le stage a pour objectif d\'Ã©tudier des mÃ©thodes pour\r\nl\'indexation fine de cette documentation numÃ©rique. En particulier, il\r\ns\'agit d\'Ã©tudier les mÃ©thodes existantes (tf idf, zipf law, glove, lsa)\r\net de fournir des outils capables de dÃ©crire ces documents au contenu\r\ntechnique via des mots-clÃ©s issus du vocabulaire mÃ©tier. Cette\r\ndescription doit pouvoir ensuite Ãªtre utilisÃ© pour rÃ©aliser des\r\ntraitements tels que des regroupements thÃ©matiques de documents.\r\n\r\nPour rÃ©aliser ce travail, nous disposerons d\'un lexique incomplet qui\r\npourra notamment Ãªtre utilisÃ© comme base d\'apprentissage pour entraÃ®ner\r\nun algorithme Ã  dÃ©tecter le vocabulaire technique. Dans ce cas, nous\r\npouvons reformuler ce problÃ¨me comme un problÃ¨me de dÃ©tection d\'entitÃ©s\r\nnommÃ©es spÃ©cifiques liÃ©es au vocabulaire technique de la SNCF.\r\n\r\nBibliographie\r\n\r\nPennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors\r\nfor word representation.  In Proceedings of the 2014 conference on\r\nempirical methods in natural language processing (EMNLP) (pp. 1532-1543)\r\n\r\nFerrer i Cancho, R., & SolÃ©, R. V. (2001). Two Regimes in the Frequency\r\nof Words and the Origins of Complex Lexicons: Zipf\'s Law\r\nRevisited. Journal of Quantitative Linguistics, 8(3), 165-173.\r\n\r\nDeerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &\r\nHarshman, R. (1990). Indexing by latent semantic analysis. Journal of\r\nthe American society for information science, 41(6), 391.\r\n\r\nLeaman, R., & Gonzalez, G. (2008, January). BANNER: an executable survey\r\nof advances in biomedical named entity recognition. In Pacific symposium\r\non biocomputing (Vol. 13, pp. 652- 663).'),
(424, '2017-11-20', 'LIMSI', 'Saclay', 'Analyse d\'un corpus clinique traduit en français\r\n\r\n[Analysis of a clinical corpus translated from English to French]\r\n\r\nMots-clés : Traitement automatique de la langue, traduction, classification\r\nautomatique, domaine biomédical\r\n\r\n*Contexte*\r\n\r\n*Création d\'un corpus clinique du français partageable*\r\n\r\nLa création d\'un corpus de documents cliniques en français partageable\r\navec la communauté scientifique afin de soutenir la recherche en\r\ntraitement automatique de la langue clinique est soumise à la\r\nréglementation française en lien avec le secret médical et la protection\r\ndes données personnelles.  La transcription des directives européennes\r\nen droit français marque actuellement une évolution forte des\r\nrèglementations. En accord avec la protection des individus offerte par\r\nla législation francaise et européene en cours de construction, nous\r\nproposons d\'utiliser un corpus de documents synthétiques, issu de la\r\ntraduction de document américains (en anglais) désidentifiés et\r\nbénéficiant d\'une autorisation de diffusion à des fins de recherche dans\r\nun cadre très strict (Johnson et al. 2016).\r\n\r\n*Validation du corpus pour le traitement automatique de la langue *\r\n\r\nAfin de valider cette approche, il est nécessaire de réaliser une étude\r\ncomparative entre le corpus synthétique et un corpus de documents natifs\r\nissu d\'hôpitaux français. Cette analyse a pour objectif de caractériser\r\nles différences qui peuvent exister entre les deux types de texte. Ces\r\ndifférences peuvent être d\'ordre syntaxique ou lexical, induites par les\r\nphénomènes de simplification et d\'explicitation (Volansky et\r\nal. 2015). Les différences peuvent également résulter de différences\r\nculturelles dans la pratique médicales en France et aux Etats-Unis. Par\r\nexemple, certains médicaments prescrits aux Etats-unis ne bénéficient\r\npas d\'autorisation de mise sur le marché en France. De même, certaines\r\npratiques médicales comme les ordonnances de non ressuscitation n\'ont\r\npas cours en France. Par ailleurs, des travaux en traductologie ont\r\nmontré que les textes traduits pouvaient être automatiquement distingués\r\nde textes natifs avec de bonnes performances (Rabinovich & Wintner,\r\n2015). Nous prévoyons d\'appliquer ces méthodes sur nos données de\r\nspécialité à différents niveaux de granularité (texte complet, section,\r\nphrase) afin d\'apprécier le degré de différence entre textes traduits et\r\ntexte natifs, sachant qu\'une grande partie des travaux en TAL clinique à\r\nl\'heure actuelle s\'appuie sur une analyse au niveau de la phrase ou de\r\nla section - selon la définition de la typologie internationale LOINC\r\n(Reich et al. 2017).\r\n\r\n*Travail à réaliser :*\r\n\r\nL\'objectif du stage est une analyse comparative de documents cliniques\r\nen français natif vs. traduit de l\'anglais.\r\n\r\nCe travail s\'appuiera notamment sur les recherches actuelles en\r\ntraductologie et en linguistique de corpus (Rabinovich & Wintner, 2015 ;\r\nVolansky et al. 2015).\r\n\r\nLes objectifs suivants seront notamment poursuivis : 1/ évaluer la\r\ngranularité permettant de distinguer automatiquement des textes natifs\r\nde textes traduits puis adaptés dans un domaine de spécialité (analyse\r\nau niveau de la phrase, de la section, du document) 2/ caractériser les\r\ndifférences et similitudes entre textes natifs et textes traduits du\r\npoint de vue stylistique, linguistique, structurel et culturel 3/\r\névaluer la pertinence du corpus issu de la traduction pour l\'évaluation\r\nde méthodes de traitement automatique de la langue clinique, par exemple\r\nla reconnaissance d\'entités nommées.\r\n\r\nLe/la stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue, en traduction\r\nautomatique ou traduction assistée par ordinateur seront un plus.\r\n\r\n*Durée* : 5 mois\r\n*Niveau* : Master 2 (professionnel ou recherche)\r\n*Rémunération* : 546,01 euros net /mois + participation au forfait de\r\ntransport\r\n\r\n*Candidature:*\r\n\r\nEnvoyer à Aurelie.Neveol[at]limsi.fr:\r\n\r\n- un CV\r\n\r\n- une lettre de motivation\r\n\r\n- les coordonnées d\'au moins deux référents (par exemple: ancien maitre\r\n  de stage, ou professeur pouvant commenter votre travail).\r\n\r\n\r\n*Références*\r\nJohnson AEW, Pollard TJ, Shen L, Lehman L, Feng M, Ghassemi M, Moody B,\r\nSzolovits P, Celi LA, and Mark RG. *MIMIC-III, a freely accessible\r\ncritical care database*. Scientific Data (2016).\r\n\r\nElla Rabinovich and Shuly Wintner. *Unsupervised Identification of\r\nTranslationese*. *Transactions of the Association for Computational\r\nLinguistics* 3:419-432, 2015.\r\n\r\nChristian Reich, Patrick Ryan, Rimma Belenkaya, Karthik Natarajan and\r\nClair Blacketer. *OMOP Common Data Model v5.2 Specifications*. Rapport\r\nTechnique.  20/07/2017\r\n\r\nVered Volansky, Noam Ordan and Shuly Wintner. *On the features of\r\ntranslationese*. *Digital Scholarship in the Humanities* 30(1):98-118,\r\nApril 2015.'),
(425, '2017-11-20', 'TrackSens', 'Metz', 'Offre de stage\r\n\r\nIngénieur NLP / Linguistique\r\n\r\nCréée en décembre 2016, TrackSens est une jeune start-up spécialisée dans le développement d\'outils de traitement automatique du texte. Elle développe actuellement un logiciel de classification automatique de documents.\r\n\r\nDans cet objectif, nous sommes à la recherche d\'un(e) ingénieur\r\nlinguiste pour un stage de 6 mois avec l\'ambition de réaliser un état\r\nde l\'art autour de la problématique de la classification des documents\r\net de développer un premier prototype.\r\n\r\nObjectifs principaux :\r\n\r\n1.  Réalisation d\'un état de l\'art autour de la classification\r\n    automatique des documents\r\n\r\n2.  Identification des méthodes et des algorithmes adaptés afin de\r\n    résoudre notre problème\r\n\r\n3.  Implémentation et test de la solution retenue\r\n\r\n4.  Développement d\'un premier prototype\r\n\r\nProfil souhaité :\r\n\r\n1. Formation en cours : Master 2 en Linguistique Informatique\r\n\r\n2. Curiosité et capacité d\'explorer de nouveaux domaines en Traitement\r\n   Automatique des Langues\r\n\r\n3. Autonomie et créativité\r\n\r\nCompétences requises :\r\n1.  Connaissances en Traitement Automatique des Langues\r\n2.  Compétences et goût pour la recherche et le développement\r\n3.  Langages Informatiques : bon niveau en développement (Python/Java)\r\n4.  Langues : anglais courant et français\r\n\r\nContexte :\r\n\r\nDébut de stage : Février 2018 (date exacte à convenir)\r\n\r\nLieu de stage : 7, av. de Blida 57000 Metz (dans le tiers-lieu de\r\ncréation TCRM-Blida ) 2\r\n\r\nIndemnités de stage : 800 ¤ brut\r\n\r\nVous intégrerez une start-up innovante, en plein développement et avec\r\nde multiples opportunités pour la suite. Participer à l\'aventure\r\nTrackSens, c\'est la garantie de rejoindre une équipe dynamique et une\r\nstart-up en croissance !\r\n\r\nSi vous êtes intéressé par cette offre, merci d\'envoyer votre\r\ncandidature (CV, lettre de motivation et relevé de notes) à\r\ncontact@tracksens.com.'),
(426, '2017-11-30', 'Inbenta', 'Toulouse', 'Stage de fin d\'étude en TAL\r\n\r\nQui est Inbenta ?\r\n\r\nCréée en 2005, Inbenta est une entreprise internationale en pleine\r\nexpansion : Etats-Unis, Espagne, Singapour, Brésil, France ... Nous\r\ndéveloppons des outils basés sur le Traitement Automatique du Langage\r\ncomme notamment des moteurs de recherche sémantiques.  Installés\r\ndepuis 5 ans à Toulouse, les 25 inbentors français sont réunis en 5\r\néquipes : projets, commercial, marketing, technique, et linguistique.\r\nAvec une moyenne d\'âge de moins de 30 ans, l\'équipe bénéficie d\'un\r\ncadre de travail propice au bien-être, afin de préserver notre\r\ncapacité d\'innovation.\r\n\r\nNos valeurs : INNOVATION, AUTONOMIE, SOLIDARITE et CONVIVIALITE\r\n\r\nSujet du stage\r\n\r\nLes chatbots d\'Inbenta incluent une couche conversationnelle « sociale\r\n» pour gérer les interactions de type phatique.  L\'objectif du stage\r\nest de trouver une méthode pérenne pour enrichir cette couche sociale\r\nde façon semi automatique.\r\n\r\nMissions\r\n\r\n- Prendre connaissance de l\'existant\r\n- Faire un état de l\'art des méthodes et ressources disponibles\r\n- Définir une méthodologie d\'enrichissement de la couche sociale\r\n- Rédaction d\'une documentation\r\n- En parallèle, l\'étudiant devra assurer la gestion linguistique et\r\n  éditoriale d\'un projet de FAQ dynamique afin qu\'il s\'approprie\r\n  l\'existant en vue d\'assurer, en cas d\'embauche après le stage, les\r\n  missions de production que nous attendons d\'un ingénieur linguiste\r\n  (20% du temps de travail)\r\n\r\nProfil recherché\r\n\r\n- Bac +5 en linguistique informatique\r\n- Connaissances en recherche d\'information\r\n- Connaissances en lexicographie\r\n- Goût pour la Recherche et Développement\r\n- Excellente maîtrise du français et bonne communication en anglais\r\n- Maîtrise des expressions régulières\r\n\r\nEn plus de ces compétences, nous recherchons une personne organisée et\r\nautonome. Elle devra avoir un bon relationnel pour communiquer\r\nrégulièrement avec les clients.\r\n\r\nModalités\r\n\r\n- Stage de 5 à 6 mois (avec possibilité d\'embauche en CDI)\r\n- Rémunération prévue: 525 euros/mois + prime en fonction des résultats\r\n- Début : à partir de Janvier/Février 2018\r\n- Lieu : Toulouse\r\n\r\nPostuler en ligne sur \r\nhttps://www.inbenta.com/fr/a-propos/carrieres/'),
(427, '2017-11-30', 'MoDyCo / IRISA', 'Paris ou Rennes', 'Offre de stage de M2 : « Langage enfantin » : aide rédactionnelle pour\r\nle récit d\'événements à des enfants\r\n\r\nStage financé par le projet ANR TREMoLo et en partenariat avec\r\nLibération.\r\n\r\n--------------\r\nContexte \r\n--------------\r\n\r\nLe projet TREMoLo étudie l\'emploi de différents registres dans la\r\nlangue française et vise à développer des méthodes automatiques de\r\ntransformation de textes d\'un registre vers un autre. Un des registres\r\nétudiés est celui qui correspond au « langage enfantin ». L\'une des\r\nvisées applicatives envisagées concernant l\'analyse de ce registre est\r\ncelle du récit d\'événements à destination des enfants. La maîtrise de\r\nplus en plus précoce par les enfants des outils informatiques et\r\nd\'Internet impulse en effet un intérêt grandissant sur la thématique\r\nSTIC pour les enfants, notamment au travers de questions liées à\r\nl\'adéquation de contenus textuels à des enfants (Eickhoff et coll.,\r\n2010) ou à l\'adaptation aux enfants du processus de recherche\r\nd\'information, y compris sur les aspects liés au filtrage ou au\r\nréordonnancement de résultats (Gossen et Nürnberger, 2013).\r\n\r\n  Mots-clés : Registres de langue, langage enfantin, récit\r\n  d\'évènements, Traitement automatique des langues (TAL), Fouille de\r\n  données\r\n  \r\n\r\n--------------\r\nDescription du stage\r\n---------------\r\n\r\nL\'objectif de ce stage est tout d\'abord de répertorier les\r\ndescripteurs, c\'est-à-dire les traits ou phénomènes linguistiques -\r\nsur les plans morphologique, syntaxique, sémantique et discursif - qui\r\npermettent de caractériser un langage approprié pour s\'adresser à des\r\nenfants de 7 à 10 ans et donc de clarifier les différences entre la\r\nlangue parlée par les adultes et celle produite par des enfants de\r\ncette tranche d\'âge. Il s\'agira ensuite de caractériser finement ces\r\ntraits au regard de la tâche de mise en récit d\'un événement (et donc\r\nen mettant l\'accent sur des descripteurs de types temps verbaux,\r\nconnecteurs temporels, cadres temporels discursifs, etc.).\r\n\r\n  \r\n\r\nEn linguistique, les travaux classiques sur le langage adressé à\r\nl\'enfant (Saint-Georges et coll., 2013) s\'intéressent à la manière\r\ndont l\'adulte adapte sa langue en s\'adressant à des enfants de moins\r\nde 3 ans. Ces travaux portent beaucoup sur les formes sonores\r\n(phonèmes et intonation) et sur la notion d\'interaction, sachant que\r\nles formes produites sont très différentes d\'un adulte à l\'autre. On\r\nsait en outre que les productions de l\'enfant s\'inspirent énormément\r\nde celles de l\'adulte (Tomasello, 2003) mais on ne sait pas comment\r\nl\'adulte pourrait s\'adapter à l\'enfant plus âgé. Or l\'enfant de 7 ans\r\nest encore en plein développement langagier, notamment au niveau des\r\nformes verbales encore peu fréquentes, des connecteurs, de l\'accord\r\ntemporel entre énoncés. L\'enfant de 7 ans n\'a pas encore fini sa\r\nmaturation cérébrale, en particulier en terme de mémoire et\r\nd\'attention, et ceci a des conséquences sur son langage et la manière\r\ndont il peut par exemple raconter une histoire (Gathercole, 1999). Des\r\nétapes développementales vis-à-vis des modes linguistiques de\r\nréférence au temps ont quant à elles été clairement mises au jour dans\r\ndes travaux comme Tartas (2001) ou Vion et coll. (1999).\r\n\r\nDans une moindre mesure, le stage a également pour objectif\r\nd\'identifier, parmi les nombreux outils existants en TAL, ceux\r\npermettant l\'annotation automatique de textes en français pour les\r\ndifférents descripteurs retenus au fil du stage. La fiabilité des\r\noutils pourra être étudiée et prise en compte pour leur sélection mais\r\nil ne s\'agit pas ici de développer de nouveaux outils.\r\n\r\nLe support d\'étude se fera en partie au regard de productions\r\njournalistiques destinées à des enfants dans le cadre d\'un partenariat\r\navec le journal Le P\'tit Libé de Libération. Le travail inclura donc\r\ndes échanges avec des journalistes de leur rédaction.\r\n\r\n---------------\r\nProfil souhaité\r\n---------------\r\n\r\n- Formation en cours : Master 2 en Linguistique ou linguistique\r\n  informatique.\r\n\r\n- Curiosité et capacité d\'explorer de nouveaux domaines en\r\n  linguistique.\r\n\r\n- Des connaissances en TAL seront un plus, mais ne sont aucunement\r\n  prérequises. Un soutien sera assuré par les encadrants an cas\r\n  d\'absence de connaissances en TAL. Du reste, le sujet sera adapté en\r\n  fonction du niveau et des types de compétences en TAL du (de la)\r\n  candidat(e).\r\n \r\n-----------------\r\nConditions\r\n-----------------\r\n\r\nContrat : stage conventionné 6 mois rémunéré.\r\n\r\nDébut : février, mars ou avril 2018.\r\n\r\nLieu : laboratoire MoDyCo (site : Université de Paris Nanterre) ou\r\nlaboratoire IRISA (site : Université de Rennes 1)\r\n\r\nEncadrants : Delphine Battistelli (MoDyCo), Gwénolé Lecorvé (IRISA)\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être envisagée.\r\n\r\nMerci d\'envoyer votre candidature aux deux adresses suivantes :\r\n\r\ndelphine.battistelli@parisnanterre.fr\r\ngwenole.lecorve@irisa.fr\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevés de notes M1 et M2.\r\n\r\n-----------------\r\nBibliographie indicative\r\n-----------------\r\n\r\nDe Belder & Moens (2010). Text simplification for children. In\r\nProc. of the SIGIR worksh. on accessible search\r\nsystems. https://lirias.kuleuven.be/bitstream/123456789/276005/1/beldersigir-as.pdf\r\n\r\nEickhoff, Serdyukov & de Vries (2010). Web page classification on\r\nchild suitability. In Proc. of the ACM international conference on\r\nInformation and knowledge\r\nmanagement. http://dmirlab.tudelft.nl/sites/default/files/cikm331s-eickhoff.pdf\r\n\r\nGathercole (1999). Cognitive approaches to the development of\r\nshort-term memory. Trends in Cognitive\r\nSciences. https://faculty.biu.ac.il/~armonls/924/NWR/gathercole%2520(1999).pdf\r\n\r\nGossen & Nürnberger (2013). Specifics of information retrieval for\r\nyoung users: A survey. Information Processing &\r\nManagement. http://wwwiti.cs.uni-magdeburg.de/iti_dke/Pdf/GossenIPM.pdf\r\n\r\nSaint-Georges, Chetouani, Cassel, Apicella, Mahdhaoui, Muratori,\r\nLaznik, Cohen (2013). Motherese in Interaction: At the Cross-Road of\r\nEmotion and Cognition? (A Systematic Review). PLoS\r\nONE. https://pdfs.semanticscholar.org/a37f/8fc857d4e7c435e6d645bc3a37ddd517c308.pdf\r\n\r\nTartas (2010). Le développement de notions temporelles par l\'enfant,\r\nDéveloppements. https://www.cairn.info/article.php?ID_ARTICLE=DEVEL_004_0017\r\n\r\nTomasello (2003), Constructing a language, a usage-based theory of\r\nlanguage\r\nacquisition. http://journals.lww.com/jonmd/Citation/2005/06000/Constructing_a_Language__A_Usage_Based_Theory_of.12.aspx\r\n\r\nVion & Colas (1999). L\'emploi des connecteurs en français :\r\ncontraintes cognitives et développement des compétences narratives (le\r\ncas de la narration de séquences arbitraires d\'événements). Prof. of\r\nConference of the International Association for the Study of Child\r\nLanguage. https://hal.archives-ouvertes.fr/hal-00241527/document'),
(428, '2017-11-30', 'LIMSI / AP-HP', 'Orsay / Paris', 'Stage Master 2 / ingénieur: Adaptation d\'un système d\'apprentissage\r\nneuronal à de nouveaux domaines\r\nLIMSI-CNRS / AP-HP\r\n\r\nMots-clés : apprentissage automatique, traitement automatique des\r\nlangues, réseaux de neurones, adaptation au domaine, domaine médical,\r\nanalyse de dossiers patients\r\n\r\nLieu : LIMSI (Orsay), AP-HP (Paris, campus Picpus)\r\n\r\nDurée : 4 à 6 mois\r\nDate de début : printemps 2018\r\n\r\nContexte\r\n\r\nLe parcours de soin d\'un patient dans un hôpital est documenté par des\r\ndonnées numériques et structurées (résultats d\'analyse, prescription de\r\nmédicaments, etc.) mais également par un grand nombre de documents\r\ntextuels rédigés par le personnel soignant : comptes-rendus\r\nd\'hospitalisation, comptes-rendus d\'opérations chirurgicales, lettres\r\nentre médecins, etc.\r\nÊtre capable d\'extraire de l\'information pertinente de ces documents\r\ntextuels pour enrichir les connaissances sur le patient et son\r\nitinéraire (par exemple, l\'histoire de sa maladie, ses antédécents, ceux\r\nde sa famille, ses facteurs de risque) permet d\'accumuler des données\r\npertinentes sur les parcours de soin. Ces données peuvent par la suite\r\nêtre utilisées dans toutes sortes d\'études visant à mieux adapter la\r\nprise en charge aux spécificités de chaque patient.\r\nUne des approches populaires pour l\'extraction d\'information dans les\r\ntextes consiste à constituer des corpus annotés à la main par des\r\nexperts et à mettre en oeuvre des outils d\'apprentissage\r\nautomatique. C\'est cette piste qui est suivie au LIMSI avec\r\nl\'élaboration d\'un système à base de réseaux de neurones [1][2][3] et\r\nl\'utilisation d\'un corpus annoté en français [4].\r\n\r\nDeux difficultés se présentent alors :\r\n- d\'une part, l\'annotation manuelle est longue et coûteuse, et donc\r\n  nécessairement faite en quantité limitée.\r\n- d\'autre part, les comptes-rendus médicaux utilisent un vocabulaire et\r\n  une structure propre à chaque domaine (cancérologie, endocrinologie,\r\n  gastro-entérologie, etc.) et, dans une moindre mesure, à chaque\r\n  service ou hôpital. Il est impossible à l\'heure actuelle d\'envisager\r\n  l\'annotation de données de chaque domaine en quantité suffisante pour\r\n  les modèles d\'apprentissage.\r\n\r\nDans le but de réaliser des campagnes d\'annotation aussi pertinentes et\r\nciblées que possible, nous souhaitons donc quantifier précisément les\r\nbesoins et les capacités de nos systèmes à s\'adapter à des domaines\r\nnouveaux ou faiblement couverts par les annotations manuelles.\r\n\r\nTravail attendu\r\n\r\nLe ou la stagiaire recruté(e) devra prendre en main les corpus et les\r\nsystèmes existants en interne. Ces systèmes permettent d\'annoter des\r\nentités de différents types (procédures, symptômes, maladies,\r\nmédicaments, etc.) dans les comptes-rendus médicaux. Il réalisera des\r\nétudes sur les différents points suivants :\r\n\r\n- quantité des données annotées nécessaires pour obtenir des résultats\r\n  satisfaisants\r\n- configuration optimale et/ou changements nécessaires aux modèles pour\r\n  garantir une adaptation efficace à un domaine nouveau comportant peu\r\n  ou pas de données annotées\r\n- comparaison avec d\'autres approches (application de dictionnaires,\r\n  systèmes à bases de règles)\r\n\r\nCompétences souhaitées\r\n\r\nNous recherchons un(e) étudiant(e) ayant des compétences solides en\r\nprogrammation et en apprentissage automatique, intéressé(e) par le\r\ntraitement de contenu en langage naturel et par une application\r\nmédicale.  Les compétences en programmation ne sont cependant pas le\r\nseul critère, et la personne retenue devra également faire preuve de\r\ncréativité et d\'esprit d\'analyse.\r\n\r\nLes candidatures doivent comporter :\r\n\r\n- Une lettre de motivation\r\n- Un relevé de notes récent\r\n- Les noms et coordonnées de deux personnes référentes\r\n- Un curriculum citae (CV)\r\n\r\nContacts\r\n\r\nnicolas.paris@aphp.fr (AP-HP)\r\naurelie.neveol@limsi.fr (LIMSI-CNRS)\r\nxavier.tannier@upmc.fr (UPMC, LIMICS)\r\n\r\nRéférences\r\n\r\n[1]: https://github.com/jtourille/yaset\r\n[2]: Julien Tourille, Olivier Ferret, Xavier Tannier, Aurélie\r\nNévéol. Neural Architecture for Temporal Relation Extraction: A Bi-LSTM\r\nApproach for Detecting Narrative Containers. in Proceedings of the 55th\r\nAnnual Meeting of the Association for Computational Linguistics (ACL\r\n2017).\r\n[3]: Julien Tourille, Olivier Ferret, Xavier Tannier, Aurélie\r\nNévéol. LIMSI- COT at SemEval-2017 Task 12: Neural Architecture for\r\nTemporal Information Extraction from Clinical Narratives. in\r\n*Proceedings of the 11th International Workshop on Semantic Evaluation\r\n(SemEval 2017).\r\n[4]: Campillos L, Deléger L, Grouin C, Hamon T, Ligozat AL, Névéol A. A\r\nFrench clinical corpus with comprehensive semantic annotations:\r\ndevelopment of the Medical Entity and Relation LIMSI annOtated Text\r\ncorpus (MERLoT).  Lang Resources & Evaluation. Springer, Berlin\r\nHeidelberg, Germany. 2017:1-31'),
(429, '2017-11-30', 'ERIC', 'Lyon', 'Sujet de stage : apprentissage de représentations pour la détection de\r\nnouveauté dans les flux textuels\r\n\r\nDurée du stage : 5 à 6 mois\r\n\r\nRémunération mensuelle : gratification standard ~600 euros\r\n\r\nLieu du stage : laboratoire ERIC (plusieurs séjours à EDF prévus)\r\n\r\nOrientation du stage : recherche et professionnelle\r\n\r\nEncadrants : J. Cugliari et J. Velcin (ERIC), P. Suignard et\r\nM. Boumghar (EDF)\r\n\r\nProblématique générale\r\n\r\nLe stage se déroulera dans le contexte du projet DyNoFlu, financé par\r\nle programme Gaspard Monge et faisant intervenir des chercheurs du\r\nlaboratoire ERIC et de l\'équipe ICAME d\'EDF Labs. L\'objectif principal\r\ndu projet consiste à modéliser conjointement l\'évolution des\r\nthématiques abordées dans des flux textuels (fournis par le partenaire\r\nindustriel) et l\'apparition des documents nouveaux annonciateurs de\r\nchangement. Un budget est ainsi prévu pour faire annoter certains\r\ntextes comme présentant un caractère nouveau, soit parce qu\'ils\r\nintroduisent une nouvelle thématique, soit parce qu\'ils changent la\r\nconfiguration des données (par ex. la fusion de deux thématiques déjà\r\nexistantes). Ces indications supervisées doivent permettre d\'apprendre\r\nun espace de représentation adapté à la tâche de détection de la\r\nnouveauté tout en la reliant à la dynamique de l\'évolution des\r\nthématiques.\r\n\r\nDans ce contexte, la stage consiste tout d\'abord à tester l\'apport\r\nd\'espaces de représentation des mots et/ou des documents déjà appris\r\nsur d\'autres corpus (à l\'instar de word2vec ou doc2vec) comme une\r\nalternative aux modèles thématiques déjà utilisé dans le cadre du\r\nprojet. Une piste intéressante, et encore relativement nouvelle,\r\nconsiste à combiner les deux approches afin d\'améliorer les\r\nperformances finales. Cette partie est encore non supervisée et\r\nl\'évaluation pourra être réalisée sur des corpus dans lesquels la\r\nnouveauté est simulée de manière artificielle. Dans un second temps,\r\nil est demandé d\'expérimenter des techniques d\'apprentissage profond\r\n(deep learning) afin d\'apprendre des espaces de représentation adaptés\r\nà la tâche de détection de la nouveauté en étant guidé, cette fois,\r\npar les étiquettes fournies par l\'annotation manuelle.  L\'évaluation\r\nfinale devra reposer sur au moins deux jeux de données : un jeu de\r\ndonnées fourni par l\'entreprise et un second jeu de données public.\r\n\r\nOrganisation du stage\r\n\r\nLe stage se passera principalement dans les locaux du laboratoire ERIC\r\navec plusieurs séjours prévus dans les locaux d\'EDF Labs en région\r\nparisienne. Il profitera également d\'une thèse CIFRE actuellement en\r\ncours entre les deux partenaires.\r\n\r\nQuelques précisions sur le contexte industriel :\r\n\r\nEDF surveille l\'évolution des thématiques discutées dans différents\r\ntypes de corpus textuels : tweet, blogs,réclamations, etc. Un plan de\r\nclassement prédéfini permet de recourir à des algorithmes de\r\nclassification supervisée performants, mais de nombreux documents se\r\nretrouvent mal ou même non classés. Cela peut être dû au fait que les\r\ncatégories évoluent au fil du temps (principe de « dérive de concepts\r\n» ou concept drift), par exemple avec l\'apparition de nouveaux termes\r\ndans le vocabulaire, ou au fait que de nouvelles catégories\r\nthématiques apparaissent. Dans ce contexte, l\'analyse des signaux\r\nfaibles sur la base des documents non classés est une piste envisagée\r\nsérieusement pour mieux appréhender ces évolutions. De manière plus\r\ngénérale, l\'entreprise souhaite être en mesure de suivre les\r\nthématiques des textes dans le temps, que celles-ci soient récurrentes\r\nou qu\'elles apparaissent et disparaissent au fur et à mesure du temps.\r\n\r\nProfil requis :\r\n\r\n- connaissances avancées en fouille de données, fouille de textes /\r\ntraitement automatique de la langue, modèles probabilistes\r\nd\'apprentissage automatique\r\n\r\n- compétences en programmation sous Python, si possible avec une\r\npremière expérience avec les librairies de deep learning (Tensor Flow,\r\nTheano, Keras...)\r\n\r\nPour candidater :\r\n\r\nMerci d\'envoyez les documents suivants à Jairo.Cugliari@univ-lyon2.fr :\r\n- Curriculum Vitae\r\n- Lettre de motivation\r\n- Derniers bulletins de note\r\n- Lettres de recommandation éventuelles\r\n\r\nRéférences bibliographiques\r\n\r\nDas, R., Zaheer, M., & Dyer, C. (2015, July). Gaussian LDA for Topic\r\nModels with Word Embeddings.  In ACL (1) (pp. 795-804).\r\n\r\nKusner, M., Y. Sun, N. Kolkin, et K. Weinberger (2015). From word\r\nembeddings to document distances. In International Conference on\r\nMachine Learning, pp. 957-966.\r\n\r\nLe, Q., & Mikolov, T. (2014). Distributed representations of sentences\r\nand documents. In Proceedings of the 31st International Conference on\r\nMachine Learning (ICML-14) (pp. 1188-1196).');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(430, '2017-11-30', 'Synapse Développement', 'Toulouse', 'Offre de stage IA et TAL - Ingénieur / M2R\r\n\r\nSujet: Apprentissage automatique pour la classification des intentions\r\nd\'utilisateurs en interaction avec un chatbot\r\n\r\nLieu : Synapse Développement - Toulouse centre \r\nContact : camille.pradel@synapse-fr.com \r\nDurée : 6 mois \r\nRémunération conventionnelle + prime technique + tickets restaurants\r\n\r\nMots-clés : Machine/Deep Learning, Traitement Automatique des Langues,\r\nChatbots, Classification multi-labels de textes\r\n\r\n--------------- \r\nContexte\r\n---------------\r\n\r\nSpécialiste de l\'Intelligence Artificielle appliquée au traitement du\r\nlangage, Synapse Développement est une société innovante d\'une dizaine\r\nde personnes et travaille pour le grand public et les grands comptes\r\ncomme Microsoft ou Amazon.\r\n\r\nEn pleine croissance, la société place l\'expertise technique et\r\nl\'excellence R&D au coeur de son activité. Nous participons régulièrement\r\nà des projets innovants avec les meilleures universités européennes et\r\nconstruisons des solutions opérationnelles pour nos clients. Nous\r\noffrons des challenges épanouissants, des solutions technologiques\r\ninnovantes, des opportunités de réalisation et une ambiance de travail\r\njeune et créative.\r\n\r\nReconnue pour ses technologies de compréhension profonde du langage,\r\nSynapse Développement est identifié comme un acteur majeur de\r\nl\'écosystème des agents conversationnels (ou chatbots) actuellement en\r\npleine effervescence.  Notre solution permet à nos clients de créer\r\nautomatiquement un chatbot capable d\'orienter des utilisateurs et de\r\nrépondre à des questions portant sur des textes issus de leur\r\ndocumentation. Le chatbot est ainsi créé et déployé en quelques clics\r\npuis s\'améliore progressivement en interagissant avec les utilisateurs.\r\n\r\n---------------\r\nVotre mission\r\n---------------\r\n\r\nLes chatbots sont des interfaces qui permettent de rendre des services\r\naux utilisateurs en interagissant avec du langage naturel. Ces services\r\npeuvent être codifiés et classés dans des catégories, mais le chatbot\r\ndoit d\'abord \"comprendre\" le message des utilisateurs pour saisir son\r\nintention. Votre objectif sera d\'explorer les méthodes de machine\r\nlearning et de traitement automatique des langues qui permettent de\r\ncaractériser les intentions d\'utilisateurs (classification\r\nmulti-labels).\r\n\r\nExemple : \"Bonjour, quel temps fera-t-il demain ?\" doit être reconnu\r\ncomme une intention de salutation et de demande de pronostiques météo.\r\n\r\nNous vous confierons la conduite des 4 étapes de ce projet :\r\n\r\n1. État de l\'art de la classification d\'intentions\r\n\r\n2. Choix de modes d\'évaluation et de métriques approprié\r\n\r\n3. Expérimentation d\'algorithmes de l\'état de l\'art (e.g. random\r\n   forest/gradient boosting avec tf-idf, doc2vec+régression\r\n   logistique...)\r\n\r\n4. Déploiement de l\'approche retenue et itérations avec l\'équipe pour\r\n   améliorer le système dans son environnement réel.\r\n\r\nSelon le profil et la motivation, des approches nouvelles pourront être\r\nmises au point, notamment basées sur des réseaux de neurones.\r\n\r\n--------------- \r\nVotre profil\r\n--------------- \r\n\r\nVous recherchez un stage de fin d\'étude pour clôturer votre Master 2 ou\r\nvotre école d\'Ingénieur (bac+5).\r\n\r\nVous disposez d\'une expérience sur des projets de Machine Learning ou de\r\nDeep Learning.\r\n\r\nVous justifiez d\'un bon niveau de programmation et d\'une capacité à\r\ntravailler en autonomie.\r\n\r\nLes compétences suivantes sont considérées comme un plus :\r\n\r\n* Traitement automatique des langues\r\n* Connaissances de Python/Sklearn/Tensorflow/Keras\r\n* Curiosité et ouverture d\'esprit.'),
(431, '2017-11-30', 'LIG', 'Grenoble', 'Génération de pictogrammes à partir de la parole pour la mise en place\r\nd\'une communication médiée par la machine\r\n\r\nEncadrants\r\n\r\nDidier Schwab (didier.schwab@imag.fr), maître de conférences à\r\nl\'Université Grenoble-Alpes\r\n\r\nBenjamin Lecouteux (benjamin.lecouteux@imag.fr), maître de conférences à\r\nl\'Université Grenoble-Alpes\r\n\r\nLieu du stage\r\n\r\nLIG (Laboratoire d\'Informatique de Grenoble), équipe GETALP (Groupe\r\nd\'Étude en Traduction Automatique/Traitement Automatisé des Langues et\r\nde la Parole), campus Universitaire de Saint-Martin d\'hères.\r\n\r\nDescription du projet\r\n\r\nOn estime que 0,5 % à 2 % de la population mondiale âgée de plus 4 ans a\r\nun trouble grave de la communication. À cause de ces difficultés, ces\r\npersonnes ont un cercle social très restreint composé essentiellement de\r\nleur famille proche ce qui pose d\'énormes contraintes d\'accessibilité et\r\nd\'intégration. Ces personnes, que seule leur famille proche est en\r\nmesure de comprendre, sont ainsi entre 30 et 120 millions, soit environ\r\n800 000 rien que pour la France. Parmi elles, on distingue :\r\n\r\n- les personnes souffrant d\'un trouble du développement. Les difficultés\r\n  surviennent dès la naissance ou peu de temps après. Ces personnes\r\n  n\'ont pratiquement rien pu acquérir de manière classique. On trouve\r\n  dans cette catégorie des maladies génétiques (syndrome de Rett,\r\n  leucodystrophies,...), certains autismes,... ;\r\n\r\n- les personnes ayant une déficience acquise. Dans ce cas, la personne a\r\n  vécu un développement normal et un évènement est survenu (Accident,\r\n  maladie) ;\r\n\r\nCes personnes ne peuvent pas communiquer avec leur environnement de\r\nmanière classique grâce à leur voix, ni même parfois avec des\r\ngestes. Toute la méthode d\'apprentissage doit être repensée en fonction\r\ndes capacités des apprenants. Leurs capacités cognitives diffèrent mais\r\nla mise en place d\'un système de communication même rudimentaire est\r\ndans la quasi-totalité des cas possible.\r\n\r\nLe projet s\'intéresse à rendre la communication possible au travers\r\nd\'une interaction médiée par la machine (beaucoup utilisé avec certaines\r\npathologies du spectre de l\'autisme, notamment avec des\r\nrobots). Cependant, comme nous nous intéressons aux troubles du langage\r\n(physique et cognitif) qui sont accompagnés de troubles moteurs, une\r\ninteraction vocale et tactile n\'est pas envisageable. Nous nous\r\nconcentrons donc sur l\'interaction visuelle grâce à ce que l\'on appelle\r\ndes oculomètres (eye-trackers).\r\n\r\nC\'est autour de cette problématique que nous travaillons depuis\r\nplusieurs mois en nous focalisant sur les jeux qui offrent au moins deux\r\navantages aux personnes : 1) les divertir ; 2) leur permettre de\r\ns\'entraîner afin de leur offrir la possibilité d\'acquérir des\r\ninteractions plus complexes.\r\n\r\nIl s\'agit ainsi d\'une première étape visant la possibilité de mettre en\r\nplace une véritable communication basée sur des pictogrammes par\r\nexemple.\r\n\r\nNotre équipe a mis à disposition de la communauté GazePlay\r\n(http://gazeplay.net) , un logiciel libre et gratuit qui rassemble\r\nplusieurs mini-jeux jouables grâce à un oculomètre (Eye-tracker). Le\r\nprix des oculomètres peut varier de quelques centaines à plusieurs\r\nmilliers d\'euros ; et à ce prix, les familles intéressées par ce type de\r\njeux doivent ajouter les logiciels généralement vendus à plusieurs\r\nmilliers d\'euros (en plus d\'être dépendants du type d\'oculomètre\r\nutilisé). À notre connaissance, notre équipe est la première au monde à\r\nporter le prix d\'entrée à une telle technologie de plusieurs milliers\r\nd\'euros à un peu plus d\'une centaine (le prix de l\'oculomètre le moins\r\ncher), en témoignent les retours positifs, le nombre de téléchargements\r\net les contacts établis (professionnels, journaux spécialisés,\r\nparents,...) depuis. Une communication scientifique sur ce sujet [Schwab,\r\n2017] a été acceptée et sera présentée aux professionnels comme aux\r\nparents en novembre prochain lors du congrès européen sur le syndrome de\r\nRett. Nous souhaitons essayer de développer une communauté\r\nd\'utilisateurs et à partir de cette communauté nous permettre d\'établir\r\ndes contacts qui nous permettront de développer recherches et outils.\r\n\r\nL\'idée est de développer un outil d\'assistance à la communication\r\nassocié à Gazeplay. Cet outil serait basé sur l\'utilisation de\r\npictogrammes, couramment utilisés dans ce type de contexte. Il doit\r\nfonctionner dans deux sens :\r\n\r\n- La génération vocale à partir des pictogrammes : Il permet à la\r\n  personne d\'utiliser un ensemble de pictogrammes (images) et de les\r\n  associer entre eux pour qu\'une synthèse vocale énonce le message à\r\n  destination de l\'entourage : cela permet d\'utiliser le\r\n  vocabulaire. Cet aspect de génération vocale existe déjà.\r\n\r\n- La génération de pictogrammes à partir du langage naturel : associer\r\n  les pictogrammes au discours correspondant est essentiel à la\r\n  réalisation du premier point [Cataix, 2017]. Pour quelqu\'un qui doit\r\n  tout apprendre ou réapprendre à partir de zéro, il s\'agit de\r\n  comprendre qu\'une image est associée à un certain mot. Ainsi, il faut\r\n  qu\'il associe le terme de `piscine\' avec l\'image de la `piscine\', le\r\n  terme `aller\' avec le pictogramme `aller\'. Cela peut se faire\r\n  évidemment par des jeux mais la mise en oeuvre en situation réelle est\r\n  essentielle [Beukelman & Mirenda, 2017]. Cette association se\r\n  complique lorsque l\'on souhaite projeter une représentation textuelle\r\n  complexe sous la forme d\'un ensemble de pictogrammes : le problème\r\n  peut alors être vu comme un cas particulier de la langue des signes\r\n  avec une notion de simplification du message en sus ; il s\'agit alors\r\n  de traduire une langue complexe dans une représentation simplifiée. Il\r\n  ne semble pas exister un moyen de le faire le plus naturellement\r\n  possible, c\'est-à-dire à partir de la voix de l\'aidant, dans les\r\n  outils ou recherches dont nous avons connaissance.\r\n\r\nAinsi, l\'objectif de ce projet est d\'étudier et de proposer des\r\nsolutions permettant de réaliser une projection du langage naturel en un\r\nensemble de pictogrammes, de manière automatique et à partir de la\r\nvoix. Les connaissances de l\'équipe dans les domaines de la traduction\r\nautomatique de la parole seront un fort atout dans la réalisation de ce\r\nprojet.\r\n\r\nSujet du Master\r\n\r\nDans un schéma classique, les aidants (famille, professionnels) parlent\r\nà la personne en situation de handicap et elle devient ainsi capable de\r\ncomprendre de nombreux messages, en tous cas ceux qui sont simples. Il\r\nfaut qu\'elle arrive à associer à chaque mot, un pictogramme afin de\r\npouvoir comprendre comment les employer. Ainsi, les aidants doivent\r\narriver à jongler avec des centaines d\'images à chaque instant de la\r\nvie. Ils mettent au point des stratégies souvent basées sur le contexte\r\nqui réduisent en partie la complexité de cette tâche. En effet, les\r\npictogrammes utilisés au moment des repas, se recoupent assez peu avec\r\nceux du moment du bain ou ceux pour aller au parc. Malheureusement, il\r\nn\'est évidement pas rare que tel ou tel pictogramme ne soit pas présent\r\ndans le classeur utilisé. De plus la sélection rapide de pictogramme\r\npeut raréfier l\'utilisation de certains.\r\n\r\nUne solution pourrait être d\'utiliser la reconnaissance vocale pour la\r\nconstitution du message sous forme de pictogramme. Il s\'agit d\'un\r\nproblème qui ne semble n\'avoir jamais été attaqué sous cet angle, nous\r\nn\'avons pas trouvé de littérature concernant la génération automatique\r\nde pictogrammes à partir de la voix ni même à partir de texte. Une seule\r\nthématique nous a paru relativement proche, la génération de langue des\r\nsignes destinées aux personnes sourdes et malentendantes mais ce\r\nproblème nous paraît bien plus complexe car les pictogrammes et les\r\nassociations possibles sont bien plus restreintes que celles offertes\r\npar une vraie langue comme la langue des signes. A contrario, la\r\nrestriction dans le langage cible nous oblige à simplifier le message\r\ninitial. Les techniques de traduction automatique, dont l\'équipe est\r\nexperte, permettront d\'apporter des solutions dans la traduction de la\r\nparole vers les pictogrammes.\r\n\r\nUne difficulté qui sera abordée dans ce sujet sera l\'évaluation de la\r\nsolution : comment vérifier la pertinence des pictogrammes choisis ? Ce\r\nsujet portera sur la constitution d\'un corpus d\'évaluation, étape qui\r\nsera essentielle au développement des méthodes évoquées précédemment.\r\n\r\nRéférences\r\n\r\n[Cataix, 2017] Communiquer autrement: Accompagner les personnes avec des\r\ntroubles de la parole ou du langage Elisabeth Cataix Nègre, De Boeck\r\nSuperieur, 12 juin 2017 - 336 pages\r\n\r\n[Beukelman & Mirenda, 2017] Communication alternative et augmentée :\r\nAider les enfants et les adultes avec des difficultés de communication,\r\nDavid Beukelman, Pat Mirenda, De Boeck Superieur, 13 octobre 2017 - 384\r\npages\r\n\r\n[Gatt & Portet, 2015] Multilingual generation of uncertain temporal\r\nexpressions from data: A study of a possibilistic formalism and its\r\nconsistency with human subjective evaluations Albert Gatt, François\r\nPortet\r\n\r\n[Lecouteux et al., 2013] Benjamin Lecouteux, Georges Linares, Yannick\r\nEstève, Guillaume Gravier. Dynamic Combination of Automatic Speech\r\nRecognition Systems by Driven Decoding. IEEE Transactions on Audio,\r\nSpeech and Language Processing, Institute of Electrical and Electronics\r\nEngineers, 2013.\r\n\r\n[Lecouteux et al., 2016] Ngoc-Tien Le, Benjamin Lecouteux, Laurent\r\nBesacier. Joint ASR and MT Features for Quality Estimation in Spoken\r\nLanguage Translation. International Workshop on Spoken Language\r\nTranslation, Dec 2016, Seattle, United States\r\n\r\n[Morel et al. 2017] Cognition sociale dans les troubles neuro-génétiques\r\nde l\'enfant : revue de la littérature A. Morel*, C. Demily, Archives de\r\nPédiatrie Volume 24, Issue 8, August 2017, Pages 757-765\r\n\r\n[Schwab, 2017] GazePlay: Creation of a community to help the development\r\nof a Free and Open-source plateform to make eye- tracker Video Games\r\naccessible to everyone. European Rett-Syndrome Congress, 2-4 novembre\r\n2017, Berlin, Allemagne'),
(432, '2017-11-30', 'ATILF', 'Nancy', 'Outil d\'exploration d\'expressions polylexicales dans un lexique et\r\ndans un corpus annotÃ©\r\n\r\n    Domaine: traitement automatique des langues\r\n    Lieu du stage: ATILF, Nancy\r\n    Encadrants: Mathieu Constant et Agata Savary\r\n    DurÃ©e du stage: 4 Ã  6 mois\r\n    RÃ©munÃ©ration: gratification rÃ©glementaire\r\n    Financement: CNRS\r\n\r\nContexte du stage\r\n\r\nLe stage se dÃ©roulera dans le cadre du projet ANR PARSEME-FR qui\r\nÃ©tudie les liens entre expressions polylexicales et l\'analyse\r\nsyntaxico-sÃ©mantique automatique. Les expressions polylexicales (EP),\r\ncomme pomme de terre, se voiler la face, Afrique du Sud, prendre une\r\ndÃ©cision, sont des groupes de mots aux propriÃ©tÃ©s imprÃ©visibles. En\r\nparticulier, leur sens ne peut souvent Ãªtre directement calculÃ© Ã \r\npartir du sens de leurs composants. Pour cette raison, elles posent\r\ndes problÃ¨mes majeurs au traitement automatique et leur traitement\r\nnÃ©cessite une description explicite dans un lexique. Un des objectifs\r\ndu projet PARSEME-FR est de construire Ã  la fois un lexique d\'EP\r\nincluant des descriptions linguistiques fines, et un corpus annotÃ© en\r\nEP pour le franÃ§ais. Un des rÃ©sultats les plus notables jusqu\'Ã \r\nprÃ©sent est l\'annotation des donnÃ©es franÃ§aises (Candito et al. 2017)\r\npour la Shared Task PARSEME sur l\'identification des expressions\r\nverbales (Savary et al. 2017). Les deux ressources crÃ©Ã©es ont pour but\r\nd\'Ãªtre exploitÃ©es dans des applications du traitement automatique des\r\nlangues telles que l\'analyse syntaxique et sÃ©mantique, mais aussi\r\nd\'Ãªtre explorÃ©es pour des Ã©tudes linguistiques.  Objectifs\r\n\r\nL\'objectif principal du stage est de dÃ©velopper des outils pour lier\r\net explorer le corpus annotÃ© et le lexique, construits dans le projet\r\nPARSEME-FR. Le travail Ã  rÃ©aliser comportera les tÃ¢ches suivantes:\r\n\r\n- Ã©tudier les propriÃ©tÃ©s linguistiques des expressions polylexicales\r\n     du franÃ§ais, en explorant le lexique des expressions verbales\r\n     extrait des tables du lexique-grammaires (Gross 1984)\r\n\r\n- dÃ©velopper un outil pour lier automatiquement les expressions\r\n     verbales annotÃ©es et leurs entrÃ©es correspondantes dans le\r\n     lexique, en s\'appuyant sur des procÃ©dures de normalisation des\r\n     expressions. Par exemple, les expressions annotÃ©es sur corpus Luc\r\n     a cassÃ© du sucre sur le dos de Paul, du sucre a Ã©tÃ© cassÃ© sur son\r\n     dos devront Ãªtre liÃ©e Ã  l\'entrÃ©e casser du sucre sur le dos [de]\r\n     du lexique.\r\n\r\n- dÃ©velopper une interface web avec l\'objectif de chercher des\r\n     expressions annotÃ©es via des filtres multicritÃ¨res et visualiser\r\n     leur description linguistique arborescente\r\n\r\n- Ã©ventuellement, Ã©tendre le travail Ã  toutes les expressions\r\n     polylexicales, ce qui impliquera la conversion automatique d\'un\r\n     dictionnaire existant de composÃ©s nominaux, adjectivaux et\r\n     adverbiaux dans le format arborescent PARSEME-FR, en particulier\r\n     en utilisant les informations syntaxiques fournies dans le corpus\r\n     annotÃ©.\r\n\r\nRÃ©fÃ©rences\r\n\r\nMarie Candito, Mathieu Constant, Carlos Ramisch, Agata Savary, Yannick\r\nParmentier, Caroline Pasquer, and Jean-Yves Antoine. Annotation\r\nd\'expressions polylexicales verbales en franÃ§ais. In Jean-Yves Antoine\r\nIris Eshkol, editor, 24e confÃ©rence sur le Traitement Automatique des\r\nLangues Naturelles (TALN), Actes de TALN, volume 2 : articles courts,\r\npages 1-9, OrlÃ©ans, France, 06 2017.\r\n\r\nMaurice Gross. Lexicon-grammar and the syntactic analysis of\r\nFrench. In Proc. of COLING-ACL 1964, pages 275-282, Stanford, CA,\r\n1984. Association for Computational Linguistics.\r\n\r\nAgata Savary, Carlos Ramisch, Silvio Cordeiro, Federico Sangati,\r\nVeronika Vincze, Behrang QasemiZadeh, Marie Candito, Fabienne Cap,\r\nVoula Giouli, Ivelina Stoyanova, and Antoine Doucet. The PARSEME\r\nshared task on automatic identification of verbal multiword\r\nexpressions. In Proc. of EACL 2017 Workshop on MWEs, pages 31-47,\r\nValencia, April 2017.  Candidater\r\n\r\nProfil du candidat:\r\n\r\n- Master ou Ã©quivalent en traitement automatique des langues ou en\r\n      informatique en prioritÃ© (mais la liste n\'est pas fermÃ©e)\r\n\r\n- CompÃ©tences: bonne maÃ®trise de la programmation, notamment la\r\n      programmation en python et la programmation web. GoÃ»t pour la\r\n      linguistique.\r\n\r\nProcÃ©dure de candidature:\r\n\r\n    Les candidatures doivent Ãªtre envoyÃ©es par mail Ã \r\n    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature\r\n    contiendra un cv, une lettre de motivation, et, Ã©ventuellement, la\r\n    recommandation d\'un enseignant.\r\n\r\n    Date limite de candidature: 15 janvier 2018 (ou jusqu\'Ã  ce ce que le poste soit pourvu)'),
(433, '2017-11-30', 'ATILF', 'Nancy', 'Stage: annotation syntaxique de Frantext\r\n\r\nLieu: ATILF, Nancy\r\nDurée: 4 à 6 mois\r\nGratification réglementaire\r\n\r\nEncadrement: Mathieu Constant, Christophe Benzitoun\r\n\r\nEn collaboration avec l\'équipe Ressources de l\'ATILF\r\n\r\nContexte:\r\n\r\nFrantext est une base de données textuelles incluant plus de 5000\r\nréférences (soit près de 300 millions de mots) s\'échelonnant du Xe au\r\nXXIe siècle (avec une majorité de textes en français moderne). Cette\r\nbase est hébergée, maintenue et enrichie à l\'ATILF. Elle dispose d\'un\r\nmoteur de requêtes qui permet de faire des recherches fines dans ce\r\ncorpus. Avec l\'objectif de permettre d\'affiner encore plus ces\r\nrequêtes, l\'ATILF s\'est lancé dans une vaste campagne d\'annotation\r\nlinguistique de la base textuelle, en commençant par l\'étiquetage\r\nmorphosyntaxique et la lemmatisation. La prochaine étape est\r\nl\'annotation syntaxique.\r\n\r\nL\'analyse syntaxique automatique de Frantext fait face à de nombreuses\r\ndifficultés. Tout d\'abord, Frantext n\'appartient pas au même\r\ndomaine/genre que les jeux de données traditionnellement utilisés pour\r\nl\'entraînement des analyseurs existants, ce qui cause des divergences\r\nlexicales et syntaxiques. Par ailleurs, la tokenisation est\r\ndifférente, ce qui est un obstacle important pour prédire la bonne\r\nstructure syntaxique. Bien que l\'on ne considère que les textes en\r\nfrançais moderne (à partir de 1850), l\'évolution lexicale et\r\nsyntaxique doit être prise en compte. Enfin, Frantext n\'a pas de\r\nsection déjà annotée et manuellement validée ce qui est problématique\r\npour l\'évaluation.\r\n\r\nL\'objectif principal du stage est d\'explorer différentes techniques\r\nd\'adaptation et de combinaison d\'analyseurs pour annoter\r\nautomatiquement Frantext en syntaxe de dépendance, en utilisant des\r\nanalyseurs existants entraînés principalement sur des corpus\r\njournalistiques. Le résultat attendu est une chaîne de traitement\r\npermettant de réaliser une analyse syntaxique automatique de qualité.\r\n\r\n \r\nTravail à effectuer\r\n\r\nLe stage se divisera en plusieurs tâches:\r\n\r\n- lire les références bibliographiques sur les techniques d\'adaptation\r\n    au domaine - ex. utilisation de représentation abstraite des mots\r\n    (Seddah et al., 2014) - et sur les techniques de combinaison\r\n    d\'analyseurs - ex. reparsing (Sagae et Lavie 2006), reranking\r\n    (Charniak et Johnson 2005), tri-learning à la Weiss et al (2015) ;\r\n\r\n- se familiariser avec des analyseurs en constituants et en\r\n      dépendances existants, à entraîner sur le French Treebank\r\n      (Abeille et al. 2003), le Sequoia (Candito et Seddah 2012) et/ou\r\n      Question Bank (Seddah et Candito 2016) ;\r\n\r\n- construire et évaluer de manière incrémentale la chaîne de\r\n      traitement en commençant par les analyseurs de base ;\r\n\r\n- éventuellement, participer à la campagne d\'annotation pour\r\n      construire rapidement un petit corpus d\'évaluation.\r\n\r\nProfil du candidat\r\n\r\n-     Formation: Master 2 traitement automatique des langues (ou équivalent) en priorité, mais la liste n\'est pas fermée ;\r\n\r\n-     Compétences: langages de script (python, perl), développement de chaînes de traitement, connaissance des méthodes d\'analyse syntaxique en dépendances (optionnel).\r\n\r\nProcédure de candidature:\r\n\r\n    Les candidatures doivent être envoyées par mail à\r\n    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature\r\n    contiendra un CV, une lettre de motivation, et, éventuellement, la\r\n    recommandation d\'un enseignant.\r\n\r\n    Date limite de candidature : 15 janvier 2018 (ou jusqu\'à ce ce que\r\n    le poste soit pourvu).\r\n\r\nRéférences:\r\n\r\nAnne Abeillé, Lionel Clément, François Toussenel. Building a Treebank\r\nfor French, pages 165-187. Springer Netherlands, Dordrecht, 2003.\r\n\r\nEugene Charniak, Mark Johnson. Coarse-to-fine n-best parsing and\r\nmaxent discriminative reranking. In Proceedings of the 43rd Annual\r\nMeeting on Association for Computational Linguistics, ACL \'05, pages\r\n173-180, Stroudsburg, PA, USA, 2005. Association for Computational\r\nLinguistics.\r\n\r\nMarie Candito and Djamé Seddah. Le corpus sequoia : annotation\r\nsyntaxique et exploitation pour l\'adaptation d\'analyseur par pont\r\nlexical (the sequoia corpus : Syntactic annotation and use for a\r\nparser lexical domain adaptation method) [in french]. In Proceedings\r\nof the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN, pages\r\n321-334, Grenoble, France, June 2012. ATALA/AFCP.\r\n\r\nDjamé Seddah and Marie Candito. Hard time parsing questions: Building\r\na QuestionBank for French. In Nicoletta Calzolari (Conference Chair),\r\nKhalid Choukri, Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente\r\nMaegaard, Joseph Mariani, Helene Mazo, Asuncion Moreno, Jan Odijk, and\r\nStelios Piperidis, editors, Proceedings of the Tenth International\r\nConference on Language Resources and Evaluation (LREC 2016), Paris,\r\nFrance, may 2016. European Language Resources Association (ELRA).\r\n\r\nDjam Seddah, Marie Candito, and Enrique Henestroza Anguiano. A word\r\nclustering approach to domain adaptation: Robust parsing of source and\r\ntarget domains. J. Log. Comput., 24(2):395-411, 2014.\r\n\r\nKenji Sagae and Alon Lavie. Parser combination by reparsing. In\r\nProceedings of the Human Language Technology Conference of the NAACL,\r\nCompanion Volume: Short Papers, NAACL-Short \'06, pages 129-132,\r\nStroudsburg, PA, USA, 2006. Association for Computational Linguistics.\r\n\r\nDavid Weiss, Chris Alberti, Michael Collins, and Slav\r\nPetrov. Structured training for neural network transition-based\r\nparsing. In Proceedings of the 53rd Annual Meeting of the Association\r\nfor Computational Linguistics and the 7th International Joint\r\nConference on Natural Language Processing of the Asian Federation of\r\nNatural Language Processing, ACL 2015, July 26-31, 2015, Beijing,\r\nChina, Volume 1: Long Papers, pages 323-333, 2015.'),
(434, '2017-11-30', 'ATILF', 'Nancy', 'Étiquetage sémantique faiblement supervisé à partir de dictionnaires -\r\napplication à la lemmatisation et à l\'identification d\'expressions\r\npolylexicales\r\n\r\n    Domaine: traitement automatique des langues\r\n    Lieu du stage: ATILF, Nancy\r\n    Encadrants: Mathieu Constant et Sandrine Ollinger\r\n    Durée du stage: 4 à 6 mois\r\n    Rémunération: gratification réglementaire\r\n    Financement: CNRS\r\n\r\nContexte du stage\r\n\r\nFrantext est une base de données textuelles incluant plus de 5000\r\nréférences (soit près de 300 millions de mots) s\'échelonnant du Xe au\r\nXXIe siècle (avec une majorité de textes en français moderne). Cette\r\nbase est hébergée, maintenue et enrichie à l\'ATILF. Elle dispose d\'un\r\nmoteur de requêtes qui permet de faire des recherches fines dans ce\r\ncorpus. Avec l\'objectif de permettre d\'affiner encore plus ces\r\nrequêtes, l\'ATILF s\'est lancé dans une vaste campagne d\'annotation\r\nlinguistique de la base textuelle, en commençant par l\'étiquetage\r\nmorphosyntaxique et la lemmatisation. Si l\'étiquetage morphosyntaxique\r\nréalisé offre de bons résultats (précision estimée à 98 %), la\r\nlemmatisation s\'appuyant sur une simple consultation de dictionnaire\r\npose de nombreux problèmes à cause de l\'ambiguïté.\r\n\r\nPar ailleurs, le projet ANR PARSEME-FR coordonné par l\'ATILF étudie\r\nles liens entre expressions polylexicales et analyse syntaxique et\r\nsémantique. En particulier, dans ce cadre, plusieurs méthodes\r\nsupervisées ont été mises au point pour identifier les expressions\r\npolylexicales (Al Saied et al. 2017, Scholivet et Ramisch\r\n2017). Cependant, de telles approches souffrent d\'un manque de\r\ncouverture, car elles sont très contraintes par les données\r\nd\'entraînement. À la place, nous souhaiterions explorer des approches\r\nfaiblement supervisées guidées par des dictionnaires, offrant une plus\r\ngrande couverture en expressions polylexicales.\r\n\r\nL\'objectif de ce stage est de développer des méthodes faiblement\r\nsupervisées d\'étiquetage sémantique reposant sur des graphes\r\nsémantiques, avec pour but d\'améliorer à la fois la lemmatisation et\r\nl\'identification des expressions polylexicales. En supposant que l\'on\r\ndispose d\'une étiquette morphosyntaxique pour le mot en entrée, la\r\nlemmatisation consiste à trouver le bon ensemble de sens partageant le\r\nmême lemme. Si l\'on considère un ensemble d\'expressions polylexicales\r\ncandidates dans une phrase en entrée, identifier les expressions\r\npolylexicales de la phrase consiste à déterminer si les expressions\r\ncandidates ont un sens compositionnel ou pas. Pour résumer, les deux\r\ntâches consistent à faire un étiquetage sémantique gros grain. Dans\r\ncette approche, les dictionnaires sont représentés comme des graphes\r\nsémantiques et des algorithmes random walk sont utilisés pour activer\r\nles bonnes analyses (lemme et segmentation lexicale) parmi les\r\nanalyses possibles décrites dans le dictionnaire.  Objectifs\r\n\r\nL\'objectif du stage est d\'appliquer diverses techniques d\'étiquetage\r\nsémantique reposant sur des graphes, à la lemmatisation et à\r\nl\'identification d\'expressions polylexicales, qui peuvent être\r\nconsidérés comme des sous-tâches de l\'annotation sémantique. Les\r\nexpériences seront de préférence réalisées sur le français, mais\r\nd\'autres langues sont aussi possibles. Le travail sera divisé en\r\nplusieurs tâches :\r\n\r\n- Lecture des principales références bibliographiques sur l\'étiquetage\r\n      sémantique à base de graphes ;\r\n\r\n- Construction d\'un graphe sémantique à partir de plusieurs\r\n      dictionnaires et éventuellement depuis des corpus ;\r\n\r\n- Implémentation de l\'algorithme de Lesk algorithm (Lesk 1986), afin\r\n      de s\'en servir comme point de comparaison ;\r\n \r\n- Implémentation de plusieurs techniques à base de graphes comme le\r\n      PageRank personnalisé (Agirre et al 2014) ;\r\n\r\n- Évaluation sur des données d\'évaluation existantes pour la\r\n      lemmatisation et l\'identification des expressions polylexicales\r\n\r\nRéférences\r\n\r\nEneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. Random walks for\r\nknowledge-based word sense disambiguation. Comput. Linguist.,\r\n40(1):57-84, March 2014.\r\n\r\nHazem Al Saied, Marie Candito, and Matthieu Constant. The atilf-llf\r\nsystem for parseme shared task: a transition-based verbal multiword\r\nexpression tagger. In Proceedings of the 13th Workshop on Multiword\r\nExpressions (MWE 2017), pages 127-132, Valencia, Spain, April\r\n2017. Association for Computational Linguistics.\r\n\r\nMichael Lesk. Automatic sense disambiguation using machine readable\r\ndictionaries: How to tell a pine cone from an ice cream cone. In\r\nProceedings of the 5th Annual International Conference on Systems\r\nDocumentation, SIGDOC \'86, pages 24-26, New York, NY, USA, 1986. ACM.\r\n\r\nManon Scholivet and Carlos Ramisch. Identification of ambiguous\r\nmultiword expressions using sequence models and lexical resources. In\r\nProceedings of the 13th Workshop on Multiword Expressions (MWE 2017),\r\npages 167-175, Valencia, Spain, April 2017. Association for\r\nComputational Linguistics.  Candidater\r\n\r\nProfil du candidat:\r\n\r\n    Master 2 ou école d\'informatique, traitement automatique des\r\n    langues en priorité, mais la liste n\'est pas fermée.\r\n\r\n    Compétences: algorithmique des graphes, calcul matriciel, maîtrise\r\n    d\'un langage de programmation (python de préférence), intérêt pour\r\n    la linguistique.\r\n\r\nProcédure de candidature:\r\n\r\n    Les candidatures doivent être envoyées par mail à\r\n    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature\r\n    contiendra un cv, une lettre de motivation, et, éventuellement, la\r\n    recommandation d\'un enseignant.\r\n\r\n    Date limite de candidature: 15 janvier 2018 (ou jusqu\'à ce ce que\r\n    le poste soit pourvu)'),
(435, '2017-12-04', 'Yseop', 'Paris', 'Yseop (www.yseop.com) propose un stage conventionné de 6 mois pour un-e\r\ninfolinguiste niveau M2, basé à Paris.\r\n\r\nCréée en 2007, Yseop compte aujourd\'hui une trentaine de collaborateurs\r\nrépartis entre Lyon, Paris, Londres, Dallas et New-York. En 2016, Yseop\r\na été reconnue meilleure innovation IT aux USA, et cette année nous\r\navons rejoint le TOP 100 des compagnies les plus disruptives au monde,\r\naux côtés de Tesla et SpaceX !\r\n\r\nGrâce au logiciel d\'Yseop, nos clients monétisent leurs données et\r\ndigitalisent leurs processus métier pour gagner en performance. Notre\r\ntechnologie est unique au monde : le logiciel d\'Yseop raisonne,\r\ninteragit, rédige et conseille automatiquement et en plusieurs langues.\r\n\r\nAu sein de l\'équipe R&D, vous participerez à la conception et au\r\ndéveloppement de la nouvelle version de notre module de NLU. Vous\r\ninterviendrez en particulier sur les tâches de modélisation des\r\ninteractions courantes avec les chatbots (salutations, remerciements,\r\netc.), la constitution des ressources linguistiques associées, la\r\nconstitution de corpus de référence et l\'évaluation des résultats. Vous\r\nparticiperez également au développement du noyau de compréhension.\r\n\r\nCompétences requises :\r\n\r\n- Traitement Automatique des Langues (étude de corpus, grammaires\r\n  locales, text-mining, extraction d\'information, techniques de machine\r\n  learning)\r\n\r\n- Programmation Java,\r\n\r\n- Maîtrise de l\'anglais,\r\n\r\n- La connaissance d\'un langage de scripts (Python, Groovy, Perl) ainsi\r\n  que du framework UIMA sont des plus,\r\n\r\n- Bonnes capacités d\'analyse,\r\n\r\n- Facilité à travailler en équipe\r\n\r\nStage à pourvoir à partir de début Mars 2018\r\n\r\nMerci de transmettre votre CV à hugues@mazancourt.com'),
(436, '2017-12-04', 'Sinequa', 'Paris', 'Stage : Amélioration de l\'analyse linguistique de documents en langue\r\njaponaise\r\n\r\nSinequa cherche un linguiste informaticien de langue maternelle\r\njaponaise pour un stage d\'une durée de 3 à 6 mois dans ses locaux à\r\nParis. Faisant partie de l\'équipe linguistique au sein du département de\r\nR&D, le stagiaire testera et améliorera l\'analyse linguistique de\r\ndocuments en langue japonaise du produit de Sinequa. Si ce stage vous\r\nintéresse, merci d\'envoyer votre CV à Frederik Cailliau\r\n(cailliau@sinequa.com).\r\n\r\nhttp://www.sinequa.com'),
(437, '2017-12-04', 'Lattice', 'Paris', '***Stage M2 au Laboratoire Lattice - UMR 8094****\r\n\"Désambiguïsation des entités nommées : une approche fondée sur les\r\nconnaissances\"\r\n\r\n* Profil recherché *\r\n+ Master 2 en Informatique\r\n+ Bonnes compétences en programmation (Java)\r\n+ Connaissances en web sémantique\r\n+ Intérêt pour le traitement automatique des langues\r\n+ Bonne connaissance de l\'anglais et du français\r\n\r\n\r\n* Contexte et objectif *\r\n\r\nLa désambiguïsation des entités nommées (personnes, lieux,\r\norganisations) est un problème récurrent en traitement automatique des\r\nlangues. Elle vise à identifier l\'entité du monde réel qui est désignée\r\npar un segment de texte. Elle est souvent décomposée en deux phases : la\r\nrecherche des candidats suivie par la sélection du meilleur\r\ncandidat. Ces algorithmes s\'appuient souvent sur des bases de\r\nconnaissances (KB) comme DBpedia/Wikidata ou encore data.bnf.fr qui\r\ndécrivent les entités ainsi que leurs propriétés et relations selon un\r\nmodèle de graphes RDF. Ces KB sont davantage nombreuses et volumineuses\r\ndans le contexte du Big Data.  Néanmoins, l\'exhaustivité de ces données\r\npeut parfois être insuffisante. En effet, il est souvent nécessaire de\r\ncompléter et d\'enrichir la KB quand il n\'y a aucun candidat ou bien le\r\nbon candidat n\'est pas présent.\r\n\r\nUn outil de désambiguïsation d\'entités nommées, baptisé REDEN, a été\r\ndéveloppé dans le contexte des humanités numériques. Cet algorithme est\r\nnon supervisé, fondé sur l\'analyse de graphes et les standards du web\r\nsémantique, indépendant de la langue, et s\'appuie sur des KB distribuées\r\nsous forme de données liées. Par rapport à des approches existantes\r\ntelles que DBpedia Spotlight ou Babelnet, REDEN est plus flexible dans\r\nle choix d\'adaptation de la KB.\r\n\r\nL\'objectif du stage est d\'adapter REDEN à des nouveaux domaines. En\r\neffet, il est envisagé d\'expérimenter avec plusieurs corpus textuels, en\r\nparticulier des textes littéraires et historiques, issus des projets de\r\nrecherche en humanités numériques en cours. Il serait nécessaire\r\nd\'effectuer un état de l\'art des approches existantes en\r\ndésambiguïsation des entités nommées. Il est également important de\r\nproposer un protocole d\'évaluation de la solution proposée, un corpus\r\nd\'évaluation (gold standard) devra donc être constitué. Pour cela, il\r\nest souhaitable d\'utiliser le framework GERBIL\r\n(http://aksw.org/Projects/GERBIL.html), il est donc nécessaire d\'adapter\r\nl\'outil développé afin de permettre son intégration dans GERBIL. Il est\r\négalement nécessaire de rendre interopérable l\'outil avec des\r\nalgorithmes de reconnaissance des entités nommées existants, en\r\nparticulier le système SEM (Dupont 2017,\r\nhttp://apps.lattice.cnrs.fr/sem/) développé au Lattice.\r\n\r\n*Bibliographie*\r\n\r\nDupont, Yoann (2017). Exploration de traits pour la reconnaissance\r\nd\'entités nommées du Français par apprentissage\r\nautomatique. TALN-RECITAL, p. 42.\r\n\r\nCarmen Brando, Francesca Frontini, Jean-Gabriel Ganascia (2016) REDEN:\r\nNamed-Entity Linking in digital Literary Editions using Linked Data\r\nSets, Complex Systems Informatics and Modeling Quarterly CSIMQ, Issue 7,\r\nJune/July 2016, pp. 60-79, RTU Press\r\n\r\nPablo Ruiz, Thierry Poibeau, Frédérique Mélanie (2015). ELCO3 : Entity\r\nLinking with Corpus Coherence Combining Open Source Annotators. In\r\nProceedings of the Demonstrations at NAACL 2015. Denver, U.S.\r\n\r\n\r\n*Localisation*\r\n\r\nLe stage aura lieu au Laboratoire LATTICE - Langues, Textes, Traitements\r\ninformatiques, Cognition - UMR 8094.\r\nDurée du stage : 5 mois à temps plein\r\nDate de début : printemps (entre février et avril)  2018\r\nGratification : suivant les règles en vigueur\r\nAdresse : Ecole Normale Supérieure, 1 rue Maurice Arnoux - F-92120\r\nMontrouge France\r\n\r\nPour candidater à ce stage, merci de transmettre un CV et une lettre\r\nmotivation à :\r\ncarmen.brando@ehess.fr,\r\nfrancesca.frontini@univ-montp3.fr,\r\nthierry.poibeau@ens.fr'),
(438, '2017-12-04', 'Fortia', 'Paris', 'DATA SCIENTIST\r\n\r\n\r\nFortia Financial Solutions	\r\n\r\nDescription du poste\r\n\r\nFortia Financial Solutions est une RegTech labélisée OSEO créée en\r\n2012, basée à Paris.\r\n\r\nLes RegTech proposent aux acteurs financiers des solutions\r\ntechnologiques destinées à gérer leurs activités « compliance », ou\r\nconformité, c\'est-à-dire le respect des dispositions législatives et\r\nréglementaires ainsi que des normes internes et statutaires. Fortia\r\nFinancial Solutions développe la plate-forme logicielle Innova, une\r\nsolution innovante reposant sur le machine-learning et l\'intelligence\r\nartificielle, dédiés aux métiers de la Finance. Rejoindre Fortia\r\nFinancial Solutions c\'est rejoindre une équipe jeune, dynamique et\r\npassionnée.\r\n\r\nSous la supervision d\'une Chief Research Scientist, vous rejoindrez\r\nune équipe R&D dédiée à l\'analyse sémantique de texte dans le contexte\r\nspécifique de la finance. Vous travaillerez sur l\'analyse des\r\nsentiments, la reconnaissance d\'entités nommées et l\'extraction\r\nd\'informations en général.\r\n\r\nVous serez amené(e) à travailler sur des problèmes d\'analyse\r\nsyntaxique de dépendance, de marquage de POS et d\'analyse syntactique\r\nen utilisant des méthodes de deep learning ( CNN, LSTM, bi-lstm, word\r\nembeddings comme word2vec ou GLOVE) ou de méthodes plus classiques\r\nd\'apprentissage automatique (svm, knn,...).\r\n\r\n- Modélisation, implémentation et testing des algorithmes.\r\n- Veille constante sur les nouveautés dans le domaine et état de l\'art\r\n      d\'articles de conférences et journaux.\r\n- Participation et rédaction de brevets et spécifications techniques.\r\n\r\n \r\nLe profil recherché\r\n\r\n    Diplômé(e) d\'une école d\'ingénieur ou équivalent avec une\r\n    spécialisation en data science/machine learning\r\n\r\n    Vous avez d\'excellentes capacités d\'analyse et de réflexion afin\r\n    de résoudre des problématiques complexes en lien avec le deep\r\n    learning et le NLP.\r\n\r\n    Vous étudiez et proposez des solutions d\'améliorations.\r\n\r\n    Vous effectuez une veille active concernant les dernières avancées\r\n    en matière de machine learning.\r\n\r\n    Vous êtes curieux(se), passionné(e) et ouvert(e) d\'esprit.\r\n\r\n    Vous justifiez au minimum de 2 ans d\'expérience (travaux d\'études\r\n    compris) sur les frameworks Python en lien avec des problématiques\r\n    de NLP (analyse des sentiments, reconnaissance d\'entités nommées\r\n    et extraction d\'informations en général).\r\n\r\n \r\nNous vous proposons\r\n\r\n    Une dimension internationale de votre travail (échanges avec des\r\n    collaborateurs, des clients étrangers).\r\n\r\n    Une plate-forme répondant à des exigences techniques très\r\n    avancées.\r\n\r\n    Un travail orienté vers l\'interactivité avec les collaborateurs de\r\n    toutes les équipes, Développeurs, Data Scientists, Experts Data.\r\n\r\n    Un environnement intellectuellement stimulant.\r\n\r\n\r\nPostuler en ligne : \r\nhttp://fortia.fr/poste/data-scientist/'),
(439, '2017-12-04', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage TAL M2 : Génération automatique de textes en français,\r\nespagnol, anglais ou allemand\r\n------------------------------------------------------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en génération\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse de\r\ndonnées textuelles du Web : identification des pages pertinentes,\r\nextraction et catégorisation des informations clés. La génération est\r\nproposée au travers de sa solution data2content qui permet, à partir\r\nd\'une base de données structurées, de produire automatiquement des\r\ntextes de qualité humaine. Nos robots rédacteurs écrivent pour des\r\nmédias de référence français comme Le Monde ou Radio France.\r\n\r\nC\'est dans le cadre de data2content que nous recherchons un·e\r\ningénieur·e linguiste pour intégrer l\'équipe actuelle et participer au\r\nparamétrage du moteur de rédaction. Les domaines d\'application sont\r\nprincipalement les médias, les sites d\'informations et les sites\r\nd\'e-commerce.\r\n\r\n-----------------------------\r\n Description du poste\r\n------------------------------\r\nLes tâches principales concernent:\r\n- Prise en main de notre moteur de rédaction.\r\n- Écriture des règles pour alimenter notre moteur de rédaction et\r\n  produire des contenus pour nos clients.\r\n- Pour les personnes natives de la langue anglaise, espagnole ou\r\n  allemande : adaptation des règles existantes en français vers la\r\n  langue maîtrisée.\r\n- Préparation des bases de connaissances structurées utilisées par les\r\n  règles.\r\n\r\n-----------------------\r\n Profil recherché\r\n------------------------\r\n\r\n- Étudiant·e en Linguistique Informatique, Traitement automatique des\r\n  langues ou Traduction\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail en\r\n  équipe\r\n- Programmation en Python\r\n- Compétences en rédaction web seraient un plus\r\n\r\n-----------------\r\n Conditions\r\n-----------------\r\n- Stage conventionné 6 mois rémunéré en fonction du niveau d\'étude\r\n- tickets resto + remboursement à moitié du pass Navigo (transport)\r\n- Bonne ambiance, coin canapé et équipe technique de grande\r\n  qualité. Apéro mensuel\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage génération ».\r\n\r\nLieu : Quartier de Charonne (Paris 11), entre Bastille et Nation. Locaux\r\nconviviaux partagés avec d\'autres start-ups data-lovers.'),
(440, '2017-12-11', 'LIASD', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage de Master 2 : Deep learning pour le résumé automatique\r\npar filtrage puis génération\r\n\r\nLIASD - Université Paris 8 - IUT de Montreuil\r\n------------------------------------------------------------------------\r\n\r\n---------------------\r\n Notre laboratoire\r\n---------------------\r\n\r\nLe LIASD est un laboratoire d\'intelligence artificielle à cheval sur le\r\ncampus de Saint-Denis de l\'Université Paris 8 et le site de l\'IUT de\r\nMontreuil. Nous développons au sein de l\'IUT de Montreuil un axe de\r\nrecherche lié au texte, à la représentation des connaissances et à la\r\nrecherche et à l\'extraction d\'information.\r\n\r\n\r\n---------------------\r\n Contexte du stage\r\n---------------------\r\n\r\nNous disposons d\'un financement de l\'Agence Nationale de la Recherche,\r\nle projet ASADERA (http://linc.iut.univ-paris8.fr/asadera), dont\r\nl\'objectif est d\'explorer de nouvelles modalités et méthodes de résumé\r\nautomatique. Dans ce cadre, nous voulons explorer des méthodes\r\ngénératives de résumé automatique. Le résumé automatique a longtemps été\r\ncantonné à des approches purement extractives (l\'extraction de fragments\r\nde texte depuis les documents à résumer), puis a évolué vers plus\r\nd\'abstraction grâce aux approches de compression de phrases (les phrases\r\nsont compressées puis une étape d\'extraction extrait les meilleures\r\nd\'entre elles). Aujourd\'hui, la communauté scientifique s\'intéresse de\r\nplus près aux approches génératives (voir par exemple\r\nhttp://aclweb.org/anthology/D17-1221), notamment grâce à l\'apport des\r\nréseaux de neurones profonds récurrents. Cependant, la complexité de\r\nl\'apprentissage de la génération d\'un texte court depuis un texte\r\nbeaucoup plus long fait qu\'une approche purement générative reste\r\nimpensable. De plus, puisque les résumés à générer diffèrent par leur\r\nsujet et donc les mots utilisés des résumés sur lesquels un modèle peut\r\nêtre appris, le mécanisme de génération doit faire appel à des\r\ntechniques particulières afin d\'éviter d\'intégrer des mots issus du\r\nvocabulaire spécifique des sujets du corpus d\'apprentissage dans les\r\nrésumés générés sur de nouveaux sujets.\r\n\r\n\r\n------------------------\r\n Description du stage\r\n------------------------\r\n\r\nNous proposons ici de réduire la complexité du problème en procédant en\r\npremier lieu à une approche de filtrage des phrases : seules les phrases\r\nles plus pertinentes doivent servir de base à l\'apprentissage de la\r\ngénération. Puis l\'apprentissage, à base de réseaux de neurones profonds\r\nrécurrents, doit incorporer un mécanisme de copie\r\n(https://arxiv.org/abs/1603.06393) afin d\'éviter l\'intégration de mots\r\nhors sujet dans les résumés générés.\r\n\r\nLe stagiaire devra donc implémenter ces différentes couches de\r\ntraitement afin de produire puis d\'évaluer un système de résumé\r\nautomatique par filtrage/génération. Les corpus ainsi que les outils\r\nd\'évaluation sont prêts à utiliser, et les mécanismes de filtrage\r\négalement. Différentes implémentations des RNN avec mécanisme par copie\r\nsont également disponible, mais externes à l\'équipe.\r\n\r\nLe stage est d\'une durée de 6 mois.\r\n\r\n\r\n---------------------------------------\r\n Compétences/Connaissances requises\r\n---------------------------------------\r\n\r\n- Niveau Master 2\r\n- Maîtrise des frameworks Keras/Tensorflow\r\n- Forte compréhension des mécanismes d\'apprentissage des réseaux de\r\n  neurone\r\n- Intérêt pour le traitement automatique du langage\r\n- Parfaite maîtrise des systèmes Linux\r\n- Maîtrise des langages Python et Java\r\n\r\n\r\n-----------------\r\n Lieu du stage\r\n-----------------\r\n\r\nIUT de Montreuil\r\n140 rue de la Nouvelle France\r\n93100 Montreuil\r\nMétro Mairie de Montreuil + bus (15 minutes)\r\n\r\n\r\n--------------------\r\nRéférences utiles\r\n--------------------\r\n\r\nJiatao Gu, Zhengdong Lu, Hang Li, and Victor OK Li. 2016. Incorporating\r\ncopying mechanism in sequence-to-sequence learning. In ACL, pages\r\n1631-1640\r\n\r\nChen Li, Fei Liu, Fuliang Weng, and Yang Liu. 2013.  Document\r\nsummarization via guided sentence compression.  In EMNLP, pages 490-500.\r\n\r\nAlexander M Rush, Sumit Chopra, and Jason Weston.  2015. A neural\r\nattention model for abstractive sentence summarization. EMNLP, pages\r\n379-389.\r\n\r\nRamesh Nallapati, Bowen Zhou, Caglar Gulcehre, Bing Xiang, et\r\nal. 2016. Abstractive text summarization using sequence-to-sequence rnns\r\nand beyond.  arXiv preprint arXiv:1602.06023.\r\n\r\n\r\nMerci d\'envoyer votre candidature à aurelien.bossard@gmail.com en\r\nindiquant en objet \"Candidature stage résumé\". N\'oubliez évidemment pas\r\nde joindre un CV et une lettre de motivation.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(441, '2017-12-11', 'Synapse Développement', 'Toulouse', 'Titre : Stage Knowledge Manager\r\n\r\nDurée du stage : 6 mois\r\nLocalisation : Toulouse centre\r\nRémunération : rémunération légale + prime + tickets restaurants \r\n\r\n*** Contexte ****\r\nSynapse Développement est une société qui développe et édite des\r\nsolutions d\'intelligence artificielle. Parmi ses activités, Synapse\r\nDéveloppement propose un chatbot alliant approche linguistique (NLP) et\r\nintelligence artificielle. Ce Chatbot est généré en 3 clics sur la base\r\nde la documentation client. Une vraie révolution dans le monde de la\r\ngestion de la connaissance et celui des chatbots !\r\nEn pleine croissance, la société place l\'expertise technique et\r\nl\'excellence R&D au coeur de son activité. Nous offrons des challenges\r\népanouissants, des solutions technologiques innovantes, des opportunités\r\nde réalisation et une ambiance de travail jeune et créative.\r\n\r\n\r\n*** Mission ***\r\n\r\nAu sein de notre équipe de développement, vous deviendrez le créateur et\r\n« l\'éleveur » de nos agents conversationnels.\r\n\r\nPour ce faire, vous travaillerez sur la plateforme propriétaire Chatbot\r\nby Synapse, un chatbot innovant capable de générer automatiquement sa\r\nbase de connaissances à partir d\'une documentation. Vous interviendrez\r\nsur la phase de mise en oeuvre et d\'optimisation du Chatbot, en\r\ncollaboration avec nos experts en Intelligence Artificielle et notre\r\néquipe produit.\r\n\r\nVotre rôle consistera notamment à :\r\n- Étudier d\'un point de vue linguistique les jeux de Question/Réponse\r\n  générés automatiquement par le système\r\n- Proposer des pistes d\'améliorations en interaction avec l\'équipe R&D\r\n- Optimiser l\'Intelligence Artificielle du système avant son déploiement\r\n- Suivre l\'utilisation réelle du chatbot dans nos outils de suivi afin de\r\n  proposer des améliorations\r\n- Formaliser un reporting interne et externe sur le suivi effectué\r\n\r\nL\'objectif global de la mission est d\'augmenter le périmètre\r\nd\'intervention du chatbot tout en veillant à la pertinence des réponses\r\napportées.\r\n\r\n*** Les apports du stage ***\r\n- Acquérir au contact de l\'équipe de développement de la plateforme\r\n  Chatbot by Synapse une première expérience en tant que Knowledge\r\n  Manager\r\n- Accompagner la transformation digitale de nos clients \r\n- Être accompagné et progresser à son rythme dans un contexte\r\n  bienveillant et responsabilisant.\r\n\r\n*** Profil recherché ***\r\nSi : \r\n- Vous possédez une double compétence (et appétence  ) en informatique\r\n  et en linguistique ;\r\n- Vous êtes en dernière année d\'une formation TAL ou des métiers du\r\n  digital ;\r\n- Vous savez être autonome, force de proposition et êtes doté de très\r\n  bonnes qualités relationnelles ;\r\n- Vous avez un côté hacker et êtes passionné par les nouvelles\r\n  technologies ;\r\n- Vous parlez anglais very well.\r\n\r\nN\'hésitez plus, et rejoignez l\'équipe Synapse !\r\n\r\nCandidature\r\n\r\nEnvoyez-nous votre CV et votre lettre de motivation à l\'adresse :\r\nmailto:direction@synapse-fr.com\r\nTel. 0561636909\r\n\r\nPatrick Séguéla\r\nDirecteur Général\r\nTel  : +33 (0)6 63 38 69 06\r\nSkype : PatrickSynapse\r\nTwitter : @patrickseguela\r\n\r\nwww.synapse-developpement.fr'),
(442, '2017-12-11', 'STL', 'Lille', 'http://natalia.grabar.free.fr/stage2018incer.php\r\n*Modèle pour la fiabilité des informations et des connaissances*\r\n\r\nAvec l\'accumulation des informations, grâce à l\'existance de différentes\r\nsources et bases, comme par exemple les bases bibliographiques, les\r\nbases de connaissances ouvertes, les réseaux sociaux, etc., il devient\r\nimportant non seulement de pouvoir accéder à ces informations mais aussi\r\nde statuer sur leur valeur et fiabilité. Cela peut en effet moduler leur\r\nfiabilité et exploitation.\r\n\r\nLe contexte du travail se situe dans le domaine médical. L\'intérêt\r\nprincipal consiste à proposer un modèle de fiabilité des\r\ninformations. Il s\'agit en particulier des informations sur les\r\ninteractions entre l\'alimentation et les médicaments. Différents\r\ncritères peuvent être pris en compte : internes (valeurs de négation,\r\nd\'incertutude ou d\'imprécision contextuelles...) et externes (type de\r\nsource, données bibliographiques associées...) au texte.\r\n\r\nCe stage s\'inscrit dans le projet ANR MIAM (Maladies, Interactions\r\nAlimentation-Médicaments). Pour la réalisation du stage, des méthodes de\r\nTraitement Automatique de la Langue et de fouille de textes seront\r\nutilisées.\r\n\r\nPlus spécifiquement, il s\'agit des objectifs suivants:\r\n- travailler avec des corpus de textes de différents types et provenant\r\n  de différentes sources\r\n- exploiter et améliorer les annotations des textes avec différents\r\n  niveaux de spécificités\r\n- proposer et modéliser les critères internes de la certitude\r\n- proposer et modéliser les critères externes de la certitude\r\n- exploiter, adapter ou développer des méthodes pour le calcul du statut\r\n  des informations\r\n- évaluer les méthodes et les résultats\r\n\r\nLe stagiaire sera amené à utiliser des outils TAL existants et à\r\ndévelopper ses propres programmes pour mieux analyser les données.\r\n\r\nPrérequis:\r\n- connaissances en TAL et en informatique\r\n- connaissances de méthodes et d\'outils d\'apprentissage automatique\r\n- manipulation et test des outils de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique\r\n- maîtrise de l\'anglais\r\n- autonomie\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\nSelon les résultats du stage, une poursuite en thèse pourrait être\r\nenvisagée.\r\n\r\nNiveau: Master 2\r\nDurée: 6 mois\r\nLieu: Lille\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à\r\neric.kergosien@univ-lille3.fr et natalia.grabar@univ-lille3.fr'),
(443, '2017-12-11', 'SNIPS', 'Paris', 'Snips is an Artificial Intelligence startup based in Paris. We are\r\nbuilding a technology in order to add voice interfaces to connected\r\ndevices, and we are doing this by protecting users\' privacy. To protect\r\npersonal data, all of our algorithms are embedded into the connected\r\ndevices themselves. This also makes Snips one of the rare GDPR compliant\r\ntechnologies when applied to voice assistants. You can find out more on\r\nhttps://snips.ai/.\r\n\r\nAspects of our solutions are Automatic Speech Recognition (ASR), and\r\nNatural Language Understanding (NLU). In the past year, we have designed\r\nstate-of-the-art solutions to these matters in French, English,\r\nMandarin, Korean, and German.\r\n\r\nWe are now looking for an awesome linguist for Japanese to help us\r\nextend our solution to Japanese.\r\n\r\nWe are offering a 3-month position in our NLU team. It will involve:\r\n\r\n   - training us and teaching us some basics about the Japanese\r\n     language;\r\n   - helping us develop our different algorithms in Japanese;\r\n   - helping us define our Japanese crowdsourcing strategy;\r\n   - testing our technology.\r\n\r\n\r\nJob requirements: - Bachelor\'s degree in linguistics or natural language\r\nprocessing;\r\n\r\n   - Native or fluent in Japanese;\r\n   - Fluent in English and/or French;\r\n   - Knowledge in formal grammars and/or regular expressions is a plus;\r\n   - Knowledge in command line is a plus (unix-style terminal);\r\n   - Interest in the Internet of Things and/or personal assistants is a\r\n     plus!\r\n\r\nJob details: - Location: Paris;\r\n   - Contract: can be either an internship, a commercial or freelance\r\n     contract;\r\n   - Duration: 3 months (~35 hours per week);\r\n   - Start date: between January 5th and January 22th;\r\n   - Gross salary: calculated from a yearly basis from ¤17000 to ¤40000\r\n     depending on the type of contract, the experience and the level of\r\n     education;\r\n   - Plus: learning fun stuff such as regular expressions, command line,\r\n     context-free grammars, etc. and being an actual actor of our\r\n     solution!\r\n   - Last but not least: free food and drinks!\r\n\r\n\r\nIf you are interested and/or you want more details about the position\r\nfeel free to email me at anais.chanclu@snips.ai. I will be delighted to\r\ndiscuss further details with you or to welcome you in our office for a\r\nlittle chat.\r\n\r\nTo apply, please proceed to our website:\r\nhttps://snips.welcomekit.co/jobs/linguist-for-japanese_paris'),
(444, '2017-12-11', 'Sinequa', 'Paris', 'Stage : Amélioration de l\'analyse linguistique de documents en langue\r\njaponaise\r\n\r\nSinequa cherche un linguiste informaticien de langue maternelle\r\njaponaise pour un stage d\'une durée de 3 à 6 mois dans ses locaux à\r\nParis. Faisant partie de l\'équipe linguistique au sein du département de\r\nR&D, le stagiaire testera et améliorera l\'analyse linguistique de\r\ndocuments en langue japonaise du produit de Sinequa. Si ce stage vous\r\nintéresse, merci d\'envoyer votre CV à Frederik Cailliau\r\n<cailliau@sinequa.com>.\r\n\r\nInternship: Enhancement of Japanese NLP capabilities on documents in\r\nJapanese\r\n\r\nSinequa is seeking a native Japanese computational linguist for an\r\ninternship of 3 to 6 months at its office in Paris. As part of the\r\nlinguistic team within the R&D department, the intern will test and\r\nenhance the Japanese NLP capabilities of Sinequa\'s product. Candidates\r\nshould send their curriculum vitae to Frederik Cailliau\r\n(cailliau@sinequa.com).\r\n\r\nhttp://www.sinequa.com'),
(445, '2017-12-11', 'Eptica', 'Boulogne-Billancourt', 'Offre de Stage en TAL: Analyse Sémantique des Conversations Digitales en\r\nLangue Anglaise.\r\n\r\nStage de 6 mois.\r\n\r\nEPTICA.\r\n\r\nLeader européen des solutions conversationnelles, collaboratives et\r\ncognitives de l\'expérience client multicanale : email, web social, chat,\r\nGestion de bases de connaissances & voix du client, Eptica permet de\r\ncréer des synergies entre le web et le Service Client d\'une entreprise\r\ndans le but d\'améliorer la qualité des conversations avec les clients,\r\nde leur fournir des informations pertinentes, de répondre rapidement et\r\nde manière personnalisée à leurs questions et de favoriser chaque\r\nopportunité de vente pour un service client d\'excellence. Eptica est\r\nréférencée dans le Magic Quadrant du Gartner depuis 2011.\r\n\r\nEptica intègre dans toutes ses lignes de produit, un moteur multilingue\r\nd\'analyse et de recherche sémantique.\r\n\r\n\r\nPRODUITS.\r\n\r\nEptica Enterprise Suite(TM) est une plate-forme intégrée permettant aux\r\nentreprises d\'appréhender le cycle client dans sa globalité, à travers\r\nles solutions suivantes :\r\n\r\n- Eptica Web Self-service pour apporter un service client en ligne 24/7\r\n- Eptica Email Management pour la gestion des emails entrants ;\r\n- Eptica Chat pour établir un dialogue proactif avec les internautes par\r\n  chat et co-navigation\r\n- Eptica Contact Assistant pour permettre aux conseillers d\'améliorer le\r\n  taux de résolution au premier contact\r\n- Eptica Fax-Letter-SMS pour prendre en charge la gestion des demandes\r\n  par fax, courrier et SMS\r\n- Eptica Analytics pour synthétiser et analyser les données du service\r\n  client grâce à un outil décisionnel.\r\n\r\nDans le cadre de ses activités de R&D, au sein de l\'équipe NLP & AI,\r\nEptica propose une offre de stage en TAL (Traitement Automatique des\r\nLangues) pour le développement de services d\'analyses en langue\r\nanglaise, pour la compréhension des conversations client.\r\n\r\n*NOS VALEURS*\r\n\r\nTénacité - Innovation - Loyauté - Diversité\r\n\r\nMISSION.\r\n\r\nLes candidats doivent développer et maintenir les fonctionnalités\r\nsémantiques d\'analyse des conversations client en langue anglaise,\r\nintégrées dans la solution logicielle éditée par Eptica.\r\n\r\nACTIVITÉS PRINCIPALES\r\n   - Réalisation des fonctionnalités sémantiques de la solution ELS\r\n     (Eptica Linguistic Services): Analyse du contenu des\r\n     conversations. Participer aux analyses préparatoires des\r\n     fonctionnalités, en langue anglaise.\r\n   - Transmission de la connaissance nécessaire à l\'exploitation :\r\n     s\'assurer que les ressources développées puissent être maintenues\r\n     par des personnes tierces grâce à la documentation technique.\r\n   - Organisation agile.\r\n\r\n\r\nPROFIL RECHERCHE\r\n - Formation en Master 2 en TAL & Sciences du langage.\r\n   - Formation initiale en TAL & Sciences du langage, langue anglaise.\r\n   - Connaissance des plateformes TAL : NooJ, TreeTagger, Stanford,\r\n     Gate, TXM\r\n   - Connaissances en Javascript, Perl,Groovy\r\n\r\n\r\nMODALITES\r\n - Stage de 6 mois (Possibilité d\'embauche en CDI)\r\n   - Rémunération prévue: 525 euros/mois + prime en fonction des\r\n     résultats\r\n   - Période: à partir de Janvier/Février 2018.\r\n   - Lieu : Boulogne-Billancourt\r\n\r\n\r\nMerci d\'adresser vos candidatures à melanie.lefeuvre@eptica.com !'),
(446, '2017-12-11', 'Eptica', 'Boulogne-Billancourt', 'Offre de Stage en TAL: Modèles de Parcours Clients, basés sur l\'Analyse\r\nSémantique des Conversations Digitales.\r\n\r\nStage de 6 mois.\r\n\r\nEPTICA.\r\n\r\nLeader européen des solutions conversationnelles, collaboratives et\r\ncognitives de l\'expérience client multicanale : email, web social, chat,\r\nGestion de bases de connaissances & voix du client, Eptica permet de\r\ncréer des synergies entre le web et le Service Client d\'une entreprise\r\ndans le but d\'améliorer la qualité des conversations avec les clients,\r\nde leur fournir des informations pertinentes, de répondre rapidement et\r\nde manière personnalisée à leurs questions et de favoriser chaque\r\nopportunité de vente pour un service client d\'excellence. Eptica est\r\nréférencée dans le Magic Quadrant du Gartner depuis 2011.\r\n\r\nEptica intègre dans toutes ses lignes de produit, un moteur multilingue\r\nd\'analyse et de recherche sémantique.\r\n\r\nPRODUITS.\r\n\r\nEptica Enterprise Suite(TM) est une plate-forme intégrée permettant aux\r\nentreprises d\'appréhender le cycle client dans sa globalité, à travers\r\nles solutions suivantes :\r\n\r\n- Eptica Web Self-service pour apporter un service client en ligne 24/7\r\n- Eptica Email Management pour la gestion des emails entrants ;\r\n- Eptica Chat pour établir un dialogue proactif avec les internautes par\r\n  chat et co-navigation\r\n- Eptica Contact Assistant pour permettre aux conseillers d\'améliorer le\r\n  taux de résolution au premier contact\r\n- Eptica Fax-Letter-SMS pour prendre en charge la gestion des demandes\r\n  par fax, courrier et SMS\r\n- Eptica Analytics pour synthétiser et analyser les données du service\r\n  client grâce à un outil décisionnel.\r\n\r\nDans le cadre de ses activités de R&D, au sein de l\'équipe NLP & AI,\r\nEptica propose une offre de stage en TAL (Traitement Automatique des\r\nLangues) pour le développement de services d\'analyses en langue\r\nanglaise, pour la compréhension des conversations client.\r\n\r\nNos valeurs\r\n\r\nTénacité - Innovation - Loyauté - Diversité\r\n\r\nMISSION.\r\n\r\nLes candidats doivent développer et maintenir des fonctionnalités\r\nsémantiques d\'analyse des conversations client pour 2 secteurs\r\nd\'activité (ecommerce et Banques & Assurances), intégrées dans la\r\nsolution logicielle éditée par Eptica.\r\n\r\nACTIVITÉS PRINCIPALES\r\n   - Réalisation des fonctionnalités sémantiques de la solution ELS\r\n     (Eptica Linguistic Services): Analyse du contenu des\r\n     conversations. Participer aux analyses préparatoires des\r\n     fonctionnalités, en langue anglaise.\r\n   - Transmission de la connaissance nécessaire à l\'exploitation :\r\n     s\'assurer que les ressources développées puissent être maintenues\r\n     par des personnes tierces grâce à la documentation technique.\r\n   - Organisation agile.\r\n\r\n\r\nPROFIL RECHERCHE\r\n - Formation en Master 2 en TAL & Sciences du langage.\r\n   - Formation initiale en TAL & Sciences du langage, langue anglaise.\r\n   - Connaissance des plateformes TAL : NooJ, TreeTagger, Stanford,\r\n     Gate, TXM\r\n   - Connaissances en Javascript, Perl,Groovy\r\n\r\n\r\nMODALITES\r\n - Stage de 6 mois (Possibilité d\'embauche en CDI)\r\n   - Rémunération prévue: 525 euros/mois + prime en fonction des\r\n     résultats\r\n   - Période: à partir de Janvier/Février 2018.\r\n   - Lieu : Boulogne-Billancourt\r\n\r\n\r\nMerci d\'adresser vos candidatures à *laura.noreskal@eptica.com !*'),
(447, '2017-12-11', 'Santé Publique France', 'Saint-Maurice (94)', 'Offre de stage M2 Linguistique informatique\r\n\r\nTitre : Classement automatisé des décès en regroupements pertinents pour\r\nl\'alerte sanitaire à partir des causes médicales inscrites en texte\r\nlibre dans les certificats de décès\r\n\r\nContexte\r\n\r\nSuite à la canicule d\'août 2003, Santé publique France a mis en place\r\ndès 2004 le système de surveillance syndromique SurSaUD (Surveillance\r\nSanitaire des Urgences et des Décès), ayant pour objectif la détection\r\nprécoce et réactive de variations inhabituelles de pathologies ou\r\nsymptômes dans les recours aux soins d\'urgences et la mortalité, ainsi\r\nque l\'évaluation d\'impact en santé publique d\'évènements (épidémies,\r\nphénomènes émergents tels que les épidémies de chikungunya, phénomènes\r\nenvironnementaux (canicule, inondations, incendies, ouragans), accidents\r\nindustriels, grands rassemblements de population (Euro de football 2016,\r\nSommets du G8/G20, ...).\r\n\r\nLa certification électronique des décès constitue l\'une des 4 sources de\r\ndonnées du système SurSaUD. Les données démographiques et les causes\r\nmédicales de décès inscrites dans le certificat de décès sont transmises\r\nà l\'Inserm-CépiDc et à Santé publique France dès la validation du\r\ncertificat par le médecin qui constate le décès. Les causes médicales de\r\ndécès sont exprimées sous forme de texte libre (Cf. exemple dans le\r\ntableau 1).\r\n\r\nLa surveillance réactive de la mortalité à visée d\'alerte à partir de\r\nces données consistera à suivre des indicateurs syndromiques, définis\r\ncomme des regroupements de causes exprimant une même pathologie que l\'on\r\nvoudra suivre en routine, afin de détecter une hausse inhabituelle de\r\ncette pathologie et alerter le cas échéant les autorités sanitaires pour\r\nqu\'elles prennent les mesures de gestion adaptées. A titre d\'exemple, on\r\ncherchera à suivre en routine les décès dont les causes médicales\r\nexpriment la survenue d\'une grippe ou d\'infection respiratoire aigüe,\r\nafin d\'identifier un éventuel phénomène émergent en dehors d\'une\r\népidémie de grippe.\r\n\r\n\r\nProposition de stage\r\n\r\nLe stage s\'inscrit dans un travail de recherche démarré en octobre 2016,\r\ns\'intitulant « construction et validation d\'indicateurs syndromique de\r\nla mortalité fondés sur les causes médicales de décès et à partir de\r\nméthodes de traitement automatique des langues ».\r\n\r\nIl consistera à effectuer :\r\n\r\n- un pré-traitement des causes médicales de décès qui arrivent en texte\r\n  libre,\r\n\r\n- le classement des causes médicales de décès issues des certificats\r\n  électroniques dans les différents indicateurs syndromiques qui auront\r\n  été préalablement identifiés et définis pour la surveillance et\r\n  l\'alerte, à partir d\'une ou deux méthodes de TAL supervisées.\r\n\r\n- d\'évaluer les performances de ce classement sur un à trois indicateurs\r\n  syndromiques (en fonction du temps). Cette étape pourra également\r\n  inclure l\'exploration des causes médicales de décès mal définies ou\r\n  non classées, afin de disposer d\'outils d\'exploration ou d\'aide à\r\n  l\'interprétation de ces catégories.\r\n\r\nLe pré-traitement et le classement pourront s\'appuyer sur un\r\ndictionnaire des causes médicales de décès construit par\r\nl\'Inserm-CépiDc.\r\n\r\nLe stagiaire pourra également s\'appuyer sur les nombreux développements\r\nproposés par les équipes ayant participé à des campagnes Clef E-Health\r\n(https://sites.google.com/site/clefehealth2017/), visant à obtenir la\r\nmeilleur méthode d\'identification de codes CIM-10 dans un corpus de\r\ntextes issus des certificats électroniques.\r\n\r\nRésultats attendus\r\n\r\nLa démarche devra être effectuée dans l\'objectif final de mettre en\r\nplace ce pré-traitement et la classification des causes de façon\r\nautomatisée pour l\'utilisation en routine pour la surveillance réactive\r\nà visée d\'alerte de la certification électronique des décès.\r\n\r\nLe travail sera valorisé par la rédaction d\'un article scientifique.\r\n\r\nDéroulement du stage \r\n\r\nCe stage d\'une durée de 5/6 mois sera co-encadré par l\'équipe de\r\nsurveillance syndromique de Santé publique France et l\'équipe du LIMSI\r\n(Laboratoire d\'informatique pour la Mécanique et les Sciences de\r\nl\'Ingénieur) au CNRS.\r\n\r\nDivers\r\n\r\n- Date : à partir de février/mars 2018 (date exacte à définir selon convenance),\r\n- Stage de 6 mois rémunéré (à préciser avec RH)\r\n- Lieu : Direction Appui, Traitements et Analyses de données de Santé publique France à Saint-Maurice (94) et CNRS-Limsi à Orsay (91)\r\n\r\nContact:\r\n\r\nCV + lettre de motivation à envoyer à :\r\nAnne Fouillet\r\nSanté publique France\r\nE-mail : anne.fouillet@santepubliquefrance.fr'),
(448, '2017-12-12', 'Storyzy', 'Paris', 'NLP Engineer Internship\r\n\r\nStoryzy is a startup based in Paris that monitors and detects fake\r\nnews sites through its unique AI technology. Specializing in automated\r\nquote extraction through NLP, Storyzy develops a database of fake news\r\nsites ensuring a safer advertising environment for brands/advertisers\r\nand platforms.\r\n\r\nStoryzy (previously Trooclick) was created in November 2012. Just a\r\nfew months later, in April 2013, it received financial support from\r\nthe BPI (French public investment bank) and in June 2013 was granted\r\nthe Status of \"Young Innovative Company\" (JEI), recognizing its\r\ninnovative nature by the French government.  Storyzy has invested $3\r\nmillion in R&D, raised $900k in August 2016, and employs 12 people (6\r\nengineers).\r\n\r\nDue to its growth, Storyzy is now looking for candidates for its office in the \"Incubateur Boucicaut\" on rue de Lourmel in Paris.\r\n\r\nMissions:\r\n\r\nAs a member of the technical team, you will benefit from ongoing\r\ntraining and you will help us design and build our information\r\nextraction framework based on advanced NLP technologies.\r\n\r\n- You will turn ideas into well-documented and reliable linguistic\r\nresources & code to ensure efficiency, quality, performance and\r\nscalability\r\n\r\n- A great team player, you will interact with other departments to\r\nunderstand and fine tune specifications\r\n\r\n- You will carry out unitary testing, create and maintain our test\r\nvalidation corpus and participate in editing technical documents\r\n\r\n- You will evolve in a DevOps culture\r\n\r\nQualifications:\r\n\r\n- Experience with NLP tools such as NooJ, Unitex or Stanford for\r\n  linguistic annotation, named entity recognition, relationship and\r\n  fact extraction, sentiment analysis, etc.\r\n\r\n- Java programming experience on Linux platforms (ORM & Spring\r\n  Framework will be a plus)\r\n\r\n- Experience in scripting languages such as Perl or Python and with\r\n  database management\r\n\r\n- Machine Learning knowledge\r\n\r\n- Excellent communication skills in English and French\r\n\r\nWe are open to new ideas that will significantly contribute to our\r\nsuccess. Our friendly team will provide the opportunity for valuable\r\ncollaboration. We offer you career perspectives in a young and dynamic\r\ncompany with an interesting and diversified scope of duties at the\r\ncutting edge of research.\r\n\r\nWe welcome applications from highly motivated individuals able to\r\nlearn new techniques and share knowledge and experience with the\r\nteam. Interested? Then send your application to jobs@storyzy.com!'),
(449, '2017-12-12', 'Idiese', 'Nantes', 'PROPOSITION DE STAGE\r\n\r\nTraitement du Langage Naturel - H/F\r\n\r\nPrésentation  de  la  société\r\n\r\nL\'entreprise Idiese est un cabinet d\'études créé en 2014 dans\r\nl\'optique d\'apporter aux industriels des solutions en matière\r\nd\'intervention consultant.  Nous intervenons auprès de nos clients à\r\ntravers des contrats d\'étude au forfait ou des missions d\'assistance\r\ntechnique.  Nous développons également nos propres solutions\r\ntechniques grâce à notre pôle R&D pour les industriels mais aussi le\r\ngrand public .\r\n\r\nContexte  de  la  mission\r\n\r\nDans le cadre du développement de notre Pôle Informatique, nous\r\nrecherchons un Etudiant(e) en formation supérieure d\'informatique,\r\nspécialisé en intelligence artificielle / traitement automatique du\r\nlangage.\r\n\r\nDétails des missions\r\n\r\nAu sein de l\'équipe R&D et en collaboration avec le responsable\r\ntechnique, vous serez en charge des missions suivantes :\r\n\r\n- Conception et développement d\'un parseur sémantique\r\n- Intégration du parseur dans une chaîne de traitement existante\r\n- Test et évaluation de modèles\r\n- Validation fonctionnelle de modèles\r\n\r\nCompétences  souhaitées\r\n- Python\r\n- Programmation  Logique\r\n- Machine  Learning\r\n- Analyse  linguistique\r\n- Linux  (Debian/Ubuntu)\r\n\r\nInformations  de  l\'offre\r\n- Contrat : stage\r\n- Dates : à partir du 1er Janvier 2017\r\n\r\nDurée : 4 à 6 mois\r\n\r\nLieu : Idiese - 1 rue jean rouxel, 44700 Orvault\r\n\r\nRémunération : gratification de stagiaire\r\n\r\nContact :\r\n\r\nStéphane MBINKY\r\n\r\nResponsable Pôle Vision - stephane.m@idiese.com'),
(450, '2017-12-13', 'Telecom ParisTech', 'Paris', '*Internship and PhD position in machine learning for multimodal\r\nengagement analysis *\r\n\r\n*in human-robot interactions (HRI)*\r\n\r\nTelecom ParisTech [1],  LTCI lab [2]\r\n\r\nDuration: 6-month internship to be continued as 3-year PhD contract\r\nStart: Any date from February 1st, 2018\r\n\r\nSalary: according to background and experience\r\n\r\n****Position description**\r\n\r\nThe internship/PhD project will take part in a collaboration between\r\nSoftbank Robotics and Télécom ParisTech on the topic of engagement\r\nanalysis in interactions of humans with Softbank\'s robots.\r\n\r\nThe role of the intern/PhD student will consist in developing robust\r\nmachine learning systems able to effectively take advantage of the\r\nmultimodal signals acquired by the robot\'s sensors during its\r\ninteraction with a human. The work will include:\r\n\r\n- the design of appropriate elicitation protocols and multimodal data\r\n  acquisition procedures ;\r\n\r\n- the development of multimodal feature learning and dynamic\r\n  classification procedures capable of handling noisy observations with\r\n  missing values, especially exploiting deep learning techniques ;\r\n\r\n- the evaluation of the system in realistic scenarios involving\r\n  end-users.\r\n\r\nThe PhD project will be hosted at Telecom ParisTech department of\r\nimages, data and signals of [3], jointly by the social computing [4] and\r\nthe audio data analysis and signal processing [5] teams.\r\n\r\n* *Candidate profile**\r\n\r\nAs a minimum requirement, the successful candidate will have:\r\n\r\n- A Master\'s degree (possibly to be granted in 2018) in one of the\r\n  following areas: computer science, artificial intelligence, machine\r\n  learning, signal processing, affective computing, applied mathematics\r\n\r\n- Excellent programming skills (preferably in Python)\r\n\r\n- Good command of English\r\n\r\nThe ideal candidate will also (optionally) have:\r\n\r\n- Knowledge in deep learning techniques\r\n\r\n-- More about the position\r\n\r\n- Place of work: Paris, France\r\n\r\n- For more information about Télécom ParisTech see [1]\r\n\r\n-- How to apply\r\n\r\nApplications are to be sent to Chloé Clavel [6], Giovanna Varni [7] and\r\nSlim Essid [8] by email (using\r\n{firstname.lastname}@telecom-paristech.fr)\r\n\r\nThe application should be formatted as a single *pdf file* and should\r\ninclude:\r\n\r\n- A complete and detailed curriculum vitae\r\n\r\n- A letter of motivation\r\n\r\n- Academic records of the last two years\r\n\r\n- The names and addresses of two referees\r\n\r\n[1] http://www.tsi.telecom-paristech.fr\r\n\r\n[2] https://www.ltci.telecom-paristech.fr/?lang=en\r\n\r\n[3] http://www.tsi.telecom-paristech.fr/en/\r\n\r\n[4] https://www.tsi.telecom-paristech.fr/recherche/themes-de-recherche/analyse-automatique-des-donnees-sociales-social-computing/\r\n\r\n[5] http://www.tsi.telecom-paristech.fr/aao/en/\r\n\r\n[6] https://clavel.wp.mines-telecom.fr/\r\n\r\n[7] http://sites.google.com/site/gvarnisite/\r\n\r\n[8] http://www.telecom-paristech.fr/~essid'),
(451, '2017-12-13', 'AIZIMOV', 'Paris', '------------------------------------------------------------------------\r\nOffre de Stage en TAL: Compréhension de texte multi-langue basés\r\nsur des corpus spécialisés\r\net participation à la création d\'interface utilisateur d\'apprentissage\r\n\r\nAIZIMOV - Jeune start-up Parisienne\r\n------------------------------------------------------------------------\r\n\r\n---------------------\r\n Notre start-up\r\n---------------------\r\n\r\nAiZimov aide à adresser les bons messages, aux bonnes personnes, aux\r\nbons moments et avec la forme qui convient. Il s\'agit d\'une entreprise\r\naxé sur les données personnelles, les réseaux sociaux et les\r\nentreprises. Notre outil s\'appuie sur l\'Intelligence Artificielle pour\r\nautomatiser la prospection.\r\n\r\nC\'est donc un vrai assistant qui rédige pour ses utilisateurs les\r\nmeilleurs emails prospectifs qui soient et traite les réponses.  En\r\nbref, nous aidons les entreprises à déceler de nouvelles opportunités,\r\noptimiser le temps de prospection et protéger la réputation en\r\nharmonisant la qualité des messages sortants.\r\n\r\n---------------------\r\n Contexte du stage\r\n---------------------\r\n\r\nNous disposons d\'un financement de la Banque Publique d\'Investissement,\r\nAiZimov est une société qui développe et édite une application\r\nd\'intelligence artificielle. Notre objectif est d\'améliorer constamment\r\nl\'expérience client et réduire les incohérences entre les messages\r\ncommerciaux et les attentes des prospects.\r\n\r\nAiZimov propose un assistant alliant approche linguistique (NLP) et\r\nintelligence artificielle. Cet assistant est disponible sans aucun\r\neffort de la part de l\'utilisateur. Une vraie révolution dans le monde\r\nde la vente et celui des entreprises !\r\n\r\nEn plein amorçage, la société place l\'expertise technique et\r\nl\'excellence R&D au coeur de son activité. Nous offrons pour nos équipes\r\ndes challenges épanouissants, des responsabilités fortes, des\r\nopportunités de réalisation et une ambiance de travail jeune et\r\ncréative.\r\n\r\n------------------------\r\n Description du stage\r\n------------------------\r\n\r\nNous proposons ici un stage opérationnel d\'analyse de texte automatisé.\r\nEn premier lieu le stagiaire devra proposer une approche de filtrage du\r\ncontenu.\r\nSeul le contenu pertinent devra être conservé.\r\nPuis l\'apprentissage, à base de technologie open source de NLU pour\r\nappréhender\r\net catégoriser ce contenu extrait.\r\nEnfin, un outil de validation et d\'enrichissement sera créer pour\r\nadministrer cet outil.\r\n\r\nLe stagiaire devra donc implémenter ces différentes couches de\r\ntraitement afin de produire puis d\'évaluer un système de traitement\r\nautomatique par filtrage/génération.\r\n\r\nLe stage est d\'une durée de 6 mois et peut déboucher sur un CDI.\r\n\r\n---------------------------------------\r\n Compétences/Connaissances requises\r\n---------------------------------------\r\n\r\n- Niveau Master 2 ou équivalent\r\n- Passion pour la compréhension de texte automatisée\r\n- Maîtrise de frameworks NLP (au choix : NooJ, TreeTagger, Stanford,\r\n  Gate, TXM)\r\n- Mi-hacker mi-structuré\r\n- Plus: Maîtrise des langages Python et JS\r\n- Non obligatoire : compréhension autour du digital en général et des\r\n  technos du web en particulier (Php, reactJS ...)\r\n\r\n-----------------\r\n Lieu du stage\r\n-----------------\r\n\r\n62 Rue Jean-Jacques Rousseau\r\n75001 Paris\r\n\r\n--------------------\r\nRéférences utiles\r\n--------------------\r\n\r\nFrenchWeb :\r\nhttps://www.frenchweb.fr/fw-radar-aizimov-lintelligence-artificielle-au-service-des-mails-prospectifs/305202\r\n\r\nIndustrie Technologie :\r\nhttps://www.industrie-techno.com/aizimov-l-intelligence-artificielle-qui-m-a-adresse-un-mail-personnalise-et-accrocheur.51847\r\n\r\nFast Company :\r\nhttps://www.fastcompany.com/40494268/four-new-ai-tools-will-help-you-be-more-productive\r\n\r\n--------------------\r\nContact\r\n--------------------\r\n\r\nMerci d\'envoyer votre candidature à jerome.devosse@aizimov.com en\r\nindiquant en objet \"Candidature NLP stage\". N\'oubliez évidemment pas de\r\njoindre un CV ou un lien vers votre profil linkedin et un email\r\nprésentant vos attentes pour votre stage et vos motivations.'),
(452, '2017-12-18', 'LIMSI', 'Orsay', 'Stages pour M1 et M2, profils TAL sémantique, représentation des\r\nconnaissances\r\n\r\nContexte : synthèse et traduction assistée vers la langue des signes\r\n\r\nLieu : LIMSI, Orsay (91)\r\n\r\nGratifications de stage\r\n\r\nDates et durée flexibles, courant 2018, à définir selon niveau et\r\ncontenu\r\n\r\n\r\nLes traducteurs en langue des signes (LS) pratiquent la déverbalisation,\r\nc\'est-à-dire une abstraction du sens du texte source, et ont souvent\r\nrecours ensuite à des schémas représentant les entités du discours et\r\nles liens entre elles pour organiser la formulation du message\r\néquivalent en LS. Des sourds et natifs de la LS utilisent aussi ce type\r\nde schémas comme forme écrite, néanmoins comparable à une représentation\r\nsémantique.\r\n\r\nCependant, aucun standard n\'existe pour la composition de ces schémas.\r\n\r\nCe stage propose d\'en constituer un corpus et d\'en étudier les \r\nrégularités par alignement manuel avec des textes sources. Pour un M2 \r\n(stage en principe plus long), on propose de procéder à une prenière \r\nétude du corpus constitué, et de suggérer des éléments de formalisation \r\nen vue d\'une éventuelle standardisation.\r\n\r\nUn PDF détaillé est proposé sur le site du laboratoire à la page du\r\nstage :\r\n\r\nhttps://www.limsi.fr/fr/formation/offres-de-stages/details/5/53\r\n\r\nPour répondre à cette offre, contacter Michael Filhol \r\n(michael.filhol@limsi.fr)'),
(454, '2017-12-18', 'Aix-Marseille Université', 'Aix-Marseille', 'Nous proposons le sujet de stage ci-dessous à Aix-Marseille Université.\r\n\r\n*_Titre _**: /De la détection des signaux sociaux des médecins à un \r\nmodèle computationnel des feedbacks pour un patient artificiel /*\r\n\r\n/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)\r\n(LSIS, DIMAG), Roxane Bertrand (Laboratoire Parole et Langage), Grégoire\r\nde Montcheuil (Laboratoire Parole et Langage), et Philippe Blache\r\n(Laboratoire Parole et Langage).\r\n\r\n/Financement /: Projet ANR Acorformed (http://www.lpl-aix.fr/~acorformed\r\n)\r\n\r\n/Contexte du stage /\r\nLe stage se déroule dans le cadre du projet ANR /Acorformed/qui vise à\r\ndévelopper une plateforme de réalité virtuelle pour former les médecins\r\nà l\'annonce d\'évènements indésirables graves avec un patient virtuel. Un\r\ndes enjeux majeurs de ce projet est de développer un patient virtuel\r\ncapable de simuler le comportement d\'un patient réel auquel on annonce\r\nune mauvaise nouvelle. Dans ce contexte, le comportement non-verbal du\r\npatient (mouvements de tête, expressions faciales, postures, gestes,\r\ndirections du regard, etc.) joue un rôle prépondérant pour apporter de\r\nla crédibilité au personnage virtuel. L\'objectif de ce stage est\r\nd\'intégrer un modèle computationnel qui permettrait de déterminer\r\nautomatiquement durant l\'interaction à quel moment un agent artificiel\r\ndoit exprimer quels feedbacks (verbaux et non-verbaux) en réponse au\r\ncomportement du médecin.\r\n\r\n/Sujet de stage /\r\nL\'objectif du stage est d\'intégrer un */modèle computationnel de\r\nfeedbacks pour un agent artificiel /*(personnage virtuel et robot\r\nhumanoïde)*//*qui permettrait de calculer automatiquement et en temps\r\nréel les feedbacks que devrait exprimer l\'agent artificiel suivant le\r\ncomportement de l\'utilisateur (mouvements de tête, direction du regard,\r\ngestes, vocabulaire, etc.).\r\n\r\nLes feedbacks se définissent comme des réponses multimodales de celui\r\nqui écoute suite au message du locuteur. Les feedbacks peuvent être\r\nverbaux (e.g. humhum, oui) ou non-verbaux (e.g. mouvements de tête,\r\nsourire). Plusieurs travaux de recherche dans le domaine des agents\r\nartificiels montrent que les feedbacks permettent d\'améliorer le degré\r\nde satisfaction et d\'engagement de l\'utilisateur. Les feedbacks\r\napparaissent en réponse au comportement verbal et non-verbal du locuteur\r\n(e.g. mouvements de tête, sourire). Dans le cadre de ce projet, il\r\ns\'agira à la fois d\'intégrer des outils permettant de reconnaître les\r\ncomportements verbaux et non-verbaux de l\'utilisateur potentiellement\r\ndéclencheur de feedbacks et d\'intégrer un modèle computationnel à base\r\nde règles dans un agent artificiel permettant de raisonner sur les\r\nfeedbacks que ce dernier doit exprimer.\r\n\r\n/Méthodologie/\r\nLa méthodologie explorée dans ce stage repose sur une approche\r\npluridisciplinaire. Il s\'agira de construireun modèle computationnel\r\nintégrant un ensemble de règles de déclenchement de feedbacks issues de\r\nl\'analyse d\'un corpus réel d\'interaction médecin-patient (Porhet et al.,\r\n2017) et d\'enrichir ces règles avec desconnaissances théoriques et\r\nempiriques sur les feedbacks, et en particulier sur les\r\n/hétéro-répétions/. Les hétéro-répétitions (appelées other-repetition)\r\nsont un procédé impliquant la reproduction (totale ou partielle)par\r\nl\'interlocuteur de l\'énoncé produit préalablement par le locuteur. Les\r\nhétéro-répétitions sont des réponses feedback particulières et\r\nconstituent un mécanisme crucial dans la conversation en face à face\r\ngrâce à leurs fonctions discursive et communicative.\r\nCe modèle devra s\'intégrer dans une plateforme d\'agent artificiel que\r\nnous avons développée au sein du LPL et qui permet d\'animer un\r\npersonnage virtuel et un robot humanoïde. Le modèle devra raisonner sur\r\nles données en entrée issues de la reconnaissance vocale et de la\r\nreconnaissance du comportement non-verbal du médecin (direction de\r\nregard, gestes et mouvements de tête). Une évaluation à travers un\r\nensemble de tests perceptifs auprès d\'utilisateurs interagissant avec le\r\npersonnage virtuel et le robot humanoïde permettra de valider le modèle\r\nproposé.\r\n\r\n/Compétences requises /\r\nLe stagiaire devra avoir des connaissances techniques (très bonnes \r\nconnaissances en java sont essentielles pour ce projet mais aussi \r\nquelques connaissances en C++), des connaissances sur les modèles \r\ncomputationnels de raisonnement et en TAL seraient un plus, une \r\nouverture pluridisciplinaire incontournable.\r\n\r\n*Contact *: Magalie Ochs (magalie.ochs@lsis.org)'),
(455, '2018-01-08', 'Airbus & LIPN', 'Elancourt', 'Offre de Stage à Airbus Defence and Space (Advanced Information Processing)\r\n\r\nSujet de Stage : Apprentissage automatique profond pour l\'extraction\r\nd\'information et d\'évènements à partir de texte.\r\n\r\nCadre du stage :\r\n\r\nCe stage recherche, d\'une durée de 6 mois, se déroulera sur le site\r\nAirbus d\'Elancourt au sein d\'une équipe de Recherche & Développement\r\nspécialisée dans le traitement massif de l\'information non structurée\r\n(Big Data).  Cette équipe est impliquée dans des projets d\'études\r\namont ainsi que divers programmes de recherche partiellement financés\r\npar l\'Agence Nationale de la Recherche, l\'Agence de Défense Européenne\r\nainsi que l\'Union Européenne. Une poursuite du stage dans le cadre\r\nd\'une convention CIFRE est envisagée sur une problématique de\r\npopulation de base de connaissances à partir de texte. L\'encadrement\r\nsera assuré par les membres du département (Leila Khelif et Bruno\r\nGrilhers ) ainsi que par des chercheurs du LIPN (Haïfa Zargayouna et\r\nThierry Charnois)\r\n\r\nContexte :\r\n\r\nLe département R&D développe actuellement, en s\'appuyant sur le socle\r\ntechnique open source OW2 WebLab, une solution de veille nommée\r\nFORTION MediaMining. Cette solution vise à fournir une solution\r\ncomplète de collecte d\'information multimédia -texte, image, audio,\r\nvidéo - disponible en sources ouvertes (web, réseaux sociaux),\r\nd\'analyse (extraction et recherche d\'information, transcription de la\r\nparole, traduction automatique, etc...) et d\'exploitation\r\n(visualisation spatio-temporelle, réseau relationnel, statistiques,\r\netc.). Celle-ci dispose notamment de fonctionnalités d\'extraction\r\nd\'information de relations et d\'évènement à base de patrons\r\nlinguistiques.\r\n\r\nObjectifs :\r\n\r\nCe stage vise à étudier la possibilité de remplacer / hybrider les\r\nsystèmes d\'extraction à base de patrons linguistiques par des systèmes\r\nà base de réseaux de neurones profond, type réseau de neurones\r\nrécurrents. Les différentes étapes du travail à réaliser sont les\r\nsuivantes :\r\n\r\n- Etat de l\'art des méthodes d\'extraction d\'information, de relation\r\net d\'évènement à base de méthode d\'apprentissage,\r\n\r\n- Identification de solutions open source ou de laboratoire,\r\n\r\n- Mise en oeuvre des solutions techniques (apprentissage sur base\r\n  annotée),\r\n\r\n- Comparaison et évaluation des approches sur un corpus de référence\r\n\r\nDomaines techniques/compétences informatiques :\r\n\r\nProfil recherché : Master 2 en Informatique (orienté recherche)\r\n\r\nDomaines techniques : Intelligence Artificielle, Apprentissage\r\nautomatique, Traitement automatique des Langues, Fouille de données,\r\nExtraction d\'information à partir de textes.\r\n\r\nCompétences en développement logiciel : Java, Python\r\n\r\nCompétences considérées comme un plus : Connaissance de Framework de\r\nDeep Learning type Keras, Tensorflow\r\n\r\nBon niveau en Anglais exigé.\r\n\r\nLa sélection se fera en deux temps : une pré-sélection par le LIPN\r\nsuivi de la sélection finale par Airbus Group.  Les locaux d\'Airbus\r\nsont dans une zone à accès restrictif. Cela impose que le(a)\r\ncandidat(e) soit habilité(e) (CD- Special France). La procédure\r\nd\'habilitation prend au minimum deux mois, il nous est donc impossible\r\nde sélectionner des candidats étrangers.\r\n\r\nDébut souhaité : mars-avril 2018\r\n\r\nModalité de dépôt de candidature :\r\n\r\nLes candidatures seront ouvertes jusqu\'à sélection d\'un(e) candidat(e)\r\net au plus tard le 16 février.  Merci d\'envoyer un CV détaillant la\r\nformation et l\'expérience acquise, les bulletins de notes ou\r\nappréciations d\'enseignants dans les compétences ciblées ainsi qu\'une\r\nlettre de motivation à : haifa.zargayouna@lipn.univ-paris13.fr,\r\nthierry.charnois@lipn.univ-paris13.fr\r\n\r\nLieu du stage : Airbus Defence and Space Advanced Information\r\nProcessing, 1, Boulevard Jean Moulin - CS 30503, 78997 Elancourt\r\nCedex- France\r\n\r\nResponsables (Airbus) :\r\nBruno GRILHERES (+33 (0)1 61 38 58 25, bruno.grilheres@airbus.com)\r\nLeila KHELIF(+33 (0) 1 61 38 56 51, leila.khelif@airbus.com)'),
(456, '2018-01-08', 'EDL', 'Berre l\'étang (13)', 'Analyse de fonctionnement de la reconnaissance vocale\r\n(TAL ou Linguistique avec des compétences informatiques) \r\n\r\nMots clés : reconnaissance vocale, correction orthographique et\r\nsyntaxique, transcription phonétique, recherche textuelle avec REGEX.\r\n\r\nSociété leader des solutions informatiques pour les services d\'Imagerie\r\nMédicale publics et privés recherche un(e) stagiaire niveau M1 ou M2.\r\n\r\nMission principale : analyse des erreurs textuelles de la reconnaissance\r\nvocale et participation dans leur prévention.\r\n\r\nObjectifs du stage :\r\n- Comparaison des résultats issus du moteur de la reconnaissance (texte\r\n  reconnu, texte corrigé, audio).\r\n- Réflexion sur l\'algorithme d\'alignement automatique de\r\n  l\'enregistrement audio et du texte corrigé ;\r\n- Repérage et classification des erreurs et des fautes ;\r\n- Création de règles syntaxiques pour le correcteur orthographique et\r\n  grammaticale ;\r\n- Réflexion et création d\'un outil pour la mise à jour du dictionnaire\r\n  orthographique.\r\n\r\nCompétences requises : \r\n\r\n- Linguistique (phonétique, orthographe et syntaxe) ;\r\n- Très bonne maitrise de la grammaire française ;\r\n- Rigueur et attention aux détails ;\r\n- Maîtrise des expressions régulières (REGEX);\r\n- Maîtrise de l\'encodage des dictionnaires Hunspell serait un plus\r\n- Maîtrise de l\'outil OpenSource LanguageTool serait un plus ; \r\n- Maîtrise d\'un langage de programmation serait un plus ;\r\n- Connaissance du domaine médical serait un plus.\r\n\r\nDébut de stage : dès que possible\r\nDurée de stage : 6 mois\r\nLieu de stage : Berre L\'Etang\r\nRémunération : selon profil\r\n\r\nAdresser CV + lettre de motivation à : mtaranina@edl.fr'),
(457, '2018-01-08', 'LATTICE', 'Paris', 'Testing Multilingual Language Representations for Parsing\r\n\r\nLanguage diversity remains a challenge for NLP. Multilingual\r\ndistributional representations (multilingual word embeddings) are known\r\nto be efficient to address different languages simultaneously, but other\r\napproaches have also been proposed like language transfer [1]. These\r\ntechniques have been applied to many different NLP areas such as\r\nmorphological analysis, NER, Machine Translation and Dependency parsing\r\n[2, 3, 4].\r\n\r\nThis internship is centered around a model-transfer dependency parsing\r\napproach using multilingual feature representations previously developed\r\nat LATTICE. This system obtained state-of-the art results during the\r\nCoNLL shared task 2017 (see http://universaldependencies.org/conll17/ ).\r\n\r\nThe goal of the internship is to try to get a better knowledge of the\r\nanalysis process and, more specifically of the multilingual\r\napproach. Neural nets are generally used as a black box but it is also\r\nadvisable to dive into the representations used and test for example the\r\nquality of the multilingual word embeddings (have the different\r\nlanguages been correctly aligned?). Different parameters (size of the\r\ntraining corpora, dictionary, etc) will be tested to see how they affect\r\nthe result.\r\n\r\nThe exact content of the internship will depend on the interest and\r\nskills of the student.\r\n\r\n* Requirements are:\r\n\r\n- excellent programming skills\r\n- some knowledge of neural networks\r\n- excellent English (both spoken and written, for this internship we\r\n  will use English as the main communication language)\r\n\r\n* Duration and conditions\r\n\r\n3 to 5 months, Spring 2018. Normal working conditions (indemnités de\r\nstage + transport)\r\n\r\n* How to apply?\r\n\r\nSend a CV, a recent grade statement and a short email explaining in a\r\nfew words your motivation to Thierry Poibeau (thierry.poibeau@ens.fr)\r\nand Kyungtae Lim (kyungtae.lim@ens.fr). The position is opened until\r\nfilled (but applications after Feb 2018 will not be considered).\r\n\r\nReferences\r\n\r\n[1] Stanford CS224n: Natural Language Processing with Deep Learning\r\n(http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-notes2.pdf)\r\n\r\n[2] Joulin, Armand, et al. \"FastText. zip: Compressing text\r\nclassification models.\" arXiv preprint arXiv:1612.03651\r\n(2016). (https://github.com/facebookresearch/fastText)\r\n\r\n[3] Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2017. Learning\r\nbilingual word embeddings with (almost) no bilingual data. In\r\nProceedings of the 55th Annual Meeting of the Association for\r\nComputational Linguistics (Volume 1: Long Papers), pages 451-462.\r\n\r\n[4] Lim, KyungTae, and Thierry Poibeau. \"A system for multilingual\r\ndependency parsing based on bidirectional LSTM feature representations.\"\r\nProceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw\r\nText to Universal Dependencies(2017): 63-70.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(458, '2018-01-08', 'E Motion Analysis', 'Paris', 'ENTREPRISE\r\n\r\nE Motion Analysis est une jeune entreprise innovante, composée de jeunes\r\ndiplômés, passionnés d\'analyse sémantique de données textuelles dans les\r\nsecteurs de l\'hôtellerie, la santé et les ressources humaines.\r\nNotre métier consiste à mettre en place une plateforme d\'annotation,\r\nd\'analyse et de visualisation de données pour aider les professionnels à\r\nprendre les bonnes décisions en innovant sans cesse.\r\n\r\nPOSTE\r\n\r\nNous recherchons actuellement un(e) stagiaire Développeur Chatbot /\r\nLangage Naturel.\r\n\r\nAu sein de notre Pôle R&D, vous participerez au développement d\'un\r\nchatbot qui devra utiliser les informations sémantiques produites par\r\nnos outils d\'analyse linguistique. Vous serez alors amené(e) à effectuer\r\nles tâches suivantes :\r\n\r\n- Evaluer les solutions de développement de Chatbot les mieux adaptées à\r\n  notre contexte,\r\n- Créer des réponses à partir des questions formulées via notre outil,\r\n- Développer l\'interface.\r\n\r\nPROFIL\r\n\r\n- Maîtrise d\'un langage de programmation pour Chatbot (Angular, Node.JS,\r\n  Vue.JS, etc.)\r\n- Bonnes connaissances des bases de données MySQL et MongoDB\r\n- Bonnes connaissances en TAL\r\n\r\nCe Stage est à pourvoir à partir de février 2018 au sein de nos bureaux\r\nsitués à La Défense.\r\n\r\nCONTACT\r\n\r\ncontact@e-motion-analysis.com'),
(459, '2018-01-08', 'Argus de la presse', 'Paris', 'L\'Argus de la presse, partenaire de plus de 30 000 marques, est une\r\nentreprise d\'intelligence économique appartenant au Groupe Cision,\r\nleader mondial des logiciels de relations médias, d\'influence et\r\nd\'intelligence médias. Le Groupe a une forte implantation\r\ninternationale, avec plus de 3.000 collaborateurs et près de 100.000\r\nclients.\r\n\r\nL\'Argus de la presse répond aux enjeux de ses clients pour leur\r\npermettre de piloter leur influence et leur réputation, mesurer et\r\nnourrir leur stratégie de communication et accompagner leur stratégie de\r\ndéveloppement.  L\'Argus de la presse se décline en 3 pôles d\'activités :\r\nMedia Intelligence, Media et Publics Insights et Market\r\nIntelligence.L\'Argus de la Presse - Groupe Cision doit répondre au\r\nquotidien aux enjeux industriels du traitement de l\'information à grande\r\néchelle.\r\n\r\nPour cela elle déploie des systèmes de gestion, de collecte et d\'analyse\r\nde données structurées et non structurées à grande échelle et des outils\r\nde veille et recherche d\'information ad hoc.\r\n\r\nL\'Argus utilise pour cela un certain nombre de technologies :\r\n\r\n   - technologies symboliques et numériques pour l\'apprentissage\r\n     automatique à partir de données\r\n   - fouille de données\r\n   - moteur de recherche texte\r\n   - traitement automatique du langage.\r\n\r\nDans ce cadre, l\'Argus est à la recherche d\'un stagiaire en Machine\r\nLearning et Information Retrieval.\r\n\r\n*Missions :*\r\n\r\nLa société lance en 2018 une nouvelle étude afin de challenger ces\r\ntechnologies dans un processus d\'amélioration continue.\r\n\r\nDans une démarche d\'innovation, la mission consiste à :\r\n\r\n- collaborer aux travaux d\'étude, de documentation, de conception et de\r\n  mise en oeuvre des Proof of Concept jusqu\'à la définition des meilleurs\r\n  scénarios de déploiement en situation réelle.\r\n\r\nCes travaux seront menés par une équipe composée des utilisateurs du\r\nsystème cible de recherche d\'information, de spécialistes en sciences de\r\nl\'information et des référents IT sur ces sujets.\r\n\r\n*Profil du candidat :*\r\n\r\nTitulaire d\'un master 2 ou doctorat en linguistique et informatique ou\r\nen data science avec une composante extraction des connaissances.\r\n\r\nVous avez une expérience académique ou professionnelle sur les outils de\r\nbase de l\'intelligence artificielle :\r\n\r\n   - technologies symboliques et numériques pour l\'apprentissage\r\n     automatique à partir de données\r\n   - constituants d\'un outil opérationnel de fouille de données\r\n   - fonctionnement des moteurs de recherche, texte, image, parole,\r\n     vidéo\r\n   - traitement automatique du langage.\r\n\r\nVous êtes à l\'aise avec la programmation et le développement de script\r\net la manipulation d\'algorithmes existants. Votre niveau en\r\nprogrammation vous permet de prototyper des solutions afin de les faire\r\nexpérimenter en interne. Dans le cadre de vos travaux, vous serez\r\namené(e) à identifier et à réutiliser des algorithmes existants pour les\r\nadapter à nos besoins métiers.\r\n\r\n*Formation et compétences requises :*\r\n\r\n*Compétences informatiques* :\r\n\r\nVous avez une connaissance académique ou pratique de certaines des\r\nsolutions suivantes :\r\n\r\n   - Outils ou algorithmes TAL : extraction d\'entités nommées,\r\n     catégorisation automatique, annotation de corpus, analyse du\r\n     sentiment, etc. ;\r\n   - Sensibilisation aux problématiques d\'analyse morphologique et\r\n     terminologique et formalismes et analyse syntaxiques\r\n   - Algorithmes de classification non supervisée (Ward clustering,\r\n     K-means...) ;\r\n   - Algorithmes de classification supervisée (Extratrees, SVM, RNN...) ;\r\n   - Base de graphes\r\n   - Langage de programmation : Python ou autre langage objet récent\r\n\r\nLe stage est à pourvoir dès que possible pour une durée de 4 à 6 mois.\r\n\r\n\r\n\r\n*Camille Connan*\r\nChargée de développement RH\r\n+33(0)1 49 25 72 78\r\ncamille.connan@argus-presse.fr\r\n\r\nhttp://www.argus-presse.fr/\r\nhttps://twitter.com/argusdelapresse\r\nhttps://www.facebook.com/Argusdelapresse/\r\nhttps://www.linkedin.com/company/argus-de-la-presse/\r\n*Consultez notre blog Culture RP http://culture-rp.com/*'),
(460, '2018-01-08', 'Prometil', 'Toulouse', 'Titre: Extraction automatique d\'une taxonomie à partir des données\r\nWikipédia adaptée à des documents techniques\r\n\r\n--------------------------\r\n\r\nStage financé par le projet CLE (Contrat de recherche Laboratoires -\r\nEntreprises)-ELENAA (des Exigences en LangagE Naturel à leurs Analyses\r\nAutomatiques)\r\n\r\n---------------------------\r\n\r\n*Contexte*\r\n---------------------------\r\n\r\nLe projet CLE (Contrat de recherche Laboratoires - Entreprises) intitulé\r\n\"ELENAA (des Exigences en LangagE Naturel à leurs Analyses\r\nAutomatiques)\", est mené par une collaboration entre Onera DTIM, IRIT\r\nSIG et la société Prometil avec un soutien financier de la région\r\nLanguedoc Roussillon Midi-Pyrénées (Occitanie).\r\n\r\nLe but de ce projet est, à partir d\'exigences réelles, écrites en\r\nlangage naturel, issues de systèmes embarqués, de réaliser des\r\nvérifications automatiques pour aider à la spécification d\'exigences\r\nplus sûres et sans erreurs. Pour ce faire, nous partirons d\'exigences\r\nécrites en langage naturel et nous plongerons ces exigences dans un\r\ncadre formel pour pouvoir utiliser des solveurs logiques. De plus, nous\r\nanalysons ces exigences en utilisant des technologies d\'intelligence\r\nartificielle (IA) comme de l\'apprentissage automatique afin d\'extraire\r\ndes anomalies spécifiques (par exemple la redondance).\r\n\r\n\r\n*Objectif*\r\n------------------------------\r\n\r\nLa société Prometil (www.prometil.com) développe depuis 3 ans un outil\r\nd\'analyse de la qualité des exigences qui sont au coeur de la conception\r\ndes systèmes embarqués, Semios (www.semiosapp.com). Il est actuellement\r\ndéployé chez des entreprises et des partenaires industriels (Toulouse,\r\nToulon, Paris). Prometil continue à innover Semios en renforçant les\r\nactivités R&D autour de cet outil par la collaboration avec les\r\nlaboratoires de recherche à travers le projet ELENAA.\r\n\r\nDans le cadre de ce projet, Prometil cherche un stagiaire en IA qui va\r\nparticiper dans les missions suivantes:\r\n\r\n   1. Extraction d\'une hiérarchie de données à partir de wikipédia\r\n   2. Etudes des différentes méthodes (algorithmes d\'apprentissage\r\n      automatique, réseaux neurones,...) d\'extraction des connaissances\r\n      à partir des documents techniques\r\n   3. Extraction des concepts significatifs liés aux domaines\r\n      spécifiques comme aéronautique, spatial, automobile, naval...\r\n   4. Construction des relations hiérarchiques (taxonomie) entre les\r\n      concepts identifiés en utilisant les données de Wikipédia.\r\n\r\n*Profil souhaité*\r\n------------------------------\r\n\r\nNiveau : Master 2 en Informatique, spécialisé en IA, Traitement des\r\ndonnées\r\n\r\n- Connaissances en méthodes d\'apprentissage automatique (supervisé et/ou\r\n  non-supervisé) et d\'apprentissage profond\r\n\r\n- Connaissances des techniques d\'extraction de graphes est un plus\r\n\r\n- Connaissances en outils du TAL (Tokenizers, POS taggers, Parsers) est\r\n  un plus\r\n\r\n- Capacités d\'analyse et de synthèse\r\n\r\n- Connaissance des langages de programmation Python et Java\r\n\r\n- Organisé(-e), autonome et curieux(-se) de nouvelles technologies\r\n\r\n*Modalités du poste*\r\n--------------------\r\n\r\nDurée : entre 4 et 6 mois\r\n\r\nDate de début: souhaité à partir de mars 2018\r\n\r\nIndemnité : minimum 550¤ /mois (possible de négocier selon les\r\ncompétences)\r\n\r\nLieu : Société Prometil - Toulouse\r\n\r\nMerci d\'adresser CV et lettre de motivation à l\'adresse mail suivante :\r\nsemios@prometil.com\r\n\r\nwww.prometil.com\r\nCharlotte BRETON COSTEDOAT\r\n\r\n*Responsable Marketing et Communication*\r\nChef de produit Maperless\r\n52 Rue Jacques Babinet 31100 Toulouse\r\nE-mail : c.breton@prometil.com\r\n\r\nTel. Prometil : +33 5 62 87 52 42\r\nExtension : 1090'),
(461, '2018-01-10', 'Yseop', 'Lyon', '*Offre de stage en Traitement Automatique du Language*\r\n\r\nYseop est une entreprise française leader du marché de la Génération\r\nAutomatique de Textes. Présente en France (Paris, Lyon), en Angleterre\r\net aux Etats Unis, sa mission principale est de fournir à ses clients\r\ndes services, un serveur de production, et un logiciel de parmétrage\r\n(IDE) permettant de construire des systèmes de génération de texte dans\r\nle but de créer divers documents, tels que des rapports d\'activité, des\r\npréparations d\'entretien, des FAQ intelligentes, etc.. Notre technologie\r\nest également utilisée dans des situations de dialogue pour la\r\nconstruction de chatbots et de systèmes de recommendation interactifs.\r\n\r\nLe stage proposé a pour but de renforcer le coeur de la technologie\r\nYseop en lui fournissant de nouvelles ressources linguistiques. La\r\nmission du stage consistera à créer des ressources linguistiques\r\n(syntaxiques et sémantiques) dans le formalisme des Grammaires\r\nCategorielles Abstraites (ACG), et à montrer l\'utilité de ces ressources\r\ndans le cadre d\'un projet pilote représentatif de projets réels. Le\r\nformalisme des grammaires catégorielles abstraites permet de représenter\r\nde manière unifiée divers formalismes existants (ex. TAG). Une partie du\r\ntravail consistera à trouver ou créer des ressources dans divers\r\nformalismes, puis à les traduire en ACG afin qu\'elles puissent être\r\nutilisées par le moteur de génération de texte d\'Yseop. Les formalismes\r\nutilisés et les langues cibles des ressources feront partie des\r\ndécisions prises lors du stage.\r\n\r\n*Informations Pratiques*\r\n\r\nNous cherchons en priorité des étudiant.e.s en stage de fin d\'étude\r\n(Master 2). Le contrat proposé est un CDD de 6 mois (rémunération à\r\ndéfinir en fonction du profil) avec embauche possible à la fin du\r\nstage. Pour postuler, merci d\'envoyer C.V. et lettre de motivation à\r\nl\'adresse suivante: rsalmon@yseop.com. La maîtrise de l\'anglais écrit\r\nainsi que de bonnes bases en programmation sont requises. Le stage se\r\ndéroulera au département R&D d\'Yseop à Lyon.'),
(462, '2018-01-10', 'CS', 'Paris', 'Description de l\'offre\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les contrôleurs à travers d\'échanges vocaux. Dans\r\nce contexte, CS conçoit et réalise une gamme de produits : systèmes de\r\ncommunication vocale (VCS), enregistreurs et simulateurs. Pour\r\nd\'autres applications comme la recherche d\'informations de parole dans\r\ndes enregistrements, les services de communication multilingue pour\r\nles compagnies aériennes ou la traduction multilingue de grosses\r\ndocumentations techniques, il est nécessaire de traiter non seulement\r\nla voix (signal audio) mais aussi la parole, c\'est à dire le contenu\r\nsémantique du signal audio, ou le texte écrit.\r\n\r\nDans ce contexte, nous souhaitons analyser les solutions disponibles\r\npour les principaux constituants d\'une chaîne de traduction de la\r\nparole : microphones à champ lointain utilisés pour la reconnaissance\r\nvocale (capteurs permettant d\'obtenir des enregistrements de qualité\r\nen environnement bruité), algorithmes permettant de déterminer le\r\ndébut et la fin d\'un message oral (question, réponse...), reconnaissance\r\nde la parole et synthèse vocale, et explorer leurs limites. Les\r\nexpérimentations seront réalisées sur PC et sur Raspberry. Une\r\nmaquette en Python déjà existante sur Raspberry pourra servir de point\r\nde départ.\r\n\r\nTravail à réaliser :\r\n\r\n1) Expérimentation des différents microphones en champ lointain\r\n\r\nDans la mouvance des assistants personnels apparus ces dernières\r\nannées, plusieurs fabricants de cartes électroniques proposent\r\naujourd\'hui des microphones sophistiqués mettant en oeuvre des\r\ntechniques de traitement de signal (formation de faisceaux par calcul,\r\ndétection d\'activité vocale, filtrage...) pour permettre un\r\nfonctionnement optimal des systèmes de reconnaissance vocale appelés\r\nen aval de la prise de son.  Le stagiaire expérimentera ces différents\r\nmicrophones, en cherchant à les paramétrer de manière à obtenir le\r\nmaximum de leurs possibilités.\r\n\r\n2) Prototypage\r\n\r\nSuite à cette première phase relative aux capteurs, le stagiaire\r\nréalisera un prototype de traduction de parole constitué :\r\n\r\n- d\'un module construisant les messages audio destinés à la\r\n  reconnaissance vocale,\r\n- d\'un module de reconnaissance vocale,\r\n- d\'un module de traduction automatique,\r\n- d\'un module de synthèse vocale,\r\n- d\'une interface utilisateur.\r\n\r\nPour le premier module, le stagiaire réfléchira aux algorithmes\r\npermettant de déterminer le début et la fin d\'un message oral\r\n(question, réponse...), de manière à offrir un service naturel à\r\nl\'utilisateur (limiter son attente du lancement de la reconnaissance\r\nvocale sans le couper au milieu de son message, possibilité de prendre\r\nplusieurs phrases successives du même locuteur avant de passer à son\r\ninterlocuteur, les traducteurs invoqués devant traduire en sens\r\nopposés). Le stagiaire envisager le cas où les deux interlocuteurs\r\nutiliseront le même microphone, et celui où l\'un des interlocuteurs\r\nutilisera une oreillette BlueTooth pour déterminer le sens de la\r\ntraduction à appliquer. Une reconnaissance du locuteur et de la langue\r\npourra aussi être étudiée.\r\n\r\nLes modules de reconnaissance et de synthèse vocales feront appel aux\r\nsolutions du marché. Le stagiaire évaluera ces solutions. Il étudiera\r\naussi les possibilités d\'envoi de la parole en continu (par opposition\r\nà l\'envoi de fichiers).\r\n\r\nLe module de traduction automatique se limitera à l\'appel d\'un\r\nexécutable, soit en local, soit sur un site Internet.\r\n\r\nL\'interface utilisateur devra offrir les informations et les champs\r\nnécessaires à un dialogue entre un client eu un agent, ou entre un\r\nagent et une machine.\r\n\r\nRésultats attendus :\r\n- Rapport d\'étude sur les microphones.\r\n- Rapport d\'étude sur les solutions de reconnaissance de la parole.\r\n- Rapport d\'étude sur les solutions de synthèse vocale.\r\n- Maquette implémentant la construction des messages audio destinés à\r\n  la reconnaissance vocale.\r\n- Prototype de traduction de parole.\r\n- Rapport d\'étude final.\r\n\r\n\r\nDurée : 4 à 6 mois\r\n\r\nProfil requis\r\n\r\nVous êtes en 4ème ou 5ème année et vous êtes à la recherche d\'un stage\r\nde 4 à 6 mois.\r\n\r\nVous avez idéalement les compétences techniques suivantes :\r\n- C/C++.\r\n- Python.\r\n\r\n\r\nPostuler sur https://cs.jobs.net/fr-FR/job/stagiaire-systeme-embarque-en-traduction-de-parole-h-f/J3W5P77793RW21LRNX4'),
(463, '2018-01-10', 'CS', 'Paris', 'Description de l\'offre\r\n\r\nDans le cadre de l\'amélioration des performances de ses systèmes de\r\ncontrôle de Trafic Aérien, et en particulier pour les services\r\nd\'enregistrement des communications vocales, CSSI cherche à intégrer\r\ndans ses solutions des technologies disponibles sur le marché :\r\nreconnaissance vocale, streaming audio, technologies IP.\r\n\r\nDans le cadre de ces travaux, le stagiaire devra réaliser un ensemble\r\nde maquettes permettant d\'évaluer la maturité et les performances de\r\nces fonctions et leurs capacités à être intégrées dans les futurs\r\nsystèmes.\r\n\r\nL\'intégration de la reconnaissance vocale dans un enregistreur audio a\r\npour but de transcrire automatiquement en texte les conversations\r\nradio des contrôleurs aériens et des pilotes d\'aéronefs lors de leur\r\nenregistrement.  \r\n\r\nProfil requis\r\n\r\nVous êtes en dernière année et vous recherchez un stage de 4 à 6 mois.\r\n\r\nVous avez idéalement les compétences techniques suivantes :\r\n- Développement C, C++, Linux, protocoles SIP, MRCP, RTP,\r\n- Conception objet (UML) et algorithmique\r\n\r\nSi possible également des compétences en :\r\n- Audio, Streaming, Reconnaissance vocale,\r\n- Conception d\'IHM, Qt\r\n\r\nPostuler sur https://cs.jobs.net/fr-FR/job/stagiaire-integration-de-la-reconnaissance-vocale-dans-un-enregistreur-audio-h-f/J3T5JT6YHL0M1GC86FY'),
(464, '2018-01-10', 'LS2N / LIMSI', 'Nantes ou Orsay', 'Objet : Stage M2 en TAL, Analyse distributionnelle en domaine de spécialité\r\n\r\nAujourd\'hui les modèles d\'analyse distributionnelle performants\r\nfournissent des ressources « prêt-à-porter » construites à partir de très\r\ngros corpus tout-venant de langue générale. Ces word embeddings\r\ngénériques ne sont pas suffisants pour représenter la sémantique en\r\ndomaine de spécialité, et il est donc nécessaire de les construire sur\r\nla base de corpus spécialisés.\r\n\r\nDans ce contexte, nous souhaitons porter notre attention sur la prise en\r\ncompte des termes dans des méthodes distributionnelles en mettant en\r\noeuvre des mécanismes de généralisation terminologique qui permettent de\r\nfactoriser des unités terminologiques. Plus particulièrement, il s\'agira\r\nde développer une approche permettant de remplacer tout terme par un\r\nterme plus générique par une acquisition préalable de classes\r\nsémantiques acquises sur un corpus de langue générale ou d\'un domaine\r\nproche de celui étudié.\r\n\r\nCe stage s\'inscrit dans le projet ANR ADDICTE (Analyse distributionnelle\r\nen domaine de spécialité) et pourra donner lieu à une thèse selon les\r\nrésultats du stage.\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\nNiveau: Master 2\r\nDurée: 5 à 6 mois\r\nLieu: Nantes ou Orsay\r\n\r\nPour présenter votre candidature, merci d\'envoyer CV, lettre de\r\nmotivation et relevé de notes à Emmanuel Morin\r\n(emmanuel.morin@univ-nantes.fr) et Thierry Hamon\r\n(thierry.hamon@limsi.fr)'),
(465, '2018-01-18', 'CS', 'Paris', 'Enconvertisseur UNL du français pour la traduction automatique\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les contrôleurs à travers d\'échanges vocaux. Dans\r\nce contexte, CS conçoit et réalise une gamme de produits : systèmes de\r\ncommunication vocale (VCS), enregistreurs et simulateurs. Pour\r\nd\'autres applications comme la recherche d\'informations de parole dans\r\ndes enregistrements, les services de communication multilingue pour\r\nles compagnies aériennes ou la traduction multilingue de grosses\r\ndocumentations techniques (Rafale pour l\'Inde/l\'Égypte..., par\r\nexemple), il est nécessaire de traiter non seulement la voix (signal\r\naudio) mais aussi la parole, c\'est à dire le contenu sémantique du\r\nsignal audio, ou le texte écrit.\r\n\r\nDans ce but, nous souhaitons étudier la faisabilité d\'un\r\nenconvertisseur du français, c\'est-à-dire un analyseur produisant des\r\ngraphes UNL (Universal Networking Language) à partir de textes en\r\nfrançais. Cet enconvertisseur nous permettra par la suite d\'évaluer la\r\npertinence des graphes UNL à la fois comme représentation source pour\r\ngénérer du texte dans plusieurs langues (déconversion) ou pour faire\r\ndes inférences (ontologies) et aussi comme interlingua pour de la\r\ntraduction automatique (enconversion + déconversion).\r\n\r\nPour transformer des phrases en graphes UNL, nous suivons la méthode\r\ndu GETA : utiliser un transducteur générique qui produit les graphes\r\nUNL à partir des représentations profondes (« structures multiniveaux\r\nde Vauquois », ou plus simplement « arbres de Vauquois ») obtenues par\r\ndes analyseurs existants. Plusieurs tels analyseurs produisant des\r\nstructures de Vauquois ont été développés sous Ariane et sont\r\ndisponibles en sources ouvertes.\r\n\r\n1) Transducteur générique « arbre de Vauquois graphe UNL »\r\n\r\nAprès une phase de prise de connaissance des principes d\'UNL et des\r\nstructures multiniveaux de Vauquois, le stagiaire étudiera l\'algorithme\r\nsimplifié du transducteur actuellement utilisé pour transformer les\r\nstructures multilniveaux en graphes UNL dans l\'enconvertisseur du\r\nfrançais. Il  l\'étendra ensuite :\r\n\r\n- en intégrant un traitement actuellement réalisé sous Ariane\r\n  (transfert),\r\n  \r\n- en prenant en compte les scopes, qui sont des entités sémantiques\r\n  autonomes actuellement non prises en compte.\r\n  \r\nle stagiaire clarifiera les éventuelles contraintes que doivent\r\nrespecter les structures multiniveaux présentées en entrée du\r\ntransducteur arbre-graphe puis il programmera l\'algorithme spécifié.\r\n\r\n2) Génération automatique d\'un analyseur du français à partir d\'un\r\ndictionnaire français-UNL\r\n\r\nD\'importantes ressources bilingues NL-UNL, avec NL = anglais (83507\r\nentrées), russe (63287 entrées), français (51352 entrées), hindi (50391\r\nentrées), malais (31406 entrées), espagnol (21874 entrées), vietnamien\r\n(10150 entrées) sont maintenues par Vyacheslav Dikonov, au laboratoire\r\nLCL de l\'institut IPPI de l\'Académie des Sciences de Moscou . Dans le\r\nbut de tirer le meilleur parti de ces dictionnaires, le stagiaire\r\nétudiera un programme générant automatiquement les fichiers.\r\n\r\nSi ce domaine vous intéresse, que vous êtes idéalement en 4ème ou 5ème\r\nannée d\'étude supérieur n\'hésitez pas à consulter nos offres de stage et\r\nà postuler sur :\r\nhttps://cs.jobs.net/fr-FR/search?keywords=stagiaire&location= ou\r\ndirectement par mail à alice.kauffmann@c-s.fr.'),
(466, '2018-01-18', 'EDF', 'Chatou (78)', 'Stage - TALN, text-mining et ontologies pour la maintenance d\'éoliennes\r\nH/F (Ref. St-18-0018)\r\n\r\nMise en ligne le 11/01/2018\r\nType d\'offre : Offre de stage (long)\r\nNiveau de formation : A partir de bac +4\r\nSpécialité(s) : Génie informatique / Télécommunications\r\nDomaine d\'intervention : R&D\r\nPays / Région(s) : France / Ile de France\r\nDépartement : YVELINES (78)\r\nVille : CHATOU (78400)\r\nNombre de places : 1\r\n\r\nDescription de la mission\r\n\r\nCONTEXTE DE LA MISSION\r\n\r\nSur les éoliennes des paramètres issus de capteurs permettent de réguler\r\net de surveiller le fonctionnement des différents composants de\r\nl\'installation et sont historisés dans des entrepôts de données. Lors de\r\nl\'observation d\'un phénomène inhabituel ou d\'un paramètre proche des\r\nlimites prévues de fonctionnement, l\'exploitant consulte notamment ces\r\nséries de données numériques pour établir un diagnostic et un pronostic\r\nsur le phénomène sous-jacent et ses conséquences prévisibles. Son\r\nobjectif est de déterminer si l\'exploitation doit être adaptée ou\r\ninterrompue pour maintenance ou si elle peut continuer jusqu\'à la\r\nprochaine période de maintenance prévue. Pour interpréter les évolutions\r\nde ces paramètres dans le temps, il a besoin de prendre en compte des\r\ninformations de contexte sur les opérations de maintenance (c\'est-à-dire\r\névénements de maintenance) qui ont été réalisées sur l\'installation\r\nainsi que les événements d\'exploitation subis par l\'installation. Une\r\ngrande partie de ces événements sont présents dans des documents\r\ntextuels non structurés ou dans du texte libre d\'outils de maintenance.\r\n\r\nL\'objectif du stage est de contribuer à la reconstitution de bases de\r\ndonnées d\'événements de maintenance et d\'exploitation à partir de corpus\r\ntextuels non structurés. Il s\'agit de mettre en oeuvre des techniques de\r\nfouille de données textuelles ou text-mining non pas statistiques (ou\r\npas uniquement) mais de traitement automatique du langage naturel (TALN)\r\net d\'analyse sémantique afin de retrouver ces évènements présents dans\r\nles textes pour reconstituer ces bases d\'évènements de maintenance et\r\nd\'exploitation des installations.\r\n\r\nUn événement est une combinaison d\'informations, comme par exemple pour\r\nla maintenance, une date, un composant d\'un matériel, un type\r\nd\'opération de maintenance et une action (prescription, réalisation,\r\n...). Certaines de ces informations peuvent être corroborées par des\r\ninformations structurées disponibles dans d\'autres parties du système\r\nd\'information (base de données de pièces de rechange...). Des documents\r\npeuvent ne contenir aucune des informations recherchées alors que\r\nd\'autres documents peuvent en contenir plusieurs qu\'il ne faudra pas\r\nmélanger.\r\n\r\nDe premiers démonstrateurs ont été réalisés en 2017 (stage et\r\ndéveloppement de chercheurs EDF R&D) pour répondre à un besoin métier et\r\nen exploitant des données textuelles de maintenance. La chaîne de\r\ntraitement comporte notamment une phase de correction orthographique,\r\ndes développements dans GATE (lexiques par catégorie d\'actions, règles\r\nJAPE, ontologies) pour l\'annotation ainsi qu\'une restitution sous forme\r\nstructurée des données extraites. Les premiers résultats ayant été jugés\r\npertinents par le métier, nous souhaitons continuer les travaux au-delà\r\ndu premier cas test, ce qui nécessite d\'améliorer la chaîne de\r\ntraitement.\r\n\r\nOBJECTIF DE LA MISSION\r\n\r\nL\'objectif du stage est de proposer et de réaliser des améliorations sur\r\nla chaîne de traitement (amélioration des développements et de\r\nl\'ontologie, développements complémentaires) afin de contribuer à\r\naméliorer les résultats, à généraliser à un périmètre plus large et à\r\ncompléter la réponse au besoin d\'analyse du retour d\'expérience.\r\n\r\nAvec des techniques et outils de text mining TALN/analyse sémantique, le\r\ntravail de stage consiste à :\r\n\r\n  * Prendre connaissance de la chaîne de traitement, l\'analyser et\r\n    proposer des pistes d\'amélioration ;\r\n  * Contribuer à la priorisation des pistes d\'amélioration avec les\r\n    chercheurs EDF R&D ;\r\n  * Concevoir, développer et évaluer des améliorations et compléments\r\n    dans la chaîne de traitement ;\r\n  * Positionner la solution mise en oeuvre dans l\'étude vis-à-vis des\r\n    autres solutions déjà mises en oeuvre par EDF sur d\'autres projets.\r\n\r\nDEBUT : à partir du 2ème trimestre 2018\r\n\r\nDUREE : 6 mois (stage rémunéré)\r\n\r\nProfil souhaité\r\n\r\nETUDIANTS CONCERNES : MASTER, ou Fin d\'études ingénieur.\r\n\r\nCOMPETENCES SOUHAITEES : La réalisation de cette étude nécessite des\r\ncompétences en modélisation des connaissances, en techniques de fouille\r\nde textes, en text-mining de type Traitement Automatique du Langage\r\nNaturel et d\'Analyse Sémantique, ainsi que des techniques et outils du\r\nweb sémantique, notamment RDF.\r\n\r\nInformation et candidature\r\n\r\nEn postulant sur cette offre sur le site internet edf recrute :\r\n\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres\r\n\r\nLa référence de cette offre est : ST-18-0018\r\n\r\nLien vers cette offre :\r\n\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-18-0018'),
(467, '2018-01-18', 'Experyenz', 'Paris', '-------------------------\r\nTitre\r\n\r\nStage: Développement et intégration d\'un moteur de recherche multilingue\r\n--------------------------\r\n\r\n---------------------------\r\n*Contexte*\r\n---------------------------\r\n\r\nLa société eXperYenZ développe une solution de gestion de contrats\r\nsignés pour ses clients. Ces contrats sont téléchargés sur la plateforme\r\nsous forme de fichiers pdf. Ces derniers doivent être OCRisés et soumis\r\nà un moteur d\'analyse qui doit retourner les index nécessaires aux\r\nrecherches et alertes nécessaires au service.\r\n\r\n*Objectif*\r\n------------------------------\r\n\r\nLe moteur de recherche est un élément clé du service développé. Il doit\r\nêtre performant pour minimiser la saisie manuelle des index et\r\nmultilingue pour accompagner notre développement à l\'international.\r\n\r\nPour cela nous souhaitons que ce moteur puisse intégrer des technologies\r\nd\'apprentissage automatique, voire d\'intelligence artificielle.\r\n\r\nNous possédons un moteur d\'OCR qui fonctionne sous C#, avec lequel les\r\ndéveloppements devront pouvoir être interfacés.\r\n\r\nDans le cadre de ce projet, eXperYenZ cherche un stagiaire en TAL qui va\r\nparticiper dans les missions suivantes:\r\n\r\n\r\n1. Etudes sur les outils du marché appliqués à l\'analyse de la qualité\r\n   des exigences\r\n\r\n2. Construction du corpus des exigences\r\n\r\n3. Choix des outils et technologies\r\n\r\n4. Développement du moteur\r\n\r\n5. Objectif de performance : à minima 50%. Plus le taux sera fort moins\r\n   nous aurons de ressources humaines à recruter pour le faire\r\n   manuellement, l\'enjeu est donc crucial sur le business model\r\n\r\n*Profil souhaité*\r\n------------------------------\r\n\r\nNiveau : Master 2 en Linguistique ou en Linguistique informatique\r\n\r\n- Connaissances en Traitement Automatique du Langage Naturel (notamment,\r\n  analyse syntaxique et sémantique)\r\n- Connaissances en outils du TAL (Tokenizers, POS taggers, Parsers, ... )\r\n- Capacités d\'analyse, de rédaction et de synthèse\r\n- Autonomie et curiosité\r\n\r\n*Modalités du poste*\r\n---------------\r\n\r\nDurée : entre 4 et 6 mois\r\n\r\nDate de début: souhaité à partir d\'Avril ou Mai 2018\r\n\r\nIndemnité : 550¤ à 700¤ /mois en fonction profil\r\n\r\nEnvoi des candidatures : laurent.lapierre@experyenz.com\r\n\r\nLieu : Région parisienne'),
(468, '2018-01-24', 'Workit', 'Boulogne-Billancourt', 'Stage Data Science (4 mois minimum)\r\n\r\n \r\nA propos de WorkIT\r\n\r\nWorkIT est un éditeur de logiciel SaaS qui fournit à ses clients\r\n(grandes marques, e-commerçants) des solutions de veille\r\nconcurrentielle (analyses de prix, d\'avis clients, alertes,\r\nbenchmarking...).\r\n \r\nCes solutions se basent sur des outils développés en interne et qui\r\npermettent dans un premier temps de collecter les données sur le web\r\n(infrastructure de crawl), de les analyser (machine learning), et de\r\nles présenter à nos clients via différents canaux.\r\n\r\nWorkIT analyse chaque jour les prix collectés dans plus de 17 pays sur\r\ndes univers allant de l\'électronique grand public à la mode, et\r\naccompagne ses clients depuis ses bureaux situés à Paris, London et\r\nDüsseldorf.\r\n \r\nL\'équipe R&D et la datascience\r\n\r\nL\'équipe RD de WorkIT est installée dans ses bureaux de Boulogne\r\nBillancourt et est constituée d\'ingénieurs de développement, d\'une\r\néquipe opérations, d\'une équipe qualité et de data scientists.\r\n\r\nL\'équipe de data scientists travaille spécifiquement sur des\r\nalgorithmes de catégorisation et de matching de produits vendus sur\r\ndes sites e-commerce. Par exemple, nous souhaitons parvenir, à partir\r\nde photos et de textes descriptifs de produits, à les catégoriser\r\nfinement et à mettre en relation des offres de produits identiques ou\r\nsimilaires vendues sur plusieurs sites distincts.\r\n\r\n Les spécificités du stage\r\n\r\nAu sein de l\'équipe data science, vous participerez aux diverses\r\nactivités permettant la mise au point et le déploiement de ces\r\nalgorithmes: organisation de la construction des datasets\r\nd\'apprentissage, recherche d\'algorithmes et d\'implémentations\r\npertinentes, entraînement et réglage des modèles, définition des\r\nprocessus d\'industrialisation, communication aux autres intervenants\r\nde la société.\r\n\r\nCe stage offre l\'opportunité de participer au sein d\'une petite équipe\r\nde recherche à toutes les phases de construction d\'une solution à une\r\nproblématique métier centrale pour WorkIT.\r\n\r\n Parmi les technologies/algorithmes que vous pourrez manipuler:\r\n\r\n   Machine learning appliqué aux images et/ou texte. Incluant le deep\r\n    learning (CNN, RNN, CapsNet, word embeddings, etc).\r\n \r\n   Environnement de développement Python/Java.\r\n\r\n   Elasticsearch, MongoDB et MySQL\r\n\r\nLe stage se déroule dans nos locaux à Boulogne-Billancourt.\r\n\r\n Le profil recherché\r\n\r\nFormation/niveau souhaitée: stage de fin d\'étude ou master en\r\ninformatique, statistiques, machine learning ou autre discipline\r\nproche.\r\n\r\nCompétences requise:\r\n\r\n    Connaissance des principales méthodes de Machine Learning\r\n\r\n    Expériences en apprentissage sur des images et/ou texte\r\n\r\n    Maîtrise de Python (sk-learn, Numpy, Scipy, Pandas, Keras,\r\n    Tensorflow, etc...)\r\n\r\n    Les connaissances d\'une ou plusieurs bases de données\r\n    relationnelles ou non relationnelles sont un plus\r\n\r\n    Autonome sous Linux\r\n\r\n \r\nPar ailleurs,\r\n\r\n   vous avez le sens de la communication et aimez travailler en\r\n   équipe,\r\n \r\n   vous avez d\'excellentes capacités d\'analyse/synthèse et savez faire\r\n   preuve de rigueur,\r\n\r\n   vous êtes curieux et créatif.\r\n\r\n \r\nUne bonne maîtrise de l\'anglais lu/écrit est indispensable.\r\n\r\n \r\nDates et sujet du stage\r\n\r\nNous avons plusieurs sujets possibles à différentes périodes de\r\nl\'année; si vous avez les compétences nécessaires, nous pouvons\r\nconstruire ensemble un sujet de stage qui réponde à vos attentes.\r\n\r\nSi vous vous reconnaissez et que vous avez envie de développer vos\r\ncompétences de data scientist dans une équipe jeune et ambitieuse,\r\nchez un leader du big data dans l\'e-commerce, alors venez nous voir;\r\nnous vous attendons.\r\n\r\nWorkIT, join the ascent.\r\n\r\nPour postuler, envoyez votre CV et votre lettre de motivation par\r\ne-mail à stage-datascience@workit-software.com'),
(469, '2018-01-24', 'Akio Software', 'Paris', 'Offre de stage chez Akio software\r\n\r\nTitre: Interprétation sémantique de la relation client\r\n\r\nDescriptif:\r\n\r\nLe sujet proposé traite de l\'interprétation sémantique des informations\r\néchangées entre une entreprise et ses clients. Le mode opératoire est\r\nomnicanal dans le sens où quelque soit le moyen choisi par le client,\r\nl\'entreprise doit pouvoir faire le lien entre le contact présent et\r\nl\'historique des interactions passées, même si elles sont de nature\r\ndifférente, que ce soit la voix, un tchat, le courriel ou les réseaux\r\nsociaux.\r\n\r\nDescription du poste:\r\n\r\nL\'objectif du stage est d\'apporter un regard extérieur sur la chaîne de\r\ntraitement actuelle afin de l\'améliorer en anglais, via une\r\nqualification quantitative. Nous sommes ouverts à de nouvelles idées qui\r\npeuvent contribuer à notre succès au sein d\'une équipe dynamique. Le\r\nstage portera essentiellement sur la partie sémantique des composants\r\nlinguistiques de calcul des thématiques, des opinions et des modalités\r\nd\'expression.\r\n\r\nProfil recherché:\r\n- Niveau Master 2 ou ingénieur dernière année.\r\n- Spécialité requise: traitement automatique de la langue.\r\n- Bonne expérience des courriels et des réseaux sociaux.\r\n- Bonne connaissance de l\'anglais qu\'il soit académique, familier ou\r\n  argotique.\r\n- La connaissance du néerlandais, du portugais ou de l\'italien serait un\r\n  plus.\r\n\r\nDurée:\r\n6 mois, de manière préférentielle d\'avril à septembre.\r\nDes adaptations sont possibles.\r\n\r\nLieu:\r\nAkio\r\nEquipe: traitement automatique de la langue.\r\n43 rue de Dunkerque, 75010 Paris.\r\n\r\nGratification:\r\nSelon les règles en vigueur avec participation aux frais de transports\r\nen commun.\r\n\r\nEncadrement:\r\nLe stage sera encadré par Gil Francopoulo.\r\n\r\nCandidature:\r\nMerci d\'envoyer un CV à gil.francopoulo@akio.com accompagné des notes de\r\nl\'année universitaire en cours et de celles de l\'année dernière.'),
(470, '2018-01-24', 'Price Observatory / LGI2P', 'Montpellier', 'Veuillez trouver ci-joint une offre de stage R&D sur Montpellier\r\nproposée dans le cadre d\'une collaboration entre la société Price\r\nObservatory (http://www.price-observatory.com/en) et le laboratoire\r\nLGI2P (http://lgi2p.mines-ales.fr/pages/la-recherche-au-centre-lgi2p) de\r\nIMT Mines Alès.\r\n\r\n*Algorithmes d\'appariement de fiches produit*\r\n\r\nStage R&D 6 mois niveau Master 2 sur Montpellier, salaire 1188 euros\r\nnet/mois, perspectives de thèse ou d\'embauche envisageables.\r\nDate limite de candidature 28/02.\r\n\r\n*Thématiques :* Comparaison de fiches produit, Algorithmique,\r\nApprentissage Automatique, développement Python/Java ou C++.\r\n\r\n*Le stagiaire aura pour mission :*\r\n\r\n - D\'analyser le contexte technique et les enjeux de la problématique\r\n   d\'appariement produit dans le contexte d\'étude associé à la société\r\n   Price Observatory.\r\n - De mener un travail bibliographique sur les approches d\'appariements,\r\n   et notamment sur celles basées sur des techniques d\'apprentissage\r\n   automatique supervisé et non supervisé.\r\n - De participer à la définition et au développement de nouveaux\r\n   algorithmes d\'appariement basés sur différentes techniques (fonctions\r\n   de proximité multi-modales, apprentissage automatique).\r\n - De contribuer à la constitution d\'une base d\'appariements de\r\n   référence et à la définition d\'un protocole de test des algorithmes.\r\n - Et éventuellement, d\'étudier la mise en production des solutions\r\n   identifiées comme d\'intérêt.\r\n\r\n*Compétences requises :*\r\n\r\n - Forte autonomie en programmation Python (ou R), et Java ou C++. Une\r\n   connaissance du langage PhP serait aussi appréciée mais ne constitue\r\n   pas un prérequis.\r\n - Bon niveau en Mathématiques (e.g., Statistiques, Algèbre linéaire) et\r\n   en Algorithmique.\r\n - Connaissances générales en apprentissage automatique (supervisé et\r\n   non supervisé).\r\n - Connaissances élémentaires en bases de données (création, requêtes\r\n   SQL, etc)\r\n - Maîtrise des processus qualité associés aux développements logiciels\r\n   en entreprise - gestionnaire de version, (GIT), tests unitaire,\r\n   rédaction de spécifications et documentations techniques, etc.\r\n - Capacité à travailler en équipe.\r\n\r\n*Rémunération :* 1188¤ net par mois. Le stagiaire sera salarié ARMINES\r\n(Première structure française de recherche orientée vers les\r\nentreprises, adossée à 48 centres de recherche).\r\n\r\n*Durée :* 6 mois (+ cf. perspectives précisées ci-dessous).\r\n\r\n*Lieu :* Price Observatory 28 Avenue du Maurin, Montpellier (à proximité\r\nde la gare).\r\n\r\n*Perspectives :* Des perspectives de thèse financée et d\'embauche sont\r\nenvisageables et seront évaluées en fonctions du travail réalisé lors du\r\nstage.\r\n\r\n*Contacts :*\r\n\r\n - Sébastien HARISPE, Enseignant-Chercheur IMT Mines Alès\r\n   (sebastien.harispe@mines-ales.fr).\r\n   \r\n - Nicolas SUTTON-CHARANI, Enseignant-Chercheur IMT Mines Alès\r\n   (nicolas.suttoncharani@mines-ales.fr).\r\n\r\n*Candidature :* Les dossiers de candidature doivent être envoyés par\r\ncourriel à M. HARISPE et M. SUTTON-CHARANI *avant le 28 février*. Ils se\r\ncomposeront nécessairement d\'un CV détaillé, d\'une lettre de motivation,\r\net des notes obtenues lors des deux dernières années, et éventuellement\r\nde lettres de recommandation. Une prise de contact avec l\'encadrement\r\nest souhaitée avant toute soumission de candidature.'),
(471, '2018-01-24', 'INRIA', 'Sophia Antipolis', '=== 6-month Internship available at INRIA Sophia Antipolis, France ===\r\n\r\n--Title--\r\n\r\nText auto-illustration for improving reading accessibility to\r\nlow-vision people\r\n\r\n--- Background and objectives ---\r\n\r\nLow vision is a condition caused by eye disease which cannot be\r\ncorrected or improved with regular eyeglasses. Retinal-degeneration\r\ndisorders concern 285 million people in the world and it is predicted\r\nthat prevalence of visual disabilities will increase markedly during\r\nthe next 20 years. These disorders characterised by a progressive\r\nretinal degeneration not only in photoreceptors but also in the\r\noverall structure of the retina. So there is a real societal and\r\nscientific challenge to provide new solutions to help low vision\r\npeople in their daily life activities. Among them, reading poses\r\nproblems for almost everyone with low vision and it is amongst the\r\nstrongest need reported by patients.\r\n\r\nThe BIOVISION team is currently working on a project to bring reading\r\nexperience to a higher level of immersivity by providing a highly\r\ncustomizable visualization software running on phone-based virtual\r\nreality platforms. In this context, in collaboration with the WIMMICS\r\nteam, we propose to explore text auto-illustration methods, consisting\r\nin automatically extracting image from the web which are related to\r\nthe text, to make reading more efficient and enjoyable for low vision\r\npatients.\r\n\r\nDuring the internship, the successful candidate will be responsible for:\r\n\r\n- investigating NLP methods to extract concepts and entities contained\r\n  in some text and link them to online image contents.\r\n\r\n- once images are collected, he/she will apply image processing\r\n  methods to create meaningful visual content from a selection of\r\n  ranked images representing the entities found.\r\n\r\n--- Candidate profile ---\r\n\r\nThe successful candidate will have the following profile:\r\n- Msc or MA Student in Computer Science, or Computational Linguistics.\r\n- Experience in Natural Langage Processing, Artificial Intelligence\r\n  and/or Machine Learning;\r\n- Excellent programming skills;\r\n- Strong interest in working in a multidisciplinary context made of\r\n  computer scientists of different fields (NLP and image processing),\r\n  and motivated my medical applications.\r\n\r\n--- Terms of the internship position ---\r\nDuration: 6 months\r\nStarting date: asap\r\n\r\nLocation: INRIA, Sophia Antipolis, France.\r\n\r\nHosting teams: BIOVISION (https://team.inria.fr/biovision/) and\r\nWIMMICS (http://wimmics.inria.fr/).\r\n\r\nInternship grant: 1200¤ / month (net salary).\r\n\r\nApplications : a curriculum vitae together with a motivation letter\r\nshould be sent to Pierre Kornprobst (pierre.kornprobst@inria.fr) and\r\nElena Cabrio (elena.cabrio@unice.fr)\r\n\r\nDeadline for applications: position open until filled.'),
(472, '2018-01-30', 'Altran', 'Puteaux', 'Stage R&D en ML && NLP niveau master2 chez Altran\r\nRéférence de l\'offre : Stage_ALTRAN RESEARCH_GOTTRA++_2018\r\nDate :  Mars 2018 - Ville : PUTEAUX - Entité : Altran Research\r\n\r\n\r\nContexte :\r\nDepuis quelques années, le test et la recette applicative sont reconnus\r\ncomme une activité essentielle pour garantir le niveau de qualité d\'un\r\nsystème d\'information livré, de ce fait il est devenu un domaine\r\nd\'expertise spécifique en termes d\'outillage et de\r\nméthodologie. Néanmoins, avec le développement des technologies IT et\r\ndes méthodologies de tests, il est devenu indispensable de faire recours\r\nà l\'automatisation des tests afin de réduire les temps des recettes et\r\nleur coût. Par ailleurs, il est important de signaler que cette\r\nautomatisation n\'est pas toujours possible ou évidente à mettre en oeuvre\r\ncomme elle dépend de plusieurs facteurs : nature et sensibilité des\r\napplications testées, environnement de test utilisé, expérience requise\r\npour certain tests, complexité des tests, etc.\r\nDe ce fait, dans le présent stage, nous nous intéressons au\r\ndéveloppement d\'une application basée sur les algorithmes du traitement\r\ndu langage naturel et du machine learning afin de définir et d\'extraire\r\ndes cas et scénarii de tests à partir des spécifications fonctionnelles\r\nd\'un projet TRA et/ou d\'un enregistrement de l\'activité des\r\nutilisateurs, et de transformer ces cas de test en scripts d\'exécution\r\npour réaliser des tests automatisé.\r\n\r\nMission :\r\nLe candidat devra :\r\n- Etude des techniques et outil d\'automatisation des tests et choix d\'un\r\n  langage de script\r\n- Etude des données projets TRA (Tierce Recette Applicative)\r\n- Etude de diverses techniques du traitement du langage naturel pouvant\r\n  être utilisées et caractérisation de l\'orientation à suivre pour\r\n  l\'application.\r\n- Identification des principaux factuers influant sur l\'automatisation\r\n  des tests\r\n- Proposition d\'une structuration de la base de données de l\'outil\r\n  prenant en compte les données projets et les facteurs identifiés\r\n- Conception d\'un moteur de recherche et d\'extraction des cas et\r\n  scénarii de test.\r\n- Application des algorithmes de machine learning afin d\'identifier les\r\n  scénarii automatisables et pertinents\r\n- Conception et développement d\'une application d\'automatisation des tests\r\n- Tests et validation des développements  \r\n- Formaliser les travaux effectués et tous les résultats obtenus dans un\r\n  rapport de stage accompagné de l\'ensemble des algorithmes et\r\n  programmes développés.\r\n\r\nProfil recherché:\r\n- Formation ingénieur ou Master 2 en IA, Data Science, Machine Learning\r\n- Programmation : javascript, HTML, JAVA J2EE, Python.\r\n- Formalisation et conception : architecture MVC et SOA, modèles UML et\r\n  MCD\r\n- Framework : Spring MVC \r\n- Bonne Connaissance en méthodes de traitement du langage naturel. \r\n- Bonne Connaissance en statistiques et en machine learning\r\n- Connaissance en BI (intégration des données + reporting)\r\n- Autonomie, ouverture d\'esprit\r\n- Maitrise des outils informatiques\r\n\r\nDurée : minimum 6 mois \r\nDate de début : Mars 2018\r\nLieu : Puteaux, siège d\'Altran France / IT Paris \r\nSecteur d\'Activité : Direction des Opération / IT Paris\r\nContact : ehab.hassan@altran.com \r\n\r\nA propos d\'ALTRAN\r\nLeader mondial du conseil en innovation et ingénierie avancée, Altran\r\naccompagne les entreprises dans leurs processus de création et\r\ndéveloppement de nouveaux produits et services. Les Innovation Makers[1]\r\ndu groupe interviennent depuis 30 ans auprès des plus grands acteurs des\r\nsecteurs aérospatial, automobile, énergie, ferroviaire, finance, santé,\r\ntélécommunications, etc. Les offres du groupe, déclinées depuis les\r\nphases du plan stratégique en matière de technologies nouvelles\r\njusqu\'aux phases d\'industrialisation, assurent la capitalisation du\r\nsavoir au sein de 5 domaines principaux : intelligent systems,\r\ninnovative product development, lifecycle experience, ingénierie\r\nmécanique, et systèmes d\'information.\r\nLe groupe Altran a réalisé en 2014 un chiffre d\'affaires de 1 756 M¤. Il\r\ncompte désormais plus de 23 000 collaborateurs dans plus de 20 pays.\r\nhttp://www.altran.com/fr \r\n\r\nA propos d\'ALTRAN RESEARCH\r\nAltran Research est le département de Recherche interne d\'Altran en\r\nFrance. Ses programmes de recherche adressent les domaines de l\'e-santé,\r\ndes transports terrestres et de la mobilité, de l\'aéronautique et du\r\nspatial, de l\'industrie et des services du futur, de l\'énergie, des\r\nsystèmes complexes.\r\n\r\nLes projets, développés dans une perspective de développement durable,\r\nfont intervenir des expertises variées en vue de développer :\r\n\r\n- de nouvelles méthodologies, de nouveaux outils, de nouvelles offres de\r\n  services permettant d\'apprécier la vraie valeur durable des solutions\r\n  en évaluant leur impacts sociaux, environnementaux et économiques\r\n- de nouveaux produits, démonstrateurs ou systèmes complexes. Ces\r\n  solutions sont modélisées et validées, à la fois sur le plan\r\n  fonctionnel, technologique et systémique.\r\n\r\n\r\nEhab HASSAN \r\nChef de Projet R&D, Département Recherche.  \r\nProgramme « Machine Driven Big Data »\r\nPatios Défense 14 bis Terrasse Bellini\r\n92807 Puteaux   \r\nFRANCE\r\nTel. : +33 (0)1 46 17 46 17');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(473, '2018-01-30', 'ERTIM & Reticular', 'Paris', '*Extraction et prétraitement de données issues d\'interviews politiques*\r\nStage proposé par l\'entreprise Reticular et le laboratoire ERTIM\r\n(Inalco)\r\n\r\n*Contexte*\r\n\r\nL\'entreprise Reticular propose des services de veille à destination à\r\ndes décideurs publics, politiques, dirigeants d\'entreprise, etc. Ces\r\nservices incluent une cartographie des acteurs (entités ou personnes),\r\nla mise en évidence de liens organiques (filiale, autorité, concurrence,\r\npartenariat, alliance) selon leur proximité d\'opinion dans le débat\r\npublic.\r\n\r\nReticular et ERTIM sont partenaires du projet TALAD (2017-2021), qui se\r\nfocalise sur les interactions entre le traitement automatique des\r\nlangues (TAL) et l\'analyse du discours (AD). L\'objectif est de\r\ndéterminer comment le TAL peut outiller l\'AD dans ses explorations et,\r\nen retour, quel éventail de phénomènes complexes l\'AD peut offrir comme\r\nproblématique nouvelle en TAL. En particulier, la nomination (différents\r\nnoms possibles pour désigner une entité) a été choisie comme objet\r\nd\'étude principal.\r\n\r\nPour ce projet, Reticular apporte des données issues d\'une collecte\r\nsemi-automatique d\'interviews « matinales ». Ces interviews constituent\r\nun matériau original, étant spontanées et pouvant être par conséquent\r\nporteuses de nominations particulièrement révélatrices sur les opinions\r\ndes personnalités interviewées (thématiques a priori : migrants vs\r\nréfugiés / patriotisme économique vs protectionnisme). Depuis plus d\'un\r\nan, plus de 5000 interviews ont été transcrites et annotées.\r\n\r\n*Objectifs principaux*\r\n\r\nLe projet venant de démarrer, il s\'agit en premier lieu de mettre en\r\nplace l\'extraction des donnés et d\'expérimenter les solutions adéquates\r\npour repérer les nominations, notamment en détectant les entités\r\ncoréférentes au sein du corpus.\r\n\r\n1/ Écriture de scripts pour extraire les données des bases Reticular\r\n   selon des mots-clés fournis par les linguistes\r\n2/ Mise au format (XML) afin de les rendre exploitable par les équipe de\r\n   recherche, notamment à des fins d\'annotation, avec métadonnées\r\n   (sources, date, interlocuteurs, etc.)\r\n3/ Description des données (statistiques sur les données)\r\n4/ Premiers travaux sur la détection de mentions d\'entités coréférentes\r\n   sur les thématiques choisies\r\n5/ Extraction d\'évènements dans les interviews liées aux entités\r\n   détectées\r\n6/ Interaction avec les équipes qui travaillent en TAL (entités nommées,\r\n   coréférence) et en AD (annotation des nominations)\r\n\r\n*Profil recherché*\r\n\r\n- M2 en TAL\r\n- Langages : python, langages web (HTML / JS)\r\n- Bases de données : PostgresSQL, MongoDB, NoSQL, XML\r\n- Compréhension des enjeux pour la linguistique et en particulier pour\r\n  l\'annotation des données\r\n- La connaissance de NodeJS, AngularJS, Java est un plus\r\n\r\n*Précisions sur l\'offre*\r\n\r\n- Durée du stage : 6 mois à temps plein\r\n- Date de début : mai 2018\r\n- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)\r\n- Lieu : Inalco, 2 rue de Lille, 75007 Paris\r\n- Possibilité de poursuivre en thèse sur le projet TALAD\r\n\r\nPour candidater, envoyez votre CV et de faire part de vos motivations à\r\nLaurent Muller (lmuller@reticularproject.com), Didier Arbant\r\n(darbant@reticularproject.com) et Damien Nouvel\r\n(damien.nouvel@inalco.fr).'),
(474, '2018-01-30', 'CEFE & Praxiling', 'Montpellier', 'Stage Master 2 : automatisation d\'analyse sémantique en vue de\r\nsynthétiser et faciliter les procédures de concertation dans le cadre\r\nde projet d\'aménagement du territoire\r\n\r\nDurée : 5 mois\r\n\r\nLocalisation : Université Paul Valéry, Rte de Mende, 34000 Montpellier\r\n\r\nLaboratoire CEFE\r\n\r\nLe CEFE, créé en 1961, est le plus important laboratoire de recherche\r\nen Ecologie en France. Le CEFE développe ses activités sur les grandes\r\npréoccupations des sociétés : la biodiversité, les changements à\r\nl\'échelle planétaire et le développement durable. Une grande partie\r\ndes recherches porte sur les écosystèmes méditerranéens et tropicaux.\r\nL\'objectif du laboratoire est d\'établir des scénarios d\'évolution des\r\nsystèmes écologiques et des stratégies pour leur conservation, leur\r\nrestauration ou leur réhabilitation.\r\n\r\nLe CEFE est organisé en quatre départements scientifiques entourés de\r\nplates-formes techniques communes. Quatre thèmes transversaux\r\ncoordonnent l\'apport scientifique du CEFE aux grands thèmes\r\ninternationaux de la recherche en Écologie :\r\n\r\n1. Action de l\'Homme, systèmes anthropisés et écologie de la conservation.\r\n2. Adaptions des espèces aux modifications de leur environnement\r\n3. Rôle de la biodiversité dans le fonctionnement des écosystèmes.\r\n4. Changements globaux et fonctionnement des écosystèmes\r\n\r\nAu sein du département `Action de l\'Homme, systèmes anthropisés et\r\nécologie de la conservation\', une équipe de chercheurs en géographie\r\ns\'intéresse plus particulièrement au conséquence des projets\r\nd\'aménagement sur les écosystèmes. Aussi, elle questionne\r\nl\'acceptation des projets d\'aménagement du territoire, notamment du\r\npoint de vue de leur impact environnementaux à travers la compensation\r\nécologique qui entre en jeu lors de leur réalisation (autoroute, ferme\r\néolienne, etc.). Plus en amont, elle travaille depuis un an sur la\r\nconcertation au sein de quelques projets d\'aménagement pour comprendre\r\ncomment le citoyen s\'il est intégré dans la conception des projets\r\npeut se porter garant d\'une meilleure prise en compte de\r\nl\'environnement.\r\n\r\nLa justification du stage\r\n\r\nD\'un point de vue de la participation, les autorisations données pour\r\nla réalisation de gros projets d\'aménagement du territoire sont\r\nconditionnées par la longue appréciation de l\'enquête publique, étape\r\nfinale d\'un processus de concertation amont plus ou moins long. Lors\r\nde cette concertation amont, de nombreuses interventions d\'acteurs ont\r\nlieux et il est souvent difficile de faire état de ce qui se passe\r\npour organiser la concertation sous forme de débat, pour : - présenter\r\nles changements de position, - expliciter les productions de savoirs\r\ncollectifs. Dans ce cadre, le passage aux outils numériques permet une\r\nstructuration de la concertation de manière dématérialisée : (i) un\r\nenregistrement des paroles d\'acteurs et (ii) l\'identification des\r\nsujets de discussion, des positionnements par acteurs. Cependant, la\r\nmise en ligne de tous les contenus (oraux ou écris) pose problème et\r\nil reste encore à traiter les contenus pour synthétiser et faciliter\r\nles différentes étapes de la concertation, en toute équité et\r\ntransparence.\r\n\r\nLe sujet du stage\r\n\r\n\r\nEn collaboration avec le laboratoire PRAXILING de l\'Université Paul\r\nValéry, vous devrez réaliser un benchmark des outils d\'analyse\r\nsémantique dématérialisé. Puis vous devrez travailler avec des\r\nchercheurs, des designers et des industriels/aménageurs pour aider à\r\nchoisir le/les meilleurs outils. Il s\'agit de les adapter au contexte\r\nde l\'analyse de contenus relatifs à la concertation dans le cadre de\r\nprojet d\'aménagement : (1) identification de thématiques communes, (2)\r\nde fréquences des besoins, (3) argument d\'oppositions et de soutiens,\r\n(4) association d\'idées et (5) explicitation des modes de discours sur\r\nles enjeux.  Enfin, vous réaliserez une conception de l\'application en\r\nroutine de l\'outil afin de pouvoir le transférer à un développeur de\r\nplateforme numérique en ligne, partenaire du projet.\r\n\r\nLes attendus du stage\r\n\r\n- Une procédure de traitement automatique sous forme de concept\r\ntransférable à un développeur web\r\n\r\n- Un article scientifique sur le sujet « analyse de contenus non\r\nargumentatifs et argumentatifs dans le cadre de projet d\'aménagement\r\ndu territoire, proposition de synthétisation/facilitation de\r\nconcertation par traitement sémantique automatique »\r\n\r\nVos candidatures sous forme de CV et lettre de motivation doivent être\r\nadressée à Mr Pierre Yves Hardy (pierre-yves.hardy@univ-montp3.fr) et\r\nSylvain Pioch (sylvain.pioch@univ- montp3.fr) avant le 20 février\r\n2018.'),
(475, '2018-02-07', 'LIG', 'Grenoble', '* Titre : Outillage de l\'accès aux textes par lecture active\r\n\r\n  étymologique multilingue *\r\n\r\n\r\n\r\n Responsables à contacter  \r\n\r\nEnvoyez votre CV par Mel à :\r\n\r\nValérie Bellynck (Valerie.Bellynck@imag.fr)\r\n\r\nMathieu Mangeot (Mathieu.Mangeot@imag.fr)\r\n\r\n\r\n\r\n* Mots clés - Keywords *\r\n\r\nRessources linguistiques, Ressources lexicales, TAL, service Web,\r\n\r\nintercompréhension en langues romanes, intercompréhension en langues\r\n\r\nsinogrammiques\r\n\r\n\r\n\r\n* Profil - Compétences *\r\n\r\nÉtudiant en M2R informatique intéressé par les langues ou plus\r\n\r\ngénéralement les humanités numériques ou linguiste ayant de bonnes\r\n\r\nconnaissances en programmation Web.\r\n\r\nHTML/XML, javascript, PHP, services Web, analyse lexicale, bases\r\n\r\nlexicales, API REST.\r\n\r\n\r\n\r\n* Précisions sur l\'offre *\r\n\r\n- Durée du stage : 5 à 6 mois à temps plein\r\n\r\n- Date de début : 2018\r\n\r\n- Rémunération : tarif en vigueur (~550¤/mois)\r\n\r\n\r\n\r\n- Lieu : Laboratoire LIG, Bâtiment IMAG, 700 avenue centrale 38400\r\n\r\n  Saitn Martin d\'Hères\r\n\r\n\r\n\r\n Description \r\n\r\n\r\n\r\nL\'apprentissage des langues peut être grandement facilité par les outils\r\n\r\ninformatiques au sens large. La lecture active est un de ceux-ci. Elle\r\n\r\npermet d\'afficher des compléments d\'information (transcriptions\r\n\r\nphonétiques, traductions de mots, etc) pendant la lecture d\'un texte.\r\n\r\nEn quelque sorte, elle réalise l\'équivalent électronique du dictionnaire\r\n\r\nmain-gauche.\r\n\r\nL\'outil affiche au dessus d\'un texte entré par l\'utilisateur une\r\n\r\ntranscription des mots dans une autre langue mieux connue de celui-ci et\r\n\r\nrend disponible la traduction de chaque mot au survol de la souris. La\r\n\r\ntraduction n\'est pas affichée de manière permanente pour inciter le\r\n\r\nlecteur à comprendre le texte.\r\n\r\nL\'utilisateur peut contribuer directement, améliorer, ou même juste\r\n\r\ns\'approprier des formes lexicales, au plus près de sa lecture. Voir\r\n\r\nhttp://jibiki.fr/lecture .\r\n\r\n\r\n\r\nLes traitements nécessaires à la réalisation de cet outil sont\r\n\r\nprincipalement l\'utilisation d\'outils de traitement automatique des\r\n\r\nlangues dont des analyseurs morphologiques ainsi que la consultation\r\n\r\nd\'une base lexicale.\r\n\r\n\r\n\r\nNous voulons étendre ce concept pour aider à retenir la forme des mots\r\n\r\net faciliter l\'intercompréhension dans des langues voisines. Il s\'agit\r\n\r\nalors d\'afficher des constituants des mots, soit pour leur origine\r\n\r\nétymologique, soit pour leur ressemblance.\r\n\r\n\r\n\r\n Problèmes durs \r\n\r\n\r\n\r\n- généricité\r\n\r\n  L\'application finale doit être conçue de manière totalement générique\r\n\r\n  du point de vue des langues traitées mais également des ressources\r\n\r\n  lexicales et des outils de TAL utilisés.\r\n\r\n\r\n\r\n- extraction d\'information\r\n\r\n  L\'information utile se trouve dans certains dictionnaires. Cependant,\r\n\r\n  bien souvent, les entrées ne sont pas suffisamment structurées pour\r\n\r\n  trouver simplement ces informations. Il faut donc les analyser pour\r\n\r\n  trouver l\'information voulue puis les modéliser pour les intégrer à la\r\n\r\n  base lexicale.\r\n\r\n\r\n\r\n- comparaison de chaînes de caractères\r\n\r\n  Il faut également être capable de modéliser les permutations\r\n\r\n  phonologiques à l\'aide d\'outils tels que des transducteurs à états\r\n\r\n  finis puis calculer des distances de chaîne entre les mots des\r\n\r\n  différentes langues en jeu (voir dans l\'exemple ci-dessous densha <=>\r\n\r\n  diànche).\r\n\r\n\r\n\r\n- conception d\'interfaces utilisateurs\r\n\r\n  L\'affichage final des résultats demande de concevoir les modalités\r\n\r\n  d\'affichage et d\'interaction permettant de rendre sensible les\r\n\r\n  différentes sources de ressemblance (racine linguistique, langue, mode\r\n\r\n  d\'écriture, ...).\r\n\r\n\r\n\r\nL\'exemple suivant est tiré d\'un scénario où le lecteur apprend le\r\n\r\njaponais et possède des connaissances en mandarin. D\'autres scénarios\r\n\r\nsont possibles avec des ensemble de langues voisines (groupes de langues\r\n\r\nou langues régionales comme les langues romanes, le français et le\r\n\r\nbreton, etc.). Cette partie du sujet peut s\'adapter aux affinités du\r\n\r\nstagiaire.\r\n\r\n\r\n\r\n Références \r\n\r\n\r\n\r\nGoudin, Y. Mangeot, M., Loiseau, M. Bellynck, Mboning, E. & Eggers,\r\n\r\nE. (2017). `La prise en charge du lexique pour l\'apprentissage sur\r\n\r\nplateforme en ligne : scénarios d\'utilisation et prises en compte des\r\n\r\nspécificités du mandarin\' avec , in Journées de l\'AREC 2017 « Le lexique\r\n\r\nchinois contemporain », Université Diderot, 2-3 juin.\r\n\r\n\r\n\r\nMangeot, M., Bellynck, V., Eggers, E., Loiseau, M., & Goudin,\r\n\r\nY. (2016). Exploitation d\'une base lexicale dans le cadre de la\r\n\r\nconception de l\'ENPA Innovalangues. In I. Smilauer & J. Kostov (Éd.),\r\n\r\nActes de la conférence conjointe JEP-TALN-RECITAL 2016 (Vol. 9 : ELTAL,\r\n\r\np. 48-64). Paris: ATALA/AFCP. Consulté à l\'adresse\r\n\r\nhttps://jep-taln2016.limsi.fr/actes/Actes%20JTR-2016/V09-ELTAL.pdf\r\n\r\n\r\n\r\nMangeot, M., (2016). Collaborative construction of a good quality, board\r\n\r\ncoverage and copyright free Japanese-French dictionary. In International\r\n\r\nJournal of Lexicography 2016; doi: 10.1093/ijl/ecw035; 35 p.\r\n\r\n\r\n\r\nDegache, C. (1997) : « Développer l\'intercompréhension dans l\'espace\r\n\r\nlinguistique roman: le programmeGalatea/Socrates », Document ronéoté,\r\n\r\nAssises de l\'enseignement du et en français, séminaire de Lyon,\r\n\r\nAupelf-Uref, 23-25 septembre 1997.\r\n\r\n\r\n\r\nMathieu MANGEOT\r\n\r\nGETALP-LIG Bureau 338\r\n\r\nBâtiment IMAG, 700 avenue Centrale\r\n\r\nF-38400 St Martin d\'Hères France\r\n\r\nTel : +33 4 57 42 15 26 / +33 4 79 75 81 89'),
(476, '2018-02-19', 'LNE', 'Trappes', '- Stage informatique Master ou école d\'ingénieur\r\n\r\n\r\n\r\n- Sujet : développement d\'un outil d\'annotation - contexte : données\r\n\r\n  multimédia générées dans le cadre d\'une compétition en robotique\r\n\r\n  agricole\r\n\r\n\r\n\r\n- Requis : forte autonomie en développement informatique, connaissances\r\n\r\n  en création d\'interfaces graphiques, capacité à utiliser des\r\n\r\n  librairies de manipulation de fichiers multimédia\r\n\r\n\r\n\r\n- 6 mois à partir de mars 2018\r\n\r\n\r\n\r\n- Lieu : Laboratoire national de métrologie et d\'essais, Trappes (78) -\r\n\r\n  Transilien lignes L et N\r\n\r\n\r\n\r\n- Rémunération : 1054¤ bruts\r\n\r\n\r\n\r\nMerci d\'envoyer votre candidature (lettre de motivation et CV) en\r\n\r\nrappelant en objet du mail la référence STA/ROSE/DE, à\r\n\r\nrecrut@lne.fr.'),
(477, '2018-02-19', 'MoDyCo / LIMSI', 'Nanterre ou Saclay', 'Offre de stage Master 1 ou 2 de Linguistique/TAL\r\n\r\n\r\n\r\nTITRE : Aide au développement d\'un outil langagier bilingue LSF-Français\r\n\r\ncentré sur l\'acquisition de la temporalité\r\n\r\n\r\n\r\n--------------\r\n\r\n\r\n\r\nStage financé par la DGLFLF, Projet « Temporalité linguistique en LSF et\r\n\r\nfrançais écrit »\r\n\r\n\r\n\r\n--------------\r\n\r\n\r\n\r\nLe présent projet a pour objet d\'étude l\'acquisition d\'un certain nombre\r\n\r\nde notions linguistiques liées à l\'expression de la temporalité chez\r\n\r\nl\'enfant sourd. On note en effet que desproblèmes sont rencontrés par\r\n\r\nces enfants pour maîtriser l\'expression de la temporalité, en Langue des\r\n\r\nSignes Française (LSF) comme en français écrit. L\'objectif du projet est\r\n\r\nde développer un premier prototype d\'aide à l\'acquisition (par des\r\n\r\nexercices d\'entraînement) des notions et structurations que nécessite\r\n\r\nl\'expression de la temporalité dans toutes les langues utilisées par les\r\n\r\nenfants sourds. Cet outil s\'adossera aux travaux menés en\r\n\r\npsycholinguistique de la LSF et en TAL. Il sera centré sur les unités\r\n\r\nadverbiales temporelles.\r\n\r\n\r\n\r\nLes outils d\'évaluation de la LSF sont absents des terrains éducatifs et\r\n\r\northophoniques (Bogliotti C., Puissant-Schontz, L. et Heouaine, S.,\r\n\r\n(2013) ; Cristini, M & Bogliotti C., 2015). En effet, les recherches\r\n\r\nlinguistiques sur la LSF sont relativement récentes et les rares\r\n\r\ndescriptions linguistiques et psycholinguistiques ne permettaient pas\r\n\r\nd\'envisager de développer de tels outils. C\'est donc à partir de ces\r\n\r\nmodélisations proposées par Battistelli (2008) et Filhol (2012) que nous\r\n\r\nallons élaborer cet outil visant à développer les compétences en\r\n\r\ntemporalité linguistique, et ce, pour les deux langues utilisées par les\r\n\r\nenfants sourds. Cet outil d\'entraînement serait proposé sous la forme\r\n\r\nd\'une application à télécharger. Il seraconstitué de plusieurs modules :\r\n\r\nun module « temporalité en LSF », un module « temporalité en français\r\n\r\nécrit » et un module « français écrit vers LSF » et « LSF vers français\r\n\r\nécrit ».\r\n\r\n\r\n\r\nMots-clés : LSF, Français écrit, Traitement automatique des langues\r\n\r\n(TAL), temporalité linguistique\r\n\r\n\r\n\r\n--------------\r\n\r\nDescription du poste\r\n\r\n---------------\r\n\r\n\r\n\r\nLe stage prendra part au développement du 3ème module, celui visant à\r\n\r\nassurer la traduction LSF-français écrit (et inversement). Il sera\r\n\r\ncentré sur les marques temporelles du type des adverbiaux temporels et\r\n\r\nse déroulera en deux phases :\r\n\r\n\r\n\r\n1) Une phase de modélisation linguistique et formelle à partir du sous\r\n\r\nensemble seulement d\'expressions d\'expressions temporelles adverbiales\r\n\r\nconsidéré dans (Filhol 2012, 2014). Il s\'agira d\'établir les règles de\r\n\r\npassage avec le formalisme de (Battistelli et al. 2008) (Teissèdre\r\n\r\n2012).\r\n\r\n\r\n\r\n2) Lister les manques à combler côté description formelle de la LSF et\r\n\r\ncompléter le passage LSF-français écrit en étendant le sous ensemble\r\n\r\nconsidéré à d\'autres expressions temporelles adverbiales et en incluant\r\n\r\négalement certains connecteurs.\r\n\r\n\r\n\r\nEn fonction des avancées au LIMSI de projets parallèles permettant la\r\n\r\nsynthèse (génération) de ces expressions, on pourra tester les\r\n\r\nexpressions produites avec des avatars comme support d\'animation.\r\n\r\n\r\n\r\n---------------\r\n\r\nProfil souhaité\r\n\r\n---------------\r\n\r\n\r\n\r\n- Formation en cours : Master 1 ou2 en Linguistique ou linguistique\r\n\r\n  informatique.\r\n\r\n\r\n\r\n- Curiosité et capacité d\'explorer de nouveaux domaines en linguistique.\r\n\r\n\r\n\r\n- Des connaissances en TAL seront un plus, mais ne sont aucunement\r\n\r\n  prérequises. Un soutien sera assuré par les encadrants an cas\r\n\r\n  d\'absence de connaissances en TAL. Du reste, le sujet sera adapté en\r\n\r\n  fonction du niveau et des types de compétences en TAL du (de la)\r\n\r\n  candidat(e).\r\n\r\n\r\n\r\n- La maîtrise de la LSF est vivement souhaitée mais ne sera pas source\r\n\r\n  de sélection (un cours intensif de LSF aura lieu pendant le stage)\r\n\r\n\r\n\r\n-----------------\r\n\r\nConditions\r\n\r\n-----------------\r\n\r\n\r\n\r\nContrat : stage conventionné 4 à 6 mois rémunéré\r\n\r\n\r\n\r\nDébut : février 2018\r\n\r\n\r\n\r\nLieu : laboratoire MoDyCo ou laboratoire LIMSI\r\n\r\n\r\n\r\nEncadrants : Delphine Battistelli (MoDyCo), Caroline Bogliotti (MoDyCo),\r\n\r\nMichael Filhol (LIMSI)\r\n\r\n\r\n\r\nMerci d\'envoyer votre candidature aux trois adresses suivantes :\r\n\r\n\r\n\r\ndelphine.battistelli@parisnanterre.fr \r\n\r\n\r\n\r\ncaroline.bogliotti@parisnanterre.fr\r\n\r\n\r\n\r\nmichael.filhol@limsi.fr\r\n\r\n\r\n\r\nDocuments souhaités : CV, lettre de motivation, relevés de notes M1 et\r\n\r\nM2.\r\n\r\n\r\n\r\n-----------------\r\n\r\nBibliographie\r\n\r\n-----------------\r\n\r\n\r\n\r\nBattistelli D., Couto, J., Minel, J.L., Schwer S. (2008) Representing\r\n\r\nand visualizing calendar expressions in texts, in Actes STEP\'08\r\n\r\n(Symposium on Semantics in Systems for Text Processing), 22-24 septembre\r\n\r\n2008, Venise.\r\n\r\n\r\n\r\nBogliotti C., Puissant-Schontz, L. & Heouaine S. (2013) Assessing\r\n\r\nmorphosyntactic skills in French Sign Language , TISLR11 Theoretical\r\n\r\nIssues in Sign Language Research, 10-13 juillet 2013\r\n\r\n\r\n\r\nCristini M. & Bogliotti, C. (2015) The phonology of French Sign Language\r\n\r\n(LSF) : non-sign repetition and discrimination tests, ICSLA15,\r\n\r\nAmsterdam, 1-3 juillet 2015\r\n\r\n\r\n\r\nFilhol, M., Hadjadj, M.N., Choisier A. (2014), Non-manual features: the\r\n\r\nright to indifference, Representation and Processing of Sign Languages:\r\n\r\nBeyond the manual channel, Language resource and evaluation conference\r\n\r\n(LREC), Iceland.\r\n\r\n\r\n\r\nTeissèdre,C(2012)Analyse sémantique automatique des adverbiaux de\r\n\r\nlocalisation temporelle : application à la recherche d\'information et à\r\n\r\nl\'acquisition des connaissances, thèse de doctorat, Université\r\n\r\nParis-Ouest Nanterre La Défense.'),
(478, '2018-02-19', 'Advanced Decision', 'Paris', 'Proposition de stage M1-M2 en fouille d\'opinion\r\n\r\n\r\n\r\nLa société Advanced Decision est engagée dans la réalisation d\'un\r\n\r\nservice de recommandation de produits touristiques « sur mesure ». La\r\n\r\nrecommandation visée sera fondée sur une appréhension fine des désirs et\r\n\r\ndes expériences associés à un produit touristique. Pour atteindre cette\r\n\r\nfinesse, seront notamment exploités des avis d\'utilisateurs postés sur\r\n\r\ndes sites dédiés sous la forme de textes. L\'analyse de ces textes doit\r\n\r\nfaire apparaître les opinions associées à certains aspects du produit\r\n\r\ntouristique évoqué (par exemple, pour un restaurant : la cuisine était\r\n\r\nbonne mais le service laissait à désirer). Un premier prototype\r\n\r\ndéveloppé par apprentissage automatique à partir de textes annotés\r\n\r\npermet d\'ors et déjà de repérer les aspects pertinents du produit\r\n\r\n(cuisine, service...) et de qualifier leur polarité (plus ou moins\r\n\r\npositive ou négative). L\'objet du stage est d\'améliorer cette dernière\r\n\r\nfonctionnalité en tenant compte notamment de la structure syntaxique des\r\n\r\ntextes analysés.\r\n\r\n\r\n\r\ncompétences requises :\r\n\r\n\r\n\r\n- niveau M1 ou M2 en informatique ou en Traitement Automatique des\r\n\r\nLangues (TAL)\r\n\r\n\r\n\r\n- maîtrise d\'au moins un langage de programmation (de préférence Python,\r\n\r\nC++, Java)\r\n\r\n\r\n\r\n- connaissances en TAL (analyse syntaxique), en apprentissage\r\n\r\nautomatique (CRF, réseaux neuronaux), en fouille de textes et fouille\r\n\r\nd\'opinion\r\n\r\n\r\n\r\nconditions :\r\n\r\n\r\n\r\nLe stage peut durer de 4 à 6 mois et démarrer dès que possible. Il sera\r\n\r\nrémunéré au tarif en vigueur. Possibilité de continuation en thèse avec\r\n\r\nun contrat Cifre.\r\n\r\n\r\n\r\nLes locaux de la société sont situés à Paris.\r\n\r\n\r\n\r\nenvoyer CV et lettre de motivation à stage@advanceddecision.fr et à\r\n\r\nisabelle.tellier@sorbonne-nouvelle.fr'),
(479, '2018-02-19', 'Fortia', 'Paris', 'Dans le cadre d\'un projet de deep learning lié au NLP/TAL au sein de\r\n\r\nnotre pôle R&D, nous recherchons 2 stagiaires suffisamment à l\'aise,\r\n\r\nl\"un en anglais, l\'autre en allemand, pour enrichir nos bases de données\r\n\r\nnécessaires à nos travaux.\r\n\r\n\r\n\r\n*Voici le descriptif du poste. *\r\n\r\n\r\n\r\nDans le cadre d\'un travail de recherche informatique, nous recherchons 2\r\n\r\nstagiaires : l\"un en analyse de documents en Allemand, l\'autre en\r\n\r\nanglais. Votre mission sera de lire, analyser, recenser et\r\n\r\ncatégoriser/tagger les éléments textuels les plus appropriés afin de\r\n\r\nconstituer et enrichir, in fine, notre base de données informatiques.\r\n\r\n\r\n\r\nVous aiderez ainsi notre équipe d\'experts scientifiques (data\r\n\r\nscientists) dans leurs travaux de recherche liée à l\'intelligence\r\n\r\nartificielle et notamment au TAL/NLP (natural language processing).\r\n\r\n\r\n\r\nVous serez au coeur d\'un sujet d\'une très grande innovation.\r\n\r\n\r\n\r\nFortia, est une prometteuse start up de 45 salariés, en pleine\r\n\r\ncroissance, qui compte déjà parmi ses clients des grands comptes tels la\r\n\r\nBNP Paribas Securities Services ou Swiss life.\r\n\r\nD\'après un récent classement, nous figurons au top 100 des Regtechs à\r\n\r\nsuivre en 2018.\r\n\r\n\r\n\r\nRejoindre Fortia Financial Solutions c\'est rejoindre une équipe jeune,\r\n\r\nambitieuse et dynamique, bénéficiant d\'une ambiance start-up et offrant\r\n\r\nses solutions aux grands noms du milieu financier en France comme à\r\n\r\nl\'international.\r\n\r\n\r\n\r\n\r\n\r\nProfil\r\n\r\n\r\n\r\nEtudiant (bac + 3 à 5) en langue étrangère appliquée allemande ou\r\n\r\nanglais (LEA, LCCE ou équivalent) ou linguistique. Vous vous\r\n\r\ncaractérisez comme quelqu\'un de très à l\'aise en allemand ou en anglais.\r\n\r\n\r\n\r\nVous êtes rigoureux(se), méthodique et appliqué(e).\r\n\r\n\r\n\r\n\r\n\r\nIl s\'agit d\'un stage entre 4 à 6 mois, rémunéré 600 euros + tickets\r\n\r\nrestaurants\r\n\r\n\r\n\r\nLe stage se déroule au 17 avenue George V, 75008 Paris.\r\n\r\n\r\n\r\nSi vous êtes intéressé(e), merci d\'envoyer vos candidatures à\r\n\r\nsarah.guighui@fortia.fr'),
(480, '2018-02-19', 'ERTIM', 'Paris', 'Extraction de concepts par AFC dans des corpus\r\n\r\nStage recherche proposé par le laboratoire ERTIM (Inalco)\r\n\r\n\r\n\r\nContexte\r\n\r\n\r\n\r\nL\'analyse formelle de concepts (AFC) (Wille, 1982) est une méthode\r\n\r\nd\'extraction de connaissances à partir de données, qui s\'appuie sur le\r\n\r\nlien entre les objets et leurs attributs. Celle-ci extrait des\r\n\r\n\"concepts\", liés les uns aux autres par une relation d\'ordre\r\n\r\npartiel. Cette méthode a l\'avantage de proposer un compromis entre\r\n\r\nl\'énumération exhaustive de nombreuses combinaisons d\'attributs\r\n\r\npossibles et une sélection trop naïve de ces attributs, isolément et/ou\r\n\r\npar régression.\r\n\r\n\r\n\r\nPlusieurs travaux ont déjà abordé ce sujet, dont (Ilieva, Ormandjieva,\r\n\r\n2007), (Falk, Gardent, 2010), (Kaytoue, Kuznetsov, Napoli, 2011).\r\n\r\n\r\n\r\nLe stage proposé vise à explorer les utilisations possibles de l\'AFC\r\n\r\npour l\'exploration de données textuelles dans les corpus. Il comportera\r\n\r\nl\'implémentation ou l\'utilisation de logiciel pour conduire l\'AFC, son\r\n\r\nexécution sur des corpus, la comparaison qualitative et quantitative\r\n\r\navec des algorithmes traditionnels en extraction d\'information (TF.IDF)\r\n\r\net des algorithmes plus récents de construction d\'espaces par méthodes\r\n\r\ndistributionnelles (embeddgins Word2Vec / FastText).\r\n\r\n\r\n\r\nObjectifs principaux\r\n\r\n\r\n\r\n- État de l\'art sur l\'adaptation de la FCA aux données textuelles\r\n\r\n- Formalisation d\'une méthode adéquate pour la recherche d\'informations\r\n\r\n- Implémentation de l\'algorithme pour extraire les concepts\r\n\r\n- Expérimentations sur des jeux de données\r\n\r\n- Évaluation de la couverture, de la complétude, de la précision des\r\n\r\nconcepts\r\n\r\n- Comparaison avec des méthodes traditionnelles ou plus récentes\r\n\r\n- Utilisation de l\'algorithme pour l\'exploration de corpus\r\n\r\n\r\n\r\nProfil recherché\r\n\r\n\r\n\r\n- M2 informatique et TAL\r\n\r\n- Programmation en python\r\n\r\n- Bonne compréhension des méthodes de fouille de données\r\n\r\n- Motivation et intérêt pour les problématiques de recherche\r\n\r\n\r\n\r\n*Précisions sur l\'offre*\r\n\r\n\r\n\r\n- Durée du stage : 5 mois à temps plein\r\n\r\n- Date de début : mai 2018\r\n\r\n- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)\r\n\r\n- Lieu : Inalco, 2 rue de Lille, 75007 Paris\r\n\r\n\r\n\r\nPour candidater, envoyez votre CV et faites part de vos motivations à\r\n\r\nDamien Nouvel (damien.nouvel@inalco.fr).\r\n\r\n\r\n\r\n\r\n\r\nRéférences \r\n\r\n- Ingrid Falk, Claire Gardent (2010). Bootstrapping a Classification of\r\n\r\nFrench Verbs Using Formal Concept Analysis.. Interdisciplinary\r\n\r\nWorkshop on Verbs.\r\n\r\n- Magda G. Ilieva, Olga Ormandjieva. (2007). Natural Language Processing\r\n\r\nand Formal Concept Analysis Technologies for Automatic Building of\r\n\r\nDomain Model.\r\n\r\n- Mehdi Kaytoue, Sergei O. Kuznetsov, Amedeo Napoli (2011), Sébastien\r\n\r\nDuplessis. Mining gene expression data with pattern structures in\r\n\r\nformal concept analysis. Information Sciences, 181-10.\r\n\r\n- Wille, R. (1982) Restructuring lattice theory: an approach based on\r\n\r\nhierarchies of concepts.'),
(481, '2018-03-11', 'Bertin IT', 'Montigny le Bretonneux', 'Société du Groupe CNIM, Bertin IT est éditeur et intégrateur de\r\nsolutions logicielles pour la Cybersécurité, l\'intelligence numérique et\r\nle traitement automatique de la parole.\r\n\r\nEngagée dans la recherche et l\'innovation dans les Technologies de\r\nl\'Information, Bertin IT s\'appuie sur une expertise technique reconnue\r\net un savoir-faire industriel développé au travers de projets civils et\r\nde défense de dimension européenne ou mondiale.\r\n\r\nBertin IT est également pionnière de l\'Intelligence Artificielle et du \r\nmachine learning, développe des technologies de transcription de la parole \r\nà l\'état d\'art.\r\n\r\nDans le cadre du développement de notre système de reconnaissance vocale\r\nen langue Japonaise, nous recherchons un(e) Stagiaire Ingénieur\r\nLinguiste en Japonais (h/f).\r\n\r\nVotre Mission : \r\n\r\nRattaché (e) au chef de projet, votre mission consistera à :\r\n\r\n- Travailler sur la normalisation du texte (segmentation en phrases et\r\n  en mots, adaptation des outils existants pour la conversion des\r\n  chiffres en lettres, traitement des mots étrangers...)\r\n\r\n- Construire un lexique : à partir du texte normalisé, définition du\r\n  lexique pour l\'ensemble du système de transcription japonais.\r\n\r\n- Construire un dictionnaire phonétique pour l\'ensemble des mots du\r\n  lexique (évaluation et adaptation des phonétiseurs automatiques\r\n  existants.\r\n\r\nProfil recherché\r\nVous êtes en bac+4/5 dans le domaine du Traitement Automatique de la\r\nLangue. Vous maîtrisez le japonais.\r\nStage basé à Montigny le Bretonneux (78).\r\n\r\nSi cette offre vous intéresse, merci de transmettre votre cv+ lettre de\r\nmotivation à : elisabeth.rayemamby@bertin.fr'),
(482, '2018-03-19', 'Calea Solutions', 'Marseille', 'STAGE DATA SCIENTIST H/F \r\n\r\nQUI SOMMES-NOUS ? \r\n\r\nCALEA SOLUTIONS est une Startup fondée en 2014 par une équipe issue du\r\nmonde du jeu vidéo. Elle est basée à Marseille et compte actuellement 20\r\ncollaborateurs.\r\nNous avons créé l\'application Android, MOOD MESSENGER\r\n(https://play.google.com/store/apps/details?id=com.calea.echo [1]), une\r\nmessagerie combinant l\'universalité du SMS avec des contenus innovants\r\ncomme le SmartEmoji ou des services enrichis intégrés à la conversation\r\n(restaurant, cinéma, Uber...). 1.2 Millions d\'utilisateurs utilisent\r\nchaque jour notre application dans 215 pays du monde. Elle fait partie\r\ndes applications les mieux notées du Google Play Store avec 4.5 étoiles.\r\n\r\nForts d\'une équipe en Data Science, nous utilisons le Machine Learning,\r\ndont le Deep Learning, dans plusieurs domaines dont la prédiction et la\r\nproposition d\'émojis (objet d\'une thèse de doctorat en cours),\r\nl\'amélioration de la connaissance de notre base utilisateur pour\r\nidentifier les fonctionnalités préférées ou l\'anticipation du churn.\r\n\r\nMISSIONS : \r\n\r\nVotre mission consistera à étudier, developper, tester et industrialiser\r\ndes algorithmes de Machine Learning pour favoriser la rétention et\r\nl\'usage de l\'application.\r\nPar exemple, il s\'agira de : \r\n\r\n* trouver des patterns dans les comportements de nos utilisateurs\r\n  annonçant un churn imminent via un apprentissage supervisé\r\n* Proposer une segmentation de notre base utilisateur pour personnaliser\r\n  nos interactions (pushes, fonctionnalités mises en avant) via de\r\n  l\'apprentissage non supervisé\r\n\r\nTECHNOS \r\n\r\n* Machine Learning (Apprentissage Supervisé, non Supervisé, voire par\r\n  renforcement)\r\n* Deep Learning (Data dans le Cloud Google : Tensorflow, Google Cloud\r\n  ML)\r\n* Statistiques, Data Mining, Data Engineering\r\n* données structurées et non structurées\r\n* Langages et librairies : python ou Java, pandas, sk-learn, TensorFlow,\r\n  SQL, BIGQUERY\r\n\r\nVOUS : \r\n\r\n* un Etudiant préparant un diplôme de niveau BAC+5, Ecole d\'ingénieurs\r\n  ou Master Universitaire.\r\n* Spécialité / Option souhaitée: Big Data  Data Mining  Machine\r\n  Learning\r\n* Soft Skills : Autonomie, sens de l\'analyse, esprit de synthèse et de\r\n  vulgarisation pour communiquer envers des Data-Scientist mais aussi\r\n  vers le Management non spécialiste\r\n\r\nCONTEXTE:  \r\n\r\n* période : 6 mois à partir de juillet 2018 \r\n* lieu : Marseille\r\n* Stage rémunéré avec possibilité d\'embauche à la fin\r\n\r\nCONTACT: \r\n\r\nFlorian FIRMIN / Data Scientist \r\nflorian@calea.io / +33 6 60 35 75 68 [2] \r\n\r\n1 place Francis Chirat [3] \r\n13002 Marseille - France [3] \r\nwww.calea.io [4] \r\n\r\nLinks:\r\n------\r\n[1] https://play.google.com/store/apps/details?id=com.calea.echo\r\n[2] tel:+33%206%2060%2035%2075%2068\r\n[3] https://maps.google.com/?q=1+place+Francis+Chirat+13002+Marseille+-+%F0%9F%87%AB%F0%9F%87%B7+France&amp;entry=gmail&amp;source=g\r\n[4] http://www.calea.io/\r\n[5] https://htmlsig.com/t/000001CS6YVT\r\n[6] https://htmlsig.com/t/000001CPCEY4\r\n[7] https://htmlsig.com/t/000001CM8HDP\r\n[8] https://htmlsig.com/t/000001CK7NPZ\r\n[9] https://htmlsig.com/t/000001CQEHZQ'),
(483, '2018-03-25', 'European Commission\'s Joint Research Centre', 'Ispra (Italie)', 'EUROPEAN COMMISSION DIRECTORATE-GENERAL HUMAN RESOURCES AND SECURITY\r\nDirectorate HR.AMC -Account management Centre\r\n\r\nHR.DDG. AMC 8 2018-IPR-I-000-9856\r\n\r\nPosition for:\r\nTrainee\r\n\r\nEntity and Sentential-level Sentiment Analysis\r\nin the News\r\n\r\n\r\nAs the science and knowledge service of the\r\nCommission, the mission of Joint Research Centre\r\nis to support EU policies with independent\r\nevidence throughout the whole policy cycle.\r\nThe JRC is located in 5 Member States (Belgium,\r\nGermany, Italy, the Netherlands and Spain).\r\n\r\n\r\nFurther information is available at: http://www.jrc.ec.europa.eu\r\n\r\n\r\nThe Joint Research Centre (JRC; http://ec.europa.eu/dgs/jrc/) is the\r\nscientific- technical arm of the European Commission. The\r\napproximately 2200 JRC employees working in Ispra are from all EU\r\ncountries and there are also some non-EU visitors.\r\n\r\nThe working environment is multilingual, multi- cultural and\r\nmulti-disciplinary. The JRC\'s Europe Media Monitor (EMM) team carries\r\nout research and development in the field of highly multilingual text\r\nmining (Language Technology; Computational Linguistics) for the\r\npurposes of media monitoring.  EMM gathers an average of 300,000\r\nonline news articles per day in over 70 languages and analyses them to\r\nhelp its large international user community understand and use this\r\nenormous amount of media information. The Europe Media Monitor EMM is\r\npublicly accessible and widely used. The EMM team has produced over\r\n200 international peer-reviewed publications. The team has also\r\nproduced and distributes a number of highly multilingual Language\r\nTechnology resources.\r\n\r\nShort description of activity:\r\n\r\nThe Text and Data Mining Unit (I3) of the European Commission\'s Joint\r\nResearch Centre (JRC) in Ispra, Italy, is looking for a trainee to\r\nsupport the JRC\'s Europe Media Monitor (EMM) team in its effort to\r\nimprove its multilingual sentiment analysis tools, especially at\r\nsentence and entity level. EMM gathers and analyses reports from\r\ntraditional and social media in dozens of languages by clustering\r\nrelated news items; categorising them; extracting information such as\r\nentities (persons, organisations, locations), events2 (who did what to\r\nwhom, where and when), quotations by and about people; identifying\r\nsentiment; as well as linking related news clusters over time and\r\nacross languages.  Methods used are mostly hybrid: machine learning\r\ntools are used to gather evidence, learn vocabulary and rules, but the\r\nresults are usually controlled and optimised through human\r\nintervention.\r\n\r\nEMM is used by European Institutions, by national authorities in EU\r\nMember States, by international organisations and by the public. The\r\npublic EMM applications NewsBrief, NewsExplorer and MedISys can be\r\naccessed freely by the general public. EMM is part of the JRC\'s\r\nCompetence Centre on Text Mining and Analysis.  As of now, the EMM\r\nteam has implemented several approaches to multilingual sentiment\r\nanalysis, for different text types (newspaper articles, microblogs,\r\nsocial media posts) and application scenarios (document level, short\r\ntexts, entity-centric).\r\n\r\nThe successful trainee will help to combine the current approaches and\r\nresources and extend them when necessary to perform multilingual\r\nentity and sentence-level sentiment analysis and evaluate the system\r\nthus obtained. The trainee is also expected to contribute to writing a\r\nscientific publication on the work carried out.\r\n\r\nQualifications:\r\n\r\nEssential:\r\n\r\n- University degree (or an almost completed degree) in computational\r\nlinguistics, computer science or related areas (the degree thesis has\r\nto be registered and the subject has to match with the project) ;\r\n\r\n- Java programming skills;\r\n\r\n- Good working knowledge of English. (B2 level)\r\n\r\nAdvantage:\r\n\r\n- Experience in methods and resources for sentiment analysis and\r\nemotion detection;\r\n\r\n- Knowledge of further foreign languages;\r\n\r\n- Good knowledge of Language Technology- related tools and methods;\r\n\r\n- Proven ability to work independently and as part of a team.\r\n\r\n\r\nIn your application, please provide clear information on your skill\r\nset, by elaborating on the above-mentioned list of requirements and by\r\nlisting your level of languages and your computer / programming\r\nskills.\r\n\r\nFor general eligibility requirements, please read the rules governing\r\nthe traineeship scheme of the JRC:\r\n\r\nhttps://ec.europa.eu/jrc/en/working-with-us/jobs/temporary-positions/jrc-trainees\r\n\r\nUnit /Directorate: I03 - Text and Data Mining Unit\r\n\r\nIndicative duration: 5 months\r\n\r\nPreferred starting date: As soon as possible\r\n\r\nDirectorate Competences\r\n\r\nJRC Site: Ispra\r\nCountry: Italy\r\n\r\nJRC contact details\r\n\r\nFor any technical problems with your application, please contact:\r\n\r\nHR-AMC8-RECRUITMENT-TOOLS-SUPPORT@ec.europa.eu\r\n\r\nApply online (Code: 2018-IPR-I-000-9856 - ISPRA)\r\n\r\nhttp://recruitment.jrc.ec.europa.eu/?type=TR&site=IPR'),
(485, '2018-03-25', 'ELDA', 'Paris', 'Nous recherchons un-e stagiaire dans le cadre d\'un projet ayant pour but\r\nl\'actualisation d\'un inventaire de ressources linguistiques pour les\r\nlangues régionales françaises, ainsi que la négociation des droits pour\r\npermettre leur partage avec la communauté des technologies de la langue.\r\n\r\nLes tâches consisteront principalement en:\r\n\r\n- La mise à jour de l\'inventaire de ressources linguistiques existant\r\n- L\'étude technique et juridique des conditions de partage actuelles de\r\n  ces ressources (analyse des formats d\'exploitation des ressources et\r\n  identification des droits d\'utilisation en coopération avec un expert\r\n  juridique en interne)\r\n- La négociation avec les fournisseurs, la définition des conditions de\r\n  réutilisation des ressources linguistiques, l\'établissement de\r\n  contrats de distribution,\r\n- La description et l\'intégration des ressources disponibles dans le\r\n  catalogue ELRA\r\n- La rédaction d\'un rapport final\r\n\r\nProfil:\r\n\r\n- Niveau master 2 traitement automatiques des langues ou domaines\r\n  assimilés\r\n- Durée : 6 mois\r\n- Aptitude à travailler tant de façon indépendante qu\'au sein d\'une\r\n  équipe\r\n- Forte aptitude rédactionnelle et analytique\r\n- Convention de stage requise\r\n\r\nToute candidature sera étudiée jusqu\'à ce que le poste soit pourvu. Le\r\nposte est basé à Paris.\r\n\r\nSalaire : en fonction des qualifications et expériences.\r\n\r\nLes candidatures doivent être adressées par courriel (lettre de\r\nmotivation et curriculum vitae) à:\r\nELDA\r\n9, rue des Cordelières\r\n75013 Paris\r\nFRANCE\r\nEmail : job@elda.org\r\n\r\nELDA, unité opérationnelle de l\'association ELRA, est chargée de\r\npromouvoir le développement de ressources linguistiques sous toutes les\r\nformes électroniques utilisables, en particulier sous la forme de corpus\r\noraux et écrits, de lexiques et de bases terminologiques. Depuis sa\r\ncréation en 1995, ELDA s\'est affirmée comme un centre unique en Europe\r\npour la distribution de ressources linguistiques, capable de répondre\r\naux divers besoins des développeurs de technologie. Ses activités se\r\ndéveloppent maintenant vers de nouveaux types de ressources\r\nlinguistiques (données de type multimodal/multimédia). Certaines\r\nressources linguistiques sont conçues au cours de projets (co-)financés\r\npar ELDA. Celles-ci sont ensuite compilées sous la forme d\'un catalogue\r\nde ressources linguistiques. ELDA est impliquée dans un certain nombre\r\nde projets européens et nationaux. ELDA s\'intéresse également aux\r\nproblèmes juridiques en rapport avec les ressources linguistiques,\r\nréalise régulièrement des études de marché sur les besoins des\r\nutilisateurs, et travaille à l\'amélioration des procédures de validation\r\ndes ressources.\r\n\r\nPour de plus amples renseignements concernant ELRA/ELDA, voir :\r\nhttp://www.elra.info ou www.elda.org'),
(486, '2018-04-21', 'INRA', 'Montpellier', 'Intitulé\r\nAnalyses bibliométrique et terminologique autour des matériaux et\r\nemballages biosourcés\r\n\r\nContexte\r\n\r\nLa littérature et les travaux de recherche récents menés dans le domaine\r\ndes matériaux et emballages bio-sourcés révèlent un foisonnement\r\nd\'acteurs venant de champs disciplinaires multiples. Il est encore\r\ndifficile de partager un vocabulaire commun dû à des représentations\r\nontologiques divergentes et à la polysémie existante, à commencer par\r\nles différents sens que prend le préfixe « bio » selon que l\'on se place\r\ndu point de vue de la ressource (bio-ressources, biomasse), du procédé\r\n(biotechnologies, bio-ingénierie, bioprocédés, bio-raffineries), du\r\nproduit (bioplastique, biomatériau, biomolécule) ou des fonctionnalités\r\npost-usage (biodégradable, bio-compostable, bio-déchets) ou encore de\r\nl\'ensemble de la chaine (bio-économie, bio-industries, bio-marchés).\r\n\r\nNous souhaitons collecter et compiler les connaissances actuelles\r\nconcernant les définitions, les normes et les acteurs qui s\'intéressent\r\naux matériaux bio-sourcés dans le but d\'améliorer notre communication\r\nscientifique et technique, grand public, nos dispositifs de veille mais\r\naussi d\'aide à la décision.\r\n\r\n\r\n\r\nDescription des missions\r\n\r\nLa/le stagiaire aura pour principale mission de réaliser une analyse\r\nbibliométrique et terminologique autour des matériaux et emballages\r\nbio-sourcés. Le projet démarrera à partir d\'entretiens et de collectes\r\nd\'information et de documents scientifiques (rapports, articles etc.)\r\nproduits au sein de l\'Inra et notamment des départements à forte\r\nactivité dans les produits bio-sourcés. Ces primo-données (Web et autres\r\nsources) feront l\'objet d\'une analyse lexicale et sémantique basée\r\nnotamment sur une extraction terminologique et bibliométrique en\r\nutilisant les outils exploités et le savoir-faire développé au sein de\r\nl\'IST/Inra. Le vocabulaire identifié viendra compléter des listes déjà\r\nétablies par des scientifiques et le tout sera organisé sous la forme\r\nd\'un lexique ou d\'un thésaurus proposant des définitions. Une fois\r\npublié selon les standards du Web sémantique notamment, cette ressource\r\npourra servir de référence dans le domaine.\r\n\r\nA cette fin, la/le stagiaire assurera la mobilisation d\'un corpus coeur\r\nd\'une 40aine de chercheur localisés sur une 10aine de villes françaises,\r\nafin de réaliser une analyse terminologique (Français/ Anglais)  issue\r\nde la consultation. Ceci constituera un préambule à des requêtes sur le\r\nWOS afin de compléter le corpus qui fera l\'objet d\'une analyse\r\nbibliométrique. Elle/il mettra en place la solution logicielle\r\npermettant aux scientifiques du département CEPIA d\'accéder et de\r\nconsulter le corpus documentaire et les résultats de l\'analyse\r\nbibliométrique. Pour toutes ces tâches, les moyens techniques et\r\nl\'accompagnement nécessaires seront mis à disposition par la DIST/Inra\r\ndans le cadre de son offre de services aux chercheurs.\r\n\r\nEnfin, le stagiaire pourra étudier les apports potentiels du vocabulaire\r\ndans le cadre d\'une veille scientifique et/ou réglementaire.\r\n\r\nLivrables\r\n\r\n- Une analyse bibliométrique et une base documentaire sur les produits\r\n  biosourcés (matériaux et emballages biosourcés)\r\n\r\n- Un vocabulaire (thésaurus ou lexique) des produits biosourcés qui\r\n  pourra être publié\r\n\r\nProfil requis\r\n\r\n- Étudiant en master 1 ou master 2 ou élève-ingénieur en 4ème ou 5ème\r\n  année dans les domaines Documentaires/bibliométriques, Linguistique,\r\n  Traitement Automatique des Langues, Analyse documentaire, ingénierie\r\n  des connaissances et sciences. Des connaissances sur les matériaux\r\n  issus de la biomasse seront appréciées.\r\n\r\n- Capacités à travailler en autonomie et à solliciter les personnes\r\n  ressources nécessaires à la réalisation du projet. Motivé,\r\n  travailleur, rigoureux et ouvert d\'esprit\r\n\r\n- Anglais lu et parlé\r\n\r\nConditions du stage\r\nDurée\r\n\r\n6 mois\r\n\r\nLieu\r\nGratification\r\n\r\nUMR IATE, Montpellier\r\nEnviron 550 ¤ net/mois\r\n\r\n\r\nModalités de candidature\r\nLes candidats doivent transmettre un CV avant le 30 juin 2018, les dates\r\nde démarrage et de fin seront adaptées 2018 à la situation du\r\ncandidat.e.\r\n\r\n  * Nathalie GONTARD, INRA UMR IATE, Montpellier\r\n    nathalie.gontard@inra.fr\r\n  * Patrice BUCHE, INRA UMR IATE, Montpellier patrice.buche@inra.fr\r\n  * Sophie AUBIN,  DIST, Versailles  sophie.aubin@inra.fr\r\n  * Johnny BEAUGRAND, INRA Unité de Recherche BIA, Nantes\r\n    johnny.beaugrand@reims.inra.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(487, '2018-04-25', 'Digimind', 'Paris', 'Stage - Linguistique Traitement Automatique des Langues\r\n\r\nParis, Île-de-France, France\r\n\r\nQUI SOMMES-NOUS ?\r\n\r\nDigimind est leader des logiciels SaaS de Social Media Analytics /\r\nMarket Intelligence permettant aux grandes marques de surveiller leur\r\nréputation sur Internet et leur environnement concurrentiel.\r\n\r\nNous travaillons avec 200+ des plus grandes marques telles que Lexus,\r\nDeloitte, BBDO et General Electrics.\r\n\r\nAvec plus d\'une centaine de collaborateurs à travers le monde,\r\nDigimind est implantée à Paris, Grenoble, New-York, Singapour et\r\nRabat.\r\n\r\nSi vous aimez toucher à tout, êtes curieux et attiré(e) par l\'aventure\r\n\"PME en pleine croissance\",\r\n\r\nNe cherchez plus, ce stage est fait pour vous !\r\n\r\nLA MISSION :\r\n\r\nDans le cadre de notre activité, nous recherchons un stagiaire TAL\r\npouvant participer à tout ou partie des missions suivantes :\r\n\r\n- Documentation des algorithmes existants de traitement du langage\r\n    dans nos solutions logicielles, dans une version vulgarisée pour\r\n    nos équipes conseil et support. Pour cette mission, vous jouerez\r\n    le rôle d\'interface entre nos équipes techniques et business.\r\n\r\n- Analyse de l\'état de l\'art de nos ressources sémantiques intégrées\r\n  dans nos algorithmes et définitions de pistes d\'optimisation de nos\r\n  dictionnaires et règles sémantiques, notamment pour nos détections\r\n  automatiques de genre, profession, âge etc.\r\n\r\nCette mission sera réalisée en plusieurs langues (a minima français,\r\nanglais).\r\n\r\n- Analyse et suivi des impacts des optimisations réalisées sur les\r\n  résultats obtenus dans nos solutions logicielles.\r\n\r\n- Vous serez rattaché à notre chef de produit et serez en contact\r\n  opérationnel quotidien avec nos équipes développement, produit et\r\n  conseil.\r\n\r\nQUI RECHERCHONS NOUS ?\r\n\r\n- Très bon niveau d\'anglais et de français\r\n\r\n- Idéalement de bonnes notions dans d\'autres langues\r\n\r\n- Jeune spécialiste des problématiques de traitement automatique de la\r\n  langue et de l\'ingénierie multilingue sans être nécessairement un\r\n  ingénieur\r\n\r\n- Formation supérieur de linguiste\r\n\r\n- Une expérience préalable dans le domaine du traitement automatisé de\r\n  la langue est un atout non négligeable\r\n\r\n- Enthousiaste, dynamique et rigoureux(se)\r\n\r\nQUE PROPOSONS-NOUS ?\r\n\r\nUne opportunité unique de participer à la croissance d\'une entreprise\r\ninternationale sur un secteur d\'avenir.\r\n\r\n- Un environnement de travail moderne et agréable au coeur de Paris\r\n- Une atmosphère agréable avec les incontournables parties de babyfoot\r\n  et de billard\r\n- De nombreux avantages: tickets restaurant, remboursement des frais\r\n  de transport\r\n- Corbeille de fruits à disposition\r\n\r\nLieu : Paris\r\n\r\nStatut : Stage\r\n\r\nRémunération selon profil\r\n\r\n\r\nPostuler en ligne : http://digimind.recruiterbox.com/jobs/fk0fls1?apply=true'),
(488, '2018-05-23', 'Wiidii', 'Bordeaux', 'Stagiaire Linguiste Informaticien H/F\r\n\r\nDébut : Juin                                                  \r\nDurée : 2 mois\r\nSalaire : Gratification conventionnelle\r\nLieu : 56 rue de Tivoli - 33000 BORDEAUX\r\n\r\nQui est Wiidii ?\r\n\r\nWiidii est une jeune start-up bordelaise créée en 2014 qui développe\r\net commercialise en B2B une application d\'assistant personnel\r\ncombinant l\'intelligence artificielle et le savoir-faire humain : Un\r\nassistant personnel propose à ses clients de gérer et simplifier leur\r\nquotidien. L\'entreprise connaît un fort développement depuis 2016.\r\n\r\nMissions détaillées\r\n\r\nAu sein d\'une équipe d\'une dizaine de personnes, et encadré par la\r\nchef de projet, nous proposons un stage de linguiste informaticien,\r\nd\'une durée de 2 mois à partir de juin. Vos missions s\'articuleront\r\nautour de deux axes :\r\n\r\nConception d\'une base de données\r\n\r\n     - Alimenter la base de données (BDD) du nouveau moteur de\r\n         l\'application : recherche de sources de BDD, et au-delà des\r\n         données pures, il s\'agit aussi d\'élaborer une BDD dynamique\r\n         autour du langage sur le plan sémantique, pragmatique et\r\n         syntaxique.\r\n\r\n     -   Architecturer, diversifier et construire la BDD.\r\n\r\n     -   Annoter la BDD en vue d\'un enrichissement lexical.\r\n\r\nSuivi client\r\n\r\n    - Prendre en charge les demandes des clients en français et en\r\n         anglais, via l\'application Wiidii : comprendre la demande du\r\n         client afin de lui apporter la réponse la plus pertinente\r\n         possible.\r\n\r\n    -    Prendre en charge l\'envoi de notifications aux clients.\r\n\r\n    -    Détecter et remonter les incidents.\r\n\r\n    - Analyser l\'activité client : profil des clients, nature des\r\n         demandes et en sortir des données statistiques.\r\n\r\nProfil et Compétences\r\n\r\nWiidii cherche un(e) candidat(e), maitrisant les bases de la\r\nlinguistique avec un fort attrait pour la sémantique. La maîtrise des\r\nrègles de la langue française est absolument indispensable et\r\nl\'anglais/espagnol/allemand écrit est un vrai plus. Le langage et sa\r\nstructuration vous passionne, vous vous intéressez à l\'évolution des\r\nnouvelles technologies appliquées au langage.\r\n\r\nRigueur, organisation, innovation, implication et adaptation sont les\r\nqualités requises pour occuper ces missions.\r\n\r\nÊtre à l\'aise en informatique et avec les outils web est un atout\r\nsupplémentaire\r\n\r\nDe formation en sciences du langage, traitement automatique des\r\nlangues (TAL) ou en ingénierie des langues.\r\n\r\nDe plus l\'esprit start-up et les nouvelles technologies vous attirent\r\nalors candidatez !\r\n\r\n                  \r\nAvantages\r\n      Tickets restaurant, participation au titre de transport\r\n\r\nTemps de travail : \r\n      35 heures/semaine.\r\n      Horaires variables du lundi au vendredi de 8h 19h.\r\n\r\nPersonne à contacter\r\n\r\nEnvoyez CV et lettre de motivation en français par mail à :\r\nrecrutement@wiidii.com'),
(489, '2018-06-06', 'Engie', 'Saint-Denis', 'Offre de stage R&D chez ENGIE LAB en Web Sémantique\r\n\r\nContexte et principales missions : \r\n\r\nVous intégrez une équipe de recherche et de développement d\'ENGIE, le\r\nLab CsAi (Computer Science and Artificial Intelligence), où vous\r\nparticipez à la réalisation de solutions autour des technologies du web\r\nsémantique.\r\n\r\nL\'objectif de ce stage est de faciliter l\'intégration sémantique (accès,\r\npartage et alignement) des données structurées hétérogènes non seulement\r\nà l\'aide des ontologies créées selon des besoins souhaités et/ou des\r\nontologies de domaine existantes mais aussi avec l\'alignement aux\r\ndifférentes données du Linked Data à savoir DBpedia, Data.gouv,\r\nWikidata, Geonames, etc.\r\n\r\nVous contribuez à mettre en place un outil permettant d\'apprendre à lier\r\net à transformer les données structurées (CSV, JSON, XML, HTML, etc.)\r\nen se basant sur les concepts d\'ontologies et les relations entre eux,\r\net de créer des nouveaux concepts du domaine. Ces ontologies sont\r\ndéveloppées pour différents domaines d\'application, gaz, électricité,\r\nbâtiments, eau, IoT, etc. Cet outil vise aussi à faciliter\r\nl\'enrichissement sémantique du modèle réalisé avec d\'autres bases de\r\nconnaissances.\r\n\r\nTâches : \r\n\r\n- Revue de la littérature scientifique et analyse et veille\r\n  technologique des développements existants liés aux systèmes\r\n  d\'apprentissage sémantique des données structurées [1,2]\r\n- Développer et implémenter des algorithmes pour un nouveau système\r\n  sémantique robuste à transformer et lier les différentes données\r\n  structurées issues des cas d\'usage métiers ENGIE\r\n- Construire du code réutilisable et des bibliothèques pour une\r\n  utilisation future\r\n- Rédiger une documentation technique selon le besoin\r\n- Déployer une application répondant aux enjeux scientifiques et\r\n  métiers.\r\n- Rédaction d\'articles scientifiques.\r\n\r\nFormation : \r\n\r\nNiveau : M2, école ingénieur en informatique, vous avez un profil\r\ntechnique en développement logiciel et une connaissance des technologies\r\nde web sémantique.\r\n\r\nCompétences : \r\n\r\n- Vous maîtrisez les langages de programmation : Java, Python, script\r\n  shell, des connaissances en IHM seraient un plus.\r\n- Connaissances en technologies du web sémantique : RDF, OWL, SPARQL,\r\n  etc.\r\n- Connaissances en apprentissage et alignement sémantique.\r\n- Vous avez une forte capacité d\'empathie et le souhait de développer\r\n  vos connaissances sur les problématiques métiers, liées au domaine de\r\n  l\'énergie.\r\n- Vous avez idéalement une connaissance en open data. \r\n- Bon niveau d\'anglais.\r\n\r\nDétails du poste : \r\n\r\n- Le stage se déroulera au CRIGEN, le centre de R&D France d\'ENGIE, est\r\n  situé à Saint Denis.\r\n- Durée : 6 mois à temps plein\r\n- Rémunération : ce stage fait l\'objet d\'une rémunération, variable en\r\n  fonction de l\'école et diplôme préparé\r\n- Début du contrat : dès que possible\r\n- Contact :  philippe.calvez1@engie.com et\r\n  sarra.ben-abbes@external.engie.com (CV + lettre de motivation)\r\n\r\n[1] Mohsen Taheriyan, Craig A. Knoblock, Pedro A. Szekely, José Luis\r\nAmbite: Learning the semantics of structured data sources. J. Web\r\nSem. 37-38: 152-169 (2016)\r\n\r\n[2] Mohsen Taheriyan, Craig A. Knoblock, Pedro A. Szekely, José Luis\r\nAmbite: Leveraging Linked Data to Discover Semantic Relations Within\r\nData Sources. International Semantic Web Conference (2016)'),
(490, '2018-07-09', 'Consortium CORLI', 'Paris', 'Job : Stage Consortium CORLI (CORpus, Langues et Interactions), Groupe\r\nde Travail (GT3) Corpus multilingues et plurilingues\r\n\r\nDate de début : 1 septembre 2018\r\n\r\nPrésentation de l\'axe :\r\n\r\nLe Groupe de Travail (GT3) Corpus multilingues et plurilingues du\r\nConsortium CORLI recherche un-e stagiaire pour une durée de 3 mois,\r\nrégime d\'indemnisation forfaitaire (env. 600 euros/mois).\r\n\r\nLe GT3 Corpus multilingues et plurilingues a été officiellement créé en\r\n2017. Dirigé par Evangelia Adamou (CNRS, Lacito), Natalie Kübler (Paris\r\nDiderot, CLILLAC-ARP), Maria Zimina (Paris Diderot, CLILLAC-ARP) et\r\nAntonio Balvet (Université de Lille, STL), le Groupe a organisé en\r\nseptembre 2017 une journée d\'études sur la thématique du\r\n\"code-switching\" (annotations, traitements automatiques). Une autre\r\njournée d\'études est prévue fin novembre 2018 sur la thématique\r\n\"annotations, analyse cross-lingue et traitement automatique des corpus\r\nmultilingues et plurilingues parallèles et comparables\".\r\n\r\nLes missions de stage sont les suivantes :\r\n\r\n- recensement des corpus multilingues et plurilingues\r\n- recensement des logiciels pour le traitement des corpus multilingues\r\n  et l\'analyse cross-lingue\r\n- recensement des pratiques et guides d\'annotation de corpus\r\n  multilingues et plurilingues\r\n- rédaction de fiches de présentation des différentes ressources, en\r\n  français et en anglais\r\n\r\n- gestion d\'un wiki dédié au GT3 du Consortium CORLI : structuration des\r\n  informations collectées, présentation sous différents formats (texte,\r\n  tableaux de synthèse, base de données)\r\n\r\nLe profil recherché pour ces missions est le suivant :\r\n\r\nétudiant-e de niveau Master (M1 ou M2) de linguistique générale,\r\ntraduction outillée, linguistique de corpus, TAL, traduction spécialisée\r\noutillée, communication, rédaction technique. Une bonne connaissance de\r\nl\'anglais est requise, ainsi qu\'un intérêt pour la linguistique outillée\r\net les corpus.\r\n\r\nLieu de réalisation des missions : Université Paris Diderot Le suivi du\r\nstage sera assuré par Natalie Kübler, Maria Zimina et Antonio Balvet\r\n\r\nLes candidats sont invités à se manifester en contactant directement les\r\ncoordinateurs du Groupe :\r\n\r\nNatalie Kübler : nkubler@eila.univ-paris-diderot.fr\r\nMaria Zimina : mzimina@eila.univ-paris-diderot.fr\r\nAntonio Balvet : antonio.balvet@univ-lille.fr\r\nEvangelia Adamou : evangelia.adamou@cnrs.fr'),
(491, '2018-07-13', 'CLILLAC-ARP', 'Paris', 'TITRE\r\nType de poste: Stage/CDD\r\nDurée du poste : 3 mois\r\nDate de début : 1 octobre 2018\r\nVille: Paris\r\n\r\nLaboratoire d\'accueil : CLILLAC-ARP (Centre de Linguistique Inter-langues, de\r\nLexicologie, de Linguistique Anglaise et de Corpus-Atelier de Recherche sur la\r\nParole), Université Paris Diderot\r\nCo-encadré par : LIPN (Laboratoire Informatique de Paris Nord)\r\n\r\nAdresse: 8 place Paul Ricoeur, 75013 Paris\r\nContact : Alexandra Mestivier, Natalie Kübler et Emmanuel Cartier\r\nEmail : avolansk@eila.univ-paris-diderot.fr , nkubler@eila.univ-paris-\r\ndiderot.fr , emmanuel.cartier@lipn.univ-paris13.fr\r\nCandidatures à envoyer avant : le 10 septembre 2018\r\n\r\n\r\nDescription du poste :\r\n\r\nL\'équipe d\'accueil 3967 CLILLAC-ARP\r\n(http://www.clillac-arp.univ-paris-diderot.fr/), dirigée par Natalie\r\nKübler, professeur à l\'UFR EILA, est adossée à trois UFR : l\'UFR\r\nd\'Études Anglophones, l\'UFR EILA, et l\'UFR de Linguistique.  Le projet\r\ndans lequel interviendra le/ la candidat(e) concerne les membres de\r\nl\'équipe appartenant à l\'UFR EILA, dont la recherche porte sur la\r\nlexicologie, la terminologie, la néologie, la linguistique de corpus,\r\nles langues de spécialité, la traductologie et les politiques\r\nlinguistiques dans un certain nombre de langues.\r\n\r\nPlus particulièrement, le/la candidat(e) participera au transfert de la\r\nplateforme Neoveille (http://lipn.univ-paris13.fr/neoveille/),\r\ndéveloppée par Emmanuel Cartier au sein du LIPN, pour une utilisation\r\ndans le cadre de l\'étude de l\'innovation dans les langues de spécialité\r\nque mènera le CLILLAC- ARP. Il/elle devra installer la plateforme,\r\ndévelopper des fonctions supplémentaires, adapter les fonctionnalités\r\nexistantes et lancer la récupération de corpus.\r\n\r\nLe/la candidat-e aura :\r\n- des connaissances de Python\r\n- une bonne connaissance/pratique des systèmes LAMP (Linux Apache MySQL\r\n  PHP) et Javascript (Jquery). Une connaissance des librairies D3.js et\r\n  Dc.js serait un plus\r\n- des connaissances de base en linguistique.\r\n- des connaissances en gestion des corpus\r\n- une bonne connaissance du système d\'exploitation Linux\r\n\r\nEtant donnée la courte durée du stage, une bonne maîtrise de la\r\nprogrammation est indispensable.\r\n\r\nRémunération : selon le niveau d\'études'),
(492, '2018-07-18', 'Otherlang', 'Paris', 'Offre de stage: Stagiaire Linguiste\r\n\r\nQui sommes-nous ?\r\n\r\nOtherLang développe une application de pratique et d\'apprentissage des\r\nlangues. Elle part du constat que les solutions actuelles ne proposent\r\njamais ensemble ces deux démarches nécessaires à l\'acquisition d\'une\r\nlangue étrangère.\r\n\r\nNous proposons une approche différente qui part de la pratique écrite\r\ncollaborative en l\'enrichissant de différents outils d\'un apprentissage\r\npersonnalisé (\"Adaptative Learning\"). Certains sont basés sur des\r\ndéveloppements sémantiques innovants.\r\n\r\nMissions\r\n\r\nNous recherchons un linguiste ou un ingénieur linguiste pour travailler\r\nsur le développement de notre application d\'apprentissage des langues.\r\n\r\nLa mission consistera à travailler sur l\'aide aux échanges entre\r\nutilisateurs (chat) et l\'apprentissage personnalisé. La mission portera\r\nsur l\'enrichissement des règles qui analysent les phrases pour\r\nidentifier les erreurs et les cartes d\'apprentissage. Pour cela, il sera\r\nnotamment demandé d\'effectuer les tâches suivantes :\r\n\r\n* conception des règles linguistiques,\r\n\r\n* création de corpus de tests,\r\n\r\n* réalisation des tests,\r\n\r\n* veille et tests des outils d\'analyse morpho-syntaxique,\r\n\r\n* veille des approches à la détection automatique des erreurs\r\n  grammaticales.\r\n\r\nCompétences \r\n\r\n* connaissances en grammaire formelle,\r\n\r\n* bon niveau de l\'anglais et/ou français,\r\n\r\n* vous êtes passionné(e) par les langues,\r\n\r\n* vous faites preuve de l\'initiative vis-à-vis du sujet de votre stage,\r\n\r\n* vous aimez évoluer en autonomie au sein d\'une petite équipe,\r\n\r\n* vous êtes organisé(e) et rigoureux(se),\r\n\r\n* la connaissance des outils de Natural Language Processing, notamment\r\n  de Stanford Parser et des expressions régulières seraient un plus.\r\n\r\nProfil \r\n\r\nÉtudiant-e de niveau Licence 3, Master 1 ou Master\r\n\r\n2 de linguistique générale ou TAL ou équivalent.\r\n\r\nType d\'offre\r\n\r\nStage de 3 à 6 mois\r\n\r\nDate de début: dès que possible\r\n\r\nInfos pratiques\r\n\r\nSociété\r\n\r\nOtherLang\r\n\r\nVille : Paris\r\n\r\nsite: www.otherlang.com\r\n\r\nContact \r\n\r\nSi cette offre vous intéresse, merci de transmettre vos\r\n\r\nmotivations dans le corps du mail et joindre votre CV à\r\nirina.maslowski@otherlang.com'),
(493, '2018-07-30', 'Advanced decision', 'Paris', 'Cadre du stage :\r\n\r\nCe stage de recherche d\'une durée de 4 à 6 mois se déroulera au sein de\r\nla société advanced decision.\r\nUne poursuite du stage dans le cadre d\'une convention CIFRE est\r\nenvisagée sur les mêmes problématiques.\r\nL\'encadrement sera assuré par l\'équipe R&D de la société en\r\ncollaboration avec des laboratoires de recherche.\r\n\r\nLa société :\r\nadvanced decision est une startup spécialisée en Intelligence\r\nArtificielle avec un savoir-faire industriel dans la réalisation de\r\nmoteurs intelligents de recommandation.\r\nNous développons un nouveau produit :  un agent virtuel de création de\r\nvoyages « sur mesure ».\r\nNotre produit utilise les dernières techniques de l\'IA et de la Data\r\nScience : NLP, Machine Learning, et Decision Management.\r\nNous recherchons un stagiaire qui souhaite s\'investir dans les domaines\r\nde l\'ingénierie linguistique et l\'extraction du sens à partir des\r\ntextes.\r\n\r\n\r\nContexte :\r\nNotre produit permet une appréhension des expériences grâce à une brique\r\nd\'analyse des avis et des commentaires. Un prototype permet d\'ores et\r\ndéjà de repérer les expériences et de qualifier leur polarité. L\'objet\r\ndu stage est d\'améliorer cette dernière fonctionnalité en tenant compte\r\nnotamment de la structure syntaxique des textes analysés.\r\n\r\nActivités :\r\n- Appropriation des travaux réalisés\r\n- État de l\'art des techniques d\'analyse des sentiments\r\n- Identification des dimensions et des ressources adaptés à notre sujet\r\n- Benchmark de certains algorithmes pour améliorer l\'analyse des\r\n  sentiments\r\n- Implémentation et optimisation\r\n\r\nCompétences :\r\n- Langage de programmation (Python, C++, Java)\r\n- Ingénierie linguistique, TAL, Fouille de textes et d\'opinions\r\n- Machine Learning (SVM, réseaux de neurones, ...)\r\n- Connaissance appréciée d\'un des frameworks (NLTK, Keras ou PyTorch)\r\n\r\nDurée : 3 à 6 mois\r\nDémarrage : asap\r\nLieu : Paris 17\r\nFormation : Ingénieur Informatique, Master en TAL\r\nIndemnité : selon convention et expérience\r\nDocuments à fournir : CV, lettre de motivation et bulletins de notes\r\nCandidature : stage@advanceddecision.fr'),
(494, '2018-09-04', 'Amadeus', 'Sophia Antipolis', 'Amadeus (https://amadeus.com)\r\n\r\nData Insight Internship - CSS-SSP-EDS \r\n\r\nIn the scope of a large code Reengineering Project, we are looking for\r\nhighly motivated and passionate Data Analyst to apply rigorous\r\nscientific methodology and algorithms to data/information embarked\r\nwithin the internal structures in our legacy code in order to improve\r\nits understanding and efficiency.\r\n\r\nAs a Data Analyst, you will provide unique insight into understanding\r\nthe structures articulating around multiple business and customer\r\nscenarios that cut across Amadeus organizational boundaries and lead\r\nthe current usage and incoming growth of a data-driven culture within\r\nthe Search Shopping and Pricing Core division.  \r\n\r\nKey Responsibilities\r\n\r\nAs a Data Analyst, you will mainly formulate analytical approaches to\r\ndetermine the functional adherence of our current internal C\r\nstructures based on the understanding of product functionality,\r\nBusiness flows etc. in terms of entropy across different processes and\r\ninformation reliability and redundancy between different internal\r\nstructures.\r\n\r\nYou will use data exploration techniques to uncover patterns in the\r\ndata from which predictive models, actionable insights or solutions\r\ncan be developed with the perspective to move from a monolithic to a\r\nService Oriented and Modular software.\r\n\r\nYou will interpret your results with the help of highly experienced\r\nfunctional experts and skilled technical developers in an\r\ninternational context, validate their approach, and learn to monitor,\r\nclearly document, analyze, in order to iterate and automatize in the\r\nmindset of a continuous improvement.\r\n\r\nQualifications\r\n\r\n- Currently pursuing graduate degree in Software Engineering, Data\r\n  Analytics, Machine Learning, Applied Mathematics or similar domain.\r\n\r\n- Programming skills in C, C++,\r\n\r\n- Proficiency using one or more scripting languages.\r\n\r\n- Software technology savvy, creativity and forward thinking.\r\n\r\n- Solid spoken and written English. \r\n\r\n- Self-driven to learn new technology area.\r\n\r\n- Ability to interact with peers and stakeholders to drive product and\r\n  business im pact.\r\n\r\n- Strong interpersonal and communications skills.\r\n\r\n\r\n\r\nLocation: \r\n   Amadeus Espaces, \r\n   Rue des Amandiers, \r\n   06410 Biot,\r\n   France.\r\n\r\nContact:\r\n   Djamal Mohia, \r\n   djamal.mohia@amadeus.com\r\n   +33 4 97 15 87 70\r\n   www.amadeus.com'),
(495, '2018-09-24', 'Labex OBVIL', 'Paris', 'Offre de stage en Humanités Numériques chez le Labex OBVIL - Sorbonne\r\nUniversité\r\nhttp://obvil.sorbonne-universite.site\r\nSeptembre 2018\r\n\r\nContexte et principales missions : Vous intégrez une équipe de recherche\r\net de développement, le labex OBVIL (Observatoire de la Vie Littéraire),\r\noù vous participez à la réalisation de solutions autour des technologies\r\ndes Humanités Numériques. Le stage se déroulera dans le cadre du projet\r\nApollinaire qui vise à mettre à mettre en ligne chronologiquement tous\r\nles écrits et tous les manuscrits d\'Apollinaire.\r\nLes textes sont disponibles en XML : format TEI.\r\n\r\nTâches :\r\n- Comprendre et apprivoiser la structure d\'un document XML ;\r\n- Savoir identifier et manipuler les éléments structurels d\'un texte \r\n  XML ;\r\n- Participer à l\'encodage de nouveaux textes en XML-TEI ;\r\n- Contrôler la qualité des textes encodés en XML-TEI par l\'équipe \r\n  scientifique en charge d\'éditer les manuscrits ;\r\n- Comprendre la notion de transformation à partir de XML vers une \r\n  publication Web, une publication PDF, ou une publication EPUB.\r\n\r\nNiveau de formation : Licence ou master\r\n\r\nCompétences requises : Connaissances en XML-TEI, DTD, CSS et Xpath ;\r\nfamiliarisation avec les logiciels d\'édition numérique de contenu\r\n(Oxygen...).\r\n\r\nEncadrement: Éric THIÉBAUD et Motasem ALRAHABI (ingénieurs de recherche\r\nOBVIL, Sorbonne Université).\r\n\r\nRémunération: standard\r\n\r\nLocalisation : Le stage se déroulera au Labex OBVIL, Maison de la \r\nRecherche, 28 rue Serpente, 75005 Paris.\r\n\r\nDurée: 6 mois\r\n\r\nDébut du contrat : Début octobre ou dès que possible après cette date.\r\n\r\nCandidature : Pour toute question ou pour nous adresser votre\r\ncandidature (curriculum vitae et lettre de motivation), merci d\'écrire à\r\nla secrétaire générale stephanie.guez@sorbonne-universite.fr en\r\nindiquant comme sujet : \"recrutement stagiaire XML\".'),
(496, '2018-09-26', 'OtherLang', 'Paris', 'Offre de stage: Stagiaire Linguiste\r\nQui sommes-nous ?\r\n\r\nOtherLang développe une application de pratique et d\'apprentissage des\r\nlangues. Elle part du constat que les solutions actuelles ne proposent\r\njamais ensemble ces deux démarches nécessaires à l\'acquisition d\'une\r\nlangue étrangère.\r\n\r\nNous proposons une approche différente qui part de la pratique écrite\r\ncollaborative en l\'enrichissant de différents outils d\'un apprentissage\r\npersonnalisé (\"Adaptative Learning\"). Certains sont basés sur des\r\ndéveloppements sémantiques innovants.\r\n\r\nMissions\r\n\r\nNous recherchons un linguiste ou un ingénieur linguiste pour travailler\r\nsur le développement de notre application d\'apprentissage des langues.\r\n\r\nLa mission consistera à travailler sur l\'aide aux échanges entre\r\nutilisateurs (chat) et l\'apprentissage personnalisé. La mission portera\r\nsur l\'enrichissement des règles qui analysent les phrases pour\r\nidentifier les erreurs et les cartes d\'apprentissage. Pour cela, il sera\r\nnotamment demandé d\'effectuer les tâches suivantes :\r\n\r\n   - conception des règles linguistiques,\r\n   - création de corpus de tests,\r\n   - réalisation des tests,\r\n   - veille et tests des outils d\'analyse morpho-syntaxique,\r\n   - veille des approches à la détection automatique des erreurs\r\n     grammaticales.\r\n\r\nCompétences - connaissances en grammaire formelle,\r\n   - bon niveau de l\'anglais et/ou français,\r\n   - vous êtes passionné(e) par les langues,\r\n   - vous faites preuve de l\'initiative vis-à-vis du sujet de votre\r\n     stage,\r\n   - vous aimez évoluer en autonomie au sein d\'une petite équipe,\r\n   - vous êtes organisé(e) et rigoureux(se),\r\n   - la connaissance des outils de Natural Language Processing,\r\n     notamment de Stanford Parser, des expressions régulières et de\r\n     programmation seraient un plus.\r\n\r\nProfil\r\n\r\nÉtudiant-e de niveau Master 1 ou Master 2 de linguistique générale ou\r\nTAL ou équivalent.\r\n\r\nType d\'offre\r\n\r\nStage de 4 à 6 mois\r\n\r\nDate de début: janvier 2019\r\n\r\nInfos pratiques\r\n\r\nSociété : OtherLang\r\n\r\nVille : Paris\r\n\r\nsite: www.otherlang.com\r\n\r\nContact\r\n\r\nSi cette offre vous intéresse, merci de transmettre vos motivations dans\r\nle corps du mail et joindre votre CV à irina.maslowski_at_otherlang.com'),
(498, '2018-10-03', 'LIFAT', 'Blois', '6-month NLP internship in Blois, France:\r\n\r\n*Verbal Multiword Expression Discovery in French Based on Seen Data and\r\n Distributional Semantics*\r\n\r\n* Scientific field: Natural Language Processing (NLP)\r\n* Location: University of Tours, LIFAT (Laboratoire d\'Informatique\r\n  Fondamentale et Appliquée de Tours), Blois campus (41)\r\n* Duration: 6 months\r\n* Remuneration : 577 ¤ / month\r\n* Detailed description: http://parsemefr.lis-lab.fr/doku.php?id=2018-lifat-m2-1\r\n\r\n* Important dates\r\n  - Application deadline: *15 December 2018* (or until filled)\r\n  - Notification: 15 January 2018\r\n  - Position starts: around February-March 2018\r\n  - Position ends: around July-August 2018\r\n\r\n* Requested candidate profile\r\n  - 2nd-year master student in computational linguistics, computer\r\n    science or alike\r\n  - Interests in linguistics and familiarity with language technology\r\n  - Good knowledge of French\r\n  - Good programming skills, preferably in Python.\r\n\r\n* Applications:\r\n  Send your CV and a cover letter to Caroline Pasquer\r\n  (first.last@etu.univ-tours.fr) and Agata Savary\r\n  (first.last@univ-tours.fr).\r\n\r\n*Motivation and objectives*\r\n\r\nThe internship will take place in the framework of the PARSEME-FR\r\nproject (http://parsemefr.lis-lab.fr), which involves several NLP teams\r\nin France.\r\n\r\nThe aim is to boost applications in Natural Language Processing (NLP),\r\nby focusing on one of their major challenges: multiword expressions\r\n(MWEs).\r\n\r\nMWEs are groups of words which exhibit unpredicted properties (Baldwin &\r\nKim, 2010). Most prominently, their meaning does not straightforwardly\r\nderive from the meanings of their components, as in \'casser sa pipe\'\r\n(literally `to break one\'s pipe\') `to die\'.\r\n\r\nTwo major MWE-related NLP tasks include MWE discovery and MWE\r\nidentification. In the former, the input consists in large quantities of\r\nraw texts and the output is a list of potential MWEs. In the latter, and\r\nidentifier takes a text on input and automatically annotates (points at)\r\nthe occurrences of MWEs in it. MWE identification is a pre-requisite for\r\ndownstream applications such as machine translation (which may want to\r\ntreat MWEs with dedicated procedures).\r\nAutomatic identification of MWEs in 19 languages was addressed by the\r\nPARSEME shared task1 (Ramisch et al., 20182018), in which the BdTln team\r\nparticipated with the VarIDE system (Pasquer et al., 2018a). The results\r\nof the shared task show that identifying unseen MWEs (i.e. those MWEs\r\nwhich do not occur in the training data) is particularly\r\nchallenging. Thus, identification should, ideally, exploit not only\r\nannotated corpora but also MWE lexicons and MWE discovery methods.\r\n\r\nThis internship is dedicated to discovering how MWE discovery could\r\nbenefit from the previously seen data, rather than be performed from\r\nscratch. The hypothesis to be tested is that new (unseen) MWEs of\r\ncertain types can be discovered due to their semantic similarity with\r\nknown (previously seen) MWEs. We focus on the domain of distributional\r\nsemantics, which is based on the hypothesis that words having a similar\r\nmeaning occur in similar contexts. Recent developments in distributional\r\nsemantics include the construction of \"word embeddings\", i.e. mappings\r\nfrom words or expressions to low-dimensional vectors of real numbers,\r\nwhich are expected to represent co-occurrence contexts of these\r\nwords/expressions in a compact way. Thus, an embedding of a\r\nword/expression can be considered an abstract representation of its\r\nmeaning.\r\n\r\nThe objectives of this internship are to exploit word embeddings for\r\ndiscovery of new MWEs based on their semantic proximity to the\r\npreviously seen MWEs, contained in a lexicon or in an annotated corpus\r\n(resources of both types belong to the outcomes of the PARSEME-FR\r\nproject). The discovery should lead to (semi-)automatic enrichment of\r\nthese initial resources.'),
(499, '2018-10-15', 'Airbus', 'Elancourt', 'Stage Traitement de la Parole (h/f)\r\n\r\nAirbus Defence and Space Elancourt\r\n\r\nAirbus est un leader mondial de l\'aéronautique, de l\'espace, de la\r\ndéfense et des services associés. En 2017, l\'entreprise a dégagé un\r\nchiffre d\'affaires de 67,0 milliards d\'euros avec un effectif\r\nd\'environ 130 000 personnes. Airbus propose la gamme d\'avions de\r\ntransport de passagers la plus complète, de 100 à plus de 600\r\nsièges. Airbus est également le fournisseur d\'avion de ravitaillement,\r\nde combat, de transport et de mission leader en Europe, ainsi que le\r\nnuméro un européen et le numéro deux mondial de l\'industrie\r\nspatiale. Sur le marché des hélicoptères, Airbus fournit les voilures\r\ntournantes civiles et militaires les plus performantes au monde.\r\n\r\nNos équipes travaillent avec passion et détermination pour faire du\r\nmonde un endroit plus connecté, plus sûr et plus intelligent. Fiers de\r\nnotre travail, nous nous appuyons sur l\'expertise et l\'expérience de\r\nchacun pour atteindre l\'excellence. Notre diversité et culture du\r\ntravail en équipe nous poussent à accomplir l\'extraordinaire - sur\r\nterre, dans le ciel et dans l\'espace.  Description du poste / stage\r\n\r\nUne offre de stage Traitement de la Parole (h/f) vient de s\'ouvrir au\r\nsein d\'Airbus Defence & Space à Elancourt.\r\n\r\nVous rejoindrez l\'équipe de Recherche & Développement composée\r\nd\'ingénieurs, d\'étudiants en thèse et de stagiaires, spécialisée dans\r\nle traitement de données multimédias (texte, audio, etc.) et le\r\ntraitement massif de l\'information non structurée (Big Data). Cette\r\néquipe est impliquée dans des projets d\'études amont ainsi que divers\r\nprogrammes de recherche partiellement financés par l\'Agence Nationale\r\nde la Recherche, l\'Agence de Défense Européenne ainsi que l\'Union\r\nEuropéenne.\r\n\r\nContexte :\r\n\r\nNotre équipe développe et adapte des briques technologiques pour le\r\ntraitement automatique de documents multimédias. Ces composants visent\r\nà fournir des solutions d\'analyse du contenu (identification de la\r\nlangue, extraction d\'information, transcription de la parole,\r\ntraduction automatique, etc.) et sont intégrés dans des applications\r\nde traitement de l\'information dans le domaine de la défense et de\r\nl\'aéronautique.\r\n\r\nDans cette perspective, ce stage s\'inscrit dans le cadre des travaux\r\nmenés sur la transcription automatique de la parole.\r\n\r\nObjectif:\r\n\r\nLa reconnaissance automatique de la parole (ASR, Speech recognition)\r\nprésente plusieurs défis notamment ceux liés à la qualité acoustique\r\ndes enregistrements (bruit, support de captation, etc.). L\'objectif de\r\nce stage est de contribuer à l\'identification et à la proposition de\r\nsolutions permettant de réduire l\'impact de ces problèmes sur la\r\nqualité de la transcription.\r\n\r\nCe stage commencera le 1er février 2019 (Date sujette à flexibilité)\r\net sera d\'une durée de 6 mois.\r\n\r\nTâches et missions principales, responsabilités\r\n\r\n- Contribution à l\'établissement d\'un état de l\'art sur les méthodes\r\n  de traitement de données audio bruitées et/ou de mauvaise qualité.\r\n\r\n- Identification de solutions open source ou de laboratoire.\r\n\r\n- Mise en oeuvre des solutions techniques (apprentissage sur des bases\r\n  existantes).\r\n\r\n- Comparaison et évaluation des approches sur un corpus de référence.\r\n\r\nCe poste exige une connaissance des risques potentiels de\r\nnon-conformité. Le/la titulaire s\'engage à agir avec intégrité,\r\nfondement du succès, de la réputation et de la croissance durable de\r\nla Société.\r\n\r\nCompétences requises\r\n\r\nVous préparez un BAC+5 en Traitement Automatique des langues (orienté\r\nrecherche), options Intelligence Artificielle, Apprentissage\r\nautomatique, Traitement automatique des Langues, Transcription\r\nautomatique.\r\n\r\nVous avez une bonne maitrise de Python, Shell, C++.\r\n\r\nVous avez des connaissances en Framework de Deep Learning.\r\n\r\nVous êtes doté(e) d\'un bon esprit d\'équipe et d\'un bon relationnel.\r\n\r\nVous avez un niveau avancé en anglais et Français courant.\r\n\r\n\r\n\r\nCandidature en ligne :\r\n\r\nhttps://company.airbus.com/careers/jobs-and-applications/search-for-vacancies~lang=fr~jobid=001A4B0A914A1EE8B2F960A4F3A78704~.html#'),
(500, '2018-10-15', 'Airbus', 'Elancourt', 'Stage Text-Mining et population de bases de connaissances (h/f)\r\n\r\nAirbus Defence and Space Elancourt\r\n\r\nAirbus est un leader mondial de l\'aéronautique, de l\'espace, de la\r\ndéfense et des services associés. En 2017, l\'entreprise a dégagé un\r\nchiffre d\'affaires de 67,0 milliards d\'euros avec un effectif\r\nd\'environ 130 000 personnes. Airbus propose la gamme d\'avions de\r\ntransport de passagers la plus complète, de 100 à plus de 600\r\nsièges. Airbus est également le fournisseur d\'avion de ravitaillement,\r\nde combat, de transport et de mission leader en Europe, ainsi que le\r\nnuméro un européen et le numéro deux mondial de l\'industrie\r\nspatiale. Sur le marché des hélicoptères, Airbus fournit les voilures\r\ntournantes civiles et militaires les plus performantes au monde.\r\n\r\nNos équipes travaillent avec passion et détermination pour faire du\r\nmonde un endroit plus connecté, plus sûr et plus intelligent. Fiers de\r\nnotre travail, nous nous appuyons sur l\'expertise et l\'expérience de\r\nchacun pour atteindre l\'excellence. Notre diversité et culture du\r\ntravail en équipe nous poussent à accomplir l\'extraordinaire - sur\r\nterre, dans le ciel et dans l\'espace.\r\n\r\nDescription du poste / stage\r\n\r\nUne offre de stage Text-Mining et population de bases de connaissances\r\n(h/f) vient de s\'ouvrir au sein d\'Airbus Defence & Space à Elancourt.\r\n\r\nVous rejoindrez l\'équipe de Recherche & Développement composée\r\nd\'ingénieurs, d\'étudiants en thèse et de stagiaires, spécialisée dans\r\nle text-mining et le traitement massif de l\'information non structurée\r\n(Big Data). Cette équipe est impliquée dans des projets d\'études amont\r\nainsi que divers programmes de recherche partiellement financés par\r\nl\'Agence Nationale de la Recherche, l\'Agence de Défense Européenne\r\nainsi que l\'Union Européenne.\r\n\r\nContexte :\r\n\r\nNotre équipe développe actuellement en s\'appuyant sur le socle\r\ntechnique open source OW2 WebLab une solution de veille nommée FORTION\r\nMediaMining. Cette solution vise à fournir une solution complète de\r\ncollecte d\'information multimédia -texte, image, audio, vidéo -\r\ndisponible en source ouverte (web, réseaux sociaux), d\'analyse\r\n(extraction et recherche d\'information, transcription de la parole,\r\ntraduction automatique, etc...) et d\'exploitation (visualisation\r\nspatio-temporelle, réseau relationnel, statistiques, etc.). Celle-ci\r\ndispose notamment de fonctionnalités d\'extraction d\'information de\r\nrelations et d\'évènement à base de patrons linguistiques permettant\r\nd\'enrichir des bases de connaissances.\r\n\r\nObjectif :\r\n\r\nNotre équipe souhaite extraire à partir de textes éventuellement\r\nmultilingues (type flux presse) des évènements de différentes natures\r\n(militaires, économiques, catastrophes naturelles, etc). Une des\r\ndifficultés de la tâche d\'extraction d\'évènements vient de leur nature\r\ncomposite qui nécessite d\'extraire différentes dimensions (sémantique,\r\nspatiale, temporelle, agentive, numérique) disséminées au sein des\r\ntextes. Analyse discursive, extraction d\'entités nommées, de\r\nrelations, résolution d\'anaphores sont ainsi nécessaires pour couvrir\r\npleinement cette tâche. Les campagnes d\'évaluation récentes sur le\r\nsujet (ex TAC KDP2017) montrent que de nombreuses pistes d\'évaluation\r\nrestent à explorer (53% de F-Mesure pour le meilleur système à date).\r\n\r\nCe stage commencera le 1er février 2019 (Date sujette à flexibilité)\r\net sera d\'une durée de 6 mois.\r\n\r\nStages chez Airbus\r\n\r\nTâches et missions principales, responsabilités\r\n\r\nCe stage vise ainsi à étudier la possibilité de remplacer / hybrider\r\nles systèmes d\'extraction à base de patrons linguistiques par des\r\nsystèmes à base de réseaux de neurones profonds de type réseaux de\r\nneurones récurrents :\r\n\r\nContribution à l\'établissement d\'un état de l\'art sur les méthodes\r\nd\'extraction d\'information, de relation et d\'évènements à base de\r\nméthode d\'apprentissage pour la population de base de connaissance.\r\n\r\nIdentification de solutions open source ou de laboratoire.\r\n\r\nMise en oeuvre des solutions techniques (apprentissage sur base\r\nannotée).\r\n\r\nComparaison et évaluation des approches sur un corpus de référence.\r\n\r\nCe poste exige une connaissance des risques potentiels de\r\nnon-conformité. Le/la titulaire s\'engage à agir avec intégrité,\r\nfondement du succès, de la réputation et de la croissance durable de\r\nla Société.\r\n\r\nCompétences requises\r\n\r\nVous préparez un BAC+5 en Traitement d\'Information (orienté\r\nrecherche), options Intelligence Artificielle, Apprentissage\r\nautomatique, Traitement automatique des Langues, Fouille de données,\r\nExtraction d\'information à partir de textes.\r\n\r\nVous avez une bonne maitrise de Java et Python.\r\n\r\nVous avez des connaissances en Framework de Deep Learning type Tensorflow.\r\n\r\nVous êtes doté(e) d\'un bon esprit d\'équipe et d\'un bon relationnel.\r\n\r\nVous avez un niveau avancé en anglais et Français courant.\r\n\r\nCandidature en ligne :\r\nhttps://company.airbus.com/careers/jobs-and-applications/search-for-vacancies~lang=fr~jobid=001A4B0A914A1ED8B2F9907C4EB89502~.html'),
(501, '2018-10-15', 'Santé publique France', 'Saint-Maurice (94)', 'Stage à Santé Publique France pour des étudiants de Master\r\n\r\nAnnée universitaire 2018-2019\r\n\r\n- Stage proposé par\r\n\r\nTitre : Influence de l\'expression du temps et de la soudaineté de la\r\nsurvenue d\'une cause médicale de décès pour la surveillance réactive\r\nde la mortalité à visée d\'alerte sanitaire.\r\n\r\nDirection/ Cire : DATA\r\n\r\nMaîtres de stage / personne contact : \r\n\r\nNom : FOUILLET Prénom : Anne\r\n\r\nTéléphone : 01 41 79 57 25 Adresse email :\r\nanne.fouillet@santepubliquefrance.fr\r\n\r\n- Type de stage proposé\r\n\r\nMaster 1 Master 2 Professionnel Master 2 Recherche\r\n\r\nExtension possible au-delà de la période obligatoire Oui Non\r\n\r\nCommentaires :\r\n\r\n- Date proposée pour le stage et durée\r\n\r\npas de contrainte de date \r\n\r\nA partir de Février/Mars 2019 \r\n\r\nDurée en mois : 5/6 mois\r\n\r\n- Sujet proposé pour le stage\r\n\r\nSanté publique France est l\'agence nationale de santé publique\r\nfrançaise. Elle intervient au service de la santé des populations.\r\nAgence scientifique et d\'expertise du champ sanitaire, elle a pour\r\nmissions : (1) l\'observation épidémiologique et la surveillance de\r\nl\'état de santé des populations ; (2) la veille sur les risques\r\nsanitaires menaçant les populations ; (3) la promotion de la santé et la\r\nréduction des risques pour la santé ; (4) le développement de la\r\nprévention et de l\'éducation pour la santé ; (5) La préparation et la\r\nréponse aux menaces, alertes et crises sanitaires ; (6) le lancement de\r\nl\'alerte sanitaire.\r\n\r\nLe stage se déroulera dans l\'unité « Application, Big Data et\r\nSurveillance Syndromique » de la Direction Appui, Traitements et\r\nAnalyses des données (DATA). Cette unité a de nombreuses missions au\r\nsein de l\'agence dont le traitement des grandes bases de données, la\r\nréalisation d\'outils de restitution graphiques et le pilotage du système\r\nnational de surveillance des urgences et des décès SurSaUD(R), mis en\r\nplace en 2004. SurSaUD(R) est un des principaux dispositifs de Santé\r\npublique France pour assurer la veille sanitaire non spécifique à visée\r\nd\'alerte notamment par l\'identification d\'événements inhabituels. Cette\r\nveille s\'appuie sur l\'analyse quotidienne du recours aux soins d\'urgence\r\nhospitaliers et libéraux (réseaux OSCOUR(R) et SOS Médecins) et de la\r\nmortalité (analyse des décès toutes causes de l\'Insee principalement et\r\nanalyse des décès par cause médicale, issue de la certification\r\nélectronique de décès).\r\n\r\nLe stage portera sur les données de la certification électronique des\r\ndécès, contenant les causes médicales de décès exprimées en texte\r\nlibre. Cette source de données est en cours de généralisation sur le\r\nterritoire, elle enregistre 13% de la mortalité nationale en 2018,\r\nproportion en hausse régulière depuis plusieurs années.\r\n\r\nUn premier travail de recherche réalisé en 2018 dans le cadre d\'un stage\r\nde Master Linguistique Informatique, a permis de sélectionner et\r\nd\'évaluer deux méthodes de classement automatisé de ces causes médicales\r\nde décès dans des regroupements prédéfinis (« regroupements syndromiques\r\n») : une méthode par règles linguistiques et un SVM.  L\'évaluation a été\r\nmenée sur des données annotées manuellement (4500 certificats de\r\ndécès). Chaque certificat de décès contient plusieurs causes médicales,\r\nclassées dans un ou plusieurs regroupements syndromiques. Ce travail a\r\nété réalisé sous Python 3.5.\r\n\r\nObjectifs du stage\r\n\r\nDans un premier temps, le stage visera à améliorer le classement réalisé\r\nlors du travail de recherche de 2018, à travers la prise en compte\r\nd\'informations complémentaires précisées par le médecin dans le\r\ncertificat. Cela peut concerner en particulier :\r\n\r\n- les informations permettant d\'exprimer une date ou un délai de\r\n  survenue d\'une cause par rapport à la date de décès.\r\n\r\n- l\'expression de la soudaineté de la survenue d\'une cause.\r\n\r\nDes illustrations de causes de décès contenant des expressions du temps\r\net de la soudaineté sont présentées en annexe.\r\n\r\nDans un second temps, le stage visera à mettre en oeuvre une méthode de\r\nclassement automatisé par apprentissage et comparer ses performances à\r\ncelles obtenues à partir des deux premières méthodes (Méthodes par\r\nrègles et SVM). L\'évaluation des performances pourra s\'appuyer sur des\r\néchantillons qui auront été annotés grâce à une méthode d\'annotation\r\nsemi-automatique.\r\n\r\nLes principales étapes du stage seront :\r\n\r\n* Prise en main des scripts et ressources, développés lors du premier\r\n  travail de recherche,\r\n\r\n* Prendre en compte des informations complémentaires à l\'aide de\r\n  traitements linguistiques,\r\n\r\n* Evaluer l\'influence de ces informations sur la dynamique des\r\n  regroupements syndromiques,\r\n\r\n* Développer et évaluer une méthode de classement de type étiqueteur,\r\n\r\n* Comparer les résultats à ceux obtenus à partir des méthodes par règles\r\n  et SVM.\r\n\r\nLe stage s\'appuiera sur des scripts et ressources existants, complétés\r\npar une documentation et un rapport de stage.\r\n\r\n- Prérequis\r\n\r\nAucun\r\n\r\nCompétences spécifiques (préciser) : \r\n\r\nMaîtrise d\'un logiciel spécifique (préciser) : langage Python\r\n\r\nAutre (préciser) : \r\n\r\n- Commentaires\r\n\r\nLe stagiaire sera co-encadré par l\'équipe du CNRS-LIMSI (Laboratoire\r\nd\'informatique pour la Mécanique et les Sciences de l\'Ingénieur),\r\nspécialisée dans le domaine du traitement automatique des langues.\r\n\r\nLe stage se déroulera à la Direction Appui, Traitements et Analyses de\r\ndonnées de Santé publique France à Saint-Maurice (94) et au CNRS-Limsi à\r\nOrsay (91).');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(502, '2018-10-16', 'Naver Labs Europe', 'Grenoble', 'Machine translation has made great progress in recent years thanks to\r\ndeep neural networks [1,2,7].  However, current machine translation\r\nsystems make a simplifying assumption that the translation of a given\r\nsentence does not depend on the other neighboring sentences. Yet, we\r\nknow that extended context can prevent mistakes in ambiguous cases and\r\nimprove translation coherence.\r\n\r\nIn the case of machine translation of user generated content (e.g.,\r\nuser reviews of hotels or restaurants), the source data is often\r\nhighly contextual and structured. Several reviews can be associated to\r\nthe same Point of Interest (POI), POIs can have specific features\r\n(e.g., their name or their location) and can also be organized into\r\ngraphs according to their similarity.\r\n\r\nThe goal of this internship is to introduce context-aware neural\r\nmachine translation models that do not process sentences in isolation\r\nbut leverage their context (history of sentences already translated,\r\nmeta information associated to a POI, POI graph structure). The\r\nmachine translation experiments will be done on several language pairs\r\nwith a POI database gathering more than 100 million POIs.\r\n\r\nRequirements\r\n\r\nâ— Student at Master (research-oriented) or PhD level.\r\n\r\nâ— Knowledge of deep learning as applied to NLP.\r\n\r\nâ— Good coding skills, including at least one the major deep learning\r\ntoolkits (preferably Pytorch).\r\n\r\nReferences.\r\n\r\n[1] Sequence to Sequence Learning with Neural Networks. Ilya\r\nSutskever, Oriol Vinyals, Quoc V. Le. NIPS 2014.\r\n\r\n[2] Neural Machine Translation by Jointly Learning to Align and\r\nTranslate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. ICLR 2015.\r\n\r\n[3] Conversational Analysis using Utterance-level Attention-based\r\nBidirectional Recurrent Neural Networks.  Chandrakant Bothe, Sven\r\nMagg, Cornelius Weber, Stefan Wermter. Interspeech 2018\r\n\r\n[4] End-to-End Memory Networks with Knowledge Carryover for Multi-Turn\r\nSpoken Language Understanding.  Yun-Nung Chen, Dilek Hakkani-TÃ¼r,\r\nGokhan Tur, Jianfeng Gao, and Li Deng. Interspeech 2016\r\n\r\n[5] An Efficient Approach to Encoding Context for Spoken Language\r\nUnderstanding. Raghav Gupta, Abhinav Rastogi, Dilek\r\nHakkani-Tur. Interspeech 2018\r\n\r\n[6] Multi-Timescale Long Short-Term Memory Neural Network for\r\nModelling Sentences and Documents. Pengfei Liu, Xipeng Qiu , Xinchi\r\nChen, Shiyu Wu, Xuanjing Huang. EMNLP 2015.\r\n\r\n[7] Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki\r\nParmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\r\nIllia Polosukhin. NIPS 2017.\r\n\r\n[8] Context-Aware Neural Machine Translation Learns Anaphora\r\nResolution. Elena Voita, Pavel Serdyukov, Rico Sennrich, Ivan\r\nTitov. EMNLP 2018.\r\n\r\n[9] Improving the Transformer Translation Model with Document-Level\r\nContext. Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai,\r\nJingfang Xu, Min Zhang and Yang Liu. EMNLP 2018.\r\n\r\n[10] Learning to Remember Translation History with a Continuous\r\nCache. Zhaopeng Tu, Yang Liu, Shuming Shi, Tong Zhang. TACL 2018.\r\n\r\n[11] Document Context Neural Machine Translation with Memory\r\nNetworks. Sameen Maruf, Gholamreza Haffari.  ACL 2018.\r\n\r\n[12] Document-Level Neural Machine Translation with Hierarchical\r\nAttention Networks. Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas,\r\nJames Henderson. EMNLP 2018\r\n\r\n[13] Improving the Transformer Translation Model with Document-Level\r\nContext. Jiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai,\r\nJingfang Xu, Min Zhang, Yang Liu. EMNLP 2018\r\n\r\n\r\nStart Date\r\nasap\r\n\r\nDuration\r\n5-6 months\r\n\r\nApplication instructions\r\n\r\nTo apply, please send a mail and CV to ioan.calapodescu@naverlabs.com,\r\nalexandre.berard@naverlabs.com and laurent.besacier@univ-grenoble-alpes.fr'),
(503, '2018-10-16', 'Naver Labs Europe', 'Grenoble', 'Machine translation has made great progress in recent years thanks to\r\ndeep neural networks [1,2,3]. A conventional neural machine\r\ntranslation (NMT) system uses a limited vocabulary of `tokens\' and its\r\ndecoder generates a token in the vocabulary at each time step. The\r\n`tokens\' of current machine translation systems can be words,\r\ncharacters [4] or subwords such as byte pair encodings (BPEs) [5]. The\r\nlatter have been particularly effective to deal with out-of-vocabulary\r\nwords and generally lead to state-of-the-art results. However, it is\r\nnot clear how many units1 should be kept for a particular MT task and\r\nwhich is the optimal granularity (characters, subwords, words), if\r\nany.\r\n\r\nThe goal of this internship is to investigate approaches that provide\r\nmodels with several views (segmentations) of the text to strengthen\r\ntheir robustness. This is particularly important for processing noisy\r\ndata such as user generated content (UGC - e.g., user reviews of\r\nhotels or restaurants). Such a multiscale neural machine translation\r\nmodel should take into account these different segmentation\r\ngranularities at both training and decoding stages. We also want the\r\nproposed method to be applicable to the latest state-of-the-art NMT\r\nbased on transformer networks [3].\r\n\r\nRequirements\r\n\r\n- Student at Master (research-oriented) or PhD level.\r\n\r\n- Knowledge of deep learning as applied to NLP.\r\n\r\n- Good coding skills, including at least one of the major deep\r\nlearning toolkits (preferably Pytorch).\r\n\r\nReferences.\r\n\r\n[1] Sequence to Sequence Learning with Neural Networks. Ilya\r\nSutskever, Oriol Vinyals, Quoc V. Le. NIPS 2014.\r\n\r\n[2] Neural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho,\r\nYoshua Bengio. ICLR q2015.\r\n\r\n[3] Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki\r\nParmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,\r\nIllia Polosukhin. NIPS 2017.\r\n\r\n[4] Jason Lee, Kyunghyun Cho, and Thomas Hofmann. 2017. Fully\r\ncharacter-level neural machine translation without explicit\r\nsegmentation. TACL 2017\r\n\r\n[5] Neural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, and Alexandra Birch. ACL,2016.\r\n\r\n[6] Improving Neural Machine Translation by Incorporating Hierarchical\r\nSubword Features. Makoto Morishita, Jun Suzuki* and Masaaki\r\nNagata. COLING 2018.5\r\n\r\n[7] Subword Regularization: Improving Neural Network Translation\r\nModels with Multiple Subword Candidates.  Taku Kudo. ACL 2018.6\r\n\r\n[8] Google\'s neural machine translation system: Bridging the gap\r\nbetween human and machine translation.  Yonghui Wu, Mike Schuster, et\r\nal. arXiv preprint arXiv:1609.08144 2016.\r\n\r\n[9] Neural Lattice-to-Sequence Models for Uncertain Inputs. Matthias\r\nSperber, Graham Neubig, Jan Niehues, Alex Waibel. EMNLP 2017.\r\n\r\n[10] On Using Monolingual Corpora in Neural Machine\r\nTranslation. Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho,\r\nLoic Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, Yoshua\r\nBengio. arXiv preprint:1503.03535.\r\n\r\n[11] Optimally Segmenting Inputs for NMT Shows Preference for\r\nCharacter-Level Processing. Julia Kreutzer, Artem Sokolov. arXiv\r\npreprint:1810.01480. 2018\r\n\r\nStart Date\r\nasap\r\n\r\nDuration\r\n5-6 months\r\n\r\nApplication instructions\r\n\r\nTo apply, please send a mail and CV to matthias.galle@naverlabs.com ,\r\nmarc.dymetman@naverlabs.com and\r\nlaurent.besacier@univ-grenoble-alpes.fr'),
(504, '2018-10-22', 'LIG / LIA', 'Grenoble', 'The LIG (Laboratoire d\'Informatique de Grenoble) and LIA (Laboratoire\r\nd\'Informatique d\'Avignon) laboratories propose the following M2 stage\r\n(research)\r\n\r\nTitle:\r\nDialog-Level Neural Spoken Language Understanding from Speech\r\n\r\nDescription:\r\n\r\nSpoken Language Understanding (SLU) is an important part of\r\nHuman-Computer interaction, and aims at extracting semantic\r\ninterpretations from human utterances [De Mori et al., 2008]. Because of\r\nthe high complexity of the problem, real applications focus on specific\r\ndomains, e.g. hotel reservation and information [Bonneau-Maynard et al.,\r\n2006]. Most of the times, SLU is performed on automatic transcriptions\r\nof the speech signal or, at best, on ASR word lattices. Thanks to neural\r\nnetworks, SLU can be possibly performed directly on speech signal,\r\novercoming or at least alleviating the problems related to automatic\r\ntranscription. Such end-2-end approaches from speech have been already\r\nproposed for spoken language translation [Bérard et al., 2018, Berard et\r\nal., 2016, Weiss et al., 2017]. Additionally, the use of Neural Networks\r\nsuch like RNNs (LSTM/GRU) [Hochreiter and Schmidhuber, 1997, Cho et al.,\r\n2014] and Transformers [Vaswani et al., 2017], in combination with\r\nattention mechanisms [Bahdanau et al., 2014], allows potentially to use\r\ncontextual information going beyond the single or a few dialog turns\r\n[Bothe et al., 2018]. This information is possibly crucial to solve\r\nlong-range ambiguïties.\r\n\r\nIn this internship the student will implement a complete neural SLU\r\nsystem, decoding semantic interpretations directly from the speech\r\nsignal and keeping into account contextual information at the whole\r\ndialog level. The student will use modular pre-built systems based on\r\nConvolutional and Recurrent Neural Networks [Berard et al., 2018,\r\nDinarelli et al., 2017] and/or Transformer networks, with the objective\r\nof creating a whole integrated SLU system. The student will run\r\nexperiments on its own using GPUs, and the system will be evaluated on\r\nthe SLU benchmark corpus MEDIA [Bonneau-Maynard et al., 2006, Hahn et\r\nal., 2010].\r\n\r\nStudent Profile:\r\n- Student for internship level (Master 2) in computer science, or from\r\n  engineering school\r\n- Computer science skills:\r\n     - Python programming with good knowledge of deep learning libraries\r\n       (Pytorch)\r\n     - Data manipulation (both textual data and audio signal)\r\n- Interested in Natural Language Processing\r\n- Skills in machine learning for probabilistic models\r\n\r\nThe internship may last from 4 up to 6 months, it will take place at LIG\r\nlaboratory (with potential visits at LIA, Avignon), GETALP team\r\n(http://lig-getalp.imag.fr/), starting from January/February 2019. The\r\nstudent will be tutored by Marco Dinarelli\r\n(http://www.marcodinarelli.it), Laurent Besacier\r\n(https://cv.archives-ouvertes.fr/laurent-besacier), and Bassam Jabaian\r\n(http://univ-avignon.fr/m-bassam-jabaian--3265.kjsp).\r\n\r\nInterested candidates must send a CV and a motivation letter to\r\nmarco.dinarelli@ens.fr, laurent.besacier@univ-grenoble-alpes.fr, and\r\nbassam.jabaian@univ-avignon.fr.\r\n\r\n\r\nReferences:\r\n\r\nDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.  Neural machine\r\ntranslation by jointly learning to align and translate.  CoRR,\r\nabs/1409.0473, 2014. URL http://arxiv.org/abs/1409.0473.\r\n\r\nAlexandre Berard, Olivier Pietquin, Christophe Servan, and Laurent\r\nBesacier.  Listen and translate: A proof of concept for end-to-end\r\nspeech-to-text translation.  CoRR, abs/1612.01744, 2016. URL\r\nhttp://arxiv.org/abs/1612.01744.\r\n\r\nAlexandre Béerard, Laurent Besacier, Ali Can Kocabiyikoglu, and Olivier\r\nPietquin.  End-to-end automatic speech translation of audiobooks.  CoRR,\r\nabs/1802.04200, 2018. URL http://arxiv.org/abs/1802.04200.\r\n\r\nHélène Bonneau-Maynard, Christelle Ayache, F. Bechet, A Denis, A Kuhn,\r\nFabrice Leféevre, D. Mostefa, M. Qugnard, S. Rosset, and J. Servan,\r\nS. Vilaneau.  Results of the french evalda-media evaluation campaign for\r\nliteral understanding.  In LREC, pages 2054{2059, Genoa, Italy, May\r\n2006.\r\n\r\nChandrakant Bothe, Sven Magg, CorneliusWeber, and StefanWermter.\r\nConversational analysis using utterance-level attention-based\r\nbidirectional recurrent neural networks. CoRR, abs/1805.06242, 2018. URL\r\nhttp://arxiv.org/abs/1805.06242.\r\n\r\nKyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares,\r\nHolger Schwenk, and Yoshua Bengio.  Learning phrase representations\r\nusing RNN encoder-decoder for statistical machine translation.  CoRR,\r\nabs/1406.1078,2014. URL http://arxiv.org/abs/1406.1078.\r\n\r\nR. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear, G. Riccardi, and G.\r\nTur.  Spoken language understanding: A survey. IEEE Signal Processing\r\nMagazine, 25:50-58, 2008.'),
(505, '2018-10-22', 'EDF R&D Lab', 'Saclay', 'STAGE INGÉNIERIE LINGUISTIQUE\r\nSUJET 2019: Exploration, analyse, modélisation et représentation de\r\ndonnées semi-structurées à des fins d\'utilisation pour la recherche et\r\nla visualisation d\'information.\r\nDURÉE : 6 MOIS ENVIRON\r\nLieux : EDF R&D Lab Saclay et déplacements sur sites industriels en\r\nFrance\r\n\r\n------------------------------------------------------------------\r\n1.	 CONTEXTE INDUSTRIEL \r\n------------------------------------------------------------------\r\n\r\nL\'approvisionnement en énergie compte parmi les enjeux politiques,\r\néconomiques et écologiques décisifs pour l\'avenir. La satisfaction de la\r\ndemande énergétique mondiale et le respect des objectifs internationaux\r\nde lutte contre le changement climatique imposent de développer des\r\nénergies décarbonées. Le nucléaire apparaît ainsi comme un élément du\r\nmix énergétique du futur.\r\nDans ce domaine où l\'ensemble des intervenants doit être irréprochables\r\nen matière de sûreté et de radioprotection, l\'exploitant doit respecter\r\nles Règles générales d\'exploitation (RGE). Les RGE sont un recueil de\r\nrègles approuvées par l\'Autorité de Sûreté Nucléaire qui définissent le\r\ndomaine autorisé de fonctionnement de l\'installation et les\r\nprescriptions de conduite associées. En effet, tel le Code de la Route,\r\nles RGE regroupent l\'ensemble des consignes à respecter par les\r\nexploitants, pour garantir le meilleur niveau de sûreté de leurs\r\ncentrales.\r\nDans le cadre des réflexions associées à la transition numérique du\r\ngroupe EDF il s\'agit d\'instruire comment l\'intégration d\'outils «\r\nintelligents » du Traitement Automatique de la Langue Naturelle écrite\r\npourrait soutenir l\'utilisation des nouvelles RGE en facilitant\r\nl\'analyse exhaustive et l\'interprétation de ses prescriptions par les\r\ndifférentes fonctions concernées.\r\n\r\n------------------------------------------------------------------\r\n2.	 SUJET DU STAGE\r\n------------------------------------------------------------------\r\n\r\nLe stage consistera à participer à l\'étude sur l\'apport des TALN pour\r\nfaciliter la consultation, l\'analyse et l\'interprétation des règles\r\ngénérales d\'exploitation d\'une centrale nucléaire.\r\nPlus précisément, il s\'agira de:\r\n- Participer à l\'analyse du besoin et s\'approprier le use case retenu ;\r\n- pré traitement : mettre sous forme exploitable pour des analyses et\r\n  traitements automatiques, un document rédigé en français en chapitres\r\n  et sous-chapitres\r\n- Exploration des données (analyses statistiques ou linguistiques)\r\n- Résoudre le use case\r\n- Constituer les ressources\r\n- Formater les données ;\r\n- Proposer des représentations, parcours, réponses compte tenu du use\r\n  case retenu\r\n- Evaluer les propositions retenues.\r\n\r\nAu terme du stage le stagiaire pourra proposer :\r\n- Une documentation technique\r\n- Le transfert et dépôt du code à l\'équipe\r\n- Un ou des prototypes des différentes propositions étudiées.\r\nIl s\'agira ensuite de mettre en perspective les éléments issus de ces\r\ndifférentes propositions compte tenu des besoins, traitements et\r\nenvironnements techniques identifiés.\r\n\r\n*** Les avantages du stage \r\nAu sein de la R&D du groupe EDF ce stage vous permettra :\r\n- De mettre en oeuvre des outils d\'analyse de données non structurées ;\r\n- De mettre en oeuvre des outils d\'analyse et de représentation de\r\n  données semi structurées ;\r\n- D\'interagir avec des experts en text mining et ergonomie ;\r\n- D\'être force de proposition dans un projet pluridisciplinaire dès les\r\n  phases amonts de conception ;\r\n- De participer à la phase amont d\'un projet industriel.\r\n\r\n\r\n------------------------------------------------------------------\r\n3.	COMPETENCES REQUISES\r\n------------------------------------------------------------------\r\n\r\nConnaissance du langage python\r\nConnaissance d\'outils de TALN\r\nTravail en équipe\r\nAisance relationnelle\r\nAisance rédactionnelle\r\nCapacités d\'adaptation et d\'initiatives\r\nAnglais lu\r\n\r\n------------------------------------------------------------------\r\n4.	INFORMATIONS PRATIQUES\r\n------------------------------------------------------------------\r\n\r\n1 - CONTACTS	\r\n	Julien Kahn (Tuteur)	julien.kahn@edf.fr\r\n	Delphine Lagarde	delphine.lagarde@edf.fr \r\n	Meryl Bothua	meryl.bothua@edf.fr\r\n\r\n2 - Lieu du stage	\r\n	EDF R&D Lab Saclay\r\n	Département PErformance et prévention des Risques Industriels du\r\n           parC par la simuLation et les EtudeS (PERICLES)\r\n	Groupe Facteurs Organisationnels et Humains (FOH)\r\n	7, boulevard Gaspard Monge 91120 PALAISEAU, FRANCE\r\n\r\n3 - Date & Durée \r\n	2019 - 6 mois environ\r\n\r\n4 - Rémunération\r\n	A définir (environ 1.000¤/mois)'),
(506, '2018-10-22', 'Orange Labs', 'Lannion', 'Intitulé du stage : « Evaluation des systèmes de dialogue à chaque tour\r\nde parole à partir de la satisfaction utilisateur»\r\n\r\nEntité : Orange Labs (Lannion). Equipe NADIA (Natural Language Dialogue)\r\nContact : Lina Rojas (linamaria.rojasbarahona@orange.com)\r\n\r\nSynthèse de la mission :\r\n\r\nL\'objectif du stage est d\'étudier la corrélation entre les métriques\r\nobjectives (par exemple : le nombre de tours, les raccrochages, les\r\nrépétitions, les mots utilisés, etc.) et la satisfaction globale de\r\nl\'utilisateur donnée à la fin du dialogue en utilisant un modèle de\r\nrégression profond.\r\n\r\nPour cela, nous utiliserons le corpus DATCHA et ses annotations. Le\r\ncorpus DATCHA est une collection de conversations entre les opérateurs\r\net les clients du service d\'assistance du chat Orange. Le corpus\r\ncomprend des annotations de la satisfaction de l\'utilisateur sur les\r\nthèmes suivants : accompagnement, écoute, conseil, solution et\r\nrecommander. [1,2]. Ces annotations sont issues des enquêtes de\r\nsatisfaction remplies par les clients à la fin de chaque conversation.\r\n\r\nLe calcul de la récompense est un point clé de l\'apprentissage par\r\nrenforcement en dialogue. La récompense est utilisée par l\'utilisateur\r\n(un humain) pour évaluer le système (la machine). La récompense peut\r\nêtre vue comment une combinaison des métriques objectives et des\r\nmétriques subjectifs (la satisfaction de l\'utilisateur) [3,4].\r\n\r\nDans ce stage, vous devrez dans un premier temps trouver les métriques\r\nobjectives qui peuvent affecter la satisfaction utilisateur. Pour cela,\r\nvous utiliserez des métriques objectives déterminées à chaque tour de\r\nparole en fonction du contexte (les tours de parole précédentes). Vous\r\npouvez également analyser les caractéristiques appris par les modèles\r\ndisponibles [2] et vous devrez implémenter un modèle de régression\r\nprofond similaire aux modèles proposés dans les travaux [3 et 4].\r\n\r\n\r\n[1] Damnati, G., Guerraz, A. & Charlet, D. Web chat conversations from\r\n    contact centers: a descriptive study. In LREC (2016).\r\n[2] Auguste, J., Charlet, D., Damnati, G., Favre, B. & Béchet,\r\n    F. Évaluation automatique de la satisfaction client à partir de\r\n    conversations de type\" chat\" par réseaux de neurones récurrents avec\r\n    mécanisme d\'attention. Auto-encoding variational bayes. arXiv\r\n    preprint arXiv:1312.6114 (2013).\r\n[3] M.  Walker,  D.  J.  Litman,  C.  A.  Kamm,  and  A.  Abella,\r\n    \"PARADISE: a framework for evaluating spoken dialogue agents,\" in\r\n    Proc. of the 8th EACL.Morristown, NJ, USA: ACL, 1997, pp.271-280.\r\n[4] A. Schmitt, B. Schatz, and W. Minker, \"Modeling and predicting\r\n    quality  in  spoken  human-computer interaction,\"  in Proc.  of  the\r\n    12th SIGDial Conference. Portland, Oregon, USA: ACL, Jun. 2011,\r\n    pp. 173-184.\r\n\r\nDétail de la mission :\r\n\r\nL\'objectif de votre travail de recherche sera de :\r\n- Analyser le corpus DATCHA et ses annotations.\r\n- Trouver les caractéristiques importantes pour la satisfaction de\r\n  l\'utilisateur. (voir les caractéristiques extraites par les modèles\r\n  présents dans [2]).\r\n- Implémenter une régression avec deep learning pour calculer l\'impact\r\n  de métriques objectives (les caractéristiques identifiées dans l\'étape\r\n  précédente) sur la satisfaction de l\'utilisateur.\r\n\r\nVous réaliserez vos travaux au sein d\'une équipe pluridisciplinaire\r\nmenant à la fois des activités de recherche et de développement\r\nlogiciel.\r\n\r\nProfil / Compétences :\r\nDans le cadre de votre formation bac+5 (école ingénieur ou master 2\r\ninformatique ou statistiques), vous êtes à la recherche d\'un stage de 6\r\nmois.\r\n- Vous avez des connaissances en statistiques et informatique.\r\n- Des connaissances en Python sont impératives.\r\n- Des connaissances en apprentissage statistique sont requises.'),
(507, '2018-10-22', 'CS', 'Le Plessis-Robinson', 'Stage - Extraction de grammaires à partir de banques d\'arbres (H/F) - Le Plessis-Robinson - CS\r\nPubliée le: 3/10/2018\r\n\r\nPartager avec:\r\n\r\nRésumé de l\'offre\r\n\r\n    Type de contrat:\r\n    Alternance / Stage\r\n    Lieu:\r\n    Le Plessis-Robinson\r\n\r\nDescription de l\'offre\r\n\r\nAvec 1800 collaborateurs pour un chiffre d\'affaires de 170 millions\r\nd\'euros en 2017, CS s\'affirme comme un concepteur, intégrateur et\r\nopérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense, de\r\nl\'Aéronautique, du Spatial, de l\'Énergie, du Transport, des secteurs\r\npublic et privé. CS réalise environ 80% de ses projets au forfait et\r\nest coté sur le marché Euronext Paris.\r\n\r\nAfin de renforcer notre équipe parisienne de la Business Unit Défense,\r\nSécurité & ATM, nous recherchons un stagiaire - Extraction de\r\ngrammaires à partir de banques d\'arbres (H/F)\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les pilotes au travers d\'échanges vocaux. Une des\r\nactivités de la BU DSA est de concevoir et de réaliser une gamme de\r\nproduits incluant systèmes de communication vocale (VCS),\r\nenregistreurs et simulateurs.\r\n\r\nDans ce contexte, nous souhaitons élaborer des analyseurs syntaxiques\r\ncouvrants en nous appuyant sur les grammaires STCG, qui sont des\r\ngrammaires de correspondances chaînes-arbres. Le stage aura pour but\r\nd\'étudier la faisabilité d\'un outil transformant une banque d\'arbres\r\nen une grammaire STCG probabilisée et la réalisation de cet outil.\r\n\r\nEn tant que stagiaire, vos missions seront les suivantes :\r\n\r\n- État de l\'art des grammaires (hors contexte, TAG...), statistiques ou\r\n  non, générées à partir de banques d\'arbres\r\n\r\n- Étude des banques d\'arbres disponibles pour le français (FTB,\r\n  Sequoia...) et de leur utilisabilité dans un cadre commercial\r\n\r\n- Développement d\'un outil transformant une banque d\'arbres en\r\n  grammaire STCG\r\n\r\n- Rédaction d\'un rapport\r\n\r\nProfil requis\r\n\r\nÉtudiant(e) en 4ème ou 5ème année d\'un cycle ingénieur ou équivalent,\r\nvous êtes à la recherche d\'un stage.\r\n\r\nVous disposez idéalement des compétences techniques suivantes :\r\n\r\n- Grammaires formelles\r\n- Banques d\'arbres\r\n\r\nPostuler en ligne : https://cs.jobs.net/fr-FR/job/stage-extraction-de-grammaires-a-partir-de-banques-darbres-h-f/J3Q3NF651S5V7PLNX6B'),
(508, '2018-10-22', 'CS', 'Le Plessis-Robinson', 'Stage - Couplage vision-audio pour reconnaissance vocale (H/F) - Le\r\nPlessis-Robinson - CS\r\n\r\nPubliée le: 3/10/2018\r\nRésumé de l\'offre\r\n\r\n    Type de contrat:\r\n    Alternance / Stage\r\n    Lieu:\r\n    Le Plessis-Robinson\r\n\r\nDescription de l\'offre\r\n\r\nAvec 1800 collaborateurs pour un chiffre d\'affaires de 170 millions\r\nd\'euros en 2017, CS s\'affirme comme un concepteur, intégrateur et\r\nopérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense, de\r\nl\'Aéronautique, du Spatial, de l\'Énergie, du Transport, des secteurs\r\npublic et privé. CS réalise environ 80% de ses projets au forfait et\r\nest coté sur le marché Euronext Paris.\r\n\r\nAfin de renforcer notre équipe parisienne de la Business Unit Défense,\r\nSécurité & ATM, nous recherchons un stagiaire - Couplage vision-audio\r\npour reconnaissance vocale (H/F)\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les pilotes au travers d\'échanges vocaux. Une des\r\nactivités de la BU DSA est de concevoir et de réaliser une gamme de\r\nproduits incluant systèmes de communication vocale (VCS),\r\nenregistreurs et simulateurs.\r\n\r\nDans ce contexte, nous souhaitons évaluer ce qu\'une exploitation\r\nmultimodale peut apporter à la qualité du signal de parole issu d\'un\r\nmicrophone intelligent et à la connaissance de l\'état émotionnel des\r\nlocuteurs. En particulier, les pistes suivantes seront étudiées :\r\n\r\n- traitement de l\'audio : reconnaissance du locuteur, émotions...\r\n- vision par ordinateur : identification du locuteur, lecture labiale....\r\n\r\n \r\n\r\nEn tant que stagiaire, vos missions seront les suivantes :\r\n\r\n - Faire un état de l\'art des traitements pouvant aider à :\r\n    - améliorer le signal vocal issus de microphones intelligents\r\n        (localisation des locuteurs, évaluer son état émotionnel...)\r\n    - évaluer l\'état émotionnel des locuteurs (énervement...)\r\n\r\n- Implémenter sur une plate-forme ARM (Raspberry Pi 3B)\r\n\r\n    - les solutions de vision permettant de commander les microphones\r\n  (direction pour le beamforming)\r\n\r\n    - toute autre solution identifiée lors de l\'état de l\'art et\r\n      pouvant améliorer la qualité du signal audio, par exemple dans\r\n      le cas où plusieurs personnes parlent simultanément\r\n\r\n- Rédaction d\'un rapport\r\n\r\nProfil requis\r\n\r\nÉtudiant(e) en 4ème ou 5ème année d\'un cycle ingénieur ou équivalent,\r\nvous êtes à la recherche d\'un stage.\r\n\r\nVous disposez idéalement des compétences techniques suivantes :\r\n\r\n- Traitement du signal\r\n- Vision par ordinateur\r\n\r\nPostuler :\r\nhttps://cs.jobs.net/fr-FR/job/stage-couplage-vision-audio-pour-reconnaissance-vocale-h-f/J3V4JP75MLXMD5JK87Z'),
(509, '2018-10-22', 'CS', 'Le Plessis-Robinson', 'Stage - Liens entre les bases lexicales riches du français et Wordnet\r\n& UNL (H/F) - Le Plessis-Robinson - CS\r\n\r\nPubliée le: 3/10/2018\r\n\r\nRésumé de l\'offre\r\n\r\n    Type de contrat:\r\n    Alternance / Stage\r\n    Lieu:\r\n    Le Plessis-Robinson\r\n\r\nDescription de l\'offre\r\n\r\nAvec 1800 collaborateurs pour un chiffre d\'affaires de 170 millions\r\nd\'euros en 2017, CS s\'affirme comme un concepteur, intégrateur et\r\nopérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense, de\r\nl\'Aéronautique, du Spatial, de l\'Énergie, du Transport, des secteurs\r\npublic et privé. CS réalise environ 80% de ses projets au forfait et\r\nest coté sur le marché Euronext Paris.\r\n\r\nAfin de renforcer notre équipe parisienne de la Business Unit Défense,\r\nSécurité & ATM, nous recherchons un stagiaire - Liens entre les bases\r\nlexicales riches du français et Wordnet & UNL (H/F)\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les pilotes au travers d\'échanges vocaux. Une des\r\nactivités de la BU DSA est de concevoir et réaliser une gamme de\r\nproduits incluant systèmes de communication vocale (VCS),\r\nenregistreurs et simulateurs.\r\n\r\nDans ce contexte, nous souhaitons élaborer une base de données\r\nlexicales riche et couvrante pour le français, en nous appuyant sur\r\ndes ressources libres disponibles comme le LVF et le DEM, NooJ ou\r\nencore Apertium. Devant à terme être liées à d\'autres langues, nous\r\nsouhaitons que les entrées de cette base de données soient reliées aux\r\nsynsets de Wordnet et aux UW d\'UNL.\r\n\r\nLe stagiaire participera aux tâches suivantes :\r\n\r\n- Faire un état de l\'art des ressources libres du français\r\n\r\n- Réaliser une base de données lexicale en Sqlite à partir d\'un\r\n  ensemble cohérent de ressources libres\r\n\r\n- Relier les entrées de la base de données obtenue aux synsets Wordnet\r\n  et aux UW UNL\r\n\r\n- Rédaction d\'un rapport\r\n\r\nProfil requis\r\n\r\nÉtudiant(e) en 4ème ou 5ème année d\'un cycle ingénieur ou équivalent,\r\nvous êtes à la recherche d\'un stage.\r\n\r\nVous disposez idéalement des compétences techniques suivantes :\r\n\r\n- Morphologie\r\n- Lexicologie\r\n- Sémantique (Wordnet, UNL)\r\n- Bases de données lexicales\r\n\r\nPostuler : \r\nhttps://cs.jobs.net/fr-FR/job/stage-liens-entre-les-bases-lexicales-riches-du-francais-et-wordnet-unl-h-f/J3S3PS6TBCN451RG0QD'),
(510, '2018-10-22', 'CS', 'Paris', 'Stage - Conception et réalisation d\'une ontologie spécialisée (H/F) - Paris - CS\r\nPubliée le: 11/10/2018\r\n\r\nRésumé de l\'offre\r\n\r\n    Type de contrat:\r\n    Alternance / Stage\r\n    Lieu:\r\n    Paris\r\n\r\nDescription de l\'offre\r\n\r\nAvec 1800 collaborateurs pour un chiffre d\'affaires de 170 millions\r\nd\'euros en 2017, CS s\'affirme comme un concepteur, intégrateur et\r\nopérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense, de\r\nl\'Aéronautique, du Spatial, de l\'Énergie, du Transport, des secteurs\r\npublic et privé. CS réalise environ 80% de ses projets au forfait et\r\nest coté sur le marché Euronext Paris.\r\n\r\nAfin de renforcer notre équipe parisienne de la Business Unit Défense,\r\nSécurité & ATM, nous recherchons un stagiaire -Conception et\r\nréalisation d\'une ontologie spécialisée (H/F).\r\n\r\nDans le domaine du contrôle du trafic aérien, les contrôleurs\r\ninteragissent avec les pilotes au travers d\'échanges vocaux. Dans la\r\ncadre de la BU Défense, Sécurité & ATM, CS conçoit et réalise une\r\ngamme de produits incluant systèmes de communication vocale (VCS),\r\nenregistreurs et simulateurs.  Dans ce contexte, nous souhaitons\r\ndévelopper une ontologie couvrant nos principaux produits.\r\n\r\nLes missions du stagiaire seront les suivantes :\r\n\r\n- Faire un état de l\'art des éditeurs d\'ontologies, des outils pour\r\n  les construire et les stocker, et des moteurs d\'inférence permettant\r\n  de les interroger\r\n\r\n- Comparer les intérêts respectifs de langages contrôlés tels que ACE\r\n  et SBVR par rapport aux langages d\'ontologies, pour opérer des\r\n  raisonnements\r\n\r\n- Faire un état de l\'art des langages d\'ontologies utilisables et\r\n  faire un choix justifié d\'un langage et d\'un éditeur d\'ontologie\r\n\r\n- Recueillir le vocabulaire (avec sa sémantique) et les règles,\r\n  souvent implicites, pour une partie restreinte du domaine\r\n\r\n- Choisir un ou plusieurs raisonneurs pour les tests\r\n\r\n- Définir un jeu de questions et tester l\'ontologie créée en utilisant\r\n  des raisonneurs\r\n\r\nProfil requis\r\n\r\nÉtudiant(e) en 4ème ou 5ème année en informatique, école d\'ingénieur\r\nou équivalent universitaire, vous êtes à la recherche d\'un stage ou\r\nd\'une alternance.\r\n \r\nVous disposez idéalement des compétences techniques suivantes :\r\n\r\n- Ontologies\r\n\r\n- Logiques (commune, premier ordre, description ...)\r\n\r\n- Langages formels\r\n\r\nPostuler : https://cs.jobs.net/fr-FR/job/stage-conception-et-realisation-d%E2%80%99une-ontologie-specialisee-h-f/J3T51Y6MXQHF6VKP28W'),
(511, '2018-10-22', 'CS', 'Paris', 'Stage - Maquettage de déconvertisseur UNL (H/F) - Paris - CS\r\nPubliée le: 2/10/2018\r\n\r\nRésumé de l\'offre\r\n\r\n    Type de contrat:\r\n    Alternance / Stage\r\n    Lieu:\r\n    Paris\r\n\r\nDescription de l\'offre\r\n\r\nAvec 1800 collaborateurs pour un chiffre d\'affaires de 170 millions\r\nd\'euros en 2017, CS s\'affirme comme un concepteur, intégrateur et\r\nopérateur de systèmes critiques de tout premier plan. Nos clients\r\neuropéens et mondiaux sont dans les secteurs de la Défense, de\r\nl\'Aéronautique, du Spatial, de l\'Énergie, du Transport, des secteurs\r\npublic et privé. CS réalise environ 80% de ses projets au forfait et\r\nest coté sur le marché Euronext Paris.\r\n\r\nAfin de renforcer notre équipe parisienne de la Business Unit Défense,\r\nSécurité & ATM, nous recherchons un stagiaire - Maquettage de\r\ndéconvertisseur (H/F).\r\n\r\nUne des activités de la BU DSA est de créer des déconvertisseurs du\r\nfrançais et de l\'anglais performants. Ces programmes, basés sur le\r\nframework de traduction automatique Ariane, génèrent du texte en\r\nfrançais et en anglais à partir d\'une représentation interlingue\r\nunique exprimée sous forme de graphes UNL.\r\n\r\nVotre mission consistera à réaliser des déconvertisseurs pour le\r\nfrançais et l\'anglais, et de les évaluer sur un corpus de test. Pour\r\ncela,\r\n\r\n- Vous vous familiariserez avec les notions le langage UNL, les\r\n  langages de programmation linguistiques Ariane (EXPANS, ROBRA et\r\n  SYGMOR), la maquette existante de déconversion du français et la\r\n  nouvelle génération structurale.\r\n\r\n- Vous vous appuyerez sur une maquette existante de déconversion du\r\n  français. L\'apport essentiel sera de remplacer la génération\r\n  syntaxique actuelle par une génération syntaxique plus performante\r\n  [Chappuy, 2011b]. Cette substitution nécessitera de mettre en\r\n  cohérence le jeu de variables de cette nouvelle génération\r\n  syntaxique avec :\r\n\r\n    -  en amont celui provenant du dictionnaire UNL-FR,\r\n    -  en aval celui attendu par la génération morphologique du français.\r\n\r\n- Enfin, il s\'agira de faire le point sur les éditeurs de graphes UNL\r\n  disponibles et d\'écrire les graphes UNL d\'une partie représentative\r\n  des phrases d\'un corpus fourni par CS.\r\n\r\nProfil requis\r\n\r\nÉtudiant(e) en 4ème ou 5ème année, école d\'ingénieur ou équivalent\r\nuniversitaire, vous êtes à la recherche d\'un stage ou une alternance\r\nde 6mois.\r\n \r\nVous disposez idéalement des compétences techniques suivantes :\r\n\r\n- Traitement automatique des langues, syntaxe, sémantique, morphologie,\r\n- C/C++ \r\n- Python\r\n\r\nPostuler : \r\nhttps://cs.jobs.net/fr-FR/job/stage-maquettage-de-deconvertisseur-unl-h-f/J3V53S6J9PSY9P8VM1Z'),
(513, '2018-10-29', 'CEA', 'Palaiseau', 'Offre Stage Master 2 / ingénieur\r\n\r\nTitre du stage: Apprentissage à partir de connaissances incertaines pour\r\nl\'annotation automatique de textes\r\n\r\nMots-clés : apprentissage automatique, traitement automatique des\r\nlangues, réseau de neurones, adaptation au domaine\r\n\r\nLieu : CEA (NanoInnov, Palaiseau)\r\n\r\nDurée : 4 à 6 mois\r\nDate de début : printemps 2019\r\n\r\nLaboratoire d\'accueil:\r\nAu coeur du Plateau de Saclay (Ile-de-France), l\'institut CEA LIST\r\nfocalise ses recherches sur les systèmes numériques intelligents. A sein\r\nde cet institut, le LVIC (Laboratoire de Vision et d\'Ingénierie des\r\nContenus) mène ses recherches dans les domaines de la Vision par\r\nOrdinateur (Computer Vision) et l\'analyse automatique de texte avec le\r\ndéfi d\'extraire et d\'organiser l\'information à partir de documents\r\nfaiblement ou non structurés (texte, image, vidéo, réseaux de capteurs).\r\n\r\nContexte du stage:\r\nLes investissements en recherche dans Le traitement automatique du\r\nlangage sont en très grande croissance pour deux raisons principales:\r\n\r\n- l\'abondance des données, le \'big data\', suscite la convoitise de\r\n  beaucoup d\'opérateurs mais toute la partie non structurée de ces\r\n  données ne peut être véritablement exploitée qu\'avec un traitement\r\n  linguistique de base.\r\n  \r\n- de très grands progrès ont été réalisés récemment grâce aux techniques\r\n  d\'apprentissage et en particulier celles à base de réseau de neurones\r\n  en s\'appuyant sur les représentation distribuées des mots ou word\r\n  embeddings (1).\r\n  \r\nLes applications de ces technologies sont multiples dans la société du\r\nnumérique : moteur de recherche, traduction automatique, outils de\r\nveille ou de recommandations... Ce stage s\'inscrit dans les activités de\r\nTraitement Automatique du Langage du Laboratoire Vision et Ingénierie\r\ndes Contenus du CEA List. Le laboratoire développe sa propre technologie\r\nd\'analyse du texte qui est diffusée en open source avec la plate-forme\r\nLima : https://github.com/aymara/lima.\r\n\r\nSujet du stage:\r\n\r\nLes systèmes de traitement linguistique ont largement adopté les\r\ntechnique d\'apprentissage supervisé : à partir de corpus annoté\r\n(c\'est-à-dire des textes pour lesquels des spécialistes de la langue ont\r\nannoté chaque mot avec des informations sur le découpage, sur la\r\nmorphologie, sur la structure de la phrase, etc.), le système apprend un\r\nmodèle qui lui permet d\'analyser des textes en entrée.\r\n\r\nQuand on ne dispose pas de corpus annoté pour une tâche d\'apprentissage\r\n(par exemple pour traiter une nouvelle langue) ni du budget pour le\r\nconstituer, on réalise de façon automatisée un corpus dit \"synthétique\"\r\npar exemple issus d\'une projection d\'annotation cross-lingue (2) ou par\r\nalignement d\'une base de connaissances sur le texte (3). Bien sûr, ces\r\ncorpus \"synthétiques\" contiennent des erreurs ou plutôt des incertitudes\r\nsur les annotations.\r\n\r\nL\'objectif du stage consiste à modéliser ces incertitudes et à les\r\nexploiter dans le processus d\'apprentissage et à évaluer les\r\namélioration des modèles produits. Les expérimentations se feront en\r\ns\'appuyant sur un framework de réseaux de neurones.\r\n\r\nTravail attendu:\r\n- Recherche bibliographique\r\n- Expérimentation d\'architecture innovantes à base de réseaux de\r\n  neurones et évaluation\r\n\r\nLe 1er sujet d\'expérimentation pourra être l\'annotation morphosyntaxique\r\npar projection directe sur un corpus bilingue aligné.\r\nL\'apprentissage et l\'évaluation se feront à partir de corpus annotés\r\nfournis.\r\n\r\nCompétences requises:\r\n- bonne maîtrise d\'un langage de programmation: C++ ou python\r\n- bonne connaissances en statistique et connaissance de base des\r\n  technologies d\'apprentissage\r\n\r\nLe goût pour les langues, le langage de façon générale et la capacité à\r\néchanger avec les autres est un plus.\r\n\r\nContacts:\r\nolivier.mesnard@cea.fr\r\n\r\nRéférences:\r\n\r\n(1) Ronan Collobert & al, 2011, Natural Language Processing (Almost)\r\n    from Scratch\r\n\r\n(2) Jörg Tiedemann and Zeljko Agic,  2016. Synthetic treebanking for\r\n    cross-lingual dependency parsing\r\n\r\n(3) Raphael Hoffmann & al 2011.  Knowledge-based weak supervision for\r\n    information extraction of overlapping relations'),
(514, '2018-10-29', 'Orange Labs', 'Lannion', 'Intitulé du stage : « Extraction non-supervisée des bases de\r\nconnaissances à partir d\'un corpus de Dialogue.»\r\n\r\nEntité : Orange Labs (Lannion). Equipe NADIA (Natural Language Dialogue)\r\nContact : Lina Rojas (linamaria.rojasbarahona@orange.com)\r\n\r\n\r\nSynthèse de la mission :\r\n\r\nLe corpus DATCHA est une collection de conversations entre les\r\nopérateurs et les clients du service d\'assistance du web chat Orange. Le\r\ncorpus comprend des annotations linguistiques: syntaxiques, sémantiques,\r\netc. [1].\r\n\r\nNéanmoins, il n\'y a pas d\'annotations qui décrivent le sujet de la\r\nconversation. Par exemple : le problème à résoudre, les étapes\r\nnécessaires au diagnostic et à la résolution du problème. Les ontologies\r\nspécifiques au domaine ont un rôle central dans les systèmes de\r\ndialogue.\r\n\r\nPlusieurs méthodes d\'apprentissage non supervisées ont été utilisées\r\npour le traitement automatique des langues : clustering, co-clustering\r\n[2], la sémantique distributionnelle [3], l\'analyse sémantique latente\r\n(LSA) [4], l\'allocation de Dirichlet latente (LDA) [5] ainsi que des\r\ntechniques de deep learning (Restricted Boltzmann Machines [6] et\r\nVariational Autoencoders [7]).\r\n\r\nL\'objectif de ce stage est d\'appliquer une méthode non supervisée de\r\ndeep learning pour l\'extraction des connaissances du domaine à partir du\r\ncorpus DATCHA et de la comparer aux autres solutions disponibles\r\n(co-clustering et LDA). Parmi les connaissances à extraire on trouvera\r\nles concepts qui décrivent les services, le script du diagnostic, les\r\nsolutions adoptées. Il sera tout à fait possible d\'utiliser les\r\nannotations disponibles comme les annotations en actes de dialogue.\r\n\r\n\r\n\r\n[1] Damnati, G., Guerraz, A. & Charlet, D. Web chat conversations from\r\ncontact centers: a descriptive study. In LREC (2016).\r\n\r\n[2] Boullé, M. Data grid models for preparation and modeling in\r\nsupervised learning. In Guyon, I., Cawley, G., Dror, G.  & Saffari,\r\nA. (eds.) Hands-On Pattern Recognition: Challenges in Machine Learning,\r\nvolume 1, 99-130 (Microtome Publishing, 2011).\r\n\r\n[3] Lund, K. & Burgess, C. Producing high-dimensional semantic spaces\r\nfrom lexical co-occurrence. Behav. research methods, instruments, &\r\ncomputers 28, 203-208 (1996).\r\n\r\n[4] Dumais, S. T. Latent semantic analysis. Annu. review information\r\nscience technology 38, 188-230 (2004).\r\n\r\n[5] Blei, D. M., Ng, A. Y. & Jordan, M. I. Latent dirichlet\r\nallocation. J. machine Learn. research 3, 993-1022 (2003).\r\n\r\n[6] Larochelle, H. & Bengio, Y. Classification using discriminative\r\nrestricted boltzmann machines. In Proceedings of the 25th international\r\nconference on Machine learning, 536-543 (ACM, 2008).\r\n\r\n[7] Kingma, D. P. & Welling, M. Auto-encoding variational bayes. arXiv\r\npreprint arXiv:1312.6114 (2013).\r\n\r\nDétail de la mission :\r\nL\'objectif de votre travail de recherche sera de :\r\n\r\n- Analyser le corpus DATCHA et ses annotations.\r\n- Implémenter une solution non supervisée du deep learning pour extraire\r\n  les concepts spécifiques aux domaines du DATCHA\r\n- Comparer votre modèle avec des solutions internes Orange\r\n  (co-clustering) ou disponibles dans les modules python (LDA).\r\n\r\nVous réalisez vos travaux au sein d\'une équipe pluridisciplinaire menant\r\nà la fois des activités de recherche et de développement logiciel.\r\n\r\nProfil / Compétences :\r\n\r\nDans le cadre de votre formation bac+5 (école ingénieur ou master 2\r\ninformatique ou statistiques), vous êtes à la recherche d\'un stage de 6\r\nmois.\r\n- Vous avez des connaissances en statistiques et informatique.\r\n- Des connaissances en Python sont impératives.\r\n- Des connaissances en apprentissage statistique sont requises.\r\n\r\n\r\nLina Rojas\r\nIMT/OLS/DIESE/DIA/NADIA\r\nSenior Research Engineer/Ingénieure de recherche senior IA&Dialogue\r\ntél. +33 (0)2 96 07 04 10\r\nlinamaria.rojasbarahona@orange.com'),
(515, '2018-11-05', 'Naver Labs', 'Grenoble', 'Master/PhD Internship - Deep Machine Reading\r\n\r\n \r\n\r\nNAVER LABS Europe\'s mission is to advance the state-of-the-art in\r\nAmbient Intelligence, while paving the way for these innovations into\r\na number of NAVER flagship products and services. This includes\r\nresearch in models and algorithms to give humans faster and better\r\naccess to data and to allow them to interact with technology in\r\nsimpler and more natural ways.\r\n\r\nIn this context, the field of Machine Reading has recently emerged as\r\na possible continuation of the tasks of Natural Language\r\nProcessing. Given a large set of passages of text associated with\r\nquestions and answers, our goal consists of learning a question\r\nanswering system solely from these examples. As research groups\r\ndedicated to Machine Reading around the globe have started to produce\r\nencouraging results, this task challenges our current understanding of\r\ndeep learning and machine comprehension.\r\n\r\nIn this internship, the successful candidate will be involved in the\r\ndesign and development of novel models for machine comprehension\r\napplied at the scale of NAVER in the context of electronic\r\nencyclopedia and social media understanding. Finally, at NAVER LABS we\r\nencourage participation in the academic community. Our researchers\r\ncollaborate closely with universities and regularly publish in venues\r\nsuch as ACL, EMNLP, KDD, SIGIR, ICML and NIPS.\r\n\r\nRequirements\r\n\r\n- Master and/or Ph.D. in machine learning with a strong interest in\r\n    Deep Learning.\r\n\r\n- Knowledge of statistical and deep learning application to NLP.\r\n\r\n- Strong development skills of relevant frameworks like pytorch and/or\r\n  tensorflow.\r\n\r\nReferences\r\n\r\n    Gated End-to-End Memory Networks , Fei Liu and Julien Perez, EACL\r\n    2017\r\n    \r\n    Dialog State Tracking, a machine reading approach using memory\r\n    networks , Julien Perez and Fei Liu, EACL 2017\r\n    \r\n    ReviewQA: a relational aspect-based opinion reading dataset ,\r\n    Quentin Grail and Julien Perez, CAP\'2018\r\n\r\nStart Date ASAP\r\nDuration 6 months minimum\r\n\r\nApplication instructions\n\n\r\nTo submit an application, please send your CV, cover letter and the\r\nnames of at least two references to julien.perez@naverlabs.com and\r\ndl_candidates@naverlabs.com'),
(516, '2018-11-05', 'Naver Labs', 'Grenoble', 'Meal Finder: fine grained information extraction from web-scale image database\r\n\r\n \r\n\r\nDoes a restaurant have your favourite dish? What\'s the price of this\r\ndish? Have they vegetarian options? Do they have a kid\'s menu?\r\n\r\nWhen looking for a restaurant, all these common questions are not\r\nnecessarily answered by your favourite search application or social\r\nweb portal So, as a user, when you have found a nice restaurant, you\r\nusually end up using additional sources of information to answer these\r\nquestions, because the data is not available directly or in an easy\r\nway. A great place to look at is directly on the restaurant\'s website,\r\nto see if they provide additional information (like an updated menu).\r\n\r\nThe goal of this internship is to investigate how to facilitate this\r\nInformation Retrieval task by automatically enriching a restaurant\r\ndatabase with unstructured information available on the Internet.\r\n\r\nThe student will have to help design and implement an information\r\nextraction tool for restaurant menus. More precisely, the tool should\r\nbe able to structure a menu, from an image representation, into its\r\nmain structures and sections, extracting first information on dishes\r\n(name, description, price(s)) or on the restaurant itself (address,\r\nopening hours, phone number).\r\n\r\nThe student will work with a multi-disciplinary team with expertise in\r\nComputer Vision, OCR, Document Structure Analysis and Information\r\nExtraction . A production database gathering more than 100 million\r\nplaces, the associated user reviews, images and menus will be\r\navailable to test and develop the system. At Naver Labs Europe we\r\nencourage participation in the academic community and our researchers\r\npublish regularly at top venues in NLP, machine learning and computer\r\nvision.\r\n\r\nStart Date asap\r\nDuration 5-6 months\r\n\r\nApplication instructions\r\n\r\n- Student at Master (research-oriented) or PhD level.\r\n- Knowledge of neural networks models and Conditional Random Fields\r\n- Good coding skills in Python\r\n\r\nhttp://www.europe.naverlabs.com/NAVER-LABS-Europe/Internships/Meal-Finder-fine-grained-information-extraction-from-web-scale-image-database'),
(517, '2018-11-05', 'Naver Labs', 'Grenoble', 'Honest Product Reviews\r\n\r\n \r\n\r\nAn increasing amount and value of information about products and\r\nplaces is stored in collections of user reviews. This information is\r\nmessy, often contradictory or redundant but taken together hides\r\ntroves of insights that users without time to read them all are\r\ninterested in.\r\n\r\nIn this internship you will explore recent summarization techniques\r\nand apply them to the problem of creating a unified review which\r\nreflects that wisdom of the crowd.\r\n\r\nAt Naver Labs Europe you will interact with researchers working in the\r\nlatest developments of machine learning and natural language\r\nprocessing, apply them to our data using our GPU cluster. We regularly\r\npublish in top conferences, release data-set and otherwise interact\r\nwith our academic collaborators.\r\n\r\n \r\n\r\nRequirements\r\n\r\n- PhD or Master (research-oriented) level\r\n- Knowledge of deep learning as applied to NLP\r\n- Good coding skills, including at least one the major deep learning\r\ntoolkits (preferably pytorch)\r\n\r\nDuration 5-6 months\r\n\r\nApplication instructions\r\n\r\nTo apply, please send a mail with CV and cover letter to\r\nmatthias.galle@naverlabs.com');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(518, '2018-11-05', 'GeoTrend', 'Toulouse', 'Offre de Stage de Master / Fin d\'étude Ingénieur :\r\n\r\nExtraction de relations économiques à partir du texte\r\n\r\n\r\n\r\n  * Cadre du stage\r\n\r\nLa société GeoTrend développe une plateforme innovante de « Business\r\nDiscovery » permettant de donner une vision rapide et complète sur\r\nn\'importe quel marché économique. Cette plateforme analyse en temps réel\r\ndes milliers de pages web pour extraire les principaux acteurs du\r\nmarché, les relations qui les lient (partenariat, compétition, etc.) et\r\nde nombreuses \'autres informations utiles à la compréhension du marché\r\ncible. Le coeur de notre métier consiste donc à développer des briques de\r\nTraitement Automatique du Langage et de Machine Learning et de les faire\r\ntourner sur des plateformes de Cloud Computing. Ce stage permettra de\r\ntravailler à la fois sur des problématiques scientifiques récentes et\r\nsur des technologies de pointe. Nous souhaitons proposer ce stage en\r\ncollaboration avec l\'équipe MELODI du laboratoire IRIT de Toulouse. Une\r\npoursuite dans le cadre d\'une thèse CIFRE est envisagée sur la base des\r\nmêmes problématiques.\r\n\r\n\r\n  * Objectifs\r\n\r\nL\'objectif du stage est d\'améliorer le système d\'extraction de relations\r\nactuel qui se base uniquement sur des règles expertes en proposant un\r\nnouveau modèle de Machine Learning.\r\n\r\nUn data-set d\'environ 2000 phrases a été annoté manuellement pour aider\r\nle stagiaire dans cette tâche. Ce data-set pourra être utilisé pour\r\névaluer de manière précise le modèle proposé mais ne suffira pas à\r\nconstituer un corpus d\'apprentissage. En effet, les modèles de Machine\r\nLearning récents (particulièrement les Réseaux Neurones) nécessitent\r\nbeaucoup de données d\'apprentissage. Des travaux récents proposent donc\r\nde construire ces corpus de manière automatique en utilisant des règles\r\nou des bases de connaissances externes (Ratner et al. 2016; Ratner et\r\nal. 2018). Les labels ainsi produits contiennent du bruit mais on peut\r\nmodéliser les erreurs commises par ces différentes règles pour améliorer\r\nles résultats.\r\n\r\nLa première étape du stage consistera à faire un état de l\'art plus\r\napprofondi sur l\'extraction de relations. Une piste ou plusieurs seront\r\nensuite retenues pour être mises en oeuvre, évaluées et comparées.\r\n\r\n\r\n* Compétences recherchées\r\n\r\n  * Modèles de Machine Learning (SVM, LSTM, etc.)\r\n  * Intérêt pour le Traitement Automatique du Langage (analyse\r\n    syntaxique, word embeddings, etc.)\r\n  * Frameworks: python, sklearn, ...\r\n\r\n\r\n* Contacts :\r\n\r\n  * Grégoire Sigel, gregoire@geotrend.fr\r\n  * Farah Benamara, Benamara@irit.fr <mailto:Benamara@irit.fr>\r\n\r\n\r\n* Conditions:\r\n\r\n  * Localisation : Toulouse, dans les locaux de Geotrend et\r\n    ponctuellement à l\'IRIT.\r\n  * Date de démarrage : à partir de février 2019\r\n  * Durée : de 4 à 6 mois\r\n  * Indemnité : Indemnité légale\r\n  * Suite envisagée en Thèse CIFRE\r\n  * Ressources bibliographiques\r\n\r\nRatner, Alexander, Stephen H. Bach, Henry R. Ehrenberg, et\r\nal.2018Snorkel: Rapid Training Data Creation with Weak\r\nSupervision. InVLDB.\r\n\r\nRatner, Alexander J, Christopher M De Sa, Sen Wu, Daniel Selsam, and\r\nChristopher Ré2016Data Programming: Creating Large Training Sets,\r\nQuickly. InNIPS pp. 3567-3575.\r\n\r\n*Grégoire Sigel*\r\nCTO & Co-foundeur, Geotrend\r\n+33(0)6 26 98 16 84 gregoire@geotrend.fr\r\nwww.geotrend.fr\r\nAirbus BizLab 57 Avenue Jean Monnet, 31770 Colomiers'),
(519, '2018-11-05', 'Botfuel', 'Paris', '6 Month NLP Internship Offer\r\n\r\nBotfuel (www.botfuel.io) is a Paris-based startup specialized in\r\nchatbots and conversational intelligence. We are looking for an intern\r\nto join our NLP team, starting in the spring of 2019 (the exact date is\r\nflexible and depends on your school/academic constraints). Please see\r\nbelow for the internship details.\r\n\r\nIf you are interested or have any questions, please do not hesitate to\r\ncontact Zorana Ratkovic, Lead NLP Engineer (zorana@botfuel.io).\r\n\r\nNLP Internship Offer\r\n\r\nThe Company\r\n\r\nBotfuel (www.botfuel.io) specializes in chatbots and conversational\r\nintelligence. We offer a chatbot-building framework for enterprises\r\nlooking to automate customer relationships by deploying conversational\r\nservices/chatbots at scale. Since 2016, we have been developing Natural\r\nLanguage Processing (NLP) technologies in order to provide our customers\r\nwith a great conversational experience.\r\n\r\nThe Internship\r\n\r\nAt Botfuel, we develop Natural Language Understanding (NLU) services in\r\norder to understand and interpret user utterances and requests. The NLP\r\nteam works on a variety of dialog-related problems, such as intent\r\nclassification, information extraction and coreference resolution.\r\n\r\nWhat you\'ll be doing:\r\n\r\n   - Researching, developing, testing and deploying NLP methods in order\r\n     to improve the quality of Botfuel\'s NLU services\r\n   - Collaborating with other member of the NLP team, including\r\n     researchers, engineers and computational linguists\r\n\r\nWho You Are\r\n\r\n   - Pursuing an Engineering degree or a Masters degree in Artificial\r\n     Intelligence, Data Science, NLP, Machine Learning (ML) or a related\r\n     field\r\n   - Experience in Python\r\n   - Experience in NLP and/or ML\r\n   - Capacity to work independently, as well as collaborate within a\r\n     team\r\n   - Interest in chatbots/dialogs/NLU is a plus\r\n\r\nPractical Information\r\n   - Duration: 6 months, starting in spring 2019\r\n   - Location: Paris, France (75002)\r\n   - Remuneration: depending on experience\r\n\r\n\r\nIf you are interested, please send your CV to Zorana Ratkovic, our Lead\r\nNLP Engineer (zorana@botfuel.io).'),
(520, '2018-11-08', 'IRIT', 'Toulouse', '**Title**\r\n\r\nDetecting intentions during crisis events\r\n\r\n**Background and objectives**\r\n\r\nSocial media platforms offer great opportunities to identify public\r\ncommitments to intentions and desires/plans to act from user-generated\r\ncontents. Automatically detecting intentions can have many potential\r\napplications, such as in commerce marketing (consumption intentions:\r\nsell, purchase), security and defense (intention to attack, to connect\r\nto terrorist organizations), health (intention to suicide), and\r\nemergency management (intentions to help, evacuate). Mining intentions\r\nfrom texts can thus help decision makers to differentiate between\r\nintentional and non-intentional messages (\"I want to buy this great\r\nphone\" vs.\"Trump won the US election\") and to better identify the type\r\nof intention behind each message which is a primordial step to help\r\ncompanies, government, or institutions to better predict users\' future\r\nactions and thus improve their strategies.\r\n\r\nThe internship will focus on the development of an automatic intention\r\nmodel on social media data which will foster the ability of public\r\nservices to take action quicker in crisis situations, by monitoring\r\nuser\'s expectations and intents.\r\n\r\nThe internship is funded by the French Interior Department (no French\r\ncitizenship required) within a joint project between Institut de\r\nRecherche en informatique de Toulouse (IRIT-Toulouse University) and\r\nInstitut Jean Nicod (IJN-Ecole Normale Supérieure).\r\n\r\n**Candidate profile**\r\nThe successful candidate will have one of the following profile:\r\n- Msc or MA student in Computer Science, or Computational Linguistics.\r\n- Experience in Natural Language Processing, and/or Machine Learning;\r\n\r\n**Terms of the internship position**\r\n- Duration: 5 months\r\n- Starting date: from February to April 2019\r\n- Location: IRIT, Toulouse University (France),\r\n\r\n**Applications**\r\n- A curriculum vitae together with a motivation letter should be sent to\r\nFarah Benamara (farah.benamara@irit.fr), Véronique Moriceau\r\n(veronique.moriceau@irit.fr) and Alda Mari (alda.mari29@gmail.com)\r\n- Deadline for applications: position open until filled.'),
(521, '2018-11-12', 'Linagora', 'Toulouse', 'Poste : Stage détection et formalisation des intentions dans les\r\nemails\r\n\r\nRéf. : Stage-2018-AssistantEmailIntentionDetection\r\n\r\nContrat : Stage de Fin d\'études\r\n\r\nDate de démarrage : ASAP (durée 6 mois)\r\n\r\nMots-clés : Intention dans les emails, Traitement Automatique des\r\nLangues, Sémantique\r\n\r\nGrâce à la compétence technique et l\'engagement de ses 160\r\ncollaborateurs, LINAGORA est aujourd\'hui le leader français sur le\r\nmarché très porteur du Logiciel Libre.  Nos clients sont en majorité\r\ndes grands comptes, public et privé.\r\n\r\nNotre métier :\r\n\r\n- L\'édition de logiciels Open-Source innovants et répondant aux\r\nbesoins actuels et futurs du marché (bureau virtuel, assistant\r\nintelligent pour l\'entreprise, middleware SOA, sécurité, gestion des\r\nidentités).\r\n\r\n- La prestation de services pour accompagner les grands projets\r\nOpen-Source : conseil, intégration/développement, maintenance,\r\nformation des utilisateurs.\r\n\r\nLinagora est présent en France (Paris, Marseille, Toulouse, Lyon) au\r\nVietnam (Hanoï), Quebec et Tunisie (Tunis).  Linagora participe à\r\ndiférent projets de recherche Européens H2020 (C2Net) et Français /\r\nPSPC (OpenPaaS).\r\n\r\nNos principaux axes de recherche concernent la reconnaissance et la\r\ncompréhension de la parole, le « text mining », les architectures\r\nmiddleware distribuées, le Cloud Computing, l\'ingénierie\r\ncollaborative, la sécurité, les architectures Big-Data et les\r\ncommunautés open-source.\r\n\r\nCONTEXTE\r\n\r\nLa société Linagora (http://linagora.com) propose dans le cadre de son\r\nprojet de recherche Open-PaaS:NG des outils open-source innovants pour\r\naméliorer le travail collaboratif en entreprise. La plate-forme\r\nOpenPaaS (http://open-paas.org) est un outil de travail collaboratif\r\nproposant plusieurs services tels que : gestion des mails et des\r\nagendas partagés, édition collaborative temps-réel de documents, chat\r\net réseau social d\'entreprise.\r\n\r\nDans ce contexte, nous nous intéressons au module de gestion des\r\nmails. Nous voulons enrichir ce module avec des fonctionnalités de\r\nrecommandations à l\'utilisateur qui s\'appuient sur des techniques\r\nsémantiques et des techniques de machine learning.\r\n\r\nMISSION\r\n\r\nVous serez intégré au Linagora Labs (https://research.linagora.com) au\r\nsein d\'une équipe de recherche pluridisciplinaire à forte composante\r\nIntelligence Artifcielle, pour améliorer un module d\'identifcation et\r\nde formalisation des intentions dans les emails. Une intention est le\r\nbut véhiculé par le mail. Nous nous focaliserons sur :\r\n\r\n1. l\'identifcation et la formalisation des intentions dans des\r\néchanges emails répétitifs (comme la prise de rdv, les échanges de\r\npièces jointes, l\'envoi de candidatures, les appels d\'ofres, etc.).\r\n\r\n2.  Pour chaque intention identifée, la ou les canevas des réponses\r\nnécessaires pour répondre à l\'intention.\r\n\r\nPlus précisément, Linagora a développé un module smart reply\r\n(https://ci.linagora.com/zsellami/automatic-email-answering)\r\npermettant de proposer des réponses aux emails de RDV. L\'identifcation\r\ndes intentions s\'appuie sur une approche symbolique qui consiste à\r\nrechercher dans le texte des éléments linguistiques (verbes, syntagmes\r\nnominaux, entités nommées) qui manifeste un RDV. La formalisation de\r\nces intentions est intégrée dans une ontologie en utilisant les\r\nprincipes du formalisme FrameNet\r\n(http://asfalda.linguist.univ-paris-diderot.fr/frameIndex.xml).\r\n\r\nLa notion principale de FrameNet est le cadre conceptuel (Frame). Dans\r\nnotre cas, un Frame correspondra a une intention. Chaque Frame\r\ncomportera :\r\n\r\n1.  des unités lexicales qui indique la présence d\'une intention dans\r\nun mail ou un sous-ensemble de phrases dans le mail (exemple, propose\r\nun rdv, convenir à un rdv, changer de date de réunion, etc.)\r\n\r\n2.  des rôles à instancier dans le Frame. Par exemple, pour un Frame\r\nde suggestion de disponibilités, les dates/heures auront le rôle\r\ncréneau dans ce Frame.\r\n\r\nPROFIL\r\n\r\nVous êtes issu d\'une formation supérieure bac+5 et êtes en recherche\r\nd\'un stage de fn d\'étude.\r\n\r\nVous disposez de :\r\n\r\n1. Bonnes compétences en linguistique et en analyses de corpus\r\ntextuels.\r\n\r\n2. Bonnes compétences en programmation Python ou Java.\r\n\r\n3. Bonnes connaissances et compétences en Traitement Automatique des\r\nLangues. La maîtrise d\'un ou de plusieurs dependency parser (comme\r\ncore nlp, spacy python, GATE, etc.) et extracteurs d\'entités nommées\r\n(comme Gate, DBPedia spotlight, Duckling Facebook, etc.) serait un\r\nplus ;\r\n\r\nVous saurez vous montrer passionné, rigoureux ainsi que faire preuve\r\nd\'autonomie. Vous avez un goût certain pour la découverte et\r\nl\'expérimentation, vous êtes force de proposition et êtes capable\r\nd\'argumenter vos choix techniques. Vous partagez notre choix de\r\nprivilégier des logiciels libres et de contribuer aux communautés\r\nd\'utilisateurs (listes, FAQ, HOWTO).\r\n\r\nINFORMATIONS PRATIQUES\r\n\r\nContacts\r\n\r\nZied Sellami ou Jean-Pierre Lorré\r\n\r\nzsellami@linagora.com, jplorre@linagora.com\r\n\r\nLieu du stage - Durée Toulouse - 6 mois\r\n\r\nSociété Linagora\r\nWebsite : https://research.linagora.com / Twitter : @LinagoraLabs'),
(522, '2018-11-12', 'Linagora', 'Toulouse', 'Plateforme d\'exploration de contenu textuel\r\n\r\nRéf. : Stage-2018-NLP\r\n\r\nDurée : 6 mois\r\n\r\nDate de démarrage : ASAP 2018\r\n\r\nENVIRONNEMENT\r\n\r\nCréée en 2000, Linagora (http://linagora.com) se positionne\r\naujourd\'hui comme le leader français de l\'Open Source.  Son but est de\r\npromouvoir l\'Open Source auprès des institutions publiques et privées\r\net d\'accompagner ses clients vers leur indépendance numérique, en\r\nproposant des produits de haute qualité, fruit du travail de\r\ncollaborateurs passionnés.  En pleine croissance et déjà présente sur\r\nquatre continents, LINAGORA est à la recherche de nouveaux talents,\r\namoureux des technologies Libres et Open Source. Venez rejoindre une\r\néquipe chaleu- reuse et une ambiance stimulante !\r\n\r\nNotre métier :\r\n\r\n- L\'édition de logiciels Open-Source innovants et répondant aux\r\nbesoins actuels et futurs du marché (bureau virtuel, assistant\r\nintelligent pour l\'entreprise, middleware SOA, sécurité, gestion des\r\nidentités).\r\n\r\n- La prestation de services pour accompagner les grands projets\r\n  Open-Source : conseil, intégration/développement, maintenance,\r\n  formation des utilisateurs.\r\n\r\nCONTEXTE\r\n\r\nMots-clés : Traitement Automatique de la Langue (TAL) / Natural\r\nLaguage Processing (NLP), annotation sémantique, indexation,\r\nSolrTextTagger, Kibana, EalsticSearch, Open Linked Data\r\n\r\nLa société Linagora (http://linagora.com) propose dans le cadre de son\r\nprojet de recherche Open-PaaS:NG des outils open-source innovants pour\r\naméliorer le travail collaboratif en entreprise. La plate-forme\r\nOpenPaaS (http://open-paas.org) est un outil de travail collaboratif\r\nproposant plusieurs services tels que : gestion des mails et des\r\nagendas partagés, édition collaborative temps-réel de documents, chat\r\net réseau social d\'entreprise.\r\n\r\nDans ce contexte, nous nous intéressons aux ressources textuelles de\r\ncette plate-forme (emails, documents, pièces jointes dans les emails,\r\netc.). Nous voulons mettre en place un outil d\'extraction de données\r\nsémantiques (mots-clés, concepts et entités nommées) open-source.\r\n\r\nMISSION\r\n\r\nVous serez intégré au Linagora Labs (https://research.linagora.com) au sein d\'une équipe de re-\r\ncherche pluridisciplinaire à forte composante Intelligence Artificielle.\r\n\r\nLe contenu informationnel sous forme textuelle est prédominant dans\r\nl\'environnement des entreprises (mails, documents administratifs, CV,\r\ncomptes rendus de réunions, etc.). Ce type de contenu représente une\r\nsource riche en informations clés (chiffres clés de transactions, des\r\nadresses mails, des contacts, etc.).\r\n\r\nParadoxalement, ce contenu est rarement exploité :\r\n\r\n- En raison de la volumétrie usuelle de ces données, il est rarement\r\n  possible d\'exploiter manuellement ce contenu.\r\n\r\n- En raison de la complexité de la structuration des données\r\ntextuelles, les technique traditionnelles de fouille de données ne\r\npermettent pas d\'en réaliser un traitement automatisé.\r\n\r\nDans ce contexte, les outils de Traitement Automatique de la Langue\r\n(TAL / NLP) offrent une solution viable d\'exploration et\r\nd\'exploitation de contenus textuels. En effet, ils permettent\r\nd\'extraire du texte des indicateurs saillants (termes, relations\r\nlexicales, verbes, etc.). Pour cela, ces outils de TAL peuvent\r\ns\'appuyer sur des ressources externes comme des dictionnaires\r\nd\'entités nommées (Personnes, Lieux, Organisations) pour localiser des\r\nindices précis. C\'est ce que nous appelons l\'annotation de textes.\r\n\r\nDans le cadre de ce stage, nous nous intéresserons plus précisément à\r\nl\'utilisation de dictionnaires sémantique ouverts (Open Linked Data)\r\ncomme DBPedia, Wikidata, Yago et FreeBase pour annoter sémantiquement\r\ndes documents textuels.\r\n\r\n- Première objectif du stage : Tout d\'abord, le stagiaire devra\r\nrecenser les principales ressources de données ouvertes exploitables\r\net de mettre en place un outil d\'annotation sémantique capable\r\nd\'utiliser ces dictionnaires. La difficulté à lever est la volumétrie\r\ndes Open Linked Data (plusieurs millions d\'entrées) et la\r\ndésambiguïsation des annotations polysémiques (exemple : Paris comme\r\nVille et Paris comme une Personne) .\r\n\r\n- Deuxième objectif du stage : Le deuxième objectif du stage est de\r\nmettre en place un outil d\'exploration graphique des résultats de\r\nl\'outil d\'annotation. Pour cela le stagiaire réalisera un état des\r\nlieux de l\'existant, identifiant les outils d\'indexation et de\r\nvisualisation des indexes, tels que par exemple Kibana, solr,\r\nElasticSearch ... A l\'issu de ce travail, l\'outil cible sera choisit\r\ncollectivement Il devra définir des tableaux de bord à partir des\r\nCharts disponibles. La difficulté à lever est la création d\'un index\r\nSolr à partir des annotations extraites.\r\n\r\nPROFIL\r\n\r\nVous êtes issu d\'une formation supérieure bac+5 et êtes en recherche\r\nd\'un stage de fin d\'étude.\r\n\r\nVous disposez de :\r\n\r\n1. Bonnes compétences en programmation Python ou Java. Connaître le\r\nlangage Scala serait un plus ;\r\n\r\n2. Bonnes connaissances et compétences en Traitement Automatique des\r\nLangues. La maîtrise d\'un ou de plusieurs API (comme core nlp, spacy\r\npython, GATE, etc.) et extracteurs d\'entités nommées (comme Gate,\r\nDBPedia spotlight, Duckling Facebook, etc.) serait un plus ;\r\n\r\n3. Des compétences en Machine Learning et Deep learning seraient un\r\nplus.\r\n\r\nVous saurez vous montrer passionné, rigoureux ainsi que faire preuve\r\nd\'autonomie. Vous avez un goût certain pour la découverte et\r\nl\'expérimentation, vous êtes force de proposition et êtes capable\r\nd\'argumenter vos choix techniques. Vous partagez notre choix de\r\nprivilégier des logiciels libres et de contribuer aux communautés\r\nd\'utilisateurs (listes, FAQ, HOWTO)\r\n\r\nINFORMATIONS PRATIQUES\r\n\r\nContacts\r\n\r\nZied Sellami, Jean-Pierre Lorré\r\n\r\nzsellami@linagora.com, jplorre@linagora.com\r\n\r\nLieu du stage - Durée Toulouse - 6 mois\r\n\r\nSociété Linagora\r\n\r\nWebsite : https://research.linagora.com / Twitter : @LinagoraLabs'),
(523, '2018-11-12', 'STL', 'Lille', 'Phonétique pour les besoins cliniques des orthophonistes\r\n\r\nL\'orthophonie est dédiée à l\'évaluation et au traitement de troubles\r\ndu langage oral et écrit. Elle concerne les troubles développementaux\r\n(acquisition du langage) et les troubles acquis (troubles consécutifs\r\nà une lésion cérébrale chez l\'adulte).\r\n\r\nPour l\'évaluation des déficits langagiers et l\'établissement du\r\ndiagnostic, les orthophonistes utilisent des batteries de tests. Il\r\nexiste ainsi des batteries de tests pour les maladies\r\nneurodégénératives comme la maladie d\'Alzheimer [Sagot et al., 2012;\r\nGuard, 2010], pour l\'évaluation de la dyslexie [Lefavrais, 2005] et\r\npour le bilan informatisé de langage oral [Khomsi & Khomsi,\r\n2009]. Cependant, les batteries de tests existants ne sont pas\r\nnombreuses et ne permettent pas de couvrir toutes les situations que\r\nles orthophonistes doivent prendre en charge ce qui constitue une\r\nlimitation pour le diagnostic et le traitement des troubles du\r\nlangage.\r\n\r\nL\'objectif de ce travail de stage consiste à proposer des méthodes\r\nautomatiques pour préparer des tests pouvant être utilisés pour un\r\ndiagnostic plus précis et un traitement plus ciblé des troubles du\r\nlangage. Le stage s\'intéresse tout particulièrement au niveau\r\nphonétique de la langue. Pour la réalisation du stage, des méthodes\r\nd\'Intelligence Artificielle, de Traitement Automatique de la Langue et\r\nde fouille de textes seront utilisées.\r\n\r\nCe stage s\'inscrit dans le projet ANR DEMONEXT [demonext]. Les\r\nobjectifs de ce projet consistent à construire une base de données\r\nmorphologiques du français et à répondre à des besoins multiples,\r\ncomme la confirmation empirique et l\'élaboration d\'hypothèses en\r\nmorphologie, le développement d\'outils en traitement automatique des\r\nlangues, l\'enseignement du vocabulaire et le diagnostic et le\r\ntraitement des troubles du langage développementaux ou acquis.\r\n\r\nPlus spécifiquement, le stagiaire devra effectuer les tâches\r\nsuivantes:\r\n\r\n-     travailler avec des corpus de textes\r\n-     adapter un module de transcription phonétique au français\r\n-     tester et améliorer ce module de transcription phonétique\r\n-     travailler avec les orthophonistes pour élaborer des tests\r\n-     faire des présentations lors des réunions\r\n-     lire des articles et rédiger les rapports\r\n\r\nLe stagiaire sera amené à utiliser des outils existants et à\r\ndévelopper ses propres programmes pour mieux traiter les données.\r\n\r\nPrérequis:\r\n\r\n-    connaissances en IA, TAL et informatique\r\n-    manipulation et test des outils d\'IA et de TAL\r\n-    habitude de Linux\r\n-    capacité de travailler en équipe et individuellement\r\n-   lecture et analyse de la littérature scientifique, y compris en anglais\r\n-    autonomie\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\n    Niveau: Master, ingénieur\r\n    Durée: 6 mois\r\n    Lieu: Lille\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de\r\nmotivation, le relevé de notes et les contacts de deux référents à\r\nNatalia Grabar (natalia.grabar@univ-lille.fr) et Mai Thi Tran\r\n(thi-mai.tran@univ-lille.fr)\r\n\r\nREFERENCES:\r\n\r\n    Guard O. (2010). La batterie BAC 40 : un outil d\'évaluation\r\n    cognitive pour le diagnostic de la maladie d\'Alzheimer au cabinet\r\n    du spécialiste. Revue Neurologique 166(6-7): 615-620.\r\n    \r\n    Khomsi A., J. Khomsi. (2009). Bilo Petits. Bilan informatise de\r\n    langage oral pour les enfants de 3 ans a 5 ans 6 mois. ECPA\r\n\r\nLefavrais P. (2005). Alouette-R test d\'analyse de la lecture et de la\r\ndyslexie. ECPA.\r\n\r\nSagot C and TM Tran and J Pariente. (2012). Développement d\'une\r\nbatterie francophone pour l\'évaluation des troubles du langage dans\r\nles maladies neurodégénératives : 10 ans de recherches sur les\r\naphasies primaires progressives. Revue française de Linguistique\r\nAppliquée 17(2): 117-133.\r\n\r\ndemonext : https://www.demonext.xyz/'),
(524, '2018-11-12', 'LIMSI', 'Orsay', 'Offre de stage: \r\n\r\nTitre\r\n\r\nComparaison de fonctions objectif pour l\'apprentissage de représentation :\r\napplication à la vérification du locuteur et au calcul de similarité\r\nsémantique textuelle\r\n\r\nDescriptif\r\n\r\nPour candidater, envoyer lettre de motivation, CV et dernières notes à :\r\nSahar Ghannay (ghannay@limsi.fr), Sophie Rosset (rosset@limsi.fr), Hervé\r\nBredin (bredin@limsi.fr)\r\n\r\nSujet\r\n\r\nLe rôle de la fonction objectif dans l\'apprentissage neuronal est de\r\nfournir une mesure de la performance du réseau de neurones (i.e. sa\r\ncapacité à répondre correctement à une tâche précise). Cette mesure,\r\nlorsqu\'elle est dérivable, permet alors de mettre à jour le réseau de\r\nneurones par rétro-propagation du gradient de telle sorte que sa\r\nperformance soit améliorée. Parmi ces fonctions objectif, on peut par\r\nexemple citer la \"contrastive loss\" [HCL06], la \"triplet loss\" [SKP15],\r\nou encore la \"center loss\" [WZLQ16]. L\'objectif de ce stage est de\r\ncomparer différentes fonctions objectif permettant l\'apprentissage des\r\nreprésentations neuronales adaptées à des tâches applicatives telles que\r\nla vérification du locuteur et la similarité sémantique textuelle. La\r\nplupart de ces méthodes ont été initialement proposées dans le domaine\r\nde la vision par ordinateur pour la reconnaissance d\'image (et de visage\r\nen particulier) et certaines ont été appliquées récemment à tâche de\r\nvérification du locuteur [Bre17]. Cependant, elles n\'ont pas encore été\r\nutilisées pour la tâche de similarité sémantique textuelle.\r\n\r\nDescription des tâches\r\n\r\nImplémentation des différentes fonctions objectif : Après une étape\r\nd\'étude de la littérature sur le sujet, la première tâche consiste à\r\nimplémenter les fonctions objectif les plus prometteuses en les testant\r\nsur des exemples jouet bien maîtrisés (tels que la base MNIST de\r\nreconnaissance de chiffre manuscrit, par exemple).\r\n\r\nApplication à la vérification du locuteur : La tâche de vérification du\r\nlocuteur consiste à déterminer si deux signaux audio proviennent ou non\r\nde l\'enregistrement du même locuteur. On utilisera la base de données\r\nVoxCeleb [CNZ18, NCZ17] pour mener ces expériences. Elle contient plus\r\nd\'un million d\'enregistrements correspondant à plus de 6000 locuteurs,\r\net constitue de fait le plus grand corpus librement disponible pour\r\nl\'identification et la vérification du locuteur.\r\n\r\nApplication au calcul de similarité sémantique textuelle : La tâche de\r\nsimilarité sémantique textuelle (SST) est motivée par le fait que la\r\nmodélisation de la similarité sémantique des phrases est un problème\r\nfondamental en compréhension de la langue, pertinent pour de nombreuses\r\napplications, notamment la traduction automatique, la recherche de\r\nréponses à des questions précises (ou questions-réponses), le dialogue\r\ndialogue, etc. Cette tâche consiste à évaluer dans quelle mesure deux\r\nphrases sont sémantiquement équivalentes. Plusieurs approches ont étés\r\nproposées [CDA + 17], qui sont fondées généralement soit sur les\r\nméthodes classiques en traitement automatique des langues (TAL), soit\r\nsur des méthodes d\'apprentissage profond. La première approche s\'appuie\r\nsur l\'utilisation d\'un classifieur enrichi par différents types de\r\ndescripteurs : sémantiques, syntaxiques, etc. La deuxième est fondée sur\r\nl\'exploitation des représentations de phrases et des architectures\r\nneuronales. Dans le cadre des campagnes d\'évaluation SemEval, la tâche\r\nde SST a été proposée. Dans ce cadre, la tâche consiste pour le système\r\nde SST à attribuer un score de similarité à chaque paire de phrase sur\r\nune échelle de 0 (les deux phrases sont complètement différentes) à 5\r\n(les deux phrases sont complè tement identiques)... Notre objectif dans ce\r\nstage est de pouvoir étudier les différentes fonctions objectif sur la\r\ntâche SST et de comparer nos résultats aux résultats obtenus par les\r\ndifférents systèmes ayant participé à la tâche 5 (en anglais) de la\r\ncampagne d\'évaluation SemEval 2017. Ce système fait la combinaison des\r\napproches de TAL et d\'apprentissage profond.\r\n\r\nRéférences\r\n\r\n[Bre17] Hervé Bredin. Tristounet : triplet loss for speaker turn\r\nembedding. In 2017 IEEE International Conference on Acoustics, Speech\r\nand Signal Processing (ICASSP), pages 5430-5434. IEEE, 2017.\r\n\r\n[CDA + 17] Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and\r\nLucia Specia. Semeval-2017 task 1 : Semantic textual\r\nsimilarity-multilingual and cross-lingual focused evaluation. arXiv\r\npreprint arXiv :1708.00055, 2017.\r\n\r\n[CNZ18] Joon Son Chung, Arsha Nagr ni, and Andrew Zisserman. Voxceleb2 :\r\nDeep speaker recognition. arXiv preprint arXiv :1806.05622, 2018.\r\n\r\n[HCL06] Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality\r\nreduction by learning an invariant mapping. In CVPR 2006, pages\r\n1735-1742. IEEE, 2006.\r\n\r\n[NCZ17] Arsha Nagrani, Joon Son Chung, and Andrew Zisserman. Voxceleb :\r\na large-scale speaker identification dataset. arXiv preprint arXiv\r\n:1706.08612, 2017.\r\n\r\n[SKP15] Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet\r\n: A unified embedding for face recognition and clustering. In\r\nProceedings of the IEEE conference on computer vision and pattern\r\nrecognition, pages 815-823, 2015.\r\n\r\n[WZLQ16] Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A\r\ndiscriminative feature learning approach for deep face recognition. In\r\nEuropean Conference on Computer Vision, pages 499-515. Springer, 2016.\r\n\r\nDétails\r\n\r\nDomaine\r\ntraitement du langage parlé, écrit et gestuel\r\nMots clés\r\nreconnaissance de locuteur\r\nApprentissage\r\nTraitement Automatique du Language Naturel Écrit\r\nNiveau : M2\r\nGroupe(s) : ILES, TLP\r\nDate de début : date de début à définir avec le stagiaire\r\nDurée du stage : 5-6 mois (stage pouvant donner lieu à une poursuite en\r\nthèse)'),
(525, '2018-11-12', 'Bertin IT', 'Montpellier', 'Évaluation d\'outils d\'extraction d\'entités nommées\r\n\r\nDurée, démarrage\r\nD\'une durée de 6 mois, le stage se déroulera dans les locaux du centre\r\nR&D à Montpellier. Démarrage dès que possible.\r\n\r\nPrésentation de l\'entreprise\r\nSociété du Groupe CNIM, Bertin IT est un éditeur et intégrateur de\r\nsolutions logicielles pour la cyber sécurité, la cyber-intelligence, la\r\nveille stratégique et le traitement automatique de la parole. Sa marque\r\nAMI, leader dans l\'édition de logiciels d\'acquisition, de gestion et de\r\ntraitement de l\'information texte issue du Web, offre des solutions de\r\nveille stratégique et d\'intelligence compétitive. En particulier, notre\r\nsolution, AMI Enterprise Intelligence, permet aux entreprises\r\nd\'exploiter le Big Data afin d\'anticiper les évolutions de leur\r\nenvironnement concurrentiel et technologique et d\'identifier de\r\nnouvelles perspectives de développement.\r\n\r\nDescription du stage\r\nDans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),\r\nnous proposons des outils avancés d\'analyse de texte en vue de faciliter\r\naux veilleurs et analystes l\'exploitation et la navigation dans\r\nl\'importante masse de documents collectés à l\'issue du processus de\r\nveille. Divers traitements sont proposés tels que l\'extraction des\r\nprincipales thématiques, l\'analyse de sentiment ou la détection des\r\névénements clés. Nous fournissons en particulier des outils permettant\r\nl\'identification des entités nommées ainsi que les concepts clés\r\napparaissant dans les documents. Une entité nommée (Named Entity)\r\nfaisant référence à une personne ou tout autre objet du monde réel\r\npouvant être désigné par un nom propre (lieu géographique, nom\r\nd\'organisation, nom d\'une marque, d\'un produit, etc.). Ce type de\r\nproblématique est désigné sous la dénomination NER (Named entity\r\nRecognition. Dans ce cadre et dans le but d\'une amélioration de nos\r\noutils NER existants, nous souhaitons tester et évaluer des approches\r\nbasées sur des réseaux de neurones. La mission consiste à sélectionner\r\ndes outils OpenSource permettant d\'implémenter des réseaux de neurones\r\n(Tensorflow, Theano ou autre), construire des modèles NER à base de ces\r\noutils, évaluer et comparer les modèles construits avec les outils AMI\r\nainsi que des outils de référence comme Stanford NER.  Les langues\r\ncibles de l\'étude sont l\'Anglais et le Français.\r\n\r\nMots clés Deep learning, Réseaux de neurones, Benchmark, Extraction\r\nd\'entités nommées, NER, Mesures d\'évaluation,\r\n\r\nProfil souhaité\r\nBac +4/5, vous êtes issu(e) d\'une école d\'ingénieur ou suivez un Master\r\nen mathématiques appliquées, statistiques ou data science. Vous avez une\r\nappétence pour les statistiques et le data science. Une bonne\r\nconnaissance d\'au moins un langage de script tel que R, Python ou autre\r\nest indispensable. Pour cette mission, l\'autonomie, le dynamisme ainsi\r\nle sens de la rigueur seront particulièrement appréciés.\r\n\r\nSi vous êtes intéréssé(e) merci d\'envoyer votre Cv et lettre de\r\nmotivation à :\r\nLeila.khouas@bertin.fr  et frederique.segond@bertin.fr'),
(526, '2018-11-12', NULL, 'Paris', 'Offre de stage : exploration de logiciels de traduction automatique dans\r\nle contexte d\'une maison d\'édition\r\n\r\nDescriptif\r\n\r\nUn grand éditeur scientifique souhaite valoriser son fonds d\'ouvrages\r\nnon encore traduits en anglais mais, pour des raisons de coût, une\r\ntraduction purement manuelle n\'est pas envisageable. C\'est pourquoi\r\nl\'éditeur souhaite lancer une étude préliminaire portant sur la\r\npertinence et les usages possibles de la traduction automatique dans ce\r\ncontexte. Il s\'agit d\'étudier la qualité possible d\'une traduction\r\nautomatique et d\'estimer le coût (en temps) de la post-édition par un\r\nexpert linguiste ou un traducteur, afin d\' obtenir un ouvrage de qualité\r\nsatisfaisante pour une publication en ligne ou papier.\r\n\r\nOn propose donc un stage d\'une durée de 3 à 6 mois, de préférence à\r\ntemps plein (ou à temps partiel, mais avec des horaires fixes chaque\r\nsemaine si l\'étudiant doit encore suivre des cours pendant la période de\r\nstage), autour de cette problématique.\r\n\r\nLe stage consistera à :\r\n\r\n1) sélectionner avec la maison d\'édition en question quelques ouvrages\r\n   représentatifs, tous disponibles en version électronique en français,\r\n2) recenser, analyser et classer les différents systèmes de traduction\r\n   automatique actuellement disponibles,\r\n3) procéder à la traduction automatique de ces ouvrages (en activant le\r\n   ou les logiciels de traduction automatique qui auront été choisis),\r\n4) définir des indicateurs de qualité explicite, tant lexicale,\r\n   syntaxique que sémantique,\r\n5) évaluer la qualité comparée de ces traductions à l\'aune de ces\r\n   indicateurs,\r\n6) étudier la faisabilité et le coût de la post-édition manuelle pour\r\n   obtenir un texte de qualité satisfaisante pour une publication.\r\n\r\nIl faudrait qu\'un ouvrage soit entièrement traduit pendant le stage afin\r\nd\'évaluer la faisabilité sur un ouvrage complet.\r\n\r\n\r\nProfil recherché :\r\n\r\n- de préférence étudiant(e) anglophone ou, à défaut, avec un excellent\r\n  niveau en anglais\r\n- étudiant(e) de Master (M2) avec une formation pertinente (traduction,\r\n  linguistique, traitement automatique des langues, informatique) -- il\r\n  est indispensable de maîtriser l\'informatique, au-delà d\'une simple\r\n  utilisation des outils  bureautique\r\n- compétences en informatique (programmation de scripts en perl ou\r\n  python)\r\n- des compétences en traitement automatique des langues seraient un plus\r\n\r\nComment candidater ? \r\n\r\nEnvoyer par mail (adressé à Thierry Poibeau: prenom.nom@ens.fr) les\r\ndocuments suivants :\r\n\r\n- une courte lettre de motivation (éventuellement directement dans le\r\n  corps du mail)\r\n- un CV\r\n- un relevé de notes récent (de niveau M1 ou M2)\r\n- des éléments concrets permettant d\'apprécier les compétences en\r\n  anglais\r\n\r\nLe stage aura lieu dans le quartier latin à Paris. Il sera indemnisé\r\nsuivant les règles en vigueur pour les stages.  Il est soumis à\r\nl\'établissement d\'une convention de stage préalable.'),
(527, '2018-11-19', 'Advanced decision', 'Paris', '***Cadre du stage***\r\n\r\nCe stage de recherche d\'une durée de 4 à 6 mois se déroulera au sein de\r\nla société Advanced Decision. Une poursuite du stage dans le cadre d\'une\r\nconvention CIFRE est envisagée sur les mêmes problématiques.\r\nL\'encadrement sera assuré par l\'équipe R&D (Hamid Hammouche) ainsi que\r\npar des enseignants chercheurs de l\'IRIT (Farah Benamara et Véronique\r\nMoriceau).\r\n\r\nLa société Advanced Decision est une startup spécialisée en Intelligence\r\nArtificielle avec un savoir-faire industriel dans la réalisation de\r\nconfigurateurs d\'offres intelligents. Nous développons un nouveau\r\nproduit, unique sur le marché : un assistant intelligent de voyage\r\npersonnalisé.\r\n\r\nNotre produit utilise les dernières techniques de l\'IA et de la Data\r\nScience : NLP, Machine Learning. Nous recherchons un stagiaire qui\r\nsouhaite s\'investir dans les domaines de l\'ingénierie linguistique et\r\nl\'extraction du sens à partir de textes hétérogènes.\r\n\r\n***Contexte & Objectif***\r\n\r\nAdvanced Decision est engagée dans la réalisation d\'un service de\r\nrecommandation de produits touristiques (hébergement, loisirs, ...). Notre\r\nsolution permet une appréhension fine des expériences associées à chaque\r\nproduit. Pour atteindre cette finesse, nous analysons finement les\r\nverbatim postés dans les réseaux sociaux. Notre première application est\r\ndédiée à l\'activité de restauration. L\'analyse de ces verbatim doit\r\nfaire apparaître les opinions associées à chacun des aspects du\r\nrestauration (par exemple, la cuisine était bonne mais le service\r\nlaissait à désirer). Un corpus de 100 000 phrases a été qualifié et\r\nannoté. Un prototype développé par apprentissage automatique permet\r\nd\'ores et déjà de repérer les aspects pertinents (cuisine, ambiance, ...)\r\net de qualifier leur polarité (plus ou moins positive ou négative). Les\r\nrésultats des analyses obtenus sont encourageants mais une amélioration\r\ndes performances est attendue. L\'objectif du stage est double : (i)-\r\naméliorer la précision et la polarité et (ii)- repérer des sens\r\nimplicites (figuré, ironie).\r\n\r\n***Activités***\r\n\r\n- Appropriation des travaux réalisés\r\n- Benchmark des techniques et outils d\'analyse des sentiments\r\n- Proposition de solutions\r\n- Implémentation et expérimentations\r\n\r\n***Compétences***\r\n- Langage de programmation (Python et/ou Java)\r\n- Fouille de textes et d\'opinions\r\n- Connaissance appréciée d\'un des frameworks suivants : NLTK, Keras,\r\n  spaCy, PyTorch\r\n\r\n***Durée***\r\n\r\n4 à 6 mois\r\n\r\n***Lieu***\r\n\r\nParis (France)\r\n\r\n***Formation***\r\n\r\nIngénieur, Master en Informatique ou linguistique\r\n\r\n***Indemnité***\r\n\r\nSelon convention et expérience du candidat\r\n\r\n***Dossier***\r\n\r\nCV, lettre de motivation et bulletins de notes à envoyer à\r\nstage@advanceddecision.fr ; benamara@irit.fr ;\r\nveronique.moriceau@irit.fr'),
(528, '2018-11-19', 'Lattice', 'Paris', 'Offre de stage : génération de poésie à partir d\'une base de poèmes\r\nclassiques\r\n\r\nDescriptif\r\n\r\nLe projet vise à mettre en ligne un programme de génération de poésie à\r\npartir des poème existants, en s\'inspirant du livre \"100.000 milliards\r\nde poèmes\" de Queneau (mais, dans notre cas, le projet porte sur la\r\npoésie du 19e siècle). Un premier générateur a été mis au point : il est\r\nfondé sur un corpus de plus de 800 sonnets : des vers sont tirés au sort\r\nau hasard au début, puis de façon à ce qu\'ils forment un poème de type\r\nclassique (c\'est-à-dire en respectant les contraintes de rimes\r\nnotamment).\r\n\r\nLe stage vise à reprendre le premier prototype réalisé, à le mettre en\r\nligne en collaboration avec l\'équipe chargée de la partie site Web du\r\nprojet, et à proposer et implémenter diverses extensions sur cette base\r\n(générer des poèmes avec des contraintes de contenu, de manière\r\ninteractive, etc.).\r\n\r\nLe stage est organisé dans le cadre du projet Oupoco (\"L\'Ouvroir de\r\nPoésie Combinatoire »,\r\nhttp://transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire).\r\n\r\nLe stage aura lieu au Lattice, à Montrouge (à 5mn du métro Mairie de\r\nMontrouge, ligne 4). Il sera indemnisé suivant les règles en vigueur\r\npour les stages.  Il est soumis à l\'établissement d\'une convention de\r\nstage préalable. Dates exactes à définir (3 à 6 mois, de préférence à\r\ntemps plein, au premier semestre 2019)\r\n\r\nProfil recherché :\r\n\r\n- étudiant(e) de Master (M2) avec une formation pertinente (traitement\r\n  automatique des langues, éventuellement informatique ou littérature\r\n  avec les compétences informatiques adéquates)\r\n- compétences en programmation (scripts en perl ou python)\r\n- compétences en programmation Web et en mise en ligne d\'applications\r\n- compétences en traitement automatique des langues \r\n- intérêt pour la littérature et la poésie \r\n\r\n\r\nComment candidater ? \r\n\r\nEnvoyer par mail (à Thierry Poibeau : prenom.nom@ens.fr) les documents\r\nsuivants :\r\n\r\n- une courte lettre de motivation (éventuellement directement dans le\r\n  corps du mail)\r\n- un CV\r\n- un relevé de notes récent (de niveau M1 ou M2)\r\n\r\nLes candidatures seront étudiées au fil de l\'eau, la date limite pour\r\ncandidater est le 31 novembre (mais il est conseillé de candidater dès\r\nque possible sans attendre la date butoir. Le stage peut être pourvu\r\navant la date de fin de candidature.'),
(529, '2018-11-19', 'TETIS / CIRAD', 'Paris', 'Stage Master 2 ou école ingénieur: Conception et intégration d\'une\r\nplateforme de visualisation de données textuelles hétérogènes\r\n\r\nEncadrement\r\n\r\nJacques Fize (UMR TETIS, CIRAD), Mathieu Roche (UMR TETIS, CIRAD ),\r\nMaguelonne Teisseire (UMR TETIS, IRSTEA)\r\n\r\nContexte général\r\n\r\nLe stage se déroule dans le cadre du projet SONGES sur la mise en\r\ncorrespondance de données textuelles massives et hétérogènes. Dans ces\r\ntravaux, nous élaborons des modèles de représentation de données ainsi\r\nque des mesures de similarité à partir d\'indicateurs trouvés dans les\r\ntextes (thématiques, spatiaux et temporels). L\'objectif est d\'organiser\r\net valoriser des ensembles de données dans leurs dimensions hétérogènes\r\net massives. Parmi les données exploitées, nous travaillons sur un\r\nensemble de données produites dans le cadre du projet BVLAC, un projet\r\nmené par le CIRAD (1) qui promeut des techniques agricoles issues de\r\nl\'agroécologie à Madagascar.\r\n\r\nObjectif\r\n\r\nL\'objectif de ce stage est de développer une interface de visualisation\r\ndes liens (thématiques et spatiaux) entre documents d\'un corpus. Cette\r\ninterface devra permettre aux producteurs des données d\'explorer et de\r\nvaloriser ces corpus . Plus particulièrement, vous développerez une\r\nplateforme Web utilisant des librairies dédiées telles que : D3.js,\r\nSigma.Js, Topogram.io, etc.\r\n\r\nDe façon plus précise, le stage sera décomposé en plusieurs étapes :\r\n- Appropriation du sujet (état de l\'art, exploration des données)\r\n- Proposition de premières visualisations statiques des données à l\'aide\r\n  des librairies disponibles sur Python ou R comme : ggplot2,\r\n  matplotlib, basemap, geopandas\r\n- Conception de l\'interface de visualisation\r\n- Stockage des données dans un SGBD (2). La sélection du SGBD dépendra des\r\n  besoins identifiés pour construireles différentes visualisations\r\n- Choix du framework (Flask, Rshiny,...) et des librairies Javascript\r\n  (Sigma.js, Topogram.io, leaflet, ...) nécessaires à l\'implémentation de\r\n  l\'interface\r\n- Développement de l\'interface\r\n- Analyse et évaluation des visualisations produites\r\n\r\nCompétences\r\n\r\nLangage de programmation : Python ou R\r\n\r\nMaitrise de SGBD tels que MariaDB, MongoDB, ElasticSearch ou PostGreSQL\r\n(avec POSTGIS)\r\n\r\nDéveloppement Web : HTML/CSS mais surtout Javascript (Connaissances en\r\ndesign d\'IHM (3) souhaitées)\r\n\r\nDivers\r\n\r\nDurée : 6 mois\r\n\r\nGratification : Taux légal en vigueur\r\n\r\nLocalisation : Maison de la télédétection - Montpellier\r\n\r\nComment candidater ?\r\n\r\nEnvoyer un CV ainsi que vos relevés de notes des deux dernières années à\r\njacques.fize@cirad.fr, maguelonne.teisseire@irstea.fr,\r\nmathieu.roche@cirad.fr\r\n\r\n1 Centre de coopération internationale en recherche agronomique pour le\r\ndéveloppement\r\n\r\n2 Système de Gestion de Base de Données\r\n\r\n3 Interface Homme-Machine'),
(530, '2018-11-19', 'IRISA', 'Lannion', 'L\'objectif de ce stage est de mettre en place des outils d\'aide à la\r\ncomparaison de processus de pré-traitements agro-alimentaires sur la\r\nbase de leurs indicateurs environnementaux et économiques.\r\n\r\nEn s\'appuyant sur des méthodes de classification automatique\r\nnon-supervisée (clustering), une première fonctionnalité visée sera\r\nd\'identifier des classes de procédés qui se comportent de manière\r\nsimilaire sur des sous-ensembles d\'indicateurs. De manière\r\ncomplémentaire, il serait intéressant d\'identifier au sein de chaque\r\nclasse et pour chaque procédé, les propriétés typiques et atypiques qui\r\nles caractérisent.\r\n\r\n\r\nUn enjeu majeur des méthodes d\'analyse de données pour l\'aide à la\r\ndécision est de fournir une représentation des données et des\r\nconnaissances extraites la plus interprétable possible. Pour répondre à\r\ncet enjeu, l\'originalité de l\'approche d\'analyse est de procéder à une\r\nréécriture au préalable des données selon un vocabulaire personnalisable\r\npar l\'expert. Par exemple, une valeur de 0,85 pour un indicateur i\r\npourra être interprété comme « élevé » ou bien « pas significative »,\r\netc. Un travail confié au stagiaire sera d\'adapter les méthodes\r\nd\'analyse de données pour gérer ces réécritures symboliques au lieu de\r\ndonnées numériques, puis de fournir des représentations graphiques de\r\nces données et des connaissances structurelles découvertes.\r\n\r\nL\'objectif du stage de master est donc de proposer une méthode qui\r\npermette de transformer un vecteur de n dimensions (n étant le nombre\r\nd\'indicateurs retenus) en représentations graphiques de type « tag of\r\nwords » exprimées dans une seule dimension terminologique. Cette\r\ntransformation s\'appuiera sur un système de partitionnement flou à\r\ndéfinir pour chaque indicateur afin de transformer une donnée numérique\r\nen donnée catégorielle.\r\n\r\nMots clés du stage : analyse de données, fouille de données,\r\napprentissage automatique, visualisation de données\r\n\r\nCompétences requises : programmation Java, modélisation de systèmes\r\nd\'informations, analyse de données (data mining, clustering, etc.),\r\ncommunication et travail d\'équipe, dynamisme.\r\n\r\nDurée du stage : 6 mois\r\n\r\nLieu du stage : Lannion\r\n\r\nContacts: patrice.buche@inra.fr, gregory.smits@univ-rennes1.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(531, '2018-11-19', 'LIG', 'Grenoble', 'The LIG (Laboratoire d\'Informatique de Grenoble) laboratory proposes the\r\nfollowing M2 stage (research)\r\n\r\nTitle:\r\nNeural coreference resolution\r\n\r\nDescription:\r\nCoreference resolution aims at detecting chains of coreference mentions \r\nin a text, that is mentions in the text that refer to the same entity.\r\nWhile at first coreference resolution was split into two separated \r\nsub-problems, i.e. mention detections and resolution of coreferent \r\nmentions [1], thanks to the development of sophisticated neural models \r\n[2,3,4], end-to-end coreference resolution system can be based on a \r\nwhole single model.\r\nThe aim of this stage is to study Sequence-to-Sequence [5] and \r\nTransformer [6] neural models for coreference resolution, integrating \r\ndifferent types of attention mechanisms and possibly arbitrarily-long \r\ncontext [8], with the goal of understanding their impact in dealing with \r\nthis complex NLP problem.\r\n\r\nIn this internship the student will implement parts of the systems for \r\ncoreference resolution with Sequence-to-Sequence and Transformer neural \r\nmodels.\r\nThe student will run experiments on his own using GPUs, and the systems \r\nwill be tested on the CoNLL Semeval 2012 benchmark [7].\r\n\r\nProfile:\r\n- Student for internship level stage (Master 2) in computer science, or \r\n  from engineering school\r\n- Computer science skills:\r\n     Python programming with good knowledge of deep learning libraries \r\n     (TensorFlow or PyTorch)\r\n     Textual data manipulation (xml format, tabular format, CoNLL\r\n     format)\r\n- Interested in Natural Language Processing\r\n- Skills in machine learning for probabilistic models\r\n\r\nThe internship may last from 4 up to 6 months, it will take place at LIG\r\nlaboratory, GETALP team (http://lig-getalp.imag.fr/), starting from\r\nJanuary/February 2019.\r\nThe student will be tutored by Marco Dinarelli (www.marcodinarelli.it) \r\nand Laurent Besacier (http://lig-membres.imag.fr/besacier/).\r\nInterested candidates must send a CV and a motivation letter to\r\nmarco.dinarelli@ens.fr and laurent.besacier@univ-grenoble-alpes.fr.\r\n\r\n[1] Vincent Ng\r\n     Supervised noun phrase coreference research: The first fifteen \r\n     years.\r\n     Proceedings of ACL, 2010\r\n\r\n[2] Sam Wiseman, Alexander M. Rush, Stuart M. Shieber\r\n     Learning Global Features for Coreference Resolution\r\n     Proceedings of NAACL-HLT, 2016\r\n\r\n[3] Kenton Leey, Luheng Hey, Mike Lewisz, and Luke Zettlemoyer\r\n     End-to-end Neural Coreference Resolution\r\n     Proceedings of EMNLP, 2017\r\n\r\n[4] Kenton Lee Luheng He Luke Zettlemoyer\r\n     Higher-order Coreference Resolution with Coarse-to-fine Inference\r\n     Proceedings of NAACL, 2018\r\n\r\n[5] Ilya Sutskever, Oriol Vinyals, Quoc V. Le\r\n     Sequence to Sequence Learning with Neural Networks\r\n     Proceedings of NIPS, 2014\r\n\r\n[6] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion \r\n     Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\r\n     Attention Is All You Need\r\n     Proceedings of NIPS, 2017\r\n\r\n[7] Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, \r\n     Yuchen Zhang\r\n     Conll-2012 shared task: Modeling multilingual unrestricted \r\n     coreference in ontonotes\r\n     Proceedings of EMNLP and  CoNLL-Shared Task, 2012\r\n\r\n[8] Zhang, Jiacheng, et al. \"Improving the Transformer Translation Model \r\n     with Document-Level Context.\" EMNLP 2018.'),
(532, '2018-11-23', 'Southpigalle', 'Paris', '*INTITULÉ :* Data Science / Traitement du langage (NLP)\r\n\r\n*CONTEXTE :* Stage rémunéré (1000 ¤ brut/mois) et conventionné, à Paris\r\n(II). Durée : 4 / 6 mois.\r\n\r\n*CONTACTS :* Louis de Cointet, CTO et co-fondateur\r\n(louis@southpigalle.io / +33 6 71 70 18 11)\r\n\r\n*PRÉSENTATION DE LA SOCIÉTÉ :*\r\n\r\nsouthpigalle est une société spécialisée sur les technologies de l\'AI et\r\nles workflows conversationnels (\"voice\", \"text\" et \"IoT\" bots), basée à\r\nParis II et StationF.\r\n\r\nNous permettons aux entreprises d\'optimiser leurs processus et de\r\ndévelopper de nouveaux services personnalisés pour leurs collaborateurs\r\net clients.\r\n\r\nNous comptons de nombreux clients dans le secteur du Luxe (LVMH, Kering,\r\nRichemont), du Retail (BEL, Royal Canin), des médias (MyLittleParis,\r\nMK2), et de la Banque/Finance.\r\n\r\nNous faisons partie des programmes d\'accélération du Groupe LVMH à\r\nStationF (\r\nhttp://southpigalle.io/presse/180410_LesEchos_LVMH-Inaugure-La-Maison-des-Startups-au-sein-de-StationF\r\n) et Microsoft (programme \"Microsoft for Startups\"). Nous sommes\r\négalement dans les 100 startups de la french retailTech identifiées par\r\nLSA (\r\nhttps://storage.googleapis.com/store-iobot/20180906_LSA_100_start_up_retailtech.pdf\r\n)\r\n\r\n*PRÉSENTATION DU STAGE :*\r\n\r\nSouthpigalle accueille régulièrement des stagiaires au sein de son pôle\r\nData Science / NLP.\r\n\r\nL\'objet de ce stage est de travailler à l\'enrichissement de notre brique\r\nde traitement du langage (\"NLP\") qui fonctionne aujourd\'hui en français\r\net anglais, et de proposer des pistes / implémenter des évolutions\r\npermettant de la porter dans d\'autres langues (espagnol, italien et\r\nchinois par exemple).\r\n\r\nPour ce faire, on s\'attachera à conserver la structure centrale de la\r\ntechnologie comme base de départ, afin de pouvoir modifier certaines\r\ncomposantes de cette dernière, et plus particulièrement :\r\n\r\n(1) Data cleaning: nettoyage de la phrase, stop words, lemmatisation ;\r\n\r\n(2) Data preprocessing : choix entre différents embeddings, entraînement\r\n    de ces embeddings sur différents corpus ;\r\n(3) Machine learning: évolution des algorithmes supervisés\r\n    (classification) et non supervisé (text clustering) déjà présents ;\r\n(4) Entités: adaptation de l\'architecture de reconnaissance des entités\r\n    et mise à jour de ces dernières.\r\n\r\nLe stage pourra aborder l\'un ou plusieurs des aspects cités avant.\r\n\r\nLa connaissance des langages utilisés sur notre stack technique (HDFS /\r\nSpark / Python pour le Machine Learning) et des librairies du marché\r\n(Manipulation de données : Numpy, Pandas, Seaborn, Analyse de données :\r\nSklearn, Gensim, Keras, Fasttext, Traitement de la langue : Spacy, Nltk\r\n...  constitue un plus.\r\n\r\nAu delà de l\'expertise, nous valorisons fortement l\'autonomie et la\r\nprise d\'initiative de la part de nos stagiaires, qui seront amenés à\r\ntravailler dans un environnement flexible, mais extrêmement dynamique et\r\nchallenging.'),
(533, '2018-11-28', 'TETIS / LIRMM', 'Montpellier', 'Stage M2 - Recherche\r\n\r\nTitre: Détection de fausses nouvelles (fake news) fondée sur les\r\ninformations textuelles et structurées\r\n\r\nEncadrants : Mathieu Roche (TETIS, Cirad), Konstantin Todorov (LIRMM,\r\nUniv. Montpellier)\r\n\r\nMots clés:  intelligence artificielle, fake news, machine learning,\r\ngraph/word embeddings, traitement automatique des langues, ...\r\n\r\nSujet:\r\n\r\nLes fausses nouvelles (fake news) sont devenues un problème de plus en\r\nplus important, tant du point de vue de la société que de celui de la\r\nrecherche. De nombreuses approches récentes [1,2] dans diverses\r\ncommunautés scientifiques portent sur des problèmes tels que la\r\nvérification des faits, la détection de la pertinence ou de point de\r\nvue dans des documents par rapport à des assertions particulières.\r\n\r\nDan ce contexte, 3 laboratoires français et allemands (dont le LIRMM\r\net TETIS à Montpellier) ont uni leur efforts pour collecter et publier\r\nsous la forme de graphe de connaissances les données et méta-données\r\ncontenues dans un grand nombre de site de fact-checking (tels que\r\nPolitifact www.politifact.com ou Snopes www.snopes.com). En résulte la\r\nbase ClaimsKG https://github.com/claimskg/claimskg_generator, un graphe de connaissances contenant plus de 24K\r\nassertions annotées et liées qui facilite la création de requêtes\r\nstructurées sur les assertions, leurs valeurs de vérité (True, False,\r\netc.), leurs auteurs, dates de publication, etc.\r\n\r\nCe stage aura pour but d\'exploiter cette ressource et de proposer des contributions\r\nméthodologiques fondées sur des analyses statistiques approfondies :\r\n\r\n(1) Intégration de nouveaux descripteurs (descripteurs dits exogènes,\r\nword embeddings, etc.) pour améliorer l\'identification de \"fake news\"\r\ndans un processus d\'apprentissage automatique.\r\n\r\n(2) Mise en place d\'un processus de clustering d\'assertions dans le\r\nbut d\'identifier les descripteurs clés utiles pour discriminer les\r\nfake news. Notons que le clustering visera à regrouper les assertions\r\nqui portent sur le même événement ou bien sur des événements\r\nsimilaires/liés.\r\n\r\nPlan de travail  :\r\n\r\n1) Etat de l\'art du domaine de vérification automatique d\'assertions à\r\nla base de méthodes d\'apprentissage automatique.\r\n\r\n2) Etudes de l\'état de l\'existant, en particulier la ressource ClaimsKG.\r\n\r\n3) Proposition de méthodes d\'identification des descripteurs les plus\r\npertinents pour la détection de fake news.\r\n\r\n4) Rédaction d\'un papier scientifique à soumettre à une conférence\r\ninternationale\r\n\r\nLe travail s\'effectuera à TETIS et au LIRMM dans le cadre d\'une\r\ncollaboration avec l\'Institut de sciences sociologiques GESIS à\r\nCologne (Allemagne).\r\n\r\nPrérequis  :\r\n- Bon niveau de programmation (java / python)\r\n- Des bases en science de données, machine learning et web sémantique\r\n- Bon niveau en anglais\r\n\r\nLe stage sera rémunéré et aura une durée de 6 mois à partir du mois de\r\nfévrier 2019.\r\n\r\nContacts  :\r\n\r\nEnvoyez un CV à  mathieu.roche@cirad.fr et  todorov@lirmm.fr .\r\n\r\nRéférences:\r\n\r\n[1] S. Vosoughi, D. Roy, and S. Aral. The spread of true and false\r\nnews online. Science, 359(6380):1146-1151, 2018\r\n\r\n[2] K. Popat, S. Mukherjee, J. Strötgen, and G. Weikum. Where the\r\ntruth lies: Explaining the credibility of emerging claims on the web\r\nand social media. In Proceedings of the 26th International Conference\r\non World Wide Web, pages 1003-1012. 2017'),
(534, '2018-11-28', 'TETIS', 'Montpellier', 'Stage Master 2 ou école ingénieur\r\n\r\nConception et intégration d\'une plateforme de visualisation de données\r\ntextuelles hétérogènes\r\n\r\nEncadrement\r\n\r\nJacques Fize (UMR TETIS, CIRAD), Mathieu Roche (UMR TETIS, CIRAD),\r\nMaguelonne Teisseire (UMR TETIS, IRSTEA)\r\n\r\nContexte général\r\n\r\nLe stage se déroule dans le cadre du projet SONGES sur la mise en\r\ncorrespondance de données textuelles massives et hétérogènes. Dans ces\r\ntravaux, nous élaborons des modèles de représentation de données ainsi\r\nque des mesures de similarité à partir d\'indicateurs trouvés dans les\r\ntextes (thématiques, spatiaux et temporels). L\'objectif est\r\nd\'organiser et valoriser des ensembles de données dans leurs\r\ndimensions hétérogènes et massives. Parmi les données exploitées, nous\r\ntravaillons sur un ensemble de données produites dans le cadre du\r\nprojet BVLAC, un projet mené par le CIRAD (Centre de coopération\r\ninternationale en recherche agronomique pour le développement) qui\r\npromeut des techniques agricoles issues de l\'agroécologie à\r\nMadagascar.\r\n\r\nObjectif\r\n\r\nL\'objectif de ce stage est de développer une interface de\r\nvisualisation des liens (thématiques et spatiaux) entre documents d\'un\r\ncorpus. Cette interface devra permettre aux producteurs des données\r\nd\'explorer et de valoriser ces corpus . Plus particulièrement, vous\r\ndévelopperez une plateforme Web utilisant des librairies dédiées\r\ntelles que : D3.js, Sigma.Js, Topogram.io, etc.\r\n\r\nDe façon plus précise, le stage sera décomposé en plusieurs étapes :\r\n\r\n\r\n1. Appropriation du sujet (état de l\'art, exploration des données)\r\n\r\n2. Proposition de premières visualisations statiques des données à\r\nl\'aide des librairies disponibles sur Python ou R comme : ggplot2,\r\nmatplotlib, basemap, geopandas\r\n\r\n3. Conception de l\'interface de visualisation\r\n\r\n4. Stockage des données dans un SGBD 2 . La sélection du SGBD dépendra\r\ndes besoins identifiés pour construire les différentes visualisations\r\n\r\n5. Choix du framework (Flask, Rshiny,...) et des librairies Javascript\r\n(Sigma.js, Topogram.io, leaflet, ...)  nécessaires à l\'implémentation\r\nde l\'interface\r\n\r\n6. Développement de l\'interface\r\n\r\n7. Analyse et évaluation des visualisations produites\r\n\r\nCompétences\r\n\r\n- Langage de programmation : Python ou R\r\n\r\n- Maitrise de SGBD tels que MariaDB, MongoDB, ElasticSearch ou\r\n  PostGreSQL (avec POSTGIS)\r\n\r\n- Développement Web : HTML/CSS mais surtout Javascript (Connaissances\r\n  en design d\'IHM 3 souhaitées)\r\n\r\nDivers\r\n\r\nDurée : 6 mois\r\n\r\nGratification : Taux légal en vigueur\r\n\r\nLocalisation : Maison de la télédétection - Montpellier\r\n\r\nComment candidater ?\r\n\r\nEnvoyer un CV ainsi que vos relevés de notes des deux dernières années\r\nà jacques.fize@cirad.fr, maguelonne.teisseire@irstea.fr,\r\nmathieu.roche@cirad.fr'),
(535, '2018-11-28', 'TETIS', 'Montpellier', 'Stage Master 2 Pro ou école ingénieur\r\n\r\nMise en place d\'un système d\'acquisition semi-automatique d\'un corpus de\r\ndonnées hétérogènes (Images et Textes) - Application à la problématique de la\r\nsécurité alimentaire en Afrique de l\'Ouest\r\n\r\nLe stage s\'inscrit dans le cadre d\'un projet interdisciplinaire\r\nconcernant la gestion des risques liés à la sécurité alimentaire. Le\r\nprojet est centré sur le cas de l\'Afrique de l\'Ouest, où les risques\r\nagricoles sont d\'autant plus aigus que les services nationaux de\r\nsurveillance et de suivi peuvent être défaillants faute de moyens\r\ntechniques et financiers. Actuellement les images de télédétection\r\nsatellitaire sont utilisées en routine pour produire des cartes\r\nd\'anomalies de croissance de la végétation en temps quasi-réel, aux\r\néchelles nationale et régionale. Cependant détecter une anomalie de\r\ncroissance ne suffit pas à établir un diagnostic sur la production\r\nagricole d\'une région, car de nombreux facteurs rentrent en ligne de\r\ncompte. D\'un autre côté, les journaux locaux et les nouveaux médias\r\nfont état de certains événements (sécheresse, inondation, état\r\nsanitaire, etc.) qui ont un impact direct sur la production\r\nagricole. Ces événements ne sont pas tous répertoriés, ils ne\r\ndécrivent pas de façon exhaustive la situation régionale ou nationale,\r\nmais ils apportent une information thématique complémentaire de celle\r\ndes images satellite. Ainsi, nous proposons un stage de recherche\r\nayant comme objectif d\'établir un lien entre textes et images afin de\r\nfaire un diagnostic sur la production agricole en cours de saison en\r\nvue d\'améliorer les systèmes d\'alerte précoce. Pour atteindre cet\r\nobjectif, deux activités seront menées : (i) utiliser des techniques à\r\nla pointe de fouille de textes sur le thème du climat et de la\r\nproduction agricole et avec un ancrage géographique en Afrique de\r\nl\'Ouest ; (ii) lier les informations géo-localisées ainsi extraites\r\naux observations faites par satellite pour poser un diagnostic en\r\ntemps quasi-réel.\r\n\r\nLa zone géographique d\'étude concerne l\'Afrique de l\'ouest. Les\r\ndonnées textuelles à acquérir correspondent à des journaux, des\r\nbulletins officiels de veille sur le déroulé de la campagne agricoles\r\némis par les systèmes d\'alertes précoces internationaux, régionaux ou\r\nnationaux et des données provenant de plateformes de médias sociaux\r\n(p. ex., Blogs, Twitter, Flickr, Instagram). Ces données seront\r\nrécoltées en adaptant (si nécessaire) un système de web scraping mis à\r\ndisposition. Les données image sont essentiellement des cartes\r\nd\'indicateurs NDVI (Normalized Difference Vegetation Index) décadaires\r\nproduites à partir d\'images acquises à basse et moyenne résolutions\r\nspatiales (entre 250 m et 1 km).\r\n\r\nLes objectifs de ce stage comprennent la production d\'un corpus mis à\r\ndisposition et d\'un rapport détaillant le contenu et les liens\r\nsémantiques entre les différentes données. Le livrable consistera dans\r\nla rédaction d\'un data paper permettant la valorisation du corpus\r\nconstitué.\r\n\r\nLe planning prévisionnel est structuré comme suit :\r\n\r\n\r\n1. étude du cahier des charges du corpus à constituer et choix de la\r\nzone d\'étude,\r\n\r\n2. adaptation et mise en oeuvre du processus de récolte des données\r\n(via le système existant mis à disposition)\r\n\r\n3. constitution du corpus (textes, images) sur la zone d\'étude,\r\n\r\n4. Mise en relation et évaluation du corpus avec les experts,\r\n\r\n5. Rédaction du Data paper.\r\n\r\nCompétences requises :\r\n\r\nLangages Python et Java, outils NLP (souhaité)\r\n\r\nCapacité de travail en équipe pluridisciplinaire.\r\n\r\nDivers :\r\n\r\nDurée : 5 à 6 mois\r\n\r\nGratification : taux légal en vigueur\r\n\r\nLocalisations : TETIS (Maison de la Télédétection) à Montpellier\r\n\r\nCandidature :\r\n\r\nEnvoyer un CV + relevés de notes des deux dernières années à\r\nroberto.interdonato@cirad.fr et agnes.begue@cirad.fr'),
(536, '2018-11-28', 'Yseop', 'Lyon', 'Sujet: Extraction non supervisée de relations syntaxiques profondes à\r\npartir de corpus\r\n\r\n= La société\r\n\r\nYseop est l\'éditeur international d\'un logiciel d\'Intelligence\r\nArtificielle spécialisé dans la génération automatique de texte en\r\nlangage naturel (Natural Language Génération ou NLG).\r\nNous offrons une solution qui raisonne, dialogue et rédige comme un être\r\nhumain, en plusieurs langues, et qui se concentre sur deux coeurs\r\nd\'expertise : la génération automatique de rapports et la relation\r\nclients.\r\nAujourd\'hui, nous comptons plus de 50 000 utilisateurs quotidiens de la\r\ntechnologie Yseop, principalement des entreprises du CAC 40 et du\r\nFortune 500.\r\n\r\n= La mission\r\n\r\nL\'objet du stage est de réaliser un analyseur de corpus extrayant des\r\nrelations syntaxiques profondes (et leur arguments) liées à des\r\nprédicats donnés dans des corpus client. Cette extraction servira\r\nd\'entrée à un processus d\'apprentissage qui permettra l\'adaptation des\r\ngrammaires de génération à un contexte applicatif spécifique. On pourra\r\npar exemple se baser sur des approches comme UCCA (Universal Conceptual\r\nCognitive Annotation) ou FrameNet.\r\n\r\nLa langue des documents est l\'anglais mais le prototype réalisé devra\r\nêtre aisément portable sur d\'autres langues, en premier lieu le\r\nfrançais.\r\n\r\nCette mission se déroulera au sein de l\'entité Yseop Lab, en étroite\r\ncollaboration avec les équipes travaillant sur l\'apprentissage et\r\nl\'analyse automatique des langues.\r\n\r\n= Le profil recherché\r\n\r\nVous avez un niveau M2 en TAL, avec de bonnes connaissances en\r\nprogrammation, en particulier en Python avec des outils TAL associés\r\n(Spacy, NLTK). Des connaissances en bases de données, en modélisation\r\ndes données et en apprentissage automatique seront appréciées.\r\n\r\nLe stage se déroule dans les locaux de la société, à Paris (75001), pour\r\nune durée de 6 mois à partir de début Janvier 2019.\r\n\r\n= Pour postuler\r\n\r\nRendez-vous sur la page\r\nhttps://www.welcometothejungle.co/companies/yseop/jobs/stage-nlp-analyse-de-corpus_paris'),
(537, '2018-11-28', 'INRA', 'Montpellier', 'L\'INRA de Montpellier propose un stage de Master de constitution d\'une\r\nressources terminologique en lien avec l\'analyse de la littérature\r\nscientifique sur les matériaux issus de la biomasse d\'origine animale ou\r\nvégétale.\r\n\r\nContexte\r\n\r\nLa littérature et les travaux de recherche récents menés dans le domaine\r\ndes matériaux et emballages bio-sourcés révèlent un foisonnement\r\nd\'acteurs venant de champs disciplinaires multiples. Il est encore\r\ndifficile de partager un vocabulaire commun dû à des représentations\r\nontologiques divergentes et à la polysémie existante, à commencer par\r\nles différents sens que prend le préfixe « bio » selon que l\'on se place\r\ndu point de vue de la ressource (bio-ressources, biomasse), du procédé\r\n(biotechnologies, bio-ingénierie, bioprocédés, bio-raffineries), du\r\nproduit (bioplastique, biomatériau, biomolécule) ou des fonctionnalités\r\npost-usage (biodégradable, bio-compostable, bio-déchets) ou encore de\r\nl\'ensemble de la chaine (bio-économie, bio-industries, bio-marchés).\r\n\r\nNous souhaitons collecter et compiler les connaissances actuelles\r\nconcernant les définitions, les normes et les acteurs qui s\'intéressent\r\naux matériaux bio-sourcés dans le but d\'améliorer notre communication\r\nscientifique et technique, grand public, nos dispositifs de veille mais\r\naussi d\'aide à la décision.\r\n\r\nDescription des missions\r\n\r\nLa/le stagiaire aura pour principale mission de réaliser une analyse\r\nbibliométrique et terminologique autour des matériaux et emballages\r\nbio-sourcés. Le projet démarrera à partir d\'entretiens et de collectes\r\nd\'information et de documents scientifiques (rapports, articles etc.)\r\nproduits au sein de l\'Inra et notamment des départements à forte\r\nactivité dans les produits bio-sourcés. Ces primo-données (Web et autres\r\nsources) feront l\'objet d\'une analyse lexicale et sémantique basée\r\nnotamment sur  une extraction terminologique et bibliométrique en\r\nutilisant les outils exploités et le savoir-faire développé au sein de\r\nl\'IST/Inra. Le vocabulaire identifié viendra compléter des listes déjà\r\nétablies par des scientifiques et le tout sera organisé sous la forme\r\nd\'un lexique ou d\'un thésaurus proposant des définitions. Une fois\r\npublié selon les standards du Web sémantique notamment, cette ressource\r\npourra servir de référence dans le domaine.\r\n\r\nA cette fin, la/le stagiaire assurera la mobilisation d\'un corpus coeur\r\nd\'une 40aine de chercheur localisés sur une 10aine de villes françaises,\r\nafin de réaliser une analyse terminologique (Français/ Anglais)  issue\r\nde la consultation. Ceci constituera un préambule à des requêtes sur le\r\nWOS afin de compléter le corpus qui fera l\'objet d\'une analyse\r\nbibliométrique. Elle/il mettra en place la solution logicielle\r\npermettant aux scientifiques du département CEPIA d\'accéder et de\r\nconsulter le corpus documentaire et les résultats de l\'analyse\r\nbibliométrique. Pour toutes ces tâches, les moyens techniques et\r\nl\'accompagnement nécessaires seront mis à disposition par la DIST/Inra\r\ndans le cadre de son offre de services aux chercheurs.\r\n\r\nEnfin, le stagiaire pourra étudier les apports potentiels du vocabulaire\r\ndans le cadre d\'une veille scientifique et/ou réglementaire.\r\n\r\nLivrables\r\n\r\n- Une analyse bibliométrique et une base documentaire sur les produits\r\n  biosourcés (matériaux et emballages biosourcés)\r\n\r\n- Un vocabulaire (thésaurus ou lexique) des produits biosourcés qui\r\n  pourra être publié\r\n\r\nProfil requis\r\n\r\n- Étudiant en master 1 ou master 2 ou élève-ingénieur en 4ème ou 5ème\r\n  année dans les domaines Documentaires/bibliométriques, Linguistique,\r\n  Traitement Automatique des Langues, Analyse documentaire, ingénierie\r\n  des connaissances et sciences. Des connaissances sur les matériaux\r\n  issus de la biomasse seront appréciées.\r\n\r\n- capacités à travailler en autonomie età solliciter les personnes\r\n  ressources nécessaires à la réalisation du projet Motivé, travailleur,\r\n  rigoureux et ouvert d\'esprit\r\n\r\n- Anglais lu et parlé\r\n\r\nModalités de candidature\r\n\r\nLes candidat.e.s doivent transmettre un CV et une lettre de motivation\r\naux encadrants, le stage démarrera à partir de début Mars 2019.\r\n\r\nConditions du stage\r\nDurée : 6 mois, à partir de Mars 2019\r\nLieu : UMR IATE, INRA Montpellier\r\nGratification : Environ 550 ¤ net/mois\r\n\r\nSophie Aubin\r\nDIST\r\nINRA - Bâtiment D\r\n42, Rue Georges Morel,\r\n49070 Beaucouzé\r\n02 41 22 56 57'),
(538, '2018-12-03', 'LIG / Gipsa Lab', 'Grenoble', 'Sujet\r\n\r\nSystème d\'annotation automatique du beatbox et conversion morphographique\r\n\r\nEncadrants\r\n\r\n- Benjamin Lecouteux et Didier Schwab (LIG)\r\n  [Benjamin.Lecouteux@univ-grenoble-alpes.fr Didier.Schwab@imag.fr]\r\n\r\n- Nathalie Henrich Bernardoni (GIPSA-lab)\r\n  [Nathalie.Henrich@gipsa-lab.fr]\r\n\r\navec la participation d\'Adrien Contesse (Vocal Grammatics)\r\n\r\nDescription du stage\r\n\r\nCommuniquer par la parole ou par le chant requiert une bonne\r\ncoordination des gestes respiratoires, phonatoires et articulatoires,\r\nadaptée aux contraintes phonétiques et physiologiques et à la situation\r\nde communication. C\'est même le corps tout entier, de la posture aux\r\ngestes vocaux et manuels, qui devient instrument au service de\r\nl\'expression humaine. Dans ce contexte, un art vocal urbain émergent est\r\nparticulièrement intéressant, le Human Beatbox (en français, boîte à\r\nrythme humaine). Cette pratique artistique s\'est développée au cours des\r\nannées 1980 en s\'inscrivant dans le cadre de la culture hip-hop.\r\n\r\nPlusieurs équipes de recherche se sont intéressées au beatbox, notamment\r\nl\'équipe VSLD du GIPSA-lab, en collaboration avec le LPNC pour les\r\naspects phonétiques et le TIMC pour les aspects ventilatoires. Pour ces\r\ntravaux, les chercheurs annotent manuellement des performances de\r\nbeatbox au niveau phonétique pour en étudier la production. Ce travail\r\nest long, fastidieux, et difficile à réaliser avec les alphabets actuels\r\n(API, beatbox alphabet). Il pourrait être effectué avec le soutien des\r\noutils d\'annotation automatiques.\r\n\r\nDe grands progrès ont été réalisés récemment dans le domaine de la\r\nreconnaissance automatique de la parole grâce à l\'apprentissage profond\r\n: nous pouvons voir le beatbox comme une langue à part entière, un\r\nlangage musical. L\'objectif du stage est d\'explorer les méthodes\r\npermettant d\'annoter automatiquement des prestations de beatbox (sous\r\nformes d\'unités phonétiques, par exemple), en s\'appuyant sur des outils\r\nétat de l\'art tels que KALDI ou ESPnet.\r\n\r\nUn autre aspect de ce stage porte sur la représentation sous la forme\r\nd\'unités pictographiques de ces mêmes démonstrations. Récemment, des\r\ninfographistes et pratiquant du beatbox ont proposé des associations\r\nsons/pictogrammes qui s\'appuie sur une approche de phonétique\r\narticulatoire des sons produits en Human Beatbox. Il s\'agit du projet «\r\nVocal Grammatics » (http://www.vocalgrammatics.fr) qui permet par le\r\ndéveloppement d\'une représentation morphographique des sons du beatbox\r\nde faciliter la transcription des séquences musicales, et\r\nl\'apprentissage par les enfants et les adultes. Le stagiaire de master\r\ntravaillera également sur la projection de sons de beatbox sous la forme\r\nd\'unités pictographiques.\r\n\r\nLe master se fera dans le cadre d\'une collaboration entre deux\r\nlaboratoires : le LIG pour les aspects reconnaissance automatique de la\r\nparole et le GIPSA-lab pour les aspects voix/linguistique. Il sera\r\nencadré par Benjamin Lecouteux et Didier Schwab (LIG) et Nathalie\r\nHenrich Bernardoni (GIPSA-lab), avec la participation de l\'infographiste\r\nAdrien Contesse (Vocal Grammatics).'),
(539, '2018-12-03', 'Synomia', 'Boulogne-Billancourt', 'Sujet: Deep learning et parsing multilingue\r\n\r\n= La société\r\n\r\nSynomia édite des assistants professionnels qui aident les\r\n\"brain-workers\", c\'est-à-dire celles et ceux qui ont la charge\r\nd\'identifier et de saisir de nouveaux territoires, idées et\r\nopportunités, dans leurs tâches quotidiennes. Synomia dispose d\'une\r\ntechnologie NLP propriétaire qu\'elle enrichit continuellement depuis\r\nses débuts, et qui constitue le socle technologique sur lesquelles\r\nsont basées toutes les apps commercialisées par l\'entreprise. Synomia\r\na été élue Meilleure start-up où il fait bon travailler au le\r\nclassement HappyAtWork en 2017 et en 2018.\r\n\r\n= La mission\r\n\r\nL\'objet du stage est de tester différentes approches de Deep Learning\r\npour réaliser des analyseurs de corpus dans différentes langues. Cette\r\nmission se déroulera au sein de l\'équipe NLP de Synomia, dirigée par\r\nD. Bourigault.\r\n\r\n= Le profil recherché\r\n\r\nVous avez un niveau M1 ou M2 en TAL, avec de bonnes compétences en\r\nprogrammation, en particulier en Python, ainsi qu\'une bonne\r\nconnaissance des techniques d\'apprentissage automatique.\r\n\r\nLe stage se déroule dans les locaux de la société, à\r\nBoulogne-Billancourt (92100), pour une durée de 3 à 6 mois à partir de\r\nJanvier 2019.\r\n\r\nContacts : rose.louis@synomia.com'),
(540, '2018-12-03', 'IGN', 'Saint-Mandé', 'Le laboratoire des sciences et technologies de l\'information\r\ngéographique (LaSTIG) de l\'IGN propose un stage de M2 sur\r\nl\'identification des variations expressives des noms de lieux, en lien\r\navec l\'intention du producteur.\r\n\r\n------ Mots clés\r\n\r\nInformatique, TAL, nom de lieu, distance entre chaîne de caractères\r\n\r\n------ Contexte\r\n\r\nCe stage s\'intègre au projet ANR 2016 CHOUCAS qui implique des\r\nchercheurs en raisonnement spatial, gestion de données et de\r\nconnaissances, extraction d\'information et géovisualisation de\r\ndonnées. Le projet vise à améliorer le processus de décision lors de la\r\nlocalisation de personnes en détresse en milieu naturel terrestre, en\r\nréponse à un besoin exprimé par le Peloton de gendarmerie de haute\r\nmontagne de Grenoble (PGHM). L\'objectif est de proposer des méthodes et\r\ndes outils permettant de constituer et enrichir des données\r\ngéographiques issues de sources hétérogènes, des modèles de raisonnement\r\nspatial flou, et des environnements de géovisualisation. La localisation\r\nest effectuée, lors de l\'appel téléphonique émis la victime, par les\r\nsecouristes du PGHM qui disposent de nombreuses sources de données\r\ntextuelles hétérogènes : guides touristiques, guides de randonnées,\r\ndescriptions d\'itinéraires, récits de randonnées, etc. Ces sources sont\r\nqualifiées d\'hétérogènes parce qu\'elles diffèrent par la longueur, les\r\nobjectifs, le niveau de langue, le contexte de production, le lexique,\r\nla morphologie, la syntaxe, etc.\r\n\r\n------ Sujet\r\n\r\nLes noms propres de lieux constituent des informations cruciales pour\r\nlocaliser un document. Cependant, la graphie de ces noms ne correspond\r\npas toujours à celle que l\'on peut trouver dans les dictionnaires de\r\nnoms propres de lieux. Certaines variations peuvent être analysées comme\r\ndes coquilles, d\'autres sont inspirées des pratiques d\'écriture\r\nvéhiculées par les réseaux sociaux, et relèvent donc d\'une variation\r\nvolontaire, portée par une intention.\r\n\r\nDes outils informatiques existent pour mesurer la distance entre deux\r\nchaînes de caractères. Cependant, ces distances ne prennent pas en\r\ncompte des phénomènes courants et facilement interprétables par des\r\nhumains : par exemple, la troncature de Pralognan-la-Vanoise en\r\nPralognan ou la construction du sigle PLV, ni l\'intention éventuelle du\r\nrédacteur dans la variation : Pralognaaaaaaaaaaaan. Des variations ont\r\nété recensées et analysées, et de nouvelles distances sont définies qui\r\nprennent en compte des variations de graphie et des approximations\r\nphonétiques (stage en cours).\r\n\r\nLe premier objectif de ce stage est de construire un processus\r\nd\'identification des noms propres de lieux intégrant ces différents\r\ncalculs de distance entre chaînes de caractères, dans l\'interface GATE\r\net de mesurer ses performances (rappel, précision, F-mesure) selon les\r\ntypes de textes (corpus CHOUCAS, récits de vie, corpus d\'opinions\r\nconcernant des projets d\'aménagements urbains, corpus de titres de\r\ncartes, etc.).\r\n\r\nLe deuxième objectif vise à explorer des modifications de ces distances\r\nafin de mieux prendre en compte les caractéristiques (fondées sur des\r\nindications lexicométriques) des différents corpus dans la désignation\r\ndes lieux et guider le choix des distances à utiliser pour identifier\r\nles noms de lieux d\'un corpus à l\'aide de dictionnaires.\r\n\r\nUn troisième objectif consisterait, au vu des résultats précédents, à\r\nproposer et tester des pistes d\'identification de l\'intention de\r\nl\'auteur d\'un texte, à partir de l\'analyse de la désignation des lieux,\r\nafin de quantifier les variations entre graphie utilisée dans un texte\r\net graphie de référence d\'un nom de lieu.\r\n\r\n------ Références\r\n\r\nDominguès, C., & Eshkol-Taravella, I. (2015). Toponym recognition in\r\ncustom-made map titles. International Journal of Cartography, 1(1),\r\n109-120.\r\n\r\nFairon, C., Klein, J. R., & Paumier, S. (2006). SMS pour la science\r\n(licence: 1 utilisateur, manuel+ CD-Rom): Corpus de 30.000 SMS et\r\nlogiciel de consultation (Vol. 3). Presses univ. de Louvain.\r\n\r\nPanckhurst R. (2006a), « Le discours électronique médié : bilan et\r\nperspectives », in A. Piolat (Éd.). Lire, écrire, communiquer et\r\napprendre avec Internet. Marseille : Éditions Solal, 345-366.\r\n\r\nVéronis, J., & Guimier de Neef, E. (2006), « Le traitement des nouvelles\r\nformes de communication écrite », in Sabah, G. (Éd.), Compréhension\r\nautomatique des langues et interaction, Paris : Hermès Science, 227-248.\r\n\r\nZenasni, S., Kergosien, E., Roche, M., & Teisseire,\r\nM. (2016). Découverte de nouvelles entités et relations spatiales à\r\npartir d\'un corpus de SMS. Actes de la conférence JEP-TALN-RECITAL 2016,\r\nvolume 2, 403-410.\r\n\r\n\r\n------ Compétences particulières et formation requise\r\n\r\nCe stage s\'adresse aux étudiants de master 2 ou de 3ème année d\'école\r\nd\'ingénieurs avec une spécialisation en informatique ou en TAL.\r\n\r\n\r\n------ Lieu du stage\r\n\r\nLaboratoire en sciences et technologies de l\'information géographique \r\nInstitut national de l\'information géographique et forestière\r\n73 avenue de Paris\r\n94165 Saint-Mandé Cedex\r\nmétro : Saint-Mandé - ligne 1 ou RER A - Vincennes\r\n\r\n------ Durée et rémunération\r\n\r\ndurée : 5 mois\r\ndébut : avril 2019\r\ngratification : environ 550 euros mensuels\r\n\r\n------ Prolongements éventuels\r\n\r\nLe COGIT propose chaque année des bourses de thèse ainsi que des\r\ncontrats de post-doctorant.\r\n\r\n------ Encadrement du stage\r\n\r\nCatherine Dominguès\r\nIGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex\r\nmél : catherine.domingues[@]ign.fr\r\n\r\nPhilippe Gambette\r\nUniversité Paris-Est Marne-la-Vallée, LIGM, 5 Boulevard Descartes, 77420\r\nChamps-sur-Marne\r\nmél : philippe.gambette[@]u-pem.fr\r\n\r\n------Pour candidater\r\n\r\nLe dossier de candidature sera envoyé par courriel à Catherine Dominguès\r\net Philippe Gambette. Il devra se composer d\'un curriculum vitae et\r\nd\'une lettre de motivation, accompagnés des relevés de notes des années\r\nde M1 et M2 (ou deux dernières années d\'école d\'ingénieurs), de la\r\ndescription des enseignements suivis (un lien vers le site internet de\r\nla formation est le bienvenu) et du dernier rapport de stage ou mémoire\r\nrédigé (en version électronique).'),
(541, '2018-12-03', 'LIUM', 'Le Mans', 'Le LIUM propose une offre de stage de *Master 2* en partenariat avec la\r\nSNCF autour des word embeddings.\r\n\r\n*Sujet de stage* : AmÃ©liorer la catÃ©gorisation de documents Ã  l\'aide des\r\nword embeddings.\r\n\r\n*Laboratoire d\'accueil* : LIUM, Ã‰quipe LST - https://lium.univ-lemans.fr \r\n*Partenaire industriel* : SNCF INNOVATION & RECHERCHE\r\n*Site* : Le Mans\r\n*Co-encadrement* : Nathalie Camelin (nathalie.camelin@univ-lemans.fr), \r\n Nicolas DuguÃ© (nicolas.dugue@univ-lemans.fr)\r\n\r\n*RÃ©sumÃ©* : Le LIUM a mis en oeuvre une chaÄ±Ì‚ne de traitement pour\r\napprendre des word embeddings sur le corpus SNCF dont le vocabulaire est\r\ntrÃ¨s spÃ©cialisÃ©. La qualitÃ© des vecteurs a Ã©tÃ© Ã©valuÃ©e qualitativement\r\npar des agents SNCF. Il s\'agit pour le stage d\'utiliser ces word\r\nembeddings dans le processus de classification des documents, notamment\r\nen utilisant des Convolutional Neural Networks. Le stagiaire pourra\r\nÃ©galement contribuer Ã  amÃ©liorer l\'apprentissage des word embeddings,\r\nune nouvelle Ã©valuation des reprÃ©sentations apprises est prÃ©vue avec les\r\nagents SNCF dans la suite du projet.\r\n\r\n*Pour postuler : *Ã‰crire Ã  Nathalie Camelin et Nicolas DuguÃ© avec un CV,\r\nune lettre de motivation et votre relevÃ© de notes de M1.'),
(542, '2018-12-03', 'ICVL', 'Blois', '*Proposition de stage de recherche*\r\n\r\n  * Sujet: Représentation orientée-objet d\'expressions polylexicales\r\n    dans une métagrammaire\r\n\r\n  * Domaine de recherche: traitement automatique des langues\r\n\r\n  * Lieu du stage:\r\n    o Blois (antenne de l\'Université de Tours),\r\n    o déplacements fréquents à l\'Université d\'Orléans\r\n\r\n  * Encadrement:\r\n    o Agata Savary (http://www.info.univ-tours.fr/%7Esavary/),\r\n      laboratoire LIFAT, Université de Tours\r\n    o Emmanuel Schang (https://sites.google.com/site/emmanuelschang/),\r\n      laboratoire LLL, Université de Orléans\r\n    o Anaïs Lefeuvre-Halftermeyer\r\n      (https://sites.google.com/site/nlplefeuvreanais/), laboratoire\r\n      LIFO, Université de Orléans\r\n\r\n  * Financement: fédération ICVL <http://www.info.univ-tours.fr/ICVL/>\r\n\r\n  * Durée: 6 mois (début en février-mars 2018)\r\n\r\n  * Rémunération: 577 EUR/mois\r\n  \r\nContexte et objectifs\r\n\r\nLe domaine de ce stage est celui de la linguistique computationnelle,\r\nqui vise d\'une part la compréhension du langage naturel (c\'est à dire\r\ncelui de l\'homme, par opposition aux langages formels, dédiés aux\r\nmachines) du point de vue computationnel, et d\'autre part la\r\nconstruction de modèles et logiciels pour un traitement et une\r\ngénération utiles des énoncés langagiers.\r\n\r\nNous nous intéressons à un des défis majeurs des données langagières,\r\nqui sont les expressions polylexicales(EP), telles que le cordon bleu,\r\nle hot dog, prendre le taureau par les cornes, etc. Le problème majeur\r\nqu\'elles posent est le fait que leur sens ne peut pas être déduit du\r\nsens de leurs composants, ce qui rend difficile leur traitement par\r\nordinateur.\r\n\r\nNous souhaitions atteindre simultanément plusieurs objectifs pour le\r\ncodage de ces expressions dans une grammaire formelle:\r\n\r\n  * sa non-redondance,\r\n\r\n  * sa flexibilité,\r\n\r\n  * la réduction du coût de son développement,\r\n\r\n  * son interopérabilité.\r\n\r\nUne preuve de concept a été développée récemment pour une méthode de\r\ncodage lexical, syntaxique et sémantique des expressions polylexicales\r\navec XMG2, un langage formel orienté-objet, développé au LIFO d\'Orléans\r\net à l\'Université de Düsseldorf en Allemagne. Cette méthode appliquée à\r\nplus grande échelle devrait répondre aux 4 défis mentionnés plus haut.\r\n\r\nDans le cadre du stage, il s\'agirait de la poursuite de ces travaux. Le\r\nstage est interdisciplinaire et connecte les domaines de la linguistique\r\net de l\'informatique. On vise:\r\n\r\n  * une intégration de nouveaux types d\'EP françaises dans la\r\n    métagrammaire XMG existante, nommée FrenchTAG, selon le méthode\r\n    citée plus haut,\r\n\r\n  * l\'examen de la portabilité des EP françaises dans une langue créole,\r\n    à savoir le guadeloupéen, dont une Grammaire d\'Arbres Adjoints (TAG)\r\n    est développée au LLL,\r\n\r\n  * l\'examen de l\'impact de ces méthodes novatrices pour la tâche de\r\n    l\'analyse syntaxique (parsing) avec le formalisme des Grammaires\r\n    d\'Arbres Adjoint, qui est connu pour une représentation habile des\r\n    expressions polylexicales; un compilateur TAG et un parseur TAG sont\r\n    développés par le LIFO d\'Orléans et par l\'Université de Düsseldorf\r\n    (partenaire privilégié du LIFAT et du LIFO)\r\n\r\nProfile attendu des candidat(e)s\r\n\r\n  * Etudiant(e) en Master d\'informatique, linguistique computationnelle ou linguistique\r\n\r\n  * Connaissance de langages/grammaires formelles\r\n\r\n  * Capacité de travail en autonomie\r\n\r\n  * Mobilité Blois-Orléans\r\n  \r\n Cadre international et national\r\n\r\n  * Collaboration étroite entre le LIFAT, le LIFO et l\'Université de\r\n    Düsseldorf (Abteilung für Computerlinguistik\r\n    (https://user.phil.hhu.de/kallmeyer/team/)\r\n\r\n  * Groupe de Recherche International Structure, Emergence and Evolution\r\n    of Pidgin and Creole Languages\r\n    (http://www.pidgins-creoles.cnrs.fr/fr)\r\n\r\n  * Projet ANR PARSEME-FR (http://parsemefr.lis-lab.fr) sur le parsing\r\n    et les expressions polylexicales en français\r\n\r\n  * *Réseau PARSEME (http://www.parseme.eu), financé en 2013-2017 dans\r\n     le cadre d\'une action COST*'),
(543, '2018-12-10', 'CEA LIST', 'Saclay', 'Présentation du laboratoire d\'accueil\r\n\r\nLe Laboratoire de Vision et d\'Ingénierie des Contenus (LVIC) est l\'un\r\ndes composants de l\'Institut CEA LIST qui est spécialisé dans la\r\nconception et le développement de systèmes complexes ou à forte\r\ncomposante logicielle. Le LVIC emploie une cinquantaine de chercheurs et\r\ningénieurs travaillant sur l\'analyse et l\'interprétation de données\r\nmultimédia (texte, image et analyse de vidéos).  Dans un cadre « Big\r\nData », le laboratoire développe des algorithmes robustes pour\r\nl\'extraction, l\'analyse et le traitement de grands volumes de données\r\nmultimédia. Nos technologies ont contribué à l\'émergence de nouvelles\r\nactivités économiques par la création de startups. Par ailleurs, le\r\nlaboratoire participe à de nombreux projets collaboratifs (ANR, Europe\r\nFP7, Pôle de Compétitivité) avec des partenaires académiques, PMEs ou\r\ngrands industriels.\r\n\r\nLe Laboratoire de Vision et d\'Ingénierie des Contenus mène ses\r\nrecherches dans les domaines de la Vision par Ordinateur (Computer\r\nVision) et l\'analyse automatique de texte avec le défi d\'extraire et\r\nd\'organiser l\'information à partir de documents faiblement ou non\r\nstructurés (texte, image, vidéo).\r\n\r\nContexte du stage\r\n\r\nCe stage s\'inscrit dans le cadre du projet ANR LabForSims2 dont le but\r\nest de faire évoluer la simulation pour les professionnels de santé\r\ngrâce à l\'introduction de technologies innovantes. Deux grands axes\r\ntechnologiques (réalité mixte et analyse conversationnelle) sont\r\ninscrits dans le projet et appliqués dans deux méthodologies de\r\nsimulation : jeu sérieux décrivant la stratégie diagnostique d\'une\r\nurgence chirurgicale abdominale, d\'une part, et mannequin haute fidélité\r\ndans un scénario de réanimation néonatale, d\'autre part.\r\n\r\nL\'équipe Multimédia du LVIC est en charge, dans ce projet, du deuxième\r\naxe technologique qui traite de l\'analyse conversationnelle. Dans ses\r\ntravaux, elle a développé plusieurs agents conversationnels jouant les\r\nrôles de patient, de radiologue, de chirurgien, etc. pour dialoguer en\r\nlangage naturel avec les étudiants en médecine.\r\n\r\nDescription du stage\r\n\r\nL\'objectif de ce stage est de réaliser l\'évaluation scientifique des\r\ndifférents agents conversationnels dans le contexte médical. Le travail\r\nà réaliser consiste à collecter des données du domaine et à créer des\r\ncorpus pour l\'évaluation de la capacité des agents à comprendre et à\r\ndialoguer avec les étudiants en médecine pour des scénarios\r\nspécifiques. Plus spécifiquement, il s\'agit de :\r\n\r\n- collecter des données orales (dialogues, questions/réponses) et les\r\n  transcrire en texte (à l\'aide d\'outils automatiques) ;\r\n- annoter les données collectées ;\r\n- identifier et modéliser des critères qui permettront de mener\r\n  l\'évaluation ;\r\n- exploiter les critères et corpus pour développer et appliquer une\r\n  méthodologie d\'évaluation ;\r\n- participer à la rédaction de publications scientifiques.\r\n\r\nNiveau demandé :\r\nMaster 2 en linguistique informatique \r\n\r\nDurée : 4 à 6 mois\r\n\r\nRémunération : 700¤ pour un master 2 en université\r\n\r\nCompétences requises ou souhaitées :\r\n- Collecte et création de ressources linguistiques ;\r\n- Connaissances en TAL ;\r\n- Bonne maîtrise de la ligne de commande sous Linux (bash, python, sed,\r\n  awk...) ;\r\n- Une connaissance des agents conversationnels (chatbots) serait un plus\r\n\r\nContact :\r\nGaël de Chalendar\r\ngael.de-chalendar@cea.fr'),
(544, '2018-12-10', 'Akio software', 'Paris', 'Offre de stage chez Akio software\r\n\r\nTitre: sémantique de la relation client en anglais\r\n\r\nDescriptif:\r\n\r\nLe sujet proposé traite de l\'interprétation sémantique des informations\r\néchangées entre une entreprise et ses clients. Le mode opératoire est\r\nomnicanal dans le sens où quelque soit le moyen choisi par le client,\r\nl\'entreprise doit pouvoir faire le lien entre le contact présent et\r\nl\'historique des interactions passées.\r\n\r\nDescription du poste:\r\n\r\nL\'objectif du stage est d\'apporter un regard extérieur sur la chaîne de\r\ntraitement actuelle afin de l\'améliorer en anglais. Nous sommes ouverts\r\nà de nouvelles idées qui peuvent contribuer à notre succès au sein d\'une\r\néquipe dynamique. Le stage portera essentiellement sur la partie\r\nsémantique des composants linguistiques de calcul des thématiques, des\r\nopinions et des modalités d\'expression.\r\n\r\nProfil recherché:\r\n\r\n- Niveau Master 1 ou 2 en linguistique ou en traitement automatique du\r\n  langage.\r\n- Très bon niveau de langue en anglais, qu\'il soit académique, familier\r\n  ou argotique.\r\n- Etre un anglophone natif serait un plus.\r\n- Etre rigoureux.\r\n- Bonne maîtrise des outils informatiques.\r\n\r\nDurée:\r\n6 mois, de manière préférentielle d\'avril à septembre.\r\nDes adaptations sont possibles.\r\n\r\nLieu:\r\nAkio\r\nEquipe: traitement automatique de la langue.\r\n43 rue de Dunkerque, 75010 Paris.\r\nwww.akio.com\r\n\r\nGratification:\r\nSelon les règles en vigueur avec participation aux frais de transports\r\nen commun.\r\n\r\nEncadrement:\r\nLe stage sera encadré par Gil Francopoulo avec l\'aide de Lynda Ould\r\nYounes.\r\n\r\nCandidature:\r\nMerci d\'envoyer un CV à gfrancopoulo@akio.com et louldyounes@akio.com\r\naccompagné des notes de l\'année universitaire en cours et de celles de\r\nl\'année dernière.\r\n\r\n * Gil Francopoulo  \r\n  Expert Sémantique  \r\n *  Semantics Expert  \r\n *  T. +33 (0)1 53 20 60 44     \r\n *  43 rue de Dunkerque  \r\n  75010 Paris - France  \r\n  www.akio.com');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(545, '2018-12-14', 'LIMSI / STL', 'Paris', 'Détection automatique de mésusages de médicaments dans les réseaux sociaux\r\n\r\nOn parle du mésusage de médicaments lorsque les patients ne respectent\r\npas les prescriptions ou le bon usage de médicaments, ce qui peut\r\nmener à des situations potentiellement dangeureuses. Parmi les\r\nmésusages les plus fréquents, se trouvent par exemple le non-respect\r\ndu dosage (sur-dosage ou sous-dosage) ou la prise de médicaments pour\r\ndes indications différentes de celles pour lesquelles ils ont été\r\nprescrits.\r\n\r\nIl est estimé que la non-adhérence aux prescriptions est d\'environ 50%\r\nchez les malades chroniques dans les pays industrialisés, et que le\r\ntaux de non-adhésion est supérieur dans les pays en voie de\r\ndéveloppement [1]. Cela indique qu\'il existe un vrai problème de santé\r\npublique. En effet, les chercheurs indiquent que l\'amélioration\r\nd\'adhésion peut avoir un impact bien plus positif sur la santé de la\r\npopulation que des progrès effectués dans des traitements médicaux\r\nspécifiques [2].\r\n\r\nActuellement, il existe très peu d\'information sur les mésusages : les\r\npatients ne les signalent pas aux médecins ni aux autorités de\r\nsanté. Il est donc nécessaire d\'analyser d\'autres sources\r\nd\'information [3-6]. Nous proposons d\'étudier les informations\r\ndisponibles dans les réseaux sociaux et les forums de discussion\r\nrelatifs à la santé en français [7].\r\n\r\nL\'objectif de ce travail de stage consiste à proposer et tester des\r\nméthodes automatiques pour explorer de grands volumes de données pour\r\ndétecter de nouveaux cas de mésusages dans les réseaux sociaux. Pour\r\nla réalisation du stage, des méthodes d\'Intelligence Artificielle, de\r\nTraitement Automatique de la Langue et de fouille de textes seront\r\nutilisées.\r\n\r\nPlus spécifiquement, le stagiaire devra effectuer les tâches\r\nsuivantes:\r\n- travailler avec des corpus de textes\r\n- exploiter de méthodes de TAL, d\'IA\r\n- travailler avec les algorithmes d\'apprentissage supervisé\r\n- évaluer les résultats obtenus\r\n- faire des présentations lors des réunions\r\n- lire des articles et rédiger les rapports\r\n\r\nLe stagiaire sera amené à utiliser des outils existants et à\r\ndévelopper ses propres programmes pour mieux traiter les données.\r\n\r\nPrérequis:\r\n\r\n- connaissances en IA, TAL et informatique\r\n- manipulation et test des outils d\'IA et de TAL\r\n- habitude de Linux\r\n- capacité de travailler en équipe et individuellement\r\n- lecture et analyse de la littérature scientifique, y compris en anglais\r\n- autonomie\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\n    Niveau: Master, ingénieur\r\n    Durée: 6 mois\r\n    Lieu: Paris\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de\r\nmotivation, le relevé de notes et les contacts de deux référents à\r\nÉlise Bigeard (bigeard@limsi.fr) et Natalia Grabar\r\n(natalia.grabar@univ-lille.fr) et\r\n\r\nREFERENCES:\r\n\n\nWHO (2003). Adherence to Long-Term Therapies: Evidence for\r\nAction. Technical report, WHO. Available online at:\r\nhttp://www.who.int/chp/knowledge/ publications/adherence_report/en/\r\n(2018/06/01).\r\n\r\nHaynes, R. B., McDonald, H., Garg, A. X., and Montague,\r\nP. (2002). Interventions for helping patients to follow prescriptions\r\nfor medications. Cochrane Database Q11 Syst. Rev. CD000011. doi:\r\n10.1002/14651858.CD000011\r\n\r\nFeehan, M., Morrison, M. A., Tak, C., Morisky, D. E., DeAngelis,\r\nM. M., and Munger, M. A. (2017). Factors predicting self-reported\r\nmedication low adherence in a large sample of adults in the US general\r\npopulation: a cross-sectional study. BMJ Open 7:e014435. doi:\r\n10.1136/bmjopen-2016- 014435\r\n\r\nNatarajan, N., Putnam, W., Van Aarsen, K., Beverley Lawson, K., and\r\nBurge, Q9 F. (2013). Adherence to antihypertensive medications among\r\nfamily practice patients with diabetes mellitus and\r\nhypertension. Can. Fam. Physician 59, e93-e100\r\n\r\nCameron, D., Smith, G. A., Daniulaityte, R., Sheth, A. P., Dave, D.,\r\nChen, L., et al. (2013). Predose: a semantic web platform for drug\r\nabuse epidemiology using social media. J. Biomed. Inform. 46,\r\n985-997. doi: 10.1016/j.jbi.2013. 07.007\r\n\r\nKalyanam, J., Katsuki, T., Lanckriet, G. R. G., and Mackey,\r\nT. K. (2017). Exploring trends of nonmedical use of prescription drugs\r\nand polydrug abuse in the twittersphere using unsupervised machine\r\nlearning. Addict. Behav. 65, 289-295. doi:\r\n10.1016/j.addbeh.2016.08.019\r\n\r\nBigeard, É., Grabar, N., and Thiessard, F. (2018). Detection and\r\nAnalysis of Drug Misuses. A Study Based on Social Media\r\nMessages. Frontiers in Pharmacology, Front Pharmacol. 2018 Jul\r\n26;9:791. doi: 10.3389/fphar.2018.00791. eCollection 2018.'),
(546, '2018-12-14', 'IRIT', 'Toulouse', 'PHD and Internship positions at IRIT (Toulouse) funded by the ANR COST\r\nproject (2019-2022)\r\n\r\nTitle: Deep models for task-based information retrieval\r\n\r\nKeywords: information retrieval, deep sequential models, deep\r\nreinforcement learning\r\n\r\nAdvisors: Eric Gaussier (eric.gaussier@imag.fr), Karen Pinel-Sauvagnat\r\n(karen.pinel-sauvagant@irit.fr), Lynda Tamine-Lechani\r\n(lynda.lechani@irit.fr)\r\n\r\n===============\r\nContext\r\n===============\r\n\r\nWhile search systems today are very efficient for simple look-up\r\ninformation tasks (fact-finding search), they are unable to guide users\r\nengaged in exploratory, multi-step and highly cognitive search tasks\r\n(e.g, diagnosis, human learning). Hence, paradoxically, while we\r\nconsider information search nowadays to be \'natural\' and \'easy\', search\r\nsystems are not yet able to provide adequate support for achieving a\r\nwide range of real-life work complex search tasks[1]. In the CoST\r\nproject (funded by ANR 2019-2022), we envision a shift from search\r\nengines to task completion engines by dynamically assisting users in\r\nmaking the optimal decisions, empowering them to achieve multi-step\r\ncomplex search tasks. While most of previous work rely on query-aware\r\nmodels and techniques to structure the session context and model search\r\nsatisfaction [2,3,4] at the query level, we rather attempt to design\r\ntask-aware IR models to make task-level satisfaction predictions.\r\n===================================\r\n\r\nPhD\r\n===================================\r\nThis PhD will be focussed on applying neural approaches for task-based\r\ninformation retrieval. Based on the findings that have raised from\r\nprevious works about the effectiveness of seq2seg models to capture\r\nreformulation patterns for the next query prediction task [4,5], we\r\nenvision new end-to-end network architectures that make possible to\r\naccount for sequences of sub-tasks.  We will also explore end-to-end\r\nlearning for task satisfaction prediction based on deep reinforcement\r\nlearning that goes beyond query-level relevance. The candidate will\r\ninvestigate the modelling, the deployment and evaluation of search\r\nassistance techniques (eg., query suggestion) and ranking models using\r\ndeep neural networks architectures.  The evaluation of the resulting\r\nsystems will be carried out using both public benchmarks (eg., TREC\r\nTasks, TREC session, AOL dataset) as well as laboratory-built datasets\r\nbuilt within the CoST project.\r\n\r\n- Starting and duration: September 2019, 36 months\r\n- Skills: the successful candidate is expected to have skills/background\r\n  in information retrieval, machine learning, deep learning. Background\r\n  in reinforcement learning would be greatly appreciated.\r\n===================================\r\n\r\nInternship.\r\n===================================\r\n\r\nThis internship will be focused on: (1) a review of recent neural\r\napproaches for next query prediction in session-based search; (2) the\r\ndevelopment of a baseline framework for query prediction in task-based\r\nsearch.\r\n\r\n- Starting and duration: March 2019, 4-6 months\r\n- The successful candidate is expected to have skills/background in\r\n  information retrieval and machine learning.\r\n\r\n===================================\r\nApplication process: Deadline March, 30th 2019.\r\n===================================\r\nTo apply, please email your application to: eric.gaussier@imag.fr,\r\nkaren.sauvagnat@irit.fr, lynda.lechani@irit.fr.\r\n\r\nThe application should consist of the following:\r\n+ a curriculum vitae\r\n+ transcript of marks according to M1-M2 profile or last 3 years of\r\n  engineering school (with indication on the ranking if possible)\r\n+ covering letter\r\n+ letter(s) of recommendation including at least one letter drawn up by\r\n  a university referent\r\n\r\nPotential candidates will be invited for an interview with the supervisors.\r\n\r\n[1] Ahmed Hassan Awadallah, Ryen W. White, Patrick Pantel, Susan T.\r\nDumais, and Yi-Min Wang. Supporting Complex Search Tasks, CIKM\'2014.\r\n[2] Jiyun Luo, Sicong Zhang, and Hui Yang. 2014. Win-win search:\r\ndual-agent stochastic game in session search, SIGIR\'2014\r\n[3] Bhaskar Mitra. 2015. Exploring Session Context using Distributed\r\nRepresentations of Queries and Reformulations, SIGIR\'2015\r\n[4] Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal\r\nFleury. Learning to Attend, Copy, and Generate for Session-Based Query\r\nSuggestion, CIKM\'2017\r\n[5] Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma,\r\nJakob Grue Simonsen, and Jian-Yun Nie. A Hierarchical Recurrent\r\nEncoder-Decoder for Generative Context-Aware Query Suggestion, CIKM\'2015'),
(547, '2018-12-14', 'INRA / MAP-MAACC', 'Paris', 'AgroParisTech & INRA \r\nUMR MIA 518 \r\nEquipe LINK (Learning and INtegration of Knowledge) \r\n16, rue Claude Bernard \r\n75 231 Paris cedex 05 	\r\n\r\nUMR MAP-MAACC \r\n3495 CNRS/MCC \r\n144 avenue de Flandre \r\n75019 Paris, France 	\r\n\r\nSujet de stage de Master M2 \r\n\r\nConstruction d\'une base de connaissances pour l\'architecture\r\nbiomimétique durable\r\n\r\nContacts : liliana.ibanescu@agroparistech.fr ,\r\nnatasha.heil@paris-lavillette.archi.fr\r\n\r\nObjectifs \r\n\r\nL\'objectif du stage est de construire une ontologie pour représenter et\r\nstructurer une base de connaissances à partir des données, connaissances\r\net outils disponibles qui peuvent être utilisés pour la conception\r\nbiomimétique en architecture dans une démarche de développement durable.\r\n\r\nLe biomimétisme étudie la nature pour l\'imiter ou pour résoudre des\r\nproblèmes humains [1,3]. Les défis de la conception biomimétique sont\r\nliés d\'une part à la complexité de la biologie comme modèle à transférer\r\ndans des domaines techniques, et d\'autre part à la difficulté de\r\ncommuniquer entre des domaines disciplinaires différents [5]. Une des\r\npistes à explorer serait d\'évaluer les outils présentés dans [5] dans un\r\ncontexte donné et pour un objectif précis, e.g. l\'optimisation\r\nfonctionnelle d\'un produit.\r\n\r\nParallèlement, en architecture il existe des exemples de conception\r\ndurable inspirés de la nature [2] :\r\n\r\n 1. Le centre hydrologique de l\'Université de Namibie a des capteurs\r\n    de brouillard inspirés par la forme de la carapace du coléoptère\r\n    namibien Stenocara dont les micro-bosses attirent l\'eau et les\r\n    rainures cireuses la font circuler.\r\n    \r\n 2. L\'Esplanade Theater à Singapour [1] a une toiture inspirée par la\r\n    peau des fruits du durian [2] et elle est composée de panneaux\r\n    d\'aluminium qui filtre la lumière naturelle et qui change de\r\n    direction selon la position du soleil. Cette innovation dans\r\n    l\'architecture réduit de 30% l\'énergie totale consommée dans le\r\n    bâtiment et de 55 % l\'utilisation de l\'éclairage artificiel.\r\n    \r\n 3. La forme du bâtiment de l\'ArtScience Museum de Singapour [3] ,\r\n    inspirée par la fleur de lotus, permet de récupérer l\'eau de pluie\r\n    et laisse enter la lumière naturelle dans plusieurs directions\r\n    diminuant ainsi l\'usage de l\'éclairage artificiel.\r\n\r\nL\'approche biomimétique est adoptée pour le développement durable, mais\r\nelle n\'est pas utilisée de manière productive dans le domaine de\r\nl\'architecture. La difficulté réside dans la recherche et\r\nl\'identification de modèles biologiques pertinents pour le défi de la\r\nconception.\r\n\r\n\r\nRésultats attendus \r\n\r\nDans ce projet nous nous intéressons à l\'identification et à la\r\ncapitalisation des ressources (données, référentiels et outils)\r\nexistantes dans le domaine de la conception biomimétique et qui seraient\r\nutiles pour l\'architecture durable. Le premier enjeu sera d\'identifier\r\net de définir les concepts clés à la croisé de ces deux domaines\r\n(conception biomimétique et architecture durable). Ensuite seront\r\névalués les ressources identifiées dans [5] pour sélectionner celles qui\r\npeuvent être réutilisées en architecture, et qui sont\r\nouvertes/accessibles. Une troisième étape sera d\'explorer s\'il existe\r\nsur le web de données liées des référentiels concernant les différents\r\ndomaines d\'intérêt (i.e. biomimétisme, architecture, processus de\r\nconception, développement durable) et proposer des liens entres les\r\nconcepts identifiés et ces référentiels. Enfin, un premier prototype\r\nd\'une ontologie noyau sera proposé.\r\n\r\nLes trois partenaires de ce projet sont d\'une part des membres de\r\nl\'équipe LInK de l\'UMR MIA 518 experte en représentation de\r\nconnaissances, construction et alignement d\'ontologies, et, d\'autre\r\npart, un membre du MAACC, le laboratoire de Modélisation pour\r\nl\'Assistance à l\'Activité Cognitive de la Conception, qui est une équipe\r\nde l\'UMR MAP 3495 CNRS/MCC (Modèles et simulations pour l\'Architecture\r\net le Patrimoine) et un membre de l\'équipe BIOADAPT de l\'UMR 7179\r\nCNRS-MNHN.\r\n\r\n\r\n\r\nBibliographie \r\n\r\nBenyus J. (1997) Biomimicry: Innovation Inspired by Nature, New York,\r\nHarper Collins Publishers\r\n\r\nChayaamor-Heil, N., Guéna, F., Hannachi-Belkadi, N. (2017) Biomimétisme\r\nen architecture. État, méthodes et outils, Les Cahiers de la recherche\r\nArchitecturale Urbaine et Paysagère\r\nhttps://journals.openedition.org/craup/309\r\n\r\nISO 18458:2015 Biomimetics -- Terminology, concepts and\r\nmethodology. https://www.iso.org/standard/62500.html\r\n\r\nSuárez-Figueroa M.C., Gómez-Pérez A., Fernández-López M. (2012) The NeOn\r\nMethodology for Ontology Engineering. In: Suárez-Figueroa M.,\r\nGómez-Pérez A., Motta E., Gangemi A. (eds) Ontology Engineering in a\r\nNetworked World. Springer, Berlin, Heidelberg\r\n\r\nWanieck, Kristina & Fayemi, Pierre-Emmanuel & Maranzana, Nicolas &\r\nZollfrank, Cordt & Jacobs, Shoshanah (2017) Biomimetics and its Tools,\r\nBioinspired, Biomimetic and Nanobiomaterials. 1-52\r\n\r\nLieu du stage: AgroParisTech (Paris), durée de 6 mois, stage rémunéré\r\n(environ 500 euros par mois)\r\n\r\n[1] https://fr.wikiarquitectura.com/b%C3%A2timent/complexe-esplanade/ \r\n\r\n[2] un fruit exotique originaire d\'Asie du Sud \r\n\r\n[3] https://www.safdiearchitects.com/projects/marina-bay-sands-artscience-museum'),
(548, '2018-12-21', 'Viavoo', 'Boulogne-Billancourt', 'Stage 6 mois pour M2 : Ingénieur(e)-Linguiste TAL\r\n\r\nBoulogne-Billancourt, Île-de-France, France - R&D - Ing-TAL\r\n\r\n*Viavoo RECRUTE !*\r\n\r\nÉditeur SaaS, Viavoo compte parmi les leaders européens en solutions\r\nsémantiques multilingues et multicanaux.\r\n\r\nForte d\'un important travail de R&D en continu depuis sa création en\r\n2009, Viavoo a développé un ensemble technologique qui associe\r\ningénierie linguistique et intelligence artificielle au service de\r\nsolutions de Customer Intelligence (Analytics, Insights-API, Reports,\r\nBenchmark) et de Bot (mail, chat, voice).\r\n\r\n*Votre mission*\r\n\r\nViavoo recrute un(e) stagiaire dont le rôle sera de travailler sur une\r\nméthode de classification automatique des verbatims clients selon des\r\nthèmes ou catégories.\r\n\r\nÀ partir d\'un corpus de données multicanaux parlant des produits et du\r\nparcours client, l\'objectif du stage est de classifier ces données en\r\nprenant en compte les technologies et modèles existants à Viavoo ainsi\r\nque l\'état-de-l\'art autour des techniques d\'annotation et de\r\nclassification automatiques.\r\n\r\nVous intégrerez l\'équipe R&D et serez amené(e) à participer à\r\nl\'évolution de la technologie hybride existante à l\'entreprise.\r\n\r\nLes tâches entreprises tout au long du stage concernent principalement :\r\n\r\n- Établir un état-de-l\'art récent sur la classification automatique\r\n- Créer un gold standard à des fins d\'évaluation\r\n- Conception et implémentation d\'un classifieur automatique\r\n- Détection automatique de classes\r\n- Tests et évaluation\r\n\r\n*Notre offre*\r\n\r\n- Un stage conventionné de 6 mois à pourvoir sur Boulogne-Billancourt\r\n- Rémunération du stage + mutuelle & prévoyance + remboursement de la\r\n  moitié du passe Navigo\r\n- Un environnement de travail dynamique, bienveillant et innovant\r\n- Un encadrement rigoureux et une équipe technique de grande qualité\r\n- Bonne ambiance, grande cuisine et babyfoot, plusieures activités entreprise\r\n\r\n*Profil recherché*\r\n\r\n- M2 en Ingénierie Linguistique / TAL / Data Science\r\n- Compétences en TAL\r\n- Connaissances en apprentissage automatique (supervisé et sans corpus\r\n  d\'entraînement)\r\n- Programmation en Python et/ou Javascript\r\n- Compréhension des enjeux pour la linguistique générale (morphologie,\r\n  syntaxe, sémantique)\r\n- Anglais technique\r\n- Autonomie et capacité à travailler en équipe\r\n\r\n*Postuler en ligne :* https://www.viavoo.com/carrieres/'),
(549, '2018-12-21', 'Institut international pour la Francophonie', 'Lyon', 'Offre de stage pour du balisage de corpus lexicographique\r\n\r\nTitre : Stage\r\n\r\nDurée : 4 mois\r\nFonction / métier : Informaticien\r\n\r\nNiveau de responsabilité : -Aucun(e)-\r\n\r\nPrésentation - missions\r\n\r\nL\'Institut international pour la Francophonie (2IF) recrute un·e\r\nstagiaire informaticien·ne.\r\n\r\nPrésentation de la structure\r\n\r\nComposante de l\'Université Jean Moulin Lyon 3, l\'Institut\r\ninternational pour la Francophonie (2IF)\r\n(https://2if.universite-lyon.fr/) travaille sur l\'étude, la\r\ncompréhension et le rayonnement de la Francophonie à travers trois\r\nmissions :\r\n\r\n- La formation initiale sur le thème de la Francophonie ;\r\n- La production de recherche sur l\'objet francophonie et son attractivité ;\r\n- Production d\'idées, de discours et prospective sur et pour la Francophonie.\r\n\r\nParmi ses actions, l\'institut est l\'opérateur d\'un projet de\r\nDictionnaire des francophones piloté et financé par la Délégation\r\ngénérale à la langue française et aux langues de France\r\n(http://www.culture.gouv.fr/Thematiques/Langue-francaise-et-langues-de-France).\r\n\r\nDescription de la mission du stage\r\n\r\nSous la direction de Noé Gasparini (chef de projet du Dictionnaire des\r\nfrancophones, 2IF), la/le stagiaire participera au projet de\r\nDictionnaire des francophones. Ce projet vise à aligner plusieurs\r\nressources lexicographiques francophones afin de les rendre\r\naccessibles en ligne, et de permettre leur enrichissement\r\nultérieur. La base de données est structurée grâce à l\'ontologie\r\nOntoLex. Le développement informatique est réalisé par une entreprise\r\nextérieure, l\'Institut international pour la francophonie assurera\r\nl\'encadrement stratégique mais n\'assurera pas d\'encadrement\r\ninformatique.\r\n\r\nCe stage consistera en une participation à la numérisation du\r\ndictionnaire intitulé Inventaire des particularités lexicales du\r\nfrançais d\'Afrique noire publié initialement en 1983 et réédité en\r\n2004.\r\n\r\nPlusieurs étapes sont prévues :\r\n\r\n- Conception d\'un outil de balisage permettant d\'ajouter dans le\r\ndocument numérisé les balises propres à l\'ontologie OntoLex (RDF/OWL)\r\nafin d\'aligner cette ressource avec les ressources existantes.\r\n\r\n- Identification des nouvelles balises nécessaires, qui ne sont pas\r\nencore dans le vocabulaire contrôlé déjà collecté, et documentation de\r\nleur intégration.\r\n\r\n- Développement d\'un outil d\'affichage permettant de faciliter la\r\nrelecture manuelle des erreurs de balisage, des coquilles\r\ntypographiques et orthographiques. La relecture détaillée sera\r\nréalisée durant le stage et l\'outil doit pouvoir permettre la\r\nrelecture ultérieure d\'autres ressources numérisées.\r\n\r\n- Rédaction de la documentation afin de permettre l\'extension de\r\nl\'outil de balisage à d\'autres ressources.\r\n\r\nCes outils et la documentation associée, de même que tout le\r\ndéveloppement logiciel et les données présentes dans les bases de\r\ndonnées seront publiés sous licence libre.\r\n\r\nType de structure : Etablissement public scientifique et technique\r\n\r\nStructure de recrutement : Université Jean Moulin Lyon 3 (Institut\r\ninternational pour la Francophonie - 2IF)\r\n\r\nEmplacement : Bâtiment Citroën (bureau 110), 24 rue Salomon Reinach,\r\n69007 Lyon\r\n\r\nConditions d\'exercice : Stage conventionné de 4 mois du 1 er avril au\r\n31 juillet 2019 à temps plein (35 heures par semaine avec\r\ngratification légale minimale).\r\n\r\nProfil recherché\r\n\r\nÉtudiant·e en informatique, de préférence formé·e en ingénierie de la langue.\r\n \r\n- Connaissance du balisage des données, idéalement en RDF\r\n- Sens de l\'organisation et du travail en autonomie\r\n- Rigueur, esprit d\'initiative et de synthèse\r\n- Un intérêt pour la diversité des usages de la langue française\r\n  serait un plus\r\n\r\nDATES LIMITES\r\nDate limite de candidature : 03/03/2019\r\nDate de prise d\'effet du poste : 01/04/2019\r\nDate de publication : 21/12/2018\r\nContact et information\r\nCandidature et demande d\'information à adresser à\r\nnoe.gasparini@univ-lyon3.fr\r\n04.78.78.73.76'),
(550, '2019-01-07', 'EDF', 'Chatou', 'Stage - TALN, text-mining et ontologies pour la maintenance\r\nd\'installations solaires photovoltaïques - H/F (St-19-0001)\r\n\r\nExtension d\'une chaîne de traitement TAL (ontologie et règles)\r\nd\'extraction de données à partir de compte rendus textuels non\r\nstructurés d\'interventions de maintenance.\r\n\r\nRéférence de l\'offre de stage : ST-19-0001\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-19-0001\r\n\r\nType d\'offre : Offre de Stage (long)\r\n\r\nNiveau de formation : A partir de bac +4\r\n\r\nSpécialité(s) : Génie informatique / Télécommunications\r\n\r\nDomaine d\'intervention : R&D\r\n\r\nPays : France\r\n\r\nRégion(s) : Ile de France\r\n\r\nDépartement(s) : Yvelines\r\n\r\nVille(s) : CHATOU (78400)\r\n\r\nNombre de postes : 1\r\n\r\nMise en ligne le : 2018-12-18\r\n\r\nDescription de l\'offre\r\n\r\nCONTEXTE\r\n\r\nLes installations de production d\'électricité solaires photovoltaïques\r\nsont appelées à se développer très fortement en accord avec la\r\nProgrammation Pluriannuelle de l\'Energie présentée par le gouvernement\r\nfin novembre 2018 et le Plan Solaire d\'EDF lancé le 11 décembre 2018\r\npour développer 30 GW d\'énergie solaire en France d\'ici 2035.\r\n\r\nComme toute installation de production d\'électricité, la bonne\r\nperformance dans la durée est conditionnée à une maintenance et une\r\nsurveillance adaptées des installations pour identifier au plus tôt les\r\ndéfauts ou sous-performances, les corriger mais aussi affiner les\r\npolitiques de maintenance préventives voire parfois les choix de\r\nconception ; pour cela, les ingénieurs et techniciens spécialistes de\r\nces installations peuvent notamment analyser le Retour d\'Expérience,\r\nc\'est-à-dire analyser les événements de surveillance et de maintenance\r\ndéjà intervenus sur les installations existantes pour en tirer des\r\nleçons pour la maintenance à venir.\r\n\r\nDans un domaine et une problématique voisine, une chaîne de traitement\r\nTALN a été développée pour extraire les actions de maintenance réalisées\r\nsur les composants à partir de textes de compte-rendu techniques\r\nd\'intervention de maintenance d\'éoliennes afin de constituer des bases\r\nstructurées d\'historiques d\'opérations de maintenance réalisées sur les\r\ninstallations ; cette chaîne de traitement TAL se base notamment sur des\r\nressources dédiées qui ont été structurées dans une ontologie et sur des\r\nrègles d\'extraction (JAPE) dans une application basée sur la plateforme\r\nGATE de l\'Université de Sheffield.\r\n\r\nLe besoin est de constituer des bases de données d\'événements de\r\nmaintenance et d\'exploitation à partir de corpus textuels non\r\nstructurés. Il s\'agit de mettre en oeuvre des techniques de traitement\r\nautomatique du langage naturel (TALN) et d\'analyse sémantique afin\r\nd\'identifier les évènements tracés dans les textes pour reconstituer ces\r\nbases d\'évènements de maintenance et d\'exploitation des installations.\r\n\r\nUn événement est une combinaison d\'informations, comme par exemple pour\r\nla maintenance, une date, un composant d\'un matériel, un type\r\nd\'opération de maintenance et une action (prescription, réalisation,\r\n...) ou par exemple pour la surveillance une date, un composant d\'un\r\nmatériel, et un état ou un défaut observé, ou encore une valeur\r\nmesurée. Certaines de ces informations peuvent être corroborées par des\r\ninformations structurées disponibles dans d\'autres parties du système\r\nd\'information (base de données de pièces de rechange...). Des documents\r\npeuvent ne contenir aucune des informations recherchées alors que\r\nd\'autres documents peuvent en contenir plusieurs qu\'il ne faut pas\r\nmélanger.\r\n\r\nOBJECTIF ET DESCRIPTIF DU STAGE\r\n\r\nL\'objectif du stage est de reprendre la chaîne de traitement TALN\r\ndéveloppée pour la maintenance des éoliennes et d\'éventuelles extensions\r\nspécifiques déjà réalisées pour les documents du domaine photovoltaïque\r\net de proposer et de réaliser des améliorations pour en étendre le champ\r\nd\'application au traitement du domaine de la maintenance des\r\ninstallations solaires photovoltaïques. Cela nécessitera notamment\r\nd\'enrichir l\'ontologie pour prendre en compte les composants des\r\ninstallations solaires, les actions de maintenance spécifiques à ces\r\ninstallations (en enrichissant les actions et composants dans\r\nl\'ontologie existante), ainsi que la description de constats relatifs à\r\nl\'état (visuel et fonctionnel ainsi que des défauts, dégradations etc.)\r\ndes composants qui constitue un nouveau besoin du domaine (en plus de\r\nl\'identification des actions sur les composants).\r\n\r\nAvec des techniques et outils de text-mining TALN/analyse sémantique, le\r\ntravail de stage consiste donc à :\r\n\r\n- Prendre connaissance de la chaîne de traitement et de l\'analyse à\r\n  réaliser et proposer des pistes d\'amélioration ;\r\n\r\n- Contribuer à la priorisation des pistes d\'amélioration avec les\r\n  chercheurs EDF R&D ;\r\n\r\n- Concevoir, développer et évaluer des améliorations et compléments dans\r\n  l\'ontologie et la chaîne de traitement ;\r\n\r\n- Positionner la solution mise en oeuvre dans l\'étude vis-à-vis des\r\n  autres solutions déjà mises en oeuvre par EDF sur d\'autres projets.\r\n\r\nConditions du stage :\r\n\r\nLe stage se déroulera au sein des locaux d\'EDF R&D à Chatou et sera\r\nrémunéré.\r\n\r\nDurée : 6 mois.\r\n\r\n\r\nProfil souhaité\r\n\r\nEtudiants concernés :\r\nMASTER, ou Fin d\'études ingénieur.\r\n\r\nCompétences souhaitées :\r\nLa réalisation de cette étude nécessite des compétences en modélisation\r\ndes connaissances, en techniques de fouille de textes, en text-mining de\r\ntype Traitement Automatique du Langage Naturel et Analyse Sémantique,\r\nainsi que des techniques et outils du web sémantique, notamment RDF.\r\n\r\n\r\nInformation et candidature :\r\nEn postulant sur cette offre sur le site internet :\r\nhttps://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-19-0001'),
(551, '2019-01-07', 'LIP6', 'Paris', 'Sujet Structuration et établissement de filiations entre des données hétérogènes: le cas des archives de Jacques Derrida\r\n\r\nContexte \r\n\r\nL\'Institut des Textes et Manuscrits Modernes (ITEM, UMR 8132 ENS-CNRS)\r\net le LIP6 (UMR 7606 Sorbonne Université - CNRS) développent un\r\nprogramme d\'exploitation des archives numériques du philosophe Jacques\r\nDerrida déposées à l\'IMEC (disques durs et supports de sauvegarde\r\ndivers, dont plus de 500 disquettes). L\'objectif du projet est d\'adapter\r\nla critique génétique à l\'environnement technologique du XXIe siècle en\r\nexploitant les documents nativement numériques (« born digital ») d\'un\r\ncréateur. La critique génétique s\'est développée à partir des traces\r\nmanuscrites du processus créateur conservées dans les brouillons des\r\nécrivains. Depuis une trentaine d\'années, on assiste au remplacement\r\nprogressif de l\'écriture manuscrite par l\'écriture numérique, et les\r\narchives que les écrivains confient aux bibliothèques sont de plus en\r\nplus constituées d\'ordinateurs et de supports numériques. Préserver,\r\ndécrire et exploiter ces nouvelles collections numériques constitue un\r\nenjeu majeur, tant pour les institutions de conservation que pour les\r\nchercheurs.\r\n\r\nEn utilisant les outils d\'exploration développés par l\'informatique\r\nforensique, que l\'on appelle aussi la criminalistique numérique, et,\r\nplus généralement, l\'IA, le projet a l\'ambition d\'élaborer une\r\ncodicologie du XXIe siècle adaptée aux traces nativement numériques\r\nstockées dans les disques durs.\r\n\r\nDans cette perspective, le corpus des archives numériques de Jacques\r\nDerrida est particulièrement intéressant. D\'une part, Derrida est un\r\ntémoin exemplaire de la mutation numérique qui se met en place à partir\r\ndu milieu des années 1980 (il avait plus de 50 ans lorsqu\'il a fait\r\nl\'acquisition de son premier ordinateur en 1985), ce qui permet\r\nd\'observer à l\'état natif le bouleversement des pratiques d\'écriture\r\ninduit par ce qu\'il appelle les « machines à traitement de texte ».\r\n\r\nD\'autre part, par crainte d\'une disparition accidentelle de données (par\r\nsuite d\'un cambriolage ou d\'une coupure de courant), il a multiplié les\r\ncopies des textes à la rédaction desquels il travaillait. De ce fait,\r\nl\'archive numérique contient une masse de dossiers et de fichiers\r\nportant le même nom mais n\'ayant pas forcément le même contenu. Cette\r\nredondance est disséminée aussi bien à l\'intérieur d\'un support donné\r\n(on trouve des sous-arborescences partiellement identiques en différents\r\npoints de l\'arborescence d\'ensemble) qu\'entre les différents supports.\r\n\r\nAttendus du stage\r\n\r\nC\'est ce second volet qui fait l\'objet du stage proposé. Son objectif\r\nest de mettre de l\'ordre dans ce buisson foisonnant, en établissant un\r\ninventaire des différents fichiers présents dans l\'archive, puis en\r\nstructurant ces données à l\'aide d\'un graphe des différents états\r\nreprésentatifs du processus d\'écriture et en le visualisant. Pour un\r\ntexte final donné, ceux-ci devront prendre notamment en compte les\r\nemplacements physiques des fichiers correspondants, leurs noms, leurs\r\ncaractéristiques temporelles (dates de création et de modification,\r\nabsolues et relatives), les liens de parenté des fichiers entre eux\r\n(jumeaux, frères, antécédents ou successeurs), leur place dans le\r\ndéroulement temporel de l\'écriture induite de différentes façons, par\r\nexemple avec les techniques algorithmiques mises en oeuvre pour\r\nconstruire des arbres phylogénétiques.\r\n\r\nCompétences requises :\r\n\r\n- Intérêt pour les textes\r\n- Bonne connaissance d\'un langage de programmation objet (l\'idéal serait\r\n  un connaissance de Python, mais la maîtrise de Java ou d\'un autre\r\n  langage objet suffirait)\r\n- Connaissance de base en algorithmique\r\n- Des compétences dans les techniques de traitement du langage naturel\r\n  seraient un plus\r\n\r\n\r\nEncadrement et conditions financières\r\n\r\nIl s\'agit d\'un projet interdisciplinaire conduit conjointement par\r\nl\'ITEM et le LIP6. L\'encadrement sera assuré pour l\'ITEM, en particulier\r\npar Aurèle Crasson et Jean-Louis Lebrave, et pour le LIP6, par\r\nJean-Gabriel Ganascia.\r\n\r\nLe candidat percevra une gratification d\'environ 480 ¤ / mois. La durée\r\ndu stage est de 3 mois minimum pouvant se prolonger jusqu\'à 6 mois.\r\n\r\nLieu du stage\r\n\r\nÉquipe ACASA, Laboratoire Lip 6, 4 Place Jussieu, 75005 Paris\r\n\r\nContact : Jean-Gabriel Ganascia (Professeur, Sorbonne Université):\r\njean-gabriel.ganascia@lip6.fr\r\n01 44 27 37 27'),
(552, '2019-01-07', 'MaCompta.fr', 'La Rochelle', 'Offre de stage : Développements d\'outils innovants de traitement de\r\ndocuments électroniques et de reconnaissance de caractères dans le cadre\r\nd\'applications de gestion et comptabilité, stockage de données\r\nsensibles.\r\n\r\nVotre Mission :\r\n\r\nMacompta.fr est un éditeur de site internet leader sur le marché des\r\npetites entreprises et associations et en forte croissance (6.000\r\nutilisateurs, croissance de 35 % par an, 10 collaborateurs).\r\n\r\nNous accompagnons nos clients dans la numérisation de leurs process de\r\ngestion, comptabilité et paie.\r\n\r\nNous recherchons un stagiaire pour renforcer nos équipes chargées de\r\nmettre au point des solutions innovantes dans des problématiques variées\r\n: Séparation de fichiers pdf en documents unitaires, reconnaissance de\r\ncaractères pour l\'enregistrement automatisé de documents comptables,\r\nchiffrement et stockage de données, stockage sécurisé de codes d\'accèset\r\nutilisation pour une connexion sécurisée à des API bancaires.\r\n\r\nProfil : Etudiant en master 2\r\n\r\nDurée : _4 mois à 6 mois\r\n\r\nRémunération :\r\n900 brut + Tickets Restaurant.\r\n\r\nPlus de renseignements :\r\nSylvain Heurtier\r\nTél : 05 46 45 11 99\r\nsheurtier@macompta.fr\r\nPostuler :\r\nenvoyer CV + lettre de motivation à sheurtier@macompta.fr'),
(553, '2019-01-07', 'IGN', 'Saint-Mandé', '*Budget participatif dans la gestion des villes*\r\n\r\n*Mots clés*\r\nInformatique, TAL, textométrie, budget participatif\r\n\r\n*Contexte*\r\n\r\nLe budget participatif (BP) est un outil de démocratie participative en\r\nplein essor. Impulsé par une institution, il permet de dédier un budget\r\nd\'investissement à la réalisation de projets proposés par les\r\ncitoyen.nes.  Ce dispositif produit un certain nombre de données, les\r\nplus intéressantes étant probablement les propositions et les\r\ncommentaires qui y sont attachés.\r\n\r\nOpen Source Politics (OSP) est une entreprise relevant du champ de\r\nl\'économie sociale et solidaire qui développe des plateformes numériques\r\nlibres et open source et anime des ateliers d\'intelligence collective\r\npour accompagner des acteurs publics, privés et associatifs engagés dans\r\ndes démarches participatives.\r\n\r\nLes chercheurs du LaSTIG, de l\'EHESS et d\'OSP travaillent sur les\r\nbudgets participatifs de plusieurs villes et ces corpus, par leur\r\ntaille, justifient l\'utilisation d\'outils de TAL afin d\'effectuer des\r\nsynthèses aux institutions qui ont confié leurs données et leur faire un\r\nretour sur la conception de leur budget participatif.\r\n\r\n*Sujet*\r\n\r\nDifférents indicateurs et outils d\'analyse des corpus de propositions\r\nont déjà été mis en oeuvre par les partenaires, mais ils dépendent de la\r\ntaille des corpus et des a priori des villes et diffèrent par leur\r\nfacilité d\'utilisation. Dans ce contexte, l\'objectif du stage est triple :\r\n\r\n\r\n- proposer et mettre en oeuvre de nouvelles pistes d\'analyse de ces\r\n  corpus et détailler les variables sur lesquelles fonder la conception\r\n  d\'un budget participatif ;\r\n- définir un protocole minimal d\'analyse de budget participatif\r\n  (catégories, propositions, commentaires) ;\r\n- caractériser les BP, les préoccupations des contributeurs des\r\n  différentes villes et leur évolution dans le temps par une analyse\r\n  contrastive des différents corpus (différentes villes, plusieurs\r\n  années).\r\n\r\n\r\nUne partie du stage se déroulera chez OSP, et dans ce contexte, Dans la\r\npartie du stage se déroulant chez OSP, le ou la stagiaire aura l\'occasion\r\nde se familiariser avec la technique du budget participatif déployée par\r\ncette entreprise, et l\'utilisation pratique du traitement automatique de la\r\nlangue dans un cadre professionnel.\r\n\r\n\r\n*Productions attendues : *\r\n\r\n- rédaction d\'un mémoire qui devra répondre aux objectifs du stage ;\r\n- définition d\'un protocole minimal d\'analyse de budget participatif\r\n  (catégories, propositions, commentaires).\r\n\r\n*Compétences particulières et formation requise*\r\n\r\nCe stage s\'adresse aux étudiants de master 2 ou de 3ème année d\'école\r\nd\'ingénieurs avec une spécialisation en informatique ou en TAL, ainsi\r\nqu\'à .des étudiants de master 2 dans une filière en sciences sociales\r\nayant des connaissances solides en TAL ou en textométrie.\r\n\r\n*Lieu du stage*\r\n\r\nLaboratoire en sciences et technologies de l\'information géographique\r\n\r\nInstitut national de l\'information géographique et forestière\r\n73 avenue de Paris\r\n94165 Saint-Mandé Cedex\r\nmétro : Saint-Mandé - ligne 1 ou RER A - Vincennes\r\n\r\n*Durée et rémunération*\r\n\r\ndurée : 5 mois\r\ndébut : avril 2019\r\ngratification : environ 550 euros mensuels\r\n\r\n*Prolongements éventuels*\r\n\r\nLe COGIT propose chaque année des bourses de thèse ainsi que des\r\ncontrats de post-doctorant.\r\n\r\n*Encadrement du stage*\r\n\r\nCatherine Dominguès\r\nIGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex\r\nmél : *catherine.domingues[@]ign.fr*\r\n\r\n\r\nCarmen Brando\r\n\r\nCentre de recherches historiques / Plateforme Géomatique de l\'EHESS\r\n54 boulevard Raspail, 75006 Paris\r\nmél : carmen.brando@ehess.fr\r\n\r\nAntoine Gaboriau (doctorant CIFRE EHESS/OSP)\r\nLiberté Living Lab, 9 rue d\'Alexandrie, 75002 Paris\r\nmél : *antoine@opensourcepolitics.eu*\r\n\r\n*Pour candidater*\r\n\r\nLe dossier de candidature sera envoyé par courriel aux trois\r\nencadrants. Il devra se composer d\'un curriculum vitae et d\'une lettre\r\nde motivation, accompagnés des relevés de notes des années de M1 et M2\r\n(ou deux dernières années d\'école d\'ingénieurs), de la description des\r\nenseignements suivis (un lien vers le site internet de la formation est\r\nle bienvenu) et du dernier rapport de stage ou mémoire rédigé (en\r\nversion électronique).'),
(554, '2019-01-07', 'LIUM / SNCF', 'Le Mans', 'Bonjour à tou.te.s,\r\n\r\nLe LIUM propose une offre de stage de *Master 2* en partenariat avec la\r\nSNCF autour des word embeddings.\r\n\r\n*Sujet de stage* : Améliorer la catégorisation de documents à l\'aide des\r\nword embeddings.\r\n\r\n*Laboratoire d\'accueil* : LIUM, Équipe LST - https://lium.univ-lemans.fr \r\n*Partenaire industriel* : SNCF INNOVATION & RECHERCHE\r\n*Site* : Le Mans\r\n*Co-encadrement* : Nathalie Camelin (nathalie.camelin@univ-lemans.fr), \r\n Nicolas Dugué (nicolas.dugue@univ-lemans.fr)\r\n\r\n*Résumé* : Le LIUM a mis en oeuvre une chaîne de traitement pour\r\napprendre des word embeddings sur le corpus SNCF dont le vocabulaire est\r\ntrès spécialisé. La qualité des vecteurs a été évaluée qualitativement\r\npar des agents SNCF. Il s\'agit pour le stage d\'utiliser ces word\r\nembeddings dans le processus de classification des documents, notamment\r\nen utilisant des Convolutional Neural Networks. Le stagiaire pourra\r\négalement contribuer à améliorer l\'apprentissage des word embeddings,\r\nune nouvelle évaluation des représentations apprises est prévue avec les\r\nagents SNCF dans la suite du projet.\r\n\r\n*Pour postuler : *Écrire à Nathalie Camelin et Nicolas Dugué avec un CV,\r\nune lettre de motivation et votre relevé de notes de M1.\r\n\r\nMerci de transmettre aux intéressé.e.s.\r\n\r\nCordialement\r\n\r\nNicolas Dugué'),
(555, '2019-01-07', 'SNCF', 'Saint-Denis', 'Offre de stage SNCF : analyse d\'émotions et d\'opinions dans les\r\ninteractions client/agent ou agent/agent\r\n\r\nLa Direction Innovation & Recherche de SNCF recherche un stagiaire pour\r\ntravailler sur un projet d\'étude ayant pour objectif de mieux comprendre\r\nle ressenti des clients et des agents, et de détecter ce qui génère\r\nsatisfaction ou insatisfaction, à travers l\'exploration de données\r\ntextuelles.\r\n\r\nMission :\r\nAvec la montée en puissance des chatbots, agents conversationnels, ou\r\nencore agents virtuels, la détection automatique ou semi-automatique des\r\némotions devient un enjeu industriel important. En effet, si un\r\nassistant intelligent est capable de comprendre et de s\'adapter en\r\nfonction de l\'état émotionnel de son utilisateur, alors ce dernier sera\r\nplus enclin à accepter sa présence ainsi que son rôle.\r\nDans le cadre de cette problématique, SNCF souhaite mener une étude sur\r\nla détection des émotions dans ses données. Celles-ci sont de type\r\ntextuel et sont issues de plusieurs sources : web, chatbots SNCF, forums\r\ndédiés aux agents.\r\nLe stagiaire aura pour mission d\'analyser linguistiquement les marqueurs\r\nd\'émotions et d\'opinions dans des corpus SNCF, d\'étudier et de mettre en\r\noeuvre  des méthodes existantes, notamment en Traitement Automatique du\r\nLangage, pour la détection des émotions dans les corpus mentionnés\r\nci-dessus. L\'objectif du stage est double : i) le travail permettra de\r\ntester le potentiel des technologies de TAL pour la détection des\r\némotions ; ii) les analyses fournies mettront en lumière la valeur des\r\ndonnées SNCF pour des cas d\'usage client ou métier.\r\n\r\nDescriptif de la mission :\r\nPour mener à bien son étude, le stagiaire devra :\r\n\r\n- Prendre connaissance du contexte du stage (SNCF, Direction Innovation\r\n  & Recherche, objectifs du stage et cadre de réalisation, projet dans\r\n  lequel le stage s\'insère et interlocuteurs sur les sujets concernés)\r\n\r\n- Faire un état de l\'art sur la détection des émotions dans les données\r\n  langagières\r\n\r\n- Constituer le corpus d\'étude : nettoyer, transcrire, étiqueter les\r\n  données SNCF\r\n\r\n- Définir une grille d\'annotation, analyser linguistiquement et annoter\r\n  le corpus en marqueurs d\'émotions\r\n\r\n- Evaluer la qualité de l\'annotation et la richesse du corpus en\r\n  marqueurs d\'émotions\r\n\r\n- Proposer et tester des pistes d\'exploitation des résultats à l\'aide\r\n  d\'outils de traitement automatique du langage au regard des usages et\r\n  besoins métiers\r\n\r\nPrésentations et rapports :\r\n\r\n- Présentation de début de stage à la SNCF (au bout d\'un mois de stage)\r\n  : contexte du stage, planning de réalisation, premiers travaux\r\n  réalisés, méthode envisagée\r\n\r\n- Rapport final de stage complet comprenant : bref état de l\'art,\r\n  méthode retenue, travaux réalisés, résultats obtenus et difficultés\r\n  rencontrées...\r\n\r\n- Deux soutenances de fin de stage : une à l\'école et une à la SNCF\r\n\r\n- Des présentations en interne SNCF ou externes pourront être effectuées\r\n\r\nPériode souhaitée :\r\nAvril - Septembre 2019\r\n\r\nDiplôme préparé :\r\nMaster en Traitement Automatique des Langues, ou en Sciences du Langage\r\navec des notions d\'informatique.\r\n\r\nProfil souhaité / Particularités :\r\n\r\n- Compétences en Traitement Automatique des Langues (TAL), ou en\r\n  Sciences du Langage avec de bonnes notions en TAL\r\n\r\n- Manipulation et test des outils de TAL\r\n\r\n- Capacités d\'analyse et de synthèse\r\n\r\n- Autonomie, qualités relationnelles, qualité de présentation\r\n  (orale/écrite)\r\n\r\nModalités du poste\r\n\r\n- Durée : 6 mois\r\n\r\n- Rémunération prévue : indemnités de stage + carte de circulation SNCF\r\n\r\n- Début : à partir d\'avril 2019\r\n\r\n- Lieu : Saint-Denis\r\n\r\nTuteur : Luce Lefeuvre\r\n\r\nMerci d\'adresser CV et lettre de motivation à Luce Lefeuvre et Coralie\r\nReutenauer à l\'adresse mail suivante : coralie.reutenauer@sncf.fr . Date\r\nlimite de soumission des candidatures : 20 janvier 2019.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(556, '2019-01-07', 'LS2N', 'Nantes', '3-6 Month \"Artificial Intelligence for Learning\" Internship Offers\r\nhttps://aile.comin-ocw.org\r\n\r\nThe University of Nantes/LS2N Lab. (ls2n.fr) and IMT Atlantique (imt-atlantique.fr) aim at recruiting several 3-6 months interns to join our teams, starting in Spring/Summer of 2019.\r\n\r\nThe students are intended to work on research projects targeted at the Learning, Teaching and Education domains we have got running. A brief description of each internship topics is given below. The Artificial Intelligence domains concerned are Machine Learning, Data mining, Natural Language Processing, Distributed Data Management, Web Semantic, Learning analytics, User Interaction modeling.\r\n\r\nIf you are interested or have any questions, please do not hesitate to contact Olivier Aubert (olivier.aubert@univ-nantes.fr), Nicolas Hernandez (nicolas.hernandez@univ-nantes.fr) and the referrer of the internship topic.\r\nTo apply, send a curriculum vitae together with your academic results and a motivation letter and indicate the topics of interest.\r\n\r\n\r\nContext and objectives\r\n=================\r\n\r\n  Artificial Intelligence is sometimes described as the new electricity. As such, it is supposed to have a profound influence over many fields, of which Education has been repeatedly singled out.\r\n\r\n  At University of Nantes, IMT Atlantique and Ecole Centrale, researchers have taken on questions relating AI and education for some time now through several national and international projects such as COCo (coconotes.comin-ocw.org), Hubble (hubblelearn.imag.fr), PASTEL (projets-lium.univ-lemans.fr/pastel), SEDELA (sedela.cominlabs.u-bretagneloire.fr), eFIL (efil.cominlabs.u-bretagneloire.fr), X5-GON (www.x5gon.org), ClassCode (pixees.fr/classcode-v2).\r\n\r\n  The AILE (Artificial Intelligence for Learning Environment) project (https://aile.comin-ocw.org) aims at strengthening this eco-system, to develop some regular scientific activities (seminars, joint events), and to prepare their activities in the theme over the next 5 years.\r\n\r\n\r\nInternship topics (sujets de stage) list\r\n============================\r\n\r\n  In addition to the topic study, the students will also participate to transversal team activities involving simultaneously all the students and the researchers (research reading groups, seminars, conference organization).\r\n\r\nMeasuring the hardness of an educational resource\r\n--------------------------------------------------------------------\r\n  - Many educational resources are available on the web but it is important to evaluate automatically the age group the resource is intended for and the level required to understand it. This task requires the use of machine learning. This project is principally based on X5-GON data.\r\n  - Referrers: Colin de la Higuera (cdlh@univ-nantes.fr), LS2N TALN team\r\n\r\nDetecting the theme shifts in a lecture\r\n--------------------------------------------------\r\n  - In a lecture presented by a one hour video or a 50 pages pdf, the themes vary over time. We aim to use techniques from data science to study the so-called concept drift in this context. This project is based on X5-GON/PASTEL data.\r\n  - Referrers: Nicolas Hernandez (nicolas.hernandez@univ-nantes.fr) and Colin de la Higuera (cdlh@univ-nantes.fr), LS2N TALN team\r\n\r\nPredicting MOOC attrition\r\n----------------------------------\r\n  - Using learning traces left by MOOC users, and generalizing from previous activities, can we compute attrition indicators? This project is based on HUBBLE data.\r\n  - Referrers: Antoine Pigeau (antoine.pigeau@univ-nantes.fr), LS2N DUKe team\r\n\r\nMixing AI techniques to give relevant insights on Mooc attrition\r\n------------------------------------------------\r\n  - Using learning traces left by MOOC users, how can we mix AI techniques to give relevant insights and explainable results as well. This project is based on HUBBLE data.\r\n  - Referrers: Serge Garlatti (Serge.Garlatti@imt-atlantique.fr), IHSEV Lab-STICC\r\n\r\nDesigning feedback\r\n---------------------------\r\n  - How can we design feedback, for example dashboards that makes those insights explicit and actionable for the users?  This project is based on HUBBLE data.\r\n  - Referrers: Jean-Marie Gilliot (jm.gilliot@imt-atlantique.fr), IHSEV Lab-STICC\r\n\r\nResource evolution\r\n--------------------------\r\n  - Analyzing user activity would allow to identify activities generating unexpected behaviour, and therefore help resource/MOOCs authors to refactor their content using this information. This project is principally based on FUN MOOCs data.\r\n  - Referrers: Yannick Prié (yannick.prie@univ-nantes.fr), LS2N DUKe team\r\n\r\nWhat next?\r\n---------------\r\n  - Identification and suggestion of personalized pedagogical paths (made of texts, videos, and other media) according to specific objectives of knowledge and competencies to be acquired by the learner. This is mainly related to X5-GON data.\r\n  - Referrers: Hoël le Capitaine (hoel.lecapitaine@univ-nantes.fr), LS2N DUKe team\r\n\r\nFrom micro-competence to professional project.\r\n--------------------------------------------------------------\r\n  - Can we support learner to define their personal learning paths, in terms of objectives and aimed competencies? A meta review on AI, competencies and self development will be part of the work;\r\n- Referrers: Jean-Marie Gilliot (jm.gilliot@imt-atlantique.fr) & Issam Rebaï (issam.rebai@imt-atlantique.fr), IHSEV Lab-STICC\r\n\r\nEducational datahub\r\n-------------------------\r\n  - Re-centralizing data is a powerful paradigm to enable semantic indexing, incremental data integration, and query discovery. Many resources exist in education but they are spread around the web. We propose to build a datahub for educational resources. This portal accepts resources as RDF data and allows query processing across data.\r\n  - Referrers: Hala Skaf (hala.skaf@univ-nantes.fr), LS2N GDD team\r\n\r\n\r\nWho You Are\r\n==========\r\n  - Pursuing an Engineering degree or a Masters degree in Artificial Intelligence, Data Science, Natural Language Processing, Machine Learning or a related field\r\n  - Capacity to work independently, as well as collaborate within a team\r\n  - Solid programming skills'),
(557, '2019-01-09', 'LIFO', 'Orléans', 'Le LIFO (Laboratoire d\'Informatique fondamentale d\'Orléans) recherche un\r\nétudiant de Master 2 à partir de janvier 2019 pour la réalisation d\'un\r\nstage de recherche d\'une durée de 6 mois et dont la description est\r\ndonnée ci-après.\r\n\r\nLe personne recrutée terminera soit un *Master en Informatique* avec un\r\nintérêt pour le Traitement Automatique des Langues, soit un *Master en\r\nTAL*.\r\n\r\nDépôt des candidatures par courrier électronique auprès des trois\r\nencadrants principaux _*avant le vendredi 18 janvier 2019*_, délai de\r\nrigueur. Merci de joindre à votre candidature :\r\n\r\n  * un CV détaillé de vos activités passées\r\n  * une lettre de motivation\r\n  * vos relevés de notes des deux dernières années d\'études\r\n\r\n*------ Description du sujet **------*\r\n\r\n_*Titre*_ : Apprentissage de modèles pour l\'extraction de graphes\r\ntemporels dans les discours\r\n\r\n_*Description du stage*_ : Le groupe de travail \"Prétopologie, TAL et\r\ntemporalité\" réunit des chercheurs des laboratoires LIFO et LLL\r\nspécialisés en Linguistique, Traitement Automatique des Langues et\r\nApprentissage Automatique. Le sujet d\'étude de ce groupe est l\'analyse\r\ndu discours et plus particulièrement la tâche consistant à extraire d\'un\r\ntexte annoté une structure temporelle prenant la forme d\'un DAG (Graphe\r\nOrienté sans Cycle) d\'événements verbaux pré-identifiés [Ning et al.,\r\n2017]. L\'approche envisagée consiste à apprendre un espace\r\nprétopologique structurant (algorithme LPS [Caillaut&Cleuziou, 2018] à\r\npartir d\'un ensemble de prédicats censés capturer l\'information\r\nlinguistique, lexicale, syntaxique et sémantique portée par chaque\r\névénement temporel.\r\n\r\nLe stagiaire aura pour mission la réalisation d\'une preuve de concept\r\npar le développement d\'une chaîne de traitement complète permettant\r\nd\'extraire les relations prédicatives à partir d\'une corpus d\'énoncés\r\npré-annotés. Il participera à l\'élaboration de ces prédicats en\r\nconcertation avec l\'équipe au regard des travaux récents sur cette\r\nproblématique et évaluera quantitativement et qualitativement les\r\nstructures temporelles issues de l\'algorithme LPS relativement aux\r\nprédicats construits et aux approches existantes.\r\n\r\n_*Encadrants*_ :\r\n\r\n  * Encadrants principaux : Anaïs Lefeuvre-Halftermeyer\r\n    (anais.halftermeyer@univ-orleans.fr) , Gaëtan Caillaut\r\n    (gaetan.caillaut@univ-orleans.fr), Anne-Lyse Minard\r\n    (anne-lyse.minard@univ-orleans.fr)\r\n\r\n  * Autres membres du groupe de travail : Sylvie Billot et Guillaume\r\n    Cleuziou\r\n\r\n_*Références*_ :\r\n\r\n[Caillaut&Cleuziou, 2018] Gaëtan Caillaut, Guillaume Cleuziou: Learning\r\nPretopological Spaces to Model Complex Propagation Phenomena: A Multiple\r\nInstance Learning Approach Based on a Logical Modeling. CoRR\r\nabs/1805.01278 (2018)\r\n\r\n[Ning et al., 2017] Qiang Ning, Zhili Feng, Dan Roth: A Structured\r\nLearning Approach to Temporal Relation Extraction. EMNLP 2017: 1027-1037\r\n\r\nParamita Mirza and Anne-Lyse Minard. HLT-FBK: a complete Temporal\r\nProcessing system for QA TempEval. In Proceedings of the 9th\r\nInternational Workshop on Semantic Evaluation (SemEval 2015).\r\n\r\n_*Rémunération*_ : conventionnelle (~570¤ mensuel)'),
(558, '2019-01-16', 'Jouve', 'Lens', 'Sujet de stage : Améliorer la classification de brevets à l\'aide des\r\ndernières technologies de l\'IA (word embedding, deep learning, ...)\r\n\r\nDurée :  Stage M2 de 4 à 6 mois,\r\nDisponibilité : dès que possible\r\nLieu : Jouve, Parc d\'activités du Gard, 62300 Lens\r\n\r\nContexte : Nous recherchons un stagiaire qui est intéressé par\r\n           l\'intelligence artificielle (IA) et le traitement automatique\r\n           des langues (TAL)\r\n           Spécialiste du traitement des données,  Jouve est un acteur\r\n           important dans la dématérialisation des brevets.\r\n           Le service R&D de Jouve a réalisé une chaîne de\r\n           classification sémantique de brevets utilisant plusieurs\r\n           méthodes (classifieurs SVM, méthodes par similarité,...)\r\n           Au sein du service R&D et rattaché(e) à l\'Ingénieur R&D, vous\r\n           serez en charge de la recherche sur la classification\r\n           sémantique de documents.\r\n\r\nMissions :\r\n\r\n  * Réaliser un état de l\'art en se focalisant sur les dernières\r\n    techniques (word-embedding, deep learning, ...), les différentes\r\n    directions d\'approfondissement des recherches seront alors définies.\r\n  * Contribuer à l\'amélioration des résultats de précision et de rappel\r\n    de la classification et ajouter des traitements de visualisation.\r\n  * Pour la visualisation, mettre en évidence des relations entre les\r\n    termes de l\'intitulé de classe  et le brevet lui-même.\r\n  * Préparer des données /Apprentissage deep-learning ou autre\r\n    classifieur/Evaluation/Visualisation\r\n  * Mettre en place des tests et des apprentissages : plusieurs millions\r\n    de brevets sont disponibles.\r\n\r\nVos forces et vos atouts :\r\n\r\n  * Autonomie, curiosité et forte appétence « recherche »,\r\n  * Esprit d\'équipe\r\n  * Connaissances en :\r\n    - TALN (Traitement Automatique du Langage Naturel), Lemmatisation/\r\n      * Analyse syntaxique / word embedding\r\n    - Intelligence Artificielle : Réseaux de Neurones, SVM , deep\r\n      learning\r\n  * Au moins un de ces langages : C/C++, python, R, ...\r\n\r\nQui sommes-nous ? :\r\n\r\nEntreprise :  Jouve (www.jouve.com) propose des\r\nsolutions et services pour transformer les données les plus complexes de\r\nses clients, optimiser leurs processus métiers et créer de nouvelles\r\nexpériences digitales. Pionnier sur les marchés de l\'aéronautique et de\r\nl\'édition, Jouve propose également des solutions innovantes pour\r\nrépondre aux nouveaux besoins des acteurs de l\'industrie, de la banque,\r\nde l\'assurance, de la santé et de l\'éducation.  Jouve compte 2500\r\ncollaborateurs et est implanté dans 14 pays en Europe, en Amérique du\r\nNord, en Afrique et en Asie. Jouve Lens a bâti ses équipes managériales,\r\ncommerciales et d\'ingénierie sur des profils dotés de connaissances\r\navancées dans le domaine de la conversion numérique.\r\n\r\nPour postuler : Ecrire aux Ressources Humaines, Marie Mendy\r\n(mmendy@jouve.com) , avec un CV, une lettre de motivation et votre\r\nrelevé de notes de M1'),
(559, '2019-01-17', 'IGN', 'Saint-Mandé', 'CrÃ©ation d\'une base de connaissances sur les ports Ã  partir des textes\r\ndes instructions nautiques\r\n\r\nMots-clÃ©s:  crÃ©ation et peuplement de bases de connaissances\r\ngÃ©orÃ©fÃ©rencÃ©es, intÃ©gration de donnÃ©es Ã  rÃ©fÃ©rences spatiales,\r\nextraction d\'informations topographiques Ã  partir de textes.\r\n\r\nContexte et objectifs\r\n\r\nL\'Institut national de l\'information gÃ©ographique et forestiÃ¨re (IGN)\r\net le Service Hydrographique et OcÃ©anographique de la Marine (SHOM)\r\nsont les opÃ©rateurs publics respectivement en charge de l\'information\r\ngÃ©ographique et forestiÃ¨re et de l\'information gÃ©ographique maritime\r\net littorale de rÃ©fÃ©rence. Ã€ ce titre, les deux Ã©tablissements\r\nproduisent des rÃ©fÃ©rentiels et des services destinÃ©s Ã  rÃ©pondre aux\r\nbesoins d\'informations gÃ©olocalisÃ©es, notamment au profit des\r\npolitiques publiques comportant des enjeux d\'analyse spatiale et de\r\nlocalisation. Ceci suppose de produire des rÃ©fÃ©rentiels qui soient Ã \r\nla fois les plus exhaustifs, dÃ©taillÃ©s, qualifiÃ©s, Ã  jour et\r\ninteropÃ©rables possibles.\r\n\r\nLes rÃ©fÃ©rentiels de donnÃ©es gÃ©orÃ©fÃ©rencÃ©es sont de plus en plus\r\nutilisÃ©s pour permettre l\'annotation spatiale de documents textuels et\r\nainsi faciliter l\'accÃ¨s Ã  leur contenu, voire son analyse spatiale. En\r\nrevanche, peu de travaux se sont intÃ©ressÃ©s Ã  l\'extraction\r\nd\'information gÃ©ographique Ã  partir de textes pour alimenter de tels\r\nrÃ©fÃ©rentiels. Pourtant, certains textes offrent des descriptions de\r\nl\'espace trÃ¨s prÃ©cises et dÃ©taillÃ©es et constituent parfois la seule\r\nsource d\'informations disponible.\r\n\r\nCe stage explorera les potentialitÃ©s de l\'extraction d\'information Ã \r\ncomposante spatiale dans des textes alliÃ©e aux standards du Web de\r\ndonnÃ©es pour construire et peupler une base de connaissances sur les\r\nports et mouillages dÃ©crivant leur localisation, leur configuration\r\nspatiale, leurs Ã©quipements, etc. Ã  partir des  Instructions Nautiques\r\nproduites par le SHOM. L\'objectif est de se doter de connaissances\r\nstructurÃ©es pour rÃ©pondre Ã  des requÃªtes sur la localisation des ports\r\net mouillages, leurs conditions d\'accÃ¨s et d\'utilisation et Ã  terme\r\ndÃ©velopper des services d\'aide Ã  la navigation Ã  base de raisonnement.\r\n\r\nCorpus de travail\r\n\r\nLes  Instructions Nautiques  sont des documents textuels dÃ©crivant les\r\namers et dangers pour la navigation cÃ´tiÃ¨re, les ports et mouillages,\r\nleurs chenaux d\'accÃ¨s, leurs Ã©quipements et les services proposÃ©s aux\r\nnavigateurs, etc.\r\n\r\nLes sections dÃ©diÃ©es Ã  la description des ports et mouillages suivent\r\nune structure relativement rÃ©guliÃ¨re. Elles dÃ©butent par un paragraphe\r\ndÃ©crivant la localisation gÃ©nÃ©rale du port, sa capacitÃ© d\'accueil\r\nainsi que son statut administratif. Puis viennent le plus souvent des\r\nexplications sur les manoeuvres de chenalage pour y accÃ©der, suivies\r\nd\'une description des diffÃ©rentes zones de mouillage et installations\r\nportuaires. On y trouve enfin la liste des Ã©quipements - notamment Ã \r\ndestination des plaisanciers - ainsi que les coordonnÃ©es des services\r\nutiles - bureau du port, mairie, dÃ©lÃ©gation Ã  la mer et aux affaires\r\nlittorales, etc. L\'extrait ci-dessous dÃ©crit le port de\r\nSaint-Cast.Extrait des instructions nautiques pour le port de\r\nSaint-Cast (Source : SHOM)\r\n\r\nVerrous scientifiques\r\n\r\nIl s\'agira d\'extraire, typer, dÃ©sambiguÃ¯ser et structurer les\r\ninformations sur les ports et les diverses entitÃ©s spatiales qui les\r\ncomposent dÃ©crites par les textes (noms, types d\'objets gÃ©ographiques,\r\nlocalisations absolues et relatives, fonctions, ...) pour les intÃ©grer\r\ndans une base de connaissances et vÃ©rifier la cohÃ©rence des\r\ninformations extraites, infÃ©rer de nouveaux faits. Ceci suppose de\r\nproposer des solutions pour :\r\n\r\n- Adapter les approches existantes d\'extraction d\'information Ã \r\ncomposante spatiale Ã  partir de textes Ã  des corpus techniques\r\ncaractÃ©risÃ©s par un vocabulaire trÃ¨s spÃ©cifique au domaine,\r\nmaisrelativement peu structurÃ©s au sein des diffÃ©rentes sections. En\r\nparticulier, de nombreuses entitÃ©s spatiales mentionnÃ©es ne possÃ¨dent\r\npas de nom ;\r\n\r\n- ReprÃ©senter, stocker et manipuler des informations Ã  composante\r\nspatiale qualitative (rÃ©fÃ©rences spatiales indirectes, positionnement\r\nrelatif, etc.) et Ã  diffÃ©rents niveaux de dÃ©tail selon les standards\r\ndu Web de donnÃ©es ;\r\n\r\n- DÃ©sambiguÃ¯ser les entitÃ©s spatiales extraites. Ceci nÃ©cessite de\r\nprendre en compte :\r\n\r\n	- des critÃ¨res de liage dont la disponibilitÃ© pourra varier,\r\n\r\n	- les Ã©ventuelles variations des entitÃ©s spatiales d\'une source Ã \r\nl\'autre (variations de nom, de propriÃ©tÃ©s, de temporalitÃ©, de niveau\r\nde dÃ©tail de descriptions, etc.).\r\n\r\n- DÃ©tecter et corriger d\'Ã©ventuelles incohÃ©rences spatiales ou\r\ntemporelles dans les informations extraites, amÃ©liorer le typage des\r\nentitÃ©s spatiales, infÃ©rer des relations spatio-temporelles entre\r\nentitÃ©s gÃ©ographiques, etc.\r\n\r\nRenseignements pratiques\r\n\r\nUne poursuite du sujet de stage en thÃ¨se de doctorat est possible (financement SHOM/IGN).\r\n\r\nProfil recherchÃ© : Master 2 ou diplÃ´me d\'ingÃ©nieur en informatique :\r\nreprÃ©sentation de connaissances, Web sÃ©mantique, sciences de\r\nl\'information gÃ©ographique, extraction d\'informations Ã  partir de\r\ntextes.\r\n\r\nCompÃ©tences et connaissances:\r\n- Un bon niveau en programmation est essentiel\r\n\r\n- En raison de la nature du corpus de documents, la maÃ®trise du\r\n  franÃ§ais est nÃ©cessaire.\r\n\r\n- Extraction d\'informations Ã  partir de textes.\r\n\r\n- DonnÃ©es gÃ©ographiques vectorielles.\r\n\r\n- Web de donnÃ©es, notamment RDFS et OWL.\r\n\r\nDurÃ©e et pÃ©riode de stage :  5 mois, au cours du printemps et de l\'Ã©tÃ©\r\n2018.\r\n\r\nLieu du stage :  Equipe  LaSTIG /Strudel,  Institut national de\r\nl\'information gÃ©ographique et forestiÃ¨re (IGN), Saint-MandÃ© (mÃ©tro 1,\r\nstation Saint MandÃ©).\r\n\r\nIndemnitÃ©s de stage :  Stage gratifiÃ© selon la lÃ©gislation franÃ§aise.\r\n\r\nModalitÃ©s de candidature : Envoyer un CV, une lettre de motivation \r\nciblÃ©e sur le sujet et les relevÃ©s de notes des 2 derniÃ¨res annÃ©es\r\nd\'Ã©tudes par email, au format PDF et en un seul fichier Ã \r\nnathalie-f.abadie@ign.fr\r\n\r\nEncadrement du stage :\r\n\r\n- Nathalie Abadie (LaSTIG - COGIT/Strudel,  IGN, \r\n  nathalie-f.abadie@ign.fr )\r\n\r\n- Eric Kergosien (Geriico - UniversitÃ© de Lille, \r\n  eric.kergosien@univ-lille3.fr )\r\n\r\n- Eric Saux (Irenav - Ecole Navale,  eric.saux@ecole-navale.fr )'),
(560, '2019-01-17', 'IGN', 'Saint-Mandé', 'Géoréférencement d\'images anciennes à l\'aide des indications de\r\nlocalisation fournies par leurs métadonnées\r\n\r\nMots-clés:  Web de données, référentiels de données géographiques\r\nvectorielles, analyse spatiale, extraction d\'informations\r\ntopographiques à partir de textes, programmation.\r\n\r\nContexte\r\n\r\nDe plus en plus d\'institutions patrimoniales et culturelles publient\r\nles catalogues des collections dont elles ont la garde sur le Web afin\r\nde faciliter la découverte de ces collections. Ces catalogues se\r\ncomposent, pour chaque ressource patrimoniale ou culturelle, de\r\nmétadonnées permettant d\'en découvrir le contenu même lorsque aucune\r\ncopie numérique de la ressource n\'est disponible: titre, auteur,\r\néditeur, date, mots-clés, etc. Désenclaver ces jeux de métadonnées\r\nsuppose de les interconnecter avec des référentiels communs, comme des\r\nthésaurus sur les types d\'oeuvres architecturales, des index d\'auteurs\r\nou des jeux de données géographiques. Ceci permet de désambiguïser les\r\nchaînes de caractères utilisées pour désigner les auteurs, les types\r\nd\'oeuvres ou les lieux en leur substituant les identifiants de\r\nressources décrites par les référentiels et faisant autorité. En\r\noutre, ceci permet de naviguer aisément au travers des collections et\r\nde leurs référentiels associés en suivant les liens ainsi explicités.\r\n\r\nLe projet  ALEGORIA vise à valoriser des fonds iconographiques\r\ninstitutionnels décrivant le territoire français à différentes époques\r\nallant de l\'entre-deux-guerres à nos jours. Ces clichés s\'accompagnent\r\nde métadonnées, et lorsqu\'une photographie représente une entité\r\ngéographique, sa légende peut contenir des indications sur la\r\nlocalisation de cette entité ou sur le lieu de prise de vue. On\r\nretrouve ce type d\'informations dans les métadonnées de la\r\nphotographie présentée en figure 1.\r\n\r\nFigure 1: Une photographie conservée au musée Nicéphore Niépce et ses\r\nmétadonnées\r\n(http://www.open-museeniepce.com/recherche-photos/photo,2611 )\r\n\r\nPrincipales hypothèses et objectifs du stage\r\n\r\nUne des réalisations prévues par le projet  ALEGORIA est un moteur\r\nd\'indexation et de recherche multimodal et à grande échelle, couplant\r\nrecherche par contenu et par métadonnées dans les fonds d\'images\r\nnumérisées et documentées. Ce moteur s\'appuiera, entre autres, sur les\r\nindications de localisation fournies par les métadonnées des images.\r\n\r\nL\'objectif de ce stage est de faciliter l\'exploitation par le moteur\r\nd\'indexation des indications de localisation disponibles dans les\r\nmétadonnées. Une première étape consistera à extraire des métadonnées\r\ndes jeux d\'images du projet ALEGORIA les indications de localisation,\r\nreprésentées sous la forme d\'entités spatiales nommées [M15]. Il\r\nconviendra en outre de déterminer si ces entités spatiales nommées\r\ndésignent le contenu de l\'image ou le lieu de sa prise de vue. Enfin,\r\nune dernière étape consistera à résoudre ces entités spatiales\r\nnommées, c\'est-à-dire à associer à chaque mention d\'entité spatiale\r\nnommée l\'identifiant de l\'entité géographique du monde réel à laquelle\r\nelle fait référence [PAB17]. L\'utilisation d\'un jeu de données\r\ngéographiques de référence comportant des indications de localisation\r\ndirectes (coordonnées ou géométrie), permettra de localiser\r\nprécisément les entités spatiales mentionnées dans les métadonnées.\r\n\r\nVerrous scientifiques\r\n\r\nUne première difficulté réside dans le manque d\'informations de\r\ncontexte dans les métadonnées, dans la mesure où ce sont des textes\r\nrelativement courts. Les approches d\'extraction et de résolution des\r\nentités spatiales choisies devront s\'adapter à cette contrainte.\r\n\r\nLe traitement des entités spatiales relatives constitue une seconde\r\ndifficulté majeure. En effet, il s\'agit d\'entités spatiales\r\nidentifiées et localisées par référence à une autre entité spatiale\r\nnommée, comme \"la rive droite de la Saône\" par exemple. L\'approche\r\nd\'extraction proposée devra être en mesure de détecter ces entités\r\nspatiales relatives. En outre, dans la mesure où elles ne figurent pas\r\ndans les référentiels géographiques, il conviendra de proposer une\r\napproche pour dériver leur localisation à partir des données\r\ngéographiques disponibles.\r\n\r\nRenseignements pratiques\r\n\r\n- Formation : Master 2 ou troisième année d\'école d\'ingénieur en\r\ninformatique ou en géomatique avec une forte composante informatique.\r\n\r\n- Durée et période de stage : 5 mois, au cours du printemps et de\r\n  l\'été 2018.\r\n\r\n- Lieu de stage : Equipe  LaSTIG /Strudel,  Institut national de\r\nl\'information géographique et forestière (IGN), Saint-Mandé (métro 1,\r\nstation Saint Mandé).\r\n\r\n- Indemnités de stage:  Stage gratifié selon la législation française.\r\n\r\n- Modalités de candidature : Envoyer par email un fichier PDF avec\r\nvotre curriculum vitae, une lettre de motivation ciblée sur le sujet ,\r\nvos relevés de notes des deux dernières années d\'études.\r\n\r\n- Encadrement de stage :\r\n Nathalie Abadie (IGN/COGIT):  nathalie-f.abadie[]ign.fr\r\n Carmen Brando (EHESS):  carmen.brando[]ehess.fr\r\n\r\n- Bibliographie\r\n\r\n[M15] Moncla, L. (2015) Automatic Reconstruction of Itineraries from\r\nDescriptive Texts. Thèse de doctorat de l\' Université de Pau et des\r\nPays de l\'Adour et de l\'Université de Saragosse.\r\n\r\n[PAB17] Paris, P-H, Abadie, N., Brando C. (2017). Linking spatial\r\nnamed entities to the Web of Data for geographical analysis of\r\nhistorical texts. Journal of Map & Geography Libraries. Volume 13,\r\n2017 - Issue 1: Semantic Historical Gazetteers: A Place for Places -\r\nPapers from the DH2016 GeoHumanities SIG Workshop.'),
(561, '2019-01-17', 'GREYC', 'Caen', 'Research Internship on Multimodal Deep Learning Techniques for the\r\nIdentification of Asymmetric Relations\r\n\r\nGaël Dias, Youssef Chahir and Houssam Akhmouch\r\n\r\nCNRS GREYC UMR 6072 - Normandy University\r\n\r\nInternship Description\r\n\r\nTraditionally in classification, a learning example refers to a unique\r\nobject 0 A that must be categorized in some class given an input set\r\nof features. For example in sentiment classification, a text\r\ntransformed in some learning representation can be classified either\r\nas positive, negative or neutral [4].\r\n\r\nBut many other situations exist. In this internship, we are\r\nparticularly interested in identifying relations between pairs of\r\nobjects. In this case, a learning example (0 A r 0 B ) refers to a\r\npair of objects 0 A and 0 B that must be transformed in some\r\nlearning representation so that the model can predict if some relation\r\nr holds between them, or not. For instance, in image classification, a\r\nmodel may have to predict if two patches are similar or not [10].\r\n\r\nWithin this context, a vast majority of works have been tackling\r\nsymmet- ric relations (e.g. matching images, synonymy detection),\r\nwhile asymmetric relations (e.g. textual entailment, temporal image\r\nordering) have received less attention. Indeed, it has been shown that\r\nasymmetry is usually a difficult prob- lem [8] as it involves the\r\ndirection of the relation. So, if two objects O A and O B are in an\r\nasymmetric relation , let\'s say (O A -> O B ), then the learning\r\nexample (O A -> O B ) is a positive example, while (O B -> O A ) is a\r\nnegative example.\r\n\r\nIn this internship, we are particularly interested in designing\r\nlearning models that can positively handle asymmetry. Different work\r\ndirections will be studied such as (1) the development of specific\r\nasymmetric deep learning architectures [2, 9], (2) the computation of\r\nsemantic feature spaces capable of handling asymmetry [7, 1, 3, 6]\r\nor (3) a combination of both ideas [5]. In particular, multimodal\r\n(text, image and text/image) experiments will be performed on gold\r\nstandard data sets in order to evaluate the performance of the\r\ndifferent proposed models.\r\n\r\nCandidate Profile\r\n\r\nThe successful candidate must pursue Master or Engineering School\r\nlevel stud- ies in Data Science, Computer Science, Applied\r\nMathematics, or related scientific fields and show strong background\r\nin Mathematics, Machine Learning and Programming. Additional knowledge\r\nin Deep Learning (both theoretically and practically) will be highly\r\nappreciated as well as experience in Natural Language Processing\r\nand/or Computer Vision.\r\n\r\n\r\nInternship Organization\r\n\r\nThe internship will start at the beginning of 2019 (January, February\r\nor March) and will last up to 6 months. It will take place at the CNRS\r\nGREYC UMR 6072 Laboratory in Caen (France). Some visits to the\r\ninternship partner Crédit Agricole Brie Picardie in Serris near Paris\r\nwill be planned. The candidate will be compensated following the rules\r\nin force for internships. Note that the internship is subject to the\r\nestablishment of a preliminary internship agreement.\r\n\r\nInternship Perspectives\r\n\r\nDepending on the obtained results and the dedication/motivation of the\r\nsuccess- ful candidate, there shall be a possibility to pursue PhD\r\nstudies in collaboration with all the internship partners, i.e. CNRS,\r\nNormandy University and Crédit Agricole Brie Picardie.\r\n\r\n\r\nApplication Procedure\r\n\r\nApplicants are requested to submit their application with an academic\r\nCV, copies of academic degree records and certificates, and two\r\npotential references (if possible). Applications must be sent directly\r\nto the internship coordinators:\r\n\r\nGaël Dias (gael.dias@unicaen.fr), Youssef Chahir (youssef.chahir@unicaen.fr)\r\nand Houssam Akhmouch (houssam.akhmouch@unicaen.fr).\r\n\r\nNote that the CNRS GREYC UMR 6072 is committed to being a fully\r\ninclusive institution which actively recruits staff from all sectors\r\nof society. It is proud to be an equal opportunities employer and\r\nencourages applications from everybody, regardless of race, sex,\r\nethnicity, religion, nationality, sexual orientation, age, disability,\r\ngender identity, marital status/civil partnership, pregnancy and\r\nmaternity, as well as being open to flexible working practices.\r\n\r\nReferences\r\n\r\n[1] Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, and Andrew McCallum.\r\nDistributional inclusion vector embedding for unsupervised hypernymy de-\r\ntection. In Conference of the North American Chapter of the Association\r\n2for Computational Linguistics: Human Language Technologies (NAACL-\r\nHLT), pages 485-495, 2018.\r\n[2] Goran Glava¨ and Simone Paolo Ponzetto. Dual tensor model for detecting\r\nasymmetric lexico-semantic relations. In Conference on Empirical Methods\r\nin Natural Language Processing (EMNLP), pages 1757-1767, 2017.\r\n[3] Goran Glava¨ and Ivan Vulic. Explicit retrofitting of distributional word\r\nvectors. In 56th Annual Meeting of the Association for Computational\r\nLinguistics (ACL), volume 1, pages 34-45, 2018.\r\n[4] Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. Recurrent convolutional\r\nneural networks for text classification. In 29th AAAI Conference on Arti-\r\nficial Intelligence (AAAI), volume 333, pages 2267-2273, 2015.\r\n[5] Simon Moura, Amir Azarbaev, and Massih-Reza Amini. Heterogeneous\r\ndyadic multi-task learning with implicit feedback. In 25th International\r\nConference on Neural Information Processing (ICONIP), 2018.\r\n[6] Marek Rei, Daniela Gerz, and Ivan Vulic. Scoring lexical entailment with\r\na supervised directional similarity network. In 56th Annual Meeting of the\r\nAssociation for Computational Linguistics (ACL), pages 638-643, 2018.\r\n[7] Ivan Vulic and Nikola Mrksic. Specialising word vectors for lexical entail-\r\nment. In Conference of the North American Chapter of the Association\r\nfor Computational Linguistics: Human Language Technologies (NAACL-\r\nHLT), pages 1134-1145, 2018.\r\n[8] Ekaterina Vylomova, Laura Rimell, Trevor Cohn, and Timothy Baldwin.\r\nTake and took, gaggle and goose, book and read: Evaluating the utility\r\nof vector differences for lexical relation learning. In 54th Annual Meeting\r\nof the Association for Computational Linguistics (ACL), pages 1671-1682,\r\n2016.\r\n[9] Qi Wang, Tong Ruan, Yangming Zhou, Daqi Gao, and Ping He. An\r\nattention-based bi-gru-capsnet model for hypernymy detection between\r\ncompound entities. arXiv preprint arXiv:1805.04827, 2018.\r\n[10] Sergey Zagoruyko and Nikos Komodakis. Learning to compare image\r\npatches via convolutional neural networks. In IEEE Conference on Com-\r\nputer Vision and Pattern Recognition (CVPR), pages 4353-4361, 2015.'),
(562, '2019-01-18', 'Crigen-Engie', NULL, 'Offre de stage R&D chez Crigen-ENGIE\r\nActive Learning\r\nVision par ordinateur, Traitement Automatique du Langage\r\n\r\nContexte\r\n\r\nENGIE est l\'un des leaders mondiaux dans les domaines de l\'énergie et de\r\nl\'environnement. ENGIE est fortement engagé dans la transition\r\nénergétique et dans le développement des énergies renouvelables.\r\n\r\nL\'équipe de recherche et de développent du lab CSAI (Computer Science\r\nand Artificial Intelligence) réalise des solutions pour de nombreuses\r\nentités d\'ENGIE, notamment autour des problématiques de la vision par\r\nordinateur et du traitement automatique du langage naturel.\r\n\r\nPour mener à bien ces travaux, des bases de données annotées sont\r\nnécessaires. C\'est dans ce cadre là que s\'inscrit ce stage sur\r\nl\'apprentissage actif. Afin d\'optimiser le processus de labélisation de\r\ndonnées et éviter d\'annoter d\'énormes bases contenant des informations\r\nredondantes, les méthodes d\'apprentissage actif permettent de\r\nsélectionner les meilleurs exemples à labéliser par l\'utilisateur. Cela\r\npermet ainsi d\'annoter moins d\'exemples mais de manière plus pertinente.\r\n\r\nL\'objectif du stage consiste donc à développer un algorithme\r\nd\'apprentissage actif permettant d\'accélérer le processus d\'acquisition\r\nde données labélisées de qualité. Cet outil servira notamment pour les\r\nprojets de vision par ordinateur et de traitement automatique du langage\r\nnaturel [1][2][3][4].\r\n\r\n\r\nMissions\r\n\r\n- Conduire une étude bibliographique sur les méthodes d\'apprentissage\r\n  actif. Cette étude devra notamment comporter les méthodes standard de\r\n  l\'apprentissage actif ainsi que leur application dans les domaines du\r\n  traitement naturel du langage et de la vision par ordinateur.\r\n- Ré-implémenter certaines méthodes existantes et les évaluer.\r\n- Analyser et comparer ces méthodes afin de synthétiser les avantages et\r\n  défauts de chacunes d\'entre elles.\r\n- Proposer des pistes de travaux et d\'amélioration par rapport à l\'état\r\n  de l\'art.\r\n- Implémenter les améliorations identifiées dans les environnements et\r\n  architectures du lab CSAI.\r\n- Valider les contributions par des expérimentations appropriées.\r\n- Dans la mesure du possible, rédiger et soumettre une publication\r\n  scientifique.\r\n- Documenter le code.\r\n\r\n\r\nProfil recherché\r\n\r\nNiveau: M2, école d\'ingénieur. Spécialisation: Machine Learning ou\r\nMaths.\r\n\r\n\r\nCompétences nécessaires:\r\n\r\n- Connaissances en machine learning\r\n- Connaissances en mathématiques (algèbre, optimisation, statistiques,\r\n  ...)\r\n- Expérience en programmation dans au moins un langage informatique\r\n- Bon niveau d\'anglais\r\n- Motivé\r\n- Autonome\r\n\r\n\r\nCompétences appréciables:\r\n\r\n- Connaissance en vision par ordinateur et en traitement naturel du\r\n  langage\r\n- Expérience en python et/ou en C++\r\n- Connaissance en deep learning et des outils associés (tensorflow,\r\n  keras, pytorch,caffe...)\r\n\r\n\r\n\r\nDivers\r\n\r\nDurée du stage: 6 mois - date de commencement flexible.\r\n\r\nConvention de stage obligatoire.\r\n\r\nLe dossier de candidature doit être envoyé le plut tôt possible à\r\nPhilippe Calvez (philippe.calvez1@engie.com), Ahmed Mabrouk\r\n(ahmed.mabrouk@engie.com) et Chan-Lang Solène\r\n(solene.chan-lang@external.engie.com). Il doit contenir les documents\r\nsuivants:\r\n- un CV détaillé (ensemble des expériences et technologies maîtrisées)\r\n- une lettre de motivation\r\n- des lettres de recommandations (optionnel)\r\n\r\n\r\nReferences\r\n\r\n[1] Burr Settles. Active learning literature survey. Computer Sciences\r\n    Technical Report 1648, University of Wisconsin- Madison, 2009.\r\n[2] Cynthia A. Thompson, Mary Elaine Califf, and Raymond\r\n    J. Mooney. Active learning for natural language parsing and\r\n    information extraction. In Proceedings of the Sixteenth\r\n    International Conference on Machine Learning (ICML- 99), pages\r\n    406-414, Bled, Slovenia, June 1999.\r\n[3] Kuoliang Wu, Deng Cai, and Xiaofei He. Multi-label active learning\r\n    based on submodular functions. Neurocom- puting, 313:436-442, 2018.\r\n[4] Ozan Sener and Silvio Savarese. Active learning for convolutional\r\n    neural networks: A core-set approach. In International Conference on\r\n    Learning Representations, 2018.'),
(563, '2019-01-21', 'Softlaw', 'Paris', 'OFFRE DE STAGE M2 :  Analyse automatique des contrats\r\n\r\nCONDITIONS DU STAGE :\r\nDébut : démarrage possible à tout moment à partir de février 2019\r\nDurée : 4 à 6 mois\r\nGratification : standard de marché\r\nLocaux : beaux locaux dans le centre de Paris (M° Chaussée d\'Antin - Le\r\n         Pelletier - Trinité d\'Orves)\r\n\r\nENTREPRISE :\r\nSOFTLAW est une entreprise pionnière de la legaltech et la première\r\nsociété en France à avoir développé une solution d\'analyse automatique\r\nde contrats utilisant l\'intelligence artificielle pour extraire\r\nautomatiquement les informations clés des contrats et faciliter leur\r\nanalyse.\r\n\r\nSUJET DU STAGE :\r\nAfin de permettre à nos utilisateurs d\'adapter les algorithmes\r\nd\'extraction d\'information présente dans les contrats, par exemple pour\r\npermettre de reconnaître de nouvelles catégories non prévues\r\ninitialement, nous travaillons sur des solutions d\'online machine\r\nlearning pouvant cohabiter avec des modèles pré-entraînés.\r\n\r\nDans le cadre du stage, vous mettrez en oeuvre des méthodes d\'analyse de\r\ncontrats reposant sur l\'online machine learning.\r\n\r\nLe stage comportera plusieurs étapes :\r\n- Réalisation d\'un état de l\'art,\r\n- Sélection et implémentation des techniques les plus prometteuses,\r\n- Évaluation des différents modèles proposés,\r\n- Intégration des développements dans la plateforme NLP de la Société,\r\n- Utilisation du/des modèle(s) dans le cadre de l\'identification de\r\n  concepts juridiques (topic modeling).\r\n\r\nPRINCIPALES TECHNOLOGIES UTILISÉES :\r\n- Langage : Python\r\n- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.\r\n- IDE : pycharm\r\n\r\nCONNAISSANCES, COMPÉTENCES RECHERCHÉES\r\n- Fort intérêt pour le traitement de données textuelles\r\n- Autonomie, rigueur et communication\r\n- Innovation/R&D et force de proposition\r\n- Travail en équipe\r\n\r\nLES PLUS DU STAGE :\r\n- Stage extrêmement formateur permettant de se former sur les\r\n  technologies à la pointe de l\'état de l\'art en NLP / Machine Learning\r\n- Travail dans un cadre stimulant : l\'entreprise a ses bureaux au sein\r\n  d\'un accélérateur de startups prometteuses et des locaux très\r\n  agréables\r\n- Entreprise et secteur dynamiques\r\n\r\nContact : s.morard@softlaw.digital (06 11 12 14 87)'),
(564, '2019-01-21', 'Softlaw', 'Paris', 'STAGE M2 :  Analyse automatique des textes juridiques\r\n\r\nCONDITIONS DU STAGE :\r\nDébut : démarrage possible à tout moment à partir de février 2019\r\nDurée : 4 à 6 mois\r\nGratification : standard de marché\r\nLocaux : très beaux locaux dans le centre de Paris (M° Chaussée d\'Antin\r\n         - Le Pelletier - Trinité d\'Orves)\r\n\r\n\r\nENTREPRISE :\r\nSOFTLAW est une entreprise pionnière de la legaltech et la première\r\nsociété en France à avoir développé une solution d\'analyse automatique\r\nde contrats utilisant l\'intelligence artificielle pour extraire\r\nautomatiquement les informations clés des contrats et faciliter leur\r\nanalyse.\r\n\r\nSUJET DU STAGE :\r\nDans le cadre du développement de notre solution d\'analyse de contrats,\r\nvous utiliserez notre approche hybride basée à la fois sur des méthodes\r\nde machine learning et d\'analyse sémantique pour prendre en compte de\r\nnouveaux types de contrats.\r\n\r\nNotamment, vous entrainerez des classifieurs dédiés pour catégoriser des\r\narticles spécifiques et des algorithmes permettant l\'identification et\r\nl\'extraction d\'informations précises.\r\n\r\nLe stage comportera plusieurs étapes :\r\n- Réalisation d\'un état de l\'art sur les différentes techniques\r\n  d\'extraction d\'information textuelle à partir des documents non\r\n  structurés,\r\n- Implémentation d\'une approche hybride : machine learning et analyse\r\n  sémantique,\r\n- Évaluation des performances de la solution développée,\r\n- Intégration des développements dans la plateforme NLP de la Société\r\n\r\nPRINCIPALES TECHNOLOGIES UTILISÉES :\r\n- Langage : Python\r\n- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.\r\n- IDE : pycharm\r\n\r\nCONNAISSANCES, COMPÉTENCES RECHERCHÉES\r\n- Fort intérêt pour le traitement de données textuelles\r\n- Autonomie, rigueur et communication\r\n- Innovation/R&D et force de proposition\r\n- Travail en équipe\r\n\r\nLES PLUS DU STAGE :\r\n- Stage extrêmement formateur permettant de se former sur les\r\n  technologies à la pointe de l\'état de l\'art en NLP / Machine Learning\r\n- Travail dans un cadre stimulant : l\'entreprise a ses bureaux au sein\r\n  d\'un accélérateur de startups prometteuses et des locaux très\r\n  agréables\r\n- Entreprise et secteur dynamiques\r\n\r\n\r\nContact : s.morard@softlaw.digital (06 11 12 14 87)'),
(565, '2019-01-23', 'ERTIM', 'Paris', '*Reconnaissance et désambiguïsation des entités*\r\nStage proposé par le laboratoire ERTIM (INALCO)\r\n\r\n*Contexte*\r\n\r\nLes entités nommées sont des éléments linguistiques utilisés par de\r\nnombreuses applications en TAL, telles quelles (indexation de documents,\r\nrecherche et extraction d\'information, etc.) ou comme éléments exploités\r\npour de nombreuses autres tâches. Leur détection et leur catégorisation\r\nsont aujourd\'hui assez bien maîtrisées.\r\n\r\nCes dernières années, de nombreux travaux de recherche ont porté sur la\r\ndésambiguïsation (ou liaison, résolution) d\'entités. Il s\'agit alors de\r\ndéterminer à quel référent d\'une base de connaissances une expression\r\nlinguistique fait mention (ou NIL si le référent n\'existe pas). Cela\r\nconcerne une plus large gamme d\'expressions linguistiques que les\r\n\"entités nommées\".\r\n\r\nDans le cadre du projet TALAD (https://web.u-cergy.fr/anr-talad/) nous\r\nexploitons les entités pour l\'étude des \"nominations\" (diversité\r\nd\'expressions linguistiques qui réfèrent à une même entité). La\r\ndétection, reconnaissance et désambiguïsation des entités est une brique\r\nimportante dans ce projet, en interaction avec la\r\ncoréférence. L\'objectif du projet est de déterminer quelles entités sont\r\nmentionnées dans un texte, par quelles expressions linguistiques, et\r\ndans quels contextes.\r\n\r\nPar ailleurs, le traitement des entités nécessite de s\'appuyer sur un\r\ncorpus à large couverture, contenant de nombreuses mentions. À cet\r\neffet, les travaux initialisés récemment par l\'entreprise Emvista\r\nexploitent les liens contenus dans les résumés d\'articles Wikipedia afin\r\nde constituer un corpus volumineux, en français, contenant des\r\nannotations collectées automatiquement, qui peuvent être utilisées pour\r\nla détection, la reconnaissance et la désambiguisation des entités.\r\n\r\n*Sujet de stage*\r\n\r\nEn premier lieu, il s\'agira d\'exploiter le corpus fourni dans le cadre\r\ndu projet TALAD (transcription d\'interviews matinales), en interaction\r\navec des collègues linguistes de l\'équipe PraxiLing, afin d\'y\r\ncaractériser les entités d\'intérêt (entités nommées, entités\r\ncollectives, nominations et dénominations) et de déterminer les méthodes\r\nadéquates pour les repérer automatiquement.\r\n\r\nPour ce qui concerne les ressources extraites depuis Wikipedia, on\r\ncherchera à évaluer la qualité des ressources, à prototyper un système\r\nde désambiguïsation des entités pour le français en utilisant les\r\nméthodes état de l\'art de machine learning et à l\'évaluer\r\ncomparativement à d\'autres systèmes existants, avec une attention\r\nparticulière portée au cas difficile des organisations.\r\n\r\n*Objectifs principaux*\r\n\r\n- Caractérisation des entités d\'intérêt pour le projet TALAD\r\n- Expérimentation de la détection automatiques d\'entités pour la\r\n  nomination\r\n- Participation à l\'extraction et l\'évaluation du corpus de référence\r\n  depuis Wikipedia\r\n- Prototypage d\'un système de désambiguïsation à base de machine\r\n  learning\r\n- Implémentation et évaluation comparative des systèmes de\r\n  désambiguisation\r\n\r\n*Profil recherché*\r\n\r\n- M2 TAL, ou informatique avec for intérêt pour le TAL\r\n- Programmation en python\r\n- Méthodes de machine learning (CRF, LSTM, SVM, etc.)\r\n- Intérêt pour la reconnaissance et la désambiguïsation des entités\r\n\r\n*Précisions sur l\'offre*\r\n\r\n- Durée du stage : 5 ou 6 mois à temps plein\r\n- Date de début : mars ou avril 2019\r\n- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)\r\n- Lieu : Inalco, 3bis rue Taylor, 75010 Paris\r\n\r\n*Candidature*\r\n\r\nEnvoyez votre CV et faites part de vos motivations à Damien Nouvel\r\n(damien.nouvel@inalco.fr)\r\n\r\n\r\n*Références *\r\n\r\n- Named Entities for Computational Linguistics. Damien Nouvel, Maud\r\n  Ehrmann, Sophie Rosset. John Wiley & Sons, 2016.\r\n- Dénomination référentielle, désignation, nomination. Pierre\r\n  Frath. Langue française 4, 2015.\r\n- Data Adaptation for Named Entity Recognition in Twitter with\r\n  Features-Rich CRF. Ngoc Tan Le, Fatiha Sadat, Damien Nouvel. WiNLP\r\n  2018.\r\n- Learning Multilingual Named Entity Recognition from Wikipedia. Joel\r\n  Nothman et. al. Artificial Intelligence 194 2013.\r\n- Evaluating Entity Linking: An Analysis of Current Benchmark Datasets\r\n  and a Roadmap for Doing a Better Job. Marieke Van Erp et. al. LREC\r\n  2016.'),
(566, '2019-02-04', 'LIFAT', 'Tours', '==========\r\nStage de master de 6 mois au Lifat, université de Tours : annotation\r\nautomatique d\'expériences en biologie systémique\r\n========== \r\n\r\n****Description**** \r\n\r\nDans le cadre du projet ANR Abliss (Automating Building from Literature\r\nof Signalling Systems), le laboratoire de recherche en informatique\r\nfondamentale et appliquée (Lifat) de l\'université de Tours propose un\r\nstage de master de 6 mois (avec prolongement possible par un CDD ou une\r\nthèse), à compter de mars-avril 2019.\r\nLe stagiaire travaillera sur le logiciel libre Unitex pour modéliser\r\n(dans des textes en anglais) les protéines, gènes, molécules, etc. qui\r\napparaissent dans des descriptions d\'expériences extraites des articles\r\nscientifiques du domaine de la biologie systémique. Ceci pour\r\nsélectionner les phrases contenant de telles descriptions et les annoter\r\nsous une forme Prédicat-Arguments. Il aura aussi pour charge le\r\ndépouillement et l\'analyse des résultats obtenus.\r\n\r\n****Compétences**** \r\n\r\nIdéalement, la personne candidate devra être dans un master en\r\nbio-informatique (si possible avec une licence en informatique) ou un\r\nmaster mention CCI (avec des études antérieures en biologie). Des\r\ncandidatures d\'étudiants en master de traitement automatique des langues\r\n(avec une formation informatique) sont aussi possibles, sous réserve de\r\nconnaissances en biologie. La connaissance d\'Unitex peut être un plus,\r\nmais n\'est pas obligatoire.\r\n\r\n****Localisation**** \r\n\r\nLe stage est situé au laboratoire de recherche en informatique\r\nfondamentale et appliquée (Lifat) de l\'université de Tours, 64 avenue\r\nJean-Portalis, 37200 Tours. La personne recrutée travaillera dans\r\nl\'équipe BdTln. Des déplacements chez les autres partenaires du projet\r\n(INRA de Tours et LRI de l\'université Paris-Sud) pourront être demandés.\r\n\r\n****Gratification**** \r\n\r\nLa gratification est celle prévue par la loi. \r\n\r\n****Date limite de candidature**** \r\n\r\n28 février 2019 \r\n\r\n****Procédure de candidature**** \r\n\r\nMerci de joindre une lettre de motivation et un CV avec un contact\r\nacadémique et, éventuellement, une lettre de recommandation.\r\n\r\nContacts : Denis Maurel (Lifat) et Anne Poupon (INRA) \r\ndenis.maurel@univ-tours.fr, anne.poupon@inra.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(567, '2019-02-04', 'ITESOFT-Yooz', 'Aimargues', '*Stage d\'Ingénieur d\'exploitation d\'une plateforme d\'intelligence \r\nartificielle d\'analyse de document*\r\n\r\n*Présentation de l\'entreprise*\r\n\r\nYooz est l\'activité SaaS du Groupe ITESOFT-Yooz, éditeur leader sur le\r\nmarché de la dématérialisation des processus documentaires. Yooz est une\r\nSAS de 47 personnes, fondée au 1/1/15, le siège social est localisé à\r\nAimargues (30) et un établissement secondaire est à La Rochelle (17).\r\nYooz propose des solutions logicielles, sous forme de service Internet\r\n(en mode SaaS), permettant à toutes les organisations quelle que soit\r\nleur taille (entreprises, experts comptables, collectivités,\r\nassociations...), de bénéficier des avantages apportés par la\r\ndématérialisation et le traitement automatique des documents ; et ce,\r\nquels que soient les volumes à traiter.\r\n\r\nAujourd\'hui Yooz offre des solutions de traitement de toute pièce\r\ncomptable (factures, achats...). Une valeur ajoutée essentielle du service\r\nde dématérialisation de Yooz est la performance de l\'intelligence\r\nartificielle de Document Understanding des documents dématérialisés,\r\nc\'est-à-dire l\'automatisation de la classification et de l\'extraction\r\ndes informations portées par les documents. L\'innovation technologique\r\ndans ce domaine est dans le coeur de la stratégie de Yooz. Cette\r\ninnovation s\'appuie sur nos développements propres et sur des\r\ncollaborations avec la recherche académique. La performance de notre\r\nintelligence artificielle dans sa capacité à traiter l\'ensemble des\r\ndocuments d\'entreprise est un défi technologique et un enjeu économique\r\nimportant pour maintenir notre leadership sur le marché très\r\nconcurrentiel de la capture.\r\n\r\n*Cadre du Stage : l\'équipe d\'exploitation d\'une plateforme\r\nd\'intelligence artificielle d\'analyse de document*\r\n\r\nMaintenir la performance et au-delà, l\'amélioration continue de la \r\nperformance d\'un service d\'IA traitant 80 000 documents par jour \r\nprovenant de plus de 2000 clients est un défi quotidien. Cette mission \r\nse décline en 3 champs d\'ingénierie :\r\n\r\n- *Développement logiciel *: il s\'agit de réaliser la maintenance du\r\n  service global de document understanding. Ce service orchestre et\r\n  intègre les différents modules d\'IA et de traitement de document qui\r\n  permettent la classification et la fouille de document. Les\r\n  développements sont réalisés suivant les spécifications du responsable\r\n  du développement produit et en collaboration avec l\'équipe de\r\n  recherche fournissant les technologies. Juge et partie, cette tâche de\r\n  développement logiciel s\'accompagne de l\'implantation du logiciel sur\r\n  les postes de production. Elle inclut donc les actions de\r\n  paramétrages, de recette et de déploiement de l\'ensemble du logiciel\r\n  sur les machines de production.\r\n\r\n- *Exploitation *: il s\'agit de superviser la production du service de\r\n  document understanding, c\'est-à-dire garantir que tout document\r\n  présenté sur une machine de production est traité\r\n  rapidement. Basiquement cette mission consiste à détecter les\r\n  blocages, réaliser des reprises et analyser les causes pour proposer\r\n  des solutions, soit en collaboration avec les équipes de R&D et\r\n  d\'exploitation des data centers, soit en corrigeant le service global\r\n  le cas échéant, soit en proposant et en implémentant une\r\n  automatisation de la détection et de la reprise du cas.\r\n\r\n- *L\'amélioration continue des performances*, il s\'agit d\'une part de\r\n  concevoir et réaliser les apprentissages pour maintenir et améliorer\r\n  les performances de différents sous-systèmes d\'IA, et d`autre part de\r\n  proposer et spécifier avec l\'équipe de recherche des améliorations des\r\n  modules technologiques. Pour ce faire, l\'ingénieur doit analyser des\r\n  résultats de traitement des documents et déterminer les axes de\r\n  progrès en conséquence. Il est responsable du contenu de la base de\r\n  connaissance sur laquelle repose le service d\'IA. Tout comme le\r\n  développement du service global, l\'ingénieur est responsable du\r\n  déploiement des apprentissages sur les machines de production. Le\r\n  reporting de la supervision des performances est réalisée directement\r\n  auprès du directeur R&D.\r\n\r\nEn conclusion, la position est stratégique, technique et analytique, au\r\ncentre de la R&D en relation avec les équipes de développement produit,\r\nde recherche, d\'exploitation des data center et du directeur R&D. A la\r\nfois intégrateur technique, utilisateur de technologie et responsable de\r\nl\'exploitation en production, l\'équipe d\'exploitation a des missions\r\nvariées et nécessite une grande rigueur, perspicacité et capacité\r\nd\'analyse de systèmes complexes.\r\n\r\n*Objectif du Stage *: il s\'agit de participer à toute la variété des\r\nmissions de l\'équipe d\'exploitation. En particulier dans le cadre du\r\nstage il s\'agit concrètement :\r\n\r\n- De participer au développement logiciel du service global de document\r\n  understanding V2 actuellement en cours de développement. Les\r\n  développements se feront avec le progiciel Freemind d\'analyse de\r\n  document et par des scripts d\'intégration de technologie en jscript,\r\n  éventuellement python ou java. Ce service est un système complexe\r\n  combinant des modules d\'IA, d\'OCR et de manipulation de document (PDF,\r\n  JPG...). En collaboration avec un ingénieur, le stagiaire montera en\r\n  compétence sur les modules intégrés et participera à leur intégration\r\n  dans un service global.\r\n\r\n- D\'assister l\'ingénieur d\'exploitation dans la supervision de\r\n  l\'exploitation, notamment en étudiant les procédures appliquées pour\r\n  en identifier les tâches automatisables et implémenter des outils\r\n  d\'automatisation. Pour acquérir le savoir-faire, il participera\r\n  occasionnellement aux tâches de suivi.\r\n\r\n- De réaliser des améliorations d\'apprentissage sur des cas précis\r\n  sélectionnés par l\'ingénieur d\'exploitation. La stagiaire se formera à\r\n  quelques techniques d\'apprentissage, de réglages et de paramétrage des\r\n  bases de connaissance. Il mettra en oeuvre, et suivant la\r\n  méthodologie, procèdera la recette et la démonstration des\r\n  améliorations.\r\n\r\nLors du stage, le ou la stagiaire sera sous la supervision de Vincent\r\nPoulain d\'Andecy (resp Recherche), travaillera en collaboration avec\r\nLaurent Danièle (resp Développement), avec un ingénieur de\r\ndéveloppement, un ingénieur d\'exploitation et occasionnellement fera du\r\nreporting d\'exploitation au directeur R&D.\r\n\r\n*Compétences techniques *: pas de forte contrainte (JAVA ou Python ou\r\nJScript). Le stagiaire se formera aux outils de l\'entreprise, en\r\nparticulier le progiciel Freemind.\r\n\r\n*Division *: Recherche et Développement\r\n*Lieu du Stage *: Aimargues\r\n*Indemnité *: 900 ¤ mensuel + 176 ¤ de ticket restaurant (mensuel) + \r\nhébergement gracieux sur site (sous réserve disponibilité).\r\nPerspective à l\'issue du stage : le poste pourra être pérennisé en CDI\r\ningénieur d\'exploitation'),
(568, '2019-02-04', 'Syllabs', 'Paris', '------------------------------------------------------------------------\r\nOffre de stage TAL M2 : Génération automatique de textes\r\n------------------------------------------------------------------------\r\n\r\nSyllabs est spécialisée en analyse sémantique et en génération\r\nautomatique de textes. Nos technologies sont le fruit d\'années de\r\ndéveloppement et maîtrisent toutes les étapes du processus d\'analyse de\r\ndonnées textuelles du Web : identification des pages pertinentes,\r\nextraction et catégorisation des informations clés. La génération est\r\nproposée au travers de notre moteur de rédaction qui permet, à partir\r\nd\'une base de données structurées, de produire automatiquement des\r\ntextes de qualité humaine. Nos robots rédacteurs écrivent pour des\r\nmédias de référence français comme Le Monde ou Radio France.\r\n\r\nC\'est dans le contexte de la génération automatique de textes que nous\r\nrecherchons un·e ingénieur·e linguiste pour intégrer l\'équipe actuelle\r\net participer au paramétrage du moteur de rédaction. Les domaines\r\nd\'application sont principalement les médias et l\'immobilier.\r\n\r\n-----------------------------\r\n Description du poste\r\n------------------------------\r\nLes tâches principales concernent:\r\n- Prise en main de notre moteur de rédaction.\r\n- Écriture des règles pour alimenter notre moteur de rédaction et\r\n  produire des contenus pour nos clients.\r\n- Préparation des bases de connaissances structurées utilisées par les\r\n  règles.\r\n\r\n-----------------------\r\n Profil recherché\r\n------------------------\r\n\r\n- Étudiant·e en Linguistique Informatique, Traitement automatique des\r\n  langues ou Traduction\r\n- Excellentes qualités rédactionnelles, goût pour l\'écriture\r\n- Aptitude pour la représentation formelle du langage\r\n- Excellente capacité de communication et aptitude pour le travail en\r\n  équipe\r\n- Programmation en Python\r\n- Compétences en rédaction web seraient un plus\r\n- Langues maternelle : français, espagnol, anglais, allemand ou\r\n  portugais.\r\n\r\n-----------------\r\n Conditions\r\n-----------------\r\n- Stage conventionné 6 mois rémunéré en fonction du niveau d\'étude\r\n- tickets resto + remboursement à moitié du pass Navigo (transport)\r\n- Bonne ambiance, coin canapé et équipe technique de grande\r\n  qualité. Apéro mensuel\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com en\r\nindiquant dans l\'objet du mél « stage génération ».\r\n\r\nLieu : Quartier de Charonne (Paris 11), entre Bastille et Nation. Locaux\r\nconviviaux partagés avec d\'autres start-ups data-lovers. Possibilité\r\nd\'embauche après le stage à Paris ou à Nantes.'),
(569, '2019-02-04', 'DGA-MI', 'Rennes', 'L\'équipe TAL de DGA-MI recrute un stagiaire :\r\n\r\nCONTEXTE :\r\nLe domaine du traitement automatique des langues (TAL/NLP) a connu un\r\ngrand essor ces dernières années, notamment grâce aux approches de deep\r\nlearning et à la généralisation de l\'open source. Cependant ces\r\ntraitements ne correspondent souvent qu\'à des briques technologiques\r\nindépendantes, qui ne suffisent pas pour mettre en place une chaîne de\r\ntraitement complète, allant du texte brut jusqu\'à l\'information\r\nstructurée.\r\n\r\nSUJET :\r\nL\'objectif de ce stage est donc de tirer parti des technologies open\r\nsource pour développer des systèmes pour plusieurs tâches de TAL, puis\r\nles intégrer dans une même chaîne de traitement, complétée par une IHM\r\npermettant de visualiser directement le résultat des traitements.\r\n\r\nLes technologies intégrées seront définies en coordination avec le\r\nstagiaire, parmi les principales tâches TAL pour l\'écrit :\r\nprétraitements, identification de langue, traduction automatique, OCR,\r\ndétection d\'entités nommées, fouille d\'opinions, classification\r\nthématique, résumé automatique, etc. En fonction des cas, ces systèmes\r\npourront provenir de diverses sources : soit des modèles pré-entraînés\r\ndistribués en ligne, soit des modèles déjà entraînés en interne, soit de\r\nnouveaux modèles que le stagiaire entraînera à partir de code open\r\nsource et de données libres.\r\n\r\nPROFIL DU CANDIDAT :\r\n\r\n- Bac +4 ou bac +5\r\n\r\n- Compétences requises : apprentissage automatique, programmation Python\r\n  et bash, expressions régulières Perl ou équivalent, aisance avec\r\n  l\'environnement Linux et les outils en ligne de commande, maîtrise de\r\n  l\'anglais\r\n\r\n- Compétences souhaitées : traitement automatique des langues,\r\n  développement d\'IHM, deep learning, maîtrise d\'une langue étrangère\r\n  autre que l\'anglais\r\n\r\nCONDITIONS DU STAGE\r\nDurée : 4 à 6 mois (pas de contrainte sur la date de début de stage)\r\nGratification standard\r\n\r\nPoint de contact : dga-mi.stage.fct@intradef.gouv.fr'),
(570, '2019-02-04', 'STL', 'Lille', 'Stage : M2 TAL, Simplification automatique de textes médicaux, STL\r\n(CNRS/Université de Lille)\r\n\r\nLa simplification automatique de textes est un domaine du TAL, dans\r\nlequel il s\'agit d\'appliquer des transformations sur les phrases d\'un\r\ntexte pour les rendre plus lisibles, tout en conservant leur sens\r\nintact. Cela est pratiqué aussi bien à destination des humains que pour\r\nfaciliter les tâches nécessitant l\'analyse automatique de textes [3].\r\n\r\nLa simplification, dont l\'objectif est de faciliter des traitements\r\nd\'analyse automatique, peut faire partie de différentes applications.\r\nAinsi, la première application à l\'avoir exploitée cherchait à\r\nsimplifier les structures de phrases avant de procéder à leur analyse\r\nsyntaxique automatique [3].  Dans d\'autres contextes, la simplification\r\npeut être utilisée pour adapter certains genres de textes à des outils,\r\nqui n\'ont pas été entraînés pour les traiter spécifiquement, comme par\r\nexemple l\'analyse d\'un texte biomédical effectuée avec des outils\r\nentraînés sur des textes journalistiques [6].\r\n\r\nDans le domaine médical, la simplification peut également servir à\r\nfaciliter l\'éducation thérapeutique des patients [2] ou l\'accès à\r\nl\'information par les enfants [5]. En effet, des études ont montré\r\nqu\'une meilleure compréhension des informations de santé par les\r\npatients et leurs familles mène à une meilleure adhésion au traitement\r\net à un processus de soins plus réussi [4,1].\r\n\r\nL\'objectif du travail de stage consiste en la création, le test et\r\nl\'évaluation de ressources et/ou de méthodes en vue de la simplification\r\nautomatique de textes médicaux. La question de recherche précise pourra\r\nêtre définie en accord avec le ou la stagiaire.\r\n\r\nLe ou la stagiaire sera amené(e) à utiliser des outils existants et à\r\ndévelopper ses propres programmes pour effectuer les traitements\r\nadaptés.\r\n\r\nCompétences demandées :\r\n\r\n- connaissances en TAL et informatique\r\n- aptitude à installer et tester de nouveaux outils informatiques\r\n- habitude de Linux\r\n- lecture et analyse de la littérature scientifique, en français et en\r\n  anglais\r\n- autonomie\r\n\r\nLe stage est rémunéré selon les règles en vigueur.\r\n\r\n- Niveau: Master, ingénieur\r\n- Durée: 6 mois\r\n- Lieu: Lille\r\n\r\nPour présenter une candidature: envoyer un CV, la lettre de motivation,\r\nle relevé de notes et les contacts de deux référents à Rémi Cardon\r\n(remi.cardon@univ-lille.fr) et Natalia Grabar\r\n(natalia.grabar@univ-lille.fr).\r\n\r\n[1] ND Berkman, SL Sheridan, KE Donahue, DJ Halpern, and K Crotty.  Low\r\nhealth literacy and health outcomes : An updated systematic review.\r\nAnnals of Internal Medicine, 155(2) : 97-107, 2011.\r\n\r\n[2] Frédérique Brin-Henry. Éducation thérapeutique du patient et\r\northophonie.  In Communiquer malgré l\'aphasie. S. Médical, 2014.\r\n\r\n[3] R. Chandrasekar, Christine Doran, and B. Srinivas. Motivations and\r\nmethods for text simplification. In Proceedings of the 16th Conference\r\non Computational Linguistics - Volume 2, COLING \'96, pages 1041-1044,\r\nStroudsburg, PA, USA, 1996. Association for Computational Linguistics.\r\n\r\n[4] T. Davis and M. Wolf. Health literacy : implications for family\r\nmedicine.  Fam Med, 36 :595-598, 2004.\r\n\r\n[5] J. De Belder and M.-F. Moens. Text simplification for children. In\r\nWorkshop on accessible search systems of SIGIR, pages 1-8, 2010.\r\n\r\n[6] Siddhartha Jonnalagadda, Luis Tari, Jörg Hakenberg, Chitta Baral,\r\nand Graciela Gonzalez. Towards effective sentence simplification for\r\nautomatic processing of biomedical text. In Proceedings of Human\r\nLanguage Technologies : The 2009 Annual Conference of the North American\r\nChapter of the Association for Computational Linguistics, Companion\r\nVolume : Short Papers, pages 177-180. Association for Computational\r\nLinguistics, 2009.'),
(571, '2019-02-11', 'Lattice', 'Paris', 'STAGE : MISE AU POINT DE DISPOSITIFS INFORMATIQUES ET ARTISTIQUES POUR\r\nLA DIFFUSION DE POESIE EN LIGNE\r\n\r\nStage de 3 à 4 mois, à Paris (début en mars ou avril 2019)\r\nNiveau M2 ou équivalent\r\nConvention de stage obligatoire\r\n\r\n\r\nCONTEXTE\r\nLe stage est organisé dans le cadre du projet OuPoCo (« L\'Ouvroir de\r\nPoésie Combinatoire »,\r\nhttp://transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire). Ce\r\nprojet vise à développer d\'une part, un « générateur automatique de\r\npoésie » (c\'est-à-dire un programme capable de générer automatiquement\r\ndes poésies) et, d\'autre part, des dispositifs permettant de diffuser\r\nces poésies sur différents supports et sous différents formats (recueil\r\nsous forme d\'un ouvrage classique, réseaux sociaux, installation\r\nartistique).\r\n\r\nLe stage concerne les dispositifs de diffusion des poésie. Il mêlera\r\ninformatique, chaîne éditoriale et développements artistiques. Le stage\r\nsera dirigé par Mathilde Roussel et Matthieu Raffard depuis leur atelier\r\n(http://www.raffard-roussel.com), en lien avec Thierry Poibeau\r\n(http://lattice.cnrs.fr/Thierry-Poibeau qui dirige le projet OuPoCo.\r\n\r\nLIEU ET HORAIRE DU STAGE\r\nLe stage aura lieu du lundi au vendredi de 10h00 à 18h00 dans l\'atelier\r\ndes artistes Mathilde Roussel et Matthieu Raffard au 189 rue Ordener\r\n(accessible depuis le métro Lamarck-Caulaincourt ligne 12 ou bien Guy\r\nMoquet ligne 13).\r\n\r\nOBJECTIF DU STAGE\r\nLe stage aura pour but de développer un certain nombre de projets\r\nsatellites autour du générateur de poésie élaboré par le Lattice. Il\r\npourra s\'agir, par exemple, de développer un programme qui puisse\r\nproduire, via un site d\'édition en ligne, des recueils de poésie créés\r\nsur demande à partir du générateur de poésie. Il pourra aussi s\'agir de\r\ndévelopper une petite application qui puisse permettre de publier sur\r\nles réseaux sociaux via un flux RSS des fragments de poésies illustrés\r\npar des images générées automatiquement. Il faudra enfin gérer les\r\névolutions du site Web du projet, en fonction de l\'avancement de\r\ncelui-ci et en partenariat avec le prestataire qui réalisera la version\r\nd\'amorçage du site Web du projet.\r\n\r\nD\'autres applications et projet périphériques seront également à\r\ndévelopper au cours du stage, ils seront réalisés en étroite\r\ncollaboration avec Mathilde Roussel et Matthieu Raffard qui à travers\r\nleur travail d\'artiste cherchent à inventer de nouvelles attitudes face\r\naux machines.\r\n\r\nPour finir, le stagiaire sera invité à participer à la création d\'une\r\noeuvre d\'art en relation avec le projet OUPOCO. L\'oeuvre de cette création\r\nreste à définir, elle pourra prendre la forme d\'un système d\'impression,\r\nd\'une performance, ou bien d\'une installation interactive.\r\n\r\n\r\nPROFILS RECHERCHÉS :\r\n\r\n- étudiant(e) de niveau M2 (Master universitaire, Ecole d\'art, etc.)\r\n  avec une formation pertinente (design numérique, édition numérique,\r\n  éventuellement informatique ou littérature avec les compétences\r\n  informatiques adéquates).\r\n- compétences en programmation (scripts en perl ou python)\r\n- compétences en programmation Web et en mise en ligne d\'applications\r\n- compétences ou intérêt en programmation et génération d\'images (\r\n  processing ou python )\r\n- intérêt pour la littérature et la poésie \r\n- sensibilité et intérêt pour les arts plastiques\r\n- sens de la créativité et de l\'innovation\r\n\r\nLe stage durera 3 à 4 mois, à partir du 1er mars 2019 si possible. Il\r\nest indemnisé suivant les règles en vigueur. Il implique la signature\r\nd\'une convention de stage fournie par l\'université ou l\'école de\r\nl\'étudiant.\r\n\r\n\r\nCOMMENT CANDIDATER ?\r\n\r\nEnvoyer par mail (à Matthieu Raffard et Mathilde Roussel :\r\nraffard.roussel@gmail.com avec copie à Thierry Poibeau,\r\nthierry.poibeau@ens.fr) les documents suivants :\r\n\r\n- une courte lettre de motivation (éventuellement directement dans le\r\n  corps du mail)\r\n- un CV\r\n- un relevé de notes récent (de niveau M1 ou M2)\r\n\r\nLes candidatures seront étudiées au fil de l\'eau, la date limite pour\r\ncandidater est fin février (mais il est conseillé de candidater dès que\r\npossible sans attendre la date butoir. Le stage peut être pourvu avant\r\nla date de fin de candidature).'),
(572, '2019-02-11', 'GEOLSemantics', 'Gentilly', 'Stage en TAL, Analyse syntaxique de l\'arabe\r\n\r\nContexte : \r\n\r\nCréé en 2009, GEOLSemantics est un éditeur de logiciels innovants dans\r\nle monde des technologies de l\'information et de la communication et\r\nparticulièrement dans les domaines de la linguistique et de la\r\nsémantique. Les solutions de GEOLSemantics analysent les contenus des\r\ntextes pour identifier, normaliser et structurer les données pertinentes\r\ncontenues dans les textes pour les rendre directement utilisables par\r\ndes processus automatiques apportant les réponses appropriées aux\r\nobjectifs métiers.\r\n\r\nObjectifs de lamission\r\n\r\nDans le cadre d\'un projet de recherche l\'entreprise GEOLSemantics\r\npropose un stage dans le traitement automatique de la langue arabe. La\r\nmission principale sera de mettreau point l\'analyse morphosyntaxique\r\nprofonde de l\'arabe en enrichissant les ressources existantes et en\r\nparticipant à l\'élaboration des règles de désambiguïsation et des règles\r\nsyntaxiques pour son intégration dans l\'outil d\'extraction d\'information\r\nexistant.\r\n\r\nTâches principalesà réaliser\r\n\r\n   - Prise en main du système de GEOLSemantics   \r\n   - Amélioration de la désambiguïsation   \r\n   - Élaboration de règles pour l\'analyse syntaxique   \r\n   - Reconnaissance des entités nommées   \r\n   - Réalisation des tests et de la documentation technique   \r\n\r\nProfil recherché\r\n   \r\n   - Étudiant(e) en Linguistique Informatique, Traitement automatique\r\n     des langues ou Traduction\r\n   - Langue maternelle : arabe   \r\n   - Bonne capacité de communication et aptitude pour le travail en\r\n     équipe\r\n   - Connaissance d\'un langage de script (Python, Perl, etc)   \r\n   - Connaissances en Linux et SVN appréciées   \r\n\r\nConditions\r\n   \r\n   - Stage conventionné de 5 à 6 mois rémunéré   \r\n   - Remboursement à moitié du pass Navigo (transport)   \r\n\r\nMerci d\'envoyer votre candidature à l\'adresse\r\nchristian.fluhr@geolsemantics.comet en indiquant dans l\'objet du mail «\r\nstage en traitement de l\'arabe ».\r\n\r\nLieu : Gentilly.'),
(573, '2019-02-15', 'Orthodidacte', 'Grenoble', 'Intitulé du stage : Amélioration d\'un moteur d\'analyse syntaxique du\r\nfrançais écrit destiné à détecter des erreurs orthographiques.\r\n\r\nContact par courriel : Baptiste Ranty\r\n(baptiste.ranty@orthodidacte.com<mailto:baptiste.ranty@orthodidacte.com>)\r\n\r\nDurée du stage : 4 à 6 mois\r\n\r\nRégion : Auvergne-Rhône-Alpes\r\n\r\nVille : Grenoble\r\n\r\nNiveau d\'étude : Master 2\r\n\r\nNous sommes :\r\n\r\nUne entreprise grenobloise innovante. Orthodidacte est le spécialiste du\r\ndiagnostic, de la formation et de la certification en langue française,\r\nau travers de plateformes numériques.\r\nAvec la plateforme d\'e-learning, professionnels, étudiants et\r\nparticuliers suivent un parcours personnalisé selon leurs besoins. Des\r\nservices d\'accompagnement pédagogique en présentiel sont également\r\nproposés.\r\nAvec la plateforme de dictée numérique, élèves et adultes peuvent\r\ns\'entraîner sur Internet à la dictée et bénéficier d\'une correction\r\nautomatique et instantanée.\r\nEnfin, grâce à la Certification Le Robert, cocréée par Orthodidacte et\r\nles Éditions Le Robert, chacun peut faire valoir son niveau en français\r\nsur son CV.\r\n\r\n\r\nVotre mission :\r\n\r\nDans la plateforme e-learning Orthodidacte.com, un outil de détection et\r\nde catégorisation d\'erreurs de langue est en cours de développement.\r\n\r\nIl fonctionne à partir de règles de détection qui s\'appuient notamment\r\nsur de l\'analyse morphosyntaxique.\r\n\r\nDans l\'optique de rendre cet outil plus performant, vous aurez la charge\r\nde mettre au point et d\'implémenter de nouvelles règles d\'analyse\r\nsyntaxique.\r\n\r\nIl s\'agira donc de réaliser l\'analyse syntaxique automatique de textes\r\npour faire fonctionner des règles de détection prédéterminées.\r\n\r\nVous travaillerez en collaboration avec l\'équipe linguistique.\r\n\r\nVotre profil :\r\n\r\n- Master 2 en linguistique informatique ou TAL\r\n- Goût prononcé pour la langue française et la linguistique\r\n- Bases en programmation Python\r\n- Notions de TAL\r\n- Autonomie, rigueur et communication\r\n\r\nCompétences appréciées :\r\n\r\n- Connaissance de la librairie python spaCy\r\n- Traitement automatique de corpus'),
(574, '2019-02-25', 'Exane', 'Paris', 'Stage Natural Language Processing / NLG / IA - H/F\r\nRéférence :                  SOGLAC.STA.NLP-NLG-IA\r\nType de contrat :            Stage / 6 mois\r\nLieu :                       Paris\r\n\r\n\r\nNOTRE SOCIÉTÉ\r\n\r\nDepuis plus de 25 ans, le Groupe Exane se développe à travers 3\r\nfondamentaux : les actions européennes, l\'investissement et la recherche\r\nactions et dérivés. Reconnu dans les principaux sondages professionnels,\r\nle Groupe figure aujourd\'hui parmi les principaux acteurs indépendants\r\nde la Finance de Marché en Europe et intervient sur trois métiers :\r\n\r\n- l\'Intermédiation Actions (Cash Equities) : Exane BNP Paribas propose à\r\n  une clientèle institutionnelle des services incluant la recherche, la\r\n  vente et l\'exécution sur les valeurs européennes. Depuis 2004,\r\n  l\'Intermédiation Actions est au coeur du partenariat qui lie Exane à\r\n  BNP Paribas ;\r\n\r\n- les Dérivés : acteur historique sur les produits de flux, Exane\r\n  Derivatives a développé une offre complète de services allant de la\r\n  recherche à l\'exécution ;\r\n\r\n- l\'Asset Management : la gestion d\'actifs du Groupe est incarnée par\r\n  deux sociétés de gestion, Exane Asset Management et Ellipsis AM,\r\n  spécialisées respectivement sur l\'univers des actions et des\r\n  obligations.\r\n\r\nAvec plus de 900 collaborateurs, le Groupe Exane s\'est développé à\r\nl\'échelle internationale et est aujourd\'hui présent sur 10 sites dans le\r\nmonde, Paris et Londres étant ses principales implantations.\r\n\r\nVOS MISSIONS\r\n\r\nL\'explosion récente des techniques de Machine Learning, de la robotique\r\net du Big Data, les projets de génération automatique de texte et le\r\ntraitement automatique du langage naturel (« Natural Language Generation\r\n», « Natural Language Processing») sont en plein essor.\r\n\r\nA ce titre, au sein du département Recherche et Développement, vous\r\nintégrez l\'équipe Cash Equity Advisory d\'Exane BNP Paribas.\r\n\r\nVous participerez à la construction de nouveaux produits qui mettront en\r\nvaleur ces nouvelles technologies et interactions conversationnelles.\r\n\r\nVos missions s\'articuleront de la façon suivante :\r\n\r\n- Mise au point de méthodes avancées de génération et de traitement du\r\n  langage appliqués à des outils de production de texte, d\'interfaces\r\n  conversationnelles et la détection automatique d\'intentions de\r\n  l\'utilisateur,\r\n\r\n- Interprétation des données financières (bilan, comptes de résultats,\r\n  cash-flow),\r\n\r\n- Participation au projet d\'intégration des prévisions des analystes\r\n  financiers, en collaboration avec nos analystes financiers et nos\r\n  forces de vente afin de digitaliser l\'interprétation des « grilles\r\n  financières\" en traduisant, sous la forme de commentaires\r\n  synthétiques, les éléments clefs observés par les investisseurs,\r\n\r\n- Participation à des projets de type « bot » de support utilisateurs,\r\n  clients et plus généralement d\'aide utilisateur.\r\n  \r\nCes spécifications sont non-exhaustives et pourront évoluer tout au long\r\ndu stage, au fur et à mesure des réflexions, des recherches, des tests\r\net résultats intermédiaires obtenus.\r\n\r\nCe stage vous permettra d\'aboutir à la réalisation de démonstrateurs\r\ntechniques et à l\'évolution des règles de génération de texte\r\nexistantes.  Vous maîtriserez ainsi les techniques avancées de\r\ngénération automatique de texte et comprendrez les techniques de\r\ntraitement et de génération du langage.\r\n\r\nEnfin, vous aurez réalisez les différentes étapes d\'un travail de\r\nrecherche et développement dans le domaine du conseil en investissement\r\nfinancier.\r\n\r\nPROFIL\r\n\r\n- Bac + 4/5 en Master type linguistique informatique ou équivalent,\r\n  spécialités Traitement Automatique de la Langue, Traduction\r\n  Automatique, Traitement Automatique du Langage Naturel, Linguistique\r\n  Informatique,\r\n\r\n- Bilingue anglais ; une 3ème langue européenne, comme l\'allemand,\r\n  serait appréciée,\r\n\r\n- Très bonne capacité de rédaction et aisance en communication orale et\r\n  écrite,\r\n\r\n- Excellente orthographe et grammaire,\r\n\r\n- Aptitude à apprendre rapidement de nouveaux concepts techniques et à\r\n  prendre en main des outils internes ou externes.\r\n\r\n- Environnement technique : Windows/Linux, Opensource, Java / C++ /\r\n  Python...\r\n\r\nPOSTULER\r\n\r\nCe stage d\'une durée de 6 mois est à pourvoir dès Juin 2019. Ouvert à\r\nl\'alternance pour 12 mois.\r\n\r\nPour postuler, veuillez adresser votre candidature sur :\r\n\r\nhttps://exane-recrute.talent-soft.com/Pages/Offre/detailoffre.aspx?idOffre=2775&idOrigine=380&LCID=1036'),
(575, '2019-02-25', 'Labex OBVIL', 'Paris', 'Ceci est une offre de stage en Humanités Numériques chez le Labex OBVIL \r\n- Sorbonne Université\r\n\r\nContexte et principales missions :\r\n\r\nVous intégrez une équipe de recherche, de développement et d\'édition, le\r\nlabex OBVIL (Observatoire de la Vie Littéraire), où vous participez à la\r\nréalisation de solutions autour des technologies des Humanités\r\nNumériques.\r\n\r\nLe stage se déroulera dans le cadre du projet HyperPaulhan, mené dans le\r\ncadre du Labex OBVIL en partenariat avec l\'IMEC, et a pour objectif la\r\nmise en ligne des correspondances inédites de Jean Paulhan déposées dans\r\nles fonds d\'archives de l\'IMEC\r\n(http://obvil.sorbonne-universite.site/projets/hyperpaulhan) Le(La)\r\nstagiaire recruté(e) participera à la numérisation des lettres dans le\r\ncadre de séjour à l\'IMEC (Caen) pris en charge par le LABEX. Il/Elle\r\ns\'occupera aussi de la transcription d\'une partie des lettres (images et\r\nlettres sont présentées côte à côte sur le site). Il/Elle sera\r\nassocié(e) aux réunions d\'équipe, ainsi qu\'à la préparation d\'une\r\njournée d\'études en 2019, qui interrogera les moyens d\'exploiter un\r\ncorpus électronique de correspondances. Elle pourra bénéficier d\'une\r\nformation au langage XML-TEI et Oxygen, et aura également un accès\r\nprivilégié aux archives de l\'IMEC, qui pourront nourrir le travail de\r\nréflexion d\'un mémoire.\r\n\r\nLa rémunération perçue est conforme à ce qui est prévu par l\'université.\r\n\r\nDurée: 3 à 6 mois\r\nDébut du contrat: dès que possible.\r\n\r\nSi vous êtes intéressé(e), vous pouvez envoyer votre cv et une lettre de\r\nmotivation à Camille Koskas : Camkoskas@gmail.com'),
(576, '2019-03-11', 'Yseop', 'Paris', 'Sujet : Stage - enrichissement et maintenance des bases lexicales\r\n \r\n= La société\r\n\r\nYseop est l\'éditeur international d\'un logiciel d\'Intelligence\r\nArtificielle spécialisé dans la génération automatique de texte en\r\nlangage naturel (Natural Language Génération ou NLG).\r\nNous offrons une solution qui raisonne, dialogue et rédige comme un être\r\nhumain, en plusieurs langues, et qui se concentre sur deux coeurs\r\nd\'expertise : la génération automatique de rapports et la relation\r\nclients.\r\nAujourd\'hui, nous comptons plus de 50 000 utilisateurs quotidiens de la\r\ntechnologie Yseop, principalement des entreprises du CAC 40 et du\r\nFortune 500.\r\n\r\n= La mission\r\n\r\nLes applications (chatbots, etc.) réalisées pour nos clients intègrent\r\nun lexique applicatif qui mêle fréquemment des données très métier et\r\ndes améliorations qui peuvent bénéficier à l\'ensemble de nos\r\nréalisations futures.\r\n\r\nL\'objectif est de concevoir et de développer les outils permettant\r\nd\'analyser et de ré-intégrer ces données issues des projets dans notre\r\ndictionnaire commun.  Ces outils devront également permettre d\'enrichir\r\nle dictionnaire à partir de données lexicographiques ou terminologiques\r\nouvertes.\r\n\r\nCette mission se déroulera au sein de l\'entité Yseop NLU, en étroite\r\ncollaboration avec les équipes travaillant sur l\'apprentissage et\r\nl\'analyse automatique des langues.\r\n\r\n= Le profil recherché\r\n\r\nVous avez un niveau M2 en TAL, avec de bonnes connaissances en\r\nprogrammation, en particulier en Python ainsi qu\'en SQL (MySQL de\r\npréférence) Des connaissances sur les outils de TAL standard (Spacy,\r\nNLTK) et la manipulation de données ouvertes seront appréciées.\r\n\r\nLe stage se déroule dans les locaux de la société, à Paris (75001), pour\r\nune durée de 6 mois à partir de début Avril 2019.\r\n\r\n= Pour postuler\r\n\r\nRendez-vous sur la page\r\nhttps://www.welcometothejungle.co/companies/yseop/jobs/stage-nlu-enrichissement-et-maintenance-des-bases-lexicales_paris'),
(577, '2019-03-11', 'Airbus', 'Toulouse', 'Airbus is a global leader in aeronautics, space and related services. In\r\n2017, it generated revenues of ¤ 67 billion and employed a workforce of\r\naround 130,000. Airbus offers the most comprehensive range of passenger\r\nairliners from 100 to more than 600 seats. Airbus is also a European\r\nleader providing tanker, combat, transport and mission aircraft, as well\r\nas Europe\'s number one space enterprise and the world\'s second largest\r\nspace business. In helicopters, Airbus provides the most efficient civil\r\nand military rotorcraft solutions worldwide.\r\n\r\nOur people work with passion and determination to make the world a more\r\nconnected, safer and smarter place. Taking pride in our work, we draw on\r\neach other\'s expertise and experience to achieve excellence. Our\r\ndiversity and teamwork culture propel us to accomplish the extraordinary\r\n- on the ground, in the sky and in space.\r\n\r\nDescription of the job\r\n\r\nStart date: 1st May 2019 (date subject to some flexibility)\r\n\r\nDuration: 4-8 Months\r\n\r\nLocation: Toulouse (France)\r\n\r\nThe internship will take place within the AIRBUS central research\r\ndivision among the Artificial Intelligence and Data Science team.\r\n\r\nIn order to meet the extraordinary challenges of AIRBUS group future,\r\nour group is in charge of augmenting our systems with Artificial\r\nIntelligence technologies. The team\'s goal is to actively research the\r\nlatest approaches that can enhance AIRBUS products and services as well\r\nas developing beyond state-of-the-art components to address the specific\r\nchallenges of our industrial domain.\r\n\r\nThis internship will be embedded in our learning assistant initiative\r\nthat is trying to enhance traditional system interaction by adding\r\nconversational agent.\r\n\r\nDepending on the profile and research objectives, the intern could\r\ncontribute to NLP (Natural Language Processing) research topics:\r\nconversational technologies (NLU, speech recognition), knowledge\r\nextraction, information retrieval, question answering...\r\n\r\nTasks & accountabilities\r\n\r\nYour main tasks will include:\r\n\r\n  * Grasp the research objectives and the long term targets of the\r\n    project\r\n\r\n  * Analyse the state-of-the-art (SotA) in the relevant literature as\r\n    well as published open source projects\r\n\r\n  * Re-implement existing approaches on AIRBUS dataset\r\n\r\n  *Perform analysis of relevant metrics to identify limitations\r\n\r\n  * Develop an innovative approach to overcome current limitations\r\n\r\nYou will work in a transnational team composed of senior scientists and\r\nresearch engineers. You may also work in close cooperation with trainees\r\ndealing with connected topics.\r\n\r\nThis job requires an awareness of any potential compliance risks and a\r\ncommitment to act with integrity, as the foundation for the Company\'s\r\nsuccess, reputation and sustainable growth.\r\n\r\nRequired skills\r\n\r\nYou must be an undergraduate for the full duration of the placement,\r\nstudying towards a degree in one of the following: Computer Science,\r\nNLP, Speech Recognition, Machine Learning, Deep Learning. You ideally\r\nhave initial experience or past projects in this field.\r\n\r\nYou have existing practice of Python or JAVA. Additional programming\r\nlanguages or scripting such as shell would be a plus. Familiarity with\r\ndocker, GPUs and the cloud would also be a plus.\r\n\r\nYou are a good team player and have excellent interpersonal skills. You\r\nare recognized for your curiosity, creativity and ability to learn\r\nquickly and to suggest potential solutions.\r\n\r\nEnglish: negotiation level. French, German or Spanish would be a plus.\r\n\r\nContact point:\r\n\r\ncatherine.kobus@airbus.com and gerard.dupont@airbus.com'),
(578, '2019-03-20', 'LIDILEM', 'Grenoble', '/*Stage \"Structuration d\'une base de ressources sonores et analyse de \r\ntraces\"*/\r\n\r\n*PrÃ©sentation gÃ©nÃ©rale du projet*\r\n\r\n1. Contexte et environnement de travail\r\n\r\nL\'UniversitÃ© Grenoble Alpes accueille plus de 45 000 Ã©tudiants avec le\r\nconcours de 3000 enseignants-chercheurs, chercheurs et enseignants, et\r\nde 2500 personnels de support et d\'accompagnement.\r\n\r\nLe projet e-FRAN Fluence (2017-2020) est portÃ© par Sylviane Valdois\r\n(LPNC-CNRS) et par le CNRS.\r\n\r\n  * Fluence : http://fluence.cnrs.fr/\r\n\r\n  * Luciole : http://wiki.lezinter.net/index.php/LUCIOLE:Accueil\r\n\r\nL\'UniversitÃ© Grenoble Alpes est reprÃ©sentÃ©e par le Service des Langues,\r\nqui gÃ¨re les budgets pour 2 tÃ¢ches :\r\n\r\n  * CrÃ©ation du jeu Luciole (LIDILEM) ;\r\n  * Interface de suivi (Service des Langues).\r\n\r\n    Dans le cadre du projet e-FRAN FLUENCE, le LIDILEM recrute un\r\n    stagiaire pour participer au projet Â« LUCIOLE Â» pour une durÃ©e de 6\r\n    mois (800h).\r\n\r\n    La prise de fonctions se fera entre le 18/03 et le 01/04.\r\n\r\n2. Objectifs...\r\n\r\n    1. ...du projet Fluence\r\n\r\nLe projet Fluence cible avant tout la fluence de lecture, qui est un\r\nfort prÃ©dicteur de la rÃ©ussite scolaire. L\'hypothÃ¨se centrale est que\r\nles jeux vidÃ©os d\'action (Green, Li, et Bavelier 2010) permettent\r\nd\'entraÃ®ner des mÃ©canismes cognitifs favorisant l\'amÃ©lioration de la\r\nFluence de lecture (Meyer, Diard, et Valdois 2017).\r\n\r\n3 applications (dont 2 ciblant la fluence de lecture) ont Ã©tÃ© conÃ§ues\r\npour le projet Fluence :\r\n\r\n 1. EVAsion (LPNC) : jeu d\'action ciblant les mÃ©canismes\r\n    visuo-attentionnels ;\r\n 2. ELARGIR (Gipsa) : application visant Ã  assister les tÃ¢ches de\r\n    lecture rÃ©pÃ©tÃ©e visant l\'amÃ©lioration de la vitesse et de la\r\n    prosodie ;\r\n 3. Luciole (LIDILEM) : application ciblant la comprÃ©hension de l\'oral\r\n    en anglais.\r\n\r\nPour valider les deux applications portant sur la lecture (applications\r\n1 et 2), une Ã©tude longitudinale est au coeur du projet, impliquant\r\nLuciole pour le groupe Â« contrÃ´le Â».\r\n\r\n    2. ...du projet Luciole\r\n\r\nDans ce contexte, le projet Luciole a Ã©tÃ© intÃ©grÃ© au projet Fluence pour\r\nfournir un groupe contrÃ´le aux autres applications. Inversement, la\r\nconception du protocole expÃ©rimental fait que les autres applications\r\nsont le groupe contrÃ´le de l\'application Luciole.\r\n\r\nAfin qu\'il n\'y ait pas d\'interfÃ©rence entre les applications, nous ne\r\nmettons pas les Ã©lÃ¨ves en contact avec la langue anglaise Ã©crite et\r\nn\'avons pas non plus de modalitÃ©s de jeu d\'action.\r\n\r\n\"Poster des suspects\" affichÃ© dans les salles de classe et utilisÃ© par\r\nles enfants pour identifier les \"mÃ©chants\" (en les scannant avec la\r\ntablette)\r\n\r\nLes objectifs du jeu sont de faire travailler la comprÃ©hension de l\'oral\r\n(en anglais) aux Ã©lÃ¨ves franÃ§ais qui semblent avoir certaines\r\ndifficultÃ©s avec cette activitÃ© langagiÃ¨re (Commission EuropÃ©enne\r\n2012). Pour cela, nous nous appuyons sur les thÃ©ories de l\'acquisition\r\nfondÃ©es sur l\'usage (Bybee 2008; Krashen 1982).\r\n\r\nEn nous appuyant sur les Instructions Officielles (MEN 2015), nous avons\r\nconÃ§u des modalitÃ©s de jeu autour d\'Ã©lÃ©ments langagiers ciblÃ©s dans les\r\nprogrammes (lexique, phonologie, culture, etc.). Plusieurs types\r\nd\'activitÃ© sont proposÃ©s Ã  l\'Ã©lÃ¨ve, celles-ci vont permettre de\r\nprÃ©senter des Ã©lÃ©ments langagiers, d\'entraÃ®ner l\'Ã©lÃ¨ve Ã  les reconnaÃ®tre\r\net enfin de lui proposer de les reconnaÃ®tre en contexte.  Toutes les\r\nactivitÃ©s sont justifiÃ©es par une narration qui donne au joueur le rÃ´le\r\nd\'un agent secret. Cette narration vise Ã  faire de la langue un moyen\r\nd\'atteindre un autre objectif (Cornillie, Thorne, et Desmet 2012), Ã \r\nsavoir libÃ©rer des animaux, Ã  l\'Ã©gard desquels les enfants ont de\r\nl\'empathie (Cassels et al. 2017).\r\n\r\nDans le cadre de ce protocole, les groupes sont testÃ©s concernant la\r\nlecture et l\'anglais en dÃ©but de la 1re annÃ©e puis Ã  la fin de chaque\r\nannÃ©e, ce qui permet d\'Ã©valuer l\'efficacitÃ© de chaque dispositif. Dans\r\nle cadre de Luciole, nous allons pouvoir confronter la rÃ©ussite des\r\nÃ©lÃ¨ves dans le jeu Ã  leurs progrÃ¨s, afin d\'Ã©valuer le transfert de\r\ncompÃ©tences du jeu vers la vie \"rÃ©elle\", enjeu au coeur du domaine du jeu\r\nsÃ©rieux (Girard, Ã‰calle, et Magnan 2013).\r\n\r\n    Le projet commence sa 3^e annÃ©e au cours de laquelle nous allons\r\n    commencer Ã  prÃ©parer les contenus pour les sessions de jeu de\r\n    l\'annÃ©e 2020.\r\n\r\n    Le travail est effectuÃ© au LIDILEM en collaboration avec le LIDILEM.\r\n\r\n3. Bibliographie\r\n\r\nBybee, Joan. 2008. Â« Usage-Based Grammar and Second Language Acquisition\r\nÂ». In /Handbook of Cognitive Linguistics and Second Language\r\nAcquisition/, Ã©ditÃ© par Peter Robinson et Nick C. Ellis,\r\n216-26. Routledge. http://www.unm.edu/jbybee/downloads/Bybee2008UBGandSLA.pdf.\r\n\r\nCassels, Matthew T., Naomi White, Nancy Gee, et Claire Hughes. 2017.  Â«\r\nOne of the family? Measuring early adolescents\' relationships with pets\r\nand siblings Â». /Journal of Applied Developmental Psychology/ 49 (2017):\r\n12-20. http://dx.doi.org/10.1016/j.appdev.2017.01.003.\r\n\r\nChampin, Pierre-Antoine, Alain Mille, et Yannick PriÃ©. 2013. Â« Vers des\r\ntraces numÃ©riques comme objets informatiques de premier niveau : une\r\napproche par les traces modÃ©lisÃ©es Â». /Intellectica/, n^o 59 (juin):\r\n171-204.\r\n\r\nCommission EuropÃ©enne. 2012. Â« First European Survey on Language\r\nCompetences: Final Report Â». Luxembourg: Publications Office of the\r\nEuropean Union.\r\nhttp://ec.europa.eu/dgs/education_culture/repository/languages/policy/strategic-framework/documents/language-survey-final-report_en.pdf.\r\n\r\nCornillie, Frederik, Steven L. Thorne, et Piet Desmet. 2012. Â« Digital\r\ngames for language learning: from hype to insight? Â» /ReCALL/ 24 (3):\r\n243-256. https://doi.org/10.1017/S0958344012000134.\r\n\r\nGirard, Coralie, Jean Ã‰calle, et Annie Magnan. 2013. Â« Serious games as\r\nnew educational tools: how effective are they? A meta-analysis of recent\r\nstudies Â». /Journal of Computer Assisted Learning/ 29 (3):\r\n207-219. https://doi.org/10.1111/j.1365-2729.2012.00489.x.\r\n\r\nGreen, C. Shawn, Renjie Li, et Daphne Bavelier. 2010. Â« Perceptual\r\nLearning During Action Video Game Playing Â». /Topics in Cognitive\r\nScience/ 2 (2):\r\n202-216. https://doi.org/10.1111/j.1756-8765.2009.01054.x.\r\n\r\nKrashen, Stephen D. 1982. /Principles and Practice in Second Language\r\nAcquisition/. Language Teaching Methodology Series. Oxford: Pergamon\r\nPress.\r\n\r\nMEN. 2015. Â« Programmes d\'enseignement de l\'Ã©cole Ã©lÃ©mentaire et du\r\ncollÃ¨ge Â». Bulletin officiel spÃ©cial 386. Paris: MinistÃ¨re de\r\nl\'Ã‰ducation Nationale.\r\nhttp://www.education.gouv.fr/cid95812/au-bo-special-du-26-novembre-2015-programmes-d-enseignement-de-l-ecole-elementaire-et-du-college.html.\r\n\r\nMeyer, Sventlana, Julien Diard, et Sylviane Valdois. 2017. Â« How do\r\naction video games improve reading performance? Theoretical framework\r\nand design principles of an educational software, based on\r\nvisuo-attentional training Â». In . Ajaccio.\r\nhttps://sile2017france.sciencesconf.org/121465.\r\n\r\n*Sujet\r\n\r\nStructuration d\'une base de ressources sonores et analyse de traces*\r\n\r\nAlors qu\'Ã  l\'heure actuelle, un peu plus de la moitiÃ© du jeu LUCIOLE a\r\nÃ©tÃ© rÃ©alisÃ©e (2 annÃ©es de jeu sur 3 annÃ©es prÃ©vues), il a dÃ©jÃ  nÃ©cessitÃ©\r\nla crÃ©ation d\'une base de plus de 2000 sons enregistrÃ©s par des\r\nlocuteurs natifs. Chacun des sons est dÃ©crit dans une base de donnÃ©es\r\nindiquant les locuteurs concernÃ©s (genre, variÃ©tÃ© d\'anglais, etc.), la\r\ntranscription des sons et la liste des activitÃ©s auxquelles ils sont\r\nintÃ©grÃ©s.\r\n\r\n\r\n  Des sons pour l\'enseignement\r\n\r\nEn outre, le jeu ne vise pas Ã  se substituer Ã  l\'enseignement de la\r\nlangue anglaise Ã  l\'Ã©cole primaire, mais Ã  le complÃ©ter ou Ã \r\nl\'enrichir. S\'il peut faciliter pour les enseignants une diffÃ©renciation\r\nde l\'apprentissage en permettant de faire travailler certains Ã©lÃ¨ves en\r\nautonomie pour de courtes sessions, l\'intÃ©gration du jeu Ã  la classe n\'a\r\npas vocation Ã  Ãªtre dÃ©finie par les chercheurs dans le cadre du projet\r\nFLUENCE. Toutefois, bien conscients de certaines des difficultÃ©s des\r\nprofesseurs des Ã©coles par rapport Ã  la langue anglaise, il nous semble\r\npertinent de mettre Ã  disposition de la communautÃ© enseignante\r\n(formateurs ou professeurs des Ã©coles) les enregistrements audio\r\nrÃ©alisÃ©s par des locuteurs natifs.\r\n\r\nDe ce fait, nous aimerions, en marge du projet FLUENCE, structurer les\r\ndiffÃ©rentes donnÃ©es de maniÃ¨re Ã  pouvoir servir de matÃ©riel pÃ©dagogique\r\net permettre Ã  des enseignants et / ou des ingÃ©nieurs pÃ©dagogiques de\r\nles intÃ©grer au sein de leurs pratique. Pour permettre Ã  ces derniers de\r\ns\'emparer de la base de sons, nous voulons mettre Ã  disposition une API\r\nqui permettrait aux utilisateurs de sÃ©lectionner les sons en fonction\r\ndes diffÃ©rents traits rÃ©pertoriÃ©s, voire de l\'analyse des transcriptions\r\ndes sons (ex : tous les sons croisant de l\'anglais et du franÃ§ais dans\r\nlesquels le mot Â« /spy /Â» est mentionnÃ©).\r\n\r\n\r\n  Des informations pour la recherche\r\n\r\nLes requÃªtes permises par le systÃ¨me d\'information mis en place devront\r\npouvoir Ãªtre attaquÃ©s par le logiciel de statistiques R [1] afin de nous\r\npermettre une analyse fine des traces d\'interaction Ã  notre disposition.\r\n\r\nEn effet, Ã  chaque fois qu\'un joueur (faisant partie du protocole\r\nexpÃ©rimental) entend un son, un observÃ©(Champin, Mille, et PriÃ© 2013)est\r\ncollectÃ©. En croisant les donnÃ©es de nos traces, avec celles des\r\nprÃ©/post-tests et de la base de son Ã  crÃ©er, il nous sera possible de\r\nsavoir si certains Ã©noncÃ©s rendent l\'acquisition plus efficaces que\r\nd\'autres, en fonction de la situation d\'Ã©coute et du rÃ´le du son dans\r\nl\'interaction du joueur avec le systÃ¨me.\r\n\r\n\r\n  Missions\r\n\r\n  * proposer une structuration des diffÃ©rentes donnÃ©es ;\r\n  * fournir un systÃ¨me d\'interrogation (API) ;\r\n  * interroger cette API avec R ;\r\n  * Si possible : interroger cette API pour le Web ;\r\n  * proposer des scripts pour la transformation de certaines traces.\r\n\r\n\r\n  ActivitÃ©s\r\n\r\n 1. Familiarisation avec le jeu existant, sa structuration, son\r\n    fonctionnement ;\r\n 2. Prise en main des outils mis Ã  disposition (gitlab, mediawiki) ;\r\n 3. Choix d\'une solution technique (technologie) ;\r\n 4. ModÃ©lisation :\r\n    1. des sons ;\r\n    2. de la base de sons ;\r\n    3. de l\'API ;\r\n    4. des traces et de leurs transformations ;\r\n 5. ImplÃ©mentation ;\r\n 6. Test de l\'API Ã  travers la transformation de traces.\r\n\r\n  Profil recherchÃ©\r\n\r\nÃ‰lÃ¨ve ingÃ©nieur en derniÃ¨re annÃ©e ou Ã©tudiant Master 2 avec\r\nspÃ©cialisation EIAH, SystÃ¨mes d\'Information, Sciences cognitives,\r\nHumanitÃ©s numÃ©riques, Traitement Automatique des Langues ou Psychologie.\r\n\r\n\r\n  CompÃ©tences recherchÃ©es\r\n\r\n  * Programmation Web (php, javascript, MariaDB, API REST) ;\r\n  * Programmation R ;\r\n  * IngÃ©nierie des traces ;\r\n  * Connaissances en statistiques infÃ©rentielles apprÃ©ciÃ©es ;\r\n  * Aptitude au travail en Ã©quipe ;\r\n  * Gestion de projet ;\r\n  * CapacitÃ© Ã  dÃ©fendre et justifier un point de vue ;\r\n  * Dynamisme, force de proposition, capacitÃ© d\'adaptation ;\r\n  * Bon niveau d\'anglais apprÃ©ciÃ©.\r\n\r\n[1] https://cran.r-project.org/\r\nhttps://cran.r-project.org/web/packages/RMariaDB/index.html\r\nhttps://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html \r\n\r\nhttps://cran.r-project.org/web/packages/jsonlite/index.html');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(579, '2019-03-27', 'GEOLSemantics', 'Gentilly', 'Contexte :\r\n\r\nCréée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans\r\nle domaine des technologies de l\'information et de la communication, et\r\nplus particulièrement dans le domaine de l\'extraction\r\nd\'informations. Les solutions de GEOLSemantics analysent les contenus\r\ntextuels pour identifier, normaliser et structurer les données\r\npertinentes qu\'ils contiennent, afin de les rendre directement\r\nexploitables par des processus automatiques.\r\n\r\nMission :\r\n\r\nDans le cadre de la mise en place d\'une nouvelle fonctionnalité dans sa\r\nsolution globale, GEOLSemantics propose un stage en informatique pour\r\nl\'industrialisation de son outil de détection d\'une grande liste de mots\r\ndans un flux très volumineux de textes. L\'algorithme à implémenter est\r\nun automate d\'etat fini réalisé sous forme d\'un dictionnaire arborescent\r\nau niveau du caractère garantissant des temps de traitement compatibles\r\navec les volumes à traiter.\r\n\r\nLa mission principale sera de réaliser la préparation des données,\r\nl\'algorithme de détection des mots ba sé sur le parcours du dictionnaire\r\narborescent. Il sera aussi demandé de réaliser une interface afin de\r\npermettre la consultation des résultats obtenus afin de présenter les\r\ncapacité de ce traitement..\r\n\r\nLe stage se découpera de la manière suivante :\r\n\r\n* Compréhension et implémentation de l\'algorithme de détection des mots\r\n\r\n* Émission d\'alertes\r\n\r\n* Réalisation d\'une interface de consultation des résultats\r\n\r\nIl sera aussi demandé, à chaque phase, de réaliser les tests et la\r\ndocumentation nécessaires.\r\n\r\nProfile recherché :\r\n\r\n- Formation d\'ingénieur ou maitrise informatique\r\n\r\n- Environnement technique : Windows/Linux, Java/Python,\r\n  Eclipse/Netbeans, SVN, Maven, ...\r\n\r\n- Autonomie\r\n\r\n- Bonne aisance rédactionnelle\r\n\r\n- Capacité à travailler en équipe\r\n\r\nDurée : minimum 6 mois\r\n\r\nDate de début : avril 2019\r\n\r\nLieu : Gentilly\r\n\r\nPour postuler, envoyez votre candidature à\r\nchristian.fluhr@geolsemantics.com\r\n\r\nwww.geolsemantics.com'),
(580, '2019-03-27', 'BRGM et LLL', 'Orléans', 'Stage de master 1 ou 2\r\n\r\nBRGM (bureau de recherches géologiques et minières) et LLL (Laboratoire\r\nLigérien de Linguistique)\r\n\r\nStructuration de descriptions géologiques\r\n\r\n*Contexte* : Toutes les données sur les ouvrages souterrains (forages,\r\nsondages, puits et sources) du territoire sont collectées pour être\r\nconservées dans une base de données nommée la Banque du Sous-Sol (BSS),\r\norganisée et gérée par le BRGM, service géologique national. Cette\r\nbancarisation permet d\'améliorer notre connaissance du sous-sol et de\r\nfavoriser les applications en ressources naturelles (ressources fossiles\r\net énergétiques), en géotechniques (travaux d\'infrastructure et\r\nd\'aménagement, etc.). Cette base de donnée contient 700 000 ouvrages et\r\ntravaux souterrains qui, pour près de la moitié, contiennent des données\r\net information sur la géologie du sous-sol et plus particulièrement la\r\ndescription géologique le long des logs de sondages/forages. Ces données\r\nsont actuellement mises à disposition sur notre plateforme de diffusion\r\nInfoTerre (http://inforterre.brgm.fr).\r\n\r\nCes coupes géologiques sont par la suite validées et traitées afin de\r\nfournir une information géologique en tout point de\r\nl\'espace. Aujourd\'hui, environ 20% des logs possèdent une coupe\r\ngéologique élaborée et vérifiée par un professionnel.\r\n\r\nAfin de pouvoir mieux traiter et vérifier ces données, il nous faut\r\ntransférer ces descriptions géologiques aujourd\'hui sous forme de textes\r\ndans des champs attributaires du modèle de données accueillant les\r\ncoupes géologiques.\r\n\r\nL\'extraction d\'information, domaine du Traitement Automatique des\r\nLangues, s\'intéresse à cette question de la structuration de données à\r\npartir d\'informations non structurées présentes dans des descriptions\r\ntextuelles.  Les méthodes permettant de structurer l\'information peuvent\r\nêtre de deux types : symboliques ou statistiques. Lorsque le domaine\r\nd\'application est très restreint, par exemple la nature des roches, les\r\nméthodes symboliques basées sur des règles ou grammaires locales et des\r\nlexiques du domaine permettent d\'obtenir des résultats satisfaisants.\r\n\r\n*Descriptif du stage* : Le sujet du stage proposé portera sur le\r\ndéveloppement d\'une approche visant à automatiser un « transfert » des\r\ndescription d\'une nature de roche aujourd\'hui en texte vers des champs\r\nattributaires (contenant des lexiques) bien définis.\r\nPar exemple :\r\nEn texte : « sable argileux »\r\nStructuré : lithologie 1 : sable ; qualifiant : argileux\r\n\r\nPendant la durée du stage, le stagiaire sera en charge d\'établir un état\r\nde l\'art sur les méthodes existantes permettant de résoudre la\r\nproblématique.  Il pourra travailler sur des logiciels comme Unitex\r\n(https://unitexgramlab.org/fr) ou tout autre outil adapté pour modéliser\r\nles descriptions des natures de roche et ainsi les extraire des textes,\r\net devra mettre en place une évaluation automatique régulière du système\r\ndéveloppé. Le stagiaire sera également amené à développer des scripts\r\npython pour le traitement des données textuelles (pré- et\r\npost-traitement) ainsi que pour interagir avec la base de données.\r\n\r\n\r\n*Profil candidat(e)* : Stage de master\r\n\r\n   - Formation en Traitement Automatique des Langues\r\n   - Connaissance de base de l\'outil UNITEX ou d\'un outil d\'analyse de\r\n     corpus\r\n   - Manipulation de base de données et des registres des lexiques\r\n   - Programmation Python\r\n   - Intérêt pour le langage scientifique de description/observation des\r\n     roches.\r\n\r\nMotivation, rigueur, capacité d\'organisation et relationnelle, autonomie\r\net esprit d\'initiative sont des plus pour la sélection des candidats.\r\n\r\n\r\n*Encadrement* :\r\nBRGM : Christelle Loiselet (Ingénieur géologue),\r\nLLL : Anne-Lyse Minard (Maître de Conférences en TAL)\r\n\r\n*Durée du stage* : 6 mois\r\n\r\n*Période du stage* : Avril - Septembre 2019\r\n\r\n*Localisation du stage* : au Centre scientifique et technique du BRGM à\r\nOrléans (45) et au Laboratoire Ligérien de Linguistique à l\'Université\r\nd\'Orléans (45).\r\n\r\n\r\nUne lettre de motivation et un CV actualisés sont à adresser à\r\nChristelle Loiselet (c.loiselet@brgm.fr) ou à Anne-Lyse Minard\r\n(anne-lyse.minard@univ-orleans.fr).'),
(581, '2019-03-27', 'Crédit Agricole', 'Montrouge', 'Emploi : Freelance/Stage Annotation manuelle de textes financiers en\r\nAnglais/Français\r\n=========================================================================\r\n\r\nLe DataLab Groupe de Crédit Agricole SA recherche 3 ou 4 annotateurs à\r\ntemps plein ou partiel, débutants et confirmés, pour l\'annotation\r\nmanuelle de textes financiers Anglais/Français.\r\n\r\nContexte\r\n\r\nLe DataLab développe des méthodes d\'extraction d\'information à partir de\r\ntextes en langue naturelle.\r\nDans le cadre de la préparation de cette tâche d\'extraction\r\nd\'information, l\'équipe construit un corpus de textes annotés.\r\n\r\nDurée : 1 à 2 mois (temps plein ou partiel)\r\nLieu de travail : DataLab Groupe\r\nDate de démarrage souhaitée : Juin\r\nRémunération : selon profil\r\nCandidature : envoi d\'un CV\r\nContacts:\r\nAymen SHABOU\r\n(aymen.shabou@credit-agricole-sa.fr),\r\nYulia KOLOSKOVA\r\n(Yulia.koloskova@credit-agricole-sa.fr)\r\n\r\nDescription\r\n\r\nLa mission de la personne recrutée sera d\'annoter des entités nommées\r\nd\'intérêt et leurs relations.\r\nL\'annotation se fera en équipe à l\'aide d\'un logiciel collaboratif dédié\r\net selon des consignes d\'annotation détaillées, pour lesquels la\r\npersonne recrutée sera formée.\r\nL\'annotation se fera sous la supervision d\'un infolinguiste Sénior du\r\nDataLab.\r\n\r\nCompétences\r\n- maîtrise de la langue anglaise\r\n- maitrise de la langue française\r\n- grande rigueur\r\n- aptitude pour le travail en équipe\r\n- une expérience en annotation manuelle de textes serait un plus\r\n- des connaissances en TAL / linguistique / ingénierie de la\r\n  connaissance seraient un plus\r\n- des connaissances en corpus financiers seraient un plus.\r\n\r\nAutres opportunités\r\n\r\nLes opportunités d\'annotation de corpus textuels sont nombreuses dans le\r\ngroupe. Les profils recrutés sur ce projet seront donc sollicités en\r\npriorité par le DataLab pour les futurs besoins d\'annotation.'),
(582, '2019-04-10', 'Lo Congrès', 'Pau', 'OFFRE DE STAGE\r\n\r\nDéveloppeur/Développeuse TAL (Traitement Automatique des Langues)\r\n\r\nLOCALISATION : Pau (Billère, 64)\r\n\r\nLe Congrès permanent de la langue occitane est une institution\r\nacadémique de régulation de la langue occitane. Il rassemble les\r\nfédérations historiques et les institutions d\'étude, de valorisation\r\net transmission de cette langue, et est soutenu par les collectivités\r\n(Régions Occitanie et Nouvelle-Aquitaine via l\'Office public de la\r\nlangue occitane, Auvergne-Rhône-Alpes) et le ministère de la Culture\r\net de la Communication-DGLFLF.\r\n\r\nLe Congrès est éditeur du portail locongres.org (300 000 visites/an),\r\nplateforme de ressources lexicales et d\'outils linguistiques en langue\r\noccitane. Il pilote également la Feuille de route de développement\r\nnumérique de l\'occitan, dirige différents projets en technologies de\r\nla langue (programme LINGUATEC, clavier prédictif Android, correcteur\r\northographique pour éditeurs de texte, client de messagerie et\r\nnavigateurs web) et travaille en partenariat avec le laboratoire\r\nCLLE-ERSS (UMR CNRS/Toulouse 2) autour de la constitution d`une base\r\ntextuelle (BaTelÒc) et d\'un lexique ouvert des formes fléchies\r\n(LOFlÒc).\r\n\r\nLe Congrès est constitué d\'une équipe de 6 personnes (directeur,\r\ndéveloppeuse TAL/Webmaster, chargé de mission linguistique,\r\nlexicographes et secrétaire-comptable).\r\n\r\nMISSIONS\r\n\r\nVos missions s\'effectueront dans le cadre d\'un consortium européen\r\nassociant universités, académies de la langue et une société de\r\ndéveloppement de logiciels : LINGUATEC (EFA227/16) « Développement de\r\nla coopération transfrontalière et du transfert de connaissances en\r\ntechnologies de la langue ». Il s\'agit d\'un programme retenu par le\r\nsecond appel à projets du Programme de Coopération Territorial\r\nEspagne-France- Andorre POCTEFA (2014-2020) qui a pour objectif le\r\ntransfert de technologies et le développement de ressources et\r\nd\'applications linguistiques innovantes en aragonais, basque et\r\noccitan.\r\n\r\nEn fonction de la durée du stage et de vos centres d\'intérêt, vous\r\neffectuerez tout ou partie des tâches suivantes :\r\n\r\n1. Réalisation d\'un lexique de formes fléchies contenant les mots\r\nfrançais des dictionnaires bilingues du Congrès :\r\n\r\nDans le cadre de la refonte de son site Internet, Le Congrès souhaite\r\nfusionner ses applications en une seule multi-application. Celle-ci\r\npermettra d\'accéder, pour un mot tapé par l\'utilisateur, à ses\r\ntraductions (ou aux traductions de son lemme), à ses flexions, aux\r\nexpressions qui le contiennent... Cet outil permettra, entre autres,\r\nd\'accéder aux traductions en occitan du lemme d\'une forme fléchie en\r\nfrançais.\r\n\r\nVous serez chargé de la réalisation de la base de formes fléchies françaises qui sera interrogée par cet outil, qui\r\nservira également à construire divers outils comme un traducteur automatique. Vous extrairez les formes\r\nfrançaises des dictionnaires bilingues du Congrès, recenserez les formes fléchies existantes et génèrerez les\r\nformes fléchies manquantes. Vous pourrez vous appuyer pour ce faire sur les règles de flexion du français et sur la base de formes fléchies Morphalou.\r\n\r\n2. Enrichissement des ressources en français du traducteur automatique\r\nApertium :\r\n\r\nDans le cadre de Linguatec, Le Congrès développe un traducteur\r\nautomatique occitan-français et français- occitan. Afin d\'améliorer\r\nson fonctionnement, vous aurez la charge d\'enrichir les lexiques de\r\nformes fléchies en français d\'Apertium à partir du lexique de forme\r\nfléchies décrit ci-dessus ainsi que du lexique de formes fléchies\r\nMorphalou.\r\n\r\nVous serez également chargé d\'améliorer le PoS-tagger français\r\nd\'Apertium en enrichissant sa base de règles de désambiguisation.\r\n\r\nPROFIL\r\n- Etudiant en Master 1 informatique ou linguistique.\r\n- Capacité à utiliser un ou plusieurs langages de programmation.\r\n- Connaissances solides en grammaire française.\r\n- Autonomie, rigueur, capacité d\'analyse, maîtrise des échéances\r\n\r\nDUREE DU STAGE\r\n\r\nEntre un et deux mois.\r\n\r\nREMUNERATION\r\n\r\nMontant de la gratification obligatoire. Si stage inférieur à 44\r\njours, possibilité de prise en charge de l\'hébergement.\r\n\r\nEnvoyer CV + Lettre de motivation à : b.dazeas@locongres.org'),
(583, '2019-08-26', 'Worldline', 'Seclin', 'Smarter Chatbots (F/H) en Alternance\r\n\r\nPublish Date: Aug 13, 2019\r\n\r\nLocation: Seclin - 59, Nord, FR\r\n\r\nCompany: Atos\r\n\r\nAbout Worldline\r\n\r\nWorldline [Euronext: WLN] is the European leader in the payment and\r\ntransactional services industry. With innovation at the core of its\r\nDNA, Worldline\'s core offerings include pan-European and domestic\r\nCommercial Acquiring for physical or online businesses, secured\r\npayment transaction processing for banks and financial institutions,\r\nas well as transactional services in e-Ticketing and for local and\r\ncentral public agencies. Thanks to a presence in 30+ countries,\r\nWorldline is the payment partner of choice for merchants, banks,\r\npublic transport operators, government agencies and industrial\r\ncompanies, delivering cutting-edge digital services. Worldline\'s\r\nactivities are organized around three axes: Merchant Services,\r\nFinancial Services including equensWorldline and Mobility &\r\ne-Transactional Services. Worldline employs circa 11,000 people\r\nworldwide, with estimated pro forma revenue of circa 2.3 billion euros\r\non a yearly basis. worldline.com\r\n\r\nLe contexte\r\n\r\nRemises sur le devant de la scène grâce à l\'explosion récente des\r\ntechniques de machine learning, de la robotique grand public et du big\r\ndata, les problématiques de reconnaissance vocale (« Automatic Speech\r\nRecognition »), ou de traitement automatique du langage naturel («\r\nNatural Language Processing/Understanding ») voient s\'ouvrir un nouvel\r\nhorizon. Au sein de l\'équipe « User Experience » du département\r\nRecherche et Développement de Worldline, nous nous intéressons aux\r\ninteractions avec des assistants personnels virtuels grâce à ces\r\nnouvelles interfaces conversationnelles : comment extraire des\r\nconcepts présents dans les requêtes formulées par l\'utilisateur ?\r\nComment créer un dialogue qui semble « naturel » ? Quelles sont les\r\nmeilleures solutions logicielles et matérielles à mettre en place ?\r\n\r\nLe projet\r\n\r\nCe stage a pour objet l\'expérimentation de méthodes avancées de\r\ntraitement du language dans le but de proposer une meilleure\r\nexpérience conversationnelle : prise en compte de feedback explicite\r\nou implicite pour enrichir une écoute active lors de la conversation,\r\ncontextualisation du dialogue et gestion de modèles multilingues,\r\néquivalence sémentique pour une reformulation précise de réponses à\r\npartir de contenus externes, recommandations et système de relance de\r\nconversation pour éviter les impasses.\r\n\r\nDes approches de Machine Learning orientées traitement de séquences\r\nseront à privilégier. En relation avec des partenaires de Worldline,\r\non cherchera des outils pour mesurer les performances des différentes\r\nméthodes, et pour industrialiser la création de modèles. Le stage\r\naboutira à la réalisation d\'un démonstrateur technique ou\r\nd\'usage. Vous serez amené à partager vos travaux lors d\'événements\r\ninternes.\r\n\r\nEnvironnement technique : Kotlin, Javascript, Opensource, etc.\r\n\r\nCompétences développées\r\n\r\n- Maîtriser des techniques avancées de traitement automatique du\r\n  langage orienté conversations et chatbots\r\n\r\n- Réaliser les différentes étapes d\'un travail de recherche et\r\n  développement entreprise : élaborer une réflexion originale sur un\r\n  sujet donné, établir un état de l\'art des technologies et des\r\n  usages, faire des choix techniques appropriés à un contexte donné,\r\n  valider ces choix par la réalisation de solutions innovantes et\r\n  démonstratives.\r\n\r\nQui êtes-vous ?\r\n\r\nDe formation supérieure en informatique (Bac+5), vous recherchez un\r\nstage dans l\'innovation.\r\n\r\nVous avez acquis de bonnes connaissances dans le domaine du traitement\r\ndu langage.\r\n\r\nAutonome et impliqué(e), vous faites preuve d\'une grande curiosité et\r\nd\'une appétence particulière pour tout ce qui a trait à l\'Innovation,\r\naux nouveaux usages et nouvelles technologies.\r\n\r\nWhy work at Worldline?\r\n\r\nOur success comes from strong skills, new ideas, diverse points of\r\nview and the energy of all women and men from Worldline. Not only do\r\nthey represent our Human Capital, they are also key players in our\r\nsuccess. We make managing our talents a major asset in the success of\r\nour business.\r\n\r\nAt Worldline, we do more than just managing our talents. It is our top\r\npriority to involve them, inspire them, and develop them. In line with\r\nour guiding principle \"Build your career and grow with us\", it is our\r\nmission to ensure that their potential can grow and flourish through\r\nthe numerous development programs and career opportunities we offer.\r\n\r\nYour Application\r\n\r\nIf you wish to apply for this position, please click below to complete\r\nour online application form and attach your CV in either Word, rtf or\r\ntext format.  Worldline is an equal opportunity employer. All\r\napplicants will be considered for employment without attention to\r\ntheir race, color, religion, sex, sexual orientation, gender identity,\r\nnational origin, veteran or disability status. Our recruitment\r\ndecisions are based solely on qualifications, skills, knowledge and\r\nexperience and relevant business requirements.\r\n\r\nWe are committed to making reasonable adjustments to the applications\r\nprocess for people with disabilities.\r\n\r\nPostuler en ligne :\r\n\r\nhttps://jobs.atos.net/job/Seclin-Smarter-Chatbots-%28FH%29-en-Alternance-Nord/535071901/'),
(584, '2019-10-14', 'Naver Labs', 'Grenoble', 'NAVER LABS Europe: Internship  \r\n\r\nStart date: Fall 2019 or early 2020\r\n\r\nDuration; 5-6 months\r\n\r\nWe are opening a research internship on Reinforcement Learning\r\ntechniques for applications to controlled text generation.  Under\r\nconditions where training data is limited, standard end-to-end\r\ntraining of seq2seq models may generalize poorly and produce\r\ninadequate results at test time. A possible remedy is to augment\r\nmodels with rewards that control the quality of the outputs. These\r\nrewards can address two complementary goals: (i) taking into account\r\nglobal characteristics of observed sequences that go beyond standard\r\nlocal teacher-forcing training techniques (observation bias problem),\r\nand (ii) moving the generation process towards desired properties of\r\nthe output (e.g. favoring shorter sentences or performing style\r\ntransfer).\r\n\r\nSupervisors: Marc Dymetman and Hady Elsahar.\r\n\r\nWe are looking for a motivated intern to help us develop methods and\r\nalgorithms for addressing this general problem, both in theory and in\r\npractice. Experiments will be conducted on selected text generation\r\ntasks (NLG, Summarization or Machine Translation).\r\n\r\nThe successful candidate should be enrolled in a graduate program, at\r\nthe Master or (preferably) PhD level, with experience (ideally) in\r\nDeep Learning, Reinforcement Learning and Natural Language Processing.\r\n\r\nPublication of results in major conferences/journals will be strongly\r\nencouraged.\r\n\r\nREQUIRED SKILLS :\r\n\r\nStrong mathematical and programming skills as well as familiarity with\r\none of the major current deep learning toolkits (PyTorch preferred but\r\nnot compulsory) are a requirement.\r\n\r\nFor more information and for applying, please visit the link below:\r\n\r\nhttps://europe.naverlabs.com/job/reinforcement-learning-for-controlled-text-generation/'),
(585, '2019-10-15', 'Naver Labs', 'Grenoble', 'Job Type : Internship  \r\nStart date : November 2019 or otherwise August2020\r\nDuration : 5-6 months\r\n\r\nDescription\r\n\r\nAspect-based sentiment analysis (ABSA) is the task of identifying\r\nfine-grained opinion polarity towards specific aspects associated with\r\na given target.\r\n\r\nThe goal of this internship is exploring and implementing a new neural\r\narchitecture for end-to-end ABSA, where term detection, aspect and\r\npolarity classification are jointly modeled. Special attention will be\r\ngiven to data-efficient methods in order to cope with situations where\r\nlittle amount of annotated data is available. Experiments will be\r\nconducted and evaluated on multiple datasets from various domains and\r\nlanguages and results will be evaluated not only on specific ABSA\r\nsubtasks but also on the full chain of annotations.\r\n\r\nThe expected outcome is, a minima, a multilingual prototype working on\r\ndifferent domains.\r\n\r\nThe successful candidate should be enrolled in a graduate program, at\r\nthe Master or PhD level, with a focus on NLP and Deep Learning.\r\n\r\nPublication of results in major conferences/journals will be strongly\r\nencouraged.\r\n\r\nRequired skills\r\n\r\nGood programming skills and proficiency with TensorFlow or PyTorch\r\n\r\nReferences\r\n\r\nTask: SemEval2016 Task 5: http://alt.qcri.org/semeval2016/task5/\r\n\r\n[1] Pontiki, Maria, Dimitris Galanis, Haris Papageorgiou, Ion\r\nAndroutsopoulos, Suresh Manandhar, Mohammed AL-Smadi, Mahmoud\r\nAl-Ayyoub, et al. 2016. \"SemEval-2016 Task 5 : Aspect Based Sentiment\r\nAnalysis.\" In Proceedings of the 10th International Workshop on\r\nSemantic Evaluation (SemEval-2016), 19-30. Association for\r\nComputational Linguistics.\r\n\r\n[2] Bailin, Wang and Lu, Wei. \"Learning Latent Opinions for\r\nAspect-level Sentiment Classification\". Proceedings of AAAI 2018, New\r\nOrleans.\r\n\r\n[3] Chi Sun, Luyao Huang, Xipeng Qiu. \"Utilizing BERT for Aspect-Based\r\nSentiment Analysis via Constructing Auxiliary Sentence\". Proceedings\r\nof NAACL-HLT 2019, pages 380-385 Minneapolis, Minnesota, June 2 - June\r\n7, 2019.\r\n\r\nApplication instructions\r\n\r\nPlease note that applicants must be registered students at a\r\nuniversity or other academic institution and that this establishment\r\nwill need to sign an \'Internship Convention\' with NAVER LABS Europe\r\nbefore the student is accepted.\r\n\r\nYou can apply for this position online. Don\'t forget to upload your CV\r\nand cover letter before you submit. Incomplete applications will not\r\nbe accepted.\r\n\r\nAbout NAVER LABS\r\n\r\nNAVER LABS is a world class team of self-motivated and highly engaged\r\nresearchers, engineers and interface designers collaborating together\r\nto create next generation ambient intelligence technology and services\r\nthat are rich with the organic understanding they have of users, their\r\ncontexts and situations.\r\n\r\nSince 2013 LABS has led NAVER\'s innovation in technology through\r\nproducts such as the AI-based translation app `Papago\', the\r\nomni-tasking web browser `Whale\', the virtual AI assistant `WAVE\',\r\nin-vehicle information entertainment system `AWAY\' and M1, the 3D\r\nindoor mapping robot.\r\n\r\nThe team in Europe is multidisciplinary and extremely multicultural\r\nspecializing in artificial intelligence, machine learning, computer\r\nvision, natural language processing, UX and ethnography. We\r\ncollaborate with many partners in the European scientific community on\r\nR&D projects.\r\n\r\nNAVER LABS Europe is located in the south east of France in\r\nGrenoble. The notoriety of Grenoble comes from its exceptional natural\r\nenvironment and scientific ecosystem with 21,000 jobs in public and\r\nprivate research. It is home to 1 of the 4 French national institutes\r\nin AI called MIAI (Multidisciplinary Innovation in Ai) It has a large\r\nstudent community (over 62,000 students) and is a lively and\r\ncosmopolitan place, offering a host of leisure opportunities. Grenoble\r\nis close to both the Swiss and Italian borders and is the ideal place\r\nfor skiing, hiking, climbing, hang gliding and all types of mountain\r\nsports.\r\n\r\nApply Online\r\n\r\nhttps://europe.naverlabs.com/job/end-to-end-aspect-based-sentiment-analysis/'),
(586, '2019-10-15', 'Syllabs', 'Paris', 'Offre de stage : M2 Linguistique informatique (H/F) - Extraction \r\nd\'information (Paris 11e)\r\n\r\nCréée en 2006, Syllabs compte parmi les leaders mondiaux en solutions\r\nsémantiques et production automatique de contenus multilingues.\r\n\r\nForts d\'un important travail de R&D en continu depuis notre création,\r\nnous avons développé un ensemble technologique comprenant des solutions\r\nde collecte (/web mining/), d\'analyse (/text mining/) et de génération\r\nde textes (robots rédacteurs). Nous développons des solutions de\r\nrédaction automatique d\'articles pour plusieurs acteurs médias (Les\r\nEchos, Le Monde, Slate, Radio France...) ainsi que des descriptifs pour\r\ndes sites de l\'e-commerce, de l\'immobilier ou du tourisme.\r\n\r\nSyllabs recrute un(e) stagiaire dont le rôle sera d\'améliorer la partie \r\nlinguistique de notre système d\'extraction d\'information.\r\n\r\n*-----------------------------*\r\n*Description du stage*\r\n-----------------------------\r\n\r\nL\'extraction d\'information de Syllabs utilise un outil dédié à base de\r\nrègles linguistiques afin d\'identifier et d\'extraire, à partir d\'un\r\ndocument rédigé en langage naturel, tous type d\'expressions\r\nlinguistiques et de tonalité. Nous souhaitons prolonger les travaux\r\nd\'extraction au gré des différents projets en cours et à venir.\r\n\r\nEn collaboration avec les personnes travaillant sur l\'outil, les tâches\r\nentreprises tout au long du stage concerneront principalement :\r\n\r\n  * La compréhension du fonctionnement du système et des besoins.\r\n\r\n  * La prise en main de l\'existant et la révision des règles et de la\r\n    structure des projets.\r\n\r\n  * L\'écriture de nouvelles règles et la gestion de lexiques.\r\n\r\n  * L\'écriture de tests unitaires, à partir de corpus définis au\r\n    préalable.\r\n\r\n  * Selon la durée du stage, le développement spécifique et\r\n    apprentissage pour la désambiguïsation en sortie d\'extraction.\r\n\r\n-----------------------------\r\n*Profil recherché*\r\n*-----------------------------*\r\n\r\n  * Formation M2 en linguistique informatique\r\n\r\n  * Aptitude pour la représentation formelle du langage\r\n\r\n  * Expérience avec un outil d\'extraction d\'information (Nooj, Gate...)\r\n\r\n  * Bon niveau en Python serait un plus\r\n\r\n  * Autonomie et capacité à travailler en équipe\r\n\r\n  * Bon sens relationnel et à l\'écoute\r\n\r\n-----------------------------\r\n\r\n*Divers*\r\n\r\n-----------------------------\r\n\r\nDurée : de 4 à 6 mois\r\n\r\nStage conventionné, rémunération supérieure à la rémunération minimale +\r\ntickets resto + remboursement de la moitié du passe Navigo.\r\n\r\nNos locaux sont situés dans le très agréable quartier de Charonne, entre\r\nBastille et Nation, au 35 rue Chanzy (75011), que nous partageons avec\r\nd\'autres start-ups innovantes.\r\n\r\nMerci d\'envoyer votre candidature à l\'adresse jobs@syllabs.com'),
(587, '2019-11-07', 'HelloWork', 'Rennes', 'Stage M2 : Segmentation textuelle dans un cadre de classification\r\nautomatique d\'offres d\'emploi (English version below)\r\n\r\n\r\nContexte\r\n\r\nChez HelloWork, nous mettons en relation les recruteurs, les\r\ncollectivités et les centres de formations avec tous les actifs. Qu\'ils\r\ncherchent à évoluer dans leur entreprise ou juste à en changer. Qu\'ils\r\nse réorientent ou montent en compétences. Qu\'ils soient en recherche\r\nactive ou à l\'écoute d\'opportunité. Nos services RegionsJob, ParisJob,\r\nCadreo, BDM et MaFormation leur permettent de trouver leur équilibre vie\r\npro / vie perso tout au long de leur carrière. HelloWork développe\r\négalement des logiciels RH pour accompagner et favoriser l\'expérience\r\nrecruteur et candidat sur l\'intégralité d\'un processus de recrutement\r\navec Talent Detection, Talentplug ou encore CVCatcher.\r\n\r\n\r\nHelloWork recherche un(e) stagiaire pour travailler sur la segmentation\r\nautomatique des offres d\'emploi en vue de la classification supervisée\r\ndes offres.\r\n\r\n\r\nDescription du stage\r\n\r\nAfin de rendre le processus du recrutement plus efficace et ainsi\r\nd\'améliorer l\'expérience candidat et recruteur, nous développons un\r\nsystème de classification supervisée multi-classe des offres\r\nd\'emploi. Pour améliorer notre système, nous souhaitons mettre en place\r\nune segmentation automatique des offres basée sur des approches\r\nstatistiques (clustering / similarité entre les segments textuels /\r\nglissement thématique (topic shift) pour déterminer les frontières des\r\nsegments textuels, etc.), combinées si besoin avec des règles manuelles\r\nou déduites automatiquement.\r\n\r\nNous disposons d\'offres semi-structurées ou non-structurées. Votre\r\nobjectif sera de proposer et d\'implémenter un algorithme qui découpe une\r\noffre en segments sémantiquement homogènes (ex. \"Intitulé de poste\",\r\n\"Description de l\'entreprise\", \"Missions\", \"Profil recherché\", etc.). Ce\r\ndécoupage doit répondre à nos besoins d\'amélioration de la\r\nclassification supervisée des offres.\r\n\r\nCette mission implique de :\r\n\r\n  * analyser la structure \"type\" de l\'offre d\'emploi,\r\n\r\n  * comprendre le fonctionnement de notre classifieur d\'offres,\r\n\r\n  * définir quels segments doivent être utilisés/écartés pour une\r\n    performance de classification optimale,\r\n\r\n  * faire un état de l\'art des techniques de segmentation de documents\r\n    textuels, mais aussi de détection de plagiat et de doublons ou Near\r\n    Duplicate Detection en anglais (pour écarter la partie \"Description\r\n    de l\'entreprise\" partagées par plusieurs offres).\r\n\r\n  * sélectionner une/des approche(s) adaptée(s) à la nature du document\r\n    et au contexte industriel,\r\n\r\n  * implémenter cette approche en Python,\r\n\r\n  * évaluer l\'impact de cette approche sur les performances de\r\n    classification automatique.\r\n\r\n\r\nVous serez intégré dans notre équipe pluridisciplinaire DataLab. En\r\ncharge des problématiques Big Data, elle est composée de data\r\nscientists, d\'experts NLP et web sémantique, de data architectes, data\r\ningénieurs, d\'un web analyste et d\'une référente qualité. Vous pourrez\r\nvous appuyer sur nos connaissances du domaine du recrutement issues de\r\n19 ans d\'activité de l\'entreprise. Vos travaux seront appliqués à nos\r\nflux d\'offres grandissants et auront un vrai impact business. En\r\nfonction de la durée du stage et de votre avancement, vous pourrez aussi\r\nêtre amené à mesurer l\'impact de vos travaux sur la mise en ligne\r\nautomatique des offres et sur notre système de recommandation.\r\n\r\n\r\n\r\nProfil recherché\r\n\r\n  * Etudiant en M2 en Traitement Automatique des Langues ou en Data\r\n    Science avec un intérêt pour des technologies type NLP / Text\r\n    Analytics\r\n\r\n  * Vous souhaitez compléter votre formation par un stage résolument\r\n    tourné vers l\'opérationnel\r\n\r\n  * Maîtrise du langage de programmation Python\r\n\r\n  * Connaissances en Machine Learning appréciées\r\n\r\n\r\nCe poste est basé à Rennes au sein de notre siège social.\r\n\r\nStage de 4 à 6 mois.\r\n\r\n\r\nContact\r\n\r\nCécile Bagot (cbagot@hellowork.com)'),
(588, '2019-11-13', 'LIMSI', 'Orsay', 'Stage M2 : *Identifier des phrases identiques et similaires en corpus *\r\n*clinique*.\r\n\r\n[Identifying identical and similar sentences in clinical corpus]\r\nMots-clés : traitement automatique de la langue, similarité, domaine\r\nbiomédical\r\n\r\n*Durée* : 5 mois\r\n*Niveau* : Master 2 (professionnel ou recherche), fin d\'école d\'ingénieur\r\n*Rémunération* : Indemnité de stage, soit ~ 600 ¤/mois, indemnité de\r\ntransport incluse\r\n\r\nContexte\r\n\r\n 1. L\'apprentissage automatique est un levier important des technologies\r\n    du langage. Il repose sur la disponibilité de corpus annotés pour\r\n    définir des méthodes, entraîner des modèles et évaluer des\r\n    algorithmes. Ces données doivent être représentatives de différents\r\n    phénomènes linguistiques (formulations syntaxiques, distribution\r\n    statistique de l\'emploi de termes spécifiques, erreurs humaines\r\n    telles que les fautes d\'orthographe, etc.)  afin de garantir la\r\n    robustesse des méthodes et outils développés. Par ailleurs, les\r\n    données doivent également être partageables afin de garantir la\r\n    transparence et la reproductibilité des expériences.\r\n\r\n 2. Dans le domaine biomédical, le secret médical et la préservation de\r\n    la confidentialité s\'accompagnent d\'un cadre réglementaire qui\r\n    restreint l\'accès aux données textuelles telles que les\r\n    comptes-rendus hospitaliers dans un objectif de recherche en\r\n    traitement automatique de la langue. Le partage des documents\r\n    cliniques n\'est possible qu\'après *anonymisation*, c\'est à dire un\r\n    traitement des textes qui garantisse scientifiquement\r\n    l\'impossibilité de savoir que des informations concernant un\r\n    individu donné sont présentes dans les textes, de ré-identifier tout\r\n    individu concerné par les textes, ou de faire des inférences sur les\r\n    informations concernant ces individus.\r\n\r\nObjectifs du stage\r\n\r\nL\'objectif de ce projet est d\'analyser un corpus de do*cuments cliniques\r\ndu point de vue de la similarité entre énoncés*. Ce travail permettra\r\nd\'identifier dans un corpus clinique les phrases les plus similaires à\r\nune phrase source, afin de mettre en oeuvre le principe de k-anonymat\r\npour identifier des phrases cliniques - réelles ou synthétiques -\r\npropice au partage dans le respect de la confidentialité.  Approche\r\nproposée\r\n\r\nNous nous intéressons ici à la constitution d\'un corpus de phrases\r\nredondantes. L\'approche suivie par Li et al. (2015) consiste à filtrer\r\nles phrases par fréquence et à conserver les phrases qui reviennent à\r\nl\'identique dans les compte-rendu de différents patients. Si cette\r\napproche permet d\'éliminer les phrases de faible fréquence contenant\r\npotentiellement des données identifiantes, elle élimine également les\r\nphrases contenant des données cliniques (résultats de laboratoire) alors\r\nque nous souhaitons disposer d\'outils du TAL capables de les traiter. La\r\nsolution que nous envisageons vise à produire des données fictives mais\r\nnéanmoins réalistes sur les plans cliniques (permettant une association\r\nentre plusieurs données cliniques telles que descriptions et résultats\r\nde laboratoire) et linguistiques en identifiant en plus des phrases\r\nstrictement identiques des groupes de phrases similaires qui pourraient\r\ndonner lieu à la production de phrases anonymes et réalistes en générant\r\nune nouvelle variante non rencontrée en corpus. A partir d\'une phrase\r\nsynthétique (générée), l\'examen des phrases réelles les plus similaires\r\npermettra de sélectionner des phrases conformes au principe de\r\nk-anonymat (Sweeny, 2002).\r\n\r\nDans ce contexte, nous prévoyons de confier au stagiaire de M2 une étude\r\nexploratoire permettant d\'implémenter plusieurs méthodes de calcul de\r\nsimilarité entre énoncés (phrases) et d\'analyser la prévalence de\r\ndifférents types de similarité au sein de deux corpus clinique en\r\nfrançais : un corpus réel (LERUDI) et un corpus synthétique, issu de la\r\ntraduction de documents américain (MIMIC).\r\n\r\n\r\nProgramme de Travail :\r\n\r\n - Identifier les phrases redondantes dans un corpus\r\n - Prendre en charge le découpage en phrase du corpus, l\'identification\r\n   de phrases identiques\r\n - Identifier des phrases similaires dans un corpus\r\n - Etudier différents types de « similarités » : distance de\r\n   Levenshtein, similarité Dice ou cosine, homologie à l\'aide d\'outils\r\n   fournis (module Text::Similarity dans PERL, BLAST, ...)\r\n - Si l\'avancement du travail le permet, proposer une visualisation des\r\n   résultats\r\n\r\nRéférences\r\n\r\nSweeney, L. (2002). k-anonymity : A model for protecting privacy.\r\nInternational Journal of Uncertainty, Fuzziness and Knowledge-Based\r\nSystems, 10(05) :557-570.\r\n\r\nLi, Dingcheng & Rastegar-Mojarad, Majid & Li, Yanpeng & Sohn, Sunghwan &\r\nMehrabi, Saeed & Elayavilli, Ravikumar & Yu, Yue & Liu, Hongfang & Wang,\r\nYanshan. (2015). A Frequency-based Strategy of Obtaining Sentences from\r\nClinical Data Repository for Crowdsourcing. Studies in health technology\r\nand informatics. 216. 1033-4.\r\n\r\n\r\nCompétences souhaitées:\r\n\r\nLe stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue et/ou en\r\napprentissage automatique seront un plus. Le contenu et l\'ambition du\r\nstage pourront être modulés en fonction du niveau d\'étude et de la durée\r\ndu stage du candidat.\r\n\r\nPour candidater :\r\n\r\nEnvoyer un CV, un relevé de notes récent ainsi que les coordonnées (nom,\r\nmail) d\'au moins deux référents (professeurs ou encadrants de précédents\r\nstages ou emplois pouvant attester de vos compétences) à\r\nCyril.Grouin[at] limsi.fr et Aurelie.Neveol[at]limsi.fr'),
(589, '2019-11-13', 'IRIT', 'Toulouse', 'Proposition d\'un stage niveau Master 2:\r\nExplication de modèles en Traitement Automatique des Langues par\r\nextraction d\'arguments\r\nNatural Language Processing model explanation by argument extraction.\r\n\r\n\r\nContexte: Ce stage aura lieu dans le cadre du projet 3IA toulousain\r\nANITI, au sein de la chaire de Leila Amgoud \"Empowering Data-driven AI\r\nby Argumentation and Persuasion\", à l\'IRIT.\r\n\r\nLe succès croissant des modèles d\'apprentissage neuronal en Traitement\r\nAutomatique des Langues (TAL/NLP) soulève des questions cruciales sur la\r\nconfiance que l\'on peut accorder à des \"boites noires\" dont les\r\ndécisions sont difficiles à diagnostiquer. Une approche courante en\r\napprentissage automatique est de chercher à repérer quels éléments de\r\nl\'entrée (des pixels d\'une image, des mots d\'un texte) ont influencé le\r\nmodèle appris ou ses prédictions.\r\n\r\nCes approches sont en général peu structurées et ne fournissent pas une\r\nexplication cohérente reliant les éléments importants de la décision\r\n(Belinkov & Glass, 2019).\r\n\r\nEn traitement automatique des langues, ou l\'entrée est un texte, isoler\r\ndes éléments pertinents est déjà une base compréhensible par l\'humain\r\n(Lei et al., 2016; Bastings et al., 2019), mais une explication\r\nconvaincante demanderait à relier ces éléments pour expliciter leur rôle\r\ndans la décision, que ce soit pour supporter un choix ou pour ignorer un\r\nautre, en d\'autre terme développer une argumentation de la décision.\r\n\r\nCe stage a pour but d\'enrichir les approches par extraction d\'arguments\r\nde la décision en fournissant des argumentations structurées, en\r\ncombinant les méthodes de repérage de \"bons\" arguments et les méthodes\r\npermettant d\'induire automatiquement des liens pertinents entre éléments\r\ntextuels (Liu & Lapata, 2018).\r\n\r\n\r\nEncadrement: Philippe Muller, Leila Amgoud, Emiliano Lorini\r\nContact: philippe.muller@irit.fr\r\n\r\n\r\n- Compétences attendues:\r\nMaster 2 en mathématique ou informatique en cours, connaissances en\r\napprentissage automatique. Des connaissances en TAL seraient un plus,\r\nmais ne sont pas un prérequis.\r\n\r\n- Compétences développées pendant le stage: TAL, Deep learning,\r\n  argumentation, IA explicable.\r\n\r\n- Durée: 5 ou 6 mois\r\n- Gratification au taux légal\r\n\r\n\r\nRéférences\r\n\r\n- Joost Bastings, Wilker Aziz, Ivan Titov: Interpretable Neural\r\n  Predictions with Differentiable Binary Variables.  ACL (1) 2019:\r\n\r\n- Yonatan Belinkov, James R. Glass: Analysis Methods in Neural Language\r\n  Processing: A Survey. TACL 7: 49-72 (2019)\r\n\r\n- Tao Lei, Regina Barzilay, Tommi S. Jaakkola: Rationalizing Neural\r\n  Predictions. EMNLP 2016: 107-117\r\n\r\n- Tim Miller: Explanation in artificial intelligence: Insights from the\r\n  social sciences. Artif. Intell. 267: 1-38 (2019)\r\n\r\n- Yang Liu, Mirella Lapata: Learning Structured Text\r\n  Representations. TACL 6: 63-75 (2018)\r\n\r\n- Julia Strout, Ye Zhang, Raymond J. Mooney: Do Human Rationales Improve\r\n  Machine Explanations?  Proceedings of the Second BlackboxNLP Workshop\r\n  on Analyzing and Interpreting Neural Networks for NLP, (2019)'),
(590, '2019-11-22', 'CIRAD', 'Montpellier', 'Stage Master 2\r\n\r\nIntégration d\'informations sémantiques pour identifier les variables\r\nessentielles à partir de données textuelles hétérogènes : application à la\r\nMalherbologie\r\n\r\nDurée : 5 à 6 mois à partir de février 2020\r\n\r\nEncadrement : Sandrine Auzoux (AIDA) et Mathieu Roche (TETIS)\r\n\r\nContact : sandrine.auzoux@cirad.fr et mathieu.roche@cirad\r\n\r\nDescription :\r\n\r\nLes adventices (mauvaises herbes) sont une contrainte majeure de la\r\nproduction agricole tropicale, induisant des pertes de récoltes de 30\r\nà 80%. Le calage des pratiques de désherbage dans les itinéraires\r\ntechniques nécessite une bonne connaissance de leur comportement. Le\r\ndéveloppement de l\'agroécologie en région tropicale nous amène à\r\nconsidérer les dimensions négatives et positives des adventices.\r\n\r\nLe travail proposé dans le cadre de ce stage au Cirad (TETIS/AIDA)\r\nconsiste à proposer et mettre en oeuvre une méthode automatique\r\nd\'identification de variables essentielles pour la gestion des\r\nadventices qui implique la mise en place de nouvelles pratiques\r\nagricoles et la mobilisation de la biodiversité. Nous définissons les\r\nvariables essentielles comme une combinaison d\'éléments\r\ncaractéristiques, par exemple le climat, le milieu, la localisation et\r\nle nom vernaculaire.\r\n\r\nLe but du stage est d\'identifier, par des méthodes de fouille de\r\ntextes, les variables essentielles de manière automatique à partir de\r\ndonnées textuelles. Dans l\'extrait ci- dessous, les variables\r\nessentielles du pissenlit à extraire sont par exemple une combinaison\r\nde climat tempéré, milieux humides et échelle mondiale.\r\n---\r\nFaire connaissance avec le Pissenlit et ses bienfaits.\r\nL\'herbacée, Taraxucum officinale, connue sous le nom de pissenlit,\r\nelle est une plante originaire d\'Europe de l\'Ouest. Le pissenlit pousse\r\nà l\'état sauvage dans les climats tempérés et milieux humides de toutes\r\nles régions du monde, pouvant vivre jusqu\'à 2 000 mètres d\'altitude.\r\n---\r\n\r\nDans le processus de fouille de textes à mettre en place, deux verrous\r\nscientifiques seront particulièrement étudiés :\r\n\r\n- Adapter les méthodes de fouille de textes aux différents types de\r\ndonnées mobilisées (scientifique vs. grand public).\r\n\r\n- Intégrer des ressources sémantiques et scientifiques (par exemple,\r\nthésaurus) au processus proposé.\r\n\r\nDans ce cadre, le processus reposera sur 3 grandes étapes qui seront\r\nmises en place et évaluées avec des experts du domaine :\r\n\r\n1) Acquisition de données textuelles en anglais par des méthodes\r\nsemi-automatiques (web crawling / web scraping). Deux types de\r\ndocuments seront étudiés : (1) des documents « grand public » issus du\r\nweb (blogs, sites touristiques, presse) et ( 2) des publications\r\nscientifiques (articles scientifiques).\r\n\r\n2) Extraction de variables essentielles dans ces données par des\r\nméthodes adaptées au domaine de la Malherbologie. Ces méthodes\r\ns\'appuieront sur l\'intégration de connaissances sémantiques notamment\r\nspatiales (par exemple, Geonames, OpenStreetMap, etc.) et thématiques\r\n(par exemple, Agrovoc, dictionnaire des plantes, etc.)\r\n\r\n3) Evaluation de ces informations dans un cadre pluridisciplinaire et\r\nmise en lien avec des bases de données de référence.\r\n\r\nLieu et gratification :\r\n\r\nCe stage basé au Cirad à Montpellier (https://www.cirad.fr/) bénéficie\r\nd\'une gratification mensuelle de 580 euros .\r\n\r\nProfil : Master 2 ou École d\'Ingénieur en Informatique / Science des Données'),
(591, '2019-11-22', 'CIRAD', 'Montpellier', 'Stage Master 2\r\n\r\nBiodiversité et pratique de recherche : extraction automatique de mots-\r\nclés caractérisant les thématiques saillantes issues de données\r\ntextuelles\r\n\r\nDurée : 5 à 6 mois à partir de février 2020\r\n\r\nEncadrement : Mathieu Roche (TETIS) et Christian Leclerc (AGAP)\r\n\r\nContact : mathieu.roche@cirad et christian.leclerc@cirad.fr\r\n\r\nDescription :\r\n\r\nDe nombreux travaux de fouille de textes permettent (i) de faire\r\némerger les descripteurs linguistiques les plus significatifs (mots,\r\nsyntagmes) à partir d\'un corpus puis (ii) de les regrouper. Ceci\r\npermet de mettre en relief, de manière automatique, les thématiques\r\nabordées dans les textes facilitant l\'organisation et l\'indexation des\r\ndocuments, la recherche d\'information, la compréhension et l\'analyse\r\ndes textes. Il permet aussi de comparer, pour une période donnée, les\r\napproches privilégiées par différentes unités de recherche, ou encore\r\nde décrire l\'évolution de ces approches au cours du temps. Cette\r\nanalyse portera sur Biodiversité et pratique de recherche au Cirad,\r\navec l\'objectif d\'appliquer la méthode à d\'autres thématiques,\r\nnotamment le territoire et la mobilité.\r\n\r\nLa réalisation du premier point (identification des descripteurs\r\nlinguistiques significatifs) s\'appuie, en grande partie, sur\r\nl\'utilisation de méthodes d\'extraction de la terminologie à partir de\r\ntextes, en combinant méthodes linguistiques et statistiques pour\r\nconstituer une liste de descripteurs linguistiques. La deuxième étape\r\ndu processus consiste à utiliser ces descripteurs afin de mettre en\r\nlumière les différentes thématiques abordées dans les textes. Pour\r\ndécouvrir des structures thématiques \"cachées\" dans les corpus de\r\ntextes, les méthodes appelées \"topic models\" seront utilisées,\r\nnotamment, le modèle probabiliste génératif LDA, i.e. Latent Dirichlet\r\nAllocation.\r\n\r\nDans ce contexte, les objectifs du stage sont déclinés selon 4\r\nsous-tâches :\r\n\r\n(1) Intégrer des outils de la littérature d\'extraction de la\r\nterminologie (en particulier BioTex -\r\nhttp://tubo.lirmm.fr:8080/biotex) et des approches LDA dans le cadre\r\ndu développement d\'un système générique et utilisable par des non\r\ninformaticiens.\r\n\r\n(2) Intégrer et combiner des ressources sémantiques (vocabulaire\r\ncontrôlé) fournies par les utilisateurs aux méthodes d\'extraction de\r\nla terminologie.\r\n\r\n(3) Étudier la valeur structurante des termes rares (queue de\r\ndistribution) associées aux fonctions de rangs propres aux systèmes\r\nd\'extraction de la terminologie. De nouvelles fonctions de rangs\r\npourront alors être proposées, pour mettre en valeur les termes rares\r\net pertinents.\r\n\r\nLieu et gratification :\r\n\r\nCe stage basé au Cirad à Montpellier (https://www.cirad.fr/) bénéficie d\'une\r\ngratification mensuelle de 580 euros.\r\n\r\nProfil :\r\nMaster 2 ou École d\'Ingénieur en Informatique / Science des Données');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(592, '2019-11-22', 'Bertin IT', 'Montpellier', 'Durée, démarrage\r\nD\'une durée de 6 mois, le stage se déroulera dans les locaux du centre\r\nR&D à Montpellier.\r\nDémarrage dès que possible.\r\n\r\nPrésentation de l\'entreprise\r\nSociété du Groupe CNIM, Bertin IT est un éditeur et intégrateur de\r\nsolutions logicielles pour la cyber sécurité, la cyber-intelligence, la\r\nveille stratégique et le traitement automatique de la parole. Sa marque\r\nAMI, leader dans l\'édition de logiciels d\'acquisition, de gestion et de\r\ntraitement de l\'information texte issue du Web, offre des solutions de\r\nveille stratégique et d\'intelligence compétitive. En particulier, notre\r\nsolution, AMI Enterprise Intelligence, permet aux entreprises\r\nd\'exploiter le Big Data afin d\'anticiper les évolutions de leur\r\nenvironnement concurrentiel et technologique et d\'identifier de\r\nnouvelles perspectives de développement.\r\n\r\nDescription du stage\r\nDans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),\r\nnous proposons des outils avancés d\'analyse de texte en vue de faciliter\r\naux veilleurs et analystes l\'exploitation et la navigation dans\r\nl\'importante masse de documents collectés à l\'issue du processus de\r\nveille. Divers traitements sont proposés tels que l\'extraction des\r\nprincipales thématiques, l\'identification des entités nommées ainsi que\r\nles concepts clés apparaissant dans les documents.\r\n\r\nVotre mission principale sera de développer un module d\'extraction\r\nd\'événements de type « rachat d\'entreprise ». Ce choix découle de\r\nl\'intérêt de nos clients d\'étudier la présence d\'un tel événement dans\r\ndifférents médias afin d\'avoir une vision générale de leur marché et de\r\nmaintenir automatiquement à jours leur base de connaissance sur les\r\ndifférents acteurs de ce marché.\r\n\r\nCe module d\'extraction se basera sur un corpus de textes issus de\r\ndifférents médias référents à la notion de rachat (à construire), sur\r\nl\'utilisation de FrameNet pour la définition des arguments de\r\nl\'événement «rachat» dans les médias analysés, et une approche hybride\r\npour l\'extraction des événements. Cette approches hybride consistera à\r\nvoir quel serait le meilleur algorithme d\'apprentissage pouvant prendre\r\nen compte les relations de dépendances syntaxiques existant entre les\r\ndifférents arguments d\'un événement. La langue cible est l\'anglais.\r\n\r\n\r\nMots clés : TALN, Deep learning, Réseaux de neurones, Extraction\r\nd\'événement, rôles thématiques, extraction d\'informations\r\n\r\nProfil souhaité\r\nVous êtes actuellement en dernière année d\'école d\'Ingénieur (ou cursus\r\nuniversitaire en mathématiques appliquées, statistiques ou data science,\r\nlinguistique informatique). Vous avez une appétence pour le traitement\r\ndu langage naturel et les méthodes d\'apprentissage. Une bonne\r\nconnaissance d\'au moins un langage de script tel que R, Python ou autre\r\nest indispensable ainsi qu\'une bonne connaissance d\'outils de NLP tel\r\nque Standford parser et librairie de deep learning telle que Torch ou\r\nTensorflow. Vous êtes également reconnu(e) pour votre rigueur et votre\r\ndynamisme.\r\n\r\nVous êtes enthousiaste à l\'idée de contribuer au développement de notre\r\nactivité, rejoignez-nous !\r\nSi vous êtes intéressé(e) merci d\'envoyer votre Cv et lettre de\r\nmotivation à : sabrina.pagel@bertin.fr et frederique.segond@bertin.fr'),
(593, '2019-11-22', 'Bertin IT', 'Montpellier', 'Durée, démarrage\r\nD\'une durée de 6 mois, le stage se déroulera dans les locaux du centre\r\nR&D à Montpellier.\r\nDémarrage dès que possible.\r\n\r\nPrésentation de l\'entreprise\r\nSociété du Groupe CNIM, Bertin IT est un éditeur et intégrateur de\r\nsolutions logicielles pour la cyber sécurité, la cyber-intelligence, la\r\nveille stratégique et le traitement automatique de la parole. Sa marque\r\nAMI, leader dans l\'édition de logiciels d\'acquisition, de gestion et de\r\ntraitement de l\'information texte issue du Web, offre des solutions de\r\nveille stratégique et d\'intelligence compétitive. En particulier, notre\r\nsolution, AMI Enterprise Intelligence, permet aux entreprises\r\nd\'exploiter le Big Data afin d\'anticiper les évolutions de leur\r\nenvironnement concurrentiel et technologique et d\'identifier de\r\nnouvelles perspectives de développement.\r\n\r\nDescription du stage\r\nDans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),\r\nnous proposons des outils avancés d\'analyse de texte en vue de faciliter\r\naux veilleurs et analystes l\'exploitation et la navigation dans\r\nl\'importante masse de documents collectés à l\'issue du processus de\r\nveille. Divers traitements sont proposés tels que l\'extraction des\r\nprincipales thématiques, l\'identification des entités nommées ainsi que\r\nles concepts clés apparaissant dans les documents.\r\n\r\nVotre mission principale sera d\'étudier la mise en oeuvre d\'un outil\r\npermettant de déterminer, de façon la plus fiable possible, les\r\ndocuments les plus pertinents correspondant à des requêtes utilisateurs,\r\nen utilisant les techniques de l\'apprentissage (Machine Learning).\r\nLe projet de stage se composera :\r\n- D\'une phase d\'étude (identification d\'algorithme de machine learning,\r\n  benchmarks, réglages, tests)\r\n- D\'une phase d\'implémentation logicielle (module d\'apprentissage,\r\n  modélisation, corpus, évaluation)\r\n\r\nEncadré(e) par les responsables du projet, vous travaillerez en\r\ncollaboration avec les chercheurs et l\'équipe d\'ingénieurs. Votre\r\nrigueur, votre curiosité et votre prise d\'initiative vous permettra de\r\nmener à bien le stage.\r\n\r\nMots clés : TALN, Deep learning, Réseaux de neurones, Recherche\r\nd\'informations\r\n\r\nProfil souhaité\r\nVous êtes actuellement en dernière année d\'école d\'Ingénieur (ou cursus\r\nuniversitaire équivalent), vous disposez idéalement d\'une première\r\nexpérience (stage inclus) réussie dans un domaine similaire. Vous\r\ndisposez d\'une bonne connaissance des algorithmes et des bibliothèques\r\nd\'algorithmes de Machine Learning et Deep Learning, des systèmes de\r\nrecherche d\'information et des langages C++ et/ou Java.\r\nLa connaissance de Python est un plus.\r\n\r\n\r\nVous êtes enthousiaste à l\'idée de contribuer au développement de notre\r\nactivité, rejoignez-nous !\r\n\r\nSi vous êtes intéréssé(e) merci d\'envoyer votre Cv et lettre de\r\nmotivation à : sabrina.pagel@bertin.fr et frederique.segond@bertin.fr'),
(594, '2019-11-29', 'ICVL', 'Blois', '======= Offre de stage de 5 mois, ICVL (Fédération informatique de la\r\n        région Centre-Val de Loire): apprentissage à partir d\'un système\r\n        symbolique ==========\r\n\r\n\r\n****Description**** \r\nL\'ICVL propose un stage de 5 mois sur l\'apprentissage à partir d\'un\r\nsystème symbolique. Aujourd\'hui la plupart des systèmes de Tal utilisent\r\nde l\'apprentissage. Mais la construction de corpus annotés présente un\r\nréel coût qui freine le développement de ces méthodes lorsque de tels\r\ncorpus ne sont pas disponibles (langues sous-dotées ou sujets peu\r\ncommuns). Le stage propose l\'étude d\'une hybridation entre un système\r\nsymbolique et un système d\'apprentissage. Le système symbolique sera\r\nutilisé pour constituer un corpus annoté sur lequel sera fait\r\nl\'apprentissage. Celui-ci pourrait disposer, en plus des annotations\r\nfournies, de toutes autres sources d\'informations disponibles librement\r\n: étiqueteur probabiliste, plongements de mots, etc.\r\n\r\nLa question se pose alors de l\'intérêt de cette hybridation entre les\r\ndeux systèmes. Est-ce que le système apprenant fera mieux au final que\r\nle système ayant servi à l\'apprentissage?\r\n\r\nUne description plus précise est disponible sur le site TLN\r\n(tln.lifat.univ-tours.fr).\r\n\r\n\r\n****Profil recherché**** \r\nIdéalement, la personne recrutée intégrera ce stage dans un cursus de\r\nmaster (soit finalisation en M2, soit stage de M1) et disposera de\r\nconnaissances théoriques et pratiques sur les techniques\r\nd\'apprentissage, telles que les CRF ou les réseaux neuronaux. Un intérêt\r\npour la langue et son traitement automatique serait apprécié, sans être\r\nun pré-requis au recrutement.\r\nCependant, ce stage est également proposé à des étudiants en fin d\'étude\r\nde Licence (L3) qui disposeraient d\'un excellent niveau académique\r\n(mention B en licence au minimum) et désireraient découvrir les\r\nproblématiques du Tal et de l\'apprentissage automatique.\r\n\r\n\r\n****Localisation**** \r\nLe stage, piloté par des chercheurs de l\'ICVL, pourra se dérouler au\r\nchoix de l\'étudiant, sur les sites de Blois ou de Tours du Lifat\r\n(laboratoire d\'informatique fondamentale et appliquée de l\'université de\r\nTours) ou sur le site d\'Orléans du Lifo (laboratoire d\'informatique\r\nfondamentale de l\'université d\'Orléans).\r\n\r\n\r\n****Gratification et durée**** \r\nGratification légale, à savoir 15% du plafond de la sécurité sociale.\r\nCinq mois de stage de préférence (22 semaines), à partir de janvier 2020\r\nau plus tôt.\r\n\r\n\r\n****Date limite de candidature**** \r\n18 décembre 2019 \r\n\r\n\r\n****Procédure de candidature**** \r\n\r\nMerci de joindre une lettre de motivation et un CV avec un contact\r\nacadémique et, éventuellement, une lettre de recommandation.\r\n\r\nContacts : Denis Maurel (Tours-Lifat), Nathalie Friburger et Nicolas\r\nLabroche (Blois-Lifat), Matthieu Exbrayat (Orléans-Lifo):\r\ndenis.maurel@univ-tours.fr, nathalie.friburger@univ-tours.fr,\r\nnicolas.labroche@univ-tours.fr, matthieu.exbrayat@univ-orleans.fr'),
(595, '2019-11-29', 'LIG', 'Grenoble', 'The LIG (Laboratoire d\'Informatique de Grenoble) laboratory proposes the\r\nfollowing M2 stage (research)\r\n\r\nTitle:\r\nAutomatic Coreference Extraction\r\n\r\nDescription:\r\nCoreference Resolution is one of the most challenging tasks in Natural\r\nLanguage Processing (NLP) [Ng 2010], [Godbert and Benoit 2017], [Lee et\r\nal. 2017].  Recent advances in neural model architectures allowed for\r\nimpressive improvements in this domain [Wiseman et al. 2016], [Lee et\r\nal. 2017, 2018]. Traditionally however, coreference resolution tasks are\r\nbased on previously, manually annotated corpora [Pradhan et al. 2012],\r\n[D esoyer et al. 2016]. Such resources are relatively rare, and very\r\nexpensive to obtain from scratch. Recent neural translation models\r\nproved to be very e ffective in capturing long range contexts [Vaswani\r\net al. 2017], [Voita et al. 2018], [Maruf and Ha ari 2017], [Bawden et\r\nal. 2017], [Zhang et al. 2018], [Miculicich et al. 2018]. In particular\r\n[Voita et al. 2018] showed that document-level neural translation models\r\ncapture to some extent coreference (at least anaphora) phenomena. We\r\nwant to exploit this feature of neural translation models to\r\nautomatically extract coreference phenomena from text. The automatically\r\nextracted annotations will be used for data augmentation for coreference\r\nresolution neural models [Vaswani et al.  2017] in order to study their\r\nimpact on quantitative evaluations.\r\n\r\nIn this internship the student will use and modify existing systems\r\n[Voita et al.  2018], [Lee et al. 2017] in order to automatically\r\nextract coreference phenomena from textual data. The latter will be used\r\nto augment existing data [Pradhan et al. 2012] for training a\r\ncoreference resolution neural model and study the impact of\r\nautomatically created data on its performance.\r\n\r\nProfi le:\r\n\r\n- Student for internship level (Master 2) in computer science, or from\r\n  engineering school\r\n- Computer science skills:\r\n  * Python programming with good knowledge of deep learning libraries\r\n    (Pytorch)\r\n  * Data manipulation (textual data): loading di fferent formats, format\r\n    transformation, storing in smart data structures, writing on disk in\r\n    different format, etc.\r\n- Interested in Natural Language Processing\r\n- Skills in machine learning for probabilistic models\r\n\r\nThe internship may last from 4 up to 6 months, it will take place at LIG\r\nlaboratory, GETALP team (http://lig-getalp.imag.fr/), starting from\r\nJanuary/ February 2020. The student will be tutored by Marco Dinarelli\r\n(http:// www.marcodinarelli.it), and Laurent Besacier\r\n(https://cv.archives-ouvertes.  fr/laurent-besacier).\r\n\r\nInterested candidates must send a CV and a motivation letter to\r\nmarco.dinarelli@univ-grenoble-alpes.fr, and\r\nlaurent.besacier@univ-grenoble-alpes.fr.\r\n\r\nREFERENCES\r\n\r\nRachel Bawden, Rico Sennrich, Alexandra Birch, and Barry Haddow.\r\nEvaluating discourse phenomena in neural machine translation. CoRR,\r\nabs/1711.00513, 2017. URL http://arxiv.org/abs/1711.00513.\r\n\r\nAd ele D esoyer, Fr ed eric Landragin, Isabelle Tellier, Ana s Lefeuvre,\r\nJean-Yves Antoine, and Marco Dinarelli. Coreference resolution for\r\nfrench oral data: Machine learning experiments with ancor. In\r\nProceedings of the 17th In- ternational Conference on Computational\r\nLinguistics and Intelligent Text Processing, Konya, Turkey, April\r\n2016. Lecture Notes in Computer Science (Springer).\r\n\r\nElisabeth Godbert and Favre Benoit. D etection de cor ef erences de bout\r\nen bout en fran cais. In TALN 2017, Orl eans, France, June 2017. URL\r\nhttps: //hal.archives-ouvertes.fr/hal-01687116.\r\n\r\nKenton Lee, Luheng He, Mike Lewis, and Luke Zettlemoyer. End-to-end\r\nneural coreference resolution. In Proceedings of EMNLP. Association for\r\nComputational Linguistics, 2017. URL\r\nhttp://aclweb.org/anthology/D17-1018.\r\n\r\nKenton Lee, Luheng He, and Luke Zettlemoyer. Higher-order coreference\r\nresolution with coarse-to- ne inference. CoRR, abs/1804.05392, 2018. URL\r\nhttp://arxiv.org/abs/1804.05392.\r\n\r\nSameen Maruf and Gholamreza Ha ari. Document context neural machine\r\ntranslation with memory networks. CoRR, abs/1711.03688, 2017. URL\r\nhttp://arxiv.org/abs/1711.03688.\r\n\r\nLesly Miculicich, Dhananjay Ram, Nikolaos Pappas, and James Henderson.\r\nDocument-level neural machine translation with hierarchical attention\r\nnetworks.  CoRR, abs/1809.01576, 2018. URL http://arxiv.org/abs/1809.\r\n01576.\r\n\r\nVincent Ng. Supervised noun phrase coreference research: The rst fteen\r\nyears. In Proceedings of the 48th Annual Meeting of the Association for\r\nCom- putational Linguistics, ACL \'10, pages 1396{1411, Stroudsburg, PA,\r\nUSA, 2010. Association for Computational Linguistics. URL\r\nhttp://dl.acm.org/ citation.cfm?id=1858681.1858823.\n\n\r\nSameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and\r\nYuchen Zhang. Conll-2012 shared task: Modeling multilingual unrestricted\r\ncoreference in ontonotes. In Joint Conference on EMNLP and CoNLL -\r\nShared Task, CoNLL \'12, pages 1{40, Stroudsburg, PA, USA,\r\n2012. Association for Computational Linguistics. URL\r\nhttp://dl.acm.org/citation.  cfm?id=2391181.2391183.\r\n\r\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,\r\nAidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all\r\nyou need. In Proceedings of NIPS, 2017. URL https://arxiv.org/pdf/1706.\r\n03762.pdf.\r\n\r\nElena Voita, Pavel Serdyukov, Rico Sennrich, and Ivan\r\nTitov. Contextaware neural machine translation learns anaphora\r\nresolution. CoRR, abs/1805.10163, 2018. URL\r\nhttp://arxiv.org/abs/1805.10163.\r\n\r\nSam Wiseman, Alexander M. Rush, and Stuart M. Shieber. Learning global\r\nfeatures for coreference resolution. CoRR, abs/1604.03035, 2016. URL\r\nhttp: //arxiv.org/abs/1604.03035.\r\n\r\nJiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai, Jingfang Xu, Min\r\nZhang, and Yang Liu. Improving the transformer translation model with\r\ndocument-level context. CoRR, abs/1810.03581, 2018. URL http://arxiv.\r\norg/abs/1810.03581.'),
(596, '2019-12-09', 'LIMSI', 'Orsay', '- Title: Research internship in NLP and ML: Text generation with\r\n  disentangled semantic and syntactic representations\r\n- Duration: 5-6 months, during the year 2020\r\n- Location: LIMSI, Orsay (south of Paris)\r\n- Supervisor: Caio Corro http://caio-corro.fr/\r\n- Team: Spoken Language Processing / Traitement Automatique de la Parole\r\n- Contact: caio.corro@limsi.fr\r\n\r\n*Context*\r\n\r\nThis internship will focus on text generation with deep generative\r\nmodels, in particular Variational Auto-Encoders (VAEs) [1,2]. The goal\r\nis to study how we can build a generative model for text generation\r\nwhere the semantic and syntactic representations are disentangled [3].\r\nThat is, we aim to generate a sentence through the following process:\r\n\r\n- sample z: a latent variable encoding a meaning,\r\n- sample z\': a latent variable encoding a surface structure (i.e. how\r\n  the meaning is expressed),\r\n- sample x from p(x | z, z\'): a sentence conditioned on its meaning\r\n  and syntactic structure.\r\n\r\nThis kind of models could be used for sentence simplification,\r\nparaphrasing or generating diverse text responses [4,5]. Previous work\r\nin the literature has explored models where z\' is encoded as a discrete\r\ncombinatorial structure [6,7]. However, these methods require annotation\r\nof linguistic structures to be available during training and they may\r\nnot be suitable for large scale learning as they are computationally\r\nexpensive.\r\n\r\nTherefore, we aim to focus on techniques closer to the ones developed in\r\ncomputer vision where both the semantic and syntactic representations\r\nare encoded in a fixed size continuous latent space and learned in a\r\nfully unsupervised setting. To this end, the successful candidate will\r\nexplore generative losses for disentangled representation learning and\r\npropose neural architectures specifically developed for text generation\r\nin this setting.\r\n\r\n*Missions*\r\n\r\n- review the literature on learning disentangled latent space with VAEs;\r\n- reproduce the experiments from [3,8] with a transformer architecture\r\n  instead of recurrent networks;\r\n- explore VAE losses for learning disantangled representations;\r\n- propose transformer architectures that isolates structural information\r\n  from semantic information (e.g. distance, see Section 3 in [9])\r\n\r\n\r\n[1] \"Auto-Encoding Variational Bayes\" Diederik P Kingma and Max Welling.\r\n[2] \"Stochastic backpropagation and approximate inference in deep\r\n    generative models\" Danilo Jimenez Rezende et al.\r\n[3] \"A Multi-Task Approach for Disentangling Syntax and Semantics in\r\n    Sentence Representations\" Mingda Chen et al.\r\n[4]  \"Generating Informative and Diverse Conversational Responses via\r\n     Adversarial Information Maximization\" Yizhe Zhang et al.\r\n[5] \"Jointly Measuring Diversity and Quality in Text Generation Models\" \r\n    Danial Alihosseini et al.\r\n[6] \"StructVAE: Tree-structured Latent Variable Models for\r\n    Semi-supervised Semantic Parsing\" Pengcheng Yin et al.\r\n[7] \"Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a\r\n    Structured Variational Autoencoder\" Caio Corro and Ivan Titov\r\n[8] \"Effective Estimation of Deep Generative Language Models\" Tom\r\n    Pelsmaeker and Wilker Aziz\r\n[9] \"Constituency Parsing with a Self-Attentive Encoder\" Nikita Kitaev\r\n    and Dan Klein'),
(597, '2019-12-09', 'LIMSI', 'Orsay', '- Title: Cross-lingual transfer with multi-lingual BERT via\r\n  linguistically informed fine-tuning\r\n- Duration: 5-6 months, during the year 2020\r\n- Location: LIMSI, Orsay (south of Paris)\r\n- Supervisor: Caio Corro - http://caio-corro.fr/\r\n- Team: Spoken Language Processing / Traitement Automatique de la Parole\r\n- Contact: caio.corro@limsi.fr\r\n\r\n*Context*\r\n\r\nRecently, much attention has been paid to large scale pre-training of\r\ncontext-sensitive representations (or context-sensitive word\r\nembeddings), in particular ELMO [1] and BERT [2] models. The main idea\r\nis to pre-train the first layers of a neural network on a large amount\r\nof unlabeled data before fine-tuning the rest of the network on a\r\ndownstream task. As such, context-sensitive representations allow to\r\nlower annotation cost and improve classification performance on a wide\r\nrange of tasks.\r\n\r\nThe multilingual BERT model pre-trains context sensitive representations\r\non a collection of texts in 104 languages instead of texts in a single\r\nlanguage. One question that arises is whether we can use the\r\nmultilingual BERT model for cross-lingual learning, that is training a\r\nmodel on a subset of these languages (source languages) and testing it\r\non a different subset (target languages). This problem is both important\r\nunder a research perspective (how can we learn multi-lingual\r\nrepresentations of typologically diverse languages?) and under an\r\napplied industry perspective (i.e. increase language coverage of\r\nNLP-based products at low cost). Previous work observed that\r\ncross-lingual transfert based on multi-lingual BERT works best for\r\ntypological similar languages (i.e. languages with similar word order),\r\nwhich is expected but disappointing [3].\r\n\r\nThis internship will focus on multilingual dependency parsing with the\r\nUniversal Dependency treebank https://universaldependencies.org/ .\r\nPrevious work has considered re-ordering source language sentences with\r\nrespect to word order in target languages [4]. However, re-ordering is\r\nnot possible for unsupervised large scale pre-training where syntactic\r\nstructures is not annotated. A different line of work proposed to force\r\nword order statistics at test time using constraints [5], but this\r\nmethod is based on a costly lagrangian optimization procedure and cannot\r\nbe applied on a per sentence basis. Alternatively, we propose to explore\r\nfine-tuning methods for multi-lingual BERT model using a linguistically\r\ninformed training algorithm, i.e. to use dominant word order information\r\n(is the object placed before or after the verb in a given language?) to\r\nensure unsupervised transfer to target languages.\r\n\r\n*Missions*\r\n\r\nThe successful candidate will develop neural network architectures and\r\ntraining algorithms for cross-lingual generalization of pre-trained\r\ncontext-sensitive representations. The main evaluation task will be\r\ncross-lingual dependency parsing. As there are many ways to tackle this\r\nproblem, the specific approach will be determined by the intern\r\naspiration, which could be for example posterior regularization or\r\nlatent variable modeling. In a nutshell, the aim is to:\r\n\r\n- propose a method for cross-lingual generalization of multi-lingual\r\n  BERT using typological information;\r\n- evaluate the proposed method on cross-lingual parsing;\r\n- evaluate if results generalize to other tasks, for example\r\n  cross-lingual named entity recognition.\r\n\r\n[1] \"Deep Contextualized Word Representations\" Matthew Peters et al.\r\n[2] \"BERT: Pre-training of Deep Bidirectional Transformers for Language\r\n    Understanding\" Jacob Devlin et al.\r\n[3] \"How multilingual is Multilingual BERT?\" Telmo Pires et al.\r\n[4] \"Zero-resource Dependency Parsing: Boosting Delexicalized\r\n    Cross-lingual Transfer with Linguistic Knowledge\" Lauriane Aufrant\r\n    et al.\r\n[5] \"Target Language-Aware Constrained Inference for Cross-lingual\r\n    Dependency Parsing\" Tao Meng et al.'),
(598, '2019-12-09', 'LIA', 'Avignon', 'Analyse de graphes signés pour détecter la corruption dans les marchés publics \r\n\r\nEncadrants\r\n\r\nRosa Figueiredo <rosa.figueiredo@univ-avignon.fr>\r\nVincent Labatut <vincent.labatut@univ-avignon.fr>\r\n\r\nLieu du stage\r\n\r\nLaboratoire Informatique d\'Avignon (LIA), Avignon, France\r\n\r\nDescriptif du stage \r\n\r\nContexte \r\n\r\nL\'ouverture massive des données publiques recouvre une importance\r\nparticulière dans le cadre des marchés publics, et la récente réforme\r\nde ces marchés introduit explicitement l\'open data dans la commande\r\npublique. Ce sont donc dès aujourd\'hui une masse importante, et à\r\ncourt terme l\'intégralité des données relatives aux marchés publics\r\nqui peuvent faire l\'objet d\'analyses qui jusqu\'à présent se heurtaient\r\nà l\'inexistence ou à la partialité de jeux de données. Que ce soit par\r\nles montants en jeu (la commande publique correspond à presque 15% du\r\nPIB, 200 milliards d\'euros par an pour les seuls marchés publics), ou\r\npar les bénéfices économiques et sociétaux escomptés derrière cet\r\nimpératif de transparence, le traitement et l\'analyse de ces données\r\nconstituent un enjeu tant académique que sociétal majeur.\r\n\r\nLe travail motivant la présente offre de stage s\'insère dans les deux\r\naxes transversaux du LIA : Systèmes Complexes et Société Numérique. À\r\nl\'intersection de l\'informatique, des sciences économiques et des\r\nsciences juridiques, il fait partie de DéCoMaP (Détection de la\r\ncorruption dans les marchés publics) un projet à plus grande échelle\r\nfinancé par l\'ANR et visant à collecter, traiter et analyser les\r\ndonnées ouvertes relatives aux marchés publics français, afin\r\nd\'élaborer un outil basé sur les méthodes de graphes signés pour la\r\ndétection des risques de corruption qui peuvent exister entre\r\nacheteurs publics et entreprises. La prise en compte de la nature\r\nduale des liens unissant entreprises et donneurs d\'ordres (relation\r\ncontractuelle normale ou corruption) est fondamentale à la bonne\r\nmodélisation du système étudié, et nécessite d\'utiliser des réseaux\r\nsignés. Il s\'agit d\'un type de réseau bien moins exploré que les\r\nréseaux non-signés classiques, et permettant d\'inclure dans un même\r\nmodèle des relations antagonistes.\r\n\r\nL\'élaboration d\'outils de détection automatique des risques de\r\ncorruption dans les marchés publics (\"red flagging\") n\'est en soit pas\r\ntotalement nouvelle, et se développe depuis quelques années déjà [1],\r\nnotamment à l\'échelle européenne [2]. Outre qu\'aucun outil n\'a à ce\r\njour été adapté au cadre juridique et aux données des marchés publics\r\nfrançais, les méthodes appliquées présentent une limite\r\nimportante. Les approches existantes se focalisent sur des données\r\nindividuelles, caractérisant de façon indépendante clients et\r\nfournisseurs, et ignorent les informations relationnelles,\r\ncorrespondant aux interdépendances et interactions entre ces\r\ndifférents acteurs. De ce fait, les outils produits passent à côté\r\nd\'un certain nombre de propriétés émergentes, i.e. présentes à une\r\ngranularité plus élevée que l\'acteur isolé.\r\n\r\n\r\nTravail demandé \r\n\r\nLe travail effectué avant ce stage a permis de collecter et structurer\r\nl\'ensemble des données issues des marchés publics français, telles que\r\nproposées par le Bulletin Officiel des Annonces des Marchés Publics\r\n(BOAMP) (annonces et avis d\'attribution). Il s\'agit maintenant\r\nd\'identifier les données a priori pertinentes, et de les enrichir à\r\npartir à la fois de l\'état de l\'art académique (analyse juridique,\r\napproche économique théorique et empirique) et de l\'expertise d\'un\r\nProfesseur en économie, Pierre-Henri Morand (LBNC - AU), qui porte le\r\nprojet DéCoMaP. En fonction du déroulement du projet, il est\r\nenvisageable de compléter la BD existante en exploitant d\'autres\r\nsources de données telles que TED (l\'équivalent européen du BOAMP).\r\n\r\nLe stagiaire utilisera les graphes signés afin de modéliser,\r\nvisualiser et analyser les réseaux complexes formés par les\r\nentreprises (fournisseurs) et les collectivités (donneurs\r\nd\'ordres). Il s\'agit de graphes dont les liens sont caractérisés par\r\nun signe, pouvant être positif ou négatif, afin de représenter des\r\nrelations antagonistes. Ces graphes seront construits à partir des\r\ndonnées obtenues à la première étape. Comme illustré dans la Figure\r\nci-dessous, plusieurs méthodes sont possibles pour effectuer cette\r\nopération, que le stagiaire devra mettre en oeuvre et comparer.\r\n\r\nUne fois les graphes obtenus, ils seront principalement utilisés pour\r\ndeux tâches. La première est leur analyse via des outils descriptifs\r\nclassiques dans le champ des réseaux complexes (taille, densité,\r\ntransitivité, centralités diverses...). La seconde vise à résoudre des\r\nproblèmes de partitionnement définis sur les graphes signés en\r\nutilisant les méthodes de résolution existantes plus adaptées [3,4]\r\naux réseaux obtenus. Avec les solutions obtenues émergeront des\r\ngroupes d\'acteurs (acheteurs publics et entreprises fournisseurs)\r\nsusceptibles d\'être liés entre eux par des pratiques délictueuses.\r\n\r\n\r\n\r\nPerspectives\r\n\r\nSous réserve qu\'à la fois le stagiaire et les encadrants soient\r\nsatisfaits du déroulement du stage, celui-ci est susceptible de\r\ndéboucher sur un doctorat prévu dans le cadre du projet ANR DéCoMaP\r\ndéjà mentionné. Ce doctorat sera co-encadré par Rosa Figueiredo et\r\nVincent Labatut (LIA - AU), comme le stage, et en plus par Christine\r\nLargeron (Laboratoire Hubert Curien - Université Jean Monnet).\r\n\r\n\r\n\r\nRéférences\r\n\r\n[1] Fazekas, Mihály, et István János Tóth. New ways to measure institutionalised grand corruption in public procurement, U4 Brief, n°9 (2014).\r\n\r\n[2] Ferwerda, Joras, et Ioana Deleanu. Identifying and Reducing Corruption in Public Procurement in the EU. European Commission, OLAF, 2013.\r\n\r\n[3] Figueiredo, Rosa et Yuri Frota. The maximum balanced subgraph of a signed graph: Applications and solution approaches. European Journal of Operational Research, 236(2) : 473-487, 2014.\r\n\r\n[4] Labatut, Vincent. Generalized Measures for the Evaluation of Community Detection Methods, International Journal of Social Network Mining, n°2(2015):44-63.\r\nThématique(s) associée(s) au stage / Keywords 	Analyse de graphes signés / Signed graphs analysis'),
(599, '2019-12-09', 'Fortia Financial Solutions', 'Paris', '\"*Fortia Financial Solutions* est une RegTech créée en 2012, basée à\r\nParis.\r\n\r\nLes RegTech proposent aux acteurs financiers des solutions\r\ntechnologiques destinées à gérer leurs activités « Compliance » ou\r\nconformité, c\'est-à-dire le respect des dispositions législatives et\r\nréglementaires ainsi que des normes internes et statutaires.\r\n\r\n*Fortia Financial Solutions* a développé la plate-forme logicielle\r\n*INNOVA*, solution innovante reposant sur le Machine-Learning (ML) et\r\nl\'Intelligence Artificielle (IA), dédiée aux métiers de la Finance. Elle\r\npermet l\'automatisation des processus et des contrôles de conformité.\r\n\r\n*DATA AVANGARDE*, solution de Master Data Management alimentée par l\'IA,\r\nvisant à automatiser et à sécuriser l\'ensemble de la chaîne de\r\nproduction des données et de gestion des référentiels, vient compléter\r\ncette offre d\'automatisation des process réglementaires.\r\n\r\nRejoindre Fortia Financial Solutions, c\'est rejoindre une équipe\r\ndynamique et passionnée.\r\n\r\n*DESCRIPTION DU POSTE*\r\nEn collaboration avec l\'équipe Produit et l\'équipe Data Science, vous\r\nserez en charge de l\'*évaluation d\'algorithmes existants* dans le cadre\r\nde travaux de recherche informatique.\r\n\r\nL\'objectif de ce stage est de *mettre en place un protocole\r\nd\'évaluation* de qualité pour les différents algorithmes de l\'IA\r\nutilisés dans nos solutions et de mener cette évaluation d\'un point de\r\nvue qualitatif.\r\n\r\nDans le cadre d\'un stage d\'une durée de 4 à 6 mois, votre mission\r\nconsistera à :\r\n\r\n- Comprendre l\'impact de sorties des algorithmes sur les produits finaux\r\n- Analyser le besoin et le type d\'évaluation nécessaire pour différents\r\n  algorithmes existants dans le but de mesurer ses performances qualitatives\r\n- Définir le périmètre et le(s) protocoles(s) de l\'évaluation\r\n- Effectuer l\'évaluation\r\n- Proposer une synthèse qualitative sur les résultats de l\'évaluation\r\n\r\n*PROFIL RECHERCHE*\r\n\r\n- Formation supérieure (Licence minimum) avec *spécialisation en\r\n  Traitement Automatique des Langues indispensable (TAL)*\r\n  \r\n- Maîtrise de l\'*anglais** et du français indispensable*\r\n\r\n- Vous êtes rigoureux et vous avez une capacité d\'analyse et de\r\n  synthèse, ce stage est fait pour vous!\"\r\n\r\n\r\n*Sabrina JEAN-BOLO *Chargée de Recrutement et RH\r\n17 avenue George V, 75008 Paris\r\n+33(0)6 49 28 67 68 / +33 (0)1 49 53 95 90\r\nsabrina.jeanbolo@fortia.fr  |  www.fortia.fr\r\nhttps://www.fortia.fr'),
(600, '2019-12-09', 'LIFAT', 'Blois', 'Weakly supervised multilingual identification of verbal multiword\r\nexpressions\r\n\r\n\r\nDomain: Natural Language Processing\r\n\r\nKeywords: natural language processing, multi-word expressions,\r\nmultilingualism, supervised machine learning\r\n\r\nLocation: University of Tours, LIFAT (Laboratoire d\'Informatique\r\nFondamentale et Appliquée de Tours), Blois campus, France\r\n\r\nSupervisors: Agata Savary, Caroline Pasquer, Jean-Yves Antoine\r\n\r\nDuration: 6 months\r\n\r\nRemuneration: around 577 EUR / month (minimum)\r\n\r\nFunding: ANR PARSEME-FR project\r\n\r\nMotivation and context\r\n\r\nThe aim of this internship is to boost applications in Natural\r\nLanguage Processing (NLP), by focusing on one of their major\r\nchallenges: multiword expressions (MWEs). MWEs are groups of words\r\nwhich exhibit unpredicted properties (Baldwin & Kim, 2010). Most\r\nprominently, their meaning does not straightforwardly derive from the\r\nmeanings of their components. For instance, faire `make/do\' and valoir\r\n`be worth sth\' are verbs, while their combination yields a noun:\r\nfaire-valoir `a stooge, a person who is used by somebody to do things\r\nthat are unpleasant or dishonest\'. Similarly, the meaning of casser sa\r\npipe `to die\' (literally to break one\'s pipe) cannot be\r\nstraightforwardly deduced from the meanings of the individual\r\ncomponents. Additionally, MWEs exhibit unpredicted morpho-syntactic\r\nand lexical constraints. For instance, replacing the verb in lancer un\r\nappel `to issue a call\' (lit. to throw a call) by a synonym yields an\r\ninvalid expression *jeter un appel `to throw a call\'. Doing alike in\r\ncasser sa pipe `to die\' imposes a literal reading of the resulting\r\nexpression: briser sa pipe `to break one\'s pipe\'.\r\n\r\nOne of the main aims of MWE-oriented NLP research is to model such\r\nexpressions so as to optimize their automatic processing (for\r\ninstance, to avoid their literal translation in machine translation\r\nsystems). Two major MWE-related NLP tasks include MWE identification\r\nand MWE discovery. In the former, an identifier takes a text on input\r\nand automatically annotates (points at) the occurrences of MWEs in\r\ncontext. In the latter, the input consists in large quantities of raw\r\ntexts and the output is a list of potential MWEs given out of\r\ncontext. MWE identification is usually done in a supervised manner,\r\ni.e. by training a system on a manually annotated corpus. MWE\r\ndiscovery, conversely, is usually unsupervised, i.e. can be applied to\r\nvery large quantities of raw data. MWE identification is a\r\npre-requisite for downstream applications such as machine translation\r\n(which may want to treat MWEs with dedicated procedures).\r\n\r\nAutomatic identification of verbal MWEs in 19 languages was addressed\r\nby the PARSEME shared task edition 1.1 (Ramisch et al., 2018), in\r\nwhich the BdTln team participated with the VarIDE system (Pasquer et\r\nal., 2018a). The results of the shared task show that identifying\r\nunseen MWEs (i.e. those MWEs which do not occur in the training data)\r\nis particularly challenging (Savary et al. 2019). Thus, identification\r\nshould, ideally, exploit not only annotated corpora but also MWE\r\nlexicons and MWE discovery methods.\r\n\r\nThe aim of this internship is, thus, to study the potential of\r\ncoupling MWE identification with their discovery, so as to better cope\r\nwith unseen data and increase the global identification\r\nperformances. The general idea is to use the MWE candidates extracted\r\nby a discovery tool, and their occurrence contexts, as seen data (as\r\nif they have been manually annotated) but with a lower reliability\r\nscore. This is to be done in a highly multilingual context, where\r\nmanually annotated data for at least 19 language are openly available.\r\n\r\nWe believe that the context of this internship is particularly\r\nstimulating. It includes the European research network PARSEME\r\n(Parsing and Multiword Expressions) and its French spin-off ANR\r\nproject PARSEME-FR. These communities have developed cross-lingually\r\nunified and validated corpora manually annotated for verbal MWEs (like\r\ncasser sa pipe or lancer un appel), which undelay the PARSEME shared\r\ntask 1.1 mentioned before. In 2020, edition 1.2 of this shared task is\r\nplanned. It will be dedicated to weakly supervised identification of\r\nverbal MWEs. The outcome of this interniship (i.e. a VMWE\r\nidentification and discovery tool) will potentially be proposed to\r\ncompete in this shared task, side-by-side with many other systems\r\ndeveloped worldwide. The student working in this internship will,\r\nthus, regularly participate in on-site or on-line meetings not only\r\nwith her/his supervisors but also with other external members of the\r\naforementioned initiatives.\r\n\r\nExpected outcomes\r\n\r\nThe expected outcomes of this internship include:\r\n\r\n- an overview of the state-of-the-art in MWE identification and\r\n  discovery, and especially on coupling these two functionalities\r\n\r\n- a system which couples, MWE identification and discovery, so as to\r\n  address the major challenge in MWE identification stemming from\r\n  unseen data\r\n\r\n- running the system on the data of the PARSEME shared task 1.2 early\r\n  2020\r\n\r\n- submitting the results to the shared task platform\r\n\r\n- submitting a system description paper to the MWE-LEX 2020 workshop\r\n\r\n- presenting the system at the MWE-LEX 2020 workshop, co-located with\r\n  the COLING 2020 conference in Barcelona in September 2020\r\n\r\nExpected follow-up\r\n\r\n    A 3-4-year PhD grant, related to the same line of research, might\r\n    be available in the research team starting from September 2020\r\n\r\nCandidate\'s profile\r\n\r\n\r\n- 2nd-year master student in computational linguistics, computer\r\n  science or alike\r\n\r\n- Interests in linguistics and familiarity with language technology\r\n\r\n- Good knowledge of French\r\n\r\n- Good programming skills, preferably in Python\r\n\r\nImportant dates\r\n\r\n    Application deadline: 16 December 2019 (or until filled)\r\n    Notification: 20 December 2019\r\n    Position starts: mid-January 2020\r\n    Position ends: around mid-July 2020\r\n\r\nHow to apply\r\n\r\nSend your CV and a cover letter to Agata Savary, Caroline Pasquer and\r\nJean-Yves Antoine (first.last@univ-tours.fr).\r\n\r\n\r\nReferences\r\n\r\nBaldwin, T. and Kim, S. N. (2010) Multiword Expressions, in Nitin\r\nIndurkhya and Fred J. Damerau (eds.) Handbook of Natural Language\r\nProcessing, Second Edition, CRC Press, Boca Raton, USA, pp. 267-292.\r\n\r\nMatthieu Constant, Gülsen Eryigit, Johanna Monti, Lonneke van der\r\nPlas, Carlos Ramisch, Michael Rosner, and Amalia\r\nTodirascu. 2017. Multiword expression processing: A\r\nsurvey. Computational Linguistics, 43(4):837-892.\r\n\r\nCaroline Pasquer, Carlos Ramisch, Agata Savary, Jean-Yves Antoine\r\n(2018) VarIDE at PARSEME Shared Task 2018: Are variants really as\r\nalike as two peas in a pod?, in the Proceedings of the Joint Workshop\r\non Linguistic Annotation, Multiword Expressions and Constructions\r\n(LAW-MWE-CxG-2018), 25-26 August 2018, Santa Fe, USA.\r\n\r\nCarlos Ramisch, Silvio Ricardo Cordeiro, Agata Savary, Veronika\r\nVincze, Verginica Barbu Mititelu, Archna Bhatia, Maja Buljan, Marie\r\nCandito, Polona Gantar, Voula Giouli, Tunga Güngör, Abdelati Hawwari,\r\nUxoa Iñurrieta, Jolanta Kovalevskaite, Simon Krek, Timm Lichte, Chaya\r\nLiebeskind, Johanna Monti, Carla Parra Escartín, Behrang QasemiZadeh,\r\nRenata Ramisch, Nathan Schneider, Ivelina Stoyanova, Ashwini Vaidya,\r\nAbigail Walsh (2018) Edition 1.1 of the PARSEME Shared Task on\r\nAutomatic Identification of Verbal Multiword Expressions, In the\r\nProceedings of the Joint Workshop on Linguistic Annotation, Multiword\r\nExpressions and Constructions (LAW-MWE-CxG-2018), 25-26 August 2018,\r\nSanta Fe, USA.\r\n\r\nAgata Savary, Silvio Ricardo Cordeiro, Carlos Ramisch (2019) Without\r\nlexicons, multiword expression identification will never fly: A\r\nposition statement, In the Proceedings of the Joint Workshop on\r\nMultiword Expressions and WordNet (MWE-WN 2019), 2 August 2019,\r\nFlorence, Italy.'),
(601, '2019-12-09', 'Ludo-Vic', 'Paris', '*6 mois de stage (Informatique - IHM - IA)*\r\n\r\nLe but de ce stage est de contribuer dans le projet \"Basic-Français : un\r\noutil d\'intégration et d\'accès à l\'emploi sur le territoire ITI\" qui a\r\npour but de renforcer les compétences des populations de migrants de\r\npremière, deuxième ou troisième génération, en les aidant à acquérir les\r\nbases du français, en se basant dans un premier temps sur le niveau A1\r\nrequis par l\'Office Français de l\'Immigration et de l\'Intégration, et\r\nqui correspond au niveau minimal nécessaire à une intégration réussie\r\ndans le monde du travail.\r\n\r\nL\'application « Basic-Français » propose le développement d\'un nouvel outil\r\nqui se distingue selon plusieurs aspects :\r\n\r\n- C\'est un outil destiné à être disponible et en classe et pour un usage\r\n  individuel, afin de renforcer la capacité de répétition des exercices\r\n  en dehors des cours, pour renforcer l\'apprentissage.\r\n- C\'est un outil qui s\'adresse à l\'apprenant dans sa langue maternelle,\r\n  et à l\'oral, levant ainsi la barrière de l\'écrit et de la langue\r\n  nationale.  Les consignes d\'utilisation de l\'outil sont donc traduites\r\n  et énoncées dans la langue maternelle idoine.\r\n- L\'apprentissage est basé en grande partie sur des animations qui\r\n  contextualisent les éléments de langage. Non seulement les apprenants\r\n  enregistrent des éléments de français, mais ils reçoivent également\r\n  des informations d\'ordre comportemental : comment agit un citoyen\r\n  français.\r\n\r\n*Missions principales*\r\n\r\nDeux avatars Ludo - le personnage masculin - et Vic - le personnage\r\nféminin -, choisis pour ne pas stigmatiser les populations visées, et\r\npour promouvoir l\'égalité des sexes, sont mis à votre disposition pour\r\nles mettre en scène et faire des animations qui illustrent les bases de\r\nfrançais.  Vous avez en plus à votre disponibilité :\r\n- Un système de reconnaisssance automatique de parole\r\n- Un système de reconnaisssance automatique d\'émotions\r\n\r\nLes 2 humanoides sont donc en interaction avec l\'apprennant.\r\n\r\n*Conditions du stage *\r\n\r\nLe stage se déroulera sur une période de 6 mois dans le département R&D\r\ndu Ludo-Vic SAS. Des outils de travail à distance sont disponibles au\r\nsein de l\'entreprise.\r\n\r\n*Profil recherché *\r\n- Bac +4/5 dans le domaine de l\'informatique et de l\'IA.\r\n- Capacité à scénariser des interactions et réaliser des animations 3D.\r\n- Expérience avec Unity3D et compétence en langage C# sont un vrai plus.\r\n\r\n*Rémunération* : conditions standard de rémunération de stage.\r\n\r\n*Contacts et candidature *\r\nMerci d\'envoyer votre CV, vos relevés de notes, vos rapports de\r\nprojets/stages... à :\r\n- Jack Amberg : jack@ludo-vic.com\r\n- Atef Ben-Youssef : atef@ludo-vic.com'),
(602, '2019-12-13', 'Tetis', 'Montpellier', 'Stage Master 2 Pro ou école ingénieur\r\n\r\nAcquisition et analyse de transcriptions de vidéos Youtube - la problématique de la sécurité alimentaire en Afrique de l\'Ouest\r\n\r\nLe stage, financé par l\'Institut Convergences Agriculture Numérique\r\n#DigitAg (https://www.hdigitag.fr), s\'inscrit dans le cadre d\'un\r\nprojet interdisciplinaire concernant la gestion des risques liés à la\r\nsécurité alimentaire. Le projet est centré sur le cas de l\'Afrique de\r\nl\'Ouest, où les risques agricoles sont d\'autant plus aigus que les\r\nservices nationaux de surveillance et de suivi peuvent être\r\ndéfaillants faute de moyens techniques et financiers. Les objectifs\r\nglobaux du projet sont doubles :\r\n\r\n(i) montrer comment les données de télédétection peuvent être\r\nenrichies par d\'autres sources de données afin de les rendre plus\r\nadaptées à l\'analyse de conditions de sécurité alimentaire et (ii)\r\ndéfinir des techniques originales de fouille de données. L\'analyse et\r\nl\'interprétation de données agroclimatiques (par exemple, imagerie\r\nsatellitaire, données climatiques) pourrait être facilitée par\r\nl\'utilisation conjointes de données indépendantes provenant de sources\r\ntextuelles, ce qui permettrait de localiser correctement les risques\r\nagricoles à l\'échelle régionale, en temps quasi-réel. Néanmoins,\r\nl\'obtention de données textuelles de qualité et leur analyse sont des\r\ntâches complexes.\r\n\r\nLe stage est axé sur l\'acquisition et l\'analyse de données textuelles\r\nsur le thème de la sécurité alimentaire provenant de la transcription\r\ntextuelle du contenu audio de vidéos Youtube. La zone géographique\r\nd\'étude est le Burkina Faso. L\'idée est de traiter une source\r\nd\'information représentant une alternative inexplorée à celles qui\r\nsont exploitées classiquement dans les processus de construction des\r\ncorpus textuels et dans des tâches de fouille de texte (par exemple,\r\njournaux, articles scientifiques, plateformes de médias sociaux\r\nclassiques). Le chaîne Youtube gérée par la RTB - Radiodiffusion\r\nTélévision du Burkina, qui contient près de 12000 vidéos, a été ciblée\r\npour cette analyse. En choisissant un canal officiel, nous visons un\r\ncompromis idéal entre les aspects dynamiques du contenu des médias\r\nsociaux et la qualité de l\'information des sources\r\nofficielles. L\'hypothèse est que les vidéos diffusées par une chaîne\r\nd\'information officielle sont plus susceptibles de contenir de\r\nl\'information utile (c.-à-d. reportages, documentaires, entrevues,\r\ntournages d\'événements officiels, etc.). De plus, le langage standard\r\net clair utilisé dans ce type de vidéos garantit une bonne qualité des\r\ntranscriptions textuelles. Les processus d\'acquisition et analyse des\r\ndonnées seront basés sur l\'utilisation d\'API Web et de bibliothèques\r\npython.\r\n\r\nLes objectifs de ce stage comprennent la production d\'un corpus public\r\net d\'une série de tâches d\'analyse basées sur l\'utilisation de\r\ntechniques de fouille de texte les plus avancées (e.g., LDA,\r\nword2vec). Le livrable consistera en un document de recherche\r\nprésentant les résultats du processus d\'analyse, et notamment les\r\nconnaissances sur la sécurité alimentaire qui peuvent être découvertes\r\ndans une telle source d\'information.  Le planning prévisionnel est\r\nstructuré comme suit :\r\n\r\n1. étude du cahier des charges du corpus à constituer,\r\n2. définition et mise en oeuvre du processus de récolte des données\r\n3. constitution du corpus sur la zone d\'étude,\r\n4. analyse du corpus,\r\n5. rédaction des livrables.\r\n\r\nCompétences requises :\r\n\r\nLangage Python, outils NLP (souhaité)\r\nCapacité de travail en équipe pluridisciplinaire.\r\n\r\nDivers :\r\n\r\nDurée : 5 à 6 mois\r\n\r\nGratification : taux légal en vigueur\r\n\r\nLocalisations : TETIS (Maison de la Télédétection) à Montpellier\r\n\r\nCandidature :\r\n\r\nEnvoyer un CV + relevés de notes des deux dernières années à\r\nroberto.interdonato@cirad.fr et mathieu.roche@cirad.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(603, '2019-12-13', 'Sorbonne Université', 'Paris', '*Offre de stage | Sorbonne Université : Imprimés de la première \r\nmodernité/Corpus/OCR*\r\n\r\n\r\nL\'équipe Antonomaz (ANalyse auTOmatique et NumérisatiOn des MAZarinades)\r\nde Sorbonne Université (Labex OBVIL et EA4509 STIH) propose, dans le\r\ncadre d\'un projet financé par le DIM STCN et l\'initiative CORLI, un\r\nstage de 3 à 5 mois à temps plein. Les missions de ce stage\r\ncontribueront principalement à améliorer la reconnaissance automatique\r\nde caractères (OCR) des imprimés anciens (en particulier du\r\nXVIIe siècle). Le stagiaire bénéficiera d\'un encadrement combinant\r\nchercheurs en informatique et en humanités numériques de manière à\r\nassurer sa progression quant aux compétences requises sur les\r\ntechnologies exploitées.\r\n\r\n*Missions*\r\nConstruire une méthodologie d\'évaluation de sorties d\'OCR sur des\r\ndocuments anciens [2] [3]. Les documents nécessitant ce passage de\r\nl\'image au texte sont une sélection d\'un corpus de « mazarinades »\r\n(imprimés français datant de la Fronde, XVIIe siècle) [4]. L\'étudiant.e\r\nsera amené.e à manipuler des outils d\'OCR (Tesseract [5], Calamari [6]\r\net Kraken [7] en premier lieu) et à étudier leur qualité selon, par\r\nexemple :\r\n- les prétraitements des images ;\r\n- les corpus d\'apprentissage offerts aux outils ;\r\n- la réalisation ou non d\'un apprentissage des outils sur les données de\r\n  l\'étude ;\r\n- l\'apprentissage d\'un modèle de reconnaissance from scratch ou \r\n  l\'affinement d\'un modèle déjà appris.\r\n\r\nL\'étudiant.e pourra ensuite mener une étude exploratoire de ce corpus\r\nocérisé en utilisant des outils de TAL ou des algorithmes de\r\nclassification (SVM ou arbres de décision par exemple).\r\n\r\nOn proposera des tests sur d\'autres corpus imprimés de la première \r\nmodernité (XVIe-XVIIIe siècles), ainsi que sur des données \r\nd\'apprentissage augmentées (ajout de flou, de tâches, etc.)\r\nPlusieurs tâches de post-traitements seront proposées \r\n(normalisation-modernisation, lemmatisation, etc.).\r\n\r\nLa réalisation concrète attendue du ou de la stagiaire sera double : la\r\ndescription d\'un protocole de recherche appliquée (à partir d\'un premier\r\ncorpus exploratoire à océriser) et la transformation de ce premier\r\ncorpus en un ensemble normalisé et lemmatisé.\r\n\r\n*Profil et compétences requises*\r\n- Connaissances en TAL et appétence pour le livre ancien\r\n- Connaissances basiques en HTML/XML et en langage de programmation\r\n  Python\r\n- Anglais (maîtrise de la littérature critique sur le sujet) et \r\n  éventuellement allemand.\r\n\r\n*À acquérir*\r\n- Prise de connaissances de travaux universitaires contemporains en OCR\r\n  de documents historiques (en français/anglais/allemand)\r\n- Mise à niveau en OCR (Optical Character Recognition) [1]\r\n- Informatique et programmation Python :\r\n- Packaging des programmes et versionning avec git\r\n- Outils de Traitement Automatiques des Langues (T.A.L.) : TXM, gate,\r\n  Spacy\r\n- Machine Learning : sklearn (librairie Python)\r\n\r\n*Conditions de recrutement*\r\n- Structure de recrutement : Sorbonne Université\r\n- Gratification : en vigueur + remboursement de 50 % des frais de\r\n  transports\r\n- Matériel : matériel informatique fourni par l\'équipe\r\n- Durée du stage : 4 à 6 mois (selon profil), 35h/semaine\r\n- Prise de fonction : Possible à partir d\'avril 2020\r\n- Localisation : Maison de la Recherche, Serpente (Quartier Saint \r\n  Michel, 75005 Paris)\r\n- Stage au sein d\'une équipe-projet de 4 personnes\r\n\r\n*Date limite de candidature : 29 février 2020*\r\n\r\nModalités de candidature : Envoyer CV et lettre de motivation à\r\nkarine.abiven@sorbonne-universite.fr et\r\ngael.lejeune@sorbonne-universite.fr\r\n\r\n*Références*\r\n[1] Lefèvre, P. (1999). Reconnaissance de l\'imprimé. Techniques de\r\nl\'Ingénieur :\r\nhttps://www.techniques-ingenieur.fr/base-documentaire/archives-th12/archives-documents-numeriques-gestion-de-contenu-tiahc/archive-1/reconnaissance-de-l-imprime-h1348/.\r\n[2] Wick, C., Reul, C., & Puppe, F. (2018). Comparison of OCR Accuracy\r\non Early Printed Books using the Open Source Engines Calamari and\r\nOCRopus. JLCL, 33(1), 79-96.\r\n[3] Springmann, U., Fink, F., & Schulz, K. U. (2016). Automatic quality\r\nevaluation and (semi-) automatic improvement of OCR models for\r\nhistorical printings. arXiv preprint arXiv:1606.05157.\r\n[4] Carrier, H., La Presse de la Fronde (1648-1653) : les mazarinades.\r\nGenève, Droz, 1989-1991.\r\n[5] Smith, R. (2007, September). An overview of the Tesseract OCR\r\nengine. In Ninth International Conference on Document Analysis and\r\nRecognition (ICDAR 2007) (Vol. 2, pp. 629-633). IEEE.\r\n[6] Wick, C., Reul, C., & Puppe, F. (2018). Calamari-A High-Performance\r\nTensorflow-based Deep Learning Package for Optical Character\r\nRecognition. arXiv preprint arXiv:1807.02004.\r\n[7] https://editiones.hypotheses.org/1958'),
(604, '2019-12-13', 'Lattice', 'Montrouge', '*** Annotation de corpus en entités nommées avec apprentissage actif ***\r\n\r\nLieu du stage : laboratoire LATTICE, Montrouge\r\n\r\nEncadrants : Frédérique Mélanie, Thierry Poibeau (LATTICE) \r\n\r\n* Motivation et descriptif\r\n\r\nOn dispose aujourd\'hui d\'outils de traitement des langues opérationnels\r\net efficaces, en partie grâce à l\'apprentissage automatique. On\r\ns\'aperçoit malgré tout souvent que ces outils restent peu robustes face\r\nà la diversité des corpus. Par exemple, les outils de reconnaissance des\r\nentités nommées sont souvent mis au point et évalués sur des corpus\r\ncomme le journal Le Monde, mais les performances observées sur des\r\ncorpus différents sont souvent très faibles, même quand il s\'agit de\r\ntexte édités et supposés écrits dans un \"français correct\". Dans ce\r\ncontexte, les performances rapportées sur les jeux de test classiques\r\nsont très peu informatives et on se heurte dès lors à des problèmes bien\r\nconnus, notamment le coût souvent prohibitif pour obtenir un corpus\r\nannoté représentatif.\r\n\r\nDes techniques comme l\'apprentissage actif peuvent aider à contourner\r\npartiellement cette difficulté, en offrant des moyens d\'annotation\r\nrapides et efficaces. Des interfaces graphiques évoluées permettant en\r\noutre d\'améliorer de manière notable la vitesse et l\'efficacité de\r\nl\'annotation en vue d\'obtenir un modèle performants pour une tâche\r\ndonnée.\r\n\r\nLe stage portera donc sur l\'annotation des entités nommées\r\n(essentiellement noms de personnes et noms de lieux) au sein de romans\r\ndu 19e ou 20e siècle, avec une visée applicative (obtention d\'un corpus\r\nannoté), et plus expérimentale (test de l\'efficacité de\r\nl\'annotation). L\'application visée est une exploration du \"Paris des\r\nécrivains\" : comment les écrivains parlent-ils de Paris ? Quels\r\nquartiers sont mis en avant ? Quel imaginaire autour de Paris ?\r\n\r\n* Public visé\r\n\r\nCe stage s\'adresse à un(e) étudiant(e) de niveau M2, de formation TAL ou\r\nHumanités numériques.\r\n\r\n* Conditions du stage\r\n\r\nStage de 4 à 6 mois, à partir du printemps 2020, indemnisé suivant les\r\nconditions en vigueur.\r\nConvention de stage obligatoire. \r\n\r\n* Comment candidater ? \r\n\r\nEnvoyer un mail avec quelques mots sur votre intérêt pour ce stage dans\r\nle corps du mail, et en pièces attachées un CV et un relevé de notes\r\nrécent.\r\n\r\nAdresser le mail à Thierry Poibeau (thierry.poibeau@ens.fr)'),
(605, '2019-12-13', 'Lattice', 'Montrouge', '*** Génération automatique de poésie inspirée de poèmes existants ***\r\n\r\nCollaboration entre les laboratoires LATTICE (Paris, Montrouge) et IRIT\r\n(Toulouse)\r\n\r\nLieu du stage : laboratoire LATTICE, Montrouge\r\n\r\nEncadrants : Thierry Poibeau, Clément Plancq (LATTICE) ; Tim Van de\r\nCruys (IRIT)\r\n\r\n* Motivation et descriptif\r\n\r\nLa génération automatique de poésie est une tâche ardue pour un système\r\ninformatique.  Pour qu\'un poème ait du sens, il est important de prendre\r\nen compte à la fois des aspects linguistiques et littéraires. Tout\r\nd\'abord, un système de génération de poésie doit modéliser de manière\r\ncorrecte la syntaxe, et la cohérence sémantique et discursive.  De plus,\r\nle système doit intégrer diverses contraintes (telles que la forme et la\r\nrime) liées à un genre poétique particulier. Enfin, le système doit\r\nfaire preuve d\'une certaine créativité littéraire, ce qui rend le poème\r\nintéressant et digne d\'être lu.\r\n\r\nCe stage s\'inscrit dans le contexte du projet Oucopo [1], qui vise à\r\nexplorer les liens entre textes et numérique avec, au-delà des aspects\r\npurement techniques et scientifiques, la prise en compte d\'aspects\r\nesthétiques. Le projet s\'inspire en premier lieu de l\'ouvrage de Raymond\r\nQueneau \"Cent mille milliards de poèmes\", paru en 1961, qui permet de\r\ncombiner des vers pour composer des poèmes respectant la forme du\r\nsonnet. Dans ce contexte, ce stage vise à étendre l\'idée de\r\nrecombinaison, en explorant l\'interaction entre des poèmes écrits par\r\ndes humains, et les poèmes générés de manière automatique. Plus\r\nspécifiquement, on utilisera des poèmes existants comme source\r\nd\'inspiration pour un système de génération de poésie automatique. A\r\npartir d\'un poème existant, un système de génération pourrait par\r\nexemple :\r\n\r\n- induire une représentation à base d\'une partie des vers d\'un poème\r\n  existant, et générer des vers pour compléter le poème ; la génération\r\n  des vers est censée suivre les contraintes du poème existant\r\n  (notamment par rapport au rythme et à la rime) ;\r\n\r\n- générer un nouveau poème similaire au poème existant, mais en\r\n  changeant le schéma de rime ;\r\n\r\n- générer un nouveau poème à base des thèmes évoqués dans le poème\r\n  existant.\r\n\r\nCette liste n\'est pas exhaustive; il existe évidemment de nombreuses\r\nmanières de générer des poèmes sur la base de ceux existants.\r\n\r\nDe manière pratique, ce stage s\'appuiera sur une système de génération\r\nde poésie existant, appelé Charles, et développé à l\'IRIT à Toulouse\r\n[2,3]. Ce système de génération utilise un modèle de réseaux de neurones\r\nrécurrents dans une configuration encodeur-décodeur. L\'encodeur\r\nconstruit d\'abord une représentation d\'une phrase entière en incorporant\r\nséquentiellement les mots de cette phrase dans un vecteur d\'état caché\r\nde taille fixe. La représentation finale est ensuite donnée au décodeur,\r\nqui émet une séquence de mots selon une distribution de probabilité\r\ndérivée de l\'état caché de la phrase en entrée. En apprenant au réseau à\r\nprédire la phrase suivante avec la phrase actuelle en entrée, le réseau\r\napprend à générer du texte brut avec une certain cohérence\r\ndiscursive. En transformant la distribution de probabilité fournie par\r\nle décodeur, afin d\'incorporer des contraintes poétiques, le réseau peut\r\nêtre exploité pour la génération de vers poétiques. Pendant ce stage, le\r\nsystème de génération serait adapté et étendu afin de mettre en oeuvre\r\nles objectifs décrits ci-dessus.\r\n\r\n* Public visé\r\n\r\nCe stage s\'adresse à un(e) étudiant(e) de niveau M2 ou 3ème année\r\nd\'école d\'ingénieurs, ayant de bonnes connaissances de programmation en\r\nPython. La connaissance de bibliothèques pour l\'implémentation de\r\nréseaux de neurones (et plus spécifiquement Pytorch) est un atout.\r\n\r\n* Conditions du stage\r\n\r\nStage de 4 à 6 mois, à partir du printemps 2020\r\nindemnisé suivant les conditions en vigueur\r\nConvention de stage obligatoire\r\n\r\n* Comment candidater ? \r\n\r\nEnvoyer un mail avec quelques mots sur votre intérêt pour ce stage dans\r\nle corps du mail, et en pièces attachées un CV et un relevé de notes\r\nrécent.\r\n\r\nAdresser le mail à Thierry Poibeau (thierry.poibeau@ens.fr)\r\n\r\n* Références\r\n\r\n\r\n[1] http://www.transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire\r\n[2] https://github.com/timvdc/poetry\r\n[3] Tim Van de Cruys. La génération automatique de poésie en\r\n    français. Proceedings of TALN 2019, pages 113-126, Toulouse, France.'),
(606, '2019-12-16', 'INRA', 'Clermont-Ferrand', 'Titre: Fouille de texte pour extraction de terminologies agricoles\r\n\r\nContact : Catherine Roussey, Irstea Centre de Clermont-Ferrand (catherine.roussey@irstea.fr)\r\n\r\nCo-encadrement par Robert Bossy, INRA, Jouy-en-Josas\r\n\r\nLocalisation : Irstea, Centre de Clermont-Ferrand, Aubière\r\n\r\nType : Stage de Master 2\r\n\r\nProfil : Étudiants de master 2 en informatique ou bioinformatique, data science\r\n\r\nPériode: courant 2020\r\n\r\nDate de début de stage mars 2020\r\n\r\nDurée: 2 à 5 mois\r\nContexte du stage\r\n\r\nDans le cadre de l\'ANR D2KAB\r\n\r\nLes ressources sémantiques (e.g., thesaurus, terminologies,\r\nvocabulaires et ontologies) sont des éléments clés pour assurer\r\nl\'interopérabilité des données. Dans certains domaines de recherche en\r\nagriculture, les scientifiques développent déjà des ressources\r\nsémantiques pour faciliter l\'intégration de leurs données avec\r\nd\'autres et permettre l\'extraction de connaissances e.g., Crop\r\nOntology ou FrenchCropUsage thesaurus. Cependant, bien souvent les\r\npersonnes concernées ne sont pas nécessairement des scientifiques, qui\r\nont l\'opportunité de s\'intéresser au monde du web sémantique, mais des\r\nacteurs du monde agricole, qui produisent ou utilisent des\r\nréférentiels simples et souvent spécifiques à une filière. Par\r\nexemples, le référentiel des stades phénologiques de la vigne ou la\r\nliste des variétés en vigne produit par l\'IFV (Institut Français de la\r\nVigne et du Vin) ou le référentiel de produits phytosanitaires produit\r\npar l\'ACTA. Récemment, une première étape a été franchie avec la mise\r\nà disposition de certains de ces référentiels sur la plateforme de\r\npartage de données agricoles, API-AGRO\r\n(https://plateforme.api-agro.fr). Mais pour aller plus loin dans le\r\npartage et la réutilisation de ces référentiels, il est nécessaire\r\nd\'adopter les principes FAIR (Findable, Accessible, Interoperable and\r\nReusable).\r\n\r\nLe projet ANR D2KAB (www.d2kab.org), démarré en 2019, regroupe un\r\nconsortium multidisciplinaire unique de 7 organisations dont 4 dans\r\nDigitAg (UM, INRA, IRSTEA, ACTA + et un partenariat avec API-AGRO)\r\ndont l\'objectif principal est de mettre en place les processus\r\npermettant de transformer les données d\'agricole en connaissances -\r\nsémantiquement riches, interopérables, ouvertes - ainsi que les\r\nméthodes scientifiques et les outils pour exploiter et diffuser ces\r\nconnaissances dans des applications scientifiques et agricoles. Le\r\nprojet est guidé par plusieurs scénarios dont un navigateur de\r\nrecherche améliorée des bulletins d\'alerte agricole intitulés Bulletin\r\nde Santé du Végétal [BSV]. D2KAB développe et maintient AgroPortal\r\n(http://agroportal.lirmm.fr), un portail de ressources sémantiques\r\npour l\'agronomie et l\'agriculture.\r\n\r\nL\'ANR D2KAB propose plusieurs offres de CDD ingénieur dont un qui sera\r\nla suite de ce stage.\r\n\r\nObjectif du stage\r\n\r\nL\'objectif de ce stage est d\'améliorer la couverture terminologique des référentiels agricoles existants en les enrichissant grâce à l\'extraction de termes spécifiques  à partir du corpus des bulletins d\'alertes (BSV). Plus précisément :\r\n\r\n- Mise en place d\'un workflow de text mining à partir du système Alvis\r\nde TALN [Alvis] proposé par l\'équipe de Bibliome de l\'INRA\r\n\r\n- Mise en place d\'un protocole de validation des termes à l\'aide de\r\nl\'outil TyDI [TyDI] . Les termes devront être validé par un réseau\r\nd\'experts par type de culture (vigne, céréale, légume)\r\n\r\n- Publication de la nouvelle version des référentiels sur l\'Agroportal.\r\n\r\nProfil du candidat\r\n\r\n\r\n- Niveau Master 2 en mathématique, informatique ou bioinformatique, data\r\nscience\r\n\r\n- Expérience avec des outils d\'apprentissage automatique et motivation\r\npour apprendre de nouvelles technologies.\r\n\r\n- Une expérience des technologies du Web sémantique sera appréciée mais\r\nn\'est pas obligatoire.\r\n\r\n- Bonnes compétences en anglais à l\'oral et à l\'écriture. Une bonne\r\nconnaissance du français ou une motivation pour apprendre est\r\nsouhaitable.\r\n\r\n- Excellentes compétences en rédaction scientifique, car il sera\r\nnécessaire de produire des rapports, de la documentation technique et\r\ndes compte rendu de réunion.\r\n\r\n- Excellente compétence en gestion de projet et planification, car il\r\nsera nécessaire de faire des points réguliers avec différentes équipes\r\ndu projet D2KAB\r\n\r\n- Autonomie et initiative, être capable de proposer de nouvelles\r\ntechniques au sein du projet et de justifier de ses choix.\r\n\r\n- Personne dynamique pour rejoindre une petite équipe de recherche à\r\nClermont-Ferrand.\r\n\r\nCandidature\r\n\r\nRépondre à l\'annonce sur le site de l\'INRA (un CV et une lettre de\r\nmotivation)\r\n\r\nhttp://jobs.inra.fr/offers/detail/285917\r\n\r\nPour toute demande d\'information contacter catherine.roussey@irstea.fr\r\n\r\nDate limite de candidature mai 2020.\r\n\r\nRémunération\r\n\r\nPrime de stage de master 2 (environs 580 ¤ par mois)\r\n\r\nRéférences\r\n\r\n[Alvis] Nédellec C, Nazarenko A, Bossy R: Information\r\nExtraction. Ontology Handbook. Edited by: Staab S, Studer R. 2008,\r\nSpringer Verlag, 663-686. URL: github.com/Bibliome/alvisnlp\r\n\r\n[BSV] C. ROUSSEY, T. ABDERRAHMANI GHORFI. Annotation sémantique pour\r\nune interrogation experte des Bulletins de Santé du Végétal. Dans les\r\nActes des 29e Journées Francophones d\'Ingénierie des Connaissances IC\r\n2018, adossée à la 11e Plate-forme Francophone d\'Intelligence\r\nArtificielle, 2-6 juillet 2018, Nancy, p 37-52\r\n\r\nPlus d\'information sur http://ontology.irstea.fr/pmwiki.php/Site/BSV\r\n\r\n[TyDI] Nédellec C., Golik W., Aubin S., Bossy R. (2010) Building Large\r\nLexicalized Ontologies from Text: A Use Case in Automatic Indexing of\r\nBiotechnology Patents. In: Cimiano P., Pinto H.S. (eds) Knowledge\r\nEngineering and Management by the Masses. EKAW 2010. Lecture Notes in\r\nComputer Science, vol 6317. Springer, Berlin, Heidelberg'),
(607, '2019-12-16', 'IRIT', 'Toulouse', '- Title: Extracting Semantic Information from Noisy Data\r\n- Duration: 6 month internship, starting February-March 2020\r\n- Location: IRIT, Toulouse (https://www.irit.fr)\r\n- Research Team: MELODI (https://www.irit.fr/-Equipe-MELODI-)\r\n- Supervisors: Nicholas Asher, Tim Van de Cruys\r\n- Contact: nicholas.asher@irit.fr, tim.vandecruys@irit.fr\r\n\r\nIn cooperation with AIRBUS\r\n\r\nDescription\r\n\r\nA prominent research subject within the domain of machine learning is\r\nadjusting learning and training to noisy data. The subject has been\r\nactively researched within the context of computer vision (Goldberger\r\nand Ben-Reuven, 2017; Vahdat, 2017; Veit et al., 2017); in our case we\r\nare interested in training from noisy linguistic data. While many groups\r\nare looking at noisy linguistic data for general purpose learning in\r\nopen domains (Baldwin et al., 2015), the goal of this research\r\ninternship is to extract semantic information from noisy linguistic data\r\nin closed or relatively closed domains. Use cases involve notices to\r\nairmen (Notams) and airport traffic information bulletins (ATIS),\r\nmaintenance logs or notes for aircraft or other industrial productions,\r\nand notes from meetings. The interest in such use cases is that they\r\nallow us to look at a variety of learning systems and compare\r\nthem. Within relatively closed domains, we have had success with distant\r\nsupervision models, where we learn weights for a set of expert coded\r\nrules based on an estimation of ground truth labels for unannotated\r\ndata, where the rules are derived from the study of a small but\r\nrepresentative and meticulously annotated corpus (Badene et al.,\r\n2019). We would like to compare such models with neural network based\r\napproaches, such as word embedding that incorporate character-based\r\nrepresentations (Joulin et al., 2017), as well as transformer networks\r\n(viz. BERT; Devlin et al., 2019) that we can adapt to the task with\r\nspecific pretraining.\r\n\r\nThis research internship would be suitable for a 2nd year master student\r\n(M2) with knowledge of machine learning and natural language processing\r\nalgorithms. Experience with Python libraries for neural network\r\nimplementations (specifically Pytorch) is a plus.\r\n\r\nReferences\r\n\r\nSonia Badene, Kate Thompson, Jean-Pierre Lorré, and Nicholas Asher\r\n(2019). Weak Supervision for Learning Discourse Structure. In\r\nProceedings of the 2019 Conference on Empirical Methods in Natural\r\nLanguage Processing and the 9th International Joint Conference on\r\nNatural Language Processing (EMNLP-IJCNLP), pp. 2296-2305.\r\n\r\nBaldwin, Timothy, Marie-Catherine de Marneffe, Bo Han, Young-Bum Kim,\r\nAlan Ritter, and Wei Xu (2015). Shared tasks of the 2015 workshop on\r\nnoisy user-generated text: Twitter lexical normalization and named\r\nentity recognition. In Proceedings of the Workshop on Noisy\r\nUser-generated Text, pp. 126-135.\r\n\r\nDevlin, Jacob, Chang, Ming-Wei, Lee, Kenton and Toutanova, Kristina,\r\n2019. BERT: Pre-training of Deep Bidirectional Transformers for Language\r\nUnderstanding. In Proceedings of the 2019 Conference of the North\r\nAmerican Chapter of the Association for Computational Linguistics: Human\r\nLanguage Technologies, pp. 4171-4186.\r\n\r\nJacob Goldberger and Ehud Ben-Reuven (2017). Training deep\r\nneural-networks using a noise adaptation layer. In 5th International\r\nConference on Learning Representations (ICLR 2017), Toulon, France.\r\n\r\nJoulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2017). Bag of\r\nTricks for Efficient Text Classification. In Proceedings of the 15th\r\nConference of the European Chapter of the Association for Computational\r\nLinguistics: Volume 2, Short Papers (pp. 427-431). Association for\r\nComputational Linguistics.\r\n\r\nArash Vahdat (2017). Toward Robustness against Label Noise in Training\r\nDeep Discriminative Neural Networks. In Advances in Neural Information\r\nProcessing Systems 30: Annual Conference on Neural Information\r\nProcessing Systems 2017, Long Beach, CA, USA, pp. 5596-5605.\r\n\r\nAndreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and\r\nSerge J. Belongie (2017). Learning from Noisy Large-Scale Datasets with\r\nMinimal Supervision. In 2017 IEEE Conference on Computer Vision and\r\nPattern Recognition (CVPR 2017), Honolulu, HI, USA, pp. 6575-6583.'),
(608, '2019-12-16', 'IRIT', 'Toulouse', '- Titre : Prédiction de la difficulté de compréhension de contenu\r\n  audiovisuel - approche basée sur des données textuelles faiblement\r\n  annotées\r\n\r\n- Domaine : Analyse, indexation et compréhension de contenus\r\n  audiovisuels (audio, vidéo, texte)\r\n- Thématique : Traitement automatique des langues - Analyse\r\n  conversationnelle et interaction\r\n- Lieu du stage : IRIT, Université Toulouse III - Paul Sabatier,\r\n  Toulouse (https://www.irit.fr)\r\n- Durée : 5 à 6 mois de stage (début février ou mars 2020)\r\n- Equipes : SAMoVA (https://www.irit.fr/recherches/SAMOVA/) et MELODI\r\n  (https://www.irit.fr/-Equipe-MELODI-)\r\n- Contacts : Isabelle Ferrané (isabelle.ferrane@irit.fr) - Tim Van de\r\n  Cruys (tim.vandecruys@irit.fr)\r\n\r\nContexte\r\n\r\nL\'exploitation avancée de grands volumes de documents audiovisuels passe\r\npar la compréhension de leur contenu. L\'analyse automatique de ces\r\ncontenus peut être réalisée sous plusieurs angles, en fonction des\r\nmodalités considérées.\r\n\r\n- L\'analyse de la composante audio permet d\'extraire des informations\r\n  (descripteurs audio) concernant l\'environnement sonore (zones de\r\n  musique, de parole ou de bruits environnants, ...), les locuteurs et\r\n  les tours de parole (Vallet et al., 2012).\r\n\r\n- L\'analyse de la composante vidéo permet d\'extraire des informations\r\n  (descripteurs visuels) concernant le cadre (intérieur, extérieur,\r\n  nuit, jour, ...) ou les intervenants (foule, personne présente en\r\n  premier plan ou groupe de plusieurs personnes, ...) (Bost et al.,\r\n  2015).\r\n\r\n- L\'analyse de la composante textuelle, à travers les sous-titres ou\r\n  bien les transcriptions automatiques à disposition, permet d\'extraire\r\n  des informations sémantiques (descripteurs texte) qui permettent\r\n  d\'enrichir la caractérisation du contenu basée sur les modalités audio\r\n  et vidéo (Lison and Tiedemann, 2016).\r\n\r\nObjectif\r\n\r\nDans ce stage, on cherche de caractériser les contenus de films selon\r\nleur niveau de difficulté de compréhension. Vue que le niveau de\r\ndifficulté de compréhension est principalement lié à la composante\r\nlinguistique, on explorera les possibilités offertes par le domaine du\r\ntraitement automatique des langues pour extraire les informations\r\npertinentes, qui pourraient donner des indications sur la tâche\r\nenvisagée.  Sujet de stage : L\'objectif de ce stage est de prédire de\r\nmanière automatique la difficulté de compréhension de séquences vidéo à\r\ntravers leurs sous-titres ou transcriptions. Dans ce but, on appliquera\r\ndes méthodes supervisées basées sur les plongements de mots (word\r\nembeddings). Ces représentations sont généralement obtenues par\r\napprentissage non-supervisé réalisés à partir d\'un volume très important\r\nde textes, et permettent de représenter les mots sous forme vectorielle\r\n(vecteur de N dimensions à coefficients réels associé à chaque mot) afin\r\nde mieux caractériser leur sens (Mikolov et al., 2013). En les intégrant\r\ndans un modèle de réseau de neurones supervisé, il est possible de\r\nconstruire des représentations vectorielles pour de plus grandes\r\nsections de texte, capable de prédire les descripteurs pertinents\r\n(Joulin et al., 2017). Pour l\'entraînement des plongements de mots, nous\r\nutiliserons un corpus de textes ciblé par rapport à la tâche envisagée\r\n(sous-titres de documents de fictions ou de transcriptions automatiques\r\nde vidéos issues du web).  L\'application d\'un modèle de classification\r\nnécessite également des données labellisées. Dans ce stage, nous avons\r\npour objectif de construire un ensemble d\'entraînement fournissant un\r\npremier niveau d\'annotation approximatif, c\'est-à-dire correspondant à\r\ndes « données faiblement annotées », à la différence d\'une vérité\r\nterrain exacte et précise. Pour cela, nous explorerons le paradigme de\r\nprogrammation de données (data programming ; Ratner et al., 2017). Le\r\nbut est de labelliser de manière automatique une grande quantité de\r\ndonnées par l\'application de fonctions de labellisation, éventuellement\r\nbruitées ; un modèle génératif effectuera alors un débruitage des\r\ndonnées en analysant les fonctions de labellisation comme variables\r\nlatentes. Ceci permet de labelliser de manière assez rapide une grande\r\nquantité de données avec une exactitude satisfaisante. Les fonctions de\r\nlabellisation s\'appuieront sur des traits linguistiques (par rapport au\r\nlexique, syntaxe, etc.). Ils pourront également s\'appuyer sur les\r\ntravaux antérieurs réalisés lors de stages précédents (Petiot, 2018 ;\r\nBerdeaux, 2019). Ce travail pourrait potentiellement se faire en\r\ncollaboration avec la société Archean Labs et le laboratoire commun\r\nALAIA, afin de comparer différentes approches possibles.\r\n\r\nCompétences\r\n\r\nCe stage s\'adresse à un(e) étudiant(e) de niveau M2 ou 3ème année\r\nd\'Ecole d\'ingénieurs, ayant de bonnes connaissances en programmation\r\nobjet (python) sous Linux. Des compétences en reconnaissance de formes\r\net apprentissage automatique sont également attendues. La connaissance\r\ndes méthodes de traitement d\'images, ou traitement de l\'audio sont un\r\nplus pour bien comprendre les objectifs visés à terme de fusion des\r\ndescripteurs audio, vidéos et texte. Un bon niveau d\'anglais est\r\négalement requis pour la lecture et compréhension d\'articles\r\nscientifiques en lien avec les différentes thématiques de recherche.\r\n\r\nRéférences\r\n\r\nX Bost, G Linares, S Gueye Audiovisual speaker diarization of TV series\r\n- Acoustics, Speech and Signal Processing (ICASSP), 2015.\r\n\r\nArmand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas\r\nMikolov. 2017. Bag of Tricks for Efficient Text Classification. In\r\nProceedings of the 15th Conference of the European Chapter of the\r\nAssociation for Computational Linguistics: Volume 2, Short Papers,\r\nValencia, Spain, pp 427-431\r\n\r\nPierre Lison and Jörg Tiedemann. 2016. OpenSubtitles2016: Extracting\r\nLarge Parallel Corpora from Movie and TV Subtitles. In Proceedings of\r\nthe Tenth International Conference on Language Resources and Evaluation\r\n(LREC\'16), pp. 923-929.\r\n\r\nTomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient\r\nEstimation of Word Representations in Vector Space. CoRR abs/1301.3781\r\n\r\nJim Petiot, Exploitation de données textuelles pour la recherche de\r\nTopics et la caractérisation de contenus de fiction : approche\r\nnon-supervisée et semi-supervisée. Stage M2 IARF, 2018.\r\n\r\nAlexandre Berdeaux, Classification supervisée de thèmes de dialogues de\r\nfilm en contexte de données faiblement annotées, Stage M2 IARF, 2019.\r\n\r\nRatner, Alexander, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen\r\nWu, and Christopher Ré.  \"Snorkel: Rapid training data creation with\r\nweak supervision.\" Proceedings of the VLDB Endowment 11, no. 3 (2017):\r\n269-282.\r\n\r\nFélicien Vallet, Slim Essid, Jean Carrive, Gaël Richard, High-Level TV\r\nTalk Show Structuring Centered on Speakers\' Interventions, TV Content\r\nAnalysis: Techniques and Applications, Edited by Shiguo Lian Auerbach\r\nPublications 2012.'),
(609, '2019-12-16', 'CEA LIST', 'Palaiseau', 'Le CEA LIST propose le sujet de stage ci-dessous pour l\'année\r\nuniversitaire 2019-2020.\r\n\r\nTitre de stage: Intégration de lexiques bilingues spécialisés dans des\r\nmodèles neuronaux pour l\'adaptation au domaine en traduction automatique\r\n\r\nLieu du stage: CEA Saclay Nano-INNOV, Laboratoire Analyse Sémantique\r\nTexte et Image (LASTI), 8 Avenue de la Vauve, 91120 Palaiseau\r\n\r\nEncadrant: Nasredine Semmar, CEA LIST, Laboratoire Analyse Sémantique\r\nTexte et Image (LASTI)\r\n\r\n\r\nLe Laboratoire d\'Analyse Sémantique des Textes et des Images (LASTI) est\r\nune équipe de 25 personnes (chercheurs, ingénieurs, doctorants) menant\r\ndes travaux de recherche sur les technologies de description et de\r\ncompréhension du contenu multimédia (image, texte, parole) et des\r\ndocuments multilingues, en particulier à grande échelle. Les enjeux\r\nscientifiques sont:\r\n\r\n- développer des algorithmes efficaces et robustes pour l\'analyse et\r\n  l\'extraction de contenu multimédia, leur classification et analyse\r\n  sémantique;\r\n  \r\n- reconstitution ou fusion de données hétérogènes pour interpréter des\r\n  scènes ou documents;\r\n  \r\n- développer des méthodes et des outils pour la construction, la\r\n  formalisation et l\'organisation des ressources et connaissances\r\n  nécessaires au fonctionnement de ces algorithmes;\r\n  \r\n- intégrer plusieurs de ces briques technologiques afin d\'accéder à\r\n  l\'information et répondre à un besoin utilisateur (moteurs de\r\n  recherche, chatbot, rapports synthétiques de veille).\r\n\r\nContexte :\r\n\r\nL\'adaptation au domaine des applications du traitement automatique de la\r\nlangue telles que la traduction automatique, la recherche et\r\nl\'extraction d\'information est devenu un axe de recherche important en\r\napprentissage automatique et plus particulièrement en apprentissage par\r\ntransfert. En traduction automatique, plusieurs pistes ont été explorées\r\npour adapter des modèles statistiques construits pour un domaine source\r\npour lequel existent une quantité suffisante de données d\'apprentissage\r\nvers un domaine cible pour lequel peu de données sont disponibles (Lewis\r\net al., 2010; Pecina et al., 2011; Wang et al., 2012). Au cours des\r\ndernières années, de nombreux travaux ont exploré l\'utilisation des\r\nlexiques bilingues spécialisés pour améliorer la performance des\r\nsystèmes de traduction statistique. La plupart d\'entre eux consistent,\r\nsoit à ajouter au corpus d\'apprentissage un lexique bilingue ou un\r\ncorpus parallèle du domaine de spécialité, soit à étendre les tables de\r\ntraduction en leur incorporant les entrées du lexique spécialisé\r\n(Langlais, 2002; Bouamor et al., 2012; Semmar et al., 2017).\r\n\r\nEn comparaison avec la traduction à base de règles ou la traduction\r\nstatistique, peu de travaux ont été réalisés pour intégrer des lexiques\r\nbilingues spécialisés dans des systèmes de traduction utilisant des\r\nmodèles neuronaux pour leur adaptation au domaine. Nous pouvons citer\r\nles travaux de Wang et al. (2017) qui ont proposé une méthode pour\r\nintégrer un lexique bilingue d\'expressions multi-mots dans un modèle\r\nneuronal de type encodeur-décodeur. En revanche, plusieurs études\r\nrécentes ont abordé l\'intégration de connaissances expertes ou\r\nressources linguistiques externes dans des modèles de réseaux de\r\nneurones profonds. Trois stratégies d\'intégration ont été explorées :\r\nLes connaissances expertes ou ressources linguistiques sont introduites\r\nen amont (Kuznetsov et al., 2018), en cours (Hu et al., 2016) ou en aval\r\ndu processus d\'apprentissage, de manière focalisée ou répartie dans le\r\nmodèle neuronal (Zennaki et al., 2018).\r\n\r\n\r\nSujet de stage:\r\n\r\nLe stage proposé portera sur l\'exploitation de lexiques bilingues\r\nspécialisés en traduction neuronale pour l\'adaptation au domaine. Il\r\nconsistera, d\'une part à implémenter un système de traduction neuronale\n\nen utilisant les librairies open source disponibles, et d\'autre part à\r\nexplorer l\'intégration d\'un lexique bilingue spécialisé dans ce type de\r\nsystème et à étudier l\'impact de ce lexique sur la qualité de\r\ntraduction.\r\n\r\nLe stage se déroulera selon les étapes suivantes:\r\n\r\n- Développement ou adaptation d\'un outil d\'alignement de mots pour la\r\n  constitution de lexiques bilingues spécialisés à partir de corpus de\r\n  textes parallèles.\r\n\r\n- Installation du système de traduction neuronale Open Source OpenNMT\r\n  (http://fr.opennmt.net/).\r\n\r\n- Spécification et implémentation d\'un modèle pour l\'intégration dans le\r\n  système OpenNMT d\'un lexique bilingue spécialisé.\r\n\r\n- Evaluation de l\'impact de ce lexique sur la qualité de traduction du\r\n  système OpenNMT.\r\n\r\n- Implémentation d\'une interface Web pour le traducteur automatique\r\n  neuronal.\r\n\r\nRéférences:\r\n- LEWIS W. D., WENDT C., BULLOCK D. Achieving Domain Specificity in SMT\r\n  without Overt Siloing. Actes de the seventh international conference\r\n  on Language Resources and Evaluation, 2010.\r\n- PECINA P., TORAL A., WAY A., PAPAVASSILIOU V., WAY A., PROKOPIDIS P.,\r\n  GIAGKOU M. Towards Using Web-Crawled Data for Domain Adaptation in\r\n  Statistical Machine Translation, 2011. Actes de the 15th Conference of\r\n  the European Association for Machine Translation.\r\n- WANG W., MACHEREY K., MACHEREY W., OCH F., XU P. Improved Domain\r\n  Adaptation for Statistical Machine Translation. Actes de the\r\n  Conference of the North American Chapter of the Association for\r\n  Computational Linguistics: Human Language Technologies, 2012.\r\n- LANGLAIS P. (2002). Improving a general-purpose statistical\r\n  translation engine by terminological lexicons. Actes de COLING: Second\r\n  international workshop on computational terminology.\r\n- BOUAMOR D., SEMMAR N., ZWEIGENBAUM P. Identifying bilingual Multi-Word\r\n  Expressions for Statistical Machine Translation. Actes de LREC 2012.\r\n- SEMMAR N., ZENNAKI O., LAIB M. Improving the Performance of an\r\n  Example-Based Machine Translation System Using a Domain-specific\r\n  Bilingual Lexicon. Actes de 29th Pacific Asia Conference on Language,\r\n  Information and Computation, Shanghai, China, 2015.\r\n- WANG X., TU Z., XIONG D., ZHANG M. Translating Phrases in Neural\r\n  Machine Translation. Actes de EMNLP 2017.\r\n- KUZNETSOV I., GUREVYCH I. From Text to Lexicon: Bridging the Gap\r\n  between Word Embeddings and Lexical Resources. Actes de COLING 2018.\r\n- HU Z., MA X., LIU Z., HOVEY E., XING E. P. Harnessing Deep Neural\r\n  Networks with Logic Rules. Actes de ACL 2016.\r\n- ZENNAKI O., SEMMAR N., BESACIER L. A Neural Approach for Inducing\r\n  Multilingual Resources and Natural Language Processing Tools for\r\n  Low-Resource Languages. Journal of Natural Language Engineering,\r\n  Cambridge University Press, 2018.\r\n\r\n\r\nConditions sur les candidatures et Profil recherché:\r\n\r\nNiveau demandé: Master 2, Ingénieur\r\n\r\nDurée : 6 mois\r\n\r\nRémunération : entre 700 ¤ et 1300 ¤ suivant la formation\r\n\r\nCompétences requises :\r\n\r\n- environnement de travail : linux\r\n\r\n- maîtrise d\'un langage de programmation : C++ ou Python\r\n\r\n- expérience avec une bibliothèque de type Tensorflow, PyTorch, etc.\r\n\r\n- notion de base en apprentissage automatique et en réseaux de neurones\r\n\r\n- notions de base en traitement automatique des langues.\r\n\r\n\r\n\r\nModalité de dépôt de candidature :\r\n\r\nLes candidatures (CV + Lettre de motivation) sont à envoyer le plus\r\nrapidement possible à Nasredine Semmar\r\n(nasredine.semmar@cea.fr<mailto:nasredine.semmar@cea.fr>).\r\n\r\n\r\nContacts pour plus d\'information :\r\nNasredine Semmar, Email: nasredine.semmar@cea.fr, \r\nTél: +33 (0)1 69 08 01 46'),
(610, '2019-12-16', 'INA', 'Bry-sur-Marne', 'Segmentation et détection automatique des situations conflictuelles en\r\ninterview politique\r\n\r\n    \r\nMots clés : Machine Learning, Diarization, Humanités numériques, parole\r\npolitique, expressivité\r\n    \r\nContexte\r\nL\'Institut national de l\'audiovisuel (INA) est un établissement public à\r\ncaractère industriel et commercial (EPIC), dont la mission principale\r\nconsiste à archiver et valoriser la mémoire audiovisuelle française\r\n(radio, télévision et web média). L\'INA assure également des missions de\r\nrecherche scientifique, de formation et de production.\r\n\r\nCe stage s\'inscrit le cadre du projet OOPAIP (Ontologie et outil pour\r\nl\'annotation des interventions politiques). C\'est un projet\r\ntransdisciplinaire porté par l\'INA et le CESSP (Centre européen de\r\nsociologie et de science politique) de l\'Université Paris 1\r\nPanthéon-Sorbonne. L\'objectif est de concevoir de nouvelles approches\r\npour élaborer des analyses détaillées, qualitatives et quantitatives des\r\ninterventions politiques médiatisés en France. Une part du projet porte\r\nsur l\'étude de la dynamique des interactions conflictuelles dans les\r\ninterviews et débats politiques, ce qui nécessite une description fine\r\net un large corpus afin de généraliser les modèles. Les verrous\r\ntechnologiques concernent la performance des algorithmes de segmentation\r\nen locuteurs et en styles de parole. L\'amélioration de leur précision,\r\nl\'ajout de la détection de parole superposée, de mesures de l\'effort\r\nvocal et d\'éléments expressifs, permettront d\'optimiser le travail\r\nd\'annotation manuel.\r\n    \r\nObjectifs du stage\r\nLe stage vise principalement à l\'amélioration de la segmentation\r\nautomatique d\'interviews politiques pour assister les travaux de\r\nrecherche en science politique. La thématique de recherche\r\ncorrespondante que nous retiendrons est la mise en évidence des\r\nsituations conflictuelles. Dans ce cadre, nous nous intéresserons\r\nnotamment à la détection du brouhaha (parole superposée). De manière\r\nplus fine, nous aimerions pouvoir extraire des descripteurs du signal de\r\nparole corrélés au niveau de conflictualité des échanges, basés, par\r\nexemple, sur le niveau d\'activation (niveau intermédiaire entre le\r\nsignal et l\'expressivité [Rilliard et al, 2018]) ou l\'effort vocal\r\n[Liénard, 2019].\r\n\r\nLe stage pourra s\'appuyer initialement sur deux corpus totalisant 30\r\ninterviews politiques annotés finement en tours de paroles - dans le\r\ncadre du projet OOPAIP. Il débutera par la réalisation d\'un état de\r\nl\'art de la diarization (segmentation et regroupement en locuteurs\r\n[Broux et al., 2019]) et de la détection de la parole superposée\r\n[Chowdhury et al, 2019]. Il s\'agira ensuite de proposer des solutions\r\nbasées sur des frameworks récents pour améliorer la localisation des\r\nfrontières de tours de parole, notamment lorsque la fréquence des\r\nchangements de locuteurs est importante - le cas limite étant la\r\nsituation du brouhaha.\r\n\r\nLa seconde partie du stage se penchera sur une mesure plus fine du\r\nniveau conflictuel des échanges, via la recherche des descripteurs les\r\nplus pertinents et par la mise au point d\'architecture d\'apprentissage\r\npour sa modélisation.\r\n\r\nLe langage de programmation utilisé dans le cadre de ce stage sera\r\nPython. Le stagiaire aura accès aux ressources de calcul de l\'INA\r\n(serveurs et clusters), ainsi qu\'à un desktop performant avec 2 GPU de\r\ngénération récente.\r\n    \r\nValorisation du stage\r\n    Différentes stratégies de valorisation des travaux du·de la\r\n    stagiaire seront envisagées, en fonction du degré de maturité des\r\n    travaux réalisés :\r\n    \r\n    - Diffusion des outils d\'analyse réalisés sous licence open-source\r\n      via le dépôt GitHub de l\'INA : https://github.com/ina-foss\r\n    -  Rédaction de publications scientifiques\r\n    \r\nConditions du stage\r\n    Le stage se déroulera sur une période de 4 à 6 mois, au sein du\r\n    service de la Recherche de l\'Ina. Il aura lieu sur le site Bry 2,\r\n    situé au 18 Avenue des frères Lumière, 94360 Bry-sur-Marne. La·le\r\n    stagiaire sera encadré·e par Marc Evrard (mevrard@ina.fr).\r\n    Gratification : environ 550 Euros par mois.\r\n    \r\nProfil recherché\r\n    - Étudiant·e en dernière année d\'un bac +5 dans le domaine de\r\n      l\'informatique et de l\'IA.\r\n    - Compétence en langage Python et expérience dans l\'utilisation de\r\n      bibliothèques de ML (Scikit-learn, TensorFlow, PyTorch).\r\n    - Vif intérêt dans les SHS, les humanités numériques et les sciences\r\n      politiques en particulier.\r\n    - Capacité à réaliser une étude bibliographique à partir d\'articles\r\n      scientifiques rédigés en anglais.\r\n    \r\nPour postuler, vous pouvez envoyer un email à mevrard@ina.fr comprenant\r\nun CV et une lettre de motivation.\r\n    \r\nBibliographie\r\n   Broux, P. A., Desnous, F., Larcher, A., Petitrenaud, S., Carrive,\r\n    J., & Meignier, S. (2018). \"S4D: Speaker Diarization Toolkit in\r\n    Python\". In Inter-speech 2018.\r\n   Chowdhury, S. A., Stepanov, E. A., Danieli, M., Riccardi,\r\n    G. (2019). \"Automatic classification of speech overlaps: Feature\r\n    representation and algo-rithms\", Computer Speech & Language,\r\n    vol. 55, pp.145-167.\r\n   Liénard, J.-S. \"Quantifying vocal effort from the shape of the\r\n    one-third octave long-term-average spectrum of speech\"\r\n    J. Acoust. Soc. Am. 146 (4), Oc-tober 2019.\r\n   Rilliard, A., d\'Alessandro, C & Evrard, M. (2018). Paradigmatic\r\n    variation of vowels in expressive speech: Acoustic description and\r\n    dimensional analysis. The Journal of the Acoustical Society of\r\n    America, 143(1), 109-122.'),
(611, '2019-12-16', 'Eloquant', 'Grenoble', 'Offre de stage\r\n\r\nSémantique : traitement automatique de la langue\r\n\r\nLe genre masculin est utilisé sans aucune discrimination et dans le seul but d\'alléger le texte.\r\n\r\nEloquant, spécialiste des solutions de Relation Client et du feedback client, recherche un stagiaire pour le\r\ndéveloppement d\'une catégorisation sémantique spécifique.\r\n\r\nInformations sur l\'offre\r\n\r\nDate cible de prise de poste : 02 mars 2020, pour 6 mois\r\n\r\nLocalisation du poste : Gières (siège social)\r\n\r\nType de contrat : Stage\r\n\r\nPour envoyer votre candidature : jobs_rd@eloquant.com\r\n\r\nStage\r\n\r\nDans le cadre de son offre Explore, Eloquant propose à ses clients\r\nd\'effectuer l\'analyse sémantique des verbatims (commentaires, avis,\r\nmails...) issus de leur propre clientèle et/ou du système\r\nd\'information. L\'analyse sémantique proposée permet, à partir d\'un\r\nverbatim fourni en entrée, d\'extraire diverses informations\r\nstructurées.  Le stage consiste à mener une étude des corpus issus de\r\ntranscriptions automatiques d\'appels téléphoniques pour dégager les\r\nentités pertinentes à relever, et développer les briques linguistiques\r\net logicielles permettant de les extraire, à l\'aide des formalismes\r\nutilisés par l\'équipe.\r\n\r\n\r\nTâches à réaliser\r\n\r\nLa technologie TAL d\'Eloquant inclut une composante d\'apprentissage\r\nmachine pour la classification automatique, et une composante «\r\nexperte » utilisant d\'une part des lexiques annotés, et d\'autre part,\r\ndes règles linguistiques pour l\'extraction de traits sémantiques pour\r\nl\'apprentissage machine, l\'extraction des fragments de texte exprimant\r\ndes opinions et des alertes, et pour la correction des résultats de\r\nclassification.  Le travail commencera donc par une prise en main de\r\nla technologie d\'Eloquant, avec en parallèle une définition des\r\nbesoins (volet en lien avec le marketing).\r\n\r\n\r\nLe stagiaire devra ensuite :\r\n\r\n- mener une étude des corpus afin de modéliser les éléments à\r\n  détecter, déterminer ce qui est possible compte tenu de la qualité\r\n  des données (volet linguistique),\r\n\r\n- effectuer plusieurs annotations des corpus, dont une pour\r\n  l\'identification des rôles des locuteurs, et d\'autres pour les\r\n  autres analyses (volet linguistique),\r\n\r\n- développer les briques linguistiques et logicielles d\'analyse\r\n  sémantique (volet développement),\r\n\r\n- évaluer les résultats en les confrontant aux annotations, et\r\nanalyser les erreurs (volet linguistique et développement).\r\n\r\nProfil\r\n\r\nLe candidat devra avoir de solides connaissances en linguistique\r\ncomputationnelle, et posséder des bases d\'un langage de programmation\r\n(de préférence Java). Il devra travailler en équipe (l\'équipe\r\nSémantique est composée d\'ingénieurs-linguistes,\r\nlinguistes-informaticiens et ingénieurs-informaticiens).  Il prendra\r\npart à la phase d\'études en amont, et devra pouvoir proposer et\r\nimplémenter des solutions.  Le stagiaire fera état de son avancement\r\nlors des points d\'équipe hebdomadaires, des points d\'avancement\r\ninternes bimensuels, et de points réguliers avec son encadrant\r\nacadémique.\r\n\r\nEntreprise\r\n\r\nSpécialiste de la Relation Client depuis 2001, ELOQUANT est le seul\r\nacteur du marché à proposer une solution globale, associant la gestion\r\nmulticanal des contacts entrants et sortants, les enquêtes en ligne et\r\nl\'analyse sémantique.  ELOQUANT a réalisé une croissance de plus de\r\n25% sur les 3 dernières années, et, grâce à une notoriété croissante\r\net une forte légitimité auprès des clients, a pour objectif\r\nd\'accélérer cette croissance dans les années à venir.'),
(612, '2019-12-16', 'Eloquant', 'Grenoble', 'Offre de stage\r\n\r\nSémantique : traitement automatique de la langue\r\n\r\nLe genre masculin est utilisé sans aucune discrimination et dans le seul but d\'alléger le texte.\r\n\r\nEloquant, spécialiste des solutions de Relation Client et du feedback\r\nclient, recherche un stagiaire pour le développement d\'une\r\ncatégorisation « Ressources Humaines ».\r\n\r\nInformations sur l\'offre\r\n\r\nDate cible de prise de poste : ASAP, pour 6 mois\r\n\r\nLocalisation du poste : Gières (siège social)\r\n\r\nType de contrat : Stage\r\n\r\n\r\nDans le cadre du développement de notre offre, nous recherchons un\r\nstagiaire dont la mission sera de développer une classification «\r\nressources humaines » pour les enquêtes RH des clients Eloquant. En\r\nparallèle, vous serez également amené à intervenir sur des projets\r\nclients avec pour principale mission de développer des classifieurs\r\nautomatiques de verbatim clients.\r\n\r\n\r\n- Recueillir les besoins de l\'équipe et des clients.\r\n\r\n- Définition des catégories, développement du système de machine\r\nlearning, des taxonomies, des lexiques et des règles linguistiques.\r\n\r\n- Confrontation des résultats avec l\'équipe métier (Pôle étude).\r\n\r\nLe stagiaire travaillera en étroite collaboration avec l\'équipe\r\nsémantique et le département Professional Services responsable de la\r\ngestion des clients.\r\n\r\nLe stage comprend deux étapes :\r\n- Développement du système de classification « RH »\r\n- Accompagnement sur des projets clients\r\n\r\nProfil\r\n- Enthousiasme et forte appétence à être en contact avec les clients\r\n- Compétences en traitement automatique des langues\r\n- Compétences en programmation (en Java serait un plus)\r\n\r\nEnvoyez votre candidature à : jobs_ps@eloquant.com\r\n\r\n\r\nEntreprise\r\n\r\nSpécialiste de la Relation Client depuis 2001, ELOQUANT est le seul\r\nacteur du marché à proposer une solution globale, associant la gestion\r\nmulticanal des contacts entrants et sortants, les enquêtes en ligne et\r\nl\'analyse sémantique.  ELOQUANT a réalisé une croissance de plus de\r\n25% sur les 3 dernières années, et, grâce à une notoriété croissante\r\net une forte légitimité auprès des clients, a pour objectif\r\nd\'accélérer cette croissance dans les années à venir.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(613, '2019-12-16', 'Latts & IGN', 'Champs-sur-Marne & Saint-Mandé', 'stage : Processus de construction sociale des incertitudes et des\r\nrisques en aménagement et urbanisme\r\n********\r\n\r\nMots clés : TAL, aménagement du territoire, environnement\r\n----------\r\n\r\nÉquipes de recherche et lieux du stage  \r\n---------------------------------------\r\nLatts  (Laboratoire Techniques, territoires, sociétés, École des Ponts\r\net Chaussées, CNRS, Université Paris Est). Champs-sur-Marne.\r\nLaSTIG (Laboratoire en Sciences et technologies de l\'information\r\ngéographique pour la ville et les territoires numériques,\r\nIGN). Saint-Mandé.\r\n\r\n\r\nDescription du projet de recherche  dans lequel s\'intègre le stage\r\n------------------------------------------------------------------\r\nL\'impact sur l\'environnement humain et naturel est un enjeu de plus en\r\nplus courant dans le processus de planification, réalisation et\r\nconcertation des projets d\'infrastructure et d\'urbanisme. Cela touche\r\nles grands projets (LGV, autoroutes, grands stades, etc) mais aussi, et\r\nde plus en plus, les micro-projets (lotissement, ZAC, centre\r\ncommercial). Un enjeu peut être érigé en risque par les associations,\r\nles habitants ou les élus locaux sur la base d\'une connaissance fine du\r\nterritoire et/ou d\'études spécialisées et expertes.\r\n\r\nCe risque pour l\'environnement, notamment s\'il contre les textes\r\nréglementaires sur la protection de l\'environnement, peut être utilisé\r\npar les acteurs pour s\'opposer au projet lors du débat public ou de\r\nl\'enquête publique ou à d\'autres moments du processus de décision. Cette\r\nopposition peut faire annuler, reporter ou modifier le projet\r\nd\'aménagement. Le recours gracieux ou contentieux est même de plus en\r\nplus fréquent, ce qui peut occasionner une incertitude ou un risque\r\nsocial, puis un risque de retard et un risque financier (pour le projet\r\net la collectivité locale ou le maître d\'ouvrage qui le pilotent).\r\n\r\nLe processus de construction des enjeux de territoire en incertitude\r\npuis en risque (et par conséquent la construction d\'une chaine\r\nd\'incertitudes ou de risques : social puis politique puis financier,\r\netc.) nécessite d\'être approfondi en raison de la multiplication des\r\nconflits fondés sur le risque, et des enjeux que cela pose en matière de\r\nconcertation, de participation et de politiques publiques d\'aménagement\r\net de protection de l\'environnement. Le cas de la construction de «\r\nfaux-risques » assimilables à des fake news serait aussi à explorer.\r\n\r\nPour comprendre la construction du discours des acteurs opposés à un\r\nprojet, et la construction des incertitudes et des risques, l\'objet du\r\nstage est de réaliser une analyse textuelle des positions de ces acteurs\r\n(recherche d\'occurrences de mots-clés par exemple) dans les registres de\r\ndébat public, les rapports de l\'enquête publique, de la concertation, la\r\npresse, etc. et de l\'interpréter.\r\n\r\nSujet du stage  (durée :  6 mois maximum)\r\n-------------------------------------------\r\nLe stage a pour objet de tester et de développer la démarche précédente\r\nsur un corpus de positions d\'acteurs (élus, associations, entreprises,\r\nhabitants, etc) issues de la concertation continue menée par la maîtrise\r\nd\'ouvrage publique et privée d\'une infrastructure de transport ou\r\nd\'urbanisme. Ce corpus sera constitué avant le début du stage.\r\n\r\nLe stage comporte les étapes suivantes :\r\n\r\n- appropriation selon le profil du-de la candidat-e des fondamentaux sur\r\n  les enjeux de contestation des projets, la construction\r\n  socio-technique du risque et les outils (analyse textuelle) ;\r\n- appropriation du corpus dans la diversité de ses textes (débat public,\r\n  enquête publique, articles de presse, sites internet, interviews,\r\n  etc.), des thématiques, des champs lexicaux, des niveaux de langue,\r\n  etc. ;\r\n- définition des incertitudes et risques analysés. Il peut s\'agir de\r\n  risques sociaux (opposition des associations ou habitants à un projet)\r\n  ; de risques politiques (opposition des élus) ; de risques\r\n  environnementaux (impact du projet sur l\'environnement naturel et\r\n  humain) ; de risques juridiques ; de risques financiers ou de retard.\r\n- traduction de ces incertitudes et risques en éléments linguistiques :\r\n  mots-clés, champs lexicaux spécifiques, verbes modaux, indices de\r\n  prise en charge du discours par le locuteur, etc., ou statistiques :\r\n  fréquences, répartitions, analyse contrastive entre sous-corpus, etc.,\r\n  à rechercher ;\r\n- état de l\'art des ressources et outils existants adaptés à\r\n  l\'identification (automatique) de ces éléments linguistiques, et mise\r\n  en oeuvre de ces outils sur le corpus sélectionné ;\r\n- analyse des résultats ;\r\n- bilan de la recherche.\r\n\r\nLes résultats de cette recherche exploratoire sont destinés aux\r\norganismes publics ou privés en charge d\'une concertation et au milieu\r\nassociatif qui y participe.\r\n\r\nDébouchés de la recherche et du stage\r\n----------------------------------------\r\nCette recherche exploratoire a pour objet de déboucher sur l\'étude d\'un\r\nmode de représentation de la construction du risque, ce qui peut\r\npermettre de visualiser la façon dont un impact pressenti à un endroit\r\nde la concertation est transformé en risque. Une poursuite de la\r\nrecherche par une thèse peut être envisagée avec deux voies :\r\n\r\n- tester un mode de représentation du processus de construction du\r\n  risque dans le temps et dans l\'espace et adapté à un public donné\r\n  (cartographie par exemple).\r\n\r\n- élargir la recherche à d\'autres projets comme les ZAC, les\r\n  lotissements, les équipements de loisirs, etc.\r\n\r\nProfil du/de la candidat-e\r\n--------------------------\r\n- Master 2 Aménagement et Urbanisme, intéressé-e par l\'informatique et\r\n  l\'analyse de discours.\r\n- Master 2 en Traitement automatique des langues, intéressé-e pour\r\n  travailler sur un corpus de textes issus de la concertation d\'un\r\n  projet d\'infrastructure ou d\'urbanisme\r\n\r\n\r\nContacts : \r\n----------\r\nLe dossier de candidature devra contenir les documents suivants :\r\n- CV,\r\n- lettre de motivation,\r\n- derniers relevés de notes (M1, et premier semestre de M2 si\r\n  disponible),\r\n- description des enseignements suivis (un lien vers le site internet de\r\n  la formation est le bienvenu),\r\n- dernier mémoire ou rapport de stage rédigé,\r\n\r\net est à envoyer avant le 20 janvier 2020 à :\r\nGeneviève ZEMBRI-MARY, professeure en Aménagement et Urbanisme,\r\nuniversité de Cergy-Pontoise, en délégation CNRS au Laboratoire\r\ntechniques territoires sociétés (Latts-UPEM, ENPC, CNRS),\r\nGenevieve.zembri-mary@enpc.fr\r\n\r\nCatherine DOMINGUÈS, chargée de recherche au Laboratoire en sciences et\r\ntechnologies de l\'information géographique (LaSTIG, IGN),\r\nCatherine.Domingues@ign.fr'),
(614, '2019-12-16', 'LIPN', 'Villetaneuse', 'Title: Multitask Learning of Easy-first Hierarchical Tree LSTMs for Joint Syntactic and Semantic Arabic Dependency Parsing\r\n\r\n\r\nContext: Collaboration between RCLN (https://lipn.univ-paris13.fr/accueil/equipe/rcln/), LIPN, Université Paris 13, and CAMeL Lab (https://bit.ly/2M0XsAG), New York University Abu Dhabi\r\n\r\nHost lab: LIPN, Université Paris 13, 99 Avenue Jean Baptiste Clément,\r\n93430 Villetaneuse\r\n\r\nSupervisors: Joseph Le Roux and Nadi Tomeh\r\n\r\nCollaborators: Nizar Habash and Dima Taji\r\n\r\nStart date: February 2020\r\n\r\nDuration: 6 months\r\n\r\nSalary: 550 euros/month\r\n\r\nProfile and required skills:\r\n\r\n- Masters in Computer Science, Computational Linguistics, Applied\r\nMathematics, or Statistics\r\n\r\n- Knowledge in Natural Language Processing and Deep Learning is highly\r\nappreciated\r\n\r\n- Programming skills in Python (and libraries such as pytorch, numpy,\r\nor scikit-learn)\r\n\r\nHow to apply: send CV and available Masters\' grades to tomeh@lipn.fr\r\nand leroux@lipn.fr\r\n\r\n\r\nDescription:\r\n\r\nIn recent work on semantic parsing, Peng et al. [2017; 2018]; and\r\nKurita and Søgaard [2019] showed that the overlap between three\r\ndifferent theories of semantics and their corresponding\r\nrepresentations can be exploited to improve performance on all three\r\ntasks. This is done using multitask learning in a deep neural\r\narchitecture. We would like to explore ways in which this approach can\r\nbe applied to Arabic, which has rich morphology and complex\r\nmorpho-syntactic interactions. We will work with two different\r\ndependency representations. The first is the Columbia Arabic Treebank\r\n(CATiB) representation [Habash and Roth, 2009], which is inspired by\r\nArabic traditional grammar and which focus on modeling syntactic and\r\nmorpho-syntactic agreement and case assignment.  The second is the\r\nUniversal Dependency (UD) representation for Arabic [Taji et al.,\r\n2017], which has relatively more focus on semantic/thematic relations\r\nwithin the sentence, and which is coordinated in design with a number\r\nof other languages [Nivre et al., 2016]. The two representations\r\ncomplement each other and stand to benefit from multitask learning\r\napproaches.\r\n\r\nIn this context, we propose to\r\n\r\n(i) Extend the easy-first hierarchical LSTM parser of Kiperwasser and\r\nGoldberg [2016] to multitask settings. We have shown that this\r\napproach can be useful for joint lexical segmentation and dependency\r\nparsing [Constant et al., 2016]. In that work we used as our\r\nsingle-task model the easy-first parser of Goldberg and Elhadad [2010]\r\ntrained with dynamic oracles [Goldberg and Nivre, 2013];\r\n\r\n(ii) Apply the model to parse Arabic sentences to both CATiB and UD\r\nrepresentations;\r\n\r\n(ii) Employ multitask modeling insights from Peng et al. [2017; 2018];\r\nand Kurita and Søgaard [2019] to enhance the multitask easy-first\r\nparser.\r\n\r\n\r\nReferences\r\n\r\n    Peng, Hao, Sam Thomson and Noah A. Smith. \"Deep Multitask Learning\r\n    for Semantic Dependency Parsing.\" ACL (2017).\r\n\r\n    Peng, Hao, Sam Thomson, Swabha Swayamdipta and Noah\r\n    A. Smith. \"Learning Joint Semantic Parsers from Disjoint Data.\"\r\n    NAACL-HLT (2018).\r\n\r\n    Kurita, Shuhei and Anders Søgaard. \"Multi-Task Semantic Dependency\r\n    Parsing with Policy Gradient for Learning Easy-First Strategies.\"\r\n    ACL (2019).\r\n\r\n    Nizar Habash and Ryan M. Roth. \"CATiB: The Columbia Arabic\r\n    Treebank.\" Proceedings of Annual Meeting of the Association for\r\n    Computational Linguistics, 2009.\r\n\r\n    Dima Taji, Nizar Habash, and Daniel Zeman. \"Universal Dependencies\r\n    for Arabic.\" Proceedings of the Workshop on Arabic Natural\r\n    Language Processing (with EACL), 2017.\r\n\r\n    Yoav Goldberg and Michael Elhadad. 2010. An efficient algorithm\r\n    for easy-first non-directional dependency parsing. In Human\r\n    Language Technologies: NAACL, pages 742-750, Los Angeles,\r\n    California.\r\n\r\n    Eliyahu Kiperwasser and Yoav Goldberg. 2016. Easy-first dependency\r\n    parsing with hierarchical tree LSTMs. Transactions of the\r\n    Association for Computational Linguistics, 4, 445-461.\r\n\r\n    Mathieu Constant, Joseph Le Roux, Nadi Tomeh. Deep Lexical\r\n    Segmentation and Syntactic Parsing in the Easy-First Dependency\r\n    Framework. NAACL, 2016, San Diego, United States.'),
(615, '2020-01-06', 'SNCF', 'Saint-Denis', 'La Direction Innovation et Recherche et la Direction Générale Sécurité\r\nde la SNCF recherchent un stagiaire pour contribuer à l\'évaluation d\'un\r\nmoteur de recherche interne.\r\n\r\nTitre : Évaluation d\'un moteur de recherche d\'entreprise sur un corpus\r\nmétier SNCF\r\n\r\n*Contexte*\r\n------------------------------\r\nDans le cadre un programme de transformation documentaire, SNCF fait\r\névoluer le moteur de recherche utilisé sur une base de documents métiers\r\ninternes. En 2019, des travaux ont permis de faire un bilan des limites\r\ndu moteur de recherche actuel, de pré-qualifier les besoins en\r\ninformation sur la base d\'un historique de requêtes et d\'identifier des\r\ncritères de paramétrage du nouveau moteur. Le paramétrage de ce nouveau\r\nmoteur est prévu courant 2020. Il s\'accompagnera d\'un protocole\r\nd\'évaluation, qui nécessite de définir un jeu de requêtes de test, des\r\nmétriques de pertinence et de mettre en oeuvre le protocole d\'évaluation.\r\n\r\n\r\n*Description *\r\n------------------------------\r\nLe stagiaire devra :\r\n\r\n- Prendre connaissance du contexte du stage (SNCF, objectifs du stage et\r\n  cadre de réalisation, programme de rattachement : programme PRISME et\r\n  Plateau Simplification de la Direction Générale Sécurité, projet dans\r\n  lequel le stage s\'insère et interlocuteurs sur les sujets concernés),\r\n\r\n- Réaliser une analyse descriptive des données utilisées en entrée\r\n  (corpus documentaire et historique de requêtes), par une analyse\r\n  sémantique et statistique. L\'analyse sera réalisée à l\'aide d\'outils\r\n  de lexicométrie et d\'outils statistiques,\r\n\r\n- Étudier les méthodes d\'évaluation de moteur de recherche et leur\r\n  application pratique dans le contexte du stage,\r\n\r\n- Proposer un protocole d\'évaluation du moteur, à travers la définition\r\n  et la construction d\'un jeu de données de test, ainsi que la\r\n  proposition de métriques.\r\n\r\n\r\nPrésentations et rapports :\r\n\r\n- Présentation de début de stage à la SNCF (au bout d\'un mois de stage)\r\n  : contexte du stage, planning de réalisation et premiers travaux\r\n  réalisés.\r\n\r\n- Rapport final de stage complet comprenant : méthodologie utilisée,\r\n  travaux réalisés, résultats obtenus et problèmes rencontrés\r\n\r\n- 2 soutenances de fin de stage : une à l\'école et une à la SNCF.\r\n\r\n- Des présentations en interne SNCF ou externes pourront être\r\n  effectuées.\r\n\r\n\r\n*Profil recherché*\r\n------------------------------\r\n\r\nNiveau : De formation Bac+5 en Sciences du langage/Traitement\r\nAutomatique du Langage Naturel ou Data Science / Statistiques.\r\n\r\nCompétences attendues :\r\n\r\n- Capacités d\'analyse, de rédaction et de synthèse\r\n\r\n- Autonomie, qualités relationnelles, qualités de présentation\r\n  (orale/écrite).\r\n\r\n- Connaissances en Traitement Automatique du Langage et linguistique\r\n\r\n- Compétences en statistiques\r\n\r\nCompétences additionnelles souhaitées :\r\n\r\n- Maîtrise d\'outils de lexicométrie/textométrie\r\n\r\n- Maîtrise de R\r\n\r\n- Compétences en informatique (programmation)\r\n\r\n\r\n*Modalités du poste*\r\n------------------------------\r\n\r\n   - Durée : 6 mois\r\n   - Rémunération prévue : indemnités de stage + carte de circulation\r\n     SNCF sur le réseau national\r\n   - Début : à partir de mars 2019\r\n   - Lieu : Saint-Denis\r\n\r\n\r\nMerci d\'adresser CV et lettre de motivation à Luce Lefeuvre et Coralie\r\nReutenauer aux adresses mail suivantes :\r\nluce.lefeuvre@sncf.fr,\r\ncoralie.reutenauer@sncf.fr'),
(616, '2020-01-06', 'LIMSI', 'Orsay', '*Veille scientifique automatisée / Scientific Survey Automation*\r\n(English description below)\r\n\r\n- Lieu du stage : LIMSI, Orsay (91)\r\n- Durée : Stage de 5 mois, pouvant démarrer après obtention de l\'accord\r\n  du fonctionnaire de défense (délai maximum de 2 mois après soumission\r\n  du dossier), le LIMSI étant une Zone à Régime Restrictif et signature\r\n  d\'une convention de stage entre le CNRS votre établissement\r\n  d\'enseignement d\'origine (délai environ 1 mois).\r\n- Indemnités de stage : le montant des indemnités de stage est d\'environ\r\n  568 ¤ par mois.\r\n- Encadrants : Ce stage s\'effectue dans le cadres d\'un projet\r\n  scientifique interne au LIMSI (une des \"actions incitatives\" de 2020),\r\n  avec comme encadrant principal Patrick Paroubek (groupe ILES) pour les\r\n  aspects fouille d\'opinion et scientométrie, Cyril Grouin (groupe ILES)\r\n  pour les aspects extraction d\'information et traitement de corpus,\r\n  Bérengère Podvin (groupe AERO ) pour la mécanique des fluides et\r\n  Michel Pons (groupe TSF) pour la mécanique énergétique.\r\n- Contact Patrick Paroubek, pap@limsi.fr, merci de mentionner \"stage\r\n  veille scientifique\" dans le sujet (thanks for mentioning \"Science\r\n  Survey Internship\" in the subject),\r\n  https://perso.limsi.fr/pap/internship_AI2020_science_survey/\r\n\r\n*Description*\r\n\r\nLe but de ce stage est de mener une étude pour savoir dans quelle mesure\r\non peut automatiser la construction d\'une réponse à la aux questions\r\nsuivantes :\r\n- Si je suis un chercheur, étant donné : mon domaine de recherche, les\r\n  articles que j\'ai publiés et les connaissances du domaine,\r\n- Quels sont les articles parmi un ensemble d\'articles que j\'ai à\r\n  relire, ceux qui vont susciter mon intérêt ?\r\n- Quels sont dans le contenu textuel des articles, les indices qui ont\r\n  déclenché mon intérêt ? et Pourquoi ? A cause de leur nouveauté ou\r\n  bien au contraire à cause de leur similarité avec des idées qui ont\r\n  déjà été abordées par d\'autres chercheurs ?\r\n\r\nL\'expérience comprendra plusieurs parties distinctes:\r\n\r\n- Élaborer, en se basant sur des interviews d\'experts du domaine et\r\n  d\'articles fournis eux, une description des critères d\'intérêt et de\r\n  leur différentes réalisations linguistiques, comme par exemple les\r\n  noms d\'auteurs connus, la présence de certaines références\r\n  bibliographiques, d\'une argumentation particulière, de la mention\r\n  d\'idées nouvelles ou importées d\'autres disciplines, de références à\r\n  des thèmes spécifiques, des expressions d\'opinions sur certaines\r\n  approches etc.\r\n- Utiliser les algorithmes d\'extraction d\'information [6] et d\'analyse\r\n  du langage naturel pour repérer et classer les mentions d\'indices\r\n  suscitant l\'intérêt dans les contenus textuels d\'un ensemble\r\n  d\'articles [1]\r\n- Utiliser les marqueurs d\'intérêt identifiés pour classer\r\n  automatiquement les articles par ordre décroissant d\'intérêt\r\n- Concevoir et implémenter une évaluation de la performance du\r\n  classement obtenu à partir d\'articles déjà publiés (une mesure\r\n  d\'évaluation possible pourrait utiliser le nombre de citations d\'un\r\n  article)\r\n\r\n\r\n*Moyens*\r\n\r\nLes travaux combineront une approche linguistique et/ou une approche de\r\ngestion des connaissances pour descrire des critères d\'intérêt qui\r\nseront mis en relation avec les algorithmes état de l\'art en fouille de\r\ntextes scientifiques [2][3]. Une fois les critères définis en\r\ncollaboration avec les chercheurs de deux domaines applicatifs : d\'une\r\npart le Traitment Automatique des Langues et d\'autre part la mécanique\r\ndes fluides - mécanique énergétique, le/la stagiaire\r\ndéploiera/développera des algorithmes d\'extraction d\'information et\r\nd\'analyse automatique du langage naturel dans une environnement Unix\r\npour implémenter la chaîne de traitement informatisée chargée d\'annoter\r\net de classer les articles scientifiques fournis en entrée de la chaîne.\r\n\r\n*Données/corpus*\r\n\r\nLes données qui seront utilisée pour les tests d\'automation avec la\r\nchaîne de traitement seront constituées d\'une part du corpus NLP4NLP\r\n[4][5] contenant 64953 articles représentatif de la littérature\r\nscientifique du domaine du Traitement Automatique des Langues, publiée\r\nsur une période de 50 ans (http://www.nlp4nlp.org/) et d\'autre part des\r\npublications de mécanique des fluides / mécanique énergétique\r\ndisponibles dans la base des publications du LIMSI.\r\n\r\n*Profil de recherche*\r\n\r\nLinguiste, linguiste-informaticien(ne)-TAListe, ou informaticien(ne).\r\nDes compétences en spécifiques en linguistique, gestion des\r\nconnaissances, traitement automatique des langues, extraction\r\nd\'information ou apprentissage automatique seront appréciées. En\r\nfonction du profil de recherche, l\'accent pourra être mis sur la\r\ndéfinition formelle des critères d\'intérêt (formalisation linguistique)\r\nou sur les aspects extraction d\'information précise (identification des\r\ncritères) ou bien encore sur l\'apprentissage automatique pour construire\r\nla représentation de la question de recherche à partir d\'un ensemble\r\nd\'articles et son évaluation. Dans tous les cas une autonomie pour la\r\nmise en place d\'une chaîne de traitement de corpus dans un environnement\r\nUnix est indispensable (des compétences en programmation Python seront\r\nappréciées).\r\n\r\n*Bibliographie*\r\n\r\n1 Romaric Besançon, Anne-Laure Daquo, Clustering de documents dans des\r\n  collections hétérogènes, Document numérique 2015/2-3 (Vol. 18), pages\r\n  81 à 100,\r\n  https://pdfs.semanticscholar.org/7c6a/b9f77507b0a585dbd7328fbc2d50e0315ac0.pdf\r\n2 Steffen Eger, Chao Li, Florian Netzer, Iryna Gurevych, Predicting\r\n  Research Trends From Arxiv, 2019,\r\n  https://www.researchgate.net/publication/331587503_Predicting_Research_Trends_From_Arxiv\r\n3 Kata Gábor, Isabelle Tellier, Thierry Charnois, Haïfa Zargayouna,\r\n  Davide Buscaldi, Détection et classification non supervisées de\r\n  relations sémantiques dans des articles scientifiques, Actes de la\r\n  conférence conjointe JEP-TALN-RECITAL 2016, volume 2 : TALN,\r\n  http://www.lattice.cnrs.fr/sites/itellier/articles/TALN2016b.pdf\r\n4 Joseph Mariani, Gil Francopoulo, Patrick Paroubek, The NLP4NLP Corpus\r\n  (I): 50 Years of Publication, Collaboration and Citation in Speech and\r\n  Language Processing, 2019\r\n  https://www.frontiersin.org/articles/10.3389/frma.2018.00036/full\r\n5 Joseph Mariani, Gil Francopoulo, Patrick Paroubek, Frédéric Vernier,\r\n  The NLP4NLP Corpus (II): 50 Years of Research in Speech and Language\r\n  Processing, 2019,\r\n  https://www.frontiersin.org/articles/10.3389/frma.2018.00037/full\r\n6 Laure Soulier, Définition et évaluation de modèles de recherche\r\n  d\'information collaborative basés sur les compétences de domaine et\r\n  les rôles des utilisateurs, Thèse de doctorat d\'informatique, 2014,\r\n  https://hal.archives-ouvertes.fr/tel-01110721/document\r\n\r\n\r\nENGLISH VERSION\r\n\r\n*Description*\r\n\r\nThe goal of this internship is to perform a study to know whether it is\r\npossible automatizing the elaboration of an answer to the following\r\nquestion:\r\nIf I am a researcher, given: my research domain, the articles I already\r\npublished and the knowledges of the domain,\r\nWhich, among some articles that I have to read, are the ones that will \r\nspark my interest?\r\nWhich are the specific clues in the text content of the articles that \r\nsparked my interest ? and Why? Because of their novelty? Or because they \r\nare similar to ideas that have already addressed by other researchers?\r\n\r\nThe experiment will address several points:\r\n- From domain expert interviews and the reading of articles provided by\r\n  these experts, write a description of the criteria associated to a\r\n  sparking of interest from the reader and of their various linguistic\r\n  realizations, for instance : the occurrence of the name of renown\r\n  authors of the field, the presence of certain bibliographic\r\n  references, of a particular claim or argument, the mention of novel\r\n  ideas or concepts imported from other disciplines, the existence of\r\n  references to specific topics or opinions expressed about particular\r\n  approaches etc.\r\n- Deploy information extraction [6] and natural language processing\r\n  algorithms to identify and classify the occurrences of interest clues\r\n  in the text content of a set of scientific articles [1]\r\n- Use the interest markers identified to rank the articles automatically\r\n  in decreasing order of interest\r\n- Design and implement an evaluation of the performance of the ranking\r\n  obtained on already published articles (a possible evaluation measure\r\n  can be based on the number of citation of an article)\r\n\r\n*Means*\r\n\r\nThe work will combine a linguistic approach and/or a knowledge\r\nmanagement approach for describing interest criteria which will be used\r\nlater with state of the art algorithms in scientific publication mining\r\n[2][3]. Once the criteria will have been defined in collaboration with\r\nexperts from two application domains: on the one hand Natural Language\r\nProcessing and on the other hand fluid mechanics and energy, the intern\r\nwill deploy/develop information extraction and natural language\r\nprocessing algorithms in a Unix environment to implement a processing\r\npipeline to annotate and rank the scientific articles given as input to\r\nthe pipeline.\r\n\r\n*Data/Corpora*\r\n\r\nThe data that will be used for testing the automation process performed\r\nwith the pipeline will be taken on the one hand from the NLP4NLP corpus\r\n[4][5] which contains 64953 articles representative of Natural Language\r\nProcessing literature over a period of 50 years\r\n(http://www.nlp4nlp.org/) and on the other hand from the publication\r\ndatabase of the fluid mechanics and energy department of LIMSI.\r\n\r\n*Research Profile*\r\n\r\nLinguist, linguist-computer-scientist-NLPist, or computer scientist.\r\nSpecific experience in linguistics, knowledge managements, natural\r\nlanguage processing, information extraction or machine learning will be\r\nappreciated. Depending on the research profile, focus can be put on the\r\nformal definition of the criteria for interest sparking (linguistic\r\nformalization) or on the precise information extraction aspect (criteria\r\nidentification) or also on machine learning for building the\r\nrepresentation of the research question of interest from a set of\r\narticles and on its evaluation. In all cases, an autonomy for deploying\r\na corpus processing pipeline in a Unix environment is required (practice\r\nof Python programming language will be a plus).'),
(617, '2020-01-06', 'LIMSI', 'Orsay', '- Lieu : LIMSI, Orsay (91), RER B Le Guichet, Orsay-ville, ou \r\n  Gif-sur-Yvette + bus\r\n- Durée : 5 mois, gratifications de stage et remboursement des frais de\r\n  transports\r\n- Niveau : M2\r\n- Profil : formation en TAL, goût pour l\'analyse des données\r\n- Encadrants : Gilles Adda (gadda@limsi.fr) et Cyril Grouin\r\n  (cyril.grouin@limsi.fr)\r\n\r\n*Description*\r\n\r\nLes médias entretiennent des rapports complexes avec la société. Ils\r\ndécrivent la société, mais en retour ils contribuent également à\r\nfaçonner notre représentation du monde. Dans le cadre d\'un projet plus\r\nvaste, nous envisageons de décrire les différences objectives de\r\nreprésentation et de traitement existant entre les femmes et les hommes\r\ndans les médias. A ce titre, nous proposons un stage sur l\'analyse des\r\ntranscriptions manuelles ou automatiques de la parole pour identifier le\r\ngenre des locuteurs.\r\n\r\nPour cela, plusieurs tâches sont possibles :\r\n- catégoriser les entités nommées existantes en genre, soit parmi deux\r\n  classes (femme/homme), soit parmi plusieurs classes\r\n  (femme/homme/autre)\r\n- étendre cette catégorisation en genre aux éléments linguistiques qui\r\n  permettent d\'identifier le genre\r\n- identifier les thèmes et sujets évoqués dans le discours et dans les\r\n  textes\r\n- identifier les références à la vie privée (âge, physique, sexualité,\r\n  vêtements, etc.)\r\n\r\nLes travaux s\'appuieront sur des corpus existants de transcription de la\r\nparole (corpus Ester et Quaero Broadcast News). Des annotations existent\r\ndéjà en entités nommées (Quaero), et des méta-données sur les locuteurs\r\nsont disponibles (Ester).\r\n\r\nL\'objectif final est de pouvoir s\'appuyer sur les éléments identifiés à\r\nl\'occasion de ce stage pour analyser et décrire les différences de\r\ntraitement entre femme et hommes, par exemple lors des interruptions de\r\nparole des femmes par les hommes (manterrupting), ou lors de\r\nréexplications condescendantes par des hommes (mansplaining).\r\n\r\nProfil de recherche\r\n\r\nLinguiste, linguiste-informaticien(ne)-TAListe, ou informaticien(ne).\r\nDes compétences en linguistique, traitement automatique des langues, et\r\nextraction d\'information seront appréciées. Dans tous les cas, une\r\nautonomie pour la mise en place d\'une chaîne de traitements dans un\r\nenvironnement Unix est indispensable.'),
(618, '2020-01-06', 'ATILF & IHRIM', 'Nancy ou Lyon', 'Titre: lemmatisation automatique de l\'ancien français\r\n\r\nDurée:  5 à 6 mois\r\nEncadrement: Mathieu Constant (ATILF, Université de Lorraine) et Alexei\r\n             Lavrentiev (IHRIM, ENS Lyon)\r\n\r\nLieu: laboratoire Analyse et Traitement Informatique de la Langue\r\n      Française (ATILF), Nancy\r\n      ou éventuellement, Institut d\'Histoire des Représentations et des\r\n      Idées dans les Modernités (IHRIM), Lyon\r\n\r\nGratification standard\r\n\r\nContact: Mathieu Constant (Mathieu.Constant@univ-lorraine.fr) et Alexei\r\nLavrentiev (alexei.lavrentev@ens-lyon.fr)\r\n\r\nCompétences requises:\r\nmaster de traitement automatique des langues ou linguistique\r\n  informatique\r\nbonnes compétences de programmation (python ou/et java)\r\nle gout de mettre le nez dans les données\r\n\r\nDescription:\r\n\r\nLe thème de recherche du stage s\'inscrit dans le cadre du projet ANR\r\nProfiterole (2017 - 2021). Ce projet a trois objectifs fortement\r\ncorrélés qui se situent dans les domaines de la linguistique et du\r\ntraitement automatique des langues (TAL).  Le premier objectif est de\r\nmodéliser les aspects morphologiques et syntaxiques de l\'évolution\r\ndiachronique du français. Le deuxième objectif est de développer une\r\nméthodologie pour explorer et annoter des données linguistiques\r\nhétérogènes tout en fournissant des analyseurs automatiques pour\r\ndifférents états du français. Le dernier objectif est d\'augmenter la\r\ncouverture des ressources linguistiques existantes pour le français, en\r\nconstruisant un corpus annoté de français médiéval (IXe - XVe siècles)\r\net des lexiques morphologiques couvrant plusieurs états du français.\r\n\r\nLe stage sera dédié à la tâche de lemmatisation de l\'ancien\r\nfrançais. Cette tâche consiste à automatiquement prédire la forme de\r\nbase d\'une forme fléchie d\'un mot apparaissant dans un texte dans le but\r\nde rechercher ce mot dans des dictionnaires ou de neutraliser les\r\nvariations morphologiques. L\'ancien français, qui est une langue\r\nnon-standardisée, est caractérisé par une variation morphologique bien\r\nplus importante qu\'en français moderne, ce qui complexifie la tâche de\r\nlemmatisation. Par ailleurs, les données annotées manuellement pour\r\ncette tâche sont rares ce qui rend difficile l\'utilisation d\'approches\r\nreposant sur l\'apprentissage automatique. Une autre difficulté est qu\'il\r\nn\'existe pas de standard pour les formes lemmatisées en ancien français,\r\nbien que des initiatives de standardisation soient en cours. Différentes\r\nétudes se sont penchées sur le problème de la lemmatisation de l\'ancien\r\nfrançais en utilisant diverses approches: par exemple, l\'utilisation de\r\nlexiques et de règles (Souvay et Pierrel 2009), l\'utilisation d\'outils\r\nexistants de lemmatisation réappris pour l\'ancien français (Stein 2007,\r\nLavrentiev et al. 2017), l\'utilisation d\'une architecture neuronale\r\n(Manjavacas et al. 2019).\r\n\r\nL\'objectif principal du stage est de développer un outil de\r\nlemmatisation pour l\'ancien français en s\'appuyant sur des outils\r\nexistants, des corpus annotés et des ressources lexicales. Plus\r\nparticulièrement, les objectifs détaillés sont les suivants:\r\n\r\n- lire la littérature sur la lemmatisation pour l\'ancien français\r\n\r\n- compiler et préparer les données disponibles \r\n- expérimenter divers lemmatiseurs existants adaptés aux données\r\n  préparées\r\n- développer un lemmatiseur reposant sur plusieurs sources d\'information\r\n  (ressources lexicales, corpus annotés et sorties des lemmatiseurs\r\n  existants, plongements de mots)\r\n- évaluer l\'outil à la fois quantitativement et qualitativement\r\n\r\n\r\nRéférences \r\n\r\n- Alexei Lavrentiev, Serge Heiden, and Matthieu Decorde. Building an\r\n  Open Morphological Lexicon and Lemmatizing Old French Texts with the\r\n  TXM Platform. In Corpus linguistics - 2017, Proceedings of the\r\n  international conference \"Corpus linguistics - 2017\", pages 48-52,\r\n  St-Pétersbourg, Russia, 2017. St-Petersburg State University and\r\n  Institute for Linguistic Studies (RAS) and Herzen State Pedagogical\r\n  University of Russia.\r\n- Enrique Manjavacas, Ákos Kádár, and Mike Kestemont. Improving\r\n  lemmatization of non-standard languages with joint learning. In\r\n  Proceedings of the 2019 Conference of the North American Chapter of\r\n  the Association for Computational Linguistics: Human Language\r\n  Technologies, Volume 1 (Long and Short Papers), pages 1493-1503,\r\n  Minneapolis, Minnesota, June 2019. Association for Computational\r\n  Linguistics.\r\n- Gilles Souvay and Jean-Marie Pierrel. LGeRM Lemmatisation des mots en\r\n  Moyen Français. Traitement Automatique des Langues, 50(2):21, 2009.\r\n- Achim Stein. Corpus-based perspectives in linguistics. In Yuji\r\n  Kawaguchi, editor, Computing Machinery and Intelligence, pages\r\n  217-229. Benjamins, 2007.'),
(619, '2020-01-07', 'ViaDialog', 'Lannion', 'ViaDialog\r\nCustomer Interactions Management\r\n\r\nVENEZ DÉVELOPPER LA RELATION CLIENT DU FUTUR AVEC NOUS !\r\n\r\nRECHERCHE DATA SCIENTIST (H/F)\r\n\r\nÀ PROPOS\r\n\r\nDepuis 2004, ViaDialog innove dans l\'industrie de la gestion des\r\ninteractions clients. Nos solutions SaaS permettent aux PME et aux\r\nGrands comptes de communiquer avec leurs clients sur tous les canaux\r\nvia des téléconseillers et/ou des assistants virtuels. L\'excellence\r\ntechnique et la QoS sont au coeur de notre stratégie. Entreprise de 50\r\ncollaborateurs enthousiastes, ingénieux et audacieux, nous évoluons au\r\nquotidien dans un marché stimulant et concurrentiel.\r\n\r\nNous recherchons un(e) stagiaire Data Scientist pour notre offre\r\nViaSpeech, notre ensemble de solutions (ASR, NLU, NLP) qui permet la\r\nqualification, le traitement, l\'analyse et l\'automatisation des\r\ndialogues clients vocaux.\r\n\r\nRESPONSABILITÉS\r\n\r\nEn relation avec le Product Owner et en support aux équipes de\r\ndéveloppement de la solution, vous serez amené(e) à :\r\n\r\n- Accompagner les équipes de Viadialog dans la structuration des données.\r\n\r\n- Accompagner les équipes de ViaDialog dans la constitution de corpus\r\n  de données d\'intérêt et tester le comportement de ces corpus.\r\n\r\n- Identifier les marqueurs sémantiques propre à chaque corpus\r\n  génériques.\r\n\r\n- Accompagner les équipes techniques dans l\'intégration des corpus\r\n  génériques dans les solutions actuelles.\r\n\r\n- Prendre part aux brainstormings, à la conception et à la promotion\r\n  de la solution.\r\n\r\nQUALIFICATIONS\r\n\r\nIntérêt réel pour les chatbots et les voicebots et les technologies\r\nd\'analyse du langage naturel et de la reconnaissance vocale (STT, TTS,\r\nSpeaker recognition, Emotion Analysis, ...).\r\n\r\nAutonome, curieux(se) et volontaire.\r\n\r\nCompétences avancées en Python, Connaissance académique des\r\nenvironnements et des framework de Machine Learning.\r\n\r\nFormation de niveau Bac +5 dans le domaine de l\'Intelligence\r\nArtificielle ou du traitement Big Data.\r\n\r\nINFOS\r\n\r\nAmbiance stimulante dans un environnement en plein essor, conditions\r\nde stage flexibles.\r\n\r\nPerspectives d\'évolution au sein de l\'entreprise. Le stage est basé à\r\nLANNION (22) avec des déplacements ponctuels à Paris.\r\n\r\nEnvoyez-nous votre lien linkedin (ou votre CV) par e-mail à\r\nrecrutement@viadialog.com'),
(620, '2020-01-15', 'Lattice', 'Montrouge', '*** Modélisation de l\'évolution des langues ***\r\n\r\nStage de M2 proposé par le laboratoire Lattice (Montrouge)\r\n\r\n* Motivations et contexte\r\n\r\nIl est aujourd\'hui admis que le changement linguistique s\'inscrit dans\r\nun continuum. A. Kroch (1989) a ainsi mis au jour, pour certains\r\nchangements (par exemple, l\'évolution du sens des mots), un schéma\r\nd\'évolution souvent qualifié de « courbe en S » (S-curve) : dans un\r\npremier temps, les emplois augmentent lentement, gagnant progressivement\r\nde nouveaux contextes, puis, dans un second temps, leur fréquence\r\ns\'accroît rapidement et pareillement en tous contextes, avant de\r\nralentir, formant ainsi une sorte de palier. Établir les temporalités\r\nexactes - durée et rythme - n\'est pas simple et suppose de travailler\r\nsur un corpus suffisamment représentatif du ou des état(s) de langue\r\ndans le(s) quel(s) s\'inscrit l\'évolution du phénomène.\r\n\r\nCe type d\'évolution a été étudié et observé sur différents corpus et\r\ndifférentes langues, notamment le français par Quentin Feltgen dans sa\r\nthèse (2017). Le but du stage est de reprendre ce type d\'expériences\r\npour d\'autres langues (allemand, italien, espagnol...) pour lesquelles de\r\ntels corpus existent.\r\n\r\nA partir de scripts existants pour différentes bases de données\r\n(français et anglais), il s\'agira d\'interroger une ou plusieurs bases de\r\ndonnées en passant des scripts, et de mener des analyses quantitatives\r\net qualitatives en collaboration avec des linguistes.\r\n\r\nCe stage s\'inscrit dans le cadre du projet OpLaDyn (Understanding\r\nOpinion and Language Dynamics using massive data - modélisation des\r\ndynamiques sociétales et langagières), auquel participe le Lattice, en\r\ncollaboration avec d\'autres laboratoires (physiciens du LPS et du LPTM\r\nnotamment).\r\n\r\n\r\n* Modalités  \r\n\r\nStage de 6 mois maximum (début entre février et avril 2020), de niveau\r\nM2, conventionné et indemnisé suivant les règles en vigueur. Le stage se\r\ndéroulera dans les locaux du Lattice à Montrouge (métro Mairie de\r\nMontrouge).\r\n\r\n* Profil recherché. \r\n\r\nEtudiant en linguistique-informatique ou en linguistique avec des\r\nconnaissances en programmation.\r\n\r\n- Compétences en programmation (scripts python) et en TAL nécessaires.\r\n- Des compétences en histoire de la langue seraient un plus. \r\n\r\n* Comment candidater ? \r\n\r\nEnvoyer par mail un CV et un relevé de notes récent à\r\nbenjamin.fagard@ens.fr et thierry.poibeau@ens.fr, ainsi que quelques\r\nmots expliquant votre intérêt pour ce stage dans le corps du mail.'),
(621, '2020-01-15', 'ERIC', 'Lyon', 'Titre du stage : Recommandation de liens dans un réseau d\'auteurs\r\nContact : julien.velcin@univ-lyon2.fr\r\nDurée: 4 à 6 mois\r\nGratification : environ 600 euros par mois\r\nLocalisation : Laboratoire ERIC, Université Lyon 2 (campus de Bron)\r\nDébut du stage : Mars-Avril 2020 (possibilités de commencer plus tôt si besoin)\r\nMots clefs : data science, natural language processing, machine\r\nlearning, representation learning, topic modeling, digital humanities\r\n\r\n## Contexte général\r\n\r\nLe projet LIFRANUM (Littératures FRAncophones Numériques), financé par\r\nl\'Agence Nationale de la Recherche pour une période allant de 2020 à\r\n2023, vise à analyser l\'impact des modifications des supports de l\'écrit\r\nsur les pratiques littéraires. Il regroupe des chercheurs de l\'équipe\r\nMARGE (Université Lyon 3) et du laboratoire ERIC (Universités Lyon 2 et\r\nLyon 1), en partenariat avec la Bibliothèque nationale de\r\nFrance. L\'ambition du projet est notamment de construire une plateforme\r\nen ligne qui permettra de faciliter l\'analyse des créations littéraires\r\nsur le Web par les chercheurs en information-communication et en\r\nlittérature.\r\n\r\n## Objectif du stage\r\n\r\nDans le cadre du projet LIFRANUM, nous cherchons un stagiaire en\r\nInformatique afin de pouvoir tester plusieurs algorithmes de la\r\nlittérature (informatique) pour suggérer de nouveaux liens dans le\r\nréseau des auteurs des textes produits sur les supports numériques (par\r\nex. site web personnel, blog), mais également pour proposer des\r\nalgorithmes originaux. Pour bien débuter, le stagiaire pourra s\'appuyer\r\nsur des travaux en cours menés par des chercheurs du laboratoire ERIC\r\nsur l\'apprentissage de représentation (representation learning)\r\nd\'auteurs. Il aura accès à des données récupérées dans le cadre du\r\nprojet, mais il travaillera également sur un jeu de données déjà\r\ncollectées au sein du laboratoire.\r\n\r\n## Ce qu\'il faut faire\r\n\r\nLes tâches prioritaire à réaliser sont les suivantes :\r\n\r\n- Etudier les travaux récents en apprentissage de représentations à\r\n  partir de réseaux de documents textuels, en particulier ceux\r\n  développés au sein du laboratoire (partie état de l\'art).\r\n  \r\n- Prendre connaissance des données fournies pour le stage (banc d\'essaie\r\n  et données du projet).\r\n  \r\n- Mettre en pratique des méthodes basées sur l\'apprentissage de\r\n  représentation et sur la modélisation.\r\n  thématique afin de suggérer des liens entre documents et auteurs.\r\n- Implémenter au moins une méthode originale développée par les\r\n  chercheurs du laboratoire, en collaboration avec le stagiaire.\r\n- Intégrer cette solution dans un logiciel actuellement en cours de\r\n  développement au sein du laboratoire.\r\n\r\n## Profil recherché\r\n\r\nNous recherchons un candidat ayant des compétences solides en\r\nanalyse/fouille de données, en programma- tion (Python de préférence) et\r\nsi possible des notions de traitement automatique des langues (natural\r\nlanguage processing) / fouille de données textuelles (text mining) et\r\nd\'apprentissage automatique (machine learning). Un intérêt pour le\r\ntravail pluridisciplinaire serait un plus.\r\n\r\n## Déroulement du stage\r\n\r\nLe stage se déroulera dans les locaux du laboratoire ERIC, sur le campus\r\nde Bron (à environ 30 min. du centre-ville de Lyon en tram). Il sera\r\nencadré par un enseignant-chercheur permanent accompagné par un étudiant\r\nen Doctorat travaillant sur les thématiques du stage. Une réunion\r\nhebdomadaire est prévue, en plus des réunions organisées pour le projet\r\nLIFRANUM.\r\n\r\n## Poursuite du stage possible\r\n\r\nUn financement de thèse pour 3 ans est prévu à partir de septembre\r\n2020. Si le stage donne satisfaction et que l\'étudiant est intéressé,\r\ncelui-ci constitue un candidat privilégié pour obtenir cette allocation.\r\n\r\n## Procédure de candidature\r\n\r\nLes candidats doivent envoyer les documents suivants à l\'adresse\r\njulien.velcin@univ-lyon2.fr avant le 15 janvier 2020 :\r\n\r\n- CV\r\n- lettre de motivation\r\n- relevés de notes des deux dernières années\r\n\r\nLes candidats retenus seront convoqués pour un entretien durant la\r\ndeuxième quinzaine du mois de janvier. Les résultats devraient être\r\ncommuniqués dans la première semaine de février.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(622, '2020-01-15', 'IGN', 'Saint-Mandé', 'Constitution d\'une base de connaissances sur la réorganisation du\r\nmaillage administratif de la France lors de la Révolution\r\n\r\nContexte\r\n\r\nL\'Institut National de l\'Information Géographique et Forestière (IGN)\r\nproduit pour sa mission de service public des référentiels\r\ngéographiques avec une certaine profondeur temporelle destinés à\r\nl\'analyse des évolutions du territoire national. Le laboratoire LASTIG\r\ntravaille ainsi depuis de nombreuses années avec des historiens pour\r\nconstituer des référentiels de données spatio-temporelles décrivant\r\nles transformations du territoire dans le temps long. L\'une de ces\r\ncollaborations reconstitue la création et l\'évolution du maillage\r\ncommunal français depuis le 18 e siècle. L\'historique des\r\ntransformations communales depuis 1795 ainsi que la cartographie des\r\nparoisses religieuses de l\'Ancien Régime sont très avancés. Le dé but\r\nde la période Révolutionnaire (1789-1794) est peu couvert, pourtant il\r\na vu les paroisses être réorganisées pour former les futures\r\ncommunes. Cette réorganisation est mal connue et aucune base de\r\ndonnées spatio-temporelle la décrivant n\'existe encore. Les\r\ninformations permettant la constitution d\'une telle base existent\r\npourtant sous la forme de texte légaux promulgués par l\'Assemblée\r\nNationale Constituante et les assemblées de district en 1790-1791\r\n(voir figure 1). Ce stage porte sur l\'extraction automatique et la\r\ngéolocalisation des informations contenues dans ces textes historiques\r\npour construire une base de connaissances géohistoriques des\r\nremembrements paroissiaux sous la Révolution française, premier\r\nchaînon manquant entre paroisses d\'Ancien Régime et premières\r\ncommunes.\r\n\r\nUn premier stage a abouti à la mise en place d\'une chaîne de\r\ntraitement montrant la faisabilité de l\'extraction, de la\r\nstructuration et de la géolocalisation automatique des informations à\r\npartir d\'un échantillon de textes (Keller, Abadie, Dumenieu, Baciocchi\r\n& Kergosien, 2018). Cette première proposition présente toutefois\r\nplusieurs limites :\r\n\r\n- La relative variabilité des textes est encore mal prise en compte,\r\nréduisant la généricité de la chaîne d\'extraction.\r\n\r\n- Les textes décrivent l\'évolution des paroisses à deux niveaux de\r\n  granularité : le territoire et les lieux de culte. Seul le niveau du\r\n  territoire est actuellement pris en compte.\r\n\r\n- La géolocalisation est gênée par la variabilité des formes écrites\r\n  des toponymes.\r\n\r\nFigure 1 - Un extrait de décret de l\'Assemblée Nationale portant sur\r\nla réorganisation des paroisses du département du Puy de Dôme. Extrait\r\nde l\'article 25 - 1 er juin 1791\r\n\r\nObjectif du stage\r\n\r\nL\'objectif du stage est double :\r\n\r\n1. améliorer la chaîne d\'extraction automatique des informations\r\nspatio-temporelles à partir des textes,\r\n\r\n2. améliorer l\'approche de géolocalisation des lieux cités dans les\r\ntextes (on parle d\'entités spatiales nommées ou ESN).\r\n\r\nDans les deux cas, on s\'appuie sur une base de données de toponymes\r\nproduite par vectorisation de la carte de Cassini (voir figure 2),\r\nquasi contemporaine des textes et présentant un niveau de détail\r\néquivalent. Les toponymes de la carte de Cassini sont ainsi très\r\nsusceptibles d\'être mentionnés dans les textes sur les remembrements\r\nparoissiaux.\r\n\r\nCette base de toponymes est exploitée par la chaîne d\'extraction des\r\ninformations spatiotemporelles pour faciliter l\'identification des\r\nportions de textes désignant des entités spatiales nommées,\r\nc\'est-à-dire des noms de lieux éventuellement accompagnés de\r\ndescripteurs (p.ex. \"l\'église paroissiale de Bourg-Lasticq\", \"le\r\nhameau de Laveix\"). Ne disposant pas d\'un corpus pré-annoté, cette\r\nchaîne de traitement a été implémentée à l\'aide de lexiques et de\r\npatrons lexico-syntaxiques. Ceux-ci ont cependant été définis pour un\r\ncorpus restreint et manquent parfois de généricité :\r\n\r\n- Si la majorité des entités spatiales mentionnées sont des toponymes\r\nseuls ou éventuellement accompagnés d\'un descripteur, certains textes\r\ncomportent néanmoins des entités spatiales étendues nécessitant un\r\ntraitement adéquat.\r\n\r\n- L\'extraction des relations spatio-temporelles entre paroisses repose\r\nsur une approche essentiellement lexicale et reste largement\r\nperfectible. Elle gagnerait notamment à traiter l\'expression\r\n\"ci-devant\", très utilisée pendant la Révolution, qui fait référence\r\nau caractère révolu de l\'information mentionnée à sa suite (p.ex. \"la\r\npartie du village de Jouffreits ci-devant dépendant de la paroisse de\r\nCharbonnières-lès-vieilles\").\r\n\r\nFigure 2 - Extrait de la feuille 12 de la carte de Cassini sur la\r\nCreuse. Les lieux nommés en gras et symbolisés par un clocher sont des\r\nchefs-lieux de pa- roisses ; le clocher représente l\'église\r\nparoissiale. Source gallica.bnf.fr / BnF\r\nhttps://gallica.bnf.fr/ark:/12148/btv1b53095185n/\r\n\r\n- L\'extraction des informations sur les lieux de culte permettrait de\r\ncompléter les infor mations relatives au territoire des paroisses,\r\nnotamment dans le cas des paroisses urbaines jusqu\'ici non traitées\r\ncar ne figurant pas sur la carte de Cassini. La base des toponymes de\r\nCassini est aussi utilisée pour géolocaliser les ESN extraites des\r\ntextes. À chaque mention d\'ESN extraite du texte sont associés les\r\nlieux de la carte de Cassini qui peuvent lui correspondre à l\'aide\r\nd\'une mesure de similarité de chaînes de caractères. Chacune de ces\r\nlistes de lieux candidats est ensuite ordonnée d\'après la distance de\r\nchaque lieu à la médiane marginale de l\'ensemble des lieux candidats\r\ndes autres ESN présentes dans le même article que celle en cours de\r\ndésambiguïsation. L\'analyse des résultats obtenus via cette approche\r\nrévèle deux principaux points d\'amélioration :\r\n\r\n1. La mesure de similarité de chaînes de caractères utilisée s\'appuie\r\nsur une distance d\'édition, ce qui présente des limites importantes\r\ndès lors que les ESN et les toponymes sont orthographiés\r\ndifféremment. Or l\'hétérogénéité des graphies de toponymes est encore\r\ntrès présente au XVIIIe siècle. Le passage à une similarité fondée\r\nsur la phonétique des toponymes est une piste d\'amélioration majeure.\r\n\r\n2. La médiane marginale est une approximation du point central de la\r\ndistribution spatiale des lieux candidats qui a l\'avantage de la\r\nsimplicité. Le classement des candidats pourrait être amélioré par une\r\nmeilleure approximation comme la médiane géométrique.\r\n\r\nCompétences et formation requises\r\n\r\nCompétences et connaissances\r\n- Extraction d\'informations à partir de textes\r\n- Résolution d\'Entités Spatiales Nommées\r\n- Apprentissage automatique\r\n- Données géographiques vectorielles\r\n- Web de données\r\n- Un intérêt pour les données anciennes et la linguistique est un plus\r\n\r\nFormation\r\n\r\nMaster 2 ou troisième année d\'école d\'ingénieur en informatique,\r\ntraitement automatique des langues ou en géomatique avec une forte\r\ncomposante informatique.  Selon le profil du candidat, l\'un ou l\'autre\r\ndes deux principaux objectifs du stage pourra être plus\r\nparticulièrement développé.\r\n\r\nInformations pratiques\r\n\r\nDurée et période de stage\r\n\r\n5 mois, printemps-été 2020\r\n\r\nLieu du stage\r\n\r\nEquipe LaSTIG/STRUDEL de l\'Institut National de l\'Information\r\nGéographique et Forestière (IGN), à Saint-Mandé (métro 1, station\r\nSaint Mandé). Le stage se déroulera dans l\'équipe STRUDEL menant des\r\nrecherches en géomatique sur les structures spatio-temporelles pour\r\nl\'analyse des territoires.\r\n\r\nIndemnités de stage\r\n\r\nStage gratifié selon la législation française.\r\n\r\nModalités de candidature\r\n\r\nEnvoyer CV et lettre de motivation ciblée sur le sujet par email au format PDF et en un seul fichier aux encadrants listés ci dessous.\r\n\r\nEncadrement du stage\r\n\r\nNathalie Abadie [STRUDEL/IGN] : nathalie-f.abadie[at]ign.fr\r\n\r\nÉric Kergosien [GERiiCO/SID/Université Lille 3] : eric.kergosien[at]univ-lille3.fr\r\n\r\nBertrand Duménieu [CRH/EHESS] : bertrand.dumenieu[at]ehess.fr\r\n\r\nStéphane Baciocchi [CRH/EHESS] : stephane.baciocchi[at]ehess.fr\r\n\r\nRéférences\r\n\r\nKeller, A., Abadie, N., Dumenieu, B., Baciocchi, S. & Kergosien,\r\nE. (2018). Vers la construction d\'une base de connaissances sur la\r\nréorganisation territoriale française à la Révolution. In Conférence\r\nSagéo 2018 Atelier Exces, Récupérée à partir de\r\nhttps://hal.archives-ouvertes.fr/hal-02399176/'),
(623, '2020-01-21', 'Litt&Arts', 'Grenoble', 'Stage « TAL pour les corpus en littérature »\r\nÉquipe Littératures, Arts et Numérique (ELAN)\r\nau sein du laboratoire Litt&Arts (UMR 5316), Grenoble\r\nAnnée 2020\r\n\r\nEn appui à nos projets de recherche, nous proposons 1 stage de 4 à 6\r\nmois en enrichissement de corpus numériques TEI.\r\n\r\nSpécialité recherchée : traitement automatique des langues et corpus\r\ntextuels\r\n\r\nProfil du candidat : étudiant·e en TAL ou linguistique outillée ayant\r\nun intérêt pour les corpus littéraires et la TEI ou étudiant·e dans\r\nl\'une des disciplines des SHS dans une filière à très forte coloration\r\nnumérique et/ou informatique\r\n\r\nContexte\r\n\r\nAu sein de l\'UMR Litt&Arts, ELAN est une équipe d\'ingénieur·e·s\r\naccompagnant les projets de recherche de l\'unité. De nombreux projets,\r\nqu\'ils traitent de manuscrits, de correspondances, de bibliographies\r\nou d\'autres types de données, nous amènent à manipuler des corpus en\r\nTEI (de leur modélisation à leur visualisation en ligne en passant par\r\ndes outils de recherche). Le stage propose de travailler sur les\r\ndonnées d\'un ensemble de projets choisis et de concevoir - selon les\r\ncas et les objectifs du projet - une ou plusieurs approches utilisant\r\ndes outils et méthodes issues du TAL afin d\'enrichir les corpus, leur\r\nvisualisation ou encore les exploitations faites de ces données.\r\n\r\nObjectifs du travail\r\n\r\nLe stagiaire devra, sous la responsabilité de deux ingénieures d\'ELAN :\r\n\r\n- étudier les spécificités des corpus littéraires vs les corpus\r\nlinguistiques et identifier les besoins de nos projets ;\r\n\r\n- faire un état de l\'art d\'outils utilisés en linguistique et en TAL\r\npour répondre à ces besoins ;\r\n\r\n- compiler les corpus issus de différents projets partageant une même\r\nproblématique afin de constituer un ensemble conséquent ;\r\n\r\n- tester différents outils et méthodes pour analyser le corpus ainsi\r\nconstitué ;\r\n\r\n- documenter ces tests et rédiger des méthodologies à destination\r\nd\'utilisateurs néophytes ou peu formés.\r\n\r\nCompétences recherchées\r\n\r\n- bonne connaissance du domaine du TAL ;\r\n- bonnes capacités rédactionnelles ;\r\n- lecture courante de l\'anglais ;\r\n- la connaissance du format XML, voire de la TEI sera appréciée ;\r\n- capacité d\'organiser son propre travail avec rigueur.\r\n\r\nNous attendons du ou de la candidate un goût certain pour la\r\ntransmission du savoir et des capacités didactiques. En effet, les\r\ndocumentations devront viser une autonomie maximale des membres des\r\nprojets, tant sur la mise en oeuvre de l\'outil ou de la méthode que sur\r\nl\'utilisation, l\'exploitation et l\'interprétation des résultats.\r\n\r\nCadre du stage\r\n\r\nLa·e stagiaire sera accueilli au sein du Laboratoire Arts et pratique\r\ndu texte, de l\'image, de l\'écran et de la scène (Litt&Arts, UMR 5316,\r\nUGA/CNRS). Il ou elle sera accompagné·e dans son travail par deux\r\nencadrantes et travaillera en collaboration avec plusieurs\r\nchercheuse·eur·s de l\'unité.\r\n\r\nDurée et date de début du contrat\r\n\r\nLe stage est prévu au printemps-été 2020.\r\n \r\nRépondre à l\'offre\r\n\r\nLes candidats doivent envoyer :\r\n\r\n(1) un CV, (2) une lettre de motivation et (3) une lettre de recommandation d\'un\r\nenseignant\r\npar mail, ayant comme objet :\r\n[Stage ELAN] Candidature de M/Mme Prénom NOM\r\nà:\r\nAnne Garcia-Fernandez : annegf@univ-grenoble-alpes.fr\r\nElisabeth Greslou : gresloue@univ-grenoble-alpes.fr'),
(624, '2020-01-21', 'Datalab Groupe Crédit Agricole', 'Montrouge', 'Stage : Assistant Infolinguiste au sein du DataLab Groupe Crédit\r\nAgricole SA\r\n========================================================================\r\n\r\nAu sein du Pôle Développement Clients et Innovation, le DataLab Groupe\r\nCrédit Agricole est un centre de compétences dédié aux sciences de la\r\ndonnée et à leurs applications dans le domaine bancaire. Son rôle est de\r\ncréer des approches innovantes pour la valorisation de la donnée interne\r\net externe, qu\'elle soit structurée ou non structurée. Dans le cadre de\r\nses missions, des thématiques scientifiques à forte valeur ajoutée sont\r\nétudiées : Apprentissage Automatique, Auto-ML, Traitement du Langage\r\nNaturel, Process Mining, Time Series Mining, Deep Learning, Géomatique,\r\netc. Ces activités sont menées conjointement avec des partenaires\r\ninternes : les Caisses Régionales, les Entités du Groupe et les\r\nProducteurs Informatiques. Le DataLab développe également un réseau de\r\npartenaires externes lors de missions industrielles (Editeurs de\r\nlogiciels, startup, SSII, etc.) ou de collaborations universitaires.\r\n\r\nDans le cadre de ce stage, vous rejoindrez l\'équipe Data Science afin de\r\ncontribuer à la valorisation de la Data et participer à la création\r\nd\'une base de connaissance au service des Clients du Groupe.\r\n\r\nDescriptif du stage :\r\n\r\nContexte et objectifs du stage :\r\n\r\nDans l\'industrie bancaire, les corpus textuels internes ou externes sont\r\nnombreuses et exploitées par différents métiers de la banque:\r\nconformité, marketing et communication, conseil, etc. Les experts\r\nmétiers ont souvent recours à ces corpus au quotidien, pour réaliser\r\ndifférentes tâches d\'analyse sémantique d\'une façon manuelle ou\r\nsemi-manuelle : extraction de l\'information pertinente, reconnaissance\r\nde type de document, recherche d\'information, etc. Ces tâches sont le\r\nplus souvent consommatrices en temps et effort humain.\r\n\r\nL\'équipe IA sémantique du DataLab développe des méthodes automatiques\r\nbasées essentiellement sur le machine learning et l\'analyse sémantique\r\nqui permettent de faciliter le travail des experts et simplifier leur\r\naccès à l\'information pertinente. Dans le cadre de développement d\'un\r\nmodèle ML, l\'équipe doit souvent construire un corpus de textes annotés\r\nqui sert en tant que corpus d\'apprentissage pour le modèle. Vu que la\r\nperformance du modèle dépend fortement de la qualité des données\r\nannotées, l\'annotation représente une phase capitale du projet.\r\n\r\nL\'objectif du stage consiste à participer à la mise en oeuvre d\'une\r\nchaîne complète d\'annotation dans le cadre d\'un projet de l\'IA\r\nsémantique : à partir de construction d\'un plan de classement jusqu\'à\r\nl\'implémentation de métriques afin d\'établir la consistance de données\r\nannotées. Une partie importante de stage sera consacrée à l\'annotation\r\nmanuelle d\'un ou plusieurs corpus à l\'aide d\'un logiciel collaboratif\r\ndédié et selon des consignes d\'annotation détaillées. Finalement, un\r\nsujet R&D dans le domaine TAL (analyse de sentiments/émotions) sera\r\nproposé qui permettra de mettre en valeur un corpus annoté.\r\n\r\nOrganisation et livrables :\r\n\r\nLe stage se déroulera en quatre étapes principales, sous l\'encadrement\r\nd\'un infolinguiste expérimenté :\r\n\r\n- Participation dans la mise en place d\'une chaîne complète d\'annotation\r\n  : construction de plan de classement, rédaction de consignes\r\n  d\'annotation, annotation manuelle, revue de résultats en équipe\r\n\r\n- Réalisation d\'un état de l\'art sur les techniques d\'annotation et de\r\n  métriques de performances (par exemple, l\'accord inter-annotateurs)\r\n\r\n- Développement des briques d\'évaluation de qualité d\'annotation et leur\r\n  intégration dans la plateforme sémantique du DataLab\r\n\r\n- Travail sur un sujet R&D dans le domaine d\'analyse de\r\n  sentiments/émotions\r\n\r\nCompétences techniques ou spécifiques au poste:\r\n\r\n\r\n- Traitement de langage naturel (NLP)\r\n\r\n- Linguistique\r\n\r\n- Développement python\r\n\r\n\r\nCompétences générales et transverses :\r\n\r\n\r\n- Ecoute, partage et communication\r\n\r\n- Grande rigueur et autonomie\r\n\r\n- Aptitude pour le travail en équipe\r\n\r\n- Une expérience en annotation manuelle de textes serait un plus\r\n\r\nOutils informatiques :\r\n\r\n- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.\r\n\r\n- Outils : Gate, Unitex, Protege, outils d\'annotation\r\n\r\n\r\nDurée : 6 mois\r\nLieu de travail : DataLab Groupe  (Montrouge)\r\nDate de démarrage souhaitée : mars/avril 2020\r\nRémunération : selon profil\r\nCandidature : envoi d\'un CV, lettre de motivation\r\nContacts:\r\nAymen SHABOU (aymen.shabou@credit-agricole-sa.fr),\r\nYulia KOLOSKOVA (yulia.koloskova@credit-agricole-sa.fr)'),
(625, '2020-01-21', 'INRIA', 'Rennes', 'The digital world is offering an amazing range of possibilities for\r\neveryone, especially for people with disabilities. Come and join us as\r\na Master 2 intern to leverage new technologies to offer life-changing\r\nsolutions for people with visual impairment.\r\n\r\nTowards Large-Scale Evaluation Protocols for the Visually Impaired\r\n\r\nPierre Kornprobst, Senior research scientist, BIOVISION Lab, Inria\r\nJean-Charle Régin, full professor and head of the C&A Lab of the I3S, CNRS\r\nAurelie Calabrese, Junior research scientist, BIOVISION Lab, Inria\r\n\r\nCONTEXT: In 2015, 405 million people were visually impaired around the\r\nglobe, against `only` 285 million in 2010 [1]. Almost half of it could\r\nhave been prevented by earlier interventions in the form of treatment\r\nor rehabilitation. Because of aging, and its strong correlation with\r\neye disease prevalence, this number is only expected to grow. To\r\naddress this global health problem, actions must be taken to design\r\neffective solutions for earlier and more decisive detection of visual\r\npathologies.\r\n\r\nPROBLEM: Since reading speed is a strong predictor of visual ability\r\nand vision-related quality of life for patients with vision loss,\r\nreading performance has become one of the most important clinical\r\nmeasures for judging the effectiveness of treatments, surgical\r\nprocedures or rehabilitation techniques.  Accurate measurement of\r\nreading performance requires highly standardized reading test, such as\r\nthe MNREAD acuity chart [2]. This test, available in 19 languages,\r\nallows to measure reading performance in people with normal and low\r\nvision. In brief, performance is measured from the time needed to read\r\na series of short sentences that were designed to be equivalent in\r\nterms of linguistics, length and layout. To ensure accurate\r\nmeasurement, each sentence must be presented only once to avoid\r\nintroduction of a memorization bias. However, because of their highly\r\nconstrained nature, MNREAD sentences are hard to produce, leading to a\r\nvery limited number of test versions (only two in French). Given that\r\nrepeated measures are needed in many applications of MNREAD, there is\r\na strong interest from the scientific and medical communities for a\r\nmuch larger pool of sentences.\r\n\r\nSTATE-OF-THE-ART: Very recently, a method for computer-generated\r\nsentences has been explored by the MNREAD creators themselves\r\n[3]. However, this semi-automated method presents several major\r\ndrawbacks: (1) it relies on sentence templates that must be created\r\nmanually (i.e., sequences of placeholders, each containing a list of\r\npossible words that fit into the sentence at that point); (2) it works\r\nin two stages (i.e., sentence creation followed by sentence selection)\r\nimplying additional calculations and longer execution time; (3) it can\r\nnot be extended to other languages.\r\n\r\nSHORT-TERM OBJECTIVE (Internship research program): Fully automated\r\ngeneration of constrained text is a very complex task. The problem\r\nthat we must solve here is to generate a very large number of\r\nsentences, while taking into account very strict linguistics, length\r\nand layout rd constraints, such as: fixed number of characters,\r\nrestricted vocabulary (3 grade level), tightly constrained physical\r\nlayout, etc. To tackle this matter, one approach we will consider is\r\noriented towards the automatic production of constrained text from a\r\ncorpus. However, to further extend the test capabilities, we must keep\r\nthe option to modify these constraints along the course of our\r\nproject. Therefore, it is crucial to consider methods based on\r\nconstraints satisfaction, such as those developed by J.C. Régin at\r\nI3S, in collaboration with the Sony Computer Science Lab [4]. These\r\nmethods are essentially based on multivalued decision diagrams and the\r\noperations that allow them to be manipulate [5,6,7], and have already\r\nproven to be efficient [8].\r\n\r\nPERSPECTIVE: In the short run, the MNREAD Android app will serve as a\r\nresearch tool, allowing for instance to generalize the principles of\r\nthe test to evaluate the effects on reading of dependent variables\r\nother than print size e.g., evaluate the readability of a new\r\ntypeface, letter spacing and line length. In the long run, the MNREAD\r\nAndroid app may be commercialized to serve as a valuable tool in\r\nclinical settings.\r\n\r\nBIBLIOGRAPHY:\r\n\r\n[1] Bourne, R., et al. (2017) Magnitude, temporal trends, and\r\nprojections of the global prevalence of blindness and distance and\r\nnear vision impairment: a systematic review and meta-analysis. The\r\nLancet Global Health, Volume 5, Issue 9, e888 - e897\r\n\r\n[2] Mansfield J.S., Ahn S.J., Legge G.E., Luebker A. (1993) A new\r\nreading-acuity chart for normal and low vision. Ophthalmic and Visual\r\nOptics/Noninvasive Assessment of the Visual System Technical Digest,\r\n(Optical Society of America, Washington, DC., 1993.) 3: 232--235.\r\n\r\n[3] Mansfield, J.S., Atilgan, N., Lewis, A.M., Legge, G.E. (2019)\r\nExtending the MNREAD sentence corpus: Computer-generated sentences for\r\nmeasuring visual performance in reading. Vision Research, 158, 11-18.\r\n\r\n[4] Papadopoulos, A., Roy, P., Régin, J.-C., Pachet, F. (2015)\r\nGenerating all Possible Palindromes from Ngram Corpora. IJCAI 2015:\r\n2489-2495\r\n\r\n[5] Perez, G., Régin, J.-C. (2015) Efficient Operations On MDDs for\r\nBuilding Constraint Programming Models. IJCAI 2015: 374-380\r\n\r\n[6] Perez, G., Régin, J.-C. (2017) Soft and Cost MDD Propagators. AAAI\r\n2017: 3922-3928\r\n\r\n[7] Perez, G., Régin, J.-C. (2018) Parallel Algorithms for Operations\r\non Multi-Valued Decision Diagrams. AAAI 2018: 6625-6632\r\n\r\n[8] Perez, G., Régin, J.-C. (2017) MDDs: Sampling and Probability\r\nConstraints. CP 2017: 226-24\r\n\r\nSUPERVISORS: The candidate will be co-supervised by P. Kornprobst, a\r\nmathematician with strong expertise in computer vision and human\r\nvision understanding, J.C. Régin, a world-wide known specialist in\r\nconstraint programming, and A. Calabrèse, a psychophysicist\r\nspecialized in visual neuroscience with a strong clinical expertise.\r\n\r\nCONDITIONS:\r\n- Duration: 6 months\r\n- Starting date: February/March 2020\r\n- Where: Inria Sophia Antipolis - Méditerranée, France (https://www.inria.fr/en/centre/sophia).\r\n- Salary: approx. 550 euros per month.\r\n\r\nCURRICULUM OF THE CANDIDATE: Applicants should have a keen interest in\r\nlinguistic, low vision or both, and a relevant Master, for example in\r\nnatural language processing, computer science, digital humanities or\r\nlinguistics.\r\n\r\nFOLLOW-UP: Funding opportunities to continue for a 4 year\r\nPh.D. including a six month period in the US.\r\n\r\nTO APPLY: Please visit https://team.inria.fr/biovision/job-offers.'),
(626, '2020-01-21', 'INRIA', 'Rennes', 'The digital world is offering an amazing range of possibilities for\r\neveryone, especially for people with disabilities. Come and join us as\r\na Master 2 intern to leverage new technologies to offer life-changing\r\nsolutions for people with visual impairment.\r\n\r\nDevelopment of an Android Application to Measure Reading\r\nPerformance in both Clinical and Research Environments\r\n\r\nAurelie Calabrese, Junior research scientist, BIOVISION Lab, Inria\r\nPierre Kornprobst, Senior research scientist, BIOVISION Lab, Inria\r\n\r\nCONTEXT: The MNREAD ACUITY CHART is a standardized reading test has\r\nbeen designed to measure the reading performance of people with normal\r\nand low vision [1] (see also video [2]). Its prominent use worldwide\r\nin both clinical and research settings makes it a strong diagnostic\r\ntool for reading deficit. In brief, the MNREAD allows to measure how\r\nreading performance changes when print size decreases, by presenting a\r\nseries of short sentences with decreasing size printed on cardboard.\r\n\r\nPROBLEM: To respond to the rapid transition to digital reading in our\r\nculture, the time has come to adapt reading-acuity measures to\r\nevaluate legibility on digital displays. Therefore, the creators of\r\nthe MNREAD have recently developed an electronic version of the MNREAD\r\ntest, running on iOS: the MNREAD iPad App ©2017 [3,4]. This digital\r\ntransition will help standardize reading assessment in several ways:\r\n(a) through unified testing and scoring methods that increase inter-\r\ntester reliability; (b) by promoting data sharing and\r\nportability. However, the MNREAD test is not yet available on Android,\r\nwhile many clinics use this platform for patient-care and data\r\ncollection.\r\n\r\nMETHOD: Our main objective is to develop an Android application that\r\nwill replicate the MNREAD iPad App, while bringing new\r\nfeatures. Throughout the developing process, e-ink tablets will be\r\nused (e.g., BOOX 13.3\"). Once development is completed, the same\r\ndevices will be used for experimental validation through\r\nwithin-subject comparison.\r\n\r\nPERSPECTIVE: In the short run, the MNREAD Android app will serve as a\r\nresearch tool, allowing for instance to generalize the principles of\r\nthe test to evaluate the effects on reading of dependent variables\r\nother than print size e.g., evaluate the readability of a new\r\ntypeface, letter spacing and line length. In the long run, the MNREAD\r\nAndroid app may be commercialized to serve as a valuable tool in\r\nclinical settings.\r\n\r\nBIBLIOGRAPHY:\r\n\r\n[1] Mansfield JS, Ahn SJ, Legge GE, Luebker A (1993) A new\r\nreading-acuity chart for normal and low vision. Ophthalmic and Visual\r\nOptics/Noninvasive Assessment of the Visual System Technical Digest,\r\n(Optical Society of America, Washington, DC., 1993.) 3: 232--235.\r\n\r\n[2] VIDEO of the classical MNREAD test:\r\nhttps://www.precision-vision.com/mn-read-testing- demonstration/\r\n\r\n[3] Calabrèse, A., To, L., He, Y., Berkholtz, E., Rafian, P., & Legge,\r\nG. E. (2018a). Comparing Performance on the MNREAD iPad Application\r\nwith the MNREAD Acuity Chart. Journal of Vision, 18(1),\r\n8. http://doi.org/10.1167/18.1.8\r\n\r\n[4] MNREAD iPad App ©2017 - Version 1.5 Legge G.E., Calabrèse A., To\r\nL., Mansfield J.S., Bigelow C.  Apple App Store -\r\nhttps://itunes.apple.com/us/app/mnread/id1196638274?ls=1&mt=8\r\n\r\nSUPERVISORS: The candidate will be co-supervised by A. Calabrèse, a\r\npsychophysicist specialized in visual neuroscience with a strong\r\nclinical expertise, and P. Kornprobst, a mathematician with strong\r\nexpertise in computer vision and human vision understanding.\r\n\r\nCONDITIONS:\r\n- Duration: 6 months\r\n- Starting date: February/March 2020\r\n- Where: Inria Sophia Antipolis - Méditerranée, France\r\n  (https://www.inria.fr/en/centre/sophia).\r\n- Salary: approx. 550 euros per month.\r\n\r\nCURRICULUM OF THE CANDIDATE: Applicants should have experience in\r\ndeveloping Android applications, a keen interest in user experience,\r\nlow vision or both, and a relevant Master, for example in computer\r\nscience, linguistics, digital humanities or natural language\r\nprocessing.\r\n\r\nFOLLOW-UP: Funding opportunities to continue for a Ph.D.\r\n\r\nTO APPLY: Please visit https://team.inria.fr/biovision/job-offers.'),
(627, '2020-01-21', 'GEOLSemantics', 'Gentilly', 'Contexte\r\n\r\nCréée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans\r\nle domaine des technologies de l\'information et de la communication, et\r\nplus particulièrement dans le domaine de l\'extraction\r\nd\'informations. Les solutions de GEOLSemantics analysent les contenus\r\ntextuels pour identifier, normaliser et structurer les données\r\npertinentes qu\'ils contiennent, afin de les rendre directement\r\nexploitables par des processus automatiques.\r\n\r\nMission\r\n\r\nDans le cadre d\'un projet sur l\'apport des technologies de NLP pour le\r\ndomaine de la santé, nous proposons un stage afin de mettre au point un\r\nsystème de détection des intentions suicidaires à partir de messages\r\nécrits sur les réseaux sociaux. Pour cela, nous nous baserons sur une\r\nétude réalisée par l\'INSERM, sur l\'expression du mal-être et des\r\nintentions de suicide. Le stage consistera donc à implémenter les\r\nrésultats de l\'étude dans notre système, pour le français mais aussi\r\npour l\'anglais, ainsi que de participer à la réalisation du produit\r\nfinal, qui générera des alertes en fonction du degré d\'urgence exprimé\r\ndans les messages.\r\n\r\nLe stage se découpera de la manière suivante :\r\n\r\n* Enrichissement de l\'ontologie métier de GEOLSemantics pour la\r\n  détection des intentions suicidaires,\r\n\r\n* Enrichissement des analyses anglais et français afin d\'extraire tous\r\n  les critères nécessaires,\r\n\r\n* Mise en place du calcul de probabilité permettant de classer les\r\n  messages arrivants selon ce qu\'ils contiennent (RAS, état inquiétant,\r\n  état urgent),\r\n\r\n* Mise en place du processus d\'alerte pour les états inquiétants et\r\n  urgents,\r\n\r\n* Test sur un corpus représentatif.\r\n\r\nIl sera aussi demandé, à chaque phase, de réaliser la documentation\r\nnécessaire.\r\n\r\nFormation\r\n\r\nMaster en informatique et linguistique\r\n\r\nLangues\r\n\r\nFrançais et anglais\r\nAutres langues bienvenues\r\n\r\nEnvironnement technique\r\n\r\n* Méthodologie Agile (Scrum)\r\n* Outils \r\n * Gestion de versions (SVN) \r\n * Gestion de production (Maven) \r\n * Intégration continue (Jenkins) \r\n * Environnement de développement (Eclipse et/ou Netbeans) \r\n\r\n* Développement (Python, Java) \r\n* Base de données (SGBD-R, NO SQL, Base de connaissance, web sémantique) \r\n* Format d\'échange (XML, RDF) \r\n* Système d\'exploitation (Windows, Linux) \r\n\r\nAutres compétences\r\n\r\n* Autonomie\r\n* Bonne aisance rédactionnelle\r\n* Capacité à communiquer avec les membres de l\'équipe\r\n\r\nCaractéristiques du stage\r\n\r\n* Durée : minimum 6 mois\r\n* Date de début : avril 2020\r\n* Lieu : Gentilly\r\n\r\nPour postuler, envoyez votre candidature à\r\nchristian.fluhr@geolsemantics.com\r\n\r\nwww.geolsemantics.com'),
(628, '2020-01-21', 'GEOLSemantics', 'Gentilly', 'Contexte :\r\n\r\nCréée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans\r\nle domaine des technologies de l\'information et de la communication, et\r\nplus particulièrement dans le domaine de l\'extraction\r\nd\'informations. Les solutions de GEOLSemantics analysent les contenus\r\ntextuels pour identifier, normaliser et structurer les données\r\npertinentes qu\'ils contiennent, afin de les rendre directement\r\nexploitables par des processus automatiques.\r\n\r\nMission :\r\n\r\nDans le cadre de l\'amélioration continue de notre solution globale\r\nd\'extraction d\'informations, nous proposons un stage en NLP afin de\r\ndésambiguïser les lieux pouvant référer à plusieurs endroits dans les\r\ntextes. Pour cela, nous nous baserons sur des systèmes géographiques\r\nexistants, en les adaptant à notre besoin, afin d\'enrichir notre Système\r\nd\'Information Géographique stocké dans une base ElasticSearch, ainsi que\r\nsur des ontologies existantes et propriétaires, et la contextualisation\r\nà travers le texte, afin d\'identifier de quel lieu il s\'agit lorsque le\r\nnom est ambigu.\r\n\r\nLe stage se découpera de la manière suivante :\r\n\r\n* Récupération de systèmes géographiques mondiaux existants\r\n  (OpenStreetMap, Geonames), transformation au format souhaité, et\r\n  intégration dans ElasticSearch\r\n\r\n* Adaptation du système géographique pour la désambiguïsation\r\n  (suppression des doublons, ajout d\'inclusions manquantes)\r\n\r\n* Création des corpus de développement et de test\r\n\r\n* Étude des critères de désambiguïsation, par exemple la distance\r\n  séparant deux lieux, dans le cadre de :\r\n\r\n * textes journalistiques,\r\n * messages de forums,\r\n\r\n* Implémentation du système de désambiguïsation des lieux afin d\'obtenir\r\n  leurs coordonnées GPS\r\n\r\n* Test sur un corpus représentatif.\r\n\r\nIl sera aussi demandé, à chaque phase, de réaliser la documentation\r\nnécessaire.\r\n\r\nFormation\r\n\r\n  Master en informatique et linguistique\r\n\r\nLangues\r\n\r\n  Français\r\n  Autres langues bienvenues\r\n\r\nEnvironnement technique\r\n\r\n* Méthodologie Agile (Scrum)\r\n* Outils \r\n * Gestion de versions (SVN) \r\n * Gestion de production (Maven) \r\n * Intégration continue (Jenkins) \r\n * Environnement de développement (Eclipse et/ou Netbeans) \r\n\r\n* Développement (Python, Java) \r\n* Base de données (SGBD-R, NO SQL, Base de connaissance, web sémantique,\r\n  ElasticSearch)\r\n* Format d\'échange (XML, RDF) \r\n* Système d\'exploitation (Windows, Linux) \r\n\r\nAutres compétences\r\n\r\n* Autonomie\r\n* Bonne aisance rédactionnelle\r\n* Capacité à communiquer avec les membres de l\'équipe\r\n\r\nCaractéristiques du stage\r\n\r\n* Durée : minimum 6 mois\r\n* Date de début : avril 2020\r\n* Lieu : Gentilly\r\n\r\nPour postuler, envoyez votre candidature à\r\nchristian.fluhr@geolsemantics.com\r\n\r\nwww.geolsemantics.com\r\nGEOLSemantics - Analyse des textes      \r\nAnalyse des textes'),
(629, '2020-02-24', 'EDF R&D', 'Palaiseau', 'Offre de stage Master 2 dans le domaine du text mining\r\n\r\nLibellé stage : Exploration, analyse, modélisation et représentation de\r\ndonnées pour la recherche et la visualisation d\'information avec Open\r\nSemantic Search et sa base Apache Lucene / Solr.\r\n\r\nDurée : 6 mois\r\n\r\nLieux : EDF R&D Lab Saclay et déplacements sur sites industriels en\r\nFrance\r\n\r\nTuteurs : Julien Kahn, Lydia Ould Ouali\r\n\r\nContacts : julien.kahn@edf.fr et lydia.ould-ouali@edf.fr\r\n\r\nEntreprise : EDF Recherche & Développement Lab Saclay - Département\r\nPErformance et prévention des Risques Industriels du parC par la\r\nsimuLation et les EtudeS (PERICLES) - groupe Facteurs Organisationnels\r\net Humains (FOH)\r\n\r\nAdresse : 7, boulevard Gaspard Monge 91120 PALAISEAU, FRANCE\r\n\r\nContexte industriel\r\n\r\nL\'approvisionnement en énergie compte parmi les enjeux politiques,\r\néconomiques et écologiques décisifs pour l\'avenir. La satisfaction de la\r\ndemande énergétique mondiale et le respect des objectifs internationaux\r\nde lutte contre le changement climatique imposent de développer des\r\nénergies décarbonées. Le nucléaire apparaît ainsi comme un élément du\r\nmix énergétique du futur.\r\n\r\nDans ce domaine où l\'ensemble des intervenants doit être irréprochables\r\nen matière de sûreté et de radioprotection, l\'exploitant doit respecter\r\nles Règles générales d\'exploitation (RGE). Les RGE sont un recueil de\r\nrègles approuvées par l\'Autorité de Sûreté Nucléaire qui définissent le\r\ndomaine autorisé de fonctionnement de l\'installation et les\r\nprescriptions de conduite associées. En effet, tel le Code de la Route,\r\nles RGE regroupent l\'ensemble des consignes à respecter par les\r\nexploitants, pour garantir le meilleur niveau de sûreté de leurs\r\ncentrales.\r\n\r\nDans le cadre des réflexions associées à la transition numérique du\r\ngroupe EDF, il s\'agit de participer à la réflexion sur comment\r\nl\'intégration d\'outils « intelligents » du Traitement Automatique de la\r\nLangue (TAL) écrite peut soutenir l\'utilisation des nouvelles RGE en\r\nfacilitant l\'analyse exhaustive et l\'interprétation de ses prescriptions\r\npar les équipes de conduite de Centrales Nucléaires de Production\r\nElectrique (CNPE).\r\n\r\nDéfinition du stage\r\n\r\nLe stage consistera à participer à l\'étude sur l\'apport et les\r\nconditions de mise en oeuvre du TAL pour faciliter la consultation,\r\nl\'analyse et l\'interprétation des règles générales d\'exploitation d\'une\r\ncentrale nucléaire.\r\n\r\nPlus précisément, il s\'agira de:\r\n\r\n1. Consolider et enrichir la chaine de traitement (aujourd\'hui scripts\r\n   python et Java) déjà constituée en l\'utilisant et la faisant évoluer\r\n   pour intégrer 3 chapitres supplémentaires des RGE (documents d\'entrée\r\n   en word) ;\r\n\r\n2. Consolider et enrichir les modalités de recherche et de présentation\r\n   des résultats au moyen du paramétrage d\'Open Semantic Search ou de sa\r\n   base Apache Lucene / Solr.\r\n\r\nEn interface avec une équipe pluridisciplinaire (ingénieurs en\r\nTraitement Automatique de la Langue, ingénieurs Facteurs Humains et\r\ningénieurs membres d\'équipes de conduite de CNPE), l\'approche développée\r\ndurant le stage, consistera à :\r\n\r\n- Identifier et prioriser les modifications et enrichissement des\r\n  traitements à réaliser ;\r\n\r\n- Implémenter les traitements retenus ;\r\n\r\n- Mettre à disposition d\'un échantillon d\'utilisateurs représentant des\r\n  équipes de conduite de CNPE le prototype.\r\n\r\nCeci afin de permettre :\r\n\r\n- Aux utilisateurs de faire des retours sur l\'usage du prototype et de\r\n  procéder à l\'amélioration incrémentale de ce dernier ;\r\n\r\n- Au titulaire du stage et à l\'équipe projet de procéder à\r\n  l\'amélioration incrémentale du prototype.\r\n\r\nLe recueil des retours utilisateur sera porté par les ingénieurs\r\nfacteurs humains. L\'analyse de ces retours sera réalisée en\r\ncollaboration avec le titulaire du stage.\r\n\r\nAu terme du stage le stagiaire aura produit :\r\n\r\n- Une documentation technique (chaîne de traitement, paramétrage d\'Open\r\n  Semantic Search et Solr, utilisation du prototype) ;\r\n\r\n- Le transfert et la dépose du code à l\'équipe projet ;\r\n\r\n- Un prototype de consultation des RGE sous Open Semantic Search.\r\n\r\n- Son rapport de stage avec une mise en perspective des développements\r\n  réalisés et résultats obtenus.\r\n\r\nLes avantages du stage\r\n\r\nAu sein de la R&D du groupe EDF ce stage vous permettra :\r\n\r\n- De mettre en oeuvre des outils et techniques d\'analyse de données non\r\n  structurées ;\r\n\r\n- De mettre en oeuvre des techniques d\'analyse et d\'enrichissement de\r\n  représentation des données ;\r\n\r\n- D\'évoluer et interagir au sein d\'une équipe pluridisciplinaire en\r\n  confrontant les réalisations aux utilisateurs ;\r\n\r\n- D\'être force de proposition dans les phases initiales d\'un projet de\r\n  R&D ;\r\n\r\n- De participer à la phase amont d\'un projet industriel.\r\n\r\nLe prototype réalisé a pour ambition de nourrir une réflexion en termes\r\nde Facteurs Humains sur l\'intelligibilité de système de recherche\r\nd\'information et à terme d\'aide à la décision à base de TAL pour les\r\nindustries à risque.\r\n\r\nCompétences requises\r\n\r\n- Python, PHP\r\n- Travail en équipe\r\n- Aisance rédactionnelle\r\n- Connaissance d\'outils de TAL\r\n- Aisance relationnelle\r\n- Anglais lu\r\n- Capacités d\'adaptation\r\n- Capacités d\'initiatives'),
(630, '2020-03-09', 'Acolad', 'Boulogne-Billancourt', 'Acolad is the European leader in professional translation and is one of\r\nthe most dynamic businesses in the industry. The group has a presence in\r\n14 countries and on 3 continents and distinguishes itself by its\r\nmulti-local market approach, a rare trait which has made it the\r\npreferred partner of many clients around the world. Acolad offers a wide\r\nrange of language services, for all industries and sectors, including\r\ntranslation, localisation, and interpretation. The Acolad group\r\nmaintains a strong partnership with over 15,000 professional translators\r\nand 6,000 clients, for 300 different language combinations.\r\n\r\nAcolad\'s Research & Development team, composed of highly dedicated\r\nComputational Linguists, Natural Language Processing (NLP) Engineers,\r\nand Machine Translation (MT) Experts, develops NLP technology for the\r\nAcolad group, employing state-of-the-art models and capitalising on our\r\ngroup-wide natural language resources. We work in close collaboration\r\nwith production teams, ensuring an industry-oriented, applied research\r\napproach.\r\n\r\nAs an intern in our team, you will have the opportunity to develop your\r\nPython programming and research skills in the context of the rich Neural\r\nMachine Translation (NMT) scientific community we operate in. Our\r\nprojects include domain adaptation of NMT engines, a study of\r\ninter-language variability of Translation Edit Rate (TER),\r\nlinguistic-driven evaluation of Post-Edited Machine Translation (PEMT),\r\nand prediction of PEMT effort.\r\n\r\nYour profile:\r\n\r\n  * A student in or a holder of a Master\'s degree in Computational\r\n    Linguistics, Natural Language Processing, Computer Science and/or\r\n    Linguistics, Data Science, or a related field\r\n  * Solid grasp of Python and Bash\r\n  * Familiar with Linux and Virtual Machines\r\n  * Fluent in French and English, knowledge of other languages is a plus\r\n  * Familiar with recent Machine Learning approaches for NLP\r\n  * Knowledge of Machine Translation and CAT Tools is appreciated but\r\n    not required\r\n\r\nPosition located in Boulogne-Billancourt, 20 minutes by public transport\r\nfrom the centre of Paris\r\n\r\nStart date: ASAP\r\n\r\nSalary: 600¤ net, transport costs, and meal vouchers (Ticket Restaurant)\r\n\r\nTo apply, send your CV and a cover letter to nalkhadhar@acolad.com'),
(631, '2020-03-09', 'LIGM', 'Marne-la-Vallée', 'Titre du stage : Approches automatiques de modernisation de textes du\r\nXVIe au XVIIIe siècle\r\n******** \r\n\r\nDescription du stage \r\n--------------------------------------- \r\nDans le cadre du projet de recherche Cité de Dames, créatrices dans la\r\ncité, qui se centre sur la thématique de la visibilité des créatrices\r\nsur la dimension urbaine (https://citedesdames.hypotheses.org/a-propos),\r\ncoordonné par Philippe Gambette et Caroline Trotot, un stage en TAL est\r\nproposé sur le sujet de la mise en oeuvre d\'approches statistiques et à\r\nbase de règles pour la modernisation orthographique des textes issus du\r\nXVIe au XVIIIe siècle.\r\n\r\nLe stage aura lieu au LIGM, Laboratoire d\'Informatique Gaspard-Monge. La\r\npersonne recrutée interagira tout particulièrement avec Eleni\r\nKogkitsidou, post-doctorante et Philippe Gambette, enseignant-chercheur\r\nà l\'Université Gustave Eiffel.\r\n\r\nObjectifs du stage \r\n--------------------------------------- \r\nAlors que la langue se trouve en plein évolution au cours de la période\r\ndu XVIe au XVIIe, il a été constaté qu\'elle présente une extrême\r\nvariabilité graphique (scauoir/sauoir/sçauoir/sçavoir/savoir,\r\nalternances u/v et i/j). En effet, elle conserve certains archaïsmes\r\n(amy/ami), son système flexionnel n\'est pas encore stabilisé (amiz/amis,\r\nchevaulx/cheval) et l\'accentuation est souvent peu régulière (Souvay &\r\nPierrel, 2009). De plus ces textes anciens issus d\'une océrisation\r\ndépendante de la qualité de l\'impression du texte original, peuvent\r\ncontenir souvent des problèmes de conversion de caractères spéciaux (s\r\nlong - ) et sont parfois peu conformes à leur version originale (Abiven\r\n& Lejeune, 2019).\r\n\r\nTraiter de façon automatique des anciens textes nécessiterait donc\r\nprendre en compte un certain nombre de paramètres afin d\'obtenir une\r\nversion modernisée : la syntaxe, la ponctuation, la conjugaison, l\'OCR\r\netc. (Catach, 1996). Également, il ne faut pas omettre la résolution de\r\nl\'ambiguïté homographique (marchez peut être utilisé comme nom au\r\npluriel alors qu\'aujourd\'hui il est le plus souvent utilisé comme verbe\r\nà la deuxième personne du pluriel) qui vient s\'ajouter à cette\r\nproblématique.\r\n\r\nDes approches à base de règles devraient être appliquées idéalement à\r\nl\'aide du logiciel Unitex (Unitex 3.1), couplées avec des approches\r\nstatistiques. Les résultats de ce stage contribueront à l\'amélioration\r\ndu traitement automatique des corpus informatisés de textes allant du\r\nXVIe au XVIIIe siècle, notamment ceux écrits par des femmes utilisés\r\ndans le cadre du projet de recherche Cité des Dames. Les outils\r\ndéveloppés le seront sous licence libre.\r\n\r\nProfil recherché \r\n--------------------------------------- \r\nFormation en cours : Master en traitement informatique des langues ou en\r\ninformatique.\r\n\r\nCompétences requises \r\n--------------------------------------- \r\n- un langage de script (Python de préférence, ou Javascript) \r\n- capacité d\'explorer de nouvelles méthodes statistiques en TAL \r\n- analyse morphosyntaxique et bonne connaissance d\'outils et logiciels\r\n  TAL\r\n\r\nCompétences complémentaires utiles \r\n--------------------------------------- \r\n- manipulation de fichiers XML \r\n- connaissances en graphes Unitex et en grammaires locales \r\n- utilisation d\'outils de versionnement (Git) \r\n\r\nDurée et gratification \r\n--------------------------------------- \r\nLe stage aura lieu sur une durée d\'au moins 12 semaines réparties au\r\nchoix entre début avril et mi-juillet.\r\n\r\nLa gratification versée correspond au montant légal, avec remboursement\r\npartiel des frais de transport.\r\n\r\nContacts \r\n---------- \r\nMerci d\'envoyer, le 16 mars 2020 au plus tard, un CV et une lettre de\r\nmotivation à Eleni Kogkitsidou (eleni.kogkitsidou@u-pem.fr) et Philippe\r\nGambette (philippe.gambette@u-pem.fr).\r\n\r\nRéférences \r\n------------------ \r\n\r\n- Abiven, K., & Lejeune, G. (2019). Analyse automatique de documents\r\n  anciens : tirer parti d\'un corpus incomplet, hétérogène et\r\n  bruité. Recherche d\'information, Document et Web Sémantique, 2(1),\r\n  1-15. https://doi.org/10.21494/iste.op.2019.0335\r\n- Bollman, M. (2019). « A Large-Scale Comparison of Historical Text\r\n  Normalization Systems », NAACL-HLT 2019.\r\n- Catach, L. (1996). « Graphist : Logiciel de lemmatisation, indexation\r\n  et modernisation automatique de textes anciens », Digital Studies/le\r\n  Champ Numérique, (4). http://doi.org/10.16995/dscn.215\r\n- Gabay, S., Riguet, M. & Barrault, L. (2019). « A Workflow For On The\r\n  Fly Normalisation Of 17th c. French », DH 2019, ADHO.\r\n- Souvay, G., & Pierrel, J.-M. (2009). « LGeRM Lemmatisation des mots en\r\n  Moyen Français ». Traitement Automatique Des Langues, 50(2), 21.\r\n- Unitex 3.1, User Manual. Disponible sur : https://unitexgramlab.org.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(632, '2020-02-13', 'BCL', 'Nice', 'OFFRE DE STAGE\r\n\r\nSTAGE pour un.e. étudiant.e. de Master 1 ou 2\r\n\r\n        Recherche outillée sur les corpus en littérature\r\n\r\nAxe transversal \"Nouvelles textualités. Statistique, pragmatique,\r\nénonciation\",\r\nLaboratoire Bases, corpus, langage (UMR 7320), Année 2020.\r\n\r\n\r\nEn appui à nos projets de recherche, nous proposons 1 stage de 4 à 6\r\nmois en exploitation des corpus textuels, en particulier littéraires.\r\n\r\nSpécialité recherchée : un.e. étudiant curieux.se. des nouvelles\r\napproches des textes littéraires.\r\n\r\nProfil du candidat : étudiant.e en Lettres ou Sciences du langage\r\nayant un intérêt pour les outils numériques appliqués à la recherche\r\nlittéraire. Niveau Master 2 ou Master 1. Le stage a pour objectif de\r\npréparer un travail de thèse au sein de BCL, sur les corpus\r\nlittéraires.\r\n\r\n    Contexte\r\n\r\nAu sein de l\'UMR BCL, un axe réunit au moins deux équipes : l\'équipe\r\n\"Linguistique de l\'énonciation\" et l\'équipe \"Logométrie. Corpus,\r\ntraitements, modèles\". Cet axe transversal s\'intéresse aux nouvelles\r\ntextualités, notion qui peut être envisagée comme nouvelles\r\nproductions textuelles mais aussi comme nouvelles approches du texte\r\nlittéraire. C\'est cette seconde perspective qui est privilégiée pour\r\nce stage.\r\n\r\nL\'étudiant.e. pourra travailler sur les nouvelles formes de\r\ntextualités induites par les textes littéraires numérisés. On pourra\r\ns\'interroger sur la délinéarisation du texte électronique et sur la\r\nlecture rhizomatique. Le deep learning et l\'application de\r\nl\'intelligence artificielle aux textes littéraires pourra être\r\nexpérimentée ; on pourra également observer la transformation des\r\ntextes anciens en nouveaux objets textuels par le transfert numérique.\r\n\r\n    Objectifs du travail\r\n\r\nLe stagiaire devra, sous la responsabilité de membres de l\'équipe\r\nLogométrie, enseignant et ingénieur d\'étude :\r\n- choisir une base de données littéraires : voir à titre d\'exemples\r\n    http://logometrie.unice.fr/pages/bases/\r\n- exploiter les données avec les outils disponibles au laboratoire\r\n- tester différentes méthodes d\'analyse\r\n- interpréter les résultats d\'un point de vue stylistique\r\n\r\n    Compétences recherchées\r\n\r\n- excellente maîtrise de la langue française\r\n- très bonnes capacités rédactionnelles\r\n- capacité à organiser son propre travail avec rigueur\r\n- curiosité pour les nouvelles technologies\r\n\r\n    Cadre du stage\r\n\r\nLa.e stagiaire sera accueilli au sein du laboratoire Bases, corpus,\r\nlangage. Il ou elle sera accompagné.e dans son travail par deux\r\nencadrants et travaillera en collaboration avec plusieurs\r\nchercheuse.eur.s de l\'unité.\r\n\r\nDurée et date de début du contrat :\r\nLe stage est prévu au printemps-été 2020.\r\n\r\nMontant de la gratification : 591,51 euros/mois\r\n\r\n    Répondre à l\'offre\r\n\r\nLes candidats doivent envoyer :\r\n(1) un CV, (2) une lettre de motivation et (3) une lettre de\r\nrecommandation d\'un enseignant par mail, ayant comme objet :\r\n[Stage Nouvelles textualités BCL] Candidature de M/Mme Prénom NOM\r\nà Véronique Magri :\r\n    magri@unice.fr'),
(633, '2020-03-24', 'STIH', 'Paris', 'Comparaison de résultats d\'outils de Détection d\'Entités Nommées\r\n\r\nDescription du stage\r\n---------------------------------------\r\nL\'extraction d\'entités nommées (NER) est un domaine très actif du\r\ntraitement Automatique des Langues en particulier pour la reconnaissance\r\nd\'entités de lieux ou de personnes. Seulement, les progrès affichés par\r\nles systèmes concernent principalement des cas très spécifiques en terme\r\nde langues d\'application, de bruitage des données (données standard ou\r\nnon ...) ou encore de types de données utilisées (registres de langue,\r\ngenre textuels...).\r\n\r\nDès lors, il est difficile pour les utilisateurs finaux, notamment dans\r\nle domaine des humanités numériques, de trouver l\'outil approprié sans\r\ndevoir sacrifier leurs besoins aux limites des systèmes considérées\r\nsurtout que les scores affichés par les systèmes sont souvent obtenus\r\nsur des données d\'évaluation très spécifiques, en \"conditions de\r\nlaboratoire\".\r\n\r\nNombre de systèmes ne font que fournir des mentions d\'entités nommées\r\ndans un texte déjà formaté, rares sont les outils capables de prendre un\r\ntexte non normalisé et de le traiter de bout en bout, jusqu\'à la\r\nproduction d\'un résultat structuré selon un format normé en passant par\r\nl\'analyse.\r\n\r\nDivers systèmes ont été conçus sur les même données ou sur des données\r\nsimilaires, quelques études comparent différentes approches (Augenstein\r\net al. 2017, Dupont 2017), mais assez peu étudient l\'intersection des\r\noutils et, à l\'inverse, leur complémentarité. Un travail de ce stage\r\nserait de comparer des outils afin d\'établir un différentiel des outils\r\net de mieux estimer les apports spécifiques de chacun.\r\n\r\nLes systèmes existants sont souvent appris sur du texte bien formé\r\n(domaine sources) comme les articles de journaux (Sagot et al. 2012).\r\nAvec l\'arrivée du Web 2.0 et les contenus générés par les utilisateurs,\r\nde plus en plus de tâches (dont la reconnaissance d\'entités nommées)\r\nportent attention sur ces données bruitées et souvent mal formées\r\n(Ritter et al. 2012).\r\n\r\nL\'utilisation d\'un tel système (de reconnaissance d\'entités nommées par\r\nexemple) sur ces données bruitées (domaine cible) nécessite donc une\r\nadaptation au domaine (Xiao et al. 2015, Tian et al. 2016). La\r\ncouverture multilingue est aussi un enjeu important dans le domaine.\r\n\r\nAucune définition des entités nommées ne fait à l\'heure actuelle\r\nconsensus, malgré divers efforts pour proposer un cadre général (Ehrmann\r\n2008, Sekine & Ranchlod 2009, Grouin et al. 2011). Bien souvent, ces\r\ntypes génériques ne correspondent pas exactement à des types d\'entités\r\nd\'intérêt, où une couche supplémentaire de sémantique est souvent\r\nnécessaire. Par exemple, une personne peut être auteur(rice) dans le\r\ncadre bibliographique, partie ou membre de la cour dans un contexte de\r\ndécisions de justice, etc. Bien souvent, de nouveaux systèmes sont créés\r\ndepuis zéro pour répondre à cette demande. Au meilleur de notre\r\nconnaissance, aucune étude n\'a été montré sur l\'adaptation d\'un schéma\r\nd\'annotation général ou d\'outils déjà existants. Un travail de ce stage,\r\nsi le temps le permet, serait d\'étudier ce point particulier.\r\n\r\nObjectifs du stage\r\n---------------------------------------\r\nFusionner et comparer sur des corpus variés les résultats d\'outils\r\nexistants pour deux langues autres que l\'anglais (Allemand, Français,\r\nChinois ...). Ceci ne nécessite pas d\'être un locuteur des langues\r\nconsidérées même si cela peut être un plus.\r\n\r\nProfil recherché\r\n---------------------------------------\r\nMaster 1 ou master 2 Traitement Automatique des langues , Humanités\r\nNumériques ou profil équivalent\r\n\r\nCompétences requises\r\n---------------------------------------\r\n- Langage de script (Python de préférence).\r\n- Notions en Traitement Automatique du Langage (TAL).\r\n\r\nCompétences complémentaires\r\n---------------------------------------\r\n- Connaissance en apprentissage Automatique.\r\n- Connaissance d\'un ou plusieurs outils d\'extraction d\'Entités Nommées.\r\n\r\nLieu de Stage\r\n---------------------------------------\r\nÉquipe de Linguistique Computationnelle du laboratoire STIH (Sorbonne\r\nUniversité)\r\nMaison de la Recherche 28, rue Serpente, Paris (métro St Michel/Odéon)\r\n\r\nDurée et gratification\r\n---------------------------------------\r\nLe stage aura lieu sur une durée de 3 à 6 mois (selon profil). Le\r\ndémarrage du stage se ferait au 1er Juin 2020, à voir selon évolution de\r\nla situation.\r\n\r\nLa gratification versée correspond au montant légal, avec remboursement\r\nde 50% des frais de transport (pass Navigo).\r\n\r\nContacts\r\n----------\r\nYoann Dupont yoann.dupont@paris-sorbonne.fr\r\nTian Tian tian.tian@sorbonne-universite.fr\r\nGaël Lejeune gael.lejeune@sorbonne-universite.fr\r\n\r\nRéférences\r\n------------------\r\n\r\nAugenstein, I., Derczynski, L., & Bontcheva, K. (2017). Generalisation\r\nin named entity recognition: A quantitative analysis. Computer Speech &\r\nLanguage, 44, 61-83.\r\n\r\nDupont, Y. (2017, June). Exploration de traits pour la reconnaissance\r\nd\'entités nommées du Français par apprentissage automatique. In TALN\r\n2017.\r\n\r\nEhrmann, M. (2008). Les Entitées Nommées, de la linguistique au TAL:\r\nStatut théorique et méthodes de désambiguïsation (Doctoral\r\ndissertation).\r\n\r\nGrouin, C., Rosset, S., Zweigenbaum, P., Fort, K., Galibert, O., &\r\nQuintard, L.  (2011, June). Proposal for an extension of traditional\r\nnamed entities: From guidelines to evaluation, an overview. In\r\nProceedings of the 5th linguistic annotation workshop\r\n(pp. 92-100). Association for Computational Linguistics.\r\n\r\nRitter, A., Clark, S., & Etzioni, O. (2011, July). Named entity\r\nrecognition in tweets: an experimental study. In Proceedings of the\r\nconference on empirical methods in natural language processing\r\n(pp. 1524-1534). Association for Computational Linguistics.\r\n\r\nSagot, B., Richard, M., & Stern, R. (2012, June). Annotation\r\nréférentielle du Corpus Arboré de Paris 7 en entités nommées.\r\n\r\nSekine, S., & Ranchhod, E. (Eds.). (2009). Named entities: recognition,\r\nclassification and use (Vol. 19). John Benjamins Publishing.\r\n\r\nTian, T., Dinarelli, M., Tellier, I., & Cardoso, P. D. (2016,\r\nMay). Domain Adaptation for Named Entity Recognition Using CRFs. In\r\nProceedings of the Tenth International Conference on Language Resources\r\nand Evaluation (LREC\'16) (pp.  561-565).\r\n\r\nXiao, M., & Guo, Y. (2015, July). Learning hidden markov models with\r\ndistributed state representations for domain adaptation. In Proceedings\r\nof the 53rd Annual Meeting of the Association for Computational\r\nLinguistics and the 7th International Joint Conference on Natural\r\nLanguage Processing (Volume 2: Short Papers) (pp. 524-529).'),
(634, '2020-10-19', 'Kaisens Data', 'La Défense', 'Kaisens Data est un éditeur de logiciels spécialisé en NLP/NLG.\r\nNous proposons de nombreuses APIs de génération de texte multilingues\r\net d\'analyse sémantique des données.\r\n\r\nNos solutions sont utilisées par de grands groupes notamment : Total,\r\nTechnipFMC, Saint Gobain, la Société Générale etc.\r\n\r\n\r\n\r\nDescriptif du stage\r\n\r\nVous serez encadré par un Data Scientist senior, PhD, spécialisé en\r\nNLP, et vous mènerez des projets qui auront vocation à devenir les\r\nfutures fonctions innovantes de nos APIs.\r\nLes tâches principales :\r\n-   Étudier l\'état de l\'art des modèles basés sur les deep Learnining\r\n    et les systèmes experts\r\n-   Implémenter les approches à base de Deep Learning et de système\r\n    expert, et évaluer leur valeur ajoutée dans notre contexte.\r\n-   Entrainer vos propres modèles sur des corpus disponibles.\r\n-   Assurer une veille technologique sur l\'état de l\'art en NLP\r\n-   Faire rayonner le savoir-faire de Kaisens Data en NLP\r\n\r\nProfil recherché\r\n-   Vous êtes issu d\'une formation spécialisée en NLP ou machine\r\n    Learning,\r\n-   Vous maîtrisez la théorie et la pratique de certaines techniques de\r\n    NLP.\r\n-   Vous savez travailler avec Python éventuellement des GPU,\r\n-   Vous êtes curieux, créatif et vous aimez faire partager vos\r\n    connaissances.\r\n\r\nLe processus de recrutement se déroule en 3 étapes : un entretien\r\nvisio/call RH + 1 test technique + 1 entretien présentiel\r\n\r\n-   Type de contrat : Stage de pré-embauche 3 ou 6 mois\r\n-   Lieu : La Défense, France (92400)\r\n-   Niveau d\'études : Bac + 4 ou Bac+5 / Master\r\n-   Expérience : < 6 mois\r\n\r\n     Aymen KHELIFI\r\n     Data scientist associé, PhD\r\n\r\n     9 allée de l\'Arche, 92671 Courbevoie\r\n     aymen.khelifi@kaisensdata.fr\r\n\r\n     Bureau : +33 (0)1 46 49 32 61\r\n     Mobile :  +33 (0)6 79 25 77 95\r\n     www.kaisensdata.fr'),
(635, '2020-11-04', 'Akio', 'Montpellier ou Paris', 'Offre de stage chez Akio\r\n\r\nTitre: Annotateur de langue espagnole\r\n\r\nDescriptif:\r\nLe sujet proposé traite de la qualification de verbatim en espagnol\r\npour le compte d\'un éditeur de logiciel français dans le domaine de la\r\nrelation client.\r\n\r\n\r\nDescription du poste:\r\nL\'objectif du stage est principalement d\'annoter des verbatim en\r\nespagnol à partir d\'un outil spécifiquement créé auquel vous serez\r\nformé. Il s\'agit d\'annoter des textes de sources diverses (emails, avis\r\nclients, textes en provenance des réseaux sociaux) afin de déterminer\r\npour chaque segment le sentiment associé : positif, négatif ou neutre.\r\n\r\nL\'autre objectif est de contribuer à l\'annotation sémantique et\r\nl\'exploration textuelle des données afin d\'être en mesure d\'en détecter\r\nles thèmes relatifs à la relation client.\r\n\r\n\r\nProfil recherché:\r\n-   Niveau Licence minimum en linguistique ou en traitement automatique\r\n    du langage\r\n-   Très bon niveau en espagnol\r\n-   Grande rigueur\r\n-   Bonne maîtrise des outils informatiques\r\n\r\nDurée:\r\n2 mois\r\n\r\nDate début de stage\r\nASAP\r\n\r\nLieu:\r\nLe stage pourra se dérouler sur notre site de Paris (75010) ou\r\nMontpellier (quartier Antigone)\r\n\r\n\r\nAkio\r\nEquipe: traitement automatique de la langue.\r\n43 rue de Dunkerque, 75010 Paris.\r\nwww.akio.com\r\n\r\n\r\nGratification:\r\nSelon les règles en vigueur avec participation aux frais de transports\r\nen commun et repas.\r\n\r\nEncadrement:\r\nLe stage sera encadré par Lynda Ould Younes\r\n\r\nCandidature:\r\nMerci d\'envoyer un CV à srumeur@akio.com et louldyounes@akio.com\r\naccompagné des notes de l\'année universitaire en cours et de celles\r\nde l\'année dernière.'),
(636, '2020-11-17', 'CEA/LIMSI/LORIA', 'NR', 'Mots-clés : traitement automatique de la langue, similarité, domaine\r\nbiomédical\r\nDurée : 5 mois\r\nNiveau : Master 2 (professionnel ou recherche), fin d\'école d\'ingénieur\r\nRémunération : Indemnité de stage, soit ~ 600 ¤/mois, indemnité de\r\ntransport incluse\r\n\r\nContexte\r\n       L\'apprentissage automatique est un levier important des\r\ntechnologies du langage. Il repose sur la disponibilité de corpus\r\nannotés pour définir des méthodes, entraîner des modèles et évaluer des\r\nalgorithmes. Ces données doivent être représentatives de différents\r\nphénomènes linguistiques (formulations syntaxiques, distribution\r\nstatistique de l\'emploi de termes spécifiques, erreurs humaines telles\r\nque les fautes d\'orthographe, etc.) afin de garantir la robustesse des\r\nméthodes et outils développés. Par ailleurs, les données doivent\r\négalement être partageables afin de garantir la transparence et la\r\nreproductibilité des expériences.\r\n       Dans le domaine biomédical, le secret médical et la préservation\r\nde la confidentialité s\'accompagnent d\'un cadre réglementaire qui\r\nrestreint l\'accès aux données textuelles telles que les comptes-rendus\r\nhospitaliers dans un objectif de recherche en traitement automatique de\r\nla langue. Le partage des documents cliniques n\'est possible qu\'après\r\nanonymisation, c\'est à dire un traitement des textes qui garantisse\r\nscientifiquement l\'impossibilité de savoir que des informations\r\nconcernant un individu donné sont présentes dans les textes, de\r\nré-identifier tout individu concerné par les textes, ou de faire des\r\ninférences sur les informations concernant ces individus.\r\n\r\nObjectifs du stage\r\nL\'objectif de ce projet est d\'analyser un corpus de documents cliniques\r\ndu point de vue de la similarité entre énoncés. Ce travail permettra\r\nd\'identifier dans un corpus clinique les phrases les plus similaires à\r\nune phrase source en utilisant un large éventail de mesures de\r\nsimilarité, y compris des modèles de recherche d\'informations,\r\nreprésentations vectorielles denses (Johnson et al. 2019), réseaux\r\nsiamois ( Neculoiu et al. 2016 ).\r\n\r\nApproche proposée\r\nNous nous intéressons ici à la constitution d\'un corpus de phrases\r\nredondantes. L\'approche suivie par Li et al. (2015) consiste à filtrer\r\nles phrases par fréquence et à conserver les phrases qui reviennent à\r\nl\'identique dans les compte-rendu de différents patients. Si cette\r\napproche permet d\'éliminer les phrases de faible fréquence contenant\r\npotentiellement des données identifiantes, elle élimine également les\r\nphrases contenant des données cliniques (résultats de laboratoire)\r\nalors que nous souhaitons disposer d\'outils du TAL capables de les\r\ntraiter. La solution que nous envisageons vise à produire des données\r\nfictives mais néanmoins réalistes sur les plans cliniques (permettant\r\nune association entre plusieurs données cliniques telles que\r\ndescriptions et résultats de laboratoire) et linguistiques en\r\nidentifiant en plus des phrases strictement identiques des groupes de\r\nphrases similaires qui pourraient donner lieu à la production de\r\nphrases anonymes et réalistes en générant une nouvelle variante non\r\nrencontrée en corpus. A partir d\'une phrase synthétique (générée),\r\nl\'examen des phrases réelles les plus similaires permettra de\r\nsélectionner des phrases conformes au principe de k-anonymat (Sweeny,\r\n2002).\r\nDans ce contexte, nous prévoyons de confier au stagiaire de M2 une\r\nétude exploratoire permettant d\'implémenter plusieurs méthodes de\r\ncalcul de similarité entre énoncés (phrases) et d\'analyser la\r\nprévalence de différents types de similarité au sein de deux corpus\r\nclinique en français : un corpus réel (LERUDI) et un corpus\r\nsynthétique, issu de la traduction de documents américain (MIMIC).\r\n\r\nProgramme de Travail :\r\n    -   Identifier les phrases identiques dans un corpus\r\n        -   Prendre en charge le pré-traitement du corpus:\r\n            découpage en phrase, ...\r\n    -   Identifier des phrases similaires dans un corpus\r\n        -   Etudier différents types de « similarités » :\r\n            distance de Levenshtein, similarité Dice ou cosine,\r\n            homologie, similarité à partir de plongements de phrases à\r\n            l\'aide d\'outils fournis (module Text::Similarity dans PERL,\r\n            BLAST, librairie FAISS, ...)\r\n    -   Si l\'avancement du travail le permet, proposer une\r\n        visualisation des résultats\r\n\r\nRéférences\r\nJohnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity\r\nsearch with GPUs. IEEE Transactions on Big Data.\r\nLi D, Rastegar-Mojarad M, Li Y, Sohn S, Mehrabi S, Elayavilli R, Yu Y,\r\nLi, H, Wang Y.  2015. A Frequency-based Strategy of Obtaining Sentences\r\nfrom Clinical Data Repository for Crowdsourcing. Studies in health\r\ntechnology and informatics. 216:1033-4.\r\nNeculoiu, P., Versteegh, M., & Rotaru, M. 2016. Learning text\r\nsimilarity with siamese recurrent networks. In Proceedings of the 1st\r\nWorkshop on Representation Learning for NLP:148-157.\r\nSweeney, L. (2002). k-anonymity : A model for protecting privacy.\r\nInternational Journal of Uncertainty, Fuzziness and Knowledge-Based\r\nSystems, 10(05) :557-570.\r\n\r\nCompétences souhaitées:\r\nLe.a stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue seront\r\nparticulièrement appréciées. Le contenu et l\'ambition du stage pourront\r\nêtre modulés en fonction du niveau d\'étude et de la durée du stage\r\ndu/de la candidat.e. Une poursuite en thèse sur la génération\r\nd\'énoncés similaires est possible dans le cadre de l\'ANR CODEINE.\r\n\r\nPour candidater :\r\nEnvoyer un CV, un relevé de notes récent ainsi que les coordonnées\r\n(nom, mail) d\'au moins deux référent.e.s (professeur.e.s ou\r\nencadrant.e.s de précédents stages ou emplois pouvant attester de vos\r\ncompétences) à Aurelie.Neveol[at]limsi.fr, Olivier.FERRET[at] cea.fr\r\net karen.fort [at] loria.fr'),
(637, '2020-11-17', 'LIG', 'Grenoble', 'The LIG (Laboratoire d\'Informatique de Grenoble) proposes the following\r\nMaster 2 level internship:\r\n\r\n*Title*: Multi-Task Neural Spoken Language Understanding from Speech\r\n\r\n*Description*: Spoken Language Understanding (SLU) is an important part\r\nof Human-Computer Interaction (HCI), and aims at extracting semantic\r\ninterpretations from human utterances [De Mori, 2008]. Because of the\r\nhigh complexity of the problem, most real applications focus on\r\nspecific narrow domains, e.g. hotel reservation and information\r\n[Bonneau-Maynard et al., 2005].\r\nTraditionaly, SLU was performed from automatic transcriptions of the\r\nspeech signal or, at best, on a word lattices. With the emergence of\r\nDeep Neural Networks (DNN), SLU can be performed directly from speech\r\nsignal, overcoming or at least alleviating the problems related to\r\nautomatic transcription. Such end-to-end approaches from speech have\r\nbeen already proposed for spoken language translation [Berard et al.,\r\n2018; Berard et al., 2016; Weiss et al., 2017], and more recently for\r\nE2E SLU [Qian et al., 2017; Serdyuk et al., 2018; Haghani et al., 2018;\r\nDesot et al., 2019; Caubrière et al., 2019].\r\nAdditionally, the use of Neural Networks such like RNNs (LSTM/GRU)\r\n[Hochreiter and Schmidhuber, 1997; Cho et al., 2014] and Transformers\r\n[Vaswani et al., 2017], in combination with attention mechanisms\r\n[Bahdanau et al., 2014], allows potentially to use contextual\r\ninformation going beyond the single or a few dialog turns [Bothe et al.,\r\n2018]. This information is possibly crucial to solve long-range\r\nambiguïties.\r\n\r\nIn this internship the student will investigate multi-task learning\r\nusing several neural models, decoding semantic interpretations directly\r\nfrom the speech signal and learning SLU tasks in a multi-task learning\r\nframework.\r\nThe student will use modular pre-built systems based on Convolutional\r\nand Recurrent Neural Networks [Berard et al., 2018; Dinarelli et al.,\r\n2020] and/or Transformer networks, with the objective of creating a\r\nwhole integrated SLU system. The student will run experiments using the\r\nteam GPUs, and the system will be evaluated on the SLU benchmarks\r\ncorpora MEDIA [Bonneau-Maynard et al.,2006, Hahn et al., 2010],\r\nPORT-MEDIA [Lefévre et al., 2012] and VOCADOM [Desot et al., 2019]\r\n\r\nProfile:\r\n\r\n   - Master 2 student level in computer science or NLP\r\n   - Interested in Natural Language Processing\r\n   - Skills in machine learning for probabilistic models\r\n   - Computer science skills:\r\n\r\n\r\n   1.   Python programming with good knowledge of deep learning\r\n        libraries Pytorch and Fairseq\r\n   2.   Data manipulation (both textual data and audio signal)\r\n\r\nThe internship may last from 5 up to 6 months, it will take place at\r\nLIG laboratory, GETALP team (http://lig-getalp.imag.fr/), starting from\r\nJanuary/February 2021. The student will be tutored by Marco Dinarelli\r\n(http://www.marcodinarelli.it), and François Portet\r\n(https://lig-membres.imag.fr/portet/home.php)\r\n\r\nInterested candidates must send a CV and a motivation letter to\r\nmarco.dinarelli@univ-grenoble-alpes.fr and/or françois.portet@imag.fr\r\n\r\nDesot, T., Portet, F., and Vacher, M. (2019). Slu for voice command in\r\nsmart home: Comparison of pipeline and end-to-end approaches. In 2019\r\nIEEE Automatic Speech Recognition and Understanding Workshop (ASRU),\r\npages 822-829. IEEE.\r\n\r\nGhannay, S., Caubrière, A., Estève, Y., Camelin, N., Simonnet, E.,\r\nLaurent, A., and Morin, E. (2018). End-to-end named entity and semantic\r\nconcept extraction from speech. In 2018 IEEE Spoken Language Technology\r\nWorkshop (SLT), pages 692-699. IEEE.\r\n\r\nHaghani, P., Narayanan, A., Bacchiani, M., Chuang, G., Gaur, N.,\r\nMoreno, P., Prabhavalkar, R., Qu, Z., and Waters, A. (2018). From audio\r\nto semantics: Approaches to end-to-end spoken language understanding.\r\nIn 2018 IEEE Spoken Language Technology Workshop (SLT), pages 720-726.\r\n\r\nQian, Y., Ubale, R., Ramanaryanan, V., Lange, P., Suendermann-Oeft, D.,\r\nEvanini, K., and Tsuprun, E. (2017). Exploring asr-free end-to-end\r\nmodeling to improve spoken language understanding in a cloud-based\r\ndialog system. In 2017 IEEE Automatic Speech  Recognition and\r\nUnderstanding Workshop (ASRU), pages 569-576. IEEE.\r\n\r\nSerdyuk, D., Wang, Y., Fuegen, C., Kumar, A., Liu, B., and Bengio, Y.\r\n(2018). Towards end-to-end spoken language understanding. In 2018 IEEE\r\nInternational Conference on Acoustics, Speech and Signal Processing\r\n(ICASSP), pages 5754-5758.'),
(638, '2020-11-25', 'LIMSI', 'Orsay', 'Le LIMSI propose un sujet de stage dont le sujet est détaillé ci-dessous\r\nSi ce sujet vous intéresse, contactez sahar.ghannay@limsi.fr ou\r\nsophie.rosset@limsi.fr.\r\n\r\nTitle :\r\n\r\nDialogue history integration\r\n\r\nContact :\r\n\r\nMaster internship at LIMSI CNRS\r\n\r\nSahar Ghannay (ghannay@limsi.fr), Sophie Rosset (rosset@limsi.fr)\r\n\r\nSubject :\r\n\r\nThe proposed internship is about task-oriented dialogue system working\r\non the cooking domain. This dialogue system handles two different types\r\nof scenarios : (1) the user wants to find a recipe meeting his/her\r\ncriteria, and (2) the user asks a question related to the cooking\r\ndomain. For the first scenario, the system accesses a database which\r\ncontains recipes. For the second scenario, the system accesses\r\nunstructured data using a community question answering module.\r\n\r\nFor, this internship we are interested in two tasks. First, we propose\r\nto investigate the use of new approaches to integrate the dialog\r\nhistory in different modules of the dialogue system including the NLU\r\nand cQA modules. Thus, these modules have to capture the common\r\ninformation between the dialog history and the candidate answers. The\r\nsecond task concerns the evaluation of the different modules and of the\r\ndialogue system through user simulation.\r\n\r\nSome of those terms are defined as follows :\r\n- Dialogue system : a dialogue system allows a user to interact using\r\nnatural language [DRO+19]. Two families of dialogue systems exist :\r\nconversational systems and task-oriented systems. Conversational\r\nsystems have to generate the most appropriate reaction given a user\'s\r\nutterance and a context, without any restriction about the domain.\r\nA task-oriented system aims to help the user perform a task or access\r\ninformation. A dialogue system generally consists of three modules :\r\nnatural language understanding (NLU), dialogue management and natural\r\nlanguage generation (NLG).\r\n\r\n- NLU takes as input the utterance of the user and returns the slots\r\nand the intent associated to this utterance. Considering the following\r\nuser utterance :\"Please find me a recipe of pancakes without eggs\", the\r\nNLU should detect the slots \"recipe : pancakes\" and \"neg-ingredient :\r\neggs\" plus the intent \"RECING\",that means that the user is looking for\r\na recipe by giving the name of the recipe and the ingredients.\r\n\r\n- Community Question Answering : Community Question Answering (cQA)\r\n[Pat17] forums, such as Quora and Stack overflow offer a new\r\nopportunity for users to provide, search and share knowledge. The cQA\r\nsystem consists on automatically search for relevant answers among many\r\nresponses provided for a given question, and search for relevant\r\nquestions to reuse their existing answers.\r\n\r\nMany approach have been proposed to integrate dialogue history\r\n[TRC+20, BZZZ19, PRMU18, BTHTH17]. Popular contextual NLU models\r\n[BTHTH17, BZZZ19] exploit the dialogue history with the memory network\r\n[WCB14].The use of the memory mechanism helps the NLU model to retrieve\r\ncontext knowledge to reduce the ambiguity of the current utterance.\r\nOther approaches propose to represent the dialog history in the form of\r\ndialog history embedding vectors. The embeddings vector can be computed\r\nweather by predicting bag-of-concepts expected in the answer of the\r\nuser from the last dialog system response [TRC+20], or by adapting the\r\nword2vec [MCCD13] approach to compute utterance embeddings that take\r\ninto account dialogue context [PRMU18]. The dialog history embedding\r\nvectors are provided as an additional information to the NLU module.\r\n\r\nHistory modeling is essential for ConvQA, since previous history turns\r\nplay an essential role in understanding the user\'s current information\r\nneed. Some existing methods simply prepend history turns [CCO+20,\r\nRCM19, BHJM19] or mark answers in the passage[CHI+18]. These methods\r\ncannot handle a long conversation history. Another existing method\r\n[HCY18] uses complicated attention mechanisms to model history and thus\r\ngenerates relatively large system overhead. [QYQ+19] propose a history\r\nanswer embedding method to model conversation history. The proposed\r\nmethod is specifically tailored for BERT-based architectures.\r\n\r\nExpected profile\r\n\r\n-   Master 2 profile student in computer Science, specialized at least\r\n    in one of the following topics :\r\n\r\n-   Machine learning\r\n\r\n-   Natural language processing\r\n\r\n-   Technical skills : python, linux\r\n\r\nPractical information\r\n\r\n-   Duration of internship : 5-6 months\r\n\r\n-   Beginning of the internship : start date to be defined with the\r\n    intern\r\n\r\n-   Gratification : around 591.91e /month and reimbursement of\r\n    transport costs and canteen subsidy\r\n\r\nReferences\r\n\r\n[BHJM19] Basma El Amel Boussaha, Nicolas Hernandez, Christine\r\n    Jacquin, and Emmanuel Morin. Multi-level context response matching\r\n    in retrieval-based dialog systems. In Proceedings of the 7th\r\n    edition of the Dialog System Technology Challenges Workshop at AAAI\r\n    (DSTC7\'19). Honolulu, HI, USA, 2019.\r\n[BTHTH17] Ankur Bapna, Gokhan Tür, Dilek Hakkani-Tür, and Larry Heck.\r\n    Sequential dialogue context modeling for spoken language\r\n    understanding. In Proceedings of the 18th Annual SIGdial Meeting on\r\n    Discourse and Dialogue, pages 103-114, Saarbrücken, Germany, August\r\n    2017. Association for Computational Linguistics.\r\n[BZZZ19] He Bai, Yu Zhou, Jiajun Zhang, and Chengqing Zong. Memory\r\n    consolidationfor contextual spoken language understanding with\r\n    dialogue logistic inference.In Proceedings of the 57th Annual\r\n    Meeting of the Association for Computational Linguistics, pages\r\n    5448-5453, 2019.\r\n[CCO+20] Jon Ander Campos, Kyunghyun Cho, Arantxa Otegi, Aitor Soroa,\r\n    Gorka Azkune,and Eneko Agirre. Improving conversational question\r\n    answering systems after deployment using feedback-weighted\r\n    learning. arXiv preprint arXiv:2011.00615, 2020.\r\n[CHI+18] Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih,\r\n    Yejin Choi, PercyLiang, and Luke Zettlemoyer. Quac: Question\r\n    answering in context. arXiv preprint arXiv:1808.07036, 2018.\r\n[DRO+19] Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen,\r\n    Sophie Rosset, Eneko Agirre, and Mark Cieliebak. Survey on\r\n    evaluation methods for dialogue systems. arXiv preprint\r\n    arXiv:1905.04071, 2019.\r\n[HCY18] Hsin-Yuan Huang, Eunsol Choi, and Wen-tau Yih. Flowqa:\r\n    Graspingflow in history for conversational machine comprehension.\r\n    arXiv preprint arXiv:1810.06683, 2018.\r\n[MCCD13] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.\r\n    Efficient estimation of word representations in vector space. arXiv\r\n    preprint arXiv:1301.3781, 2013.\r\n[Pat17] Barun Patra. A survey of community question answering.CoRR,\r\n    abs/1705.04009,2017.\r\n[PRMU18] Louisa Pragst, Niklas Rach, Wolfgang Minker, and Stefan Ultes.\r\n    On the vector representation of utterances in dialogue context. In\r\n    Proceedings of the Eleventh International Conference on Language\r\n    Resources and Evaluation (LREC 2018), 2018.\r\n[QYQ+19] Chen Qu, Liu Yang, Minghui Qiu, W Bruce Croft, Yongfeng Zhang,\r\n    and Mohit Iyyer. Bert with history answer embedding for\r\n    conversational question answering. In Proceedings of the 42nd\r\n    International ACM SIGIR Conference on Research and Development in\r\n    Information Retrieval, pages 1133-1136, 2019.\r\n[RCM19] Siva Reddy, Danqi Chen, and Christopher D Manning. Coqa:\r\n    A conversational question answering challenge. Transactions of the\r\n    Association for Computational Linguistics, 7:249-266, 2019.\r\n[TRC+20] Natalia Tomashenko, Christian Raymond, Antoine Caubrière,\r\n    Renato De Mori,and Yannick Estève. Dialogue history integration\r\n    into end-to-end signal-to-concept spoken language understanding\r\n    systems. In ICASSP 2020-2020 IEEE International Conference on\r\n    Acoustics, Speech and Signal Processing (ICASSP), pages 8509-8513.\r\n    IEEE, 2020.\r\n[WCB14] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory\r\n    networks. arXiv preprint arXiv:1410.3916, 2014.'),
(639, '2020-11-25', 'IMT-Atlantique / LS2N', 'Brest ou Nantes', 'Offre de stage Master Recherche en EIAH et TALN/Fouille de texte\r\n===============================\r\n\r\nTitre : Explorer le contenu textuel des forums des MOOCs pour analyser\r\n        le niveau d\'engagement des apprenants\r\nMots-clés : IA, TALN, EIAH, MOOC, e-Learning, modèle de l\'apprenant\r\nDurée : 6 mois\r\nGratification : environ 580 ¤/mois\r\nLieu :  selon la situation sanitaire, télétravail ou un des locaux\r\n        suivants :\r\n*   IMT Atlantique, Laboratoire Lab-STICC,\r\n    Technopôle Brest-Iroise CS 29238 Brest. France\r\n*   LS2N (UMR 6004) 2, Rue de la Houssinière\r\n    F-44322 Nantes Cedex 3 - FRANCE\r\nPerspective : la présente offre intervient en contexte de montage de\r\nprojets avec financement de thèse ; un financement effectif devra être\r\nconfirmé.\r\n\r\nContexte et sujet du stage\r\n--------------------------\r\nL\'engouement pour l\'apprentissage en ligne à des fins de formation\r\ncontinue, notamment via les MOOCs (Massive Online Open course), n\'est\r\nplus à prouver[1], et cela indépendamment de situations sociales\r\ncritiques inédites (enseignement d\'une langue à des milliers de\r\nréfugiés, continuité pédagogique de millions d\'enfants et d\'étudiants\r\nen période de confinement mondial) qui soulignent la nécessité d\'avoir\r\nla capacité d\'enseigner (et d\'apprendre) à distance[2]. Pour\r\nl\'UNESCO[3], il est nécessaire de réviser nos stratégies pour être en\r\nmesure de suivre les processus d\'apprentissage à distance des\r\napprenants, de veiller à leur niveau d\'engagement et d\'évaluer leurs\r\nrésultats d\'apprentissage.\r\nDans le cadre d\'un amorçage de collaboration scientifique, l\'équipe\r\nMOTEL (MOdels and Tools for Enhanced Learning) du laboratoire Lab-STICC\r\net l\'équipe TALN (Traitement Automatique du Langage Naturel) du\r\nlaboratoire LS2N s\'associent pour proposer un stage de recherche en\r\ntraitement automatique des langues (TAL) appliqué à l\'apprentissage\r\nhumain et indirectement au développement d\'Environnements informatiques\r\npour l\'apprentissage humain (EIAH).\r\n\r\nObjectifs du stage\r\n------------------\r\nCe stage vise à mener une étude linguistique qualitative et\r\nquantitative des messages entre les différents acteurs (apprenants,\r\ntuteurs, enseignants) d\'un forum de discussion d\'un MOOC afin de 1)\r\nmieux comprendre la nature des participations et des échanges, et par\r\nlà, 2) exprimer des indices langagiers pouvant soutenir la construction\r\nd\'indicateurs nécessaires à l\'estimation du niveau d\'engagement des\r\napprenants dans leur formation. Les fonctions méta-discursives (e.g.\r\nsalutation, demande d\'assistance, acquittement, ...) sont un des indices\r\nenvisagés pour décrire les différentes formes de participation. Une des\r\nactivités consistera à adapter une taxonomie de fonctions existante aux\r\ndonnées manipulées. La dimension émotionnelle pourra être considérée.\r\nCe travail s\'accompagnera d\'une activité d\'annotation manuelle, d\'abord\r\nà des fins d\'exploration puis éventuellement d\'entraînement ou\r\nd\'évaluation d\'un système de reconnaissance automatique. Le travail\r\nd\'exploration doit donner lieu à la définition d\'indices, ainsi qu\'à\r\nl\'implémentation de méthodes permettant leur extraction (prédiction,\r\nreconnaissance...). Diverses approches peuvent être envisagées, de\r\nl\'usage de règles à l\'apprentissage profond en passant par\r\nl\'apprentissage statistique. La langue d\'étude sera le français.\r\nDes perspectives possibles à ce stage concernent la construction\r\nd\'indicateurs d\'engagements à partir de ces indices langagiers,\r\nl\'alimentation d\'un modèle d\'apprenant à l\'aide de ces indicateurs, la\r\nclassification des apprenants selon leur niveau d\'engagement,\r\nl\'alimentation de tableaux de bord destinés aux différents acteurs\r\npédagogiques ou encore la personnalisation de l\'interaction avec un\r\nchatbot.\r\n\r\nMissions\r\n--------\r\n*   Réaliser un état des lieux des recherches scientifiques en analyse\r\n    linguistique des messages échangés sur des forums ;\r\n*   Mener une étude quantitative/qualitative de forums de plateformes\r\n    d\'apprentissage en ligne ;\r\n*   Proposer une taxonomie de fonctions méta-discursives existantes aux\r\n    données et réaliser un travail d\'annotation à des fins\r\n    d\'exploration, d\'évaluation ou d\'entraînement ;\r\n*   Déterminer des indices linguistiques soutenant le calcul du niveau\r\n    d\'engagement des apprenants ;\r\n*   Proposer et implémenter des méthodes automatiques pour l\'extraction\r\n    de ces indices à l\'aide d\'apprentissage et/ou de règles ;\r\n*   Valider la performance de ces systèmes sur un corpus de test ;\r\n*   Produire, synthétiser et restituer les résultats dans un rapport\r\n    et/ou une publication de niveau scientifique.\r\n\r\nBibliographie\r\n-------------\r\n*   Ghada AlHarbi, Thomas Hain, The OpenCourseWare Metadiscourse\r\n    (OCWMD) Corpus. LREC, 2016\r\n*   Chang-Qin Huang, Zhong-Mei Han, Ming-Xi Li, Morris Siu-yung Jong,\r\n    Chin-Chung Tsai, Investigating students\' interaction patterns and\r\n    dynamic learning sentiments in online discussions, Computers &\r\n    Education 140, 2019\r\n*   Kiruthika Ragupathi, Muthu Kumar Chandrasekaran, Min-Yen, Kan,\r\n    Bernard C Y Tan, Investigating student learning in online\r\n    discussion forums through a transactivity framework, ISSoTL,\r\n    Calgary, October 11-14, 2017\r\n*   Denyze Toffoli, De la théorie à la pratique : appliquer des modèles\r\n    cognitifs de la motivation dans un centre de langues,\r\n    ASp, 41-42, 2003\r\n*   Miaomiao Wen, Investigating Virtual Teams in Massive Open Online\r\n    Courses: Deliberation-based Virtual Team Formation, Discussion\r\n    Mining and Support, PhD thesis, Carnegie Mellon University,\r\n    August 16, 2016\r\n\r\nProfil recherché\r\n----------------\r\nCandidat.e de niveau Master Recherche :\r\n*   Des compétences solides en programmation/algorithmique (python)\r\n*   Des notions en TAL, Fouille de texte, Linguistique\r\n    computationnelle, Apprentissage Automatique ou en EIAH\r\n*   Des qualités d\'écriture et d\'organisation. La connaissance du\r\n    français est nécessaire. La pratique de l\'anglais écrit est\r\n    fortement souhaitée.\r\n*   Des qualités relationnelles (accompagnement, collaboration)\r\n*   Un dynamisme, curiosité, sens de l\'organisation et du travail en\r\n    équipe, autonomie et capacité de restitution.\r\n\r\nCandidature\r\n-----------\r\nCV et lettre de motivation à envoyer à nicolas.hernandez à\r\nuniv-nantes.fr et issam.rebai à imt-atlantique.fr\r\n________________\r\n[1] https://www.classcentral.com/moocs-year-in-review-2019\r\n[2] https://www.ifs.org.uk/publications/15038\r\n[3] https://unesdoc.unesco.org/ark:/48223/pf0000373305.locale=en'),
(640, '2020-11-25', 'LIRIS-INSA Lyon', 'Lyon', 'Offre de stage Master Recherche en Science des données et TALN\r\nSujet : Machine Learning et Word Embeddings pour la classification et\r\nl\'analyse d\'articles encyclopédiques\r\n\r\n#########\r\nContexte :\r\nDans le cadre du projet GEODE financé par le LabEx ASLAN nous\r\nrecherchons un stagiaire en informatique pour travailler sur le\r\ndéveloppement et l\'expérimentation de méthodes de classification et\r\nd\'analyse d\'articles encyclopédiques. Il s\'agit de mettre en oeuvre des\r\ntechniques d\'intelligence artificielle adaptées au traitement\r\nautomatique de la langue.\r\nCe stage s\'inscrit dans le cadre d\'une collaboration académique\r\ninterdisciplinaire (informatique, linguistique, géographie et histoire)\r\nayant comme objet principale une étude diachronique des discours\r\ngéographiques au sein des encyclopédies. Ce projet exploratoire\r\nnécessite une activité à l\'interface de plusieurs disciplines\r\n(intelligence artificielle, informatique, et linguistique) pour\r\nélaborer des méthodes innovantes, rapides et fiables de classification\r\nde textes et des modes adéquats de représentation et de visualisation\r\nde l\'information.\r\n\r\n#########\r\nObjectifs du stage :\r\nCe stage a pour objectif principal de développer des modèles\r\nde classification des articles de différentes encyclopédies\r\n(l\'Encyclopédie de Diderot et d\'Alembert (1751-1772), La Grande\r\nEncyclopédie, l\'Encyclopaedia Universalis et Wikipedia). Une première\r\ntâche s\'intéressera en particulier à la sous-classification des\r\narticles de géographie (articles décrivant des lieux : ville, rivière,\r\npays, etc.). Une deuxième tâche sera consacrée à l\'expérimentation et\r\nla génération de modèles de langue permettant une représentation\r\ninformatique des articles pour réaliser une analyse et une comparaison\r\ndes différents corpus. L\'utilisation de méthodes d\'apprentissage\r\nsupervisé ou d\'apprentissage profond sera privilégiée et nécessitera de\r\nréaliser un travail important pour la préparation des données afin de\r\nconstituer les jeux d\'entrainement et de validation.\r\n\r\n#########\r\nBibliographie :\r\n-   Horton, R., Morrissey, R., Olsen, M., Roe, G., & Voyer, R. (2009)\r\n    Mining Eighteenth Century Ontologies: Machine Learning and\r\n    Knowledge Classification in the Encyclopédie, Digital Humanities\r\n    Quarterly, Volume 3 Number 2.\r\n-   Roe, G., Gladstone, C. & Morrissey, R. (2016), Discourses and\r\n    Disciplines in the Enlightenment: Topic Modeling the French\r\n    Encyclopédie. Frontiers in Digital Humanities 2.\r\n-   Vigier, D., Moncla, L., Brenon, A., Mcdonough, K., & Joliveau, T.\r\n    (2020) Classification des entités nommées dans l\'Encyclopédie ou\r\n    dictionnaire raisonné des sciences des arts et des métiers par\r\n    une société de gens de lettres (1751-1772). 7e Congrès Mondial\r\n    de Linguistique Française (CMLF), Montpellier, France.\r\n\r\n\r\n#########\r\nProfil recherché et candidature :\r\n\r\nMaster 2 Informatique\r\nDes compétences sont attendues en programmation, en science des\r\ndonnées (Data Mining et Machine Learning) et en traitement automatique\r\nde la langue (TAL).\r\n\r\nLieu du stage : Laboratoire LIRIS-INSA Lyon, Bâtiment Blaise Pascal,\r\nCampus La Doua, Villeurbanne.\r\n\r\nPériode de stage : 5 à 6 mois entre février et juillet 2021\r\n\r\nEncadrants :\r\nLudovic Moncla, LIRIS UMR 5205 CNRS - INSA Lyon\r\nDenis Vigier, ICAR UMR 5191 CNRS - Université Lumière Lyon 2\r\n\r\nPour candidater, envoyer votre CV et vos derniers relevés de notes par\r\nmail à ludovic.moncla@insa-lyon.fr et denis.vigier@ens-lyon.fr avant le\r\n30 novembre.'),
(641, '2020-11-25', 'LISN / LIMSI', 'Orsay', 'Stage M2 :  Évaluation de l\'impact environnemental des méthodes de\r\n            traitement automatique de la langue.\r\n\r\nMots-clés : traitement automatique de la langue, complexité\r\n            algorithmique\r\n\r\nDurée :     5 mois\r\n\r\nNiveau :    Master 2 (professionnel ou recherche), fin d\'école\r\n            d\'ingénieur\r\n\r\nRémunération :  Indemnité de stage, soit ~ 600 ¤/mois, indemnité de\r\n                transport incluse\r\n\r\nLieu :  Laboratoire LISN/LIMSI, campus de l\'université Paris Saclay à\r\n        Orsay\r\n\r\nContexte\r\n\r\nDe nombreux travaux en Traitement Automatique de la Langue (TAL)\r\ns\'appuient sur des méthodes d\'apprentissage. Ainsi, l\'apprentissage\r\nprofond offre des performances souvent intéressantes pour de nombreuses\r\ntâches d\'analyse de textes. L\'essor récent des méthodes neuronales\r\ndonne lieu à une utilisation croissante de ressources numériques pour\r\nun large éventail de problèmes. Dans ce contexte, les méthodes\r\nsymboliques ou méthodes d\'apprentissage \"classiques\" sont délaissées\r\nalors qu\'une comparaison systématique serait intéressante du point de\r\nvue scientifique, opérationnel et environnemental. En particulier, les\r\nméthodes neuronales ont un impact environnemental élevé qui ne cesse\r\nd\'augmenter avec les années (Schwartz et al., 2019).\r\nUn exemple de travail pertinent en traitement automatique des langues\r\nest présenté par (Strubell et al. 2019), qui a étudié la consommation\r\nénergétique de l\'apprentissage de plusieurs modèles.\r\nSchwartz et al. (2019) prône donc l\'émergence de travaux en\r\nintelligence artificielle « verte » ou Green AI, en parallèle de\r\ntravaux standards, dans lesquels l\'efficience des méthodes serait mise\r\nen valeur, c\'est-à-dire la capacité à obtenir une performance avec un\r\nminimum de ressources.\r\nAinsi il sera intéressant de proposer une comparaison détaillée de\r\nl\'utilisation d\'un large panel de méthodes de traitement automatique de\r\nla langue du point de vue de leur performance, de leur complexité\r\nalgorithmique, du temps humain et machine requis pour les mettre en\r\noeuvre. Pour ce faire, il est nécessaire de s\'intéresser à l\'estimation\r\nde ces critères d\'impact des méthodes numériques.\r\n\r\nObjectifs du stage\r\n\r\nLe stage a pour objectif de recenser et de caractériser les outils\r\ndisponibles pour des travaux en intelligence artificielle verte en ce\r\nqui concerne l\'estimation de l\'impact environnemental des méthodes\r\nnumériques. Les outils recensés seront mis en oeuvre dans le cadre\r\nde l\'application d\'une méthode de traitement automatique de la langue\r\n(par exemple: classification de textes) afin de caractériser\r\nl\'utilisation des outils sur le plan de la facilité de prise en main,\r\nqualité et niveau de détail des informations fournies sur les méthodes\r\nTAL, et tout autre critère d\'évaluation pertinent.\r\n\r\nApproche proposée\r\n\r\nLe stage aura pour objet de réaliser une revue systématique des outils\r\nde mesure de l\'impact environnemental des expériences informatiques.\r\nUne veille de la littérature récente montre que divers outils existent\r\nafin d\'estimer l\'impact des expériences informatiques. On recense\r\nnotamment des outils en ligne (par exemple, Green Algorithms\r\nhttp://www.green-algorithms.org/ et ML CO2 impact\r\nhttps://mlco2.github.io/impact/ ) ou des outils à intégrer dans la mise\r\nen oeuvre des expériences (par exemple, \"experiment impact tracker\"\r\n(Henderson et al., 2020) et \"carbon tracker\" (Anthony et al., 2020)).\r\nNous souhaitons recenser systématiquement les outils existant et les\r\nétudier afin de déterminer les mesures d\'impact calculées, la facilité\r\nde mise en oeuvre, la portée d\'utilisation possible.\r\n\r\nRéférences\r\n\r\n-   Anthony, L. F. W., Kanding, B., and Selvan, R. (2020).\r\n    Carbontracker : Tracking and predicting the carbon footprint of\r\n    training deep learning models. In ICML Workshop on \"Challenges in\r\n    Deploying and monitoring Machine Learning Systems\".\r\n-   Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., and\r\n    Pineau, J. (2020). Towards the systematic reporting of the energy\r\n    and carbon footprints of machine learning.\r\n-   Schwartz, R., Dodge, J., Smith, N. A., and Etzioni, O. (2019).\r\n    Green AI.\r\n-   Strubell, E., Ganesh, A., and McCallum, A. (2019). Energy and\r\n    policy considerations for deep learning in NLP. In Proceedings of\r\n    the 57th Annual Meeting of the Association for Computational\r\n    Linguistics, pages 3645-3650.\r\n\r\nCompétences souhaitées:\r\n\r\nLe.a stagiaire devra avoir de bonnes compétences en informatique. Des\r\nconnaissances en traitement automatique de la langue seront\r\nparticulièrement appréciées. Le contenu et l\'ambition du stage pourront\r\nêtre modulés en fonction du niveau d\'étude et de la durée du stage\r\ndu/de la candidat.e.\r\n\r\nPour candidater :\r\n\r\nEnvoyer un CV, un relevé de notes récent ainsi que les coordonnées\r\n(nom, mail) d\'au moins deux référent.e.s (professeur.e.s ou\r\nencadrant.e.s de précédents stages ou emplois pouvant attester de vos\r\ncompétences) à Anne-Laure.Ligozat[at]limsi.fr et\r\nAurelie.Neveol[at]limsi.fr');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(642, '2020-12-03', 'LIMSI', 'Orsay', 'NL2FL (Natural to Formal Language)\r\n\r\nEncadrants :\r\ngabriel.illouz@limsi.fr, sahar.ghannay@limsi.fr,\r\nVincent Letard, sophie.rosset@limsi.fr,\r\n\r\nSujet\r\n\r\nL\'objet de stage est la traduction de la langue naturelle en langue\r\nformelle, par exemple de l\'anglais au SQL.\r\n\r\nPrenons une base de données sur des avis d\'utilisateurs sur des\r\nrestaurants. Autant\r\n\r\n\"Donner les notes de Encieux Cecile : notes, et nomLieu\"\r\n\r\nest assez direct et se traduit en :\r\n\r\nSELECT noteAvis,messageAvis,nomLieu\r\nFROM ETUDIANT NATURAL JOIN AVIS NATURAL JOIN LIEU\r\nWHERE nomEtudiant=\'Encieux\' AND prenomEtudiant=\'Cecile\';\r\n\r\nAutant, la suivante nécessite de l\'interprétation : \"la note d\'un\r\nrestaurant est calculée comme étant la moyenne des avis sur celui-ci.\r\nElle est stocké dans la table LIEU pour ne pas tre recalculée tout\r\nle temps. Afficher les lieux dont le calcul n\'est pas à jour.\"\r\n\r\nElle se traduit au final par :\r\n\r\nSELECT nomLieu\r\nFROM AVIS NATURAL JOIN LIEU\r\nGROUP BY nomLieu\r\nHAVING AVG(noteAvis) != noteLieu;\r\nLes données utilisées pendant le stage sont composées de 3 792\r\nrequêtes en anglais et leurs équivalent en SQL. Elles sont réparties\r\nen 4 niveaux de difficultés sur 5 bases de données (MOVIEDATA,\r\nCHINOOK, COLLEGE, DRIVING SCHOOL, et FORMULA I). Sur ces données, le\r\nsystme neuronal qui traduit de langue naturelle en langue formelle a\r\ndes performances qui dépassent difficilement 50% [DMS+20].\r\n\r\nLes difficultés  étudier seront celles liées au transfert\r\nd\'apprentissage, aux interprétations linguistiques, aux ambiguïtés\r\nqui devront être détectées entre les deux langues.\r\n\r\nLe but du stage sera d\'abord d\'étudier les limites des méthodes\r\nexistantes, puis de proposer une nouvelle méthode.\r\n\r\n\r\n\r\nDescription des tches\r\n\r\nTester la limite de l\'approche de l\'article [DMS+20]\r\nFaire une analyse quantitative et qualitative des erreurs\r\nProposer et évaluer d\'autres approches (analogie, PCFG +\r\ndeep learning, ...)[LRI16,YN17, DMS+20]\r\n\r\nProfil attendu\r\n\r\nMaster 2 en Informatique (ou équivalent), avec au moins une\r\nspécialité en\r\nApprentissage\r\nTraitement automatique de la langue\r\n\r\nCompétences techniques : python, linux, SQL\r\n\r\nInformations pratiques\r\n\r\nDurée du stage: 5-6 mois\r\nDébut du stage: date de début à définir avec le stagiaire\r\nGratification: environ 591 emois. Subvention frais de transport et\r\ncantine\r\n\r\n\r\nReferences\r\n[DMS+20]    Jan Deriu, Katsiaryna Mlynchyk, Philippe Schläpfer, Alvaro\r\n            Rodrigo, Dirk von Grünigen, Nicolas Kaiser, Kurt\r\n            Stockinger, Eneko Agirre, and Mark Cieliebak. A methodology\r\n            for creating question answering corpora using inverse data\r\n            annotation. In Proceedings of the 58th Annual Meeting of\r\n            the Association for Computational Linguistics, pages\r\n            897-911, Online, July 2020. Association for Computational\r\n            Linguistics.\r\n[LRI16]     Vincent Letard, Sophie Rosset, and Gabriel Illouz.\r\n            Incremental learning from scratch using analogical\r\n            reasoning. In 28th IEEE International Conference on Tools\r\n            with Artificial Intelligence, ICTAI 2016, San Jose, CA,\r\n            USA, November 6-8, 2016, pages 204-211. IEEE Computer\r\n            Society, 2016.\r\n[YN17]      Pengcheng Yin and Graham Neubig. A syntactic neural model\r\n            for general-purpose code generation. In Proceedings of the\r\n            55th Annual Meeting of the Association for Computational\r\n            Linguistics (Volume 1: Long Papers), pages 440-450,\r\n            Vancouver, Canada, July 2017. Association for Computational\r\n            Linguistics.'),
(643, '2020-12-03', 'IMS', 'Bordeaux', 'Objet :  Automatisation d\'une méthode d\'Analyse des Communications au\r\nsein d\'une Dyade en situation de Coopération (ACDC)\r\n\r\ndébut  : début 2021 (janvier, février ou mars)\r\n\r\ndurée  : 5 à 6 mois\r\n\r\nrémunération  : oui\r\nlieu (selon contexte sanitaire)  : Equipe CIH, Laboratoire IMS (UMR CNRS 5218) ENSC-Bordeaux INP, 109 Avenue Roul, 33400, Talence, France\r\n\r\nCV et lettre de motivation à envoyer à  : delphine.graeff@ensc.fr\r\n\r\nContexte\r\n\r\nDepuis plusieurs années l\'équipe CIH (Cognitique et Ingénierie\r\nHumaine), s\'intéresse aux problématiques de la cognition collective ou\r\npartagée.  Le travail de Recherche dans lequel s\'inscrit ce stage a\r\npour objectif de formaliser et de valider une méthodologie innovante\r\npour comprendre les mécanismes cognitifs mis en jeu dans différentes\r\nsituations complexes de cognition collective (collaboration,\r\ncoopération, etc.).\r\n\r\nDans ce contexte, des études sont menées sur les méthodes permettant\r\nd\'étudier la répartition et la dynamique temporelle des échanges et du\r\nleadership au sein d\'un binôme d\'individus engagés dans une tâche\r\ncognitive collaborative.  Une méthode d\'analyse innovante basée sur\r\ndes données qualitatives a été mise au point ces deux dernières\r\nannées, permettant de révéler la dynamique temporelle du leadership au\r\nsein d\'une dyade réalisant une tâche en collaboration.\r\n\r\nPrésentation de la méthode ACDC\r\n\r\nACDC est une méthode innovante d\'Analyse de la dynamique\r\nCommunicationnelle au sein d\'une Dyade en situation de Coopération\r\n(cf.  Graeff et al., 2020 ).  Pour formaliser et valider\r\nexpérimentalement le modèle ACDC, nous l\'avons jusqu\'alors uniquement\r\nappliqué à une situation particulière de coopération : le jeu de\r\ntétris. Dans cette expérience, deux participants jouent à Tetris de\r\nfaçon coopérative durant 10 minutes.  La méthode comporte 5 étapes\r\n(Figure 1). Les échanges conversationnels entre participants\r\nenregistrés sont retranscrits, caractérisés et formalisés selon le\r\nmodèle ACDC. En résulte une frise chronologique qui illustre la\r\ndynamique temporelle de l\'échange.\r\n\r\nFigure 1 : Illustration des étapes de la méthode ACDC\r\n\r\nLe modèle couvre de façon exhaustive les caractéristiques d\'un échange\r\ntelles que le type performatif, directif ou non-directif, le type de\r\ndécision, assentiment ou dissentiment ou encore le type d\'interaction,\r\nsocio-émotionnelle ou liée à la tâche.\r\n\r\nIntérêt et applications potentielles de la méthode ACDC\r\n\r\nUne des forces de notre modèle d\'analyse est la prise en compte de la\r\ntemporalité qui permettrait d\'observer par exemple la dynamique du\r\nleadership au sein de la dyade. En effet, les fluctuations et les\r\néventuelles passations du pouvoir de décision sont déterminantes et\r\npourraient être noyées dans une approche trop globale qui ne tiendrait\r\npas compte de la variable temps.\r\n\r\nDe la même façon, la possibilité d\'ajouter des événements permet de\r\ncontextualiser les échanges et les fluctuations associées. Cela permet\r\nd\'observer si par exemple le leadership change de main quand la\r\nsituation se complique ou après un échec. Par exemple, les\r\nqualificatifs des interactions (remarques positives ou négatives) ou\r\nencore le type de décision finale prise permettraient de déterminer le\r\ntype de leadership et de followership associé à la dyade observée.\r\n\r\nLa méthode ACDC a vocation à être utilisée à termes dans différents\r\ncas d\'usage, seule ou associée à d\'autres outils d\'analyse. La méthode\r\npeut s\'adresser à un chercheur mais également à un formateur ou un\r\nconcepteur par exemple. En effet, toute personne peut avec cette\r\nméthode observer la dynamique du leadership d\'une équipe qui collabore\r\net mesurer l\'impact que peuvent avoir les évènements sur cette\r\ndynamique. Qu\'ils s\'agissent d\'évènements en lien avec une expérience,\r\nun apprentissage ou encore l\'interaction avec une Interface\r\nHomme-Système.\r\n\r\nPérimètre du stage\r\n\r\nAujourd\'hui, la méthode ADCD est très peu automatisée. La\r\nretranscription est faite entièrement manuellement par un opérateur\r\nformé à la méthode : elle est réalisée sur papier et par la suite\r\nsaisie sous forme d\'une matrice de données temporelles sur tableur\r\n(Excel/Matlab), qui est elle-même retranscrite sous la forme de\r\nreprésentation graphique (InDesign).\r\n\r\nNous souhaitons limiter au maximum les tâches chronophages, peu\r\nintéressantes ou source d\'erreur, et donc automatiser la méthode pour\r\ngagner en fiabilité, en simplicité d\'usage et en rapidité d\'exécution\r\n(si possible temps réel).\r\n\r\nNous envisageons d\'automatiser tout ou partie de la méthode ACDC. La\r\nvisualisation temporelle sous forme chronologique pourrait notamment,\r\nsans grande contrainte technique, être directement générée par un\r\nlogiciel à partir des matrices de données. Toujours dans un souci de\r\ngain de temps, nous souhaitons automatiser / semi-automatiser le\r\nprocessus de modélisation, notamment grâce à l\'utilisation d\'outils\r\nd\'intelligence artificielle, en donnant en entrée le fichier son et en\r\ndemandant au logiciel de découper puis caractériser les échanges\r\nentendus, sur la base de la symbolique proposée et en fonction de\r\nrègles imposées au préalable.\r\n\r\nMissions / planning du stage\r\n\r\n- Explorer les solutions d\'automatisation existantes\r\n\r\n- Prototyper les solutions qui viendraient à manquer\r\n\r\n- Intégrer ces différentes solutions dans un même outil\r\n\r\n- Participer à l\'évaluation de l\'impact de cet outil sur l\'utilisation\r\nde la méthode ACDC en termes de rapidité de prise en main, rapidité\r\nd\'exécution, mais aussi de richesse et fiabilité de résultat.\r\n\r\n- Si suffisamment de temps disponible : Possibilité de participer à la\r\nrédaction d\'un article scientifique sur les résultats de cette étude.\r\n\r\nPremières actions\r\n\r\nLa première étape sera de se familiariser avec la méthode ACDC, pour\r\npouvoir reformuler et prioriser les besoins d\'automatisation des\r\ndifférentes étapes de la méthode avec l\'équipe.\r\n\r\nCompétences requises\r\n\r\n- Étudiant niveau Master : Soit dernière année école Ingénieur, soit\r\n2ème année Master.\r\n\r\n- Compétences sollicitées  : Programmation logicielle, Traitement\r\nAutomatique des Langues.\r\n\r\n- Sensibilités appréciées  : Data visualisation, Intelligence\r\nartificielle, démarche expérimentale.\r\n\r\n- Curieux et rigoureux.\r\n\r\nInformations pratiques\r\n\r\n- Rémunération : stage rémunéré\r\n\r\n- Lieu :  Equipe CIH, Laboratoire IMS (UMR CNRS 5218) ENSC-Bordeaux\r\nINP, 109 Avenue Roul, 33400, Talence, France\r\n\r\n- Présence sur site privilégiée , mais télétravail possible en\r\nfonction de la situation Covid.\r\n\r\n- Début de stage : début 2021. Janvier, février ou mars à définir en\r\nfonction des contraintes de l\'étudiant.\r\n\r\n- Encadrement : Delphine Graeff, Doctorante, ENSC-laboratoire IMS de Bordeaux,\r\nVéronique Lespinet-Najib, Enseignante-Chercheur, ENSC-laboratoire IMS de\r\nBordeaux et Jean-Marc André, Enseignant-Chercheur, ENSC-laboratoire IMS de\r\nBordeaux.\r\n\r\nCandidature\r\n\r\nMerci d\'envoyer votre CV et lettre de motivation à Delphine Graeff : \r\ndelphine.graeff@ensc.fr'),
(644, '2020-12-10', 'CEA LIST', 'Palaiseau', 'Présentation du laboratoire d\'accueil\r\n=====================================\r\n\r\nBasé à Paris-Saclay, le CEA List, membre de l\'Université Paris Saclay,\r\nest l\'un des quatre instituts de recherche technologique de CEA Tech,\r\ndirection de la recherche technologique du CEA. Dédié aux systèmes\r\nnumériques intelligents, il contribue au développement de la\r\ncompétitivité des entreprises par le développement et le transfert de\r\ntechnologies.\r\nL\'expertise et les compétences développées par les 800\r\ningénieurs-chercheurs et techniciens du CEA List permettent à\r\nl\'Institut d\'accompagner chaque année plus de 200 entreprises\r\nfrançaises et étrangères sur des projets de recherche appliquée\r\ns\'appuyant sur 4 programmes et 9 plateformes technologiques.\r\n21 start-ups ont été créées depuis 2003. Labellisé Institut Carnot\r\ndepuis 2006, le CEA List est aujourd\'hui l\'institut Carnot Technologies\r\nNumériques.\r\nLe Laboratoire d\'Analyse Sémantique des Textes et des Images (LASTI)\r\nest une équipe de 25 personnes (chercheurs, ingénieurs, doctorants)\r\nmenant des travaux de recherche sur les technologies de description et\r\nde compréhension du contenu multimédia (image, texte, parole) et des\r\ndocuments multilingues, en particulier à grande échelle. Les enjeux\r\nscientifiques sont :\r\n    -   développer des algorithmes efficaces et robustes pour\r\n        l\'analyse et l\'extraction de contenu multimédia, leur\r\n        classification et analyse sémantique ;\r\n    -   reconstitution ou fusion de données hétérogènes pour\r\n        interpréter des scènes ou documents ;\r\n    -   développer des méthodes et des outils pour la construction,\r\n        la formalisation et l\'organisation des ressources et\r\n        connaissances nécessaires au fonctionnement de ces\r\n        algorithmes ;\r\n    -   intégrer plusieurs de ces briques technologiques afin d\'accéder\r\n        à l\'information et répondre à un besoin utilisateur (moteurs de\r\n        recherche, agents conversationnels, rapports synthétiques de\r\n        veille)\r\n\r\nDescription du stage\r\n====================\r\n\r\nLe laboratoire LASTI participe au projet Européen H2020 Decoder visant\r\nentre autres à exploiter les technologies du traitement automatique des\r\nlangues dans le cadre de l\'ingénierie logicielle. En effet,\r\nl\'information textuelle est partout dans ce cadre : exigences,\r\nspécifications, commentaires du code, documentations utilisateur,\r\nforums (stackoverflow...), gestionnaires de tickets, etc. De plus la\r\nquantité de texte et de code correspondant disponibles en ligne\r\npermettent d\'utiliser efficacement les techniques d\'apprentissage\r\nautomatique. Les applications peuvent aller de la simple extraction\r\nd\'information (entités nommées, semantic role labeling...) pour mettre des\r\néléments en évidence dans les interfaces utilisateurs, jusqu\'à la\r\nconversion automatique de texte en code source en utilisant des\r\ntechniques issues de la automatique, en passant par l\'aide à la\r\ntraçabilité pour repérer par exemple des commentaires ou du code qui\r\nvioleraient des exigences.\r\n\r\nNous avons jusqu\'à présent reproduit un certain nombre de modèles et\r\ncollecté des données. Nous avons aussi développé les outils logiciels\r\npermettant de mettre nos résultats à la disposition des partenaires du\r\nprojet.\r\nNous avons enfin spécifié un certain nombre d\'améliorations que nous\r\ncomptons apporter aux modèles pour aller au-delà des résultats de\r\nl\'état de l\'art. Le travail du ou de la stagiaire consistera à\r\nparticiper à l\'implémentation de ces améliorations et à leur évaluation\r\nsur des données génériques permettant la comparaison avec l\'état de\r\nl\'art ainsi que sur les données du projet. Les résultats seront soumis\r\npour publication dans des conférences internationales.\r\nLes modèles sont implémentés en python avec les frameworks de deep\r\nlearning PyTorch et TensorFlow.\r\n\r\nLes modèles concernés sont ceux de [Strubell et al., 2018] pour le\r\nsemantic role labeling ;  [Thang et al., 2015] et  [Iver et al., 2018]\r\npour le semantic parsing (traduction de spécifications de haut niveau\r\nen spécifications formelles ou en code) ; [Guo et al., 2017],\r\n[Narayanan, 2019] et [Seki, 2018, 2019] pour la traçabilité horizontale\r\net verticale. Le ou la stagiaire pourra être amené.e à travailler sur\r\nplusieurs de ces modèles en fonction de l\'avancement des travaux lors\r\nde son arrivée et de ses progrès pendant son stage.\r\n\r\nLe ou la stagiaire utilisera les clusters de calcul du laboratoire.\r\nCeux-ci incluent plusieurs dizaines de noeuds GPU régulièrement mis\r\nà jour. Si jamais le confinement devait se poursuivre, il ou elle aura\r\naccès au réseau CEA et aux clusters par VPN, permettant une poursuite\r\ndu stage dans les meilleures conditions possibles.\r\n\r\nMots-clés\r\n=========\r\n\r\nTraitement automatique des langues, deep learning,\r\ningénierie logicielle.\r\n\r\nRéférences\r\n==========\r\n\r\n[Guo et al., 2017] Guo, J., J. Cheng, et J. Cleland-Huang.\r\n    « Semantically Enhanced Software Traceability Using Deep Learning\r\n    Techniques ». In 2017 IEEE/ACM 39th International Conference on\r\n    Software Engineering (ICSE), 314, 2017.\r\n[Iver et al., 2018] Iyer, Srinivasan, Ioannis Konstas, Alvin Cheung, et\r\n    Luke Zettlemoyer. « Mapping Language to Code in Programmatic\r\n    Context ». In Proceedings of the 2018 Conference on Empirical\r\n    Methods in Natural Language Processing, 1643-1652. Brussels,\r\n    Belgium: Association for Computational Linguistics, 2018.\r\n    https://doi.org/10.18653/v1/D18-1192.\r\n[Narayanan, 2019] Narayanan, Siddharth. « Semantic Similarity in\r\n    Sentences and BERT ». Medium, 27 septembre 2019.\r\nhttps://medium.com/analytics-vidhya/semantic-similarity-in-sentences-and-bert-e8d34f5a4677.\r\n    (Last accessed, 07/08/2020).\r\n[Seki, 2018] Seki, Kazuhiro. « Exploring Neural Translation Models for\r\n    Cross-Lingual Text Similarity ». In Proceedings of the 27th ACM\r\n    International Conference on Information and Knowledge Management,\r\n    1591-1594. CIKM\'18. Torino, Italy: Association for Computing\r\n    Machinery, 2018. https://doi.org/10.1145/3269206.3269262.\r\n[Seki, 2019] Seki, Kazuhiro. « On Cross-Lingual Text Similarity Using\r\n    Neural Translation Models ». Journal of Information Processing 27,\r\n    no 0 (2019):315-21. https://doi.org/10.2197/ipsjjip.27.315.\r\n[Strubell et al., 2018] Emma Strubell, Patrick Verga, Daniel Andor,\r\n    David Weiss, and Andrew McCallum. Linguistically-Informed\r\n    Self-Attention for Semantic Role Labeling. Conference on Empirical\r\n    Methods in Natural Language Processing (EMNLP). Brussels, Belgium.\r\n    October 2018.\r\n[Thang et al., 2015] Luong, Thang, Hieu Pham, et Christopher D.\r\n    Manning. « Effective Approaches to Attention-based Neural Machine\r\n    Translation ». In Proceedings of the 2015 Conference on Empirical\r\n    Methods in Natural Language Processing, 1412-1421. Lisbon,\r\n    Portugal: Association for Computational Linguistics, 2015.\r\n    https://doi.org/10.18653/v1/D15-1166.\r\n\r\n\r\nProfil du candidat/de la candidate\r\n==================================\r\n\r\nNiveau demandé : Ingénieur, Master 2\r\n\r\nDurée : 6 mois\r\nRémunération : entre 700 ¤ et 1300 ¤ suivant la formation.\r\nCompétences requises :\r\n    - Natural Language processing\r\n    - Deep Learning\r\n    - Python\r\n    - Good proficiency in English\r\n\r\nContact\r\n=======\r\n\r\nGaël de Chalendar (mailto:gael.de-chalendar@cea.fr)'),
(645, '2020-12-16', 'IRD & LIRMM', 'Montpellier', 'Liage de jeux de données complémentaires à l\'aide de méthodes\r\nd\'augmentation de bases de connaissances\r\n\r\n\r\nMots clefs: Linked Open Data, Data Linking, Knowledge Base\r\nAugmentation, Knowledge Extraction\r\n\r\n\r\nEncadrants: Konstantin Todorov et Pierre Larmande\r\n\r\nContact: konstantin (dot) todorov (at) lirmm (dot) fr - pierre (dot)\r\nlarmande (at) ird (dot) fr\r\n\r\nLieu de stage: IRD et LIRMM (Montpellier)\r\n\r\nLe liage (ou bien l\'interconnexion) de données est un domaine de\r\nrecherche actif qui vise à établir des liens sémantiques entres des\r\nentités décrites dans des jeux de données différentes. Nous nous\r\nintéressons ici aux données représentées en graphes de connaissances\r\nRDF (Resource Description Framework), publiées sur le web dans le\r\ncadre du projet collaboratif LOD (Linked Open Data) qui accueille\r\naujourd\'hui plus de 1100 jeux de données. Les liens sémantiques que\r\nnous cherchons à établir sont ceux d\'identité, donnés par la relation\r\n\"owl:sameAs\" du vocabulaire OWL (Web Ontology Language). La difficulté\r\nprovient par la grande hétérogénéité des descriptions des entités que\r\nl\'on peut retrouver dans des graphes différents [1]. La majorité des\r\noutils de liage existants se base sur l\'hypothèse que pour chaque\r\ncouple d\'entités à lier potentiellement, il existe au moins un\r\nsous-ensemble de propriétés commun (c\'est-à-dire l\'intersection des\r\npropriétés de deux entités) qui permettra d\'inférer le lien d\'identité\r\n(ou son absence). Or, dans un nombre de cas réels, cette intersection\r\nest très faible ou inexistante -- nous parlons ici de jeux de données\r\ncomplémentaires. Nous nous intéressons en particulier des données du\r\ndomaine agronomique issue du projet AgroLD [4] qui manifestent ce\r\nproblème.\r\n\r\nLa question se pose alors où chercher les informations qui peuvent\r\npermettre la comparaison des ressources.\r\n\r\nD\'une part, dans un nombre de cas ces informations sont présentes dans\r\nles graphes, mais sous une forme non-structurée (dans des champs de\r\ncommentaires textuels). Des méthodes d\'extraction de connaissances à\r\npartir du texte peuvent être appliquées afin de structurer ces\r\ninformations. Par exemple, une particularité des données biologiques\r\nd\'AgroLD est que la plupart d\'entre elles contiennent des champs\r\ntextes qui ne sont pas décrits à l\'aide de terminologies standardisées\r\nou d\'ontologies. En résultat, les découvertes qui pourraient être\r\nréalisées par la fouille de ces ressources sont limitées. Nous allons\r\ndonc nous intéresser à l\'extraction automatique d\'entités d\'intérêt et\r\nde relations à partir de ces champs textuels afin de structurer et\r\nrendre utilisables les informations y contenues [2,3].\r\n\r\nD\'autre part, un nombre d\'approches d\'augmentation de bases de\r\nconnaissances existent, qui permettent de compléter la connaissance\r\nmanquante dans un graphe de connaissance de manière automatique en\r\nutilisant les informations contenus dans des grands graphes sur le LOD\r\n(telles que DBpedia ou Wikidata). Nous proposons ici d\'utiliser et\r\nadapter ces méthodes pour la tâche particulière du liage de jeux de\r\ndonnées complémentaires en augmentant automatiquement les\r\nconnaissances dans ces jeux de données afin de permettre leur\r\ncomparaison.\r\n\r\n\r\nTâches à accomplir\r\n\r\n    Etablir un état de l\'art détaillé du domaine de liage de données\r\n    web et du domaine d\'augmentation automatique de bases de\r\n    connaissances\r\n\r\n    Proposer une méthode de liage de jeux de données complémentaires à\r\n    l\'aide des méthodes d\'augmentation de connaissances et des\r\n    méthodes d\'extraction d\'entités nommées dans le texte\r\n\r\n    Appliquer cette méthode sur des données réelles du domaine\r\n    agronomique (dans le cadre du projet AgroLD).\r\n\r\n\r\nRéférences\r\n\r\n[1] Manel Achichi, Zohra Bellahsene, Konstantin Todorov: A survey on\r\nweb data linking. Ingénierie des Systèmes d\'Information (ISI) 21(5-6):\r\n11-29 (2016)\r\n\r\n[2] Rafael Vieira and Kate Revoredo. Using Word Semantics on Entity\r\nNames for Correspondence Set Generation. OAEI 2017 challenge.\r\n\r\n[3] Yuanzhe Zhang, Xuepeng Wang, Siwei Lai, Shizhu He, Kang Liu, Jun\r\nZhao, and Xueqiang Lv. Ontology Matching with Word Embeddings. 13th\r\nChina National Conference, CCL 2014. LNCS, volume 8801\r\n\r\n[4] Aravind Venkatesan, Gildas Tagny Ngompe, Nordine El Hassouni,\r\nImene Chentli, Valentin Guignon, Clement Jonquet, Manuel Ruiz, Pierre\r\nLarmande. Agronomic Linked Data (AgroLD): a Knowledge-based System to\r\nEnable Integrative Biology in Agronomy. Plos One 13 (11), e0198270\r\n2018. https://doi.org/10.1371/journal.pone.0198270\r\n\r\n\r\nProfil recherché :\r\n\r\nNous recherchons un étudiant motivé avec une expérience en\r\napprentissage automatique et en technologies web sémantique. Le\r\ncandidat démontrera des aptitudes ou des correspondances avec la\r\nplupart des aspects suivants:\r\n\r\n- Forte motivation pour la recherche scientifique\r\n\r\n- Connaissance des technologies du web sémantique, notamment JSON /\r\n  RDF / SPARQL.\r\n\r\n- Expérience avec les outils d\'apprentissage automatique (par exemple,\r\n  Scikit Learn de Python)\r\n\r\n- Connaissance des techniques d\'exploration de texte et de données\r\n  (reconnaissance d\'entités nommées)\r\n\r\n- Excellentes compétences techniques pour mener des expériences avec\r\n  des données réelles et de référence\r\n\r\n- Bonne maîtrise de l\'anglais oral et écrit\r\n\r\n- Bonnes compétences en rédaction\r\n\r\n- Autonomie et initiative, prendre les décisions techniques au sein du\r\n  projet et justifier les choix'),
(646, '2020-12-16', 'Sorbonne Université', 'Paris', '*Offre de stage | Sorbonne Université : Analyse de Défigements par des\r\nméthodes de TAL*\r\n\r\n\r\nL\'équipe de Linguistique Computationnelle du laboratoire STIH propose\r\nun stage de Master en TAL/Fouille de Données d\'une durée de 3 à 6 mois\r\n(selon profil) dans le cadre d\'un projet de recherche financé par le\r\nGIS « Jeu et Sociétés ». Les missions de ce stage concerneront\r\nprincipalement la détection automatique des séquences défigées dans des\r\nécrits courts : microblogs et slogans publicitaires.\r\n\r\n*Objet *\r\nLes défigements sont des procédés créatifs de nature linguistique et\r\nsémiotique, qui visent à désolidariser les séquences polylexicales à\r\ncaractère figé et leurs contextes discursifs. Dès qu\'une séquence est\r\ndéfigée, de nouvelles interprétations de la séquence sont possibles,\r\ntout en gardant des liens en filigrane avec la séquence initiale. Ce\r\nmécanisme de (re)mise en relation est utilisé dans certains types de\r\nproduction langagière tels que slogans publicitaires, écrits\r\nhumoristiques, calembours etc.\r\n\r\n*Missions*\r\n\r\n 1. Construction d\'un corpus de slogans publicitaires\r\n\r\n 2. Modélisation des moules de séquences défigées en discours (typage\r\n    de construction, dépendance syntaxique, fréquence, etc.)\r\n\r\n 3. Retrouver leurs origines dans des corpus\r\n\r\n 4. Proposer des critères d\'appréciation et de classification\r\n\r\nLa réalisation concrète attendue : création d\'un outil de détection et\r\nd\'évaluation de la qualité des séquences défigées, notamment celle des\r\nslogans publicitaires\r\n\r\n*Profil et compétences requises*\r\n-   Connaissances en TAL et/ou en Apprentissage Automatique\r\n\r\n-   Pratique du langage Python\r\n\r\n-   Savoir utiliser des étiqueteurs (POS /tagger/)\r\n\r\n-   Des connaissances en phraséologie seraient un plus\r\n\r\n*À acquérir*\r\n-   Prise de connaissances de travaux universitaires contemporains en\r\n    Sciences du Langage et TAL\r\n-   Programmation Python\r\n-   Versionnage avec git\r\n\r\n\r\n*Conditions de recrutement*\r\n-   Structure de recrutement : Sorbonne Université\r\n-   Gratification : en vigueur + remboursement de 50 % des frais de\r\n    transports\r\n-   Matériel : matériel informatique fourni par l\'équipe\r\n-   Durée du stage : 3 à 6 mois (selon profil), 35h/semaine\r\n-   Prise de fonction : Possible à partir de mars/avril 2021\r\n-   Localisation : Maison de la Recherche, Serpente (Quartier Saint\r\n    Michel, 75005 Paris)\r\n-   Stage au sein d\'une équipe-projet de 4 personnes\r\n\r\n*Date limite de candidature : 29 décembre 2020*\r\n\r\nCandidature : envoyer CV et lettre de motivation à\r\ngael.lejeune@sorbonne-universite.fr et lichao.zhu@gmail.com\r\n\r\n*Références*\r\n[1] Blanche GRUNIG (1990), /Les mots de la publicité,/Paris, Collection\r\n    CNRS Plus, Presses du CNRS, 255 p.\r\n\r\n[2] François MANIEZ(2000), « Le repérage par traitement automatique du\r\n    défigement lexical des proverbes dans la presse américaine ».\r\n    Revue Française De Linguistique Appliquée, 2, 19-32.\r\n\r\n[3] Salah MEJRI (2013)*,« Figement et défigement : problématique\r\n    théorique », /Pratiques/, 159-160, 79-97.'),
(647, '2020-12-16', 'ELAN', 'Grenoble', 'Stage FAIRisation@ELAN - Décembre 2020\r\n\r\nStage M1 ou M2 « FAIRisation de données »\r\n\r\nÉquipe Littératures, Arts et Numérique (ELAN)\r\nau sein du laboratoire Litt&Arts (UMR 5316), Grenoble\r\n\r\nEn appui à nos projets de recherche, nous proposons 1 stage de 4 à 5 mois pour\r\naccompagner la FAIRisation des données que nous produisons.\r\n\r\nProfil du candidat : étudiant·e de Master dans l\'une des disciplines\r\ndes SHS dans une filière à coloration numérique\r\n\r\nContexte\r\n\r\nAu sein de l\'UMR Litt&Arts, ELAN est une équipe d\'ingénieur·e·s\r\naccompagnant les projets de recherche de l\'unité (une vingtaine) sur\r\nleurs aspects numériques. Quel que soit le projet, nous manipulons des\r\ndonnées de multiples natures : facsimilés, sources transcrites,\r\ndocumentation, code informatique...  manuscrits, correspondances,\r\nbibliographies...  Le stage propose de travailler sur l\'application\r\ndes  principes FAIR à l\'ensemble des données ainsi produites.\r\n\r\nObjectifs du travail\r\n\r\nLe ou la stagiaire devra, sous la responsabilité de deux ingénieures d\'ELAN :\r\n\r\n- vérifier le degré d\'adéquation des données avec les principes FAIR ;\r\n\r\n- effectuer une recherche d\'information (veille) sur les vocabulaires\r\ncontrôlés et thésaurus utilisables pour renseigner les métadonnées\r\nDublin Core des corpus ;\r\n\r\n- intégrer les recommandations du groupe  Data CAHIER 1 aux données en\r\nTEI ;\r\n\r\n- enrichir le site CERVIDAE (sous Omeka Classic) dédié au suivi et à\r\nla description des données des projets accompagnés par Elan ;\r\n\r\n- produire de la documentation autour de la démarche mise en oeuvre ;\r\n\r\n- mener avec l\'équipe une réflexion sur le choix d\'un entrepôt de\r\ndonnées.\r\n\r\nLe ou la stagiaire participera au travail de l\'équipe et sera impliqué\r\ndans notre réflexion autour de la notion de (ré)utilisabilité des\r\ndonnées en SHS.\r\n\r\nCompétences recherchées\r\n- capacité d\'organiser son propre travail avec rigueur\r\n- connaissance des principes FAIR\r\n- connaissance de standards de métadonnées Dublin Core\r\n- connaissance du format XML-TEI ou bonne connaissance du format XML\r\n- connaissance du CMS Omeka\r\n- lecture de l\'anglais\r\n\r\nCadre du stage\r\n\r\nLa·e stagiaire sera accueilli au sein du Laboratoire Arts et pratique\r\ndu texte, de l\'image, de l\'écran et de la scène (Litt&Arts, UMR 5316,\r\nUGA/CNRS) sur le Campus Saint-Martin d\'Herès de l\'université\r\nGrenoble-Alpes.  Il ou elle sera accompagné·e dans son travail par\r\ndeux encadrantes et travaillera en collaboration avec plusieurs\r\nchercheuse·eur·s de l\'unité.\r\n\r\nDurée et contrat\r\n\r\nLe stage est prévu au printemps-été 2021 pour une durée de 4 à 5\r\nmois. Le stagiaire bénéficiera de la gratification de stage minimale\r\nprévue par la réglementation 2 et d\'une prise en charge partielle de\r\nses frais de transports.\r\n\r\nRépondre à l\'offre\r\n\r\nLes candidats doivent envoyer :\r\n(1) un CV,\r\n(2) une lettre de motivation et\r\n(3) une lettre de recommandation d\'un de leurs enseignants\r\npar mail, ayant comme objet :\r\n[Stage ELAN] Candidature de  M/Mme Prénom NOM\r\nà :\r\nAnne Garcia-Fernandez :  annegf@univ-grenoble-alpes.fr\r\nElisabeth Greslou :  gresloue@univ-grenoble-alpes.fr'),
(648, '2020-12-16', 'LIG', 'Grenoble', 'Subject Title: Artificial intelligence and legal decisions: comparison\r\nof the performance of artificial intelligence techniques in order to\r\nunderstand and anticipate judges\' reasoning based on evidence\r\n(evidential reasoning)\r\n\r\nSupervisors:\r\nCaroline BAZZOLI, Jean Kuntzmann Laboratory,\r\ncaroline.bazzoli@univ-grenoble-alpes.fr\r\nJean-Pierre CHEVALLET, Laboratoire d\'Informatique de Grenoble,\r\njean-pierre.chevallet@univ-grenoble-alpes.fr\r\nDuration: 5-6 months\r\nKeywords : NLP; Machine learning ;Deep learning ; Text mining ;\r\n\r\nIntroduction\r\n\r\nThe objective of the project is to test and compare the performance of\r\nartificial intelligence systems derived from two different\r\nmethodologies for predicting court decisions and identifying the\r\ncriteria (facts and evidence) that influence the reasoning of judges.\r\nThe first method consists in creating a mathematical model of judges\'\r\ndecisions based on a learning process that relies on the detailed\r\nannotation of several hundred judgments. The second method, is based on\r\ndeep neural networks trained on the same corpus of judgments annotated\r\nwith decision labels.\r\n\r\nThis project is grounded on a close cooperation between computer\r\nscientists, jurists and statisticians. It involves both academic and\r\nindustrial partners. It is the first academic research in France whose\r\nobjective is to measure the performance of AI in the field of legal\r\nsciences. It seeks to find out to what extent state-of-the-art\r\nartificial intelligence models are likely to help understanding and\r\nanticipating judges\' decisions.\r\n\r\nInternship subject\r\n\r\nThe objective of the internship is to compare the performance of two\r\nscientific methods for analyzing the decision-making process of judges:\r\non the one hand, a mathematical modeling method based on human\r\nannotation work, which requires both significant human resources and\r\nadvanced legal skills; on the other hand, the use of recent advanced in\r\nnatural language processing models based on word embeddings, i.e.\r\nrepresenting words as vectors of numbers, based on their context (e.g.\r\nBERT Bidirectional Encoder Representations from Transformers) to build\r\nefficient text classification on legal texts.\r\n\r\nIn this project, the student must setup an experiment that will test\r\nthe capacity of a Neural Network (NN) to be trained to learn the judges\r\ndecision. The NN will have as input vectors embedding transformations\r\nusing FlauBERT developed in LIG as the sources text are in French.\r\n\r\nThe internship missions are:\r\n\r\nBibliographic study on the predictive efficiency of supervised\r\nclassification applicable to our context by presenting their advantages\r\nand disadvantages.\r\n\r\nProgramming of the Natural Language pre-processing phase of the text of\r\ncourt decisions for the use of FlauBERT.\r\n\r\nTest if a NN with text embeddings input, can learn and predict judges\r\ndecisions only from judgments corpus\r\n\r\nAnalyze and understand the usefulness on human annotation in the\r\nefficiency of the learning processing\r\n\r\nFind a way to automatically highlight in the original text, the\r\npassages that has been evaluated as strongly influential for the NN\r\ndecision making.\r\n\r\nCandidate profile\r\n\r\nMaster 2 in Computer science of Applied Mathématics\r\n\r\nKnowledge of programming tools in the machine learning domain : R,\r\nPython, pyTorch, etc.\r\n\r\nTheoretical knowledge in multivariate statistics, logistic regression\r\nand data analysis (classification, clustering and neural networks,\r\nDeepLearning)\r\n\r\nScientific English. French reading could be important as the text\r\ncollection is in French.\r\n\r\nPractical informations\r\n\r\nLocation : Laboratoire Informatique de Grenoble, Bâtiment IMAG,\r\nUniversité Grenoble Alpes, 700 avenue Centrale, 38401 Domaine\r\nUniversitaire de Saint-Martin-d\'Hères.\r\n\r\nUsual internship gratuity (around 540,00¤ per month)\r\n\r\nDuration : 5 or 6 months\r\n\r\nSupervisors :\r\nJean-Pierre CHEVALLET (LIG), Caroline BAZZOLI (Laboratoire Jean\r\nKuntzmann), Etienne VERGES (Centre de recherche Juridique)'),
(649, '2020-12-16', 'LIPN', 'Villetaneuse', 'Title:  Multitask Deep Learning for Joint Syntactic and Semantic\r\n        Easy-first Dependency Parsing\r\n\r\nContext: Collaboration between RCLN\r\n    (https://lipn.univ-paris13.fr/accueil/equipe/rcln/), LIPN,\r\n    Université Paris 13, and CAMeL Lab (https://bit.ly/2M0XsAG),\r\n    New York University Abu Dhabi\r\nHost lab: LIPN, Université Paris 13, 99 Avenue Jean Baptiste Clément,\r\n    93430 Villetaneuse\r\nSupervisors: Nadi Tomeh and Joseph Le Roux\r\nCollaborator: Nizar Habash, NYU Abu Dhabi\r\nStart date: February 2021\r\nDuration: 6 months\r\nStipend: 550 euros/month\r\nProfile and required skills:\r\n    -   Masters in Computer Science, Computational Linguistics, Applied\r\n        Mathematics, or Statistics\r\n    -   Knowledge in Natural Language Processing and Deep Learning is\r\n        highly appreciated\r\n    -   Programming skills in Python (and libraries such as pytorch,\r\n        numpy, or scikit-learn)\r\nHow to apply:\r\n    send CV, grades, motivation and recommendation letters to\r\n    tomeh@lipn.fr and leroux@lipn.fr\r\nPermalink:\r\nhttps://lipn.univ-paris13.fr/~tomeh/public/uploads/offers/2021-internship-multitask-parsing.pdf\r\n\r\nContext\r\nIn recent work on dependency parsing for Arabic (Kankanampati et al.\r\n2020), we proposed a multitask algorithm based on the easy-first\r\nhierarchical LSTM parser of Kiperwasser and Goldberg (2016). The\r\nmultitask algorithm is capable of decoding a sentence into multiple\r\nformalisms and is learned from multiple corresponding treebanks. In the\r\nexperiments, we considered two representations, the first one is the\r\nColumbia Arabic Treebank (CATiB) (Habash and Roth, 2009), which is\r\ninspired by Arabic traditional grammar and focuses on modeling\r\nsyntactic and morpho-syntactic agreement and case assignment.  The\r\nsecond is the Universal Dependency (UD) treebank for Arabic (Taji et\r\nal., 2017), which has relatively more focus on semantic/thematic\r\nrelations within the sentence, and is coordinated in design with a\r\nnumber of other languages.\r\nThe multitask system enables sharing representations at various levels\r\nof abstraction, and at different time steps of the parsing process,\r\nwhich makes it possible to communicate information across formalisms\r\nand to learn when sharing is important and when it is not. The joint\r\nsystem outperforms the single-task baseline on both CATiB and UD\r\ntreebanks.\r\n\r\nPropositions\r\nWe propose to extend the work of Kankanampati et al. (2020) in two\r\nways:\r\n\r\n(i) The joint parser indirectly learns the order in which to produce\r\nthe arcs of CATiB and UD trees. In fact, the easiest decision in a\r\nlocal context is selected at each step during parsing. During training,\r\nthe parser is allowed to explore erroneous arcs to reduce the effect of\r\nerror propagation, sometimes referred to as the exposure bias problem.\r\nThis is done by designing an optimal learning policy also known as a\r\ndynamic oracle. In our multitask setting, the dynamic-oracle-based\r\ntraining is suboptimal, since the number of arcs allowed by the dynamic\r\noracle during training is large and the order in which they should be\r\npredicted is unknown. In the experiments, the parser switches between\r\nthe two dimensions in about 65% of the time, but we noticed that its\r\nperformance can be improved by explicitly controlling the switching\r\nfrequency heuristically. Instead of designing a new dynamic oracle for\r\nthe multitask parser, we will explore reinforcement learning as a\r\nprincipled framework to learn this kind of sequential decisions to\r\nfurther reduce error propagation, similar to Zhang and Chan (2009). We\r\nwill however consider a policy gradient approach since it is\r\nstraightforward to apply in deep learning because it is gradient-based.\r\nPolicy gradient learning was shown to help transition-based syntactic\r\ndependency parsing (Le and Fokkens, 2017), constituency parsing (Fried\r\nand Klein, 2018), and semantic dependency parsing (Kurita and Søgaard,\r\n2019). Other approaches to RL such as DQN, Actor/Critic and MaxEnt RL\r\ncan also be considered.\r\n\r\n(ii) The current model uses Bi-LSTMs for contextual encoding of lexical\r\nand part-of-speech tags and. It also uses a multilayer perceptron for\r\narc and label scoring. We will be exploring options to replace these\r\ncomponents with transformer-based encoders and attention mechanisms.\r\nThe multitask model uses a predefined parameter sharing strategy by\r\nspecifying which layers have tied parameters. The search for the best\r\nsharing architecture considered a few alternatives and compared them on\r\nthe devset to select the best one. Similar to Yang and Hospedales\r\n(2017) and Ruder et al. (2019) we want to consider learning the best\r\nsharing strategy in a data-driven way to find the layers or subspaces\r\nthat benefit from sharing, the appropriate amount of sharing, and the\r\nappropriate relative weights of the different task losses.\r\n\r\nThe baseline multitask parser is implemented in Python and will be our\r\nstarting point:\r\nhttps://github.com/yash-reddy/MEF_parser\r\n\r\nReferences\r\n-   Nizar Habash and Ryan M. Roth. \"CATiB: The Columbia Arabic\r\n    Treebank.\" ACL (2009).\r\n-   Lidan Zhang and Kwok Ping Chan. \"Dependency Parsing with\r\n    Energy-based Reinforcement Learning.\" IWPT (2009).\r\n-   Eliyahu Kiperwasser and Yoav Goldberg. \"Easy-first dependency\r\n    parsing with hierarchical tree LSTMs.\" TACL (2016).\r\n-   Dima Taji, Nizar Habash, and Daniel Zeman. \"Universal Dependencies\r\n    for Arabic.\" WANLP (2017).\r\n-   Yongxin Yang, Timothy M. Hospedales. \"Trace Norm Regularised Deep\r\n    Multi-Task Learning.\" ICLR (2017).\r\n-   Minh Le and Antske Fokkens. \"Tackling Error Propagation through\r\n    Reinforcement Learning: A Case of Greedy Dependency Parsing\".\r\n    EACL (2017).\r\n-   Fried, Daniel and D. Klein. \"Policy Gradient as a Proxy for Dynamic\r\n    Oracles in Constituency Parsing.\" ACL (2018).\r\n-   Ruder, Sebastian, Joachim Bingel, Isabelle Augenstein and Anders\r\n    Søgaard. \"Latent Multitask Architecture Learning.\" AAAI (2019).\r\n-   Shuhei Kurita and Anders Søgaard. \"Multi-Task Semantic Dependency\r\n    Parsing with Policy Gradient for Learning Easy-First Strategies.\"\r\n    ACL (2019).\r\n-   Kankanampati, Yash, Joseph Le Roux, Nadi Tomeh, Dima Taji and Nizar\r\n    Habash. \"Multitask Easy-First Dependency Parsing: Exploiting\r\n    Complementarities of Different Dependency Representations.\"\r\n    COLING (2020).'),
(650, '2021-01-05', 'Ludo-Vic', 'Paris', 'Nous proposons un stage (de niveau Master 2/5ième année ingénieur)\r\nportant sur la détection de baisse d\'engagement durant une interaction\r\navec nos agents conversationnels.\r\nLa solution peut être trouvée en utilisant des modèles à base de règles\r\nou en utilisant des techniques de machine/deep learning [1, 2, 3, 4, 5]\r\n\r\nOBJECTIFS :\r\n-   Analyser le comportement (mouvement de tête, émotion, ...) pour\r\n    trouver les caractéristiques de baisse d\'engagement.\r\n-   Modélisation et détection de la baisse d\'engagement\r\n-   Évaluation\r\n-   Application en temps réel\r\n\r\nCONDITION DU STAGE :\r\nLe stage se déroulera sur une période de 6 mois dans le département R&D\r\ndu Ludo-Vic SAS. Des outils de travail à distance sont disponibles au\r\nsein de l\'entreprise.\r\n\r\nPROFIL RECHERCHÉ :\r\n-   Bac +5 dans le domaine de l\'informatique et de l\'IA.\r\n-   Capacité à réaliser des interactions et des animations 3D.\r\n-   Expérience avec Unity3D et compétence en langage C# sont un vrai\r\n    plus.\r\n\r\nRÉMUNÉRATION :\r\n-   conditions standards de rémunération de stage.\r\n\r\nCONTACTS ET CANDIDATURE\r\nMerci d\'envoyer votre CV (vos relevés de notes, vos rapports de\r\nprojets/stages...) à :\r\nJack Amberg : jack[at]ludo-vic.com\r\nAtef Ben-Youssef : atef[at]ludo-vic.com\r\n\r\nRÉFÉRENCE :\r\n[1] A. Ben-Youssef, C. Clavel, S. Essid, M. Bilac, M. Chamoux, and A.\r\n    Lim, \"UE-HRI: A new dataset for the study of user engagement in\r\n    spontaneous human-robot interactions,\" in Proc. 19th ACM Int. Conf.\r\n    Multimodal Interaction (ICMI), 2017, pp. 464-472. DOI:\r\n    10.1145/3136755.3136814\r\n(https://www.tsi.telecom-paristech.fr/aao/en/2017/05/18/ue-hri-dataset/)\r\n[2] A Gupta, A DCunha, K Awasthi, V Balasubramanian, DAiSEE: Towards\r\n    User Engagement Recognition in the Wild, arXiv preprint:\r\n    https://arxiv.org/abs/1609.01885\r\n[3] A. Ben Youssef, C. Clavel and S. Essid, \"Early Detection of User\r\n    Engagement Breakdown in Spontaneous Human-Humanoid Interaction,\" in\r\n    IEEE Transactions on Affective Computing, 2019, doi:\r\n    10.1109/TAFFC.2019.2898399.\r\n[4] A. Ben-Youssef, G. Varni, S. Essid, and C. Clavel, \"On-the-Fly\r\n    Detection of User Engagement Decrease in Spontaneous HumanRobot\r\n    Interaction Using Recurrent and Deep Neural Networks,\"\r\n    International Journal of Social Robotics, 2019.\r\n    (https://hal.archives-ouvertes.fr/hal-02288044)\r\n[5] L. Geng, M. Xu, Z. Wei and X. Zhou, \"Learning Deep Spatiotemporal\r\n    Feature for Engagement Recognition of Online Courses,\" 2019 IEEE\r\n    Symposium Series on Computational Intelligence (SSCI), Xiamen,\r\n    China, 2019, pp. 442-447, doi: 10.1109/SSCI44817.2019.9002713.');
INSERT INTO `mytable` (`id`, `date`, `organisation`, `ville`, `sujet`) VALUES
(651, '2021-01-05', 'LIG', 'Grenoble', 'Titre :     Développement d\'un système question / réponse\r\n            pour l\'application mobile d\'un cyber opéra\r\nEncadrant : Jean-Pierre Chevallet, équipe MRIM du Laboratoire\r\n            d\'Informatique de Grenoble (LIG)\r\nContact :   jean-pierre.chevallet@imag.fr\r\nLieu :      Laboratoire d\'Informatique de Grenoble (LIG), Bâtiment\r\n            IMAG, 700 avenue Centrale, Domaine Universitaire de\r\n            Saint-Martin-d\'Hères\r\n\r\nDurée : 5-6 mois\r\n\r\nFinancement : celui d\'un stage (1/3 du SMIC), financé par\r\nMIAI@Grenoble Alpes, (ANR-19-P3IA-0003)\r\n\r\nMot clés : Accès à l\'information, Intelligence artificielle, Traitement\r\nautomatique de la langue naturelle, Apprentissage automatique,\r\nApprentissage profond par réseaux de neurones, Génération automatique\r\nde phrases, Interaction homme machine avec un avatar, plongements de\r\nmots (embeddings), BERT et FlauBERT, programmation mobile.\r\n\r\nContexte\r\n\r\nCe projet est dans le contexte du montage d\'un spectacle qui sera en\r\ntournée en France à partir de fin 2022 avec des répétitions prévue fin\r\n2021. La première aura lieu à partir du printemps 2022 à Grenoble\r\n(Hexagone de Meylan). Il s\'agit d\'un \"cyber-opéra\" sur le thème de\r\nl\'interaction d\'un robot avec les humains, plus précisément, il s\'agit\r\nde suivre l\'évolution d\'une intelligence artificielle en apprentissage\r\navec les humains. Cet oeuvre artistique posera des questions sur le\r\nrôle des machines dans notre réalité, en particulier le rôle de\r\nl\'intelligence artificielle. Le spectacle mettra en scène un robot\r\nayant une intelligence artificielle, mais ce robot sera en fait animés\r\npar un acteur. Par contre, il est prévu une application sur téléphone\r\nmobile, qui permettra au spectateur ayant acheté un billet pour le\r\nspectacle, de faire connaissance avec le robot du spectacle, et d\'avoir\r\ndes informations sur le contenu du spectacle sous la forme d\'énigmes à\r\nrésoudre. Le spectacle en lui même répondra à une partie de l\'énigme\r\nmais l\'énigme se poursuivra dans l\'application mobile après le\r\nspectacle.\r\n\r\nLe projet informatique consiste à participer au développement de cette\r\napplication, en relation avec le scénariste, le musicien, les designers\r\n(visuel, et audio), le metteur en scène et une structure d\'aide et\r\nd\'accueil au CEA de Grenoble. Le stage se déroulera au Laboratoire\r\nd\'Informatique de Grenoble (LIG). Le développement se fera en\r\ncollaboration avec une start-up spécialisée dans la conception et la\r\nréalisation d\'avatars interactifs sur téléphone portable. Un serveur\r\ndevra être mis en place pour la partie intelligence artificielle.\r\nLe but du développement informatique est de servir l\'oeuvre mais aussi\r\nde rendre visible à des néophytes le travail scientifique réalisé dans\r\nle Laboratoire Informatique de Grenoble, en particulier le modèle de\r\nlangue FlauBERT, réalisé par l\'équipe GETALP du LIG.\r\n\r\nSujet du stage\r\n\r\nLe projet concerne le développent de l\'application sur téléphone mobile\r\nqui sera disponible pour les spectateurs, avant et après le spectacle.\r\nCette application sera développée à priori dans le langage Dart et\r\nl\'environnement Flutter. Le développement de la partie mobile fera\r\nl\'objet d\'un autre stage. Dans ce stage, il s\'agit du développement\r\nd\'un serveur qui contiendra l\'IA de l\'application mobile. Ce serveur\r\npourra fonctionner en mode question / réponse. La réponse sera produite\r\npar un réseau de neurones. Ce projet concerne précisément le\r\ndéveloppement de la partie question / réponses en langue naturelle en\r\nrapport avec le scénario du spectacle.\r\n\r\nCe projet passera par les étapes suivantes\r\n\r\n-   Etat de l\'art dans la génération de texte et les systèmes\r\n    question / réponse avec apprentissage profond;\r\n\r\n-   Analyse de la fonctionnalité d\'interaction textuelle avec l\'avatar\r\n    sur le téléphone mobile;\r\n\r\n-   Proposition d\'un modèle de construction de réponse à partir de\r\n    questions de l\'utilisateur et en tenant compte du scénario du\r\n    spectacle;\r\n\r\n-   Création d\'un corpus d\'apprentissage et d\'un corpus de questions,\r\n    pour réaliser plusieurs versions du générateur de réponses en\r\n    fonction de l\'évolution dans le temps de l\'IA et du parcours de\r\n    l\'utilisateur dans le scénario;\r\n\r\n-   Proposition d\'une architecture pour apprendre et produire les\r\n    phrases;\r\n\r\n-   Expérimentations de l\'apprentissage avec le corpus et évaluation\r\n    des réponses aux questions.\r\n\r\nProfil attendu :\r\n-   Connaissance du traitement des langues par plongement de mots\r\n    (ex: BERT), ou systèmes question / réponse;\r\n\r\n-   Pratique de l\'apprentissage automatique appliqué au traitement de\r\n    la langue;\r\n\r\n-   A l\'aise avec la mise en oeuvre de réseaux de neurones, et\r\n    connaissance des frameworks logiciels comme pyTorch.\r\n\r\n-   Facilité d\'interaction avec des non informaticiens, comme un\r\n    auteur, un metteur en scène, un musicien, etc.'),
(652, '2021-01-05', 'Lattice', 'Montrouge', '*** Production d\'un package R à partir de scripts d\'analyse\r\ntextométrique pour le français ***\r\n\r\nStage de M2 proposé par le laboratoire Lattice (Montrouge)\r\n\r\n* Motivations et contexte\r\n\r\nLe but de ce stage en informatique est de produire un paquet R\r\nreprenant un ensemble de scripts (déjà écrits en R et utilisant\r\nprincipalement les extensions Tidyverse) constituant une chaîne\r\nd\'analyse textométrique pour le français. Cette chaîne est actuellement\r\nopérationnelle, mais ne peut prétendre être diffusée en l\'état auprès\r\ndu public. Elle vise à identifier dans des corpus des patrons\r\nlexico-grammaticaux (motifs) permettant, notamment, d\'identifier des\r\néléments stylistiques représentatifs d\'un auteur ou d\'un genre textuel.\r\nLa chaine est ainsi composée :\r\n\r\n-       1°) Étiquetage morphosyntaxique. (UDPipe)\r\n-       2°) Transformation en motifs\r\n-       3°) Wordcloud\r\n-       4°) TF-IDF\r\n-       5°) AFC\r\n-       6°) Calcul de spécificités\r\n-       7°) Barycentres et pourcentage d\'apparition\r\n-       8°) Statistiques générales\r\n-       9°) Retour aux textes\r\n\r\nLa diffusion de cette chaine sous un paquet R serait un apport\r\nimportant pour les chercheurs en stylométrie. Un premier travail\r\nconsistera donc à nettoyer le code et à le rendre portable et\r\npartageable sous la forme d\'un paquet R.\r\n\r\nAu-delà, et suivant la durée du stage, diverses extensions\r\nsont envisageables, comme une extension à d\'autres langues,\r\nune réflexion sur les moyens de visualisation des résultats,\r\nune amélioration des calculs statistiques, et la recherche d\'une\r\ncomplémentarité avec d\'autres scripts (par exemple stylo).\r\n\r\n\r\n* Modalités\r\n\r\nStage de 3 à 6 mois (début entre février et avril 2021), de niveau M2,\r\nconventionné et indemnisé suivant les règles en vigueur. Le stage se\r\ndéroulera dans les locaux du Lattice à Montrouge (métro Mairie de\r\nMontrouge) ou en télétravail, suivant les mesures sanitaires en vigueur\r\ndurant le stage. Si le stage est effectué en télétravail, un suivi\r\nrégulier se fera en visio.\r\n\r\n* Profil recherché.\r\n\r\nÉtudiant-e en informatique ou en linguistique-informatique avec des\r\nconnaissances solides en programmation.\r\n\r\n- Bonne connaissance du langage R indispensable\r\n- Compétences en traitement automatique des langues\r\n\r\n* Comment candidater ?\r\n\r\nEnvoyer avant le 15 janvier 2021 par mail un CV et un relevé de\r\nnotes récent à thierry.poibeau@ens.psl.eu et\r\ndominique.legallois@sorbonne-nouvelle.fr, ainsi que quelques mots\r\nexpliquant votre intérêt pour ce stage et détaillant\r\nsommairement votre expérience de la programmation en R.'),
(653, '2021-01-05', 'LIFO', 'Orléans', 'Laboratoire/Entreprise : LIFO\r\nDurée : 6 mois (max)\r\nContact : mirian@univ-orleans.fr <mailto:mirian@univ-orleans.fr>\r\n\r\n*Contexte :*\r\nStage financé par la fédération ICVL (Informatique Centre\r\nVal de Loire)\r\n\r\nCalendrier du recrutement:\r\n\r\n+ Date limite des candidatures: 3 janvier\r\n+ Éventuelles auditions: 6 janvier\r\n+ Notifications: 7 janvier\r\n\r\nLes candidatures (CV et les relevés de notes) sont à envoyer, a\r\nu plus\r\ntôt, aux encandrants (voir emails contacts)\r\n\r\nContacts : nhiot@ennov.com, anne-lyse.minard@univ-orleans.fr,\r\nmirian@univ-orleans.fr, agata.savary@univ-tours.fr\r\n\r\n*Sujet :*\r\nLe stage proposé portera sur l\'extraction des relations et\r\nl\'instanciation de graphes, et s\'inscrira dans la continuité d\'un\r\nstage de M2 réalisé au 1er semestre 2020. Ce dernier a conduit au\r\ndéveloppement d\'un système de reconnaissances des entités médicales\r\net de la réalisation d\'une première étude de la problématique de\r\nl\'extraction des relations.\r\n\r\nTitre du stage : Construction d\'un graphe de connaissances à partir des\r\nrelations extraites dans des cas cliniques\r\n\r\nDisciplines scientifiques : Traitement Automatique des Langues ;\r\nApprentissage et Bases de Données\r\n\r\nEncadrants : LIFO (Nicolas Hiot), LLL (Anne-Lyse Minard), LIFO (Mirian\r\nHalfeld Ferrari Alves), LIFAT (Agata Savary)\r\n\r\nType de stage : M2, stage de 6 mois, financé par la fédération ICVL\r\n\r\nProjet dans lequel s\'inscrit le stage :\r\nLe groupe de travail DOING@DIAMS se concentre sur la question de la\r\ntransformation des informations (obtenues dans des documents ou des\r\nbases de données plus au moins structurées) en connaissance. Il réunit\r\ndes chercheurs des laboratoires LLL, LIFO et LIFAT, spécialisés en\r\nTraitement Automatique des Langues, Apprentissage et Bases de Données.\r\nÀ partir d\'un schéma représentant des connaissances expertes, nous\r\ncherchons à extraire les informations de textes permettant d\'instancier\r\nle graphe. L\'approche visée consiste en l\'extraction d\'entités du\r\ndomaine et de relations entre entités, relations représentant les arcs\r\ndu graphe. Les entités comme les relations devront être typées,\r\nnormalisées et associées aux noeuds du graphe. Les informations\r\nextraites seront ensuite transformées en base de connaissance. Elle\r\ndevrait permettre d\'assurer la qualité des informations, d\'offrir des\r\nméthodes permettant l\'interrogation et l\'analyse des informations et\r\nd\'offrir des mécanismes pour assurer l\'évolution cohérente des\r\nconnaissances.\r\n\r\nLe stage proposé portera sur l\'extraction des relations et\r\nl\'instanciation de graphes, et s\'inscrira dans la continuité d\'un stage\r\nde M2 réalisé au 1 er semestre 2020. Ce dernier a conduit au\r\ndéveloppement d\'un système de reconnaissances des entités médicales\r\n([1]) et de la réalisation d\'une première étude de la problématique de\r\nl\'extraction des relations.\r\n\r\nDescriptif du stage :\r\nLes objectifs du stage seront de continuer le développement d\'une\r\nchaîne de traitements pour des textes du domaine médical en français\r\n(corpus de cas cliniques utilisé pour la campagne DEFT 2020) qui\r\npermettra d\'extraire des relations entre les entités, les typer et de\r\nreprésenter ces informations sous forme de graphes grâce notamment à la\r\nnormalisation des entités. L\'extraction des relations reposera sur des\r\nrègles (ou patrons) qui utiliseront l\'analyse syntaxique (en\r\nconstituants [2] ou en dépendances [3]) et/ou en rôles sémantiques [4].\r\nLes perspectives à la suite du stage seront la généralisation du\r\nsystème à d\'autres cas d\'usage.Nicolas Hiot, doctorant au LIFO, sera\r\nl\'encadrant principal de ce stage. Le LLL et le LIFAT seront des\r\npersonnes ressources pour la partie extraction d\'information, en\r\nparticulier Anne-Lyse Minard (LLL) sur la problématique de l\'extraction\r\nde relations en domaine médical et Agata Savary du LIFAT sur les\r\nquestions de grammaires locales. Mirian Halfeld Ferrari Alves du LIFO\r\nencadrera le stage pour la partie définition du schéma/graphe et leur\r\ninstanciation en fonction des besoins pour la base de données.\r\n\r\nLe stage sera décomposé en plusieurs étapes :\r\n-   Réalisation d\'un état de l\'art des systèmes d\'extraction de\r\n    relations dans le domaine général et dans le domaine médical.\r\n-   Annotation manuelle d\'un sous-corpus pour l\'évaluation du système\r\n    et un affinage de la définition de la tâche.\r\n-   Développement d\'une méthode pour l\'extraction des relations entre\r\n    les entités d\'intérêts et leur typage.\r\n-   Développement d\'une méthode pour représenter les relations\r\n    extraites entre entités sous forme de graphes.\r\n\r\nCompétences requises :\r\n-   Étudiants de master en TAL ou master en informatique avec un\r\n    intérêt fort pour le TAL\r\n-   Bonne connaissance de python et des méthodes de TAL (parsing,\r\n    text mining, etc.)\r\n-   Capacité de travail en équipe pluridisciplinaire\r\n\r\nRéférences :\r\n[1] Anne-Lyse Minard, Andréane Roques, Nicolas Hiot, Mirian Halfeld\r\n    Ferrari Alves, Agata Savary. DOING@DEFT : cascade de CRF pour\r\n    l\'annotation d\'entités cliniques imbriquées. DEFT 2020 (workshop de\r\n    TALN 2020).\r\n[2] Anne-Lyse Minard, Anne-Laure Ligozat, Brigitte Grau, Apport de la\r\n    syntaxe pour l\'extraction de relations en domaine médical.\r\n    TALN 2011.\r\n[3] Brahim Batouche, Claire Gardent and Anne Monceaux. Parsing Text\r\n    into RDF graphs. SEPLN 2015.\r\n[4] Piek Vossen, Rodrigo Agerri, Itziar Aldabe, Agata Cybulska,\r\n    Marieke van Erp, Antske Fokkens, Egoitz Laparra, Anne-Lyse Minard,\r\n    Alessio P. Aprosio, German Rigau, Marco Rospocher, and Roxane Segers.\r\n    Newsreader: Using knowledge resources in a cross-lingual reading\r\n    machine to generate more knowledge from massive streams of news.\r\n    In knowledge-based systems, elsevier, 2016.\r\n\r\nCANDIDATURES : envoyer un CV et les relevés de notes aux encadrants\r\n(via email)\r\n\r\nContacts : nhiot@ennov.com, anne-lyse.minard@univ-orleans.fr,\r\nmirian@univ-orleans.fr, agata.savary@univ-tours.fr\r\n\r\n*Adresse d\'emploi :*\r\nLIFO - Batiment IIIA - Rue Léonard de Vinci - BP6759\r\n45067 Orléans Cedex 2\r\n\r\n**'),
(654, '2021-01-06', 'LIFAT / LIFO', 'Blois ou Orléans', 'Analyse des propriétés des mesures de qualité pour la coréférence\r\n================================================\r\n## Contexte scientifique\r\n\r\nLe Laboratoire d\'Informatique Fondamentale de l\'Université d\'Orléans\r\n(LIFO) et le Laboratoire d\'Informatique de l\'Université de Tours\r\n(LIFAT) proposent un stage dans le cadre d\'un financement de la\r\nfédération ICVL (Informatique Centre Val de Loire). Ce stage fait suite\r\nà une collaboration déjà initiée par le passé sur l\'étude des\r\npropriétés théoriques et statistiques des mesures de qualité des\r\nsystèmes de détection des coréférences.\r\n\r\nLa détection des coréférences est une tâche classique de traitement\r\nautomatique des langues naturelles (TALN). Elle consiste à identifier\r\nles chaînes de référence dans un texte, c\'est-à-dire les suites de\r\nmentions d\'une même entité ou concept. Les techniques d\'apprentissage\r\nautomatique sont aujourd\'hui dominantes dans ce domaine et leurs\r\nperformances ont connu un saut quantitatif notable au cours de ces\r\ndernières années. Les laboratoires LIFAT et LIFO ont d\'ailleurs\r\ndéveloppé un système de ce type pouvant travailler sur tout type de\r\ndocument textuel.\r\n\r\nCependant, des travaux récents, tels que ceux et Chai et al. (2020)\r\nsuggèrent que ces performances ne sont pas nécessairement dues\r\nà une meilleure compréhension du discours par les systèmes\r\nautomatiques, mais pourraient être en partie le résultat de\r\nl\'exploitation d\'artefacts statistiques par les formidables outils de\r\nreconnaissance de motifs que sont les réseaux de neurones profonds.\r\nDans ce contexte, les limites - soupçonnées depuis longtemps - des\r\nmesures de qualité existantes de ces systèmes deviennent\r\nproblématiques, l\'évaluation *qualitative* des systèmes semble refléter\r\nde moins leurs capacités réelles aussi bien comme outils à part entière\r\nque comme briques dans des chaînes de traitements.\r\n\r\nNos premiers travaux à ce sujet, concentrés sur les propriétés\r\nintrinsèques de ces métriques, nous ont permis de mettre en lumière le\r\ncaractère contre-intuitif de certaines de leurs propriétés théoriques\r\net a donné lieu à une publication en 2020 (Lion-Bouton et al. 2020) et\r\nà initier des expériences de comparaisons entre les jugements apportés\r\npar ces métriques et les jugements d\'annotateurs humains.\r\n\r\nLe sujet proposé ici consiste à poursuivre ces travaux - notamment par\r\nla poursuite de comparaisons entre mesures quantitatives, tests\r\nd\'évaluation qualitative et jugements humains - et à les compléter par\r\nune étude des propriétés des métriques dans des cas concrets, notamment\r\nen étudiant de façon systématique leur réponse à des perturbations\r\naléatoires de données réelles, dans l\'esprit de travaux comme ceux de\r\nBregeon et al. (2019).\r\n\r\n## Résultats attendus\r\n\r\n-   Établissement d\'un jeu de tests, issu de données réelles mais\r\n    permettant d\'évaluer précisément des systèmes automatiques de\r\n    détection des coréférences en fonction de leurs réponses à\r\n    différents phénomènes.\r\n-   Comparaison du comportement de systèmes existants sur ce jeu de\r\n    test avec leurs performances quantitatives rapportées et avec le\r\n    jugement porté par des humains sur la cohérence de leurs sorties.\r\n-   Construction d\'un système automatique de perturbation de données\r\n    annotées en chaînes de coréférences et étude des réponses des\r\n    métriques à différents types et différentes intensités de\r\n    perturbation.\r\n\r\n## Profil recherché\r\n\r\nCe stage demande des capacités de recherche et développement relevant\r\nd\'un niveau d\'études de fin de M2 en informatique ou en traitement\r\nautomatique du langage.\r\nMais avant tout, on attend de la personne recrutée qu\'elle présente un\r\nintérêt marqué pour la recherche, qu\'elle ait une autonomie et un sens\r\ncritique développés, et qu\'elle ne soit pas rétive à considérer les\r\nnotions de statistique nécessaires à cette étude - bien que ces notions\r\nne soient pas pré-requises.\r\nCe stage est donc proposé à des étudiants qui disposeraient d\'un bon\r\nniveau académique, d\'une curiosité scientifique affirmée et qui\r\nenvisagent une orientation professionnelle future dans le domaine de la\r\nrecherche.\r\n\r\n##  Date et lieu de stage\r\n\r\nLa personne recrutée travaillera soit au sein du laboratoire LIFAT\r\n(antenne universitaire de Blois) dans l\'équipe BDTLN\r\n(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) soit au sein\r\ndu LIFO, dans l\'équipe Contraintes et Apprentissage\r\n(http://www.univ-orleans.fr/lifo/equipes/CA/), et en collaboration avec\r\nLoïc Grobol (laboratoire Lattice de l\'École Normale Supérieure et\r\nLaboratoire de Linguistique Formelle de l\'Université de Paris).\r\nEn outre, un séminaire de recherche régulier autour de la langue\r\nnaturelle (RITUEL) est organisé entre les centres de recherche des\r\nuniversités de Tours (LI) et Orléans (LIFO, LLL). La personne recrutée\r\nsera invitée à y participer si elle le souhaite.\r\n\r\nCompte tenu du contexte sanitaire, des arrangements de travail à\r\ndistance sont envisageables.\r\n\r\n## Durée et période de stage\r\n\r\nLa durée du stage sera de 5 mois. Début de stage à négocier avec la\r\npersonne sélectionnée (mi-février 2021 au plus tard).\r\n\r\n## Rémunération\r\n\r\nLa personne recrutée recevra une gratification mensuelle correspondant\r\nà la réglementation, à savoir 15% du plafond horaire de la sécurité\r\nsociale. À titre d\'exemple, cette gratification représente un montant\r\nde 554 ¤ pour un mois avec 22 jours ouvrés, et 600,60¤ pour un mois\r\navec seulement 20 jours ouvrés (jours fériés, par exemple). Pourra\r\négalement se rajouter une indemnité de transports en commun\r\ncorrespondant à 50% d\'un abonnement mensuel étudiant. La personne\r\nrecrutée participera aux réunions de l\'équipe projet. Les frais de\r\nmission induits par ces déplacements seront remboursés.\r\n\r\n## Contact - Dépôts de candidature\r\n\r\n-   Anaïs Lefeuvre-Halftermeyer\r\n    (anais.halftermeyer@univ-orleans.fr) LIFO (U. Orléans)\r\n-   Jean-Yves Antoine (Jean-Yves.Antoine@univ-tours.fr) LIFAT\r\n    (U. Tours)\r\n-   Loïc Grobol (loic.grobol@ens.psl.eu) Lattice (ENS) et LLF\r\n    (U. Paris)\r\n-   Sylvie Billot (sylvie.billot@univ-orleans.fr ) LIFO (U. Orléans)\r\n\r\nDépôt des candidatures par courrier électronique auprès de Jean-Yves\r\nAntoine, Anaïs Lefeuvre-Halftermeyer, Loïc Grobol et Sylvie Billot,\r\navant le 10 janvier 2021, délai de rigueur. Merci de déposer :\r\n\r\n- Un CV détaillé de vos activités passées\r\n- Une lettre de motivation\r\n- Vos relevés de notes des deux dernières années d\'études\r\n\r\nLe cas échéant une lecture critique d\'article scientifique pourront\r\nêtre demandés pour la sélection.\r\n\r\n## Références\r\n\r\n-   Chai, Haixia, Wei Zhao, Steffen Eger, et Michael Strube. 2020.\r\n    « Evaluation of Coreference Resolution Systems Under Adversarial\r\n    Attacks ». In Proceedings of the First Workshop on Computational\r\n    Approaches to Discourse, 154 59. Association for Computational\r\n    Linguistics. https://www.aclweb.org/anthology/2020.codi-1.16.\r\n-   Grobol, Loïc. 2020. « Coreference Resolution for Spoken French ».\r\n    PhD Thesis, Paris, France: Université Sorbonne Nouvelle.\r\n    https://hal.archives-ouvertes.fr/tel-02928209.\r\n-   Lion-Bouton, Adam, Loïc Grobol, Jean-Yves Antoine, Sylvie Billot,\r\n    et Anaïs Lefeuvre-Halftermeyer. 2020. « Comment arpenter sans\r\n    mètre : les scores de résolution de chaînes de coréférences\r\n    sont-ils des métriques ? » In Actes du 2e atelier Éthique et\r\n    TRaitemeNt Automatique des Langues (ETeRNAL), édité par Gilles\r\n    Adda, Maxime Amblard, et Karën Fort, 10 18. Association pour le\r\n    Traitement Automatique des Langues.\r\n    https://hal.archives-ouvertes.fr/hal-02750222.\r\n-   Moosavi, Nafise Sadat. 2020. « Robustness in Coreference\r\n    Resolution ». PhD Thesis, Heidelberg, Deutschland: Universität\r\n    Heildelberg. heiDOK. http://www.ub.uni-heidelberg.de/archiv/27919.\r\n-   Bregeon, Dany, Jean-Yves Antoine, Jeanne Villaneau, et Anaïs\r\n    Lefeuvre-Halftermeyer. 2019. « Redonner du sens à l\'accord\r\n    interannotateurs : vers une interprétation des mesures d\'accord en\r\n    termes de reproductibilité de l\'annotation ». Traitement\r\n    Automatique des Langues 60 (2): 23.\r\n-   Recasens, Marta, et Eduard Hovy. 2011. « BLANC: Implementing the\r\n    Rand Index for Coreference Evaluation ». Natural Language\r\n    Engineering 17 (4): 485 510.\r\n    https://doi.org/10.1017/S135132491000029X.'),
(655, '2021-01-21', 'ATILF', 'Nancy', 'Offre de stage de 5 mois à l\'ATILF en TAL\r\n\r\n*** Titre ***\r\nLevée d\'ambiguïté lexicale à partir d\'un lexique sémantique\r\n\r\n*** Contexte et objectifs ***\r\nLes ressources linguistiques sont des composants essentiels du\r\ntraitement automatique des langues (TAL). En particulier, les corpus\r\nannotés sont sources d\'exemples pour apprendre des modèles pour\r\nrésoudre différentes tâches. Les modèles état-de-l\'art en TAL reposent\r\ngénéralement sur des réseaux de neurones appris sur des corpus annotés,\r\ncomplémentés de plongements lexicaux eux-mêmes pré-entrainés sur de\r\ngrandes masses textuelles brutes (ex. Le et al. 2020, Martin et al 2020\r\npour le français). Les ressources lexicales sont très peu exploitées\r\nbien qu\'elles puissent jouer un rôle complémentaire grâce à leur\r\ncouverture et la finesse de leurs descriptions linguistiques.\r\nCe sujet de stage est dédié à la tâche de levée d\'ambiguïté lexicale\r\navec pour objectif de combiner ressources lexicales et données\r\ntextuelles annotées. La levée d\'ambiguité lexicale est l\'un des défis\r\nmajeurs du TAL et consiste à prédire le sens d\'un mot cible dans un\r\ncontexte donné. Dans ce projet, nous nous focalisons sur les verbes.\r\nTout en nous appuyant sur des travaux récents reposant sur des méthodes\r\nsupervisées (Segonne et al 2019), nous souhaitons exploiter le lexique\r\nsémantique de verbes VerbNet (Kipper 2006) ou son équivalent français\r\nVerbNet (Danlos et al. 2016) pour bénéficier de son contenu\r\nlinguistique fin: ex. structures syntaxiques et sémantiques, classes\r\nsémantiques, exemples d\'usages pour les différentes entrées.\r\n\r\n*** Tâches à réaliser ***\r\n-   Annotation manuelle ciblée et limitée d\'un petit corpus pour un\r\n    sous-ensemble de verbes\r\n-   Encodage du lexique\r\n-   Développement et évaluation d\'algorithmes à base d\'heuristiques\r\n    (ex. Aguirre et al. 2014)\r\n-   Développement et évaluation de méthodes avancées:\r\n    ex. apprentissage supervisé, intégration de plongements lexicaux et\r\n    de plongements de graphes\r\n\r\n*** Informations complémentaires ***\r\nDurée: 5 mois\r\nLieu: laboratoire Analyse et Traitement Informatique de la Langue\r\n    Française (ATILF), Nancy\r\nEncadrement: Mathieu Constant (ATILF), Bruno Guillaume (LORIA), Karen\r\n    Fort (Univ. Sorbonne)\r\nFormation requise: niveau master 2 de traitement automatique des\r\n    langues ou de linguistique informatique\r\nGratification réglementaire\r\n\r\nContacts: Mathieu.Constant@univ-lorraine.fr, Bruno.Guillaume@loria.fr,\r\nkaren.fort@sorbonne-universite.fr\r\n\r\nCandidature:\r\nLes personnes intéressées doivent envoyer un CV et une lettre\r\nde motivation avant le 31 janvier 2021 aux personnes mentionnées\r\nci-dessus.\r\n\r\n\r\n*** Références***\r\n\r\nE. Agirre, O. López de Lacalle, and A. Soroa (2014). Random walks\r\nfor knowledge-based word sense disambiguation. Computational\r\nLinguistics, 40(1):57-84.\r\n\r\nK. Kipper Schuler (2006). VerbNet: A Broad-Coverage, Comprehensive Verb\r\nLexicon. PhD thesis, University of Pennsylvania.\r\n\r\nL. Danlos, Q. Pradet, L. Barque, T. Nakamura, and M. Constant (2016).\r\nUn Verbenet du français. Traitement Automatique des Langues, 57(1):25.\r\n\r\n\r\nH. Le, L. Vial, J. Frej, V. Segonne, M. Coavoux, B. Lecouteux, A.\r\nAllauzen, B. Crabbé, L. Besacier, D. Schwab (2020). FlauBERT:\r\nUnsupervised Language Model Pre-training for French. Proceedings of the\r\n12th Language Resources and Evaluation Conference.\r\n\r\nL. Martin, B. Muller, P. J. Ortiz Suárez, Y. Dupont, L. Romary, E.\r\nde la Clergerie, D. Seddah, B. Sagot (2020). CamemBERT: a Tasty French\r\nLanguage Model. Profeedings of ACL 2020 - 58th Annual Meeting of the\r\nAssociation for Computational Linguistics.\r\n\r\nV. Segonne, M. Candito, B. Crabbé (2019), Using Wiktionary as a\r\nresource for WSD : the case of French verb. Proceedings of the 13th\r\nInternational Conference on Computational Semantics.'),
(656, '2021-01-21', 'INRIA', 'Paris', 'Stage 1: construction d\'un vocabulaire de brevets à l\'aide du deep\r\nlearning sur très grands corpus\r\n\r\nCréation d\'un vocabulaire technique multimots par croisement du\r\nvocabulaire extrait de Wikipédia et d\'autres ressources scientifiques\r\navec un corpus de brevets.\r\n\r\n\r\n- Lire  https://stackoverflow.com/questions/61218518/count-frequency-of-multi-word-terms-in-large-texts-with-python/61293305#61293305\r\n\r\n- Extraction de phrases définitoires, analyse syntaxique, extraction\r\n  de termes et d\'hyponymes par simplification de syntagmes. Lire\r\n  https://towardsdatascience.com/unsupervised-synonym-harvesting-d592eaaf3c15\r\n\r\n- Ajout de vocabulaire multi-mots par fréquence et entropie.\r\n\r\n- Utilisation des informations portant sur les classes de brevets\r\n  (p. ex. CPC) pour la définition d\'un vocabulaire dépendant du\r\n  domaine technique.\r\n\r\n- Compléter le vocabulaire à l\'aide de plongements multi-mots\r\n\r\n- Développement d\'une taxonomie de terminologie\r\n\r\n- Intégration de la taxonomie dans un API Django\r\n\r\nL\'essentiel pour réussir\r\n\r\n- Il est important d\'être opérationnel en python et outils TAL\r\n  d\'apprentissage profond (Spacy, Pytorch, ...)\r\n\r\n- Aussi : Vous êtes passionné(e) par l\'étude de la langue et par le\r\n  traitement automatique de la langue\r\n\r\nDébut du contrat idéal : début mars.\r\n\r\nhttps://qatent.com/jobs/intern-1/'),
(657, '2021-01-21', 'INRIA', 'Paris', 'Stage 2 : Paraphrases technologiques par apprentissage profond\r\n\r\nStage 2: paraphrases spécifiques aux brevets (environ 6 mois)\r\n\r\n\r\n- Entraînement d\'un système de génération de paraphrases spécifiques\r\n  au corpus des brevets par apprentissage croisé avec des corpus\r\n  génériques de paraphrases.\r\n\r\n- Spécialisation du modèle de langage par domaine technologique\r\n  (e.g. tels que définis par les sections CPC/IPC).\r\n\r\n- Évaluation de mesures de similarités entre phrases.\r\n\r\n- Utilisation des ontologies (Wordnet, stage 1, ...) pour obtenir une\r\n  mesure / ranking de spécificités des paraphrases proposées.\r\n\r\n- Intégration dans une API Django.\r\n\r\nL\'essentiel pour réussir\r\n\r\n- Il est important d\'être opérationnel en python et outils TAL\r\n  d\'apprentissage profond (NLTK, Spacy, Pytorch, ...)\r\n\r\n- Aussi : Vous êtes passionné(e) par l\'étude de la langue et par le\r\n  traitement automatique de la langue\r\n\r\nDébut du contrat idéal : début mars.\r\n\r\n\r\nFAQ\r\n\r\n\r\n- Sur quelles données entraîner ?\r\n\r\nLire : Aaditya Prakash, Sadid A Hasan, Kathy Lee, Vivek Datla, Ashequl\r\nQadir, Joey Liu, and Oladimeji Farri. 2016. Neural paraphrase\r\ngeneration with stacked residual lstm\r\nnetworks. arXiv:1610.03098. https://arxiv.org/abs/1610.03098 (MSCOCO,\r\nQuora Duplicates, WikiAnswers Duplicates, PPDB)\r\n\r\n\r\n- Quel type de modèle neuronal utiliser ?\r\n\r\nlire :\r\n https://proceedings.neurips.cc/paper/2019/file/5e2b66750529d8ae895ad2591118466f-Paper.pdf\r\n https://opendata.stackexchange.com/questions/6094/paraphrase-data-sets\r\n\r\nV. aussi: Wang, S., Gupta, R., Chang, N. and Baldridge, J., 2019,\r\nJuly. A task in a suit and a tie: paraphrase generation with semantic\r\naugmentation. In Proceedings of the AAAI Conference on Artificial\r\nIntelligence (Vol. 33,\r\npp. 7176-7183). http://suwangcompling.com/wp-content/uploads/2018/10/AAAI_2019___Draft_3-1.pdf\r\n\r\n\r\nPostuler :\r\nhttps://qatent.com/jobs/intern-2/'),
(658, '2021-01-21', 'INRIA', 'Paris', 'Stage en legaltech: Construction d\'une base de données légale pour brevets\r\n\r\nLe startup studio d\'Inria propose un stage pour le projet qatent: Il\r\ns\'agit de constituer un corpus de la jurisprudence des brevets et le\r\npréparer pour y identifier les termes spécifiques au langage des\r\nbrevets. Vous serez assisté par un Conseil en Propriété Industrielle,\r\nqui vous guidera et vous fournira les textes légaux.\r\n\r\nmots clés : patent-NER\r\n\r\n\r\n- Constitution d\'une base de jurisprudence annotée de l\'Office\r\n  Européen des Brevets\r\n\r\n\r\n- Identification dans les textes des références à la jurisprudence et\r\n  des mentions aux articles/règles de la Convention Européenne des\r\n  Brevets (Article 56 EPC, A. 56, Art. 56 CBE...)\r\n\r\n\r\n- Identifier les mentions aux jurisprudences (T 00/641 = \"COMVIK\",\r\n  etc...)\r\n\r\n\r\n- Identifier les références aux situations de droit (\"inventive step /\r\n  non-obviousness / inventiveness \", \"novelty\",\r\n  \"clarity/clear/unclear/vague\", \"technical effect\", \"objective\r\n  problem\", \"problem-solution\", \"added subject-matter\", etc...)\r\n\r\n\r\n- Utiliser des outils spécifiques pour les brevets (patent-NER) pour\r\n  établir une relation entre jurisprudence et Directives OEB, voir\r\n  https://www.epo.org/law-practice/legal-texts/html/caselaw/2019/f/index.htm\r\n\r\n\r\nPostuler :\r\nhttps://qatent.com/jobs/intern-3/'),
(659, '2021-01-21', 'Akio', 'Paris ou Montpellier', 'Stage: Analyste / linguiste pour l\'interprétation des données de\r\nla relation client\r\n\r\nDescriptif:\r\n\r\nLe sujet proposé traite de l\'analyse et de la qualification de verbatim\r\nen français pour le compte d\'un éditeur de logiciel français dans le\r\ndomaine de la relation client.\r\n\r\n\r\nDescription du poste:\r\n\r\nL\'objectif premier du stage est d\'analyser et d\'annoter des verbatim en\r\nfrançais à partir d\'un nouvel outil spécifiquement créé auquel vous\r\nserez formé.\r\nIl s\'agit d\'annoter des textes de sources diverses (emails, avis\r\nclients, textes en provenance des réseaux sociaux ...) afin de\r\ndéterminer pour chaque segment le sentiment associé : positif, négatif\r\nou neutre.\r\n\r\nL\'autre objectif est de contribuer à l\'annotation sémantique et\r\nl\'exploration textuelle des données afin d\'=EAtre en mesure d\'en\r\ndétecter les topics relatifs à la relation client principalement dans\r\nle domaine du E-commerce et des Mutuelles / Assurances.\r\n\r\nVous serez intégré au p=F4le linguiste et travaillerez au sein\r\nd\'une équipe dynamique qui met en oeuvre les technologies les plus\r\nrécentes dans le domaine NLP.\r\n\r\n\r\nProfil recherché:\r\n-   Niveau Licence minimum en linguistique ou en traitement automatique\r\n    du langage\r\n-   Très bon niveau en français\r\n-   Grande rigueur et esprit logique\r\n-   Maîtrise des outils informatiques / compétences en programmation\r\n    non requises\r\n-   Une langue parlée couramment serait un plus : espagnol, italien,\r\n    anglais ou allemand\r\n\r\nDurée:\r\n6 mois\r\n\r\nDate début de stage\r\nASAP\r\n\r\nLieu:\r\nLe stage pourra se dérouler sur notre site de Paris (75010) ou\r\nMontpellier (quartier Antigone)\r\n\r\n\r\nAkio\r\nEquipe: traitement automatique de la langue.\r\n43 rue de Dunkerque, 75010 Paris.\r\nwww.akio.com<http://www.akio.com/>\r\n\r\n\r\nGratification:\r\nSelon les règles en vigueur avec participation aux frais de\r\ntransports en commun et repas.\r\n\r\nEncadrement:\r\nLe stage sera encadré par Lynda Ould Younes\r\n\r\nCandidature:\r\nMerci d\'envoyer un CV à srumeur@akio.com et louldyounes@akio.com\r\naccompagné des notes de l\'année universitaire en cours et de celles\r\nde l\'année dernière.'),
(660, '2021-01-21', 'LISN', 'Orsay', 'Internship for Last Year Engineer or Master 2 Students\r\n\r\nKeywords: Machine Learning, Diarization, Digital Humanities, Political\r\nSpeech, Prosody, Expressive Speech\r\n\r\n\r\nContext\r\n\r\nThis internship is part of the Ontology and Tools for the Annotation of\r\nPolitical Speech (OOPAIP), a transdisciplinary project funded under the\r\nDIM-STCN (Text Sciences and New Knowledge,\r\nhttp://www.dim-humanites-numeriques.fr/en/) by the Regional Council of\r\nIle de France. The project is carried out by the European Center for\r\nSociology and Political Science (CESSP, https://www.cessp.cnrs.fr/) of\r\nthe University of Paris 1 Panthéon-Sorbonne, the National\r\nAudiovisual Institute (INA, https://www.ina.fr/), and the LISN\r\n(https://www.limsi.fr/en/). Its objective is to design new approaches\r\nto develop detailed, qualitative, and quantitative analyzes of\r\npolitical speech in the French media. Part of the project concerns the\r\nstudy of the dynamics of conflicting interactions in interviews and\r\npolitical debates, which requires a detailed description and a large\r\ncorpus to allow for the models\' generalization. Some of the main\r\nchallenges concern the performance of speaker and speech style\r\nsegmentation, e.g., improving the segmentation accuracy, detecting\r\nsuperimposed speech, measuring vocal effort and other expressive\r\nelements.\r\n\r\n\r\nObjectives\r\n\r\nThe main objective of the internship is to improve the automatic\r\nsegmentation of political interviews. In this context, we will be\r\nparticularly interested in the detection of \"hubbub\" (strong and\r\nprolonged overlapped speech). More precisely, we would like to extract\r\nfeatures from the speech signal (Eyben, 2015) correlated with the level\r\nof conflictual content in the exchanges, based, for example, on the\r\narousal level in the speaker\'s voice-intermediate level between the\r\nspeech signal analysis and the expressivity description (Rilliard,\r\n2018)-or vocal effort (Lienard, 2019).\r\n\r\nThe internship will initially be based on two corpora of 30 political\r\ninterviews manually annotated in speech turns and speech acts-within\r\nthe framework of the OOPAIP project. It will begin with a state of the\r\nart review of speech diarization  and overlapped speech detection\r\n(chowdhury, 2019). The aim will then be to propose solutions based on\r\nrecent frameworks (Bredin, 2020) to improve the precise localization of\r\nspeaking segments, in particular when the frequency of speaker changes\r\nis high.\r\n\r\nIn the second part of the internship, we will look at a more detailed\r\nmeasurement and prediction of the conflicting level of exchanges. We\r\nwill search for the most relevant features to describe the conflicting\r\nlevel and by adapting or developing a neural network architecture for\r\nits modeling.\r\n\r\nThe programming language used for this internship will be Python. The\r\ncandidate will have access to the LISN computing resources (servers and\r\nclusters with recent generation GPUs).\r\n\r\n\r\nPublications\r\n\r\nDepending on the degree of maturity of the work carried out, we expect\r\nthe applicant to:\r\n\r\n*   Distribute the tools produced under an open-source license\r\n\r\n*   Write a scientific publication\r\n\r\n\r\nConditions\r\n\r\nThe internship will take place over a period of 4 to 6 months at the\r\nLISN (formerly LIMSI) in the Spoken Language Processing (TLP) group.\r\nThe laboratory is located near the \"plateau de Saclay\", university\r\ncampus building 507, rue du Belvédère, 91400 Orsay. The candidate\r\nwill be supervised by Marc Evrard (marc.evrard@lisn.upsaclay.fr).\r\nAllowance under the official standards\r\n(https://www.service-public.fr/professionnels-entreprises/vosdroits/F32131).\r\n\r\n\r\nApplicant profile\r\n\r\n*   Student in the last year of a 5-years diploma in the field of\r\n    computer science (AI is a plus)\r\n\r\n*   Proficiency in Python language and experience in using ML libraries\r\n    (Scikit-Learn, TensorFlow, PyTorch)\r\n\r\n*   Strong interest in digital humanities and political science in\r\n    particular\r\n\r\n*   Experience in automatic speech processing is preferred\r\n\r\n*   Ability to carry out a bibliographic study from scientific articles\r\n    written in English\r\n\r\nTo apply: Send an email to marc.evrard@lisn.upsaclay.fr including a\r\nrésumé and a cover letter.\r\n\r\n\r\nBibliography\r\n\r\nBredin, H., et al. (2020). Pyannote.audio: neural building blocks for\r\nspeaker diarization. In ICASSP 2020 (pp. 7124-7128).\r\n\r\nChowdhury, S. A., Stepanov, E. A., Danieli, M., Riccardi, G. (2019).\r\n\"Automatic classification of speech overlaps: Feature\r\nrepresentation and algorithms\", Computer Speech & Language, vol.\r\n55, pp.145-167.\r\n\r\nEyben, F., Scherer, K. R., et al. (2015). The Geneva minimalistic\r\nacoustic parameter set (GeMAPS) for voice research and affective\r\ncomputing. IEEE transactions on affective computing, 7(2), 190-202.\r\n\r\nLiénard, J.-S. \"Quantifying vocal effort from the shape of\r\nthe one-third octave long-term-average spectrum of speech\" J.\r\nAcoust. Soc. Am. 146 (4), Oc-tober 2019.\r\n\r\nOOPAIP (Ontologie et outil pour l\'annotation des interventions\r\npolitiques), DIM STCN (Sciences du Texte et connaissances nouvelles),\r\nConseil régional d\'Ile de France,  url:\r\nhttp://www.dim-humanites-numeriques.fr/projets/oopaip-ontologie-et-outils-pour-lannotation-des-interventions-politiques/\r\n\r\nRilliard, A., d\'Alessandro, C & Evrard, M. (2018). Paradigmatic\r\nvariation of vowels in expressive speech: Acoustic description and\r\ndimensional analysis. The Journal of the Acoustical Society of America,\r\n143(1), 109-122.');

--
-- Index pour les tables exportées
--

--
-- Index pour la table `mytable`
--
ALTER TABLE `mytable`
  ADD PRIMARY KEY (`id`);

--
-- AUTO_INCREMENT pour les tables exportées
--

--
-- AUTO_INCREMENT pour la table `mytable`
--
ALTER TABLE `mytable`
  MODIFY `id` int(11) NOT NULL AUTO_INCREMENT, AUTO_INCREMENT=671;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
