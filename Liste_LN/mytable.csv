"1","2007-12-22","ARISEM","Massy","Sujet : Etude, spécification et développement d'un système d'extraction de
relations entre entités nommées.

Date de démarrage : février/mars 2008
Durée : 6 mois
Niveau : Master en TAL

Contexte
--------

Dans le cadre de ses travaux de R&D, Arisem a créé un nouveau moteur
d'analyse sémantique et d'extraction d'information. Afin d'améliorer
sa pertinence, nous travaillons actuellement sur l'extraction de
relations sémantiques entre entités nommées.

Contenu du stage
----------------

D'une durée de 6 mois, ce stage est consacré à l'étude de la
problématique concernant l'extraction de relations et des différentes
approches existantes. Par la suite, le stagiaire sera amené à
participer au développement des ressources pour l'acquisition de
relations à partir d'un corpus de textes.

En collaboration avec les équipes R&D d'Arisem, le travail du
stagiaire sera découpé en trois phases :
- Compréhension de notre problématique d'extraction ;
- Etude et compréhension des différentes approches existantes pour
l'extraction de relations ;
- Participation au développement du système d'acquisition de relations
entre entités nommées.

Profil recherché
----------------

Etudiant en dernière année de master en traitement automatique des
langues, le candidat doit avoir de bonnes connaissances en
informatique et des logiciels de traitement automatique des langues
(Unitex, Gate, etc.).


Les candidatures sont à adresser à :
nicolas.dessaigne@arisem.com
aurelie.migeotte@arisem.com"
"2","2008-01-08","IGN","Saint-Mandé","Contexte

Le laboratoire COGIT travaille à un projet de conception de carte sur
mesure, c'est-à-dire une carte pertinente et efficace par rapport aux
objectifs du concepteur et adaptée à ses goûts.

Un des axes de recherche vise à constituer des bases de connaissances
qui permettront d'exploiter la description que l'utilisateur fait de
son besoin pour l'aider à concevoir sa carte dans les règles de
l'art. Pour cela, il est nécessaire d'établir des correspondances
entre la description que des utilisateurs peuvent faire de leur carte
et les paramètres de construction d'une carte tels qu'ils sont définis
par des experts.

Différentes actions ont été mises en place pour faire décrire une
carte par des publics variés. Ces travaux ont permis d'ébaucher une
description formalisée de carte.

Sujet

Le stage a pour objectif d'exploiter un ensemble commenté et organisé
d'interviews. Ces interviews font partie d'une enquête réalisée par un
service de l'IGN concernant la carte au 1/50 000 par rapport au thème
de la randonnée (à pied, en vélo, en VTT, ...). Il s'agit de mettre en
forme ce corpus puis de l'exploiter (manuellement, avec des outils de
TALN et éventuellement des méthodes numériques) afin d'identifier en
particulier les acteurs, les activités, les objectifs des acteurs par
rapport aux activités.  Ces éléments permettront de proposer des
caractéristiques de cartes pertinentes par rapport aux souhaits des
utilisateurs et cohérentes avec le modèle de description de cartes qui
est en cours d'élaboration dans l'équipe de recherche.

Compétences particulières et formation requise

master avec compétences en informatique linguistique, éventuellement
en cartographie.

Une bonne maîtrise de la langue française est indispensable.

Lieu du stage
Institut géographique national
2 avenue Pasteur
94160 Saint-Mandé

Durée et rémunération 
durée : 4 à 6 mois
début : mars/avril 2008
rémunération : 30% du SMIC

Responsable de stage
Catherine DOMINGUES
mel : catherine.domingues@ign.fr
Tél : 01 43 98 85 44
http://recherche.ign.fr/cogit"
"3","2008-01-13","LIMSI - CNRS","Orsay","Titre : Détection d'expressions figées pour les systèmes de questions-réponses

Date de démarrage : mars/avril 2008
Durée : 4 mois

Lieu du stage : LIMSI/CNRS, groupe LIR    (91403 Orsay)

Voir aussi : 
http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_expressions_figees.html

Thème  :

Dans le cadre des systèmes de questions-réponses, de recherche
d'information, mais aussi en analyse syntaxique et dans de nombreux
domaines, il est intéressant de connaître les expressions figées ou
semi-figées.  Par exemple, les locutions comme ""pomme de terre"" ou
""perdre la vie"", mais aussi des entités nommées ou des expressions
longues comme ""la déclaration universelle des droits de l'homme et du
citoyen"".  En recherche d'information et dans les systèmes
questions-réponses, connaître ce type de locutions nous permet de
décider si la requête doit être constituée de l'expression entière ou
si les mots doivent être considérés de façon indépendante.


Description  du  stage  :

De nombreux travaux ont traité le problème des locutions, mais de
nombreuses imperfections subsistent.  Le but du stage est d'étudier
l'état de l'art en la matière et de mettre en ½uvre une méthode
adaptée au contexte des systèmes de questions-réponses.


Contacts :
Xavier Tannier : xavier.tannier@limsi.fr
Véronique Moriceau : moriceau@limsi.fr

---------------"
"4","2008-01-13","LIMSI - CNRS","Orsay","--------------
Titre : Détection et validation de paraphrases en contexte

Date de démarrage : mars/avril 2008
Durée : 4 mois

Mots-clés : analyse syntaxique, paraphrases, traitement automatique de
la langue, système de questions-réponses

Lieu du stage : LIMSI/CNRS, groupe LIR     ( 91403 Orsay)

Voir aussi : 
http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_paraphrases.html

Contexte  : 
Dans le domaine de la recherche d'information, l'un des défis actuels
porte sur les systèmes de questions-réponses en domaine ouvert.
L'objectif de ces systèmes est de fournir une réponse à une question
exprimée en langage naturel en trouvant cette réponse dans un ensemble
de documents, ensemble éventuellement très large et pouvant aller
jusqu'au Web.
La plupart des systèmes de questions-réponses sont à même d'extraire
la réponse à une question factuelle lorsqu'elle est explicitement
présente dans les textes mais dans le cas contraire, ils ne sont pas
capables d'agencer différents morceaux d'information dans le cadre
d'un raisonnement pour produire une réponse.
Par exemple un raisonnement dans lequel il faut assembler plusieurs
extraits d'informations répartis dans plusieurs documents ou dans
plusieurs phrases d'un même document.  Par exemple, pour répondre à la
question ""Quel est l'âge de la femme de Tom Cruise ?"", il faut tout
d'abord identifier la femme de Tom Cruise puis chercher son âge.
Le projet CONIQUE a pour objectif de pallier cette insuffisance et
s'inscrit en cela dans un courant de recherche actuellement très actif
visant à intégrer dans les systèmes de questions-réponses des
mécanismes de compréhension de textes s'appuyant sur des inférences.
Contrairement à la plupart des travaux allant dans ce sens, le premier
axe de notre projet a pour but non pas de constituer ou d'exploiter
une base de connaissances a priori permettant de répondre aux
questions mais de modéliser l'extraction de ces connaissances à partir
de différents textes en fonction des besoins nécessaires à la
construction d'un chemin inférentiel entre les éléments trouvés dans
les textes et l'information cherchée, telle qu'elle est spécifiée par
une question.


Thème  :
Les analyseurs syntaxiques sont des outils de traitement automatique
de la langue permettant d'identifier les relations syntaxiques entre
les constituants d'une phrase (SUJET, OBJET, etc.).  Ils fournissent
des sorties dans un format qui leur est propre.
Dans le cadre de ce projet, on utilise un analyseur syntaxique pour
déterminer si un passage pré-sélectionné par un moteur de recherche
répond réellement à la question de l'utilisateur.  On cherche
notamment à montrer que certaines relations syntaxiques (ou
éventuellement sémantiques) présentes dans des passages sont (ou ne
sont pas) équivalents aux relations présentes dans la question.  Par
exemple, la question pourra porter sur le nombre de personnes ayant
""perdu la vie"" lors d'un événement, tandis que le passage précise que
cet événement ""a fait X morts"".  Cet aspect se rapproche de la
problématique de la recherche de paraphrases.

Travail  à  réaliser  : 
Le but du stage est d'étudier l'état de l'art en la matière, de
réfléchir aux avantages de se situer dans un contexte précis (les
passages) plutôt que dans un cadre général (ce que fait la
littérature), ainsi que de mettre en place des techniques de
validation des paraphrases.

Contacts :
Xavier Tannier : xavier.tannier@limsi.fr
Véronique Moriceau : moriceau@limsi.fr

---------------"
"5","2008-01-16","ARISEM","Massy","Sujet : Enrichissement des ressources linguistiques pour l'extraction
d'entités nommées

Date de démarrage: février/mars 2008 
Durée: 6 mois
Niveau: Master en TAL

Contexte
--------

Dans le cadre de ses travaux de R&D, Arisem a créé un nouveau moteur
d'analyse sémantique et d'extraction d'information. L'approche choisie 
s'appuie sur l'utilisation conjointe de différents types de ressources
linguistiques (dictionnaires, grammaires, ontologies, expressions
régulières, etc.).

Contenu du stage
----------------

D'une durée de 6 mois, ce stage est consacré à la mise à jour et
l'enrichissement des ressources linguistiques dédiées à l'allemand, le
néerlandais, l'italien et le portugais.

En collaboration avec les équipes R&D d'Arisem, le stagiaire aura pour 
objectifs principaux la création et l'enrichissement des ressources
suivantes:
- Dictionnaires de langue générale et dictionnaires orientés métier;
- Grammaires locales d'extraction d'entités nommées; 
- Ontologies métier.

Dans le cadre de son travail, le stagiaire sera également amené à:
- Participer à l'amélioration de l'éditeur de ressources linguistiques;
- Créer des corpus de test et des corpus annotés pour permettre 
l'évaluation des ressources et des traitements.

Profil recherché
----------------

Etudiant en dernière année de master en traitement automatique des
langues, le candidat doit être bilingue dans l'une des langues 
suivantes: allemand, néerlandais, italien ou portugais.

La maîtrise des outils Unitex ou Nooj et des compétences en
informatique (perl, commandes unix) sont appréciées.


Les candidatures sont à adresser à : 
nicolas.dessaigne@arisem.com <mailto:nicolas.dessaigne@arisem.com>
aurelie.migeotte@arisem.com <mailto:aurelie.migeotte@arisem.com>
---
Nicolas Dessaigne,
Directeur technique
Arisem"
"6","2008-01-21","LIMSI - CNRS","Orsay","Le groupe LIR du LIMSI (Orsay) propose le stage suivant en traduction
automatique:

""Un peu de contexte en traduction automatique : exploitation de
relations grammaticales en traduction automatique statistique""

Mots clés      : traduction automatique, traitement automatique des
                 langues, analyse syntaxique, désambiguïsation
                 lexicale
Niveau d'étude : Master Recherche ou fin d'école d'ingénieurs en
                 informatique
Durée du stage : 4 mois à partir de mars 2008
Lieu du stage  : laboratoire LIMSI-CNRS, Orsay (RER ligne B)
Description    : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2R-2008.html
Contact        : aurelien.max@limsi.fr

Résumé :
La traduction automatique a connu un nouvel essor avec l'émergence
d'approches basées sur des corpus. La traduction automatique
statistique connaît toutefois des limites. Des approches récentes
essaient donc d'intégrer des connaissances linguistiques dans ces
systèmes afin de mieux prendre en compte les caractéristiques des
textes à traduire, de leur traduction, et des relations qu'ils
entretiennent.

Les systèmes actuels en traduction automatique statistique se basent
sur une segmentation en groupes de mots des phrases à traduire
auxquels sont associées des traductions (phrase-based machine
translation). Les modèles utilisés pour guider la recherche de la
meilleure traduction se concentrent essentiellement sur les relations
de traduction et sur une bonne formation locale de la langue
cible. L'objet de ce stage est de travailler sur la prise en compte
d'informations linguistiques présentes dans la langue source, afin de
modéliser le contexte dans lequel apparaissent les groupes de mots à
traduire. On s'intéressera notamment à l'exploitation des relations
grammaticales entre les mots pour la paire de langue français-anglais."
"7","2008-01-21","IBISC - Université d'Evry","Evry","Proposition de stage à l'IBISC :
Sujet de stage : Aide à l'annotation d'articles scientifiques

Contexte
QKDB (http://physiome.ibisc.fr/qkdb) est une base de données sur la
physiologie du rein, qui décrit 300 articles scientifiques. Les
informations contenues dans cette base donnent, pour chaque article,
des détails sur les expériences et les résultats décrits dans
l'article : espèce concernée, organe, différentes mesures
effectuées... Ces informations ont été introduites manuellement dans
la base, après lecture de chacun des articles par un expert du
domaine.

Sujet
L'objet du stage est l'aide à l'annotation d'articles scientifiques
pour l'intégration dans la base de données QKDB en repérant
automatiquement les éléments du texte qui décrivent les informations à
ajouter dans la base. A cette fin, il s'agit de constituer une base de
référence contenant les textes dans lesquels seront annotés les
éléments déjà présents dans la base QKDB. En effet, actuellement, on
retrouve les articles qui répondent à une requête, mais on ne sait pas
où l'information est donnée dans l'article.

Il s'agira ainsi de revenir au texte à partir des informations de la
BD en :
- transformant les articles de pdf en texte. On partira d'outils 
  existants qu'il faudra améliorer ;
- projetant les données de la BD dans les textes, en utilisant là
  aussi des outils existants (reconnaissance d'entités numériques et
  reconnaissance de termes) afin de reconnaître la manière dont les
  attributs et les valeurs de la base sont formulés dans les textes.

La base de référence ainsi constituée devra permettre de mettre en
place un outil d'extraction automatique des données sur la physiologie
du rein.

Informations pratiques
Lieu du stage : IBISC, Tour Evry2, Evry 
(http://www.ibisc.univ-evry.fr/), équipe AMISBIO (http://amisbio.ibisc.fr)
Responsables : Brigitte Grau, Anne-Laure Ligozat
Durée : 5 mois
Niveau : M2 ou dernière année d'école d'ingénieur
Stage rémunéré"
"9","2008-02-06","Syllabs","Paris","Proposition de stages au sein de la société Syllabs
---------------------------------------------------

La société : Syllabs est un jeune laboratoire de recherche privé
spécialisé dans les domaines de la Gestion de l'Information et du
Traitement Automatique des Langues.  Syllabs est au coeur de trois
activités complémentaires : La Recherche, les Développements Innovants
et le Conseil.

Pour plus d'infos : www.syllabs.com

Nous recrutons 2 stagiaires :
- 1 linguiste TAL
- 1 linguiste-informaticien(ne)

Si vous êtes intéressé(e) par l'un de ces stages, merci d'envoyer
votre CV accompagné d'une lettre de motivation à l'adresse
jobs@syllabs.com

Syllabs est situé dans le 5ème arrondissement :
62 bis rue Gay Lussac
75005 Paris
Tel : 01.75.00.02.80

Accès :	RER B (Luxembourg) / Bus 21, 27


****************************
LINGUISTE TAL
****************************

* Contexte :

Analyse de plagiats et analyse des opinions

* Sujet du stage :

Aide à la constitution d'une typologie des transformations des textes
et étiquetage d'un corpus de plagiats + Analyse des opinions et
constitution de lexiques

* Objectifs du stage :

La personne recrutée pour ce stage mènera deux tâches en parallèle.
La première est liée au projet Piithie (projet ANR débuté en
2007). Elle concerne la validation et la modification d'une typologie
des transformations des textes et l'étiquetage d'un corpus de plagiats
d'une manière fine afin de tester ladite typologie et de constituer un
corpus de test.
La seconde se fera dans le cadre du projet RPM2 (projet ANR débuté en
2008) et concernera l'analyse des opinions. Les travaux consisteront
en un état de l'art et en la production d'un lexique simple et d'un
lexique ouvert (formes non figées).
La personne travaillera avec des informaticiens et des linguistes et
participera aux réunions projet avec les différents partenaires
(entreprises et laboratoires publics).

* Niveau souhaité : Linguiste TAL Bac+4/Bac+5 - Master

* Durée : 4-6 mois

****************************
LINGUISTE-INFORMATICIEN(NE)
****************************

* Contexte :

La création et la gestion de ressources linguistiques prend énormément
de temps. Syllabs développe des outils permettant d'aider le linguiste
dans cette tâche. De nombreux outils et interfaces sont à développer
dans ce contexte.

* Sujet du stage :

Aide aux linguistes pour la création et la gestion de ressources
linguistiques

* Objectifs du stage :

La personne recrutée pour ce stage aura pour tâche de concevoir,
implémenter et tester des méthodes permettant d'aider le linguiste
dans sa tâche. Le gros du travail sera centré sur les ressources
lexicales (morphosyntaxiques, thématiques, etc.).
Elle participera à la création d'un formalisme de description des
informations linguistiques qui s'insère dans un formalisme de
description plus large.
Le stage pourra déboucher sur une thèse avec un sujet plus ou moins
proche (Syllabs devrait débuter deux thèses, fin 2008, sur des sujets
à définir).

* Connaissances et niveau souhaités :

Linguistique Informatique, Bac+5 - Master 2

- Très bonnes connaissances dans les domaines du Traitement
  Automatique des Langues et de la Gestion de l'information.
- Très bonne maîtrise d'un langage de script : Perl ou Python

- Eléments facultatifs mais considérés comme un plus :
	- maîtrise d'une ou plusieurs langues étrangères
	- maîtrise de Java
	- désir de faire une thèse

Durée : 6 mois

-- 

---------------------------------------------------
Christelle Ayache
Chef de projet - Syllabs
62 Bis rue Gay Lussac 75005 Paris
Tel : +33 (0)1 75 00 02 80
Courriel : ayache@syllabs.com
Site Web : www.syllabs.com
---------------------------------------------------"
"10","2008-02-11","SPIM - Paris 5","Paris","Proposition de stage M2 

ADAPTATION DE TERMINOLOGIES EXISTANTES AU TRAVERS DE CORPUS

Natalia Grabar (natalia.grabar@spim.jussieu.fr)
SPIM - Centre de Recherche des Cordeliers ; U Paris Descartes, UMR_S 872 ;
INSERM, U872 ; HEGP AP-HP

Contexte

Plusieurs terminologies existent dans le domaine biomédical et
proposent des descriptions de la biologie ou de la médecine. Ces
terminologies ont deux caractéristiques principales : 1. Elles sont
spécifiques aux applications : MeSH (NLM, 2001) pour la recherche
d'information, MedDRA (Brown et al., 1999) pour la description des
effets indésirables des médicaments, GO (Gene Ontology Consortium,
2000) pour l'annotation fonctionnelle des gènes, ...  2. Elles sont
généralistes de domaines médical ou biologique : elles visent à en
proposer une description aussi exhaustive que possible.

Du fait de leur spécificité (1), leur utilisation est plus aisée dans
des applications. Quant à leur nature généraliste (2), cela correspond
à un réel besoin mais peut présenter une limite lorsque l'on travaille
avec des données d'une seule spécialité médicale (cardiologie,
stomatologie) ou même avec des données relatives à un questionnement
médical plus précis (diagnostic de métastases hépatiques du cancer
colorectal). Dans ce dernier cas surtout, il pourrait être intéressant
d'avoir une ressource terminologique adaptée à la question médicale.

Objectifs

Le coût nécessaire à l'élaboration de ressources terminologiques étant
élevé, nous proposons d'aborder cette problématique en termes
d'adaptation de terminologies. L'objectif du stage consiste à
implémenter et tester une méthodologie qui permettrait d'adapter les
terminologies existantes, au travers des corpus, à une question
médicale précise.

Le matériel principal de travail sont des mots-clés centraux pour une
question, par exemple: ""colorectal neoplasms"" ; ""liver neoplasms"" ;
""laparoscopy"" ; ""tomography, emission-computed"" ; ""magnetic resonance
imaging"" ; ""tomography, x-ray computed"" pour la question diagnostic de
métastases hépatiques du cancer colorectal. Ce matériel servira
d'amorce pour la constitution de corpus (articles scientifiques) et de
points d'entrée dans les terminologies (p.ex. l'UMLS (NLM, 2007) qui
propose plus de 140 terminologies biomédicales). Le stagiaire
utilisera des outils d'acquisition (Bourigault & Jacquemin, 2000) et
structuration (Grabar & Hamon, 2004) des terminologies. Le
développement en Perl (sous Linux/Unix) sera demandé lors de
différentes étapes de la méthodologie.

Déroulement du stage

Le stage sera encadré par un chercheur en informatique biomédicale et
en TAL, et co-encadré par un médecin. Il s'agit d'un stage de 6 mois
rémunéré. Il se déroulera au Centre de Cordeliers (Paris 6). Un CV et
une lettre de motivation sont à envoyer à Natalia Grabar.

Références 

BOURIGAULT, D. & JACQUEMIN , C. (2000). Construction de ressources
terminologiques, In J.-M. PIERREL, Ed., Industrie des langues,
pp. 215­233.

BROWN , E., WOOD , L. & WOOD , S. (1999). The medical dictionary for
regulatory activities (MedDRA). Drug Saf., 20(2), 109­17.

GENE ONTOLOGY CONSORTIUM (2000). Gene Ontology : tool for the
unification of biology. Nature genetics, 25, 25­29.

GRABAR , N. & HAMON , T. (2004). Les relations dans les terminologies
structurées : de la théorie à la pratique. Revue d'Intelligence
Artificielle (RIA), 18(1).

NLM (2001). Medical Subject Headings. National Library of Medicine,
Bethesda, Maryland. http://www.nlm.nih.gov/mesh/ meshhome.html.

NLM (2007). UMLS Knowledge Sources Manual. National Library of
Medicine, Bethesda, Maryland. www.nlm.nih.gov/research/umls/."
"12","2008-03-17","EDF","Clamart","Stage Moteur de recherche à EDF
=============================

Contexte

Le Département Internet de la Direction Informatique et Telecom a en
charge la promotion des nouvelles technologies au sein d'EDF. Afin de
mener à bien cette mission il a la responsabilité d'un certain nombre
d'Etudes d'Interêt Général dont l'objectif est d'avoir un regard sur
les solutions qu'il sera pertinent d'inclure dans le catalogue des
solutions référencées de l'entreprise. Ces études comportent
généralement cinq phases

· spécification fonctionnelle du besoin en collaboration avec une
  maîtrise d'ouvrage identifiée, cette phase comprend si nécessaire un
  maquettage, une étude ergonomique

· spécification technique : définition de l'architecture technique,
  choix des outils...

· réalisation : paramétrage/développement

· mise en ½uvre pouvant aller jusqu'à un pilote représentatif déployé
  sur des utilisateurs.
 
· retour d'expérience pour prise de décision.

Le stage proposé ci-dessous s'inscrit dans cette dynamique, il est
prévu pour une durée minimale de 3 mois extensibles à 6 mois. Le
stagiaire sera intégré dans les équipes du Département qui dispose de
toutes les compétences pour guider le stagiaire dans son travail. Le
stage débute dés que possible à partir de mars 2008.

Sujet de stage

La disponibilité d'un moteur de recherche pertinent, transverse,
indexant tous les fonds documentaires utiles et respectant les droits
d'accès est une nécessité dans l'entreprise d'aujourd'hui.

Une solution spécifique pour la recherche des documents stockés sur le
poste local doit être trouvée. Le moteur de recherche de Vista
apportera en effet un premier niveau de services, mais ne permettra
pas la recherche en mode déconnecté dans les bases Quickr (outil de
travail collaboratif retenu par EDF) ni la recherche sur les bases
Notes e-mail ou les bases documentaires personnelles des utilisateurs.

EDF dispose dans son catalogue de solution de l'outil K2 (Verity) de
la société Autonomy. Ce moteur de recherche est mis en place sur
certains Intranet ou Internet de l'entreprise.

Le stage consiste en :

· La vérification de la pertinence de K2 sur les fonds actuellement
  indexé,

· La possibilité d'étendre K2 à d'autres fonds (Quickr, bases Notes,
poste local,...)

· Une étude des nouvelles solutions disponibles sur le marché (Google,
  Sinequa, Exalead) à la fois sur le poste de travail mais aussi au
  niveau serveur. Cette étude pourra aborder également aborder des
  sujets connexes tels que la catégorisation automatique, la recherche
  de contenus non textuels, la recherche cross-langage, la veille
  technologique.

Compétences requises
· Connaissance informatique généraliste
· Bonne autonomie, aptitude à rendre compte de son travail
· Rigueur dans lanalyse des résultats et la comparaison des solutions

Lieu du stage
EDF-DIT, 1 avenue du Général de Gaulle 92141 Clamart

Contact : Cécile Gros
cecile.gros@edfgdf.fr
01 47 65 59 92"
"13","2008-06-24","LCI","Lannion","OFFRE DE STAGE LINGUISTIQUE LANNION (22)

Groupe spécialisé en communication technique multilingue propose un
stage en linguistique, au sein d'une équipe internationale à Lannion
pour des étudiants en Master I ou II de TALN ou Sciences du langage.

Contenu du stage (encadré par linguiste expérimenté) :

- Participation à un projet sur le langage SMS associé à des icônes :
  validation et enrichissement d’un lexique

- Correction de requêtes internet

Profil des stagiaires :
Langue maternelle française.
Niveau Master 1 ou 2.
Qualités requises : orthographe parfaite, rigueur, autonomie, bon
contact humain.
La connaissance des outils utilisés en TALN (scripts, perl) est un
plus.

Dates : de début juillet à fin août 2008 environ


Contact : envoyez votre CV par E-mail à
brigitte.ororke@lci-bretagne.com 
www.lci-europe.com"
"14","2008-06-24","LCI","Lannion ou télétravail","STAGE en LINGUISTE INFORMATIQUE - LANNION (22) ou à distance

Groupe spécialisé en communication technique multilingue recherche un
linguiste informaticien pour un stage de recherche :


Descriptif de la mission principale :

- Exploitation de bases de données phraséologiques bilingues ou
  multilingues dans le but de générer automatiquement des paraphrases
  pour des applications vocales (serveurs vocaux).

- Stage soit de 3 mois sur site à Lannion (Bretagne 22), soit en
  partie à temps partiel à distance en parallèle à une année d’études
  et en partie en local, dates à discuter.

Profil recherché :

Etudiant en linguistique informatique niveau Bac + 4 minimum (orienté
recherche)
Informatique : être à l'aise avec les outils de manipulations de
fichiers (scripts, perl, python, ...). Une bonne connaissance de Linux
est un plus..  Qualités requises : goût pour la recherche, curiosité,
rigueur, autonomie, bon contact humain
Langues : Français courant, anglais lu

Contact : envoyez votre CV et lettre de motivation par E-mail à
brigitte.ororke@lci-bretagne.com

http://www.lci-europe.com"
"15","2009-01-06","IGN","Saint-Mandé","Etude contrastive de corpus de cours de cartographie           
http://recherche.ign.fr/labos/cogit/

Mots-clés

TALN, fouille de textes, extraction d'informations, cartographie,
sémiologie graphique

 

Contexte

Le laboratoire COGIT travaille à un projet de conception de carte sur
mesure, c'est-à-dire une carte pertinente et efficace par rapport aux
besoins et objectifs du concepteur.

Un des axes de recherche vise à constituer une base de connaissances
(en particulier une ontologie des termes de la conception d'une
légende et une base de règles qui s'appuie sur cette ontologie) qui
permettra d'exploiter la description que l'utilisateur fait de son
besoin pour l'aider à concevoir sa carte dans les règles de l'art.

La construction d'un système graphique cohérent de signes est régie
par les règles de la sémiologie graphique. L'enseignement de la
cartographie est fondé sur la sémiologie graphique mais les manuels et
les enseignements de cartographie se spécialisent généralement sur un
certain type de carte.

Dans ce contexte, nous souhaitons analyser, pour les intégrer, les
principes de représentation cartographique tels qu'ils sont enseignés
dans différentes formations. Nous souhaitons en déduire un ensemble
cohérent de règles de représentation cartographique pour répondre au
besoin de tout utilisateur.

 

Sujet

Le stage a pour objectif de comparer les règles de représentation des
informations en réalisant une étude contrastive de deux corpus. L'un
est la version électronique du manuel de cartographie utilisé à l'ENSG
qui détaille particulièrement la fabrication de cartes topographiques
; l'autre est l'ensemble des notes de cours (version électronique)
d'un enseignement en cartographie de l'université, ciblé sur les
cartes thématiques.

Nous nous intéressons aux modes opératoires de construction de la
carte, l'ordre des étapes, les concepts (en relation avec notre
ontologie) sur lesquels s'appuient ces modes opératoires et leurs
articulations, les principes de représentation (en relation avec notre
base de règles).

Par cette comparaison, nous souhaitons analyser la complémentarité de
ces approches et les intégrer dans notre base de connaissances. Cette
étude devra aussi permettre de caractériser une carte topographique et
une carte thématique réussies.

Cette étude contrastive utilisera des outils de traitement automatique
du langage naturel (TALN).

 

Compétences particulières et formation requise

master (de préférence M2) avec compétences en TALN, informatique,
éventuellement en cartographie.

Une bonne maîtrise de la langue française est indispensable.

 

Lieu du stage

Institut géographique national

2 avenue Pasteur

94160 Saint-Mandé

 

Durée et rémunération 

durée : 4 à 5 mois

début : mars/avril 2009

rémunération : 30% du SMIC

 

Prolongements éventuels

Le COGIT propose chaque année des sujets de thèse ainsi que des stages
de post-doctorant.

 

Responsable de stage

Catherine DOMINGUES

mel : catherine.domingues@ign.fr

Tél : 01 43 98 85 44"
"16","2009-01-13","LIMSI","Orsay","Le groupe Traitement du Langage Parlé
(http://www.limsi.fr/tlp/index.html) du LIMSI-CNRS propose plusieurs
stages de master recherche, professionel, ou ingénieurs. Vous
trouverez les descriptifs de ces propositions à l'adresse suivante :

http://www.limsi.fr/tlp/stages/index.html.

N'hésitez pas à faire circuler cette information et à nous contacter
par mail pour des informations complémentaires. Les personnes
intéressées par l'une ou l'autre de ces propositions sont invitées à
contacter les responsables (de préférence par courrier électronique)
en joignant un CV et en précisant le ou les sujets concernés.


Description des activités du groupes :

Les recherches du groupe Traitement du Langage Parlé du LIMSI-CNRS ont
pour principaux objectifs de modéliser la parole et concevoir des
algorithmes pour son traitement automatique. Les activités du groupe
sont par essence pluridisciplinaires, elles abordent le traitement de
la parole d'un point de vue acoustique, phonétique, linguistique et
informatique. Elles s'intéressent également au lien entre parole et
sens, ainsi que la modélisation des processus de communication orale.

Le besoin de confronter nos modèles aux données nous amène à
développer des systèmes de traitement du langage parlé assurant des
fonctions variées telles que la reconnaissance de la parole,
l'identification de la langue, du locuteur et de son état émotionnel,
le dialogue oral homme-machine, la structuration de documents
audiovisuels, et plus récemment la traduction de la parole."
"17","2009-01-16","Temis","Paris","*Sujet du stage : * CRFs pour l'extraction d'entités/relations dans
des textes

*Lieu :* société Temis, Paris et Lifo (Laboratoire d'Informatique
Fondamentale d'Orléans)

*A destination de :* étudiants en M2 recherche informatique ou TALN,
intéressés par l'apprentissage automatique et/ou le traitement
automatique du langage

*Stage rémunéré pouvant donner lieu à une bourse de thèse Cifre*

La société Temis édite une solution logicielle pour traiter les
documents textuels. Elle est capable de les classer suivant leur
langue ou leur domaine, d'en extraire les « entités » importantes et
de caractériser les relations prédicatives qu'entretiennent ces
entités entre elles.

Le module d'extraction est réalisé à l'aide de règles écrites à la
main.  Ces règles sont spécifiques de la langue des documents et du
domaine sur lequel ils portent, elles peuvent donc être longues et
fastidieuses à écrire. Or, des techniques d'apprentissage automatique
existent depuis quelques années pour apprendre à extraire de
l'information à partir d'exemples (ce sujet a par exemple donné lieu à
la « shared task » de CoNLL 2003, 17 compétiteurs y ont
participé). Plusieurs approches différentes possibles peuvent être
mises en oeuvre pour cela : celles qui donnent actuellement les
meilleurs résultats sont fondées sur les CRFs (Conditional Random
Fields), un modèle statistique permettant d'annoter des items lexicaux
avec des labels qui désignent les zones à extraire.

L'objectif de ce stage est de tester cette méthode sur un corpus de
documents. Différentes étapes seront donc nécessaires :

- Il faudra dans un premier temps constituer un corpus d'exemples et
  l'annoter pour servir de base à l'apprentissage automatique. L'outil
  final de Temis peut servir à réaliser cette base, mais comme il ne
  produit pas une extraction parfaite, des stratégies d'amélioration
  de l'annotation initiale devront être envisagées.

- Il s'agira ensuite de fixer les paramètres de l'apprentissage. Les
  CRFs requièrent notamment la définition d'un ensemble de « fonctions
  features » qui caractérisent des configurations locales
  d'annotations..  La définitions de ces features est laissée à
  l'initiative du programmeurs, mais des méthodes classiques existent
  pour les générer à partir des données annotées. Or Temis dispose
  aussi de ressources linguistiques sous la forme de dictionnaires ou
  de règles écrites à la main. Le coeur du stage sera d'étudier dans
  quelle mesure ces ressources peuvent être traduites sous la forme de
  features, de façon aussi automatique que possible.

- Il faudra ensuite procéder à diverses expériences pour évaluer la
  qualité de l'extraction obtenue par apprentissage automatique, et la
  comparer avec celle obtenue par les règles écrites à la main. Cette
  qualité peut dépendre grandement de la langue et du domaine du
  document, ainsi que de l'ensemble des features utilisées pour
  l'apprentissage.

- Ce qui est attendu à l'issue de ce stage est la définition d'une
  chaîne de traitements mèlant production manuelle de ressources et
  apprentissage automatique, qui optimise la qualité de l'extraction
  finale.

*Ref bibliographiques :*

Daelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.
Jousse F., Tellier I., Tommasi M., Marty P. : « Learning to Extract
Answers in Question Answering: Experimental Studies », Coria 2005,
p85-99.
Lafferty J., McCallum A., Pereira F. : « Conditional Random Fields:
Probabilistic Models for Segmenting and Labeling Sequence Data »,
actes de ICML, pages 282-289, 2001.
Poibeau, T : Extraction Automatique d’Information, Hermes, Paris,
2003.
Sutton , McCallum A : « An Introduction to Conditional Random Fields »
dans « Introduction to Statistical Learning », MIT Press, 2006.

*Encadrement universitaire :* Isabelle Tellier, professeur à
l'université d'Orléans"
"18","2009-01-21","Syllabs","Paris","CONTEXTE
--------

Outil d’aide aux linguistes pour le développement de ressources
linguistiques.

SUJET DE STAGE
---------------

Conception et implémentation d’un agent intelligent dédié à
l’aspiration de contenu textuel du web, destiné à alimenter les
ressources linguistiques multilingues existantes.

OBJECTIFS DU STAGE
-------------------

La personne recrutée pour ce stage aura comme tâche principale la
conception et le développement d’un agent intelligent dédié à
l’aspiration de contenu textuel du web. Cet agent se situe dans un
contexte plus large au sein de la société Syllabs, qui est celui de
mise en place d’outils d’aide aux linguistes pour le développement et
maintenance de ressources linguistiques multilingues. L’un des aspects
clés des applications en Traitement Automatique de Langues est lié à
la qualité de ressources linguistiques sur lesquelles celles-ci
s’appuient. A priori les ressources sont toujours perfectibles, mais
son enrichissement et raffinement est un processus coûteux et parfois
assez fastidieux pour les linguistes. Dans le scénario d’utilisation
prévu, pour une ressource déterminée, un linguiste définit l’ensemble
de critères d’enrichissement de la ressource. L’agent interprète cette
spécification, dont le formalisme est à définir, et établit des
stratégies d’aspiration appropriées. Un mécanisme d’apprentissage fait
évoluer ces stratégies suivant deux paramètres : les résultats
d’aspiration et l’exploitation réalisée par les linguistes du contenu
aspiré.

Le stage nécessite une aisance avec les agents intelligents aussi bien
qu’une connaissance de divers outils de TAL (détecteurs de langue,
détecteurs d’encodage, KWIC, POS guessers, etc.). En même temps, un
soin particulier doit être accordé aux aspects techniques de l’agent,
comme la répartition de la charge de travail sur plusieurs machines et
le stockage du contenu textuel avec une accessibilité par langue, par
ressource, par utilisateur, entre autres. La personne travaillera avec
des informaticiens et des linguistes.

CONNAISSANCES ET NIVEAU SOUHAITÉS
-----------------------------------

- Ingénierie Informatique, Bac+5 - Master 2
- Connaissances des concepts liés aux agents intelligents ; goût pour
  la modélisation de connaissances
- Bonne maîtrise du langage Java et d’un langage de script
- Bonnes connaissances dans les domaines du Traitement Automatique des
  Langues

Eléments facultatifs mais considérés comme un plus :

- Maîtrise d'une ou plusieurs langues étrangères
- Connaissance d’Apache Tomcat et des services web (WSDL, XML, etc.)

DURÉE : 6 mois

LA SOCIÉTE
-----------

Syllabs est un jeune laboratoire de recherche privé spécialisé dans
les domaines de la Gestion de l'Information et du Traitement
Automatique des Langues. Syllabs est au coeur de trois activités
complémentaires : La Recherche, les Développements Innovants et le
Conseil.
Nous sommes situés dans le 13ème arrondissement de Paris.

Pour plus d'informations nous vous invitons à visiter notre site
www.syllabs.com

DOSSIER DE CANDIDATURE :
-------------------------

Merci de nous faire parvenir votre dossier de candidature à l'adresse
suivante : jobs@syllabs.com 
-	Lettre de motivation
-	CV

-------------------------------------------------------------------------"
"19","2009-01-23","LIMSI","Orsay","Le groupe ILES (anciennement groupes LIR et Geste) du LIMSI-CNRS
propose des stages pour différents niveaux d'études dans les
thématiques suivantes:

- Traitement des Langues Signées
- Recherche d'Information et Question-Réponse
- Constitution de Ressources pour le TAL
- Evaluation pour le TAL
- Analyse de Texte et Traduction Automatique

La description des différentes propositions se trouve sur la page
suivante:

http://www.limsi.fr/Scientifique/lir/stages

Les candidats devront contacter directement les responsables du/des
stages, en joignant un descriptif de leur parcours sous forme d'un
court CV et en précisant leur motivation pour les stages concernés.

Page du groupe (anciennement groupe 'LIR'):
http://www.limsi.fr/Scientifique/lir/
Page du laboratoire: http://www.limsi.fr"
"20","2009-01-23","Arisem","Massy","Arisem propose cette année six stages de niveau master :


- Enrichissement des ressources linguistiques pour l'extraction
  d'information en Néerlandais

- Analyse des opinions et sentiments

- Exploitation des « Linked Data »

- Développement d'une plateforme de démonstration des composants de
  Text Mining

- Développement d'un environnement de production de ressources
  linguistiques sous Eclipse RCP

- Evaluation de la qualité des Ressources Linguistiques

Les détails de chacun de ces stages sont disponibles sur la page
http://www.arisem.com/index.php?page=emploi

Les candidatures peuvent être directement adressées à :
nicolas.dessaigne@arisem.com
aurelie.migeotte@arisem.com"
"21","2009-01-23","INSERM","Paris","Proposition de stage M2 

LOCALISATION  DE  TERMINOLOGIES

Natalia Grabar (natalia.grabar@spim.jussieu.fr)

Centre de Recherche des Cordeliers ; U Paris Descartes, UMR_S 872 ; INSERM,
U872 eq 20 ; HEGP AP-HP


CONTEXTE. L'implémentation d'outils informatiques (p. ex., pour
encodage, archivage ou recherche de documents) nécessite souvent
l'utilisation de terminologies représentant la connaissance du
domaine. Dans certains domaines (p. ex., droit, médecine, biologie,
électricité, téléphonie), il existe déjà des terminologies mais, pour
leur meilleure utilisation, elles doivent être adaptées au contexte de
leur exploitation. Au moins deux objectifs peuvent alors être
poursuivis : (1) leur adaptation à l'application et (2) leur
adaptation au domaine, plus ciblé et précis que ne le serait une
terminologie généraliste. Le travail sera effectué dans le domaine de
médecine.


OBJECTIFS. L'objectif du stage consiste à implémenter et tester des
méthodologies qui permettent d'adapter les terminologies existantes,
entre autres au travers des corpus, à une question médicale
précise. L'application visée concerne le filtrage et la sélection
d'articles scientifiques. Le matériel principal de travail sont des
mots-clés centraux pour une question, par exemple : ""colorectal
neoplasms"" ; ""liver neoplasms"" ; ""laparoscopy"" ; ""tomography,
emission-computed"" ; ""magnetic resonance imaging"" ; ""tomography, x-ray
computed"" pour la question ""diagnostic de métastases hépatiques du
cancer colorectal"". Ce matériel servira d'amorce pour la constitution
de corpus (articles scientifiques) et de points d'entrée dans les
terminologies (p.ex. l'UMLS (NLM, 2007) qui propose plus de 140
terminologies biomédicales).

Le stagiaire s'intéressera à : 
- navigation et manipulation des arbres 
- outils d'acquisition (Bourigault & Jacquemin, 2000) 
- outils de structuration (Grabar & Hamon, 2004) des terminologies. 

Le développement en Perl sera demandé lors des différentes étapes du
travail.

DÉROULEMENT DU STAGE. Le stage sera encadré par un chercheur en
informatique biomédicale et en TAL, et co-encadré par un médecin. Il
s'agit d'un stage de 6 mois rémunéré.  Le stage se déroulera dans
l'équipe Inserm du Centre de Recherche de Cordeliers (Paris 06).

Le CV et une lettre de motivation sont à envoyer à Natalia Grabar.


Références

BOURIGAULT, D. & JACQUEMIN, C. (2000). Construction de ressources
terminologiques, In J.-M. PIERREL, Ed., Industrie des langues, pp.
215-233.

GRABAR, N. & HAMON, T. (2004). Les relations dans les terminologies
structurées : de la théorie à la pratique. Revue d'Intelligence
Artificielle (RIA), 18(1).

NLM (2007). UMLS Knowledge Sources Manual. National Library of
Medicine, Bethesda, Maryland. www.nlm.nih.gov/research/umls/."
"22","2009-01-28","INSERM","Paris","Proposition de stage de master 2

SERVICE WEB : FILTRAGE DE LA LITTÉRATURE SCIENTIFIQUE

Natalia Grabar (natalia.grabar@spim.jussieu.fr), Isabelle Colombet
(isabelle.colombet@spim.jussieu.fr)

UMR 872 EQ 20, Centre des Cordeliers ; HEGP/AP-HP


CONTEXTE. 
Cette proposition de stage s'inscrit dans le paradigme de la médecine
fondée sur les preuves (EBM). EBM consiste à fonder les décisions
médicales sur des preuves scientifiques authentifiées. Le niveau de
preuve est établi grâce aux revues systématiques de la littérature
biomédicale. Ces revues sont extrêmement lourdes à mettre en place et
à réaliser du fait du volume important de la littératude à analyser et
filtrer. Une aide automatique à la réalisation de revues systématiques
s'avère nécessaire.


OBJECTIFS DU STAGE. 
Une des étapes des revues systématiques, qui correspond à l'examen
sélectif des publications, est l'étape clé. En effet, l'oubli de
certaines études peut aboutir à des résultats biaisés et à des niveaux
de preuve insuffisants.  L'objectif de ce stage est de répondre à ce
besoin car très peu est fait pour assister les revues. Afin de
faciliter le processus de sélection d'articles, nous proposons
d'utiliser les méthodes d'analyse textuelle et sémantique au travers
un service Web dédié.
Le stagiaire aura pour objectif d'implémenter une première version de
ce service Web, selon les spécifications fournies.

Il devra en particulier : 
- compiler une liste unique de références bibliographiques provenant
  de différentes bases,
- collecter et intégrer les résumés des articles scientifiques à
  analyser [1]
- intégrer les connaissances du domaine [2] dans le processus de tri
  et de filtrage des résumés


DÉROULEMENT DU STAGE. 
Le stage sera encadré par un chercheur en informatique biomédicale et
en TAL, et co-encadré par un médecin. 
Il s'agit d'un stage de 6 mois rémunéré. 
Le stage se déroulera dans l'équipe Inserm du Centre de Recherche de
Cordeliers (Paris 06).

Le CV et une lettre de motivation sont à envoyer à Natalia Grabar.


RÉFÉRENCES

[1] NLM . Medline : medical literature on-line. National Library of
Medicine, Bethesda, Maryland, 2008. www.ncbi.nlm.nih.gov/sites/entrez.
[2] NLM . UMLS Knowledge Sources Manual. National Library of Medicine,
Bethesda, Maryland, 2007. www.nlm.nih.gov/research/umls/."
"23","2009-01-28","LINA","Nantes","Proposition de stage (niveau M1)

Sujet :

De nombreuses langues écrites disposent de ressources lexicales sous
forme de dictionnaires éditoriaux. Ces dictionnaires existent aussi
sous une forme électronique puisqu’ils ont été édités sur des outils
de traitements de texte.  Mais ces fichiers ne peuvent être utilisés
directement par des programmes de Traitement Automatique des Langues
Naturelles car ils ne respectent aucun format spécifique.

Il est possible d’écrire un programme qui soit capable de localiser
les informations à récupérer dans les dictionnaires et qui les
représente dans une structure normalisée, mais cette démarche présente
l’inconvénient de nécessiter l’écriture d’un programme, ou la
spécification de règles complexes, pour chaque dictionnaire.

Le but de ce stage est de s’affranchir de cette difficulté en
construisant un programme qui, après apprentissage, est capable de
convertir un dictionnaire éditorial en un fichier XML.

La phase d’apprentissage exploite une partie de dictionnaire
disponible sous sa forme éditoriale (les données de départ) et sous la
forme structurée au format XML.

Le convertisseur utilise les connaissances précédemment apprises pour
convertir le reste du dictionnaire. Il doit être capable de signaler
les parties du dictionnaire qu’il n’a pas été capable de convertir et
qui seront traitées ultérieurement par un linguiste.

Salaire mensuel : 530 euros bruts / 396 euros net

Durée : 3 mois, courant 2009

Lieu : Laboratoire d’informatique Nantes Atlantique (UMR CNRS 6241)

Encadrement : Chantal Enguehard, maître de conférences en
informatique, équipe Langage Naturel

Postuler : Envoyer un CV, relevé de notes et une lettre de motivation
à Chantal Enguehard, chantal.enguehard@univ-nantes.fr.


Chantal Enguehard

LINA - UMR CNRS 6241
2, rue de la Houssinière
BP 92208
44322 Nantes Cedex 03
France
http://www.sciences.univ-nantes.fr/info/perso/permanents/enguehard/"
"24","2009-02-04","CEA","Fontenay-aux-Roses","Proposition de stage de master 2 

Extraction d'information non supervisée

Olivier Ferret (ferreto__zoe.cea.fr) et Romaric Besançon
(besanconr__zoe.cea.fr)

CEA LIST/LIC2M, Fontenay-aux-Roses

CONTEXTE 
L'extraction d'information à partir de textes consiste classiquement à
repérer dans les textes des événements d'un type prédéfini ainsi qu'un
ensemble donné d'informations prenant généralement la forme d'entités
nommées et venant s'insérer dans une description a priori de ce type
d'événements appelée template. Pour un événement comme le rachat d'une
société par une autre, l'extraction se focalisera ainsi sur
l'identification de la société acheteuse, de la société achetée, du
montant du rachat et de sa date. Cette approche peut être qualifiée
globalement de dirigée par les buts ou de descendante. Plus récemment,
une approche inverse a fait son apparition, approche que nous
qualifierons ici d'extraction d'information non supervisée (Rosenfeld
et Feldman, 2007 ; Hasegawa et al., 2006 ; Shinyama et Sekine,
2006). Cette approche prend comme point de départ des entités ou des
types d'entités et se fixe comme objectif de mettre en évidence les
relations intervenant entre ces entités puis de regrouper ces
relations en fonction de leurs similarités sémantiques ou
thématiques. Une telle approche s'incarne typiquement dans une
problématique de veille telle que « suivre tous les événements faisant
intervenir les sociétés IBM et Sony », qui conduit par exemple à
extraire les « événements » suivants :

-------------------------------------------------
IBM, Sony et Philips s'allient à Redhat et Novell pour protéger Linux.

IBM, Philips, Sony, Red hat et Suse créent un fonds de brevets pour
protéger Linux
-------------------------------------------------
IBM, Sony et Toshiba présente le processeur Cell.

IBM, Sony et Toshiba veulent imposer le processeur Cell.

Sony, Toshiba et IBM, développeurs du processeur Cell (""cellule"" en
anglais), viennent de dévoiler de nouvelles données techniques sur
leur composant.
-------------------------------------------------
IBM, Sony et Nokia s'associent pour le développement durable.

IBM, Sony et Nokia cèdent des brevets « écologiques ».

IBM, Sony, Nokia et Pintey-Bowes ont lancé le 14 janvier la plateforme
Eco-Patent Commons (EPEC) qui donne librement au public une trentaine
de brevets visant à résoudre les problèmes environnementaux des
entreprises.
-------------------------------------------------

et à les regrouper en trois grandes catégories, faisant référence à
trois contextes différents.


OBJECTIFS DU STAGE
Le laboratoire LIC2M du CEA LIST dispose d'une plate-forme modulaire
de traitement des langues permettant de réaliser une analyse
linguistique d'un texte allant jusqu'au niveau syntaxique et intégrant
certaines analyses sémantiques et discursives. Cette plate-forme
inclut également des outils plus spécifiquement liés à l'extraction
d'information comme un module de reconnaissance d'entités
nommées. L'objectif du stage est de concevoir et de développer à
partir de cette plate-forme un système complet d'extraction
d'information non supervisée. Plus précisément, ce développement passe
par la proposition et l'implémentation de solutions pour les trois
sous-problèmes suivants :

  - l'extraction proprement dite de relations en se focalisant, à
    partir du résultat d'une analyse syntaxique des phrases, sur
    l'identification des prédicats intervenant entre les entités
    ciblées et des relations unissant ces prédicats aux entités ;
  - l'appariement des relations extraites pour regrouper les relations
    équivalentes à un niveau sémantique ;
  - le regroupement des relations relatives à un même événement ou à
    la même sous-thématique.

Compte tenu de l'importance de ces problèmes, en particulier des deux
derniers, une approche en deux temps est envisagée. Le premier temps
consistera à s'inspirer des travaux existants, notamment (Rosenfeld et
Feldman, 2007 ; Hasegawa et al., 2006 ; Shinyama et Sekine, 2006),
afin de mettre en oeuvre une première solution pour ces trois
sous-problèmes. Le second temps se focalisera sur les problèmes
d'appariement de relations, soit au niveau sémantique, soit au niveau
thématique, pour proposer des solutions plus originales.

Ce stage est conçu dans la perspective d'une thèse sur le même sujet
pour laquelle un financement CEA a été demandé (la possibilité
d'obtenir un financement de thèse dépend de la valeur du candidat et
d'arbitrages internes au CEA). Seront donc privilégiés les candidats
ayant comme perspective un projet de thèse.


BIBLIOGRAPHIE
Hasegawa, T.; Sekine, S. & Grishman, R. (2004) Discovering Relations
among Named Entities from Large Corpora, 42nd Meeting of the
Association for Computational Linguistics (ACL'04), pp. 415-422.

Rosenfeld, B. & Feldman, R. (2007) Clustering for unsupervised
relation identification, Sixteenth ACM conference on Conference on
information and knowledge management (CIKM'07), ACM, New York, NY,
USA, pp. 411-418.

Shinyama, Y. & Sekine, S. (2006) Preemptive Information Extraction
using Unrestricted Relation Discovery, 'Human Language Technology
Conference of the NAACL, Association for Computational Linguistics,
New York City, USA, pp. 304-311.


COMPÉTENCES REQUISES
   - niveau M2 (ou ingénieur) en Informatique avec une spécialisation
     en Traitement Automatique des Langues
   - langage C++ ainsi qu'un langage de script de type Perl ou Python

MODALITÉS
Le stage sera rémunéré et se déroulera pour une durée de 6 mois au 
sein du Laboratoire d'Ingénierie de la Connaissance Multimédia 
Multilingue (LIC2M) du CEA LIST, situé sur le centre CEA de 
Fontenay-aux-Roses (92).

Les candidats intéressés par ce stage sont invités à prendre contact
avec Olivier Ferret ou Romaric Besançon en envoyant un CV et une 
lettre de motivation.


Ce stage est également référencé au niveau du site Web du CEA à
l'adresse :
http://www.cea.fr/ressources_humaines/stages_longue_duree/extraction_d_information_non_supervisee"
"25","2009-02-16","LIPN","Villetaneuse","PROPOSITION DE STAGE DE MASTER 2 :

Langage pseudo naturel comportant des expressions spatiales (et/ou
temporelles) pour un dialogue homme-machine multimodal

Contexte

Il existe aujourd’hui des logiciels permettant de produire rapidement
la maquette d’une interface graphique. Ces logiciels permettent de
créer des menus, des icônes, des boîtes de dialogue, etc., et ils
génèrent le code de programme correspondant de manière automatique. Le
concepteur ne s’occupe plus d’écrire le code, mais interagit avec la
souris et le clavier pour placer et/ou spécifier les objets de
l'interface directement sur l’écran. Ce haut niveau de spécification
constitue un progrès important par rapport à la programmation
traditionnelle, mais ce type d’interaction est encore relativement
lourd, et en réalité moins performant que ne pourrait l'être une
interaction de type dialogue, effectuée dans un langage proche du
langage naturel.

Objectifs
Les objectifs de ce stage sont : d’une part, la définition d’un pseudo
langage naturel (i.e. un fragment du langage naturel) permettant de
spécifier rapidement des objets et leur disposition sur une interface,
afin de dialoguer avec un logiciel de maquettage qui produit et
corrige l’état d'une maquette existante.  D’autre part, la
spécification d’une architecture hybride permettant d’établir un
dialogue multimodal (au moyen de phrases dans le langage précédent, de
l’écran et de la souris) entre le concepteur de l’interface et le
logiciel de conception. Ainsi, une description comme ""Je veux une
barre de menu en haut d'une fenêtre contenant les termes File, Edit,
Format, Font et Window"" devrait permettre d'engendrer automatiquement
le code de création de tous les objets nécessaires à l’affichage d'une
telle barre de menu (en Java par exemple).  Bien que la visée soit
applicative, le stage consistera principalement en une étude
bibliographique destinée à identifier des problèmes linguistiques liés
à l’utilisation d’expressions spatiales (et/ou temporelles)
relativement à ce contexte dialogique. Il faudra établir la liste des
termes (verbes, prépositions, etc.) devant nécessairement faire partie
du langage, et la liste des problèmes soulevés par l'emploi de ces
termes (ou l’interprétation des phrases) dans le contexte prévu. Le
livre de Frédéric Landragin indiqué en bibliographie pourra servir de
base à cette réflexion. L'étude devra donner lieu à un rapport final
établissant clairement la nature du dialogue finalement envisagé, et
devra en fixer les limites en spécifiant au maximum l’architecture du
logiciel de conception (éventuellement en UML).  Pour simplifier le
travail concernant le volet architectural, l’étudiant(e) pourra
travailler dans un contexte applicatif simplifié : celui d’un monde
d’objets réduits (de taille et couleur variables par exemple), qu’il
s’agirait simplement de placer sur l’écran via un dialogue en pseudo
langage naturel.

Bibliographie

Herskovits A., 1986, Language and spatial cognition : an
interdisciplinary study of the prepositions in English, Studies in
Natural Language Processing, Cambridge, Cambridge Univ. Press.
Landragin F., 2004, Dialogue homme-machine multimodal, publications
Hermès Science, Lavoisier.
Vandeloise C., 1986, L'espace en français : sémantique des
prépositions spatiales, Travaux en linguistique, Paris, Editions du
Seuil.
Vandeloise C., 2001, Aristote et le lexique de l’espace – rencontres
entre la physique grecque et la linguistique cognitive, Editions CSLI,
collection Langage et Esprit, Université de Stanford, Stanford.

Profil souhaité
- Intérêt pour la linguistique et pour le TAL. Compétences dans ces
  domaines.
- Autonome en informatique : connaissance d'UNIX et de Java Swing (ou
  sinon de Motif et C).

Conditions
Stage de 6 mois rémunéré par le LIPN (sous réserve de l'approbation
par le conseil de laboratoire).

Responsable
Catherine Recanati (email : catherine.recanati at gmail.com ; tel :  
01 49 40 28 47)

---------"
"26","2009-02-16","LIPN","Villetaneuse","Extraction d'information dans les dossiers patients

Responsable

  Thierry Hamon, 
  thierry.hamon@lipn.univ-paris13.fr
  Tel : 01 49 40 28 32

Contexte

Les dossiers patients (comptes-rendus d'hospitalisation, résumés
d'examens, etc.) sont une source importante d'information sur les
paramètres en jeu lors des soins apportés aux malades. La médecine
translationnelle a pour objectif d'exploiter ces documents afin d'en
faire bénéficier la recherche biomédicale pour créer ou tester des
médicaments, mais aussi pour améliorer la qualité des soins médicaux
individuels.

Si les données structurées associées au patient constituent des
informations cruciales, la fouille des comptes rendus écrits en texte
libre reste inévitable. Le texte libre contient par exemple les
facteurs de risque (par exemple l'âge, le fait de fumer, etc.),
l'histoire du patient, les prescriptions (médicaments prescrits et
doses utilisées), l'environnement du patient, les co-morbidités ou les
diagnostics principaux et secondaires [Chapman et al. 2007, Crammer et
al. 2007].

Objectifs


L'objectif du stage est d'extraire automatiquement des comptes rendus
médicaux, les informations relatives aux patients (les informations
personnelles - âge, sexe, etc., l'histoire du patient, les
perscriptions, les facteurs de risque, etc.). Il s'agira de développer
ou de réutiliser des approches de traitement automatique des langues
(identification d'entités nommées, extraction et/ou identification de
termes, variation sémantique, ...) pour annoter les documents, puis de
mettre en place des approches de fouille de texte pour en extraire les
informations pertinentes.

L'évalution sera réalisée sur des données textuelles dé-identifiées
issues d'un hôpital. Les documents seront en anglais ou en français.


Profil recherché

- Intérêt pour le TAL (notamment la connaissance d'outils
  terminologiques, ou une sensibilisation à leur utilisation)

- Autonomie en informatique : connaissance d'UNIX, de Perl

Des connaissances en médecine sont un plus.


Conditions

  Stage de 6 mois rémunéré

  Début du stage : mars 2009


Références

  [Chapman et al. 2007] Chapman (Wendy), Dowling (John) et Chu
  (David).  ConText : An Algorithm for Identifying Contextual Features
  from Clinical Text. In : Biological, translational, and clinical
  language processing. pp. 81-88. Prague, Czech Republic, June 2007.

  [Crammer et al. 2007] Crammer (Koby), Dredze (Mark), Ganchev
  (Kuzman), Pratim Talukdar (Partha) et Carroll (Steven). Automatic
  Code Assignment to Medical Text. In : Biological, translational, and
  clinical language processing. pp. 129-136. Prague, Czech Republic,
  June 2007."
"27","2009-02-24","Orange Labs","Lannion","France Telecom /Orange Labs Lannion/TECH/EASY/LN	

Intitulé du Stage 
Extraction d'informations structurées dans des documents.
	

Mission:
L'équipe Langues Naturelles de France Télécom R&D dispose d'outils de
traitement automatique des textes. Le travail proposé  consistera à
utiliser nos outils de Traitement Automatique de la Langue Naturelle
ainsi que des outils standards d'analyse de grammaires régulières
(regexp, automates> ...> ) pour analyser des corpus de documents et en
extraire les informations structurées.  Les données récupérées seront
ensuite utilisées pour des applications liées aux objectifs d'Orange
Labs en traitement d'information,  dans le cadre d'un projet du
traitement des contenus multimédia.
	

Profil:
Bac + 5 en informatique ou Bac + 5 en TALN avec une forte compéte
nce en informatique	

Compétences
Connaissance d'un langage orienté objet 
Connaissance de langages de scripts (shell, python,> ...> )
Connaissance utilisateur de SQL
Sensibilisation ou intérêt pour le TALN et des formalismes de type RDF
Bonnes capacités d'analyse	

Modalités 
Site de France Telecom Recherche et Développement de Lannion (22)
5 mois à partir de mars ou avril 2009 
Stage indemnisé sur la base de 5 mois	

Le plus de l'offre
Les équipes de France Telecom R&D travaillent à la fois sur des
problématiques de recherche très en amont, et sur l'industrialisation
de solutions standard pour réaliser des services en Langage
Naturel. La mission se déroule dans une équipe pluridisciplinaire
composée de linguistes et d'informaticiens, autour de la technologie
TiLT de traitement des langues, disposant de nombreuses ressources
linguistiques et de fonctionnalités logicielles puissantes.

Contacts 

Olivier Collin  
- 02 96 05 26 10 
- olivier.collin@orange-ftgroup.com"
"28","2009-03-02","Memodata","Caen","Intitulé du stage : Révision de traductions
Lexique multilingue à base de concepts.

Mission:
Le Dictionnaire Intégral est fondé sur un jeu d'environ 45.000
concepts dont le libellé ne sert qu'à la lecture par un humain
(identification des contenus et comportements sous-jacents).
Ces concepts entretiennent entre eux des relations (parmi 200
relations) afin de décrire par approximation les sens des mots d'une
langue. Ils décrivent ainsi pour le français environ 200.000
mots-sens, pour l'anglais 160.000 mot-sens, pour l'allemand 75.000
mots-sens, pour l'arabe 80.000 mots-sens, pour le japonais 72.000
mots-sens etc.
Ces concepts enveloppent les synsets de wordnet comme d'autres
hyperstructures le font, par exemple comme Sumo (Suggested Upper
Merged Ontology).

Au fil des 20 dernières années, ces concepts nativement rédigés en
français, ont été traduits en anglais et en d'autres langues pour en
permettre la lecture par des locuteurs non francophones. Mais ces
traductions ont été réalisées au hasard, sans prise en considération
réelle du besoin.  Le stage consiste à reprendre ces concepts en
français et leur traduction et à en améliorer la traduction afin de la
rendre publiable.

Le stage est donc un stage de lexicologie multilingue appliquée à un
cadre quasi-terminologique dans lequel la terminologie est constituée
par le réseau de concepts lui-même.

Le stage s'adresse à des étudiants lisant très bien le français et
maîtrisant au moins une autre langue.

Plusieurs stages pourront être organisés:
- vers l'anglais
- vers l'allemand
- vers le portugais
- vers l'italien
- vers l'arabe
- vers le chinois
- vers l'hindi
- vers le vietanmien
- vers le persan

Mais d'autres propositions pourront retenir notre attention.
La durée des stages peut varier en fonction des impératifs d'étude de
l'étudiant.

Le stage est particulièrement indiqué à des étudiants qui souhaitent
élargir leur vocabulaire en français.

Contacts 

Contact
- 02 31 35 75 21
- Dominique Dutoit
- d.dutoit@sensagent.com ou d.dutoit@memodata.com

Mot clé : lexicologie multilingue, ontologie, réseaux sémantiques


Dominique Dutoit
MEMODATA
02 31 35 75 21
www.sensagent.com"
"29","2009-03-02","France Telecom R&D","Lannion","Stage fin d'études chez France Télécom : ""Titrage à partir des abrégés
automatiques""

Mission : 
L'équipe Langues Naturelles de France Télécom R&D dispose d'un outil
afin d'abréger automatiquement des textes. Dans le cadre d'un projet
du traitement des contenus multimédia nous envisageons d'utiliser des
abrégés très courts des textes courts et mono-thématiques (souvent
issus de la transcription automatique, donc contenant des erreurs)
afin de générer un titre car souvent les abrégés sont trop longs et
trop tirés du contexte pour être utilisés directement comme titre. Il
faut donc en extraire des syntagmes (par ex. groupes nominaux, entités
nommées) qui pourraient servir comme titre. La mission consistera à
travailler sur l'analyse des textes et leurs abrégés afin de voir
quels syntagmes pourraient pris comme titre :

* Faire les abrégés sur un corpus moyen des textes (configuration
  adaptée des outils)

* Analyse syntaxique des abrégés (et les mots-clés) pour pourvoir
  généraliser une règle qui permet d'en extraire un titre : groupes
  nominaux, entités nommées, ...

* Investiguer d'autres approches afin d'extraire des groupes nominaux
  des textes afin de générer un titre (par ex. en utilisant les
  mots-clés identifiés par l'abrégeur ou par le découpeur thématique

* Évaluation avec des titres créés manuellement sur un (autre) corpus

Profil : 
Bac +5 (master pro ou recherche)
Spécialisation du traitement automatique des langues

Compétences :
Bonnes connaissances en linguistique, plus particulièrement en syntaxe
(connaissances en sémantiques seront en plus) Connaissance de langages
de scripts (shell, python,...) Bonnes capacités d'analyse

Modalités (durée, période, localisation) :
Site de France Telecom Recherche et Développement de Lannion (22)
5 mois à partir de avril 2009

Contacts :
Johannes HEINECKE - 02 96 05 21 77 -
johannes(point)heinecke(arobase)orange-ftgroup(point)com"
"30","2009-03-18","Dédale","Paris","ASSISTANT INFORMATIQUE DOCUMENTAIRE (STAGE)

 

Présentation de Dédale

 

Dédale est une plateforme de recherche, de production et de diffusion
consacrée à l'art, à la culture et aux nouvelles technologies en
Europe.

 

Son projet s'articule autour des activités suivantes :

- le festival Emergences, rendez-vous international des nouvelles
  formes artistiques et des nouveaux médias à Paris (rencontres,
  spectacles, expositions, musiques électroniques),

- le d-lab, accompagnement de projets artistiques innovants et
  programme de résidences (axes de travail : arts de la scène et
  nouvelles technologies / art en réseau / art et technologies mobiles
  / territoires numériques / art et jeux vidéo),

- un observatoire européen des nouveaux médias et des nouvelles
  pratiques artistiques (rencontres, workshops et centre de
  ressources),

- l'assistance et le conseil aux institutions publiques et aux réseaux
  européens.

 

Dédale est soutenue par la Commission européenne, le Ministère de la
culture et de la communication, la Région Ile-de-France et la Ville de
Paris.

 

Activité européenne

 

Dédale dispose d'une expertise et d'un réseau de partenaires étendu en
Europe.

 

Elle intervient en assistance et conseil auprès d'institutions
publiques et de réseaux en France et à l'étranger dans des domaines
comme les technologies et les nouveaux usages, la création artistique
et multimédia, la numérisation du patrimoine culturel, ou encore les
nouveaux environnements d'apprentissage.

Elle réalise des études et développe des projets financés au titre de
plusieurs Directions (culture-IST) et programmes de la Commission
européenne : e-Ten, e-Content Plus, PCRD...

Au côté de la Mission de la recherche et de la technologie (Ministère
français de la culture et de la communication), elle participe au
projet de Bibliothèque numérique européenne et anime la participation
de la France aux projets européens de numérisation et de valorisation
du patrimoine.

 

 

Quelques références :

 

- ATHENA (2008-2010) / Projet réunissant 23 pays pour le développement
  de l'accès aux réseaux européens du patrimoine culturel en lien avec
  Europeana, la bibliothèque numérique européenne www.athenaeurope.org

 

- MICHAEL et MICHAELplus (2004-08) / Inventaire multilingue des
  collections numérisées des musées, des bibliothèques et des archives
  en Europe réunissant 18 pays.  www.michael-culture.org

 

- MINERVAeC (2007-08) / Réseau ministériel pour la valorisation des
  activités de numérisation réunissant 20 pays européens et 29
  partenaires associés. www.minervaeurope.org

 

- SmartCity | Nouveaux enjeux urbains et nouvelles pratiques
  artistiques en Europe (2008-09) / Programme de recherche et de
  co-production artistiques dans 11 villes européennes


Missions

 

Assister les chargés et chef de projet pour les aspects d'informatique
documentaire de projets culturels européens visant à valoriser le
patrimoine culturel ou à favoriser les échanges artistiques
internationaux par le biais des TIC.

 

    Suivi et gestion des projets existants dans leur volet technique

 

Création et gestion de langages documentaires et de référentiels
terminologiques, gestion et organisation des contenus et des
connaissances dans les bases de données et les sites web, conception,
réalisation et suivi des services documentaires...

 

Exploitation des technologies utilisées et suivi de leurs évolutions,
administration des systèmes d'informations existants, interventions de
premier niveau en installation et maintenance sur les matériels et
logiciels informatiques...

 

Préparation et rédaction des documents de travail et livrables,
échanges quotidiens avec les partenaires et notamment les
correspondants techniques, encadrement des prestataires techniques
éventuels, participation aux meetings et aux audits de projet par la
Commission européenne...

 

    Participation au développement de l'activité

 

Veille documentaire et scientifique sur les innovations technologiques
TIC, sur les terminologies, sur le multilinguisme...

 

Participation technique aux réponses aux appels à propositions et à la
mise en place de nouveaux projets

 

Compétences et qualités requises

 

- Troisième cycle en informatique documentaire apprécié

- Expérience de la gestion de projets nécessaire

- Double compétence appréciée (exemple : informatique documentaire et
  ingénierie de projets culturels)

- Intérêt pour les applications culturelles et artistiques des
  innovations technologiques

- Connaissances en développement d'application en environnement JAVA,
  XML...

- Parfaite maîtrise de l'anglais à l'oral comme à l'écrit
  indispensable (bilingue apprécié)

- Très bonnes qualités rédactionnelles et de synthèse

- Autonomie et rigueur

- Forte capacité d'adaptation à des milieux professionnels variés,
  aisance relationnelle

- Une bonne connaissance du paysage institutionnel culturel en Europe
  serait un plus


Conditions

Durée du stage : 6 mois (Convention de stage obligatoire)

Indemnités de stage

Poste à pourvoir rapidement


Contact  

Envoyer CV et lettre de motivation à l'attention de Stéphane Cagnot,
Directeur, à l'adresse suivante : anne-sophie.lelong@dedale.info"
"31","2009-04-14","Syllabs","Paris","PROPOSITION DE 2 STAGES AU SEIN DE LA SOCIÉTÉ SYLLABS 
------------------------------------------------------

* La société : Syllabs (www.syllabs.com) est un jeune laboratoire de
  recherche privé spécialisé dans les domaines de la Gestion de
  l'Information et du Traitement Automatique des Langues. Syllabs est
  au coeur de trois activités complémentaires : La Recherche, les
  Développements Innovants et le Conseil.


Nous recherchons deux stagiaires BAC+5 en Informatique :

- Développement d'un outil de compression de phrases pour le résumé
  automatique de textes

- Développement d'un outil de catégorisation des opinions pour des
  domaines spécifiques


********************************
Outil de compression de phrases
********************************

* CONTEXTE : Projet ANR RPM2 (Résumé Plurimédia, Multi-documents et
  Multi-opinion). Pour plus d'infos : http://labs.sinequa.com/rpm2/

* SUJET DU STAGE : Développement d’un outil de compression de phrases
  pour le résumé automatique de textes

* OBJECTIFS DU STAGE : 

Le stage a pour objectif le développement d’un outil de compression de
phrases pour le résumé automatique de textes. Ce travail s’inscrit
dans le cadre d’un projet de recherche ANR relatif au développement
d’un système de résumé multimédia et multi-opinion. Dans ce contexte
particulier, nous nous intéressons au cas du résumé par extraction :
il s’agit de constituer un résumé par sélection et concaténation des
phrases les plus pertinentes du document source. Le résumé ainsi
produit peut alors présenter des éléments superflus et/ou redondants
que l’on souhaiterait éliminer. L’outil de compression de phrases
intervient à ce niveau. Il n’est cependant pas exclu que la
compression puisse intervenir en amont du système de résumé i.e. avant
la phase d’extraction des phrases pertinentes.

Il existe deux grandes approches pour la compression de phrases :
l’approche linguistique qui consiste à définir des règles et
l’approche statistique qui utilise un corpus d’apprentissage pour
détecter des régularités statistiques exploitables. Certaines méthodes
dites « hybrides » s’attachent à combiner ces deux approches afin de
tirer parti des avantages de chacune. A partir d’un état de l’art, la
personne recrutée sera amenée à réaliser une évaluation des méthodes
existantes afin de déterminer l’approche finale. Aucune approche n’est
privilégiée a priori. Une attention particulière devra être portée à
deux éléments caractéristiques d’une bonne compression : la
grammaticalité et la concision. La grammaticalité consiste à s’assurer
que la phrase est grammaticalement correcte. La concision correspond
au fait qu’une phrase compressée doit rendre compte de l’information
essentielle de la phrase originale.

Une évaluation des performances de l’outil sera réalisée en fin de
stage sur la base d’un corpus annoté manuellement. Des mesures
classiques d’évaluation seront utilisées avec prise en compte de la
grammaticalité et de la concision.

La personne sera intégrée à l’équipe en charge des projets de
recherche.


* CONNAISSANCES ET NIVEAU SOUHAITÉS :

- Linguistique Informatique, Bac+5 - Master 2
- Apprentissage supervisé (SVM, perceptron, modèles de Markov)
- Modèles de langages
- Bonne maîtrise du langage Java et d’un langage de script (Perl,
  Python)

* Eléments facultatifs mais considérés comme un plus :

- Maîtrise d'une ou plusieurs langues étrangères
- Connaissance des techniques de résumé automatique

* LIEU DU STAGE : Syllabs - http://www.syllabs.com/fr/contact.html

* RESPONSABLE : Aude Giraudel

* DURÉE DU STAGE : 6 mois

* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre
  de motivation ainsi que votre CV complet à l'adresse suivante :
  jobs@syllabs.com 


*************************************
Outil de catégorisation des opinions
*************************************

* CONTEXTE : Projet ANR RPM2 (Résumé Plurimédia, Multi-documents et
  Multi-opinion). Pour plus d'infos : http://labs.sinequa.com/rpm2/


* SUJET DU STAGE : Développement d’un outil de catégorisation des
  opinions pour des domaines spécifiques


* OBJECTIFS DU STAGE : 

L’objectif du stage est la mise en place d’un outil de catégorisation
des opinions dans un ensemble de classes de type positif, négatif,
neutre. Ce travail s’inscrit dans le cadre d’un projet de recherche
ANR relatif au développement d’un système de résumé multimédia et
multi-opinion. Dans ce contexte particulier, il s’agit de produire des
résumés textuels prenant en compte les opinions afin de donner la
parole à des courants distincts, des sources d’informations avec des
points de vue différents. En cela, l’étiquetage de l’opinion, ce
qu’elle exprime, nous intéresse particulièrement et il s’agit ici de
faire de la catégorisation selon des types d’opinions préétablis afin
de pouvoir rendre dans le résumé final les différents points de vue
exprimés.

Dans une première phase, il s’agira de mettre en place un outil
d’extraction d’opinions et de catégorisation de ces opinions. Le
formalisme utilisé reste à définir. Des lexiques d’opinions
thématiques devront cependant probablement être spécifiés et
développés. Ce travail sera mené en étroite collaboration avec le pôle
linguistique de la société. Cette première phase constitue la brique
de base du système.

Dans une seconde phase, on s’attachera à mettre en place un système de
rattachement des objets cibles aux opinions exprimées. On se
focalisera alors sur les objets du domaine, leurs instances, leurs
attributs ainsi que leurs propriétés pour construire un système
complet d’analyse d’opinion. L’étude passera par une étape de
modélisation du domaine ainsi que par la mise en place d’un processus
qui fera le lien entre le modèle du domaine et les lexiques d’opinions
déjà développés.

La personne sera intégrée à l’équipe en charge des projets de
recherche.


* CONNAISSANCES ET NIVEAU SOUHAITÉS :

- Linguistique Informatique, Bac+5 - Master 2
- Modélisation des connaissances
- Algorithmes de catégorisation
- Bonne maîtrise du langage Java et d’un langage de script (Perl,
  Python)
- Bonnes connaissances dans les domaines du Traitement Automatique des
  Langues


* Eléments facultatifs mais considérés comme un plus :

- Maîtrise d'une ou plusieurs langues étrangères
- Analyse et classification d’opinions

* LIEU DU STAGE : Syllabs - http://www.syllabs.com/fr/contact.html

* RESPONSABLE : Aude Giraudel

* DURÉE DU STAGE : 6 mois

* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre
  de motivation ainsi que votre CV complet à l'adresse suivante :
  jobs@syllabs.com

 
-------------------------------------------------------------
Christelle Ayache - Chef de projet / Linguiste
Syllabs (entreprise agréée CIR)
15 rue Jean-Baptiste Berlier 75013 Paris
Tel : 01.55.43.76.36 / Fax : 01.55.43.76.35 (New!)
Courriel : ayache@syllabs.com
Site Web : www.syllabs.com
-------------------------------------------------------------"
"32","2009-04-20","Weborama","Paris","STAGE LINGUISRE INFORMATICIEN



Sujet : Participer à l'optimisation du Ciblage comportemental de Weborama



Description :

W.Cluster est la solution de Ciblage comportemental dernière
génération développée par Weborama. L'objectif de ce stage est
d'améliorer l'extraction d'information de pages web. Le travail sera
également axé sur la gestion du lexique et sur la constitution des
clusters de mots.



Compétences requises :

- Perl

- MySQL

- Des connaissances linguistiques (lexicologie, syntaxe, sémantique)

- Expressions régulières



Profil recherché : Bac +3 à Bac + 5

Sous la responsabilité d’un maître de stage vous devez être :
dynamique, minutieux.
Doté d’un grand sens de l’autonomie et de l’initiative. Etre capable
de rédiger un cahier de charge, étudier et proposer des solutions
adaptées aux besoins.



Cadre de travail : Ce poste est une opportunité d'intégrer un pôle de
développement composé de passionnés d'Internet.



Type de contrat : Stage conventionné de 6 mois



Début du contrat : dès que possible



Localisation du poste : 75019 Paris



Indemnité : selon profil



Comment postuler ?

Pour postuler, envoyez votre CV, ainsi qu'une lettre de motivation et
si possible des liens vers vos différentes réalisations.

Merci de faire parvenir votre candidature sous la référence STLI, à
Delphine Peudennier (jobs@weborama.com).



A propos de Weborama :

Pionnier des technologies de tracking numérique, Weborama a développé
une offre complète de solutions à destination des éditeurs, des
agences et des annonceurs sur Internet. Les plates-formes d'adserving,
de tracking et de web analytics de Weborama permettent aux
responsables marketing, chargés d'étude et webmasters de diffuser, de
mesurer et d'optimiser leurs investissements de communication sur le
web.



Weborama compte plus de 300 clients grands comptes, en France et en
Europe. Elle a reçu le label «société innovante» par Oseo ANVAR, et
figure aux palmarès français et européen du Deloitte Technology
Fast. Weborama est cotée sur Alternext depuis juin 2006 (codes :
FR0010337444  ALWEB).



Pour en savoir plus sur Weborama : http://weborama.com



Tessier Léa

Direction Administrative et Financière

------------------------------------------------------------

Weborama

15 rue Clavel

75019 Paris

Tel : 01.53.19.21.40

Fax : 01.53.19.21.41"
"33","2009-04-23","CEA","Fontenay-aux-Roses","COMMISSARIAT A L'Ã‰NERGIE ATOMIQUE

Centre : Fontenay-aux-Roses

Laboratoire CEA, LIST, LIC2M

Titre du stage
DÃ©veloppement d'une interface Web pour un systÃ¨me de rÃ©sumÃ©
automatique

Objectifs du stage :
Le laboratoire LIC2M a dÃ©veloppÃ© pour l'IRSN un logiciel de rÃ©sumÃ©
automatique nommÃ© Choral, accessible par l'intermÃ©diaire d'un service
Web sÃ©curisÃ© au standard WebContent (http://www.webcontent.fr/). Le
travail du stagiaire consistera Ã  dÃ©velopper une interface graphique
utilisant les technologies Web pour permettre aux utilisateurs finaux
de l'IRSN d'exploiter facilement l'outil de rÃ©sumÃ©
automatique. L'interface graphique sera dÃ©veloppÃ©e sous la forme de
portlets (JSR 286) qui seront intÃ©grÃ©es dans un portail tel que
Liferay. Cela implique l'utilisation de technologies telles que Java,
XML, JSP, etc. Des tutoriels sont disponibles Ã  partir du site de
WebContent pour aborder le dÃ©veloppement de portlets accÃ©dant Ã  des
web services. AprÃ¨s dÃ©veloppement et tests, le logiciel sera dÃ©ployÃ© Ã 
l'IRSN par le stagiaire.

Moyens informatiques mis en oeuvre :
Langages : Java, XML, JSP, XSLT, ...
Logiciels : GNU/Linux, Liferay, navigateurs, Tomcat Autres moyens mis
en oeuvre (expÃ©riences, mÃ©thodes dâ€™analyses, autres...)  â€‚â€‚â€‚â€‚â€‚

Niveau souhaitÃ© :
Bac +4 IngÃ©nieur
Bac +5 Master

DurÃ©e du stage : 4 Ã  6 mois

Contact
GaÃ«l de Chalendar
Gael.de-Chalendar@cea.fr
+33 1 46 54 80 18

Helmut Pitsch
helmut.pitsch@irsn.fr
+33 1 58 35 91 45"
"34","2009-07-06","BNP Paribas","Paris","Nous recherchons un stagiaire pour une mission de six mois (rémunérée)
pour travailler sur notre application.

Cette mission consistera à travailler pour un portail d'informations
économiques et financières interne ""LEOnard"" qui compte près de 9000
abonnés et environ 1000 connexions par jour.

 Destiné à l'ensemble des collaborateurs du groupe, ce portail allie
recherche d'informations et push (présentation d'informations)
toujours plus pointues et pertinentes.

Ces informations proviennent de base de données internes, de sites web
et de près de 400 articles issus de la presse quotidienne économique.
Plusieurs technologies sont utilisés dans LEOnard : Polyspot (moteur
de recherche), KB Crawl et KB Platform (outil de surveillance, de
collecte et de diffussion d'informations provenant du web) et Temis
(text mining).

Dans le cadre du développement de ce portail, nous recherchons un(e)
stagiaire pour poursuivre un travail entamé de catégorisation
automatique de tous nouveaux documents entrants (sectorielles --> ex:
constructeurs automobiles, pétrole, banques ...).
Un corpus de documents provenant de notre centre de Documentation 
économique a été utilisé comme documents référents (masters).

Nous souhaitons également mettre en place une technique dit de ""grains
de similarité"" permettant de proposer suite à une recherche ou
affichage d'un article un ou plusieurs documents autres similaires

Pour ce faire, nous nous sommes équipés des logiciels de Temis
(entreprise, leader dans le domaine du text mining).

Nous recherchons donc un stagiaire de niveau master (1ère ou 2ème
année) pour travailler sur ces logiciels et nous apporter ses
compétences dans l'utilisation et les perspectives que nous pouvons
tirer de ces technologies.

- Tests et analyse de l'outil de Text-mining Temis (extraction
  d'entités nommées, concepts économiques, catégorisations
  automatisées,..)

- Suivi du déploiement de la mise à disposition de ce moteur de
  recherche entreprise (outil en langage naturel) auprès des
  utilisateurs, mise à jour guide utilisateur.

- Participation aux démonstrations en interne et à l’externe.

- ...etc

Compétences requises : 

- Etre méthodique, autonome, rigoureux et curieux. 

- Prendre des initiatives, partager ses idées et son savoir-faire et
  donc savoir travailler en équipe

- Anglais lu parlé obligatoire 

- Notions informatiques type langage html, xml, structuration et
  développement de sites internet ""


Cordialement
Michel Bernardini


Michel Bernardini
BNP PARIBAS
Etudes Economiques
6 Bld Capucines
ACI : CIK01A1
75450 paris cedex 09
tel : 01.42.98.05.71 / 06.64.01.64.07
fax : 01.42.98.19.92"
"35","2009-10-22","France Telecom Orange","Paris","Intitulé
Elaboration d'un système de règles pour l'amélioration de données annuaire

Mission

La direction 118712 est une entité marketing en charge de la
définition, de la conception et du déploiement des offres de
renseignements annuaire d'Orange sur différents canaux (renseignements
téléphoniques, web, mobile,...).

L'annuaire comprend diverses informations reçues des opérateurs sous
des formes différentes. Ces données font l'objet de traitements
récurrents permettant de les normaliser, de les homogénéiser et d'en
extraire les informations les plus pertinentes pour renseigner les
clients de la meilleure façon possible.

L'objectif du stage est de permettre l'amélioration de la qualité des
données annuaire dans les traitements récurrents par l'optimisation
des régles existantes et par la mise mettre en place d'un nouveau jeu
de règles complexes.

Le stagiaire devra s'imprégner de l'existant (le fonctionnement du
système et ses régles en cours) et aura en charge la réalisation des
tâches suivantes :

 *   l'analyse des données
 *   la conception de règles formelles
 *   les tests qualité (non-régression et amélioration)
 *   la résolution des problèmes inhérents aux règles

Profil
Bac + 5 (Master pro ou recherche)
Spécialiste des langages formels (traitement automatique des langues,
linguistique)

Compétences

 *   bonne expérience des langages formels
 *   manipulation de gros volumes de données
 *   maîtrise d'excel et d'outils de manipulation de bases de données
 *   capacité d'abstraction
 *   bonnes capacités d'analyse
 *   goût pour la résolution de problèmes
 *   rigueur

Modalités
Site de France Télécom en Ile-de-France
6 mois à partir de mars 2010
Stage rémunéré

Contact
Estelle Maillebuau - 01 55 22 88 57
estelle.maillebuau@orange-ftgroup.com<mailto:estelle.maillebuau@orange-ftgroup.com>"
"36","2009-11-23","Xerox XRCE","Grenoble","Stage de 4 à 6 mois au centre de recherche Xerox Europe
(http://www.xrce.xerox.com/
http://www.xrce.xerox.com/Research-Development/Document-Content-Laboratory/Parsing-Semantics/ 
)

Date : à partir de janvier 2010

Sujet : Développements linguistiques pour l'analyse d'opinions

L'équipe Parsing&Semantics du centre de recherche XRCE Meylan
recherche un stagiaire pour travailler sur un projet Eurostar, Scoop,
dont le but est de développer un outil pour la recherche et l'analyse
d'opinions au sein d'un moteur de recherche innovant.

Il s'agit plus précisément de participer au développement de
grammaires de dépendances de l'anglais et du français afin de traiter
des phénomènes linguistiques typiquement mis en jeu pour l'expression
des sentiments.

Les différentes tâches sont les suivantes:

- analyse linguistique des corpus cibles et formalisation des
  phénomènes linguistiques mis en jeu

- Développement de grammaires pour l'analyse d'opinion (adaptation et
  développement de règles permettant de couvrir des phénomènes tels
  que la coréférence et la négation, ...)

- reconnaissance d'entités nommées, en particulier pour les noms de
  produits.

Profil demandé :

Le candidat doit posséder un très bonne connaissance du traitement
automatique des langues en général et du développement de grammaires
en particulier.

Il doit maitriser le français et l'anglais.  
Des connaissances relatives aux techniques d'analyse d'opinion
seraient un plus.

Les candidatures sont à envoyer à l'adresse suivante: 
Caroline.Brun@xrce.xerox.com"
"37","2009-12-07","EDF","Clamart","Stage Bac + 5 de 4 à 6 mois au centre de R&D d'EDF de Clamart

Sujet : Adaptation des techniques de text mining aux données 
conversationnelles issues de l'oral 

EDF utilise les techniques de Text Mining pour optimiser sa relation
client, en analysant des questions ouvertes d'enquête de satisfaction,
des textes libres et des retranscriptions de conversations issues des
centres d'appels.

La R&D d'EDF met en ½uvre des techniques de text mining sur les
transcriptions de conversations téléphoniques des centres d'appels.
La chaîne de traitement text mining (lemmatisation, extraction de
concept métier, segmentation, classement) permet ainsi de classer ces
transcriptions selon différentes thématiques. Que ces conversations
soient transcrites automatiquement ou manuellement, les entrées de la
chaîne text mining diffèrent de celles classiquement traitées par les
modules de text mining : il s'agit de données issues de l'oral
(transcription littérale manuelle ou automatique) contenant de
nombreuses disfluences comme par exemple : les hésitations, les
bégaiements sur les amorces de mots, les phrases inachevées, les
répétitions de mots ou de groupes de mots.  Ces spécificités liées à
l'oral sont difficiles à traiter, notamment lors de l'étape
d'extraction de concepts métiers (cartouches de connaissance),
extraction qui se fait à l'aide de règles, qui peuvent s'avérer peu
adaptées à des données dont le fenêtrage syntaxique diffère de celui
des données textuelles classiques.

Par ailleurs, les modules de reconnaissance automatique de la parole
utilisés génèrent un certain nombre d'erreurs incluant des erreurs de
ponctuation qui viennent ainsi altérer la transcription.

Dans les deux cas, transcriptions manuelles et automatiques,
l'objectif de se stage sera d'analyser l'impact de l'oral sur la
chaîne text mining et de proposer des alternatives aux méthodes
utilisées jusque maintenant sur des données textuelles.

Profil recherché :

Bac+5, stage de fin d'étude dans le domaine du TALN et/ou du
traitement de la parole.

Contact  et envoi des candidatures :
Chloé Clavel , 01 47 65 43 15, chloe.clavel@edf.fr
Anne Peradotto , 01.47.65.44.89, anne.peradotto@edf.fr
Lieu du stage :  EDF R&D,    1, av du Général de Gaulle,  92141 Clamart 
Cedex
Durée : 6 mois environ
Rémunération : environ 1.000¤/mois
  
 
Chloe CLAVEL
Ingénieur chercheur
EDF 
ICAME
1, av. du Général de Gaulle
92141 Clamart
 
chloe.clavel@edf.fr
Tél. : 33 (0)1 47 65 43 15"
"38","2009-12-14","Xerox XRCE","Grenoble","Proposition de stage
Date : à partir de janvier 2010
Durée : entre 4 et 6 mois

Sujet : Développer un outil de conversion ""html to text"" pour
l'extraction d'évènements à partir d'articles journalistiques

L'équipe Parsing&Semantics du centre de recherche XRCE Meylan
recherche un stagiaire pour travailler sur un projet européen, SynC3,
dont l'objectif est de développer un outil capable de représenter les
sentiments provenant de blogs qui parlent d'évènements mentionnés dans
des articles de presse.

Il s'agit plus précisément de participer au développement d'un outil
capable de convertir un article journalistique qui se présente sous la
forme d'un fichier html en un fichier texte ne contenant que le texte
pertinent du fichier html.

Les différentes tâches sont les suivantes:

- développer et améliorer un module existant de conversion de fichier
  html en fichier texte (développé en Java)

- travailler sur la segmentation d'articles. Identifier les
  différentes parties de l'article (titre, paragraphes, auteurs,
  etc.).


Profil demandé :

Le candidat doit maîtriser la manipulation de fichiers html et doit
posséder une très bonne connaissance de Java. Un bon niveau en anglais
est requis.
Des connaissances concernant la plateforme UIMA seraient un plus.

Les candidatures sont à envoyer à l'adresse suivante:
guillaume.jacquet@xrce.xerox.com"
"39","2009-12-14","Syllabs","Paris","Proposition de stage au sein de la société Syllabs

Contexte

Outil d'aide aux linguistes pour le développement de ressources
linguistiques

Sujet du stage

Intégration d'un guessing d'entités nommées pour la création et
maintenance de lexiques sémantiques et thématiques.

Objectifs du stage

L'objectif du stage est d'étudier la problématique liée à la création
et maintenance de lexiques sémantiques et thématiques, de proposer une
méthode pour alimenter semi-automatiquement ceux-ci à partir de
nouvelles entités nommées et d'intégrer un module développant la
méthode à l'ensemble d'outils de l'architecture OAL. Etant donnée une
entité nommée inconnue, le module doit suggérer aux linguistes les
traits sémantiques pertinents ainsi que l'appartenance à un ou
plusieurs lexiques thématiques existants.  Actuellement Syllabs
dispose de ressources linguistiques en plusieurs langues et pour
différents domaines. La personne travaillera avec des informaticiens
et des linguistes.


Connaissances et niveau souhaités

- Linguistique Informatique, Bac+5 - Master 2

- Bonne maîtrise du langage Java

- Bonnes connaissances dans les domaines du Traitement Automatique des
  Langues

Eléments facultatifs mais considérés comme un plus :

- Maîtrise d'une ou plusieurs langues étrangères

Durée : 6 mois

La société

Syllabs est une entreprise spécialisée dans les domaines de la Gestion de
l'Information et du Traitement Automatique des Langues. Syllabs est au c½ur
de trois activités complémentaires : La Recherche, les Développements
Innovants et le Conseil.


Pour plus d'informations : www.syllabs.com

Les candidatures doivent s'adresser à jobs at syllabs.com. Merci d'indiquer
le nom/code du stage dans l'objet du mél."
"40","2009-12-14","Syllabs","Paris","Proposition de stage au sein de la société Syllabs

Contexte

Outil d'aide aux linguistes pour le développement de ressources
linguistiques

Sujet du stage

Conception et implémentation d'une nouvelle gestion client/serveur de
ressources linguistiques, dans le cadre de l'architecture OAL (Outil
d'Aide aux Linguistes) utilisée par le Département de Développements
Linguistiques de Syllabs.


Objectifs du stage

La personne recrutée pour ce stage aura pour tâche l'enrichissement de
la gestion client/serveur de ressources linguistiques. Actuellement
Syllabs dispose de ressources en plusieurs langues et pour différents
domaines. OAL propose un client riche et une architecture qui permet à
plusieurs linguistes de travailler sur les mêmes
ressources. L'objectif du stage est d'étudier la solution actuelle,
d'en analyser les limites, et d'en proposer une autre, qui sera par la
suite implémentée. Parmi les fonctionnalités souhaitées se trouvent :
check-in et check-out de ressources, versionnage de ressources,
control d'utilisateurs, gestion de statistiques. La personne
travaillera avec des informaticiens et des linguistes. Les outils sont
développés en Java/SWING.


Connaissances et niveau souhaités

- Bac+5 - Master 2

- Très bonne maîtrise de Java/SWING


Eléments facultatifs mais considérés comme un plus :

- Connaissance du domaine du Traitement Automatique des Langues

- Connaissance de SVN

- Maîtrise d'une ou plusieurs langues étrangères


Durée : 6 mois


La société

Syllabs est une entreprise spécialisée dans les domaines de la Gestion
de l'Information et du Traitement Automatique des Langues. Syllabs est
au c½ur de trois activités complémentaires : La Recherche, les
Développements Innovants et le Conseil.

 

Pour plus d'informations : www.syllabs.com.

 

Les candidatures doivent s'adresser à jobs at syllabs.com. Merci d'indiquer
le nom/code du stage dans l'objet du mél."
"41","2009-12-14","Syllabs","Paris","STAGE EN LINGUISTIQUE INFORMATIQUE

Contexte
********
Outil d'aide aux linguistes (OAL) pour le développement de ressources
linguistiques multilingues & Linguistic Object Language (LOL) pour
l'écriture des grammaires pour l'extraction d'information.

L'un des aspects clés des applications en Traitement Automatique des
Langues est lié à la qualité de ressources linguistiques sur
lesquelles celles-ci s'appuient. A priori les ressources sont toujours
perfectibles, mais son enrichissement et raffinement est un processus
coûteux et parfois assez fastidieux pour les linguistes. Le but d'OAL
est justement de rendre cette tâche plus productive et surtout, de
faciliter le contrôle de la qualité (test de régression, gestion des
questions liées aux ressources multilingues).  Sujet du stage

1) Développement des lexiques morphosyntaxiques SylLex et des lexiques
   SylThème dans OAL, outil d'aide aux linguistes conçu pour le
   développement de ressources linguistiques ainsi que définition et
   participation à la mise en place des ressources et procédures
   nécessaires pour l'alimentation semi-automatique de l'outil.

2) Écriture des règles d'extraction d'information dans un
   environnement multilingue.

Langues possibles 
******************
allemand, danois, chinois, néerlandais, polonais, portugais, russe,
suédois ou tchèque.

Objectifs du stage
******************

La personne recrutée pour ce stage aura deux tâches principales :

1) Le développement et l'intégration des lexiques morphosyntaxiques et
thématiques de Syllabs dans une des langues listées en haut dans OAL,
notre outil d'aide aux linguistes conçu pour le développement de
ressources linguistiques. La phase de développement des lexiques
implique la création des ressources et procédures semi-automatiques
nécessaires pour alimenter le lexique tout en assurant leur qualité
(création de corpus, définition des critères linguistiques pour le
crawling conditionnel, définition du jeux d'étiquettes
morphosyntaxiques suivant les conventions du formalisme SylLex,
définition des tests de régression, évaluation quantitative et
qualitative des lexiques, évaluation de la couverture).

2) L'écriture des grammaires pour l'extraction d'information avec LOL,
un langage de programmation linguistique développé à Syllabs.

Connaissances souhaitées
************************

Étudiant(e) en Linguistique Informatique, Traitement Automatique des
Langues.
Très bonne maîtrise de la morphologie.
Très bonne maîtrise de PERL ou Python et Unix. 
Expérience avec Intex ou Nooj serait un plus.

Merci d'envoyer votre candidature à l'adresse suivante : jobs
/arrobas/ syllabs .com tout en indiquant dans l'objet du mèl « stage
en linguistique informatique »."
"42","2009-12-16","Lingway","Nantes","Lingway, spécialiste français en Traitement Automatique des Langues
propose, dans le cadre d'un projet de R&D collaborative, un stage
conventionné (M2 ou équivalent).

L'objectif du stage est de réaliser l'interface d'accès aux résultats
d'un système d'analyse automatique des offres d'emploi sur le web,
système en cours de réalisation dans le cadre du projet SIRE.

Les tâches à accomplir sont:

- collecte des informations extraites depuis les différents modules
  des partenaires,

- formalisation de ces informations forme de triplets RDF,

- mise en oeuvre d'une base RDF dédiée (""triple store"") pour stocker
  ces informations,

- développement d'une interface Web permettant la consultation de
  cette base (le site pourra présenter des résultats de requêtes
  pré-définies sous la forme de graphes).


Compétences requises:
- bonne connaissance des outils de TAL,
- langage Java, 
- développement Web (de préférence Flex),
- bonnes capacités d'analyse,
- goût pour la résolution de problèmes,
- facilité à travailler en équipe

Stage rémunéré, basé à Nantes, 6 mois à partir de Février 2010

Envoyer CV + LM à hugues.de-mazancourt@lingway.com"
"43","2009-12-31","Arisem","Massy-Palaiseau","Arisem propose cette année six stages de niveau master :

- Constitution semi-automatique d'ontologies
- Enrichissement d'un environnement de production de ressources
  linguistiques sous Eclipse RCP
- Extraction de relations sémantiques entre entités nommées
- Normalisation des dates et expressions temporelles
- Plateforme de test et d'évaluation de ressources linguistiques
- Résolution d'anaphores

Les détails de chacun de ces stages sont disponibles sur la page

http://www.arisem.com/index.php?page=emploi

Les candidatures peuvent être directement adressées à :
nicolas.dessaigne@arisem.com
aurelie.migeotte@arisem.com"
"44","2010-01-06","SenseGates","Vigneux sur Seine","Bonjour,

SenseGates, nouvelle entreprise installée à Vigneux sur Seine
(Essonne, 13 minutes de la gare de Lyon), propose six stages de niveau
master :

* Profil informaticien strict
   - Changement d'un moteur de base de données relationnelles
   - Evaluation de différents moteurs d'indexation clé/valeur (par
     ex. de cassandra à hadoop)

* Profil linguiste ou lexicographe ou terminologue traducteur
   - Contrôle / évaluation de processus d'enrichissement automatique
     de lexiques multilingues structurés (le candidat connaît 3
     langues dont le français et l'anglais)

* Profil mathématiques, IA
   - formalisation d'un langage stockant et créant des structures
     ensemblistes et méréotopologiques, leur connexité et leur
     perception selon le point de vue et leur comportement. En
     pratique ce langage est au c½ur d'un projet d'intégration en un
     palier d'analyseurs ou de générateurs linguistiques (grammaires,
     lexique génératif, isotopie, définition, corpus) ordinairement
     réalisé en plusieurs paliers (morphologie, syntaxe, sémantique,
     pragmatique, pour certains, ou par modules spécialisés comme
     figement, référence, relation entités nommées etc).

Les candidatures devront être adressées à Dominique Dutoit, 
do . dutoit at gmail . com"
"45","2010-01-16","LIMSI","Orsay","Le groupe ILES du LIMSI-CNRS propose des stages pour différents
niveaux d'études sur la thématique de la paraphrase en Traitement
Automatique des Langues:

Comparaison syntaxique de phrases
         http://www.ensiie.fr/~bg/stage_paraphrase.html

Identification de paraphrases dans les révisions de Wikipedia
         http://perso.limsi.fr/amax/recherche/sujet1-amax-M1-2010.html

Paraphrase Automatique pour la Traduction Automatique Statistique 
(Réécrire d'abord pour mieux traduire ensuite)
         http://perso.limsi.fr/amax/recherche/sujet2-amax-M2R-2010.html

Validation sur corpus monolingues de paraphrases acquises sur corpus 
multilingues
         http://perso.limsi.fr/amax/recherche/sujet3-amax-M2R-2010.html


L'ensemble des propositions de stage se trouve sur la page suivante:

http://www.limsi.fr/Scientifique/iles/propositions

Les candidats devront contacter directement les responsables du/des
stages, en joignant un descriptif de leur parcours sous forme d'un
court CV et en précisant leur motivation pour les stages concernés."
"46","2010-01-16","LIMSI","Orsay","L'équipe ILES du LIMSI propose cette année *quatre stages de M2
(master recherche ou master professionnel)* dans le domaine des
systèmes de questions-réponses, ainsi qu'*un stage de M1*.

Un résumé de ces stages est présenté ci-dessous, une description plus
complète est disponible aux adresses suivantes :
Stages de M2 :
http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_contexte_analyse.html

http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M2R_contexte_questions_complexes.html

http://sites.google.com/site/delphinebernhard/proposition-de-stage-generation-questions

http://www.ensiie.fr/~bg/stage_fouilleDeTexte.html

Stage de M1 :
http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_M1_confiance_question_reponse.html

Par ailleurs, d'autres stages dans d'autres thèmes sont proposés par 
l'équipe :
http://www.limsi.fr/Scientifique/iles/propositions"
"47","2010-01-16","OWI Technologies","Châtenay Malabry","OWI Technologies.

Nous sommes éditeur d'un logiciel de moteur sémantique reposant sur
une technologie très innovante.

La commercialisation de notre offre commence en 2010, raison pour
laquelle nous communiquons aussi peu que possible, pour l'instant.

Nous recherchons, pour la mise en ½uvre de langues supplémentaires, un
stagiaire, idéalement dans le cadre d'un Master en TAL.
Les tâches à accomplir comprennent :
- l'identification de ressources linguistiques utiles
- la description et la saisie des comportements linguistiques, au sein 
  du modèle OWI

Les compétences requises sont :
- être au minimum bilingue (anglais et autre)
- disposer d'une culture linguistique permettant de comprendre 
  rapidement le modèle OWI
- savoir travailler en équipe (autonomie et collaboration)

La durée du stage pourra être comprise entre 3 et 6 mois, et il
s'agira de travailler, au sein d'une équipe de R&D de 5 personnes,
principalement avec un docteur en informatique ayant mis en place le
français.

Le stage est rémunéré (800 euros bruts par mois).

Nos bureaux sont situés au sein de l'Ecole Centrale Paris, à Châtenay
Malabry (92).

Contact : transmettre curriculum vitae et lettre de motivation à 
stages@owi-tech.com."
"48","2010-01-19","CEA","Fontenay-aux-Roses","Proposition de stage de master 2 

Extraction supervisée de relations entre entités nommées à une large
échelle

Olivier Ferret (ferreto__zoe.cea.fr) et Romaric Besançon
(besanconr__zoe.cea.fr)

CEA LIST/LVIC, Fontenay-aux-Roses

CONTEXTE
Le sujet de stage proposé se situe globalement dans le domaine du
Traitement Automatique des Langues (TAL) et se focalise plus
précisément sur l'une de ses branches applicatives les plus actives,
l'extraction d'information. Celle-ci a pour objectif de repérer
automatiquement dans des textes les entités caractéristiques d'un
domaine ainsi que les relations intervenant entre ces entités, ceci
dans le but d'alimenter une base de connaissances ou une base de
données.

Les entités considérées dans ce cadre sont plus précisément appelées
entités nommées et dans le cas le plus général, correspondent à des
noms de personnes, de lieux, d'organisations ou à des entités
numériques telles que des dates, des montants financiers ou des
mesures. Les relations entre ces entités peuvent être dans les cas les
plus complexes des relations n-aires allant jusqu'à la notion
d'événement. Par exemple, un événement de rachat d'une entreprise par
une autre est représentable par une relation du type :

Achat_entreprise
   société acheteuse : ORG
   société achetée : ORG
   montant : MONEY
   date : DATE
où société acheteuse définit le rôle d'une entité et ORG, son type.

Dans le cadre du stage, seules des relations binaires seront
considérées. Le processus d'extraction d'information peut dans ce cas
se résumer aux deux étapes suivantes :

   - détection des entités nommées ;
   - détection des relations entre les entités identifiées.

A titre d'exemple, pour le passage :
""With a father from <loc>Kenya</loc> and a mother from
<loc>Kansas</loc>, <pers>President Obama</pers> was born in
<loc>Hawaii</loc> on <date>August 4, 1961</date>.""
ces deux étapes donnent le résultat suivant si l'on s'intéresse aux
données de naissance d'une personne :
Détection des entités nommées
   Noms de lieux : Kenya, Kansas, Hawaii
   Noms de personnes : President Obama
   Date : August 4, 1961

Détection des relations entre entités
   Lieu_naissance : bornIn(President Obama, Hawaii)
   Date_naissance : bornOn(President Obama, August 4, 1961)


OBJECTIFS DU STAGE
De nombreux travaux ont été réalisés sur la détection des entités
nommées et comparés lors de plusieurs campagnes d'évaluation (shared
task CoNLL 2002 et 2003, ACE ...). Le laboratoire LVIC (anciennement
LIC2M) du CEA LIST possède en outre, au travers de sa plate-forme
LIMA, des outils de traitement linguistique intégrant la
reconnaissance d'entités nommées ""générales"". Le stage se concentrera
donc sur la phase d'extraction de relations, pour laquelle le niveau
de performance des systèmes actuels reste à améliorer. C'est
particulièrement le cas lorsque l'objectif est de couvrir un ensemble
large de types de relations. Le stage s'effectuera dans la perspective
de l'évaluation KBP (Knowledge Base Population) de la campagne TAC
2009 (Text Analysis Conference) et en reprendra les caractéristiques
et les données. Plus précisément, cette évaluation vise à rassembler
des informations factuelles concernant des entités relevant de trois
grands types : personnes, organisations et entités géopolitiques.  Ces
informations factuelles prennent la forme de relations appartenant à
42 types possibles (date et lieux de naissance, âge, religion, nombre
d'employés, fondateur, etc).


Le LVIC dispose déjà d'outils d'extraction de relations au sein des
phrases, fondés sur la notion de patron linguistique. Un tel patron
peut être vu comme une forme d'expression régulière intégrant des
éléments de différents niveaux de généralité (mots, catégories
grammaticales, ""joker"" ...) et permettant de valider la présence
effective d'une relation entre deux entités nommées trouvées dans une
phrase. Par exemple, le patron <maladie> * traiter * par  DET
<traitement> permet de valider la présence de la relation
[traitement]--(traiter)--[maladie] dans les deux cas suivants :

   <maladie> se traite par une <traitement>
   <maladie> est traitée efficacement par le <traitement>

Le LVIC dispose également des outils permettant d'apprendre
automatiquement ces patrons à partir de corpus annotés. Le stagiaire
aura tout d'abord en charge l'application de cet existant à l'échelle
du grand nombre de relations considérées dans KBP. L'accent sera mis
sur l'utilisation de données d'apprentissage bruitées du fait de
l'impossibilité de valider manuellement de larges ensembles
d'apprentissage pour un tel nombre de relations. Deux autres
problématiques importantes seront ensuite abordées :

   - le filtrage des relations extraites, en s'appuyant notamment sur
     des méthodes d'apprentissage statistique (machines à vecteurs de
     support (SVM)) ;

   - l'extension de l'ensemble des patrons appris pour une relation
     par l'exploitation de données issues du Web. L'objectif est ici
     d'acquérir à partir d'exemples sondes de nouvelles formulations
     d'un type de relations ou des paraphrases de formulations déjà
     rencontrées.



BIBLIOGRAPHIE
Task Description for Knowledge-Base Population at TAC 2009,
http://apl.jhu.edu/~paulmac/kbp/090601-KBPTaskGuidelines.pdf


Automatic Content Extraction (ACE) Evaluation, http://www.itl.nist.gov/iad/mig/tests/ace/

Mintz, M., Bills, S., Snow, R. & Jurafsky, D. 2009. Distant
supervision for relation extraction without labeled data. Joint
Conference of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language Processing of the
AFNLP, August, Suntec, Singapore.

Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang and Ji-Rong
Wen. 2009. StatSnowball: a Statistical Approach to Extracting Entity
Relationships. 18th international World Wide Web conference (WWW
2009).

César de Pablo-Sanchez, Juan Pereaea,Isabel Segura-Bedmar, Paloma
Martinez. 2009. The UC3M team at the Knowledge Base Population task.

Culotta, A., Mccallum, A. & Betz, J. 2006. Integrating probabilistic
extraction models and data mining to discover relations and patterns
in text. Human Language Technology Conference of the North American
Chapter of the Association of Computational Linguistics, Morristown,
NJ, USA.


COMPÉTENCES REQUISES
   - niveau M2 (ou ingénieur) en Informatique avec une spécialisation
     en Traitement Automatique des Langues
   - langage C++ ainsi qu'un langage de script de type Perl ou Python

MODALITÉS
Le stage sera rémunéré et se déroulera pour une durée de 6 mois au
sein du Laboratoire Vision et Ingénierie des Contenus (LVIC,
anciennement LIC2M) du CEA LIST, situé sur le centre CEA de
Fontenay-aux-Roses (92).


Les candidats intéressés par ce stage sont invités à prendre contact
avec Olivier Ferret ou Romaric Besançon en envoyant un CV accompagné
de quelques éléments de motivation.


Ce stage est également référencé au niveau du site Web du CEA à
l'adresse :
http://www.cea.fr/ressources_humaines/stages_longue_duree/extraction_supervisee_de_relations_entre_entites3"
"49","2010-01-22","Besoins d'infos","Paris","* ENTREPRISE : Besoin d'infos est une start-up internet qui s'occupe
  de gérer des annuaires thématiques et de développer un moteur de
  recherche en langage naturel sous forme de questions /
  réponses. www.besoindinfos.com . Le principe :

- Vous posez une question sur tous les sujets...
- Vous recevez immédiatement une réponse de qualité
- Un moteur de recherche sémantique fait la jonction entre la question
  et la bonne réponse

Besoin d'infos améliore sa technologie de recherche sémantique et son
modèle morphosyntaxique pour comparer entre elles des données non
structurées exprimées en langage naturel.

* MISSION :
Le stagiaire aura comme missions principales :
- Analyse quotidienne des logs du moteur de recherche pour identifier
  les problèmes sémantiques
- Actions correctrices et paramétrages sémantiques
- Enrichissement et création de dicos et de bases de connaissances
  (KB)
- Création de KB e-commerce sur les produits et services pour faire un
  moteur de suggestions.
- Améliorations sémantiques sur les bases de données de questions
  réponses.
- Modélisation d'algorithmes sémantiques pour rendre plus efficace la
  compréhension sémantique

- Pondération syntaxique des éléments d'une phrase et d'une question.
Le stage s'effectuera au sein de l'équipe R&D de Besoin d'Infos. Le
stagiaire sera encadré tout au long du stage et bénéficiera du support
de l'équipe.

* QUALITES REQUISES : 

- Profil linguistique & sémantique appliquée au Web et à
  l'informatique.
- Envie de vivre le lancement d'un site internet et l'aventure de la
  création d'entreprise
- Rigueur, esprit d'initiative et bonne autonomie
- Très bonne culture internet et notamment des sites internet grand
  public et cybermarchands
- Maîtrise des outils bureautique Word & Excel et des navigateurs
  Explorer et Firefox
- Esprit d'entreprise et forte curiosité

* ELEMENTS PRATIQUES :
- Profil : Etudiant en stage conventionné
- Formation : Linguistique Informatique, Bac+5 - Master 2
- Durée : 3 à 6 mois de janvier à juillet / Aout 2010
- Possibilité de mi-temps.
- Lieu du stage : Telecom ParisTech, 9 rue Dareau, Paris 14e
- Indemnité de stage prévue en fonction du profil et de la durée

* RESPONSABLE : directeur R&D de Besoin d'Infos

* DOSSIER DE CANDIDATURE : Merci de nous faire parvenir votre lettre
  de motivation ainsi que votre CV complet par mail à l'adresse
  suivante : renaud.lacroix@besoindinfos.com"
"50","2010-01-27","Orange Labs","Lannion","Intitulé

Evaluation des outils d'acquisition de terminologie dans une
application multimédia

Mission

Le stage concerne une des activités du laboratoire ACTS d'Orange Labs
: les applications de moteurs de recherche de contenus vidéo.

Dans ce cadre, un des problèmes à résoudre concerne l'amélioration de
la recherche par la prise en compte de la terminologie (locutions,
entités nommées...). Il s'agit d'enrichir et de maintenir une base
terminologique existante, base construite manuellement au départ. 

Le choix technique porte sur une acquisition automatique des données
de terminologie à partir de techniques d'apprentissage. 

Un premier travail réalisé dans le cadre d'un postdoc va concerner
l'étude et la construction du corpus d'apprentissage. Ce corpus va
être ensuite utilisé pour l'acquisition de terminologie. Pour ce
faire, il existe différents outils d'acquisition (outils développés en
interne au sein d'Orange Labs et outils ""libres"" disponibles à des
fins de recherche comme ACABIT).

L'objectif du stage est de mettre en oeuvre les outils en question puis
de les évaluer sur la base du même corpus.


Plus particulièrement, les aspects suivants sont à explorer :

* Prise en main des outils d'acquisition de terminologie existant dans
  le laboratoire
* Recherche d'autres outils
* Définition des critères d'évaluation (Rappel/Précision, etc. )
* Protocole d'évaluation par ordonnancement (algorithme RankBoost)
* Mise en oeuvre des méthodes d'évaluation
* Evaluation et comparaison des méthodes
* Rédaction d'un rapport 


Profil
Bac + 5 (Master pro ou recherche ou dernière année de Grande Ecole)
orienté informatique
Des connaissances linguistiques (terminologie notamment) seraient un
plus.


Compétences

Bonne connaissance en informatique
Bonnes capacités d'analyse
Rigueur
Intérêt pour les moteurs de recherche

Modalités
Site d'Orange Labs (Côtes d'Armor)
Adresse 2 avenue Pierre Marzin 22301 Lannion

4 à 6 mois à partir du printemps 2010
Stage rémunéré

Contact
Najeh HAJLAOUI  - 02 96 05 12 82 
Najeh.Hajlaoui@orange-ftgroup.com   

Edmond LASSALLE 02 96 05 15 98
Edmond.Lassalle@orange-ftgroup.com"
"51","2010-02-04","LIMSI","Orsay","Le groupe Traitement du Langage Parlé
(http://www.limsi.fr/tlp/index.html) du LIMSI-CNRS propose plusieurs
stages de master recherche, professionel, ou ingénieurs. Vous
trouverez les descriptifs de ces propositions à l'adresse suivante :
http://www.limsi.fr/Individu/allauzen/stages/index.html

N'hésitez pas à faire circuler cette information et à nous contacter
par mail pour des informations complémentaires. Les personnes
intéressées par l'une ou l'autre de ces propositions sont invitées à
contacter les responsables (de préférence par courrier électronique)
en joignant un CV et en précisant le ou les sujets concernés.


Description des activités du groupes :

Les recherches du groupe Traitement du Langage Parlé du LIMSI-CNRS ont
pour principaux objectifs de modéliser la parole et concevoir des
algorithmes pour son traitement automatique. Les activités du groupe
sont par essence pluridisciplinaires,et elles abordent le traitement
de la parole et du langage d'un point de vue acoustique, phonétique,
linguistique et informatique. Elles s'intéressent également au lien
entre parole et sens, ainsi qu'à la modélisation des processus de
communication orale.

Le besoin de confronter nos modèles aux données nous amène à
développer des systèmes de traitement du langage parlé assurant des
fonctions variées telles que la reconnaissance de la parole, la
traduction automatique, l'identification de la langue, du locuteur et
de son état émotionnel, le dialogue oral homme-machine, la
structuration de documents audiovisuels.


     Alexandre Allauzen
Univ. Paris XI, LIMSI-CNRS
Tel : 01.69.85.80.64 (80.88)
Bur : 114     LIMSI Bat. 508
     allauzen@limsi.fr"
"52","2010-02-04","Syllabs","Paris","STAGE EN TAL

Contexte
********
Outil d'aide au linguiste

L'un des aspects clés des applications en Traitement Automatique des
Langues est lié à la qualité de ressources linguistiques sur
lesquelles celles-ci s'appuient. A priori les ressources sont toujours
perfectibles, mais son enrichissement et raffinement est un processus
coûteux et parfois assez fastidieux pour les linguistes. Le but des
outils d'aide au linguiste à Syllabs est justement de rendre cette
tâche plus productive et surtout, de faciliter le contrôle de la
qualité.

Description du stage
********************

La personne recrutée pour ce stage aura deux tâches principales :

- Prise en main d'un nouvel outil d'annotation, validation des
  fonctionnalités et du manuel
- annotation d'un corpus en français (entités nommées, parties de
  discours)

Langue
*******

Français


Connaissances souhaitées
************************

- Étudiant(e) en Linguistique Informatique, Traitement Automatique des
  Langues.
- Goût pour l'analyse du discours

Durée
*****
2-3 mois à mi-temps (10-15h hebdomadaires, à discuter)
début en fevrier

Merci d'envoyer votre candidature à l'adresse suivante : jobs
/arrobas/ syllabs .com tout en indiquant dans l'objet du mèl « stage
TAL français »."
"53","2010-02-04","Orange Labs","Lannion","Stage de Master à Orange Labs.
Lieu : site de Lannion, France
Durée : 4 à 6 mois à partir de mars/avril 2010.
Stage rémunéré.

Thématique du stage :

Ce stage s'inscrit dans la thématique de la recherche d'information et
l'accès aux contenus multimédia. La recherche d'information
multilingue (plus précisément cross-lingue ou CLIR) vise à donner à
l'utilisateur l'accès à des documents ou à des contenus exprimés dans
une autre langue ou dans plusieurs autres langues que celle de la
requête.

Une fonctionnalité de CLIR a été mise en oeuvre et intégrée à un
moteur de recherche multimédia. Elle s'appuie sur la traduction des
contenus et repose sur une approche de traduction à base
d'apprentissage.

L'objet de ce stage consiste à intégrer un ou plusieurs outils de
traduction s'appuyant sur d'autres approches de traduction
automatique.
En outre, deux phases d'évaluation sont prévues. Une première
évaluation portera sur les outils de traduction identifiés en
s'appuyant sur des corpus spécifiques et une seconde phase portera sur
l'évaluation de la fonctionnalité de CLIR après l'intégration du/des
nouveaux outils de traduction.

Il est à noter que l'intégration des outils de traduction vise en
priorité la traduction des contenus dans plusieurs langues et pourrait
s'étendre à la traduction des requêtes.

Perspectives du stage :
Le stage proposé pourrait être suivi d'une thèse sur le thème de la
recherche d'information multilingue et plus précisément sur le
traitement des requêtes pour le CLIR.

Profil recherché :
- Bac + 5 (master recherche ou pro).
- Formation de base de préférence en informatique ou en linguistique.
- Bonnes connaissances du TALN.
- Connaissances de la recherche d'information et de la traduction
  automatique.
- Maîtrise de Linux, Python ou Java, langage de script, C++ serait un
  plus.
- Langues : français et anglais (et si possible espagnol ou allemand
  ou arabe).
- Motivation pour la R&D dans un milieu industriel.
- Motivation pour effectuer une thèse après le stage.
 
Contact :
Malek Boualem
Tel : 02 96 05 29 83
Email : malek.boualem@orange-ftgroup.com
Merci de préciser l'objet : Stage de Master sur le CLIR"
"55","2010-02-15","I3S","Nice","Lieu : Sophia Antipolis et Nice
Durée : 4 à 6 mois

L'équipe Ressources Linguistiques du Laboratoire I3S (Université de
Nice) propose le stage (rémunéré) ci-dessous.

Si vous êtes intéressé(e), merci d'envoyer un CV à
Jacques.Farre@unice.fr

*Titre : traitement linguistique de requêtes dans des moteurs de
recherche*


*Sujet :* Le bon classement d'une page web dans l'ensemble des pages
répondant à une requête à un moteur de recherche dépend de la
pertinence des mots-clés présents dans cette page. Une étude
statistique des requêtes permet de définir les mots-clés les plus
intéressants.  Cependant des requêtes analogues peuvent se présenter
sous différentes formes, par exemple :

	Je cherche un appartement en location sur nice
	cherche location appartement Nice
	cherche location appartement sur nice
	cherch location  appartament Nice (avec fautes d'orthographes)

génèrent des jeux de données statistiques différents.
Un traitement de ces requêtes appliquant des technologies du
traitement automatique des langues naturelles (TALN) permettrait de
corriger les fautes d'orthographes des requêtes, de les épurer de
leurs mots fonctionnels (prépositions, articles,...)  trop généraux et
donc non porteurs de sens, et éventuellement de les normaliser, par
exemple :

   (action:location; quoi:appartement;lieu:Nice-06).

Cela permettrait alors de « fusionner » différentes requêtes telle que
celles données ci-dessus et d'améliorer ainsi les statistiques
générées.

Le stage consistera à se familiariser avec une chaîne d'analyse du
français et ses ressources linguistiques (lexiques, grammaires ...)
puis à l'adapter pour obtenir une forme aussi normalisée que possible
des requêtes. Il comprendra des visites à une PME niçoise spécialisée
dans le référencement commercial sur le web."
"57","2010-03-08","LIPN","Villetaneuse","Sujet : Indexation et recherche d'information sémantiques

Contexte

L'utilisation d'ontologies dans le cadre d'une recherche d'information
a pour but de dépasser les limites d'une recherche classique par mots
clés. Le Web sémantique propose une infrastructure qui permet de
mettre en place une recherche sémantique.

La vision implicite du Web Sémantique repose sur les hypothèses
suivantes :

- Il existe des ontologies formelles pour décrire objectivement les
  connaissances d'un domaine.

- Il est possible de décrire le contenu de documents en utilisant les
  concepts de ces ontologies.

- Il est possible pour l?utilisateur de rechercher l'information en
  utilisant ces mêmes concepts.

Actuellement, même s'il existe de plus en plus d'ontologies, il est
difficile de trouver une ontologie qui couvre la totalité des
connaissances d'une base documentaire et qui permettrait de ce fait
d'accéder à toute l'information contenue dans cette base. L'idée est
donc de proposer des méthodes d'indexation et de recherche
d'information qui exploitent la sémantique représentée dans une
ontologie (par opposition à la sémantique latente, LSI[1]) mais
également le texte lui-même pour ne pas être restreint par la
couverture de l'ontologie [4].

Objectifs

    * Établir un état de l'art sur les méthodes de recherche
      d'information sémantique.

    * Proposer des méthodes d'indexation qui permettent de combiner
      des modèles classiques de Recherche d'Information (e.g. modèle
      vectoriel [2]) avec l'exploitation d'une ontologie par le biais
      de mesures de proximité sémantique (e.g mesure de Wu&Palmer
      [3]).

    * Implémenter des propositions sur la base du moteur de recherche
      Lucene[5].

    * Participer à la création d'un benchmark pour une évaluation
      comparative par rapport à une recherche d'information classique.

Profil recherché

    * Intérêt pour l'IC et la Recherche d'Information
    * Autonome en informatique : connaissance d'UNIX, de Java (ou
      autre langage OO)

Conditions

Bac + 5 (Master pro ou recherche ou dernière année ingénieur) orienté
informatique

Stage de 4 à 6 mois, rémunéré.

Lieu du stage : LIPN (http://www-lipn.univ-paris13.fr/), Université
Paris 13.

Responsables

Sylvie Salotti & Haïfa Zargayouna
Pour envoyer votre candidature, envoyer un CV et une lettre ou un mail
de motivation à : sylvie.salotti at lipn.univ-paris13.fr,
haifa.zargayouna at lipn.univ-paris13.fr

Liens et références

[1] S. Deerwester, Susan Dumais, G. W. Furnas, T. K. Landauer,
R. Harshman (1990).  Indexing by Latent Semantic Analysis. Journal of
the American Society for Information Science 41 (6): 391?407.

[2] G. Salton , A. Wong , CS Yang (1975) A vector space model for
automatic indexing , Communications of the ACM, v.18 n.11, p.613-620,
Nov. 1975

[3] Z. Wu & M. Palmer (1994) Verb Semantics and Lexical Selection,
Proceedings of the 32nd Annual Meetings of the Associations for
Computational Linguistics, pages 133-138.

[4] H. Zargayouna (2005) ""Indexation sémantique de documents XML""
Thèse, Université Paris-Sud.

[5] http://lucene.apache.org/"
"59","2010-03-15","TEMIS","Paris","*Sujet de stage informatique, niveau M2 : * CRF pour l'extraction 
d'entités/relations dans des textes

*Lieu :* société Temis, Paris

La société Temis édite une solution logicielle pour traiter les
documents textuels. Elle est capable de les classer suivant leur
langue ou leur domaine, d'en extraire les « entités » importantes et
de caractériser les relations prédicatives qu'entretiennent ces
entités entre elles.

Le module d'extraction est réalisé à l'aide de règles écrites à la
main.  Ces règles sont spécifiques de la langue des documents et du
domaine sur lequel ils portent, elles peuvent donc être longues et
fastidieuses à écrire. Or, des techniques d'apprentissage automatique
existent depuis quelques années pour apprendre à extraire de
l'information à partir d'exemples (ce sujet a par exemple donné lieu à
la « shared task » de CoNLL 2003, 17 compétiteurs y ont
participé). Plusieurs approches différentes possibles peuvent être
mises en oeuvre pour cela : celles qui donnent actuellement les
meilleurs résultats sont fondées sur les CRF (Conditional Random
Fields), un modèle statistique permettant d'annoter des items lexicaux
avec des labels qui désignent les zones à extraire.

L'objectif de ce stage est de tester cette méthode sur un corpus de
documents. Différentes étapes seront donc nécessaires :

    * Il faudra dans un premier temps constituer un corpus d'exemples
      et l'annoter pour servir de base à l'apprentissage automatique.
      L'outil final de Temis peut servir à réaliser cette base, mais
      comme il ne produit pas une extraction parfaite, des stratégies
      d'amélioration de l'annotation initiale devront être envisagées.

    * Il s'agira ensuite de fixer les paramètres de
      l'apprentissage. Les CRF requièrent notamment la définition d'un
      ensemble de « fonctions features » qui caractérisent des
      configurations locales d'annotations. La définitions de ces
      features est laissée à l'initiative du programmeurs, mais des
      méthodes classiques existent pour les générer à partir des
      données annotées. Or Temis dispose aussi de ressources
      linguistiques sous la forme de dictionnaires ou de règles
      écrites à la main. Le coeur du stage sera d'étudier dans quelle
      mesure ces ressources peuvent être traduites sous la forme de
      features, de façon aussi automatique que possible.

    * Il faudra ensuite procéder à diverses expériences pour évaluer
      la qualité de l'extraction obtenue par apprentissage
      automatique, et la comparer avec celle obtenue par les règles
      écrites à la main.  Cette qualité peut dépendre grandement de la
      langue et du domaine du document, ainsi que de l'ensemble des
      features utilisées pour l'apprentissage.

Ce qui est attendu à l'issue de ce stage est la définition d'une
chaîne de traitements mèlant production manuelle de ressources et
apprentissage automatique, qui optimise la qualité de l'extraction
finale.


*Ref bibliographiques :*

Daelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.

Jousse F., Tellier I., Tommasi M., Marty P. : « Learning to Extract
Answers in Question Answering: Experimental Studies », Coria 2005,
p85-99.

Lafferty J., McCallum A., Pereira F. : « Conditional Random Fields:
Probabilistic Models for Segmenting and Labeling Sequence Data »,
actes de ICML, pages 282--289, 2001.

Poibeau, T : Extraction Automatique d'Information, Hermes, Paris,
2003.

Sutton , McCallum A : « An Introduction to Conditional Random Fields »
dans « Introduction to Statistical Learning », MIT Press, 2006.


*Compétences requises : *niveau M2 informatique, avec des
connaissances ou au moins un intérêt pour le TALN, l'extraction
d'information et l'apprentissage automatique

Le stage peut commencer dès avril pour au moins 4 mois, il est
rémunéré au tarif 1/3 Smic.

*Encadrement : *Hervé Azoulay, de la société Témis et Isabelle
 Tellier, professeur à l'université d'Orléans

Envoyer CV + lettre de motivation à *herve.azoulay@temis.com* et
*isabelle.tellier@univ-orleans.fr*."
"60","2010-06-16","LexisNexis","Paris","Stage de 3 à 6 mois - Linguiste informaticien / Terminologue

LexisNexis en France (600 collaborateurs, 139 M¤ de CA), filiale du
groupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les
services d'information professionnelle. Ses activités couvrent trois
domaines : l'information et l'édition juridiques, la diffusion de la
presse et de l'information économique et financière sur Internet, les
logiciels professionnels.

L'entreprise s'appuie sur une expertise éditoriale centenaire et sur
une technologie de pointe pour apporter au monde du droit et aux
professionnels de tous secteurs d'activités une vaste gamme de
produits et services réputés : JurisClasseur, Litec, D.O, Bottin
Administratif et les services en ligne LexisNexis.

LexisNexis vous propose de rejoindre le service Veille et management
de l'information dans le cadre d'un stage d'une durée de 3 à 6 mois

Vous interviendrez principalement sur le programme de traitement
automatique d'un thesaurus monolingue dans un but d'indexation de
contenus juridiques.

Les principales tâches seront :

- participer à l'amélioration et à l'optimisation du traitement
  automatique

- réaliser des analyses qualité et des tests de non-régression

Vous serez également amené à travailler sur l'enrichissement du
thesaurus.

COMPETENCES REQUISES :

- Très bonnes connaissances linguistiques et très bonne orthographe
- Maîtrise de l'outil informatique
- Esprit d'analyse
- Des connaissances en droit seraient un plus.

Rigoureux (se), organisé(e) et sérieux(se), vous faites preuve d'un
bon relationnel.

 
LIEU : 
141 rue de Javel
75015 PARIS

DURÉE : 
3 à 6 mois à pourvoir à partir du 15/06/2010.            

MODALITÉS :
Indemnité mensuelle de 417,09 euros 
50 % carte orange.
Convention de stage obligatoire
 
CONTACT :
Merci d'envoyer votre candidature (CV + lettre de motivation) ainsi
que vos disponibilités par mail : recrutement@lexisnexis.fr avec la
référence SLL005."
"61","2010-09-03","Cellfish Media","Paris","Cellfish Media recherche un stagiaire pour mettre en place un système
de simulation de dialogue en langage naturel dans nos architectures,
et l'implémentation de ce système dans nos services.


Dans ce cadre, vos missions principales seront :

· Le suivi de l'intégration du système de dialogue dans nos
  architectures.

· Le développement et la documentation du programme de pilotage du
  robot.

· Le calibrage du système via la définition de méthodes d'évaluation
  qualitative et quantitative du robot et via la configuration du
  service.

· La coordination de ces tâches avec les équipes technique, produit et
  marketing.

· Le suivi de projet en méthodologie agile ou traditionnelle, le suivi
  de la recette, la documentation du projet.

  Profil du candidat



   - De formation supérieure technique/scientifique/multimédia, vous
     êtes passionné par les nouveaux médias et les enjeux de
     l'utilisation de l'internet mobile.

   - Vous montrez un intérêt pour la R&D dans le domaine du dialogue
     naturel homme/machine. Avoir réalisé des projets dans ce domaine
     serait un atout important.

   - Vous avez de bonnes connaissances des sujets suivants :

- principes techniques fondamentaux de l'internet (HTML, XML,
  protocole http, SQL).

- programmation objet et UML.

   - Vous maîtrisez l'anglais tant à l'oral qu'à l'écrit.
   - Vous êtes à l'aise avec les outils de bureautique traditionnels.
   - Vous aimez travailler en équipe sur des sujets innovants, savez
     faire preuve d'autonomie et faire des propositions. Vous aimez
     rechercher des solutions avec persévérance. Enfin, vous aimez les
     environnements stimulants et possédez un esprit très créatif.


Ce stage de 6 mois à temps plein est à pourvoir dès à présent, avec
opportunité d'emploi pour candidat de valeur.

Indemnités de stage très motivantes + prise en charge à 50% du titre
de transport parisien et des déjeuners.

*Cellfish Media*

Cellfish Media* **est basée aux Etats-Unis et est présente en France,
en Allemagne et au Canada. Elle réunit plus de 320 collaborateurs.***

Cellfish Media est un acteur majeur de l'édition de services mobiles
avec plus de 14 millions de clients uniques dans le monde, notamment
en France où elle est leader. Cellfish Media produit au sein de ses
studios des contenus originaux spécifiques pour le mobile et les
diffuse auprès des consommateurs à travers un vaste réseau de sites et
services mobiles.

Elle propose par ailleurs aux médias et aux opérateurs des solutions
de marketing mobile pour monétiser leur trafic et aux annonceurs, un
outil de conquête puissant et ciblé.

*Contacts*

www.cellfishmedia.fr


 Xavier Laisney
Technical Project Manager - Cellfish Media
T: +33 1 72 59 58 15
xavier.laisney@cellfishmedia.fr
www.cellfishmedia.com"
"62","2010-09-09","Céditec","Créteil","Offre de stage

Navigation données textuelles, Textopol, Céditec
UPEC (université de Paris Est Créteil Val de Marne)

Profil recherché : Etudiant de master 2 en INFORMATIQUE/intégration 
multimédia/développement. Connaissances java et java 3D appréciées ainsi 
qu'un autre langage de programmation. La formation à la textométrie sera 
assurée sur place.

Le stagiaire aura pour mission de développer une interface de navigation 
des données textuelles basée sur un modèle d'analyse factorielle des 
correspondances (3D et mouvement) tel que décrit aux adresses suivantes :

http://textopol.free.fr/contrib2010.php 

http://textopol.free.fr/dotclear/index.php?2010/06/09/29-pour-une-textomtrie-multimdia-ou-tad-20


La maquette devra disposer d'un module de segmentation (a minima la forme 
graphique) rendant le dispositif autonome et facilement adaptable à une 
version Web de la plate forme TXM. Cette version sera développée dans un 
second temps pour compléter l'interface du site textopol.org.

http://textometrie.ens-lyon.fr/

Organisme d'accueil : Céditec, université de Paris Est Créteil Val de 
Marne (61 avenue du général de Gaulle, 94 000 Créteil)
http://ceditec.u-pec.fr/


4 mois + PFE : 2000 euros nets pour l'ensemble de la période - 
Possibilité d'un bureau et d'une machine pour les candidats de la région 
parisienne.

Une ANR sera déposée en avril pour des développements plus poussés. Si 
cette ANR est acceptée un contrat de 36 mois (2000 euros nets /mois) est 
prévu pour un développeur informatique (post doc, doctorant...)


Contact : JM Leblanc
jean-marc.leblanc@u-pec.fr

Responsable Textopol : Pierre Fiala
fiala@u-pec.fr

Directeurs du Céditec :
Caroline ollivier Yaniv
yaniv@u-pec.fr
Dominique Ducard
ducard@u-pec.fr

Date limite de réception des candidatures: 27 septembre 2010 - Envoyer CV 
et lettre de motivation par mail à 
jean-marc.leblanc@u-pec.fr"
"63","2010-09-24","Vision Objects","Nantes","Poste proposé : Stagiaire ingénieur R&D Traitement Automatique du Langage (TAL)
Type d'offre : Stage (stage conventionné)
Région : Pays de la Loire
Lieu : Nantes (44)

Entreprise

Créée en 1998, VISION OBJECTS (www.visionobjects.com) est un éditeur
de logiciels spécialisé dans la reconnaissance d'écriture manuscrite
s'appliquant aux marchés de la mobilité (Smartphone, Tablet, PC,
stylos numériques...), du formulaire, de la prise de notes, de
l'éducation et de l'automobile.  Vision Objects est leader sur ces
marchés et réalise 90% de son CA à l'international.

Missions

Rattaché(e) au Responsable R&D et en coordination avec les ingénieurs
Linguistes de la société, vous aurez comme principales missions :

- Prise en main des diverses technologies de modélisation du langage
  développées par la société (N-gram, N-class, etc)

- Elaboration d'un protocole expérimental visant à comparer ces
  diverses techniques avec leur différents compromis (back-off,
  cut-off, etc)

- Définition de critères de performance (perplexité, taux d'erreurs,
  etc)

- Mise en ½uvre du protocole sur différentes langues incluant des
  langues latines, cyrilliques, asiatiques, etc

- Analyse des avantages, faiblesses et complémentarités des diverses
  technologies

- Développement de nouvelles technologies de modélisation du langage
  visant à améliorer les performances des systèmes actuels de
  reconnaissance (e.g PCFG - Probabilistic Context Free Grammar, LSA -
  Latent Semantic Analysis)

Profil recherché

- Ingénieur R&D en TAL
- Titulaire ou en cours d'obtention d'un Master 2 en TAL
- Rigoureux(se) et investi(e), vous êtes vif(ve) d'esprit et curieux(se)
- Pratique régulière des langages scripts tel que Perl
- Solides connaissances en développement C/C++ sous environnement Visual
- Pratique et/ou connaissance de diverses langues souhaitées

Durée
A définir : minimum 4 mois
Début du stage : Ce stage est à pourvoir dès que possible
Indemnités de stage

Merci d'adresser votre CV et lettre de motivation à  job@visionobjects.com"
"64","2010-10-04","Temis","Paris","6-12 month Internship - Life Science Text Mining QA at TEMIS France

TEMIS, is a leading provider of text mining solutions in various
fields (life sciences, competitive intelligence, events, sentiment
analysis).  With a view to enhancing the life sciences package TEMIS
has opened a 6-12 month internship position in the R&D Life Sciences
department.

Main Responsibilities:

- Evaluate and report on the quality of identified biological and
  medical terms

- Evaluate and report on the quality of identified biological and
  medical relationships between terms

- Constitute and annotate a corpus in the life sciences domain

- Using this annotated corpus as reference, evaluate and report on the
  recall of identified biological and medical terms and relationships
  between them

Skills, Knowledge and Experience:

- Fluent English

- Good knowledge and understanding of biological and medical terms

- Java and text mining skills would be a plus

Location:

164 rue de Rivoli, Paris

Duration of the internship:

6-12 months

Monthly Indemnity:

417 Euros net

Please send CV and cover letter to dominique.noel@temis.com

Dr Dominique Noel
Senior Computational Linguist

TEMIS
164 rue de Rivoli 
75001 Paris - FRANCE

Tel: 01 80 98 11 36
Fax: 01 80 98 11 01

www.temis.com <http://www.temis.com/>"
"65","2010-11-12","Syllabs","Paris","Stage en linguistique informatique (ANGLAIS)
********************************************

Contexte
********

Syllabs est spécialisée en analyse sémantique et en création
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse
de données textuelles du Web : identification des pages pertinentes,
crawling du Web, extraction et catégorisation des informations clé.

Actuellement, nous recherchons un(e) stagiaire pour travailler dans le
domaine de la création automatique de textes en anglais. L'idée est de
créer des textes à partir d'une base de données existante (par exemple
la liste des informations sur une ville) ou créée en utilisant nos
outils d'analyse sur des textes crawlés du web.

Sujet du stage
***************

Développement de règles de création de textes en anglais.

Objectifs du stage
******************

La personne recrutée pour ce stage aura deux tâches principales :

1. Développement de règles de création de textes. Cette tâche implique
   une prise en main de l'outil, une formation au langage de l'outil
   et l'écriture des règles spécifiques pour différents domaines. Dans
   un premier temps, la personne sera amenée à créer des règles pour
   des textes courts. Ensuite, il lui sera demandé de créer de textes
   plus longs et de réfléchir à l'articulation des différentes parties
   (ex : choix des connecteurs).

2. Écriture des règles d'extraction d'information pour alimenter une
   base de données.

3. Enrichissement du lexique morphosyntaxique anglais utilisé dans les
   règles.

Profil souhaité
***************

- Étudiant(e) en Linguistique Informatique, Traitement Automatique des
  Langues.

- Langue maternelle anglais ou équivalent (long séjour dans pays
  anglophone, minimum 5 ans).

- Excellentes qualités rédactionnelles en anglais, goût pour
  l'écriture.

- Aptitude pour la représentation formelle du langage.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage TAL EN ».

Durée : stage de fin d'études (3 à 6 mois)
Début du stage souhaité : entre février et juin 2011.
Lieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris."
"66","2010-11-12","Syllabs","Paris","Sujet du stage : détection de concepts émergents dans un flux
multimédia

Durée : stage de fin d'études (5 à 6 mois)
Début du stage souhaité : entre février et avril 2011
Lieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris 
http://www.syllabs.com 

Mots-clés : apprentissage automatique, catégorisation, clustering,
multimédia

Contexte

Syllabs est spécialisée en analyse sémantique et en création
automatique de textes. Nos technologies apportent des solutions
d'analyse de données textuelles du Web : identification, récupération
et nettoyage des pages pertinentes, extraction et catégorisation des
informations clé.

Nous recherchons un(e) stagiaire dans le cadre du projet ANR SuMACC
auquel participent Eurecom, le Laboratoire Informatique d'Avignon et
Wikio. Le projet SuMACC (apprentissage coopératif semi-Supervisé de
concepts Multimédias pour l'Aide à la Catégorisation et la détection
de Concepts) propose d'explorer des stratégies d'apprentissage
originales pour l'identification de nouveaux concepts ou entités
multimédias à partir de patrons d'identification. Le démarrage du
projet est prévu pour la fin 2010.

Objectifs

Nous nous plaçons dans le contexte d'une base de documents volumineuse
contenant du texte, des images, de l'audio et de la vidéo. Le maintien
de la base requiert une catégorisation et une indexation des documents
dans un thésaurus par des documentalistes. Le thésaurus peut lui-même
subir des mises à jour en fonction de l'évolution du contenu de la
base (nouveaux thèmes émergents par exemple). Ces tâches sont très
coûteuses car actuellement effectuées de façon quasi-manuelle par les
documentalistes.

Le stage proposé vise à automatiser une partie de ces tâches. En
particulier, il faudra concevoir, implémenter et évaluer des méthodes
automatiques pour :

- détecter les nouvelles entrées ou concepts à ajouter au thésaurus ;

- contrôler la cohérence d'un concept du thésaurus à travers une
  mesure d'homogénéité des documents qu'il caractérise ;

- proposer aux documentalistes de nouveaux termes liés à chaque
  concept du thésaurus ;

Le point sur le ""contrôle de cohérence"" nécessite la définition d'une
ou plusieurs mesures d'homogénéité pour un ensemble de documents, en
tenant compte de leur nature multimédia. Ce stage aura pour effet
d'améliorer l'efficacité du travail des documentalistes.

La personne travaillera au sein de l'équipe R&D.

Profil souhaité

    * Ecole d'ingénieurs avec un goût pour la recherche, master 2
      recherche en informatique

    * Bonnes compétences en programmation : maîtrise de Java et Python
      souhaitée

    * Spécialisation en statistiques, apprentissage automatique,
      classification

Eléments facultatifs mais considérés comme un plus :


    * Connaissances souhaitées dans le domaine du
      Traitement Automatique des Langues

    * Maîtrise d'une ou plusieurs langues étrangères

Merci d'envoyer votre candidature à l'adresse
stage_emergence@syllabs.com ."
"67","2010-11-17","Atchik Services","Toulouse","Stage en TALN





Description du poste



Dans le cadre de la refonte de ses outils de modération automatique,

Atchik recherche un stagiaire (H/F)



 

La société



Pionnier du marketing conversationnel et de la modération, Atchik

accompagne marques et médias dans la gestion de leurs espaces

communautaires. Ses équipes traitent chaque mois près de 40 millions

de messages sur les blogs, les forums et les réseaux sociaux.



La mission



Au cour du département technique, vous contribuez au processus

d'innovation en étroite collaboration avec les ingénieurs de

développement et les autres intervenants de l'équipe (modérateurs et

community managers).



Votre mission vise l'amélioration significative des résultats de notre

système automatique de filtrage de contenu textes.



Cette tâche principale fera appel à de nombreuses compétences dans les

domaines suivants : information retrieval, computational linguistics,

machine learning, information management, matrix and graph algorithms,

large scale data mining.



- adapter des approches existantes aux contraintes spécifiques

  d'Atchik et de ses clients (nouvelle problématique de langage...)



- analyser et valoriser les données traitées manuellement par les

  équipes Atchik, identifier les problèmes,



- concevoir des solutions compatibles avec la taille des données et

  l'architecture technique, produire des prototypes, contribuer à

  l'industrialisation des solutions





Profil



Vous terminez une formation initiale ou continue de niveau master ou

diplôme d'ingénieur dans un des domaines suivants ou apparentés:



Informatique, Machine Learning, Linguistique Computationnelle,

Statistiques, Recherche d'Information etc





Compétences recherchées



- Connaissance forte en Machine Learning, Information Retrieval

(clustering, classification, test d'hypothèse)

- La connaissance de Hadoop est un gros plus.

- Une connaissance du NLP est un plus (classification de texte,

détection du spam).

- Connaissance et passion pour le monde du Web 

- Connaissance d'un ou plusieurs langages de scripts :java et perl minimum

- Connaissance des outils Linux

- Outils de développement collaboratif (SVN,test unitaires) Conception

et Développement orienté objet en Java 

- Maîtrise de l'anglais technique.

 





Si cette offre vous intéresse, merci d'adresser votre candidature (CV

+ lettre de motivation) à job@atchik-services.com en précisant la

référence [TALN] dans l'objet de votre email."
"68","2010-12-15","118712 (Orange)","Paris","Intitulé : Amélioration de la qualité des adresses sur des données
annuaire

Mission
La direction 118712 est une entité marketing en charge de la
définition, de la conception et du déploiement des offres de
renseignements annuaire d'Orange sur différents canaux (renseignements
téléphoniques, web, mobile,...).

L'annuaire comprend différentes informations reçues des opérateurs
sous des formes multiples. Ces données font l'objet de traitements
récurrents permettant de les normaliser, de les homogénéiser et d'en
extraire les informations les plus pertinentes pour renseigner les
clients de la meilleure façon possible.

L'objectif du stage est de permettre l'amélioration de la qualité des
données annuaire dans les traitements récurrents permettant
d'interpréter et de normaliser les adresses (localités, codes postaux,
rues,...).

Le stagiaire devra s'imprégner de l'existant (fonctionnement du
système de redressement d'adresses) et aura en charge la réalisation
des tâches suivantes :

- l'analyse des données
- la proposition d'améliorations avec les outils mis à disposition
- les tests qualité (non-régression et amélioration)
- la communication des évolutions
- la documentation du travail fourni

Profil recherché
Bac + 5 (Master pro ou recherche)
Spécialiste des langages formels (traitement automatique des langues,
linguistique)

Compétences
- manipulation de gros volumes de données
- maîtrise d'excel et d'outils de manipulation de bases de données
  (SQL, Access, Business Object,...)
- bonnes capacités d'analyse
- goût pour la résolution de problèmes
- rigueur
- bonne communication

Modalités
- Site de France Télécom en Ile-de-France
- 6 à 7 mois à partir de mars 2010
- Stage rémunéré

Contact
Estelle Maillebuau
estelle.maillebuau@orange-ftgroup.com"
"69","2010-12-27","EDF","Clamart","Stage Bac + 5 au centre de recherche d'EDF à Clamart (92)

Sujet : Modélisation sémantique de concepts métiers et d'opinions sur
des données textuelles « spontanées »

La R&D d'EDF met en œuvre des techniques de Text Mining pour optimiser
sa relation client, en analysant des questions ouvertes d'enquête de
satisfaction, des retranscriptions de conversations issues des centres
d'appels, et des corpus web.
La chaîne de traitement text mining (lemmatisation, extraction de
concept métier, segmentation, classement) permet ainsi de classer ces
données selon différentes thématiques et opinions. Que ces données
soient issues de l'oral (centres d'appel) ou du web (blogs, forums,
réseaux sociaux), les entrées de la chaîne text mining diffèrent de
celles classiquement traitées. Ces spécificités liées à l'expression
spontanée sont difficiles à appréhender, notamment lors de l'étape
d'extraction de concepts métiers qui repose sur une modélisation
sémantique à l'aide de lexiques et de règles. Ces règles peuvent
s'avérer peu adaptées à des données présentant des structures
différentes de celles des données textuelles classiques.  L'objectif
de se stage sera d'identifier ces différences en analysant les
différents corpus disponibles à EDF et de proposer des alternatives
aux méthodes utilisées jusque maintenant sur des données textuelles
classiques.

Profil recherché :
Bac+5, stage de fin d'étude dans le domaine du TALN.

Contact  et envoi des candidatures :
Chloé Clavel , 01 47 65 43 15, chloe.clavel@edf.fr
Anne Peradotto , 01.47.65.44.89, anne.peradotto@edf.fr
Lieu du stage :  EDF R&D,    1, av du Général de Gaulle,  92141
Clamart Cedex
Durée : environ 6 mois 
Rémunération : environ 1.000€/mois


Chloe CLAVEL
Ingénieur chercheur
EDF 
ICAME
1, av. du Général de Gaulle
92141 Clamart
 
chloe.clavel@edf.fr
Tél. : 33 (0)1 47 65 43 15"
"70","2010-12-27","CNES","Toulouse","Le service Gestion de l'information et de la connaissance a pour mission d’assurer la capitalisation et 
la valorisation des ressources informationnelles du CNES. En matière de gestion de connaissances, il assure 
la maintenance de la base de connaissances, en liaison avec les réseaux d’experts des directions opérationnelles 
et selon le plan élaboré dans le cadre de la politique de management de l’information. Il met en œuvre les 
outils et les moyens associés.
 
L’objectif général du stage est de participer au développement de méthodes d'enrichissement de l'ontologie 
utilisée pour le classement et la recherche des documents de la mémoire d'entreprise du CNES.

La mise en œuvre s'appuiera d’une part sur une plateforme dédiée qui dispose d'une capacité d'analyse de 
l'information textuelle sous la forme d'un moteur de recherche sémantique, d'une catégorisation automatique 
et des fonctions complémentaire et d’autre part, sur des outils d’analyse statistique et d’extraction terminologique.

Détails et candidature :

http://www.cnes.fr/web/CNES-fr/175-stages-cnes.php?view=item&item=6131"
"71","2010-12-27","Orange","Toulouse","Sujet de stage : Etude de l’apport des ontologies à la gestion de produits et de projets

Lieu du stage : Orange, Blagnac

Durée: de 4 à 5 mois


Les activités de Document Process Solutions  telles que la gestion de produits, la gestion de projets, 
etc. impliquent des processus complexes et faisant intervenir de nombreux composants. L’optimisation 
de ces activités nécessite une modélisation rigoureuse qui permette de matérialiser les interactions 
entre les divers composants et acteurs. Il s’agit en particulier de s’intéresser à :

- aider à la rationalisation des activités et à l'optimisation des pratiques

- permettre et faciliter la capitalisation des savoirs et savoir faire

- intégrer la gouvernance venant de l'urbanisme

L’objectif du stage est d’étudier l’utilisation des ontologies dans ce cadre. Il s’agit d’étudier la 
faisabilité et l’apport d’une représentation formelle et du  raisonnement permis par les ontologies 
dans les domaines en particulier de la gestion de produits et de projets.

Connaissances/compétences souhaitées:
- ontologies
- gestion de projets et de produits (pour comprendre le domaine)
- UML (un modèle de représentation de certaines connaissances existe en UML)

Contacts : mariajesus.diazvidana@orange-ftgroup.com ; josiane.mothe@irit.fr"
"72","2011-01-12","Xerox XRCE","Grenoble","Lien vers le texte de l'offre : 

http://www.xrce.xerox.com/About-XRCE/Internships/Developpement-d-une-interface-pour-un-systeme-d-extraction-automatique-d-opinions-en-ligne




Développement d'une interface pour un système d'extraction automatique d'opinions en ligne
Unit: Parsing&Semantics

Proposers Caroline Brun
Gilbert Rondeau
Duration: 6 mois
Start Date: January to March 2011

Description

Dans le cadre d'un projet de détection automatique d'opinion en ligne,
ce stage vise à la création d'une interface permettant la
visualisation des résultats de cette détection. Une visualisation à
base de facette (« faceted search ») est envisagée.

Cette interface serait développée en JAVA et fonctionnerait sur une
application JAVA existante qui collecte à partir des textes et stocke
dans une base de données H2 les résultats de l'extraction automatique
d'opinions.

Le stage consistera en:

   1. Définir l'interface à partir de la spécification des fonctionnalités attendues
   2. Adapter le stockage dans la base de données en fonction des spécifications
   3. Implanter cette interface (Swing ou FX, à définir) avec les fonctionnalités demandées

Lieu du stage : Meylan (XRCE)
About XRCE

The Xerox Research Centre Europe (XRCE) is a young, dynamic research
organization, which aims at creating innovative document technologies
to support growth in Xerox content and document management services
across the different Xerox businesses

XRCE: Château

XRCE is both a multicultural and multidisciplinary organization set in
Grenoble, France. Our domains of research stretch from the social
sciences to computing. We have renowned expertise in natural language
applications, work practice studies, image-based document processing,
distributed applications and knowledge management agents. The
diversity of culture and disciplines at XRCE makes it an interesting
and stimulating environment to work in, leading to often unexpected
discoveries!

XRCE is part of the Xerox Innovation group made up of 800 researchers
and engineers in four world-renowned research and technology
centres. Xerox is an equal opportunity employer. XRCE ensures equal
opportunities for all.

The ""Charte de la diversité"", adopted by Xerox, proves our engagement
in favour of cultural, ethnic and social diversity.

The Grenoble site is set in a park in the heart of the French Alps in
a stunning location only a few kilometers from the city centre. The
city of Grenoble has a large scientific community made up of national
research institutes (CNRS, Universities, INRIA) and private
industries. Stimulated also by the presence of a large student
community, Grenoble has become a resolutely modern city, with a rich
heritage and a vibrant cultural scene. It is a lively and cosmopolitan
place, offering a host of leisure opportunities. Winter sports resorts
just half an hour from campus and three natural parks at the city
limits make running, skiing, trekking, climbing and paragliding easily
available.  Grenoble is close to both the Swiss and Italian borders."
"73","2011-01-14","Orange Labs","Lannion","TECH/ACTS/FAST

Intitulé du Stage

Exploitation de connaissances pour l'analyse de textes en langage
naturel

Mission

Le but du stage est de concevoir, intégrer, expérimenter et évaluer
des méthodes de désambiguïsation sémantique dans un analyseur de texte
existant.  Ces méthodes à implémenter en langage Java consisteront
pour la plupart à générer des données linguistiques (lexique,
grammaire, contraintes et réseau sémantiques) à partir de
connaissances ontologiques gérées dans une base de connaissances
existante. Cette base est issue de la fusion de différentes sources
d'informations disponibles aux formats du web sémantique et devra en
intégrer de nouvelles en fonction des domaines d'expérimentations
choisis.

Profil

Master Pro ou Recherche en informatique (éventuellement option
Intelligence Artificielle, Traitement automatique du Langage
Naturelle)
Elève de dernière année de Grande Ecole

Compétences

Bonne connaissance en algorithmique
Bonne connaissance de Linux et du langage Java 
Bonne connaissance en Traitement Automatique du Langage Naturel
Connaissance des techniques du web sémantique (RDFS, OWL, SPARQL)

Modalités 

5 ou 6 mois : entre Avril 2011 et Septembre 2011 à Lannion (Côtes
d'Armor)

Le plus de l'offre

Intégration au sein d'une équipe de Traitement Automatique des Langues
Naturelles conduisant à la fois des travaux de recherche et des
développements opérationnels dans les portails internet et services de
communication du groupe Orange.

Utilisation de techniques innovantes pour des applications à fort
impact

Contacts :

Michel PLU, Ingénieur de Recherche, 02 96 05 36 98
michel.plu@orange-ftgroup.com"
"74","2011-01-14","Orange Labs","Lannion","TECH/ACTS/FAST

Intitulé du Stage (1-2 lignes)

Indicateurs linguistiques avancés pour la géolocalisation de textes

Mission: (5-6 lignes)

La géolocalisation de textes peut se faire selon une stratégie 'sac de
mots' où tous les indicateurs linguistiques géographiques sont pris en
compte à plat, indépendamment de leur contexte. Les objectifs de ce
stage sont : d'évaluer objectivement les performances d'un système de
géolocalisation au moyen des mesures standard de l'état de l'art sur
un corpus spécialement annoté, d'évaluer l'intérêt de l'import de
différentes sources de connaissances complémentaires, de proposer une
typologie des lieux dans un texte afin de structurer les différents
indices géographiques et distinguer, par exemple, les lieux où ont
lieu les événements, des lieux concernés ou cités dans le document.

Profil:

Master 2 Pro ou R en TAL avec des compétences en syntaxe et analyse
textuelle

Compétences

Bonne connaissances en syntaxe et analyse textuelle
Environnement Linux
Langage de scripts
Programmation en python

Modalités

6 mois : début Avril 2011 à fin Septembre 2011 à Lannion


Le plus de l'offre

Travail en équipe pluridisciplinaire


Contacts :

Emilie De Neef, Linguiste Informaticienne, 02 96 05 19 87
emilie.guimierdeneef@orange-ftgroup.com"
"75","2011-01-19","Temis","Paris","Stage M2 informatique, année 2010-2011


*Sujet du stage : * CRF pour l'extraction d'entités dans des textes

*Lieu :* société Temis, Paris 1er

La société Temis édite une solution logicielle pour traiter les
documents textuels. Elle est capable de les classer suivant leur
langue ou leur domaine, d'en extraire les « entités » importantes et
de caractériser les relations prédicatives qu'entretiennent ces
entités entre elles.

Le module d'extraction est actuellement réalisé à l'aide de règles
écrites à la main. Ces règles sont spécifiques de la langue des
documents et du domaine sur lequel ils portent, elles peuvent donc
être longues et fastidieuses à écrire et à maintenir. Or, des
techniques d'apprentissage automatique existent depuis plusieurs
années pour apprendre à extraire de l'information à partir
d'exemples. Celles qui donnent actuellement les meilleurs résultats
sont fondées sur les CRF (Conditional Random Fields), un modèle
statistique permettant d'annoter des items lexicaux avec des labels
qui désignent les zones à extraire.

L'objectif de ce stage est de tester cette méthode sur différents
corpus de documents dans différentes langues (au moins français et
anglais) et de styles variés (langue plus ou moins normalisée) et
d'étudier la robustesse des extracteurs acquis par les CRF sur ces
différents exemples. L'intégration de connaissances linguistiques
externes (dictionnaires, listes ou règles écrites à la main) dans le
modèle d'apprentissage fera partie des problèmes à envisager. Des
questions de normalisation des entités (variabilité de certains noms
propres suivant la langue du document par exemple) ou de recherche des
coréférences pourront aussi être abordées.

*Ref bibliographiques :*

Daelemans W., and Osborne M. (Eds) : Proceedings of CoNLL 2003.

Lafferty J., McCallum A., Pereira F. : « Conditional Random Fields:
Probabilistic Models for Segmenting and Labeling Sequence Data »,
actes de ICML, pages 282--289, 2001.

Poibeau, T : Extraction Automatique d'Information, Hermes, Paris,
2003.

Sutton , McCallum A : « An Introduction to Conditional Random Fields »
dans « Introduction to Statistical Learning », MIT Press, 2006.

Tellier I., Tommasi M., : « Champs markoviens conditionnels pour
l'extraction d'information », chapitre du livre « Modèle probabilistes
pour l'accès à l'information textuelle », à paraître, Hermès 2011.

*Compétences requises :* M2 d'informatique, maîtrise de Java et d'un
langage de scripts (Python, Perl...), des connaissances en
apprentissage automatique et/ou traitement automatique des langues
seraient appréciées

*Durée : * 6 mois, à commencer suivant disponibilités

*Rémunération :* 1/3 du Smic + l'équivalent de 10 tickets restaurant
par mois

*Encadrement universitaire :* Isabelle Tellier, professeure à
l'université d'Orléans

*Envoyer CV et lettre de motivation à :* christian.lautier@temis.com
et isabelle.tellier@univ-orleans.fr"
"76","2011-01-25","Lingway","Paris ou Nantes","Stage M2 informatique ou TAL

Sujet: Constitution et qualification de corpus

Durée: 6 mois, à commencer suivant disponibilité

Lieu: Paris (Porte d'Italie/Le Kremlin-Bicêtre) ou Nantes

Lingway, leader français en Traitement Automatique des Langues
propose, dans le cadre d'un projet de R&D collaborative (projet
GramLab), un stage conventionné (M2 ou équivalent).

Il s'agit de contribuer à un outillage de constitution automatique de
corpus Web et aux outils de qualification de ce corpus (typologie des
pages, des auteurs, des supports, etc). L'objectif du stage est de
tester plusieurs méthodes et plateformes, allant des outils de
collecte (crawling), de stockage en masse (S3, Big Tables, etc.)
jusqu'aux outils d'apprentissage automatique permettant la
qualification des textes.


Compétences requises:
- maîtrise de Java, de préférence complétée par la connaissance d'un
  langage de scripts (groovy, perl, python);
- des connaissances en TAL, apprentissage automatique, traitement
  distribués seront appréciées

Rémunération: 750 EUR/mois (brut) pour un stage M2

Envoyer CV + lettre de motivation à hugues.de-mazancourt@lingway.com"
"77","2011-01-25","CEA LIST","Fontenay-aux-Roses","Stage de Master 2 Recherche pouvant donner lieu à poursuite en thèse. 

Les applications qui utilisent une analyse linguistique des textes
sont nombreuses: veille stratégique, résumé automatique,
Question-Réponse, traduction automatique, etc. Pendant longtemps, à
défaut de capacités suffisantes des analyseurs linguistiques, on a
supposé que la sémantique serait très utile dans de telles
applications, sans pouvoir le vérifier expérimentalement. Désormais,
sans que ce soit un problème résolu, l'analyse syntaxique est
suffisamment performante pour pouvoir développer et exploiter des
méthodes d'analyse sémantique à échelle réelle [Clark & Harrison,
2008].

Une précédente thèse au Laboratoire Vision et Ingénierie des Contenus
du CEA LIST [Mouton, 2010] a permis d'obtenir des ressources
sémantiques en français de deux types à partir de la traduction de
ressources anglaises: une base lexicale du type WordNet (JAWS) et une
base de cadres sémantiques de type FrameNet.

Ces deux ressources ont permis de développer un outil de
désambigüisation sémantique (Word Sense Disambigation, WSD) et un
autre d'annotation en rôles sémantiques (Semantic Role Labeling). Ces
deux outils travaillent indépendamment et pourraient être utilisés
dans diverses applications. Le présent stage, conçu comme préalable à
une thèse de doctorat aura pour but de reprendre ce travail là où il
s'est terminé et d'aller au-delà, en direction d'un but ultime qui
serait une analyse sémantique complète des textes.

L'objectif sera d'étudier la complémentarité des deux outils et la
possibilité de les intégrer en un seul qui profitera des capacités de
chacun, la désambigüisation devant faciliter l'annotation en rôles et
celle-ci devant fournir des indices supplémentaires pour la
désambigüisation [Che & Liu, 2010]. Il faudra aussi étendre les
ressources apprises aux verbes et adjectifs, seul le lexique nominal
ayant été traité dans la thèse de Claire Mouton. Ce stage pourra par
ailleurs commencer l'exploration d'une partie prévue pour lé thèse,
l'exploitation de nouvelles informations syntaxiques qui aideront
l'analyse sémantique, en particulier l'intégration dans l'analyseur
linguistique LIMA du CEA LIST d'informations sur la valence verbale
par l'intermédiaire du lexique syntaxique Lefff [Sagot & Danlos, 2009]
de l'équipe Alpage (INRIA et Université Paris VII).

Références:
Wanxiang Che & Ting Liu. Jointly Modeling WSD and SRL with Markov
Logic.  Proceedings of the 23rd International Conference on
Computational Linguistics (Coling 2010), 2010.

Clark Peter and Harrison Phil. Boeing's NLP System and the Challenges
of Semantic Representation. In Proc SIGSEM Symposium on Text
Processing (STEP'08), Venice, Italy, 2008.

Mouton Claire. Ressources et méthodes semi-supervisées pour l'analyse
sémantique de texte en français, Thèse de doctorat de l'Université
Paris 11, 2010.

Sagot Benoît et Danlos Laurence (2009). Constructions pronominales
dans Dicovalence et le lexique-grammaire – Intégration dans le Lefff
. In Linguisticæ Investigationes 32(2) (pages 293-304).


Le stage se fera dans le Laboratoire Vision et Ingénierie des Contenus
du CEA LIST sous la direction de Gaël de Chalendar.

Gael de Chalendar
CEA LIST
Centre de Fontenay-aux-Roses
Laboratoire Vision et Ingénierie des Contenus
(Vision and Content Engineering Laboratory)
Bat. 38-2 ; 18, rue du Panorama ; BP 6
92265 Fontenay aux Roses Cedex ; France
Tél.:01.46.54.80.18 ; Fax.:01.46.54.75.80
Email : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr"
"78","2011-02-03","LaTTiCe et INRA-SenS","Région parisienne","Proposition de stage de niveau Master 2

=== Annotation de données textuelles pour l'analyse dynamique de blogs
===

Stage proposé par Thierry Poibeau
LaTTiCe-CNRS

et par Jean-Philippe Cointet
INRA-SenS, IFRIS, ISC-PIF, CorText


Ce stage concerne l'annotation de données textuelles pour l'analyse de
la diffusion de l'information dans des blogs. Il est lié à un projet
en cours entre l'Institut des Systèmes Complexes de Paris-Ile de
France (ISC-PIF, http://www.iscpif.fr/) et le laboratoire LaTTiCe (UMR
8094, http://www.lattice.cnrs.fr/). Ce projet, appelé BlogSem,
bénéficie du soutien de l'appel à idées 2010 de l'ISC-PIF.

*** Descriptif ***

Le web peut être vu comme un grand réseau d'individus produisant et
échangeant de l'information de façon horizontale. De nombreuses études
ont porté ces dernières années sur les dynamiques de ces nouvelles
sources d'information facilement accessibles en ligne comme les
blogs. L'analyse de celles-ci combine souvent deux points de vue
complémentaires : d'un côté les liens entre blogs forment un réseau
social dont la structure est pertinente pour décrire l'organisation
sociale de ces derniers ; de l'autre le contenu publié par les
blogueurs est également déterminant pour comprendre les dynamiques
sociales à l'½uvre dans le système et doit, à ce titre, faire l'objet
d'une modélisation sémantique aussi fine que possible (Adamic et
Glance, 2005 ; Thelwall, 2006 ; Cointet et Roth, 2009).

Le contenu des documents est le plus souvent modélisé par un ensemble
de mots-clés qui rend très imparfaitement compte du contenu sémantique
exprimé : les mots-clés sont par exemple atomiques, non liés entre
eux, et non qualifiés. Un moyen d'aller plus loin consiste donc à
essayer de modéliser plus finement le contenu sémantique. Les
techniques de traitement automatique des langues (TAL) n'ont pas
encore été employées à large échelle dans ce type d'étude alors
qu'elles sont pourtant relativement mûres (Poibeau, 2003), même si
elles produisent encore des analyses largement imparfaites. C'est le
couplage de ces deux domaines de recherche ce que nous nous proposons
d'explorer dans le cadre de cette proposition, en prenant au sérieux
la question de la caractérisation sémantique des contenus en ligne.

*** Contenu du stage ***

Le stage vise à fournir des annotations évoluées pour mieux
caractériser les contenus du web social. L'annotation pourra permettre
de déterminer les thèmes abordés, les opinions et les tendances
exprimées. L'annotation se fera évidemment au moyen d'outils
automatiques, soit à partir de lexiques et de grammaires représentés
sous forme d'automates, soit à partir de méthodes issues de
l'apprentissage comme les CRF (Conditional random Fields). Il pourra
également être nécessaire d'avoir recours à des outils d'extraction
d'information (extraction de terminologie par ex.). L'annotation
portera sur des volumes de données importants (plusieurs dizaines de
milliers de billets de blogs).

Cette modélisation sera ensuite utilisée pour permettre l'analyse des
dynamiques à l'½uvre (notamment l'évolution dans le temps des thèmes
et des opinions exprimées). Cette analyse sera effectuée par des
chercheurs de l'Institut des Systèmes Complexes qui disposent déjà
d'outils et de méthodes appropriées pour ce type de traitement. Le
stagiaire devra s'assurer, en lien avec les autres membres du projet,
que la modélisation du contenu proposée est en phase avec les besoins
d'analyse en aval.

*** Profil recherché et compétences requises ***

Profil master en traitement automatique des langues. Le stagiaire
devra avoir une expérience de l'annotation de données, des outils
appropriés et si possible avoir déjà travaillé à large échelle sur des
données réelles. Le stage demande une bonne maîtrise d'au moins un
langage de programmation permettant de manipuler facilement des
données textuelles (perl ou python par exemple) et le couplage avec
une base de données (MySQL par exemple).

*** Conditions du stage ***

Le stage se déroulera sur 4 à 6 mois, à partir du printemps 2011 en
région parisienne. Le stage donnera lieu à une gratification selon les
tarifs en vigueur (à titre indicatif, le tarif était de 417,09 euros
par mois d'après le taux fixé au 1er janvier 2010). Une poursuite en
thèse pourra être envisagée en cas d'obtention d'un financement.

*** Comment candidater ? ***

Envoyer un mail à Thierry Poibeau (prénom.nom@ens.fr) incluant une
brève présentation des motivations et des compétences en matière
d'annotation de données textuelles + un CV. Date limite de candidature
: le 14 février 2011.

*** Bibliographie ***

- Adamic and Glance. The political blogosphere and the 2004 US
  election: divided they blog. Proceedings of the 3rd international
  workshop on Link discovery (2005)
- Cointet et  Roth. Socio-semantic Dynamics in a Blog Network, IEEE,
  SocialCom Intl Conf on Social Computing, Vancouver, Canada, 2009.
- Leskovec et al. Cascading behavior in large blog graphs. SIAM
  International Conference on Data Mining (SDM 2007), 2007.
- Poibeau. Extraction automatique d'information. Hermès, Paris, 2003.
- Thelwall. Bloggers during the London attacks: Top information
  sources and topics. Proc. of the World Wide Web 2006 Workshop on the
  Weblogging, 2006."
"79","2011-02-03","VIRTUOZ","Paris","Sujet : STAGE, Intégration d'un étiqueteur syntaxique probabiliste pour
l'anglais

Durée : 4 mois

Début du stage : avril 2011

Lieu : VIRTUOZ, 32 rue Mogador 75009 Paris

VirtuOz est le leader des solutions d'Agents Virtuels dédiés à la
Relation Client. Les agents virtuels de VirtuOz sont conçus pour
dialoguer avec les clients et répondre à leurs demandes de façon
proactive et en temps réel.Avec plus de 12 millions de conversations
par mois, des clients internationaux, comme eBay, SFR, H&R Block, et
L'Oreal, s'appuient sur les solutions de VirtuOz pour optimiser leur
expérience client.VirtuOz a développé un étiqueteur syntaxique
probabiliste permettant d'optimiser les performances linguistiques des
agents. Le système a été éprouvé à grande échelle sur le français et
nous cherchons à présent stagiaire linguiste informaticien afin de
gérer la mise en place de cet étiqueteur pour l'anglais.

Description de la mission :
- Vous intégrerez l'équipe linguistique
- Vous devrez constituer un grand corpus adapté à nos besoin
- Vous entraînerez l'étiqueteur sur ce corpus
- Vous veillerez à la qualité des données en réalisant une étude
  comparative des performances des agents avant et après
  l'intégration.

Profil :
- Etudiant en linguistique informatique
- Très grande connaissance de la syntaxe, et des grammaire de
  dépendance et d'unification
- Rigueur, passion pour les nouvelles technologies, professionnalisme
  et dynamisme.
- Maitrise orale et écrite du Français et de l'Anglais.
- Connaissance des étiqueteurs probabilistes

Vous êtes intéressé? Envoyez votre candidature (CV + Lettre de
motivation) à Aurélie Cousseau : acousseau@virtuoz.com"
"80","2011-02-03","ATILF","Nancy","Offre de stage M2 ""Construction et désambiguïsation de terminologies
par des méthodes de fouille de données""

Cadre général :

- projet MSH ASTTIC (Annotation sémantique et terminologique de textes
  pour leur indexation et leur catégorisation)

- projet transdisciplinaire réunissant l'ATILF (Analyse et traitement
  informatisé de la langue française) et le LORIA (Laboratoire lorrain
  de recherche en informatique et ses applications)

Domaine : Fouille de données appliquée à la détection de termes en
texte intégral

Sujet :

La terminologie d'un domaine est une liste structurée de termes, un
terme pouvant être une unité lexicale simple ou complexe,
i.e. composée de plusieurs mots. Il est fréquent que, dans un même
domaine, nous ayons des terminologies différentes issues de
communautés aussi légèrement différentes. La question qui se pose est
donc de rapprocher les termes similaires en fonction, par exemple de
leurs usages dans les textes [1, 3, 4].

L'idée de ce projet est donc d'utiliser des méthodes de fouille de
données, notamment des méthodes de classification issue de l'Analyse
Formelle de Concepts [2], pour confronter les différents usages des
termes et les regrouper lorsqu'ils partagent des usages similaires.
Inversement, des usages différents du même terme devraient pemettre de
distinguer des sens différents d'un même terme [5]. Ainsi, il est
possible de confronter les usages d'un terme dans un domaine de
spécialité ou dans la langue générale. Si on prend l'exemple du terme
""composition"", il correspond à des concepts différents dans deux
sous-domaines des sciences du langage (syntaxe = grammaire et
morphologie = construction des mots), dans un autre domaine de
spécialité qu'est la musicologie, probablement dans d'autres domaines
encore, mais c'est aussi un nom du français courant.

Le stage comporte trois objectifs :
- Identifier et extraire des ressources textuelles les élements
  d'information qui permettront de caractériser les termes et leurs
  usages
- Proposer un modèle de données et définir la méthode de fouille de
  données la plus appropriée à la comparaison des usages
- Réaliser un prototype informatique implémentant cette méthode.

Encadrement : Evelyne Jacquey (ATILF) et Yannick Toussaint (LORIA)
Lieu : ATILF, Nancy
Rémunération : indemnités de stage (1/3 du SMIC net)
Durée : 5 mois  (février - juin ou mars - juillet)
Contact : Evelyne.Jacquey[AT]atilf.fr

Bibliographie :
[1] N. Aussenac-Gilles and D. Bourigault. The th[ic]2 initiative :
Corpus-based thesaurus construction for indexing www documents. In
Proceedings of the EKAW'2000 workshop Ontologies and texts, pages
71-78, Juan-Les-Pins, Université Paul Sabatier, Toulouse, Octobre
2000.

[2] Ganter B. and Wille R. Formal Concept Analysis, Mathematical
Foundations. Springer, 1999.

[3] D. Bourigault, N. Aussenac-Gilles, and J. Charlet. Construction de
ressources terminologiques ou ontologiques à partir de textes : un
cadre unificateur pour trois études de cas. Revue d'Intelligence
Artificielle (RIA), 18(1), 2004. Hermès.

[4] E. Jacquey, L. Kister, M. Grzesitchak, B. Gaiffe, C. Reutenauer,
M.  Valette, and O. Sandrine. Thesaurus et corpus de spécialité en
sciences du langage : une approche lexicométrique appliquée à
l'analyse de termes en corpus. In Actes de la conférence TALN2010,
Université de Montréal, Juillet 2010.

[5] G. Stumme and A. Maedche. Fca-merge : Bottom-up merging of
ontologies. In 17th International Joint Conferences on Artificial
Intelligence (IJCAI'01), pages 225-234, San Francisco, CA,
2001. Morgan Kaufmann Publishers, Inc."
"81","2011-02-03","Télécom Bretagne","Brest","Demande de stage

Service d'accueil : Telecom-Bretagne

Entreprise partenaire : Portik

Email : jacques.bregand@portik.fr <mailto:jacques.bregand@portik.fr>

Titre du stage : Application de commande vocale pour saisie de données

Durée : 5 à 6 mois

Lieu du stage : Télécom Bretagne

Profil : DNM

Compétences : informatique, modélisation, traitement du langage,
langages Java et Prolog

Encadrant : O. Grisvard

Email : olivier.grisvard@telecom-bretagne.eu 
<mailto:olivier.grisvard@telecom-bretagne.eu>

Mots clés : traitement automatique du langage naturel, grammaires
formelles, modélisation conceptuelle

Sujet :

Avec l'avènement de la téléphonie mobile, les applications de saisie
de données sont de plus en plus répandues. Dans certaines
circonstances, ces applications peuvent être contraignantes pour
l'utilisateur, ce qui peut engendrer une réticence de leur part. La
société 'Portik' a développé une application de saisie de données
adaptée aux travaux mobiles. Pour faire adhérer unmaximum
d'utilisateurs, elle propose que la saisie des données se fasse par la
voix.

De nombreux systèmes de reconnaissance vocale et de traitement
automatique de la parole existent actuellement, mais ils sont encore
sensibles aux perturbations du milieu extérieur et à la variabilité du
langage cible. Le moteur de reconnaissance envisagé pour ce projet est
le logiciel Pocket Sphinx. Des traitements complémentaires, tels que
la prise en compte du contexte de dialogue, la correction ou la
récupération d'erreurs de reconnaissance ou d'ambiguïtés lors de
l'analyse syntaxique et sémantique, viendront s'ajouter au moteur de
reconnaissance.

Au cours de ce stage, on s'intéressera plus particulièrement aux
niveaux de traitements post-reconnaissance vocale, dans le cadre d'une
plate-forme et d'outils existants pour le traitement du langage
naturel et la commande vocale, qu'il s'agira de mettre à profit pour
optimiser la performance de l'application sur smartphone.

Travail à réaliser :

Identification de la phraséologie de l'application cible en relation
avec 'Portik' et les futurs utilisateurs.

Définition du modèle conceptuel relatif à la phraséologie et
génération des ressources langagières pour les traitements
post-reconnaissance vocale.

Participation au choix définitif du moteur de reconnaissance et
configuration de l'étage de traitement linguistique du moteur retenu
pour le projet.

Support à l'intégration des traitements post-reconnaissance vocale sur
le smartphone, intégration réalisée dans le cadre d'un autre stage.

Etude et implémentation d'un générateur de formulaires de saisie
vocale permettant la configuration simple et rapide de l'application
en vue de son adaptation à d'autres utilisations.

Résultats attendus :

Chaîne de traitement et prototype de générateur de formulaires.

Rapport."
"82","2011-02-03","LIMSI","Orsay","Le groupe ILES du LIMSI propose un certain nombre de stages, pour des
étudiants de Master 1, Master 2 Recherche, Master 2 Professionnel ou
école d'ingénieur, dans le domaine de la recherche d'information, de
l'extraction d'information et des systèmes de question-réponse.

Stages de niveau M1

- Apprentissage de patrons d'extraction 
  http://www.limsi.fr/Individu/annlor/docs/stageApprentissagePatrons.pdf

- Analyse de l'évolution des noms d'événements dans les médias 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_TER_stage_evolution_ENE.html

- Extraction de relations et apprentissage 
  http://www.limsi.fr/Individu/annlor/docs/stageExtractionRelationsApprentissage.pdf

- Extraction des événements saillants dans un ensemble de textes 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_evenements_saillants.html

- Fait ou supposition ? Identification automatique du niveau de 
  certitude d'un événement 
  http://sites.google.com/site/delphinebernhard/proposition-de-stage_evaluation_certitude

- Génération de réponses avec hésitation pour un système de 
  questions-réponses 
  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_HesitationQR.pdf

- Génération de réponses qui reprennent la question pour un système de 
  questions-réponses 
  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_GeneLangueQR.pdf

- Simplification syntaxique 
  http://sites.google.com/site/delphinebernhard/sentence-simplification-internship



Stages de niveau M2

- Apprentissage de patrons d'extraction 
  http://www.limsi.fr/Individu/annlor/docs/stageApprentissagePatrons.pdf

- Pondération de graphes de dépendances syntaxiques pour la recherche 
  d'information précise 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_ponderation_graphes.html

- Comparaison syntaxique de phrases 
  http://www.limsi.fr/Individu/bg/pageWeb/stage_paraphrase.html

- Calcul de la similarité entre une question et un texte 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M2R_similarite_question_document.html

- Définition d'un contexte d'analyse des documents pour les systèmes de 
  questions-réponses 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M2R_contexte_analyse.html

- Extraction de relations et apprentissage 
  http://www.limsi.fr/Individu/annlor/docs/stageExtractionRelationsApprentissage.pdf

- Extraction de relations pour la synthèse de documents avec 
  TecKnowMetrix 
  http://www.limsi.fr/Individu/annlor/docs/StageTecKnowMetrixILEs.pdf

- Extraction des événements saillants dans un ensemble de textes 
  http://www.limsi.fr/Individu/xtannier/fr/Stages/sujet_2011_M1_evenements_saillants.html

- Fait ou supposition ? Identification automatique du niveau de 
  certitude d'un événement 
  http://sites.google.com/site/delphinebernhard/proposition-de-stage_evaluation_certitude

- Génération de réponses avec hésitation pour un système de 
  questions-réponses 
  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_HesitationQR.pdf

- Génération de réponses qui reprennent la question pour un système de 
  questions-réponses 
  http://www.limsi.fr/Individu/annegf/Enseignements/Stages/2011_Stage_GeneLangueQR.pdf

- Interface d'évaluation générique 
  http://www.limsi.fr/Individu/bg/pageWeb/stage_Genericite_REVISE.html

- Mise en évidence et utilisation de relations entre entités nommées 
  pour la fouille de texte et la recherche d'informations précises 
  http://www.limsi.fr/Individu/bg/pageWeb/stage_fouilleDeTexte.html

- Simplification syntaxique 
  http://sites.google.com/site/delphinebernhard/sentence-simplification-internship"
"83","2011-02-08","LIMSI","Orsay","Etude et modélisation des marqueurs discursifs dans un corpus oral EDF
de conversations téléphoniques client/conseiller


Responsables: 
Sophie Rosset, Ioana Vasilescu (LIMSI-CNRS) et Chloé Clavel (R&D EDF,
Clamart 92)

Ce sujet de stage porte sur l'étude et la modélisation des marqueurs
discursifs et des phénomènes dits ""disfluents"" (par . ex. les
hésitations) dans les corpus oraux d'EDF.

La R&D d'EDF met en ½uvre des techniques de text mining pour
optimiser sa relation client, en analysant des questions ouvertes
d'enquête de satisfaction, des retranscriptions de conversations
issues des centres d'appels, et des corpus web avec le but de classer
ces données selon différentes thématiques et opinions. Que ces données
soient issues de l'oral (centres d'appel) ou du web (blogs, forums,
réseaux sociaux), les entrées de la chaîne text mining diffèrent de
celles classiquement traitées. Ces spécificités sont liées à
l'expression spontanée et sont difficiles à appréhender, notamment
lors de l'étape d'extraction de concepts métiers. Parmi les événements
qui caractérisent ce type de données les phénomènes dits
« disfluents » (incluant des hésitations comme « euh » et
reformulations diverses mais aussi des marqueurs discursifs comme
« bon », « bein », « donc ») sont fréquents et soulèvent la question
de leur traitement par rapport à l'objectif principal qui est de
modéliser les concepts métiers. 

Nous voulons mettre en évidence/modéliser le fonctionnement des
phénomènes dits ""disfluents"" et des marqueurs discursifs dans les
corpus oraux d'EDF. 

Ce sujet convient à un(e) étudiant(e) en M2, intéréssé(e) par la
linguistique en lien avec les technologiques vocales, ayant ainsi un
solide bagage linguistique mais possédant également des connaissances
en traitemant automatique des langues. 



Description du stage:
Le dialogue homme/homme témoigne d'une variété de stratégies
interactionnelles où le contenu verbal d'un échange est accompagné de
nombre de phénomènes lexicaux et non-lexicaux ayant le rôle d'assurer
la gestion efficace de l'interaction : prendre la parole,
conserver/céder le tour de parole, indiquer des difficultés de mise en
mots. Les marqueurs discursifs font partie de ces événements verbaux
ayant le rôle de régulation de l'interaction. Quant aux ""disfluences""
et en particulier aux hésitations telles que ""euh"" en français, des
études ont montré leur rôle dans la recherche lexicale: les locuteurs
semblent faire appel à ces événements afin d'indiquer qu'ils se
trouvent en plein processus de mise en mots d'une information
pertinente au sein de leur tour de parole.

A titre d'exemple, des études récentes sur des corpus homme/machine
ont montré que ces événements loin d'être ""disfluents"" permettent
d'indiquer des zones d'information pertinente, susceptibles de subir
une reformulation.


Le travail de ce stage portera sur l'analyse des corpus oraux
homme/homme disponibles à EDF ainsi que sur la modélisation des
phénomènes observés. Il s'agira de mettre en évidence les différentes
fonctions des (classes de) marqueurs discursifs et hésitations dans le
corpus, de valider ces fonctions à travers une analyse statistique des
données et de définir les paramètres d'une modélisation automatique
puis de l'implémenter.

Plus précisément, les étapes de ce travail sont: (i) analyse
morpho-syntaxique de corpus (analyse, définition et extraction de
classes de marqueurs discursifs, étude et définition de contextes
d'occurences, classification automatique des marqueurs
discursifs/contextes d'occurences, exploitation d'outils d'analyse
morpho-syntaxique), (ii) validation statistique des données, (iii)
formalisation des résultats, (iv) développement d'un système de
classification des différentes classes de disfluences, (v) outil de
visualisation des documents analysés.

Références:
On the role of discourse markers in interactive spoken question
answering systems  / Vasilescu, I. ; Rosset, S. ; Adda-Decker,
M.. LREC 2010. Seventh International Conference on Language Resources
and Evaluation, Valetta, Malta : 2010. - 7p
On the functions of the vocalic hesitation euh in interactive
man-machine question answering dialogs in French /  Vasilescu, I. ;
Rosset, S. ; Adda-Decker, M.. , DISS 2010, Tokyo Japan: 2010. - 4p


Profil de la/du candidat(e): 
Ce stage s'adresse aux étudiant(e)s en M2 ayant suivi un parcours
linguistique/informatique/traitement automatique de la parole et de la
langue. Connaissances souhaitées: Linguistiques:
phonétique/morpho-syntaxe, analyse statistique de
données. Informatiques: environnement linux/unix, algorithme
d'apprentissage et de classification.


Lieu et durée du stage: 
Le stage se déroulera au laboratoire LIMSI-CNRS
(http://www.limsi.fr/Pratique/acces/), dans le groupe ""Traitement du
Langage Parlé"". La durée prévue du stage est de 5 mois (plein temps, a
partir de mars/avril 2011). Le sujet de stage peut être poursuivi dans
le cadre d'une thèse.


Rémunération: ~400 euros/mois (gratification selon les tarifs en
vigueur).

Encadrants (contacts): Sophie Rosset (rosset at limsi point fr), Ioana
Vasilescu (ioana at limsi point fr), Chloé Clavel (chloe clavel at edf
point fr)."
"84","2011-02-18","Teletech International","Saint Affrique (12)","TELETECH International

Recrute un Ingénieur Linguistique, H/F en stage rémunéré


Le groupe Teletech International est spécialisé dans la mise en place,
la gestion et l'hébergement de Centres d'Appels. Nous disposons
également d'une SSII intégrée, qui conçoit des solutions de relation
client (CRM) adaptées aux métiers des Centres d'Appels. Teletech
International est spécialisé sur les nouvelles technologies du Web
2.0, la gestion des connaissances, les solutions e-business et les
solutions mobiles.

Nos experts ont mis en place NestAvatar, un dispositif de création et
de gestion d'agents virtuels intelligents de 2ème génération, basé sur
des langages d'intelligence artificielle.

Sous la responsabilité du Directeur de Centre et du Directeur des
Développements Informatiques, vous aurez à :

Spécifier le champ de connaissances de l'agent virtuel, Enrichir le
contenu des dialogues, du dictionnaire, du référentiel, Perfectionner
la construction de dialogues de cet agent virtuel, Analyser le
comportement de l'agent virtuel à travers des outils statistiques,
Améliorer et optimiser les échanges linguistiques entre l'Avatar et
l'internaute, Proposer des solutions pour faciliter l'enrichissement
des connaissances.

Actuellement en Master Sciences du Langage spécialité TAL, vous
possédez de solides capacités rédactionnelles et d'analyse, un grand
esprit de synthèse et une bonne méthodologie.

Vous êtes proactif, vous maîtrisez les outils communautaires 2.0 et
êtes à l'écoute des tendances et des évolutions.


Horaires hebdomadaires : à définir
Rémunération : 417.06¤/mois pour un temps plein


Poste basé à SAINT AFFRIQUE
Adresser CV + photo à service.rh@teletech-int.com réf : Stage IL 0211
Ou contacter Mme Rossignol au : 03.80.60.90.61"
"85","2011-03-03","Lingway","Paris","Stage M2 TAL 

Sujet: Développement d'un analyseur de sentiment en portugais
Durée: 2 mois, à commencer suivant disponibilité

Lieu: Paris (Porte d'Italie/Le Kremlin-Bicêtre) 

Lingway, spécialiste français en Traitement Automatique des Langues
propose un stage conventionné (M2 ou équivalent).

L'objectif du stage est d'adapter au traitement du portugais les
outils d'analyse du sentiment développés à Lingway.

Les tâches à accomplir sont:


- analyse d'un corpus client à traiter,
    - couverture lexicale à prendre en compte
    - identification de marqueurs contextuels

- adpatation du système existant (règles d'extraction et lexique)
    
- intégration à une chaine d'analyse,

- tests

Compétences requises:
- portugais (brésilien de préférence)
- bonne connaissance des outils de TAL,
- langage de script (perl, Groovy), 
- bonnes capacités d'analyse,
- goût pour la résolution de problèmes,
- facilité à travailler en équipe

Stage rémunéré 450 euros brut mensuel, basé au Kremlin Bicêtre (porte
d'italie), dès que possible Envoyer CV + lettre de motivation à
cecile.potier@lingway.com

Cécile Potier 
Directrice Contenus Linguistiques
direct : +33 (0)1 58 46 12 52"
"86","2011-03-07","Semantia","Marseille","Semantia est un fournisseur de services en ligne (ASP), spécialisé
dans le traitement du langage pour l'optimisation de la gestion de la
relation client.

L'objectif du stage est de participer à l'optimisation des bases de
connaissances des applicatifs de la société pour le traitement et
l'analyse du langage.  Intégré au service de recherche et
développement, le stagiaire mettra en place un module permettant
d'améliorer le rendement de certaines règles linguistiques.  Le
stagiaire devra être en mesure de proposer des méthodes et de mettre
en place différentes solutions en situation.

Connaissances requises et/ou acquises
- Expertise linguistique
- Langages informatiques environnement web : PHP, SQL, HTML
- Bonnes connaissances des expressions régulières
- Facilité d'adaptation
- Travail en équipe
- Logique
- Rigueur

Niveau
Bac+3 minimum dans la discipline

Durée du Stage
De 3 à 5 mois.

Lieu du stage
Les Espaces de la Sainte-Baume
30, Avenue du Château de Jouques
13420 Gémenos

Contacts
- drh@semantia.com
- Tél. : 04 42 36 80 91



*Lucile PAROZ - Linguiste*

*Semantia*

*Tél. : 04 42 36 80 91 - e-mail : lucile.paroz@semantia.com*

*Agence Paris :*
63, avenue Marceau - 75116 Paris
Tél. : 09 52 27 34 54
*Siège :*
Les Espaces de la Sainte-Baume - 30, Avenue du Château de Jouques - 
13420 Gémenos
Tél. : 04 42 36 80 91 - Fax : 04 42 36 81 59
info@semantia.com - www.semantia.com"
"87","2011-03-09","MoDyCo","Nanterre","Profil du poste : développement web interface graphique

Recherche CDD ou stagiaires en ingéniérie Web pour le développement
d'un frontal web dans le cadre du projet ANR Rhapsodie
(http://rhapsodie.risc.cnrs.fr/fr/index.html , laboratoires
partenaires IRCAM, Paris ; MODYCO, Nanterre)

Objectifs : Développement d'une interface web de consultation,
visualisation et d'annotation de données orales structurées (3h
d'enregistrement audio avec la transcription et des analyses
linguistiques)

Tâche demandée : Mise en place d'une interface web permettant
d'accéder à des données audio et à des annotations sur ces données par
l'intermédiaire d'un langage de requête constitué au préalable.

Cette interface proposera :
- des formulaires de recherche s'appuyant sur un moteur existant
- la représentation graphique ergonomique des annotations à l'aide de
  différentes visualisations des données audio et textuelles
- la possibilité de réviser les annotations fournies
- des statistiques sur les données et leurs représentations graphiques
- un backoffice d'administration des données et des utilisateurs

Compétence techniques requises :

- Serveur : PHP ou un autre langage script (Python, Perl) et MySQL
- Client Web : Javascript, HTML 5

La connaissance de AJAX, Json, JQuery et SVG ainsi qu'en développement
des outils Web avec des accès réservés sera un plus. Un intérêt pour
les structures de la langue sera apprécié mais aucune connaissance
particulière en parole et linguistique n'est requise.

Le candidat collaborera avec l'équipe du laboratoire (linguistes et
informaticiens) pour formaliser les spécifications fonctionnelles de
l'application.

Lieu de travail : laboratoire MODYCO, Université de paris Ouest
Nanterre, télétravail possible avec mise à disposition d'ordinateur.

Début  : dès que possible.

Durée : stage 6 mois minimum et possibilité d'enchaîner sur un CDD
de 6 à 12 mois ou de démarrer directement sur un CDD selon profil.

Prière de contacter Atanas Tchobanov atanas@u-paris10.fr si intéressé.

Atanas Tchobanov
Ingénieur de recherche CNRS
MoDyCo UMR 7114"
"88","2011-03-31","LIPN","Villetaneuse","Articuler annotation sémantique de textes et mise à jour du modèle  
d'annotation

L'annotation de texte consiste à apposer sur le texte des informations
ou métadonnées dont la sémantique est portée par un modèle
d'annotation (formalisme et jeu d'étiquettes). Le processus
d'annotation, qu'il soit manuel, automatique ou semi-automatique
suppose qu'un tel modèle ait été défini au préalable pour spécifier le
type et la valeur des annotations que peuvent porter différents
éléments textuels. 

L'annotation sémantique obéit à la même logique avec cette spécificité
que les annotations ont pour ob jectif d'expliciter le sens porté par
le document qui est annoté. L'influence des travaux issus du web
sémantique et la maîtrise du clacul ontologique font que les modèles
d'annotation sémantique sont souvent de nature ontologique.
Cependant, le processus habituel consiste à construire un modèle puis
à annoter au regard de celui-ci et ne prévoit pas d'évolution du
modèle d'annotation, ce qui pose problème dans les cas nombreux où le
modèle doit évoluer (correction, précision, enrichissement, mise à
jour) au cours de la phase d'annotation.

Parallèlement, des outils existent pour annoter sémantiquement des
textes, de manière automatique ou manuelle, au regard d'une ontologie:
amaya, Firefox, SMORE, Gate's editor, Melita. Ces outils ne prennent
pas non plus en compte la mise à jour dynamique du modèle en cours
d'annotation et la possible réannotation du texte au regard du modèle
qui est mis à jour.

L'objet de ce stage est de formaliser ce processus de mise à jour du
modèle d'annotation au cours de l'annotation et de proposer une
méthode et des outils permettant de la gérer.

Ce travail s'intégrera dans le projet ONTORULE dont l'un des enjeux
est l'annotation sémantique de textes réglementaires et s'appuiera sur
les pratiques existantes d'annotation, à la fois manuelle et
automatique. On fera l'hypothèse que le modèle d'annotation est de
nature ontologique, même si d'autres types de modèles peuvent être
envisagés. Il s'agira

1. de recenser les types de modifications nécessaires sur la base de
   l'analyse des cas d'usage du projet ONTORULE (ajout, suppression,
   modification de certaines unités ontologique, restructuration de
   l'ontologie, modification des connaissances lexicales associées) ;

2. de définir une stratégie de mise-à-jour pour ces différents types de
   modifications ;

3. d'implémenter certaines de ces stratégies sur un outil d'annotation
   existant ;

4. de tester et d'évaluer les stratégies proposées au regard de
   l'analyse des besoins effectuées au point 1.

Ce stage sera rémunéré. Il aura lieu au LIPN, université Paris 13, à
Villetaneuse (93). Envoyer votre candidature avec CV à
Francois.Levy@lipn.univ-paris13.fr"
"89","2011-04-06","BNP Paribas","Paris","Stage conventionné pour un(e) étudiant(e) M1/M2 en Traitement
Automatique des Langues pour une durée de 6 mois (rémunéré)
pour début mai 

ENTREPRISE:  Etudes Economiques BNP Paribas (Paris)

Ce stage consiste à travailler pour un portail d'informations
économiques et financières interne ""LEOnard"" qui compte près de 13 000
abonnés et environ 2000 connexions par jour.

Destiné à l'ensemble des collaborateurs du groupe, ce portail allie
recherche d'informations et push (présentation d'informations)
toujours plus pointues et pertinentes.
Ces informations proviennent de base de données internes, de sites web
et de près de 400 articles issus de la presse quotidienne économique.
Plusieurs technologies sont utilisées dans LEOnard : Polyspot (moteur
de recherche, KB Crawl et KB Platform (outil de surveillance, de
collecte et de diffusion d'infomations provenant du web) et Temis
(text mining).  Nous recherchons donc un stagiaire de niveau master
(1ère ou 2ème année) pour travailler sur ces logiciels et nous
apporter ses compétences dans l'utilisation et les perspectives que
nous pouvons tirer de ces technologies.

MISSIONS: 

- Tests et analyse de l'outil de text-mining Temis (extractions
  d'entités nommées, concepts économiques, catégorisation automatique
  ...)

- Tests sur un outil de catégorisation automatique par secteur
  d'activité (Agro-alimentaire, Banque, Industrie ...) sur de nouveaux
  documents

- Suivi du déploiement de la mise à disposition de ce moteur de
  recherche entreprise (outil en langage naturel) auprès des
  utilisateurs, mise à jour du guide utilisateur.

- Participation aux démonstrations en interne à l'externe

COMPETENCES REQUISES: 

- Etre méthodique, autonome, rigoureux et curieux 

- Prendre des initiatives, partager ses idées et son savoir-faire et
  donc savoir travailler en équipe

- Anglais lu parlé obligatoire 

- Connaissance des langage de structuration (html, xml) et de
  développement (perl)


Merci de nous faire parvenir votre CV et lettre de motivation à M.
BERNARDINI Michel
E-mail : michel.bernardini@bnpparibas.com 
Tél. : 01.42.98.05.71"
"90","2011-04-18","Ami Software","Montpellier","*Visualisation graphique de données avec dimension temporelle*

Ami Software est une société qui développe des logiciels de veille, de
capitalisation et d'analyse de documents sur le Web. Dans le cadre de
l'analyse des documents collectés lors d'une veille, des outils de
visualisation de graphes sont utilisés depuis plusieurs années pour
représenter les concepts extraits, les sources d'informations et les
différentes relations pouvant exister entre ces éléments.

Afin de pouvoir développer ses outils de suivi de « tendance » sur le
web, Ami Software souhaite désormais ajouter une dimension temporelle
aux différents graphes proposés.


Le stage consistera à ajouter cette dimension temporelle à la
librairie de visualisation de graphes employée. Le stagiaire devra
réaliser un succinct état de l'art sur le sujet, s'accaparer le
produit existant, et enfin développer des solutions
appropriées. Il/elle pourra par ailleurs en parallèle être amené(e) à
constituer différents jeux de données, notamment à l'aide des outils
développés par Ami Software, afin de procéder à des tests en situation
réelle et ainsi mettre en avant la valeur ajoutée de la méthode.

Le stagiaire devra être à l'aise avec la programmation objet. Des
connaissances en ActionScript seraient un plus.

Le stage, d'une durée de 3 à 6 mois, sera rémunéré. Il se déroulera
dans les locaux R&D de la société, situés à Montpellier.

Pour postuler, merci d'envoyer un cv à l'adresse suivante: eal at
amisw dot com"
"91","2011-04-18","Ami Software","Montpellier","*Web temps réel : Intégration avancée de Twitter*

Ami Software est une société qui développe des logiciels de veille, de
capitalisation et d'analyse de documents sur le Web. Depuis quelques
années, on assiste à l'évolution du Web 2.0 vers le Web dit « temps
réel », qui se caractérise par la diffusion instantanée (et publique)
de l'information, notamment via des plateformes de microblogging, dont
l'exemple le plus connu est Twitter. Cette nouvelle façon de
communiquer ouvre la voie à de nouveaux traitements, comme l'analyse
en temps réel de l'évolution d'une thématique ou d'une opinion en
ligne, ce qui peut s'avérer crucial dans un cadre de veille
informationnelle.

Ami Software travaille actuellement sur l'identification, l'analyse,
la modélisation et la représentation du cheminement d'une information
ou d'une opinion sur Internet (le « buzz »). Cette étude passe par
l'analyse conjointe du contenu sémantique des documents ainsi que de
la topologie du Web, de plus en plus marquée par les réseaux sociaux
(détection de communautés en ligne, calcul d'autorité). Afin de
pouvoir améliorer ses outils de suivi de « tendance » sur le web, Ami
Software a réalisé des premières intégrations de Facebook et Twitter.

Le stage consistera à pousser plus loin l'intégration de Twitter dans
les outils de la société. Après s'être imprégné du produit existant,
le stagiaire devra réaliser un succinct état de l'art sur le sujet :
accès aux données, analyse des différents éléments pertinents à
indexer, etc.  Il s'agira enfin d'implémenter les solutions retenues.

Le stagiaire intègrera l'équipe R&D et sera notamment encadré par un
doctorant travaillant sur le sujet. Il/elle devra être à l'aise en
programmation Web, notamment en Javascript. Une bonne
connaissance/pratique des réseaux sociaux (ainsi que de leurs APIs)
serait un plus.

Le stage, d'une durée de 3 à 6 mois, sera rémunéré. Il se déroulera
dans les locaux R&D de la société, situés à Montpellier.

Pour postuler, merci d'envoyer un cv à l'adresse suivante: alu at
amisw dot com."
"92","2011-05-30","OWI Technologies","Bourg-la-Reine","Présentation de la société.

OWI Technologies est une jeune entreprise qui développe des logiciels
de Traitement Automatique du Langage Humain.

L'équipe est composée de quatre associés, ingénieurs de 45 ans
(Centrale Paris, SupElec, X-Télécom), trois docteurs et deux
ingénieurs.  Après 15 ans de recherches sur le procédé, ponctués par
un dépôt de brevet, nous avons réalisé des études de marché, puis
développé une première offre innovante sur le traitement des mails.

Confortés par nos premiers succès commerciaux, nous nous engageons à
présent dans une nouvelle phase de R&D, consistant d'une part à
renforcer les performances techniques et fonctionnelles de notre offre
existante, d'autre part à initier de nouveaux domaines (notamment sur
l'apprentissage automatique) qui permettront le développement de
nouvelles offres.

Mission.

Vous rejoignez l'équipe de Recherche & Développement pour améliorer le
dictionnaire des proximités sémantiques (synonymes) en langue
française.  Plusieurs stages sont à pourvoir.

Profil recherché.
Etudiant de langue maternelle française.

Compétences techniques.
Connaissance de Microsoft Excel.
Esprit d'analyse.

Conditions pratiques.
Lieu : Bourg-la-Reine (92)
Type de contrat : stage conventionné.
Durée : 1 ou 2 mois.
CV et lettre de motivation à stages@owi-tech.com"
"93","2011-06-01","Exalead","Paris","Descriptif du stage
--------------------------------
Exalead, entreprise du groupe Dassault Systèmes, est un fournisseur de
logiciels de recherche et d'accès à l'information en entreprise et sur
le Web.

Nous recherchons un stagiaire dans le cadre d'un projet de mise en
place d'un service de veille sur internet.
Après une revue de l'état de l'art, le stagiaire élaborera un système
de désambiguïsation lexicale capable de s'adapter à du vocabulaire non
présent dans les dictionnaires traditionnels. Pour parvenir à cette
fin, il s'orientera très probablement vers des modèles d'espaces de
mots.


Compétences
-----------------------------
- Traitement automatique des langues
- Programmation (C++, Java, python)


Mots-clés
-----------------------------
sémantique, espaces de mots, désambiguïsation lexicale, induction de
sens, calcul vectoriel


Références
-----------------------------
Patrick Pantel and Dekang Lin. 2002. Discovering Word Senses from
Text.  In /Proceedings of ACM SIGKDD Conference on Knowledge Discovery
and Data Mining 2002/. pp. 613-619. Edmonton, Canada. [PDF
http://webdocs.cs.ualberta.ca/%7Elindek/papers/kdd02.pdf][PS
http://webdocs.cs.ualberta.ca/%7Elindek/papers/kdd02.ps]

Jean Véronis/. HyperLex: lexical cartography for information
retrieval.  Computer Speech & Language/ In Word Sense Disambiguation,
Vol. 18, No.  3. (July 2004), pp. 223-252. [PDF
http://www.google.com/url?sa=t&source=web&cd=1&ved=0CBgQFjAA&url=http%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fdownload%3Fdoi%3D10.1.1.66.6499%26rep%3Drep1%26type%3Dpdf&rct=j&q=HyperLex%3A%20lexical%20cartography%20for%20information%20retrieval&ei=oMrjTZftJo_E8QON7aWfBw&usg=AFQjCNFIIryl6QLmhPc6btcI-_7WQCshHw&cad=rja }

Eneko Agirre et Philip Edmonds, editeurs. Word sense disambiguation -
algorithms and applications. Springer, 2007 [PDF
http://www.wsdbook.org/wsdbook-ch1.pdf]


Durée
-----------------------------
6 mois


Claire Mouton
Research Engineer
Tel : +33 1 55 35 27 39
Fax : +33 1 55 35 26 27
Claire.Mouton@exalead.com <mailto:Claire.Mouton@exalead.com> 	Exalead

10 place de la Madeleine - 75008 Paris, France
fr.exalead.com/software <http://fr.exalead.com/software>"
"94","2011-06-27","Lingway","Paris","Sujet: Evaluation de ressources et Développement d'un analyseur de
sentiment en chinois
Durée: 6 mois, à commencer suivant disponibilité

Lieu: Paris (Porte d'Italie/Le Kremlin-Bicêtre)

Lingway, spécialiste français en Traitement Automatique des Langues
propose un stage conventionné.

L'objectif du stage est d'adapter au traitement du chinois les outils
d'indexation/recherche et d'analyse du sentiment développés à Lingway.

Les tâches à accomplir sont:
- évaluation du système existant,
- définition d'un bouquet de sources de presse générale en chinois
- analyse d'un corpus client à traiter:
-- couverture lexicale à prendre en compte
-- identification de marqueurs contextuels
-- implémentation dans le système existant (règles d'extraction et
   lexique)
- intégration à une chaine d'analyse,
- tests

Compétences requises:
- chinois (mandarin de préférence)
- bonne connaissance des outils de TAL,
- langage de script (perl, Groovy),
- bonnes capacités d'analyse,
- goût pour la résolution de problèmes,
- facilité à travailler en équipe

Stage rémunéré 450 euros brut mensuel, basé au Kremlin Bicêtre (porte
d'italie), dès que possible.
Envoyer CV + lettre à hugues.de-mazancourt@lingway.com"
"95","2011-10-17","Université d'Artois","Arras","Offre de stage conventionné (Master TAL)

Intitulé du stage :     « Traitement automatique de corpus bilingues »

Lieu du stage :         Université d'Artois, pôle d'Arras

                        Centre de recherche : « Grammatica » (EA 4521)


http://www.univ-artois.fr/recherche/unites-de-recherche/grammatica

Durée :                 3 mois TC (ou 6 mois TP)

Début du stage :        1er novembre 2011

Gratification :         417,09 ¤/mois (temps complet)



Descriptif :

Dans le cadre d'un projet de constitution de corpus bilingues, le Centre
de recherche Grammatica de l'Université d'Artois propose un stage de
trois mois à temps complet (ou éventuellement, de six mois à temps
partiel) dans le domaine du TAL. Le(la) candidat(e) doit être en mesure
d'effectuer de façon autonome les tâches suivantes :


- récupération de textes au format .txt

- vérification de textes récupérés au format .txt (correction
  typographique et orthographique)

- analyses linguistiques automatiques (segmentation, étiquetage)

- formatage et structuration à la norme TEI (balisage XML standardisé)

- alignement

- vérification manuelle d'alignements automatiques (français-anglais/
  anglais-français)



Une bonne connaissance d'outils TAL et une bonne maîtrise de l'anglais
écrit sont indispensables.



Les candidats intéressés sont priés d'envoyer leur CV accompagné d'une
lettre de motivation à Mr Dejan STOSIC à l'adresse :
dejan.stosic@univ-artois.fr pour le 21 octobre 2011 au plus tard."
"96","2011-10-23","Syllabs","Paris","Offre de stage :  Analyse et génération de descriptifs produits
(Syllabs)

------------------------------------------------------------------------

------------
Contexte
------------

Syllabs est spécialisée en analyse sémantique et en création automatique
de textes. Nos technologies sont le fruit d'années de développement et
maîtrisent toutes les étapes du processus d'analyse de données
textuelles du Web : identification des pages pertinentes, extraction et
catégorisation des informations clé.

Actuellement, nous recherchons un(e) linguiste francophone pour un stage
dans le domaine de la création automatique de textes en français (langue
maternelle uniquement). L’idée est de créer des descriptifs de lieux ou
de produits à partir d’une base de données existante (par exemple la
liste des caractéristiques d’un produit).

----------------------------
Description du poste
----------------------------

Les tâches principales concernent:

- Écriture de règles de génération automatique de descriptifs de
  produits et de lieux.

- Règles d’extraction d’information sur ces produits et lieux.

--------------------
Profil souhaité
--------------------

- Langue maternelle français.

- Excellentes qualités rédactionnelles en français, goût pour
  l’écriture.

- Aptitude pour la représentation formelle du langage.

- Excellente capacité de communication et aptitude pour le travail
  d’équipe.

- De bonnes connaissances de l’allemand, portugais ou néerlandais
  seraient un plus.

Diplôme et expérience

- Formation en cours : Master en Traitement Automatique des Langues ou
  similaire.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en indiquant
dans l'objet du mél « Stage génération FR ». 

Lieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris.

Contrat : stage conventionné rémunéré en fonction du niveau d’étude."
"97","2011-10-25","Télécom Bretagne","Brest","Sujet du stage M2 (5-6 mois) : Un langage contrôle pour les Instructions
Nautiques du SHOM

Responsables : Yannis Haralambous (Télécom Bretagne / Lab-STICC),
Georges Dubois (SHOM)

Laboratoire d'accueil : Télécom Bretagne http://www.telecom-bretagne.eu
et Lab-STICC, pôle CID, équipe DECIDE http://www.lab-sticc.fr/

Les langages contrôlés sont des langages artificiels utilisant un
sous-ensemble du vocabulaire, des formes morphologiques, des
constructions grammaticales et des interprétations sémantiques d’une
langue naturelle (dans notre cas : le français). En quelque sorte ils
constituent le pont entre les langages formels et les langues
naturelles. De ce fait, ils remplissent la fonction de communication du
médium texte tout en étant rigoureux et analysables par la machine sans
ambiguïté.

En particulier, ils peuvent être utilisés pour faciliter l’alimentation
de bases de connaissances, dans le cadre d’une interface homme-machine
au moment de la saisie du texte.

Le Service Hydrographique et Océanographique de la Marine (SHOM) publie
depuis plusieurs années les Instructions Nautiques, un recueil de
renseignements généraux, nautiques et réglementaires, destinés aux
navigateurs. Ces informations complètent les cartes marines. Elles sont
obligatoires à bord des navires de commerce et de pêche.

L’Organisation Hydrographique Internationale (OHI) a publié des normes
spécifiant l’échange de données liées à la navigation et notamment un
modèle universel de données hydrographiques (norme S-100, janvier 2010).

Le but de ce stage est d’élaborer un langage contrôlé qui couvre les
besoins des Instructions Nautiques et qui permette l’alimentation de
bases de connaissances conformes à la norme S-100. Comment faire évoluer
le langage selon les évolutions des ontologies concernées et
l'alimentation de la base de connaissances ?

Dans le contexte d’une thèse CIFRE, deux applications seront envisagées
: (a) une interface homme-machine qui analyse en temps réel le texte
saisi par l’opérateur des Instructions Nautiques et qui valide son
appartenance au langage contrôlé ; (b) un outil semi-automatique de
traduction des documents existants dans le langage contrôlé.

Ce stage se concentrera sur la faisabilité d’un langage contrôlé qui
satisfasse les deux contraintes : exploitation optimale du contenu
traditionnel des Instructions Nautiques et adéquation avec la norme
S-100. Un prototype de langage sera élaboré, accompagné des algorithmes
d’extraction de connaissances et d’alimentation d’une base de
connaissance conforme à la norme S-100.

Ce stage est proposé en collaboration avec le SHOM.

Pour candidater : envoyer LM+CV à 
yannis.haralambous [ à ] telecom-bretagne.eu"
"98","2011-11-10","Semantia","Marseille","Semantia est un fournisseur de services en ligne (ASP), spécialisé
dans le traitement du langage pour l'optimisation de la gestion de la
relation client.

Objectif du Stage :

L'objectif du stage est de réaliser une étude qualitative et
stratégique sur l'histoire et les technologies du traitement
automatique du langage naturel et écrit.  Le stagiaire devra mettre en
place des méthodes ainsi que des outils d'extraction et d'analyse des
données ciblées par l'étude, en collaboration avec l'équipe
linguistique et de développement.

Connaissances requises et/ou acquises :

Expertise linguistique
Langages informatiques environnement web : PHP, SQL, HTML
Bonnes connaissances des expressions régulières
Facilité d'adaptation
Travail en équipe
Logique
Rigueur

Niveau :
Bac+3 minimum dans la discipline

Durée du Stage :
De 3 à 5 mois.

Lieu du Stage :
PACA, 13420 Gémenos

Contacts :
drh@semantia.com
Tél. 04 42 36 80 91"
"99","2011-11-21","Syllabs","Paris","Objet : Stage recherche à Syllabs

Lieu : Syllabs, 15 rue Jean-Baptiste Berlier, 75013 Paris

Durée : 5 à 6 mois

Début du stage souhaité : entre janvier et avril 2012



Sujet du stage

Extraction automatique d'objets et d'attributs en domaine spécialisé

Mots-clés

extraction d'information, extraction d'attributs, moteur de recherche,
web

Contexte

Syllabs est spécialisée en analyse sémantique et en création automatique
de textes.
Nos technologies sont le fruit d'années de développement et maîtrisent
toutes les étapes du processus d'analyse de données textuelles du Web :
identification des pages pertinentes, crawling du Web, extraction et
catégorisation des informations clé.
Dans le cadre d'un projet de recherche, Syllabs développe des méthodes
pour construire de manière semi-automatique des moteurs de recherche
verticaux thématiques (i.e. politique, astronomie, ...) et souhaite les
enrichir de connaissances du domaine extraites (semi-) automatiquement.

Objectifs

Contrairement aux moteurs de recherche généralistes, les moteurs de
recherche thématiques sont centrés sur un domaine et peuvent tirer parti
de cette verticalité pour réaliser des analyses fines sur leurs
documents.
Nous nous intéressons, dans le cadre de ce stage, à la découverte
d'objets d'un domaine et de leurs propriétés (attributs/valeurs) à
partir d'un ensemble de documents et de connaissances minimalistes
(quelques objets+attributs du domaine).

Illustration (astronomie)
 - objets : terre, mercure, mars
 - caractéristiques : diamètre, volume, distance du soleil...

Les méthodes utilisées durant ce stage seront centrées sur le traitement
automatique des langues et l'apprentissage statistique.  La personne
recrutée travaillera au sein de l'équipe R&D.

Profil recherché
    * École d'ingénieurs avec un goût pour la recherche, Master 2
      recherche en informatique
    * Bonnes compétences en programmation : maîtrise de Python et/ou
      Java
    * Connaissances en traitement automatique des langues

Éléments facultatifs mais considérés comme un plus
    * Connaissances en recherche d'information
    * Connaissances en apprentissage statistique
q
Merci d'envoyer votre candidature à l'adresse
stage_extraction_objets@syllabs.com"
"100","2011-12-19","ELDA","Paris","ELDA (Evaluation and Language resources Distribution Agency, 
www.elda.org <http://www.elda.org/>) a pour activités principales la 
distribution et la production de ressources linguistiques, ainsi que 
l'évaluation de technologies de la langue.

Dans le cadre de ses activités de production, ELDA offre 1 stage de
concepteur de documents textuels illustrés (H/F).

Contexte

ELDA participe à un projet visant à évaluer les systèmes d'analyse
automatique des documents écrits. Pour les systèmes en compétition, il
s'agit de répondre automatiquement aux questions suivantes :

  * Comment le document est-il structuré (zones de texte, images...) ?

  * Quelles sont les écritures présentes, avec leur type
    (manuscrit/dactylo) et leur langue (Français, Anglais, Arabe, autre)?

  * Quelles sont les informations principales du documents (auteur,
    destinataire, objet, date...) ?

Afin de disposer de données pour l'évaluation des systèmes d'analyse
automatique, des documents originaux sont collectés. Rédigés par des
volontaires (rémunérés) sous une identité fictive qui leur est
attribuée, ces documents se basent sur des scénarios fictifs et des
modèles de documents crées par ELDA (formulaires, bon de commande, page
de catalogue, tract politique ou commercial, carte de voeux,
en-têtes...).

Une fois collectés, ces documents font l'objet d'une description
manuelle de leur contenu, afin de pouvoir comparer l'analyse automatique
des systèmes avec les performances humaines.


Mission

Sous la responsabilité du chef de projet, le candidat réalisera les
modèles de document nécessaires à la rédaction des documents à
collecter. Les modèles peuvent être :

  * des fichiers images que les volontaires devront imprimer puis
    compléter manuellement ;

  * des fichiers .doc ou .ppt à compléter électroniquement (saisie au
    clavier) avant impression ;

  * des lettres-types au format image guidant la rédaction de courriers
    manuscrits ou dactylo.

Selon ses compétences, le stagiaire pourra également intervenir sur
d'autres aspects du projet, comme la maintenance du site web de collecte
(php/mySQL), la validation des documents collectés, ou encore leur
annotation (i.e. la description des documents via un logiciel dédié).


Profil recherché

  * Formation universitaire ou ingénieur

  * Maîtrise de l'édition sous Word et Powerpoint

  * Compétences en traitement d'image (Gimp/Photoshop, gestion des
    formats)

  * Qualités rédactionnelles : orthographe, grammaire, inspiration
    (invention des scénarios fictifs)

  * Un bon niveau d'anglais et/ou d'arabe constitue un plus (afin de
    réaliser/décliner les modèles dans les 2 autres langues du projet,
    le français étant la langue principale).

Durée : Stage long (4 mois minimum)

Ce stage, basé à Paris-13e (RER Cité universitaire), est à pourvoir
avant le printemps 2012.

Les candidatures (CV, lettre de motivation) doivent être adressées à
Matthieu Carré (carre@elda.org). Elles seront étudiées à partir de
janvier 2012."
"101","2011-12-19","Scan-Research","Paris","SCAN-research

Proposition de stage pour un info-linguiste (niveau Master II)

Stage dans une société innovante d'étude et d'analyse de la conversation
des Internautes

1. Présentation de la société et du secteur d'activité

Scan-research est une jeune start-up créée en août 2010, spécialisée
dans l'observation et l'analyse de l'opinion des Internautes. 

Nous sommes aujourd'hui hébergés par l'incubateur d'entreprises
innovantes Agoranov (incubateur créé par UPMC, Paris IX-Dauphine, ENS,
Paris tech) ; nous avons reçu le soutien d'Oséo et de la Mairie de Paris

  - Nos clients sont de grandes entreprises du luxe (LVMH...), de l'énergie
    (EDF, ERDF...) et des administrations.

  - Nous avons conclu un partenariat avec de grands titres de presse
    pour suivre les évolutions de la conversation des Internautes durant
    les élections présidentielles.


Nous sommes à la recherche d'étudiants motivés, curieux et autonomes
pour nous accompagner dans la réalisation de nos études et de nos
missions de veille et d'analyse sur la conversation des Internautes, à
l'aide de notre plateforme propriétaire.

Les tâches qui vous seront confiées seront (entre autres) les suivantes :

- Construire les ontologies en fonction desquelles seront catégorisées
  les conversations observées

- Rédiger les descripteurs linguistiques de ces ontologies selon les
  méthodologies que nous avons développées

- Interagir avec les développeurs de notre plateforme, et les
  concepteurs du moteur de TAL avec lequel nous travaillons


2. Profil

Vous êtes infolinguistes, avec : 

- une bonne connaissance des problématiques du Traitement Automatique
  des Langues Naturelles

- Une connaissance des problèmes liés à la constitution d'ontologies
  appliquées à la réalité sociale

- Une bonne culture générale notamment en matière de sociologie, ne
  nuira pas ; un intérêt pour les questions de formation de l'opinion et
  de sémantique politique sera apprécié. 

- Une pratique courante de l'anglais est un requis


Nous cherchons des candidats à la fois rigoureux, imaginatifs,
intéressés à  participer à l'élaboration de méthodologies innovantes en
matière de mise en ½uvre des techniques de linguistiques appliquées aux
sciences sociales et au marketing.

3. Modalités pour postuler

Envoyez votre candidature par mail à gilles.achache@scan-research.net

4. Déroulement du stage

Salaire : à négocier
Lieu du stage : Paris (boulevard Raspail)
Durée : 6 mois / 12 mois (possibilité de transformer le stage en premier
        emploi en cas de réussite)
Date de démarrage :     15 janvier 2012"
"102","2012-01-03","LIMSI","Orsay","Stage M2 : Détection de réactions et de promesses dans les articles de
presse.


Mots-clés : traitement automatique de la langue, classification,
événements 

Contexte

Entre autres objectifs, le projet ANR ChronoLines a pour but de créer
de façon semi-automatique des chronologies à partir de dépêches
d'agences. Étant donnés un thème fourni par l'utilisateur et un
ensemble de textes, il s'agit de retrouver dans les documents les
événements les plus importants concernant ce thème, puis de les
ordonner et de les présenter à l'utilisateur pour validation. Par
exemple, pour une demande sur un nom de personne, le système devra
retracer les événements marquants de sa vie. Pour les négociations de
paix au Moyen-Orient, les principales dates importantes s'y
rattachant.

Un point intéressant se rattachant à ce projet est le fait que de
nombreux événements sont sujets à :

    * Des projections dans le futur : promesses d'un homme politique
      ou d'une entreprise, prévisions, annonces diverses, etc.

    * Des réactions de personnalités : par exemple, un attentat
      important sera condamné par les gouvernants du monde entier, une
      décision politique d'envergure sera à la fois louée et critiquée
      par de nombreuses personnes, etc.

Ces aspects sont intéressants à deux titres. Tout d'abord, un
événement sujet à de nombreuses réactions pourra être qualifié
d'""important"", et donc aura plus de chances d'apparaître dans une
chronologie thématique. D'autre part, ajouter à ces chronologies des
liens vers les promesses faites au sujet d'un événement, ou vers
l'ensemble des réactions qu'il a suscitées, pourrait apporter une
fonctionnalité appréciée des utilisateurs.


Travail à réaliser :

Durant ce stage, on utilisera un corpus de plusieurs années de
dépêches d'agence, composant une base très importante d'événements et
de déclarations de toutes sortes. L'objectif du stagiaire sera de :

    * Parcourir la littérature scientifique sur le sujet
      (classification de texte notamment).

    * Réaliser un système permettant de décider si un article ou une
      partie d'un article représente une promesse faite par une
      personne ou une organisation, ainsi qu'une réaction à un
      événement ayant eu lieu auparavant (et d'indiquer à quel
      événement la réaction correspond).

Le stagiaire devra avoir de bonnes compétences en informatique et en
traitement automatique de la langue.

Durée : 4 à 6 mois

Niveau : Master 2 (professionnel ou recherche)

Contacts :

Veronique.Moriceau[at]limsi.fr

Xavier.Tannier[at]limsi.fr"
"103","2012-01-03","EDF","Paris","Proposition de stage opérationnel en Text-Mining

Depuis le 1er juillet 2007, le marché de l'électricité est entièrement
ouvert à la concurrence et permet au consommateur de choisir librement
son fournisseur d'énergie. Dans ce contexte, il est devenu stratégique
pour EDF de comprendre les besoins de ses clients, mais également
d'expliquer et de prédire leur comportement.

Le Domaine Analyse de la Connaissance Client au sein du Département des
Systèmes d'Information de la Branche Commerce a, pour partie, la mission
d'analyser les différents systèmes d'information d'EDF et notamment les
données textuelles présentes dans ses bases. Actuellement, nous
utilisons des techniques de Text Mining pour analyser automatiquement
des commentaires et notamment des réclamations de clients provenant de
nos différents SI. 

Le stage que nous proposons est opérationnel et va comprendre plusieurs
axes :

La création de cartouches d'extraction de connaissances (Technologie
Skill Cartridge développée par la société TEMIS) permettant à la fois
d'améliorer et de repérer des concepts métier, mais également de
contribuer à l'amélioration de nos modèles de classement.

Une étude portant sur la comparaison des résultats obtenus en Text
Mining sur l'analyse des commentaires « réclamation » avec les
informations rentrées manuellement par le conseiller.

La mise en place d'un processus d'industrialisation plus léger,
permettant, non pas d'analyser l'intégralité des champs commentaires,
mais un échantillon représentatif de nos clients. 

Le stage aura une durée de 6 mois et se déroulera dans la tour EDF à la
Défense au cours de l'année 2012. Le stagiaire sera rémunéré.  

Le profil recherché est un étudiant de niveau BAC +5 spécialisé en
Traitement Automatique du Langage. De bonnes connaissances linguistiques
et informatiques sont indispensables. Des connaissances statistiques ou
des outils développés par TEMIS seraient un plus apprécié. 

Les candidatures (CV + lettre de motivation) sont à envoyer à
anne-laure.guenet@edf.fr."
"104","2012-01-03","GEOLSemantics","Paris","-------------------------------
Stage fin d'études pré-embauche : Ingénieur Développement

Avant-vente: Authentification forte grâce à la voix

La société :

La société GEOLSemantics est une société française basée à Paris et qui
compte une quinzaine de personnes.
Elle a pour vocation de proposer des solutions logicielles pour aider à
la détection et au tracking d'activités hostiles envers les Etats, les
entreprises et les personnes. Ces solutions s'appliquent à l'information
contenue dans les différents média : texte, audio et vidéo.
Elles utilisent des algorithmes sophistiqués d'analyse sémantique
multilingue pour permettre aux opérationnels de disposer d'une
information synthétique représentant la connaissance extraite des
différentes sources d'information.
Elles utilisent également des technologies d'avant-garde
d'identification de locuteur dans les médias audio ou vidéo.

Sujet du stage 

GEOLSemantics recherche un stagiaire bac +5 en informatique pour la
réalisation d'un prototype `authentification forte de locuteur'
utilisant nos outils de biométrie vocale.
Intégré(e) au sein d'une équipe à taille humaine, vous aurez la
possibilité de vous épanouir dans le monde de la sécurité renforcée et
de la lutte contre l'usurpation d'identité.

Contenu du stage :

Le but de ce stage est de réaliser un prototype pour appuyer la vente de
nos solutions de biométrie vocale. L'objectif est d'améliorer la
sécurité d'accès des applications grâce à l'identification vocale du
locuteur. Cette authentification forte vient en complément des méthodes
classiques basées sur un login/mot de passe.

Déroulement du stage :
-	Choix et mise en place de l'architecture,
-	Elaboration de scenarii,
-	Développement de l'infrastructure du prototype,
-	Développement d'une application sous Androïd pour la mise à
        disposition du prototype sur mobile,
-	Test et présentation aux avant projets client.

Vos capacités d'autonomie, vos aptitudes à vous exprimer et à rédiger
vous permettront rapidement d'être responsable de la réalisation et du
suivi complet de vos travaux sous la conduite d'un ingénieur
expérimenté.

Profil du stagiaire :

Compétences techniques requises :

-	Master 2 ou ingénieur en informatique 
-	bonnes connaissances en Java Web (notion de HTML/CSS)
-	des connaissances en Androïd (ou capacité à acquérir ces
        connaissances rapidement)
-	capacité à appréhender un domaine nouveau (biométrie vocale)
-	Maîtrise du XML et de RDF

Qualités requises : Bon rédactionnel. Forte curiosité fonctionnelle,
forte autonomie

Le stage est placé sous la responsabilité du responsable avant-vente

-	Durée : 6 mois minimum
-	Début du stage : dès que possible
-	Lieu : Paris 15ème
-	Indemnités : à débattre

Candidature à adresser  (CV, lettre de motivation, photo) à :
Emmanuel Dupont, Directeur des Opérations 
Société GEOLSemantics
32,  rue Brancion
75015 Paris
emmanuel.dupont@geolsemantics.com
Site WEB : en cours de construction

----------------------------------------

Stage fin d'études pré-embauche : Ingénieur Développement
Module d'élaboration de règles linguisitiques

La société :

Basée à Paris, GEOLSemantics est une jeune entreprise innovante qui
développe et commerciale des logiciels de traitement automatique du
langage naturel pour satisfaire des besoins de veille stratégique. Les
applications sont multiples et principalement centrées sur la détection
automatique de menace, de rumeur ou d'opinion à partir de l'analyse
systématique des documents multi-lingues publiés sur le WEB, dans les
sites, les blogs, les forums ou les réseaux sociaux.

Sujet du stage

GEOLSemantics recherche un stagiaire bac +5 en informatique pour la
réalisation de son module d'élaboration de règles linguistiques de haut
niveaudestinée à extraire des connaissances structurées exprimées dans
une ontologie. Intégré(e) au sein d'une équipe à taille humaine, vous
aurez la possibilité de vous épanouir dans le monde du Web 3.0 sur des
technologies J2ee (Portlet sous Liferay, Java).

Contenu du stage :

Actuellement, l'écriture de règles linguistiques nécessite une expertise
pointue sur notre moteur de traitement. GEOLSémantics souhaite mettre à
disposition de ses ingénieurs et de ses partenaires un SDK d'assistance
à l'écriture de règles linguistiques. Le but de cet outil est
d'augmenter la productivité en interne et de faciliter la prise en main
de notre progiciel par des intervenants extérieurs.

A partir du cahier des charges, vous devrez comprendre le besoin
fonctionnel pour rédiger les spécifications fonctionnelles et mettre en
place rapidement une première maquette. Après validation auprès des
utilisateurs finaux, vous aurez la responsabilité de développer et
livrer le SDK.

La décomposition des activités est la suivante : 60% de spécification :
compréhension du besoin, des langages manipulés par les linguistes, du
métier du Web 3.0; 40% de développement en Java (exécutable intégré à
notre moteur sémantique et IHM).

Vos capacités d'autonomie, vos aptitudes à vous exprimer et à rédiger
vous permettront rapidement d'être responsable de la réalisation et du
suivi complet de vos travaux sous la conduite d'un ingénieur
expérimenté.

Profil du stagiaire :

Compétences techniques requises :
- Capacité à appréhender un domaine nouveau (le Web sémantique)
- Base algorithmique sur les automates 
- Bonnes compétences en Java
- Maîtrise du XML et de RDF

Qualités requises : Bon rédactionnel. Forte curiosité fonctionnelle
Langue : Anglais exigé

Le stage est placé sous la responsabilité du Directeur des Opérations

-	Durée : 6 mois minimum
-	Début du stage : dès que possible
-	Lieu : Paris 15ème
-	Indemnités : à débattre

Candidature à adresser  (CV, lettre de motivation, photo) à :
Emmanuel Dupont, Directeur des Opérations 
Société Cadège/GEOLSemantics
32,  rue Brancion
75015 Paris
emmanuel.dupont@geolsemantics.com
Site WEB : en cours de construction

---------------------------------------------
Stage fin d'études pré-embauche : Ingénieur Développement

Algorithme de clustering

La société :

Basée à Paris, GEOLSemantics est une jeune entreprise innovante qui
développe et commerciale des logiciels de traitement automatique du
langage naturel pour satisfaire des besoins de veille stratégique. Les
applications sont multiples et principalement centrées sur la détection
automatique de menace, de rumeur ou d'opinion à partir de l'analyse
systématique des documents multi-lingues publiés sur le WEB, dans les
sites, les blogs, les forums ou les réseaux sociaux.

Sujet du stage

GEOLSemantics recherche un stagiaire bac +5 en informatique pour la
réalisation d'un algorithme de clustering. Intégré(e) au sein d'une
équipe à taille humaine, vous aurez la possibilité de vous épanouir dans
le monde du Web 3.0.

Contenu du stage :

De façon à évaluer la qualité des outils de regroupement d'information
concernant des personnes (comme 123people), la communauté scientifique a
organisé plusieurs compétitions internationales (campagnes WEBS). A
partir d'un ensemble de textes qui concernent des personnes avec des
homonymes (personnes différentes de même nom), une première phase
consiste à regrouper les documents parlant de la même personne par des
technologies de clustering et dans un deuxième temps pour chaque cluster
qui concerne une seule personne (les homonymes étant sensé avoir été
distingués par le clustering) on extrait un certain nombre d'information
concernant la personne (date et lieu de naissance, adresse, téléphone,
diplômes, ...).

La société GEOLSemantics a développé des traitements linguistiques
automatiques qui permettent d'identifier dans les textes les éléments
significatifs et d'extraire des informations concernant les personnes.
En s'appuyant sur les outils existant dans la société, il est demandé au
stagiaire de développer un algorithme de clustering qui s'appuiera sur
les résultats de l'analyse linguistique des textes décrivant les
personnes.  Ensuite de compléter les règles d'extraction des
connaissances pour extraire de chaque cluster les informations demandées
par la campagne d'évaluation WEBS. Les résultats pourront être comparés
aux résultats obtenus pas les participants aux campagnes précédentes.

La langue de la campagne étant l'anglais, il est demandé au stagiaire
d'avoir une maîtrise de cette langue.

Vos capacités d'autonomie, vos aptitudes à vous exprimer et à rédiger
vous permettront rapidement d'être responsable de la réalisation et du
suivi complet de vos travaux sous la conduite d'un ingénieur
expérimenté.

Profil du stagiaire :

Compétences techniques requises :

Profil demandé :

- Master 2 ou ingénieur en informatique ayant une connaissance en
  traitement automatique des langues.
- Goût de la compétition (il faut sortir de meilleurs résultats que les
  autres). Les résultats pourront faire l'objet d'une publication
  scientifique.
- Capacité à appréhender un domaine nouveau (le Web sémantique)
- Bonnes compétences en Java
- Maîtrise du XML et de RDF

Qualités requises : Bon rédactionnel. Forte curiosité fonctionnelle
Langue : Anglais exigé

Le stage est placé sous la responsabilité du Directeur Scientifique

-	Durée : 6 mois minimum
-	Début du stage : dès que possible
-	Lieu : Paris 15ème
-	Indemnités : à débattre

Candidature à adresser  (CV, lettre de motivation, photo) à :
Emmanuel Dupont, Directeur des Opérations 
Société Cadège/GEOLSemantics
32,  rue Brancion
75015 Paris
emmanuel.dupont@geolsemantics.com
Site WEB : en cours de construction"
"105","2012-01-04","EDF R&D","Clamart","Stage Bac+5 : Evaluation d'outils text mining pour la connaissance
client - le cas des données web

Lieu du stage : EDF R&D, 1, av du Général de Gaulle, 92141 Clamart

Contexte : stage de R&D en collaboration avec la branche Commerce d'EDF
- Direction des Système d'Information- Domaine Analyse de Connaissance
Client- Département Analyse Client

Sujet :

L'analyse des opinions des clients en tant que consommateurs mais aussi
en tant que citoyens est une problématique au c½ur des préoccupations
d'EDF, depuis l'ouverture du marché de l'énergie. De quoi se plaignent
les clients ? Quel est l'impact d'une nouvelle offre sur la satisfaction
? Quelle est l'ampleur du phénomène « Green Attitude » ? Comment est
perçu le nouveau compteur communicant? La R&D d'EDF développe depuis
2002 des techniques de text mining destinées à analyser les opinions
exprimées par les clients dans les questions ouvertes d'enquêtes de
satisfaction, et les réclamations des clients provenant de nos
différents Systèmes d'Information. Ces technologies ont été transférées
au niveau opérationnel à la branche commerce d'EDF avec laquelle nous
travaillons en étroite collaboration. L'activité de la R&D se focalise
actuellement sur l'adaptation de ces techniques sur d'autres sources ou
supports d'information et notamment sur les données issues du web. Ce
dernier type de données pose un certain nombre de problèmes liés à leur
caractère bruité (usage de smileys, fautes d'orthographes, abréviations,
etc.).

L'objectif de ce stage sera d'évaluer trois outils d'analyse automatique
de données textuelles existants, dont l'outil LUXID de la société TEMIS
utilisé actuellement à EDF. Le stagiaire aura pour mission de prendre en
main ces outils de les comparer selon les critères suivants :

- La pertinence de leurs sorties sur un corpus issus du Web2.0
  d'expressions d'opinions autour d'EDF.

- L'architecture logicielle, l'ergonomie et les fonctionnalités de ces
  outils.


Profil recherché :
Bac+5, stage de fin d'étude dans le domaine du TALN.
Compétences en informatique et en TAL
Programmation : perl ou équivalent

Contact  et envoi des candidatures :

Chloé Clavel, 01 47 65 43 15, chloe.clavel@edf.fr

Durée : environ 6 mois

Rémunération : environ 900¤ net /mois

      Chloe CLAVEL
      Ingénieur chercheur
      EDF
      ICAME
      1, av. du Général de Gaulle
      92141 Clamart

      chloe.clavel@edf.fr
      Tél. : 33 (0)1 47 65 43 15"
"106","2012-01-09","IGN","Saint-Mandé (94)","Extraction de règles de conception de cartes d'un corpus de la
cartographie

Mots clés
TAL, informatique, gestion des connaissances, cartographie

Contexte

Le laboratoire COGIT de l'Institut national de l'information
géographique et forestière (IGN) étudie les problématiques liées à
l'utilisation de données topographiques pour la fabrication de produits
(cartes géographiques, lot de données) ou de services répondant à des
besoins particuliers, spécifiés par les utilisateurs de ces produits.
Ce stage a pour objectif d'extraire les règles de conception de cartes
telles qu'elles sont décrites dans un corpus textuel de la cartographie,
disponible dans une version électronique. Ce corpus a été formé à partir
de sources différentes : un manuel de cartographie utilisé dans une
école d'ingénieurs topographes qui détaille particulièrement la
fabrication de cartes topographiques et des notes de cours de différents
enseignements en cartographie de l'université, ciblé sur les cartes
thématiques.

Nous nous intéressons particulièrement aux règles de conception de la
carte, l'ordre des étapes, les concepts (en relation avec l'ontologie de
la cartographie OntoCarto) sur lesquels s'appuient ces modes opératoires
et leurs articulations, les principes de représentation (en relation
avec la base de règles OntoCartoRules). Pour l'extraction des règles,
sera mis en oeuvre l'outil SEMEX, une plateforme d'exploration
sémantique et d'aide à l'acquisition de règles métiers candidates
développée à Paris 13.

Ce stage est co-encadré par les laboratoires COGIT de l'IGN et LIPN
(Laboratoire d'informatique de Paris Nord) à Villetaneuse.

Sujet

L'objectif du stage est d'identifier les règles de conception d'une
carte (topographique ou thématique) et de réécrire ces règles dans un
formalisme plus rigide compatible avec la base de connaissances déjà
construite.

Pour ce travail, il faudra préciser la notion de règle dans ce corpus ;
reconnaître les variations de vocabulaire autour des noms des concepts
du domaine ; repérer les indices de désambiguïsation propres à ce corpus
; définir les marqueurs spécifiques au corpus qui annoncent la
définition de règles et le caractère plus ou moins impérieux de cette
règle. En effet certaines règles sont essentielles à la compréhension de
la carte par le lecteur, d'autres correspondent plus à des habitudes ou
des préférences du concepteur. L'objectif final est d'identifier les
structures des phrases correspondant, pour ce corpus, à des règles et si
possible leur impériosité et leur portée, en particulier déterminer si
la règle s'applique à toutes les cartes ou plus spécifiquement à une
carte topographique ou à une carte thématique.

L'ontologie OntoCarto intègre déjà les concepts correspondant aux
travaux sur les variables visuelles réalisés par Bertin sur lesquels
sont fondées les règles de la sémiologie cartographique.

Bibliographie

Bertin, J. (1967). Sémiologie graphique : les diagrammes, les réseaux,
les cartes.

Dominguès, C., S. Christophe, et L. Jolivet (2009). ""Connaissances
opérationnelles pour la conception automatique de légendes de
cartes"". 20èmes Journées Francophones d'Ingénierie des Connaissances
(IC'2009), Hammamet, Tunisie.

Dominguès, C., O. Corby, et F. Soualah-Alila. ""Raisonner sur une ontologie cartographique
pour concevoir des légendes de cartes"". 12e Conférence Internationale Francophone sur
l'Extraction et la Gestion de Connaissance (EGC'2012), 31 janvier - 3 février, Bordeaux,
France (à paraître).

manuel d'utilisation de SemEx :
http://www-lipn.univ-paris13.fr/~guisse/ontorule/SemEx/SemEx_Manual.pdf

Compétences particulières et formation requise

Ce stage s'adresse aux étudiants de master 2 ou de 3ème année d'école d'ingénieurs
avec une spécialisation en informatique ou en traitement automatique du langage
naturel.

Lieu du stage
IGN/laboratoire COGIT
73 avenue de Paris
94165 Saint-Mandé Cedex
métro : Saint-Mandé - ligne 1
Durée et rémunération
durée : 5 à 6 mois
début : mars/avril 2012
rémunération : 30% du SMIC
Prolongements éventuels

Le COGIT propose chaque année des sujets de thèse ainsi que des stages
de postdoctorant.

Responsable du stage
Catherine Dominguès
IGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex
tél : 01 43 98 85 44 mél : catherine.domingues@ign.fr

Le stage est co-encadré par : François Lévy
LIPN, Institut Galilée, Avenue J.B. Clément, 93430 VILLETANEUSE
tél : 01 49 40 35 78 mél : Francois.Levy@lipn.univ-paris13.fr

Pour candidater
Le dossier de candidature sera envoyé par mail. Il devra se composer
d'un curriculum vitae et d'une lettre de motivation, accompagnés des
relevés de notes des années de M1 et M2 (ou deux dernières années
d'école d'ingénieurs) et d'une description des enseignements suivis (un
lien vers le site internet de la formation est le bienvenu).

Catherine Dominguès
Laboratoire COGIT/Service de la recherche
T +33 (0)1 43 98 85 44
catherine.domingues@ign.fr
IGN - INSTITUT NATIONAL DE L'INFORMATION
GEOGRAPHIQUE ET FORESTIERE
73 AVENUE DE PARIS
94165 SAINT-MANDE CEDEX
http://recherche.ign.fr/cogit


L'INSTITUT NATIONAL DE L'INFORMATION GÉOGRAPHIQUE ET FORESTIÈRE EST NÉ
LE 1ER JANVIER 2012
DE LA FUSION DE L'INSTITUT GEOGRAPHIQUE NATIONAL ET DE L'INVENTAIRE
FORESTIER NATIONAL."
"108","2012-01-16","Lexis Nexis","Paris","LexisNexis en France (600 collaborateurs, 140 M¤ de CA), filiale du
groupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les
services d'information professionnelle. Ses activités couvrent trois
domaines : l'information et l'édition juridiques, la diffusion de la
presse et de l'information économique et financière sur Internet, les
logiciels professionnels. 


L'entreprise s'appuie sur une expertise éditoriale centenaire et sur une
technologie de pointe pour apporter au monde du droit et aux
professionnels de tous secteurs d'activités une vaste gamme de produits
et services réputés : JurisClasseur, Litec, D.O, Bottin Administratif et
les services en ligne LexisNexis.  


Mission :

Intégré(e) à l'équipe « Management de l'information» votre mission
consistera à participer aux activités relatives au textmining, qui
traitent de l'extraction d'information juridique à valeur ajoutée.


Profil :

Master 2 en linguistique, avec de bonnes connaissances en TAL.

Vous êtes d'une nature rigoureuse et méticuleuse. Une sensibilité pour
l'étude du langage juridique serait un plus.

Niveau d'étude :

Master 2, stage de fin d'étude.

LIEU : 
141 rue de Javel

75015 PARIS

DUREE : 

5-6 mois à partir de février 2011

MODALITES:
Indemnité mensuelle de 417,09 euros 

50% carte orange.
Convention de stage obligatoire

CONTACT :

Merci d'envoyer votre candidature (CV + lette de motivation) ainsi que
vos disponibilités par mail : celine.aubier@lexisnexis.fr"
"109","2012-01-16","CEA-LIST","Palaiseau","Proposition de stage de Master 2 (6 mois)

Extraction faiblement supervisée de relations entre entités à une large
échelle

CEA LIST, Laboratoire Vision et Ingénierie des contenus, Nano-Innov
(Palaiseau)
Encadrants: Olivier Ferret et Romaric Besançon


CONTEXTE

Le sujet de stage proposé se situe dans le domaine de l'extraction
d'information. Celle-ci a pour objectif de repérer automatiquement dans
des textes les entités caractéristiques d'un domaine ainsi que les
relations intervenant entre ces entités, ceci dans le but d'alimenter
une base de connaissances ou une base de données.

À titre d'exemple, pour le passage :
""With a father from Kenya and a mother from Kansas, President Obama was
born in Hawaii on August 4, 1961.""
une telle extraction donne le résultat suivant si l'on s'intéresse aux
données de naissance d'une personne :
Lieu_naissance : bornIn(President Obama, Hawaii)
Date_naissance : bornOn(President Obama, August 4, 1961)

OBJECTIFS

Le stage se situe plus précisément dans le cadre de l'extraction de
relations à large échelle, c'est-à-dire opérant sur de larges ensembles
de textes (plusieurs millions) et se focalisant sur un grand nombre de
types de relations (plusieurs dizaines). Compte tenu de ce cadre, la
ligne directrice est l'adoption d'une approche faiblement supervisée :
au lieu d'apprendre des modèles de relations à partir de corpus annotés
manuellement, le principe est de prendre comme point de départ des
relations issues d'une base de connaissances et de projeter ces
relations dans un corpus selon un processus d'annotation non supervisée
pour construire des exemples d'apprentissage automatiquement. Le
laboratoire LVIC du CEA LIST a déjà mis en ½uvre une telle approche dans
le cadre de l'évaluation KBP (Knowledge Base Population) de la campagne
TAC (Text Analysis Conference).

Le stage se situera dans le prolongement de ce travail en développant la
problématique de l'apprentissage faiblement supervisé de relations et
plus particulièrement de l'utilisation de données d'apprentissage
bruitées. Deux problématiques seront abordées dans cette optique :

- le filtrage des relations extraites, que ce soit pour la construction
  des exemples d'apprentissage ou l'extraction finale des relations, en
  s'appuyant notamment sur des méthodes d'apprentissage statistique ;

- l'extension de l'ensemble des exemples pour une relation par
  l'exploitation de données issues du Web. L'objectif est ici d'acquérir
  à partir d'exemples sondes de nouvelles formulations d'un type de
  relations ou des paraphrases de formulations déjà rencontrées.

COMPÉTENCES REQUISES
    - niveau M2 (ou ingénieur) en Informatique avec une spécialisation
      en Traitement Automatique des Langues
    - langages C++, Python

Le stage sera rémunéré et se déroulera au centre Nano-Innov du CEA, à
Palaiseau.


Les candidats intéressés par ce stage sont invités à prendre contact
avec Olivier Ferret (olivier.ferret@cea.fr) ou Romaric Besançon
(romaric.besancon@cea.fr) en envoyant un CV et une lettre de motivation."
"110","2012-01-16","CEA-LIST","Palaiseau","Proposition de stage de Master 2 (6 mois)

Développement de ressources linguistiques pour l'extraction d'événements
dans le domaine financier

CEA LIST, Laboratoire Vision et Ingénierie des contenus, Nano-Innov
(Palaiseau)

Encadrants: Romaric Besançon et Nasredine Semmar

Le stage se situe dans le contexte de l'extraction d'information,
domaine dont l'objectif est d'identifier des événements ou faits dans
des textes, et de structurer les informations retenues. Le stage se
situe plus précisément dans le cadre d'un projet sur l'extraction
d'événements dans le domaine financier, pour des textes en langues
anglaise et arabe (une seule de ces langues ou les deux seront traitées
dans le cadre du stage selon les connaissances du stagiaire). La
spécification des événements à extraire est définie sous la forme d'une
ontologie. Les événements concernent par exemple les changements de
personnel dans une entreprise, les évolutions d'indicateurs financiers,
les mentions de transactions financières.

Le stage se situera dans le prolongement du travail déjà réalisé dans le
cadre de ce projet, et consistera à développer les ressources
linguistiques nécessaires pour la reconnaissance des événements.

Plus précisément, les événements sont reconnus en deux étapes:

- la reconnaissance des entités nommées relatives aux événements (par
  exemple, les noms des entreprises ou des personnes concernées etc.),
  ainsi que des autres entités spécifiques typées associées aux
  événements (par exemple, les montants, les produits financiers etc.)

- l'association des différentes entités relatives à un même événement
  dans une structure commune de formulaire (ou template) associant
  chaque entité retenue à un rôle dans l'événement : par exemple, une
  personne mentionnée est celle qui quitte un poste et une autre
  personne est celle qui arrive dans le poste.

Les méthodes pour la reconnaissance des entités nommées et des
événements reposent sur l'utilisation de patrons lexico-syntaxiques
s'appuyant sur les résultats d'un outil d'analyse linguistique des
textes.
Le travail du stagiaire consistera à développer ce type de ressources
pour la reconnaissance des événements financiers, en s'appuyant sur le
système d'analyse linguistique existant et sur les modèles de patrons
existants. Ce travail pourra également porter sur l'amélioration
générale du traitement linguistique (analyse morpho-syntaxique et
syntaxique), si la reconnaissance des événements est limitée par la
qualité de l'analyse existante.

Profil

- niveau Master M2 informatique ou linguistique, connaissances en
  traitement automatique des langues

- Maîtrise de l'anglais, la connaissance de la langue arabe est un plus

Le stage sera rémunéré et se déroulera au centre Nano-Innov du CEA, à
Palaiseau.

Les candidats intéressés par ce stage sont invités à prendre contact
avec Romaric Besançon (romaric.besancon@cea.fr) ou Nasredine Semmar
(nasredine.semmar@cea.fr) en envoyant un CV et une lettre de motivation."
"111","2012-01-16","CEA-LIST","Palaiseau","Choral est un système de résumé automatique mono-document par extraction
développé au LVIC, industrialisé et mis à la disposition des 3000
utilisateurs de l'IRSN [1]. Choral repose largement sur l'analyseur
linguistique multilingue du laboratoire, LIMA [2]. Actuellement, Choral
se contente d'extraire verbatim les phrases du document source qu'il
juge les plus pertinentes selon plusieurs critères (sens des mots les
plus représentés dans le document, expressions exprimant le point de vue
de l'auteur, présence de syntagmes nominaux complexes, ...).

Le but du stage sera d'améliorer la lisibilité des textes produits de
deux manières:

- en exploitant la résolution de coréférences dont LIMA est
  capable. LIMA sait détecter les référents des pronoms: dans les
  phrases ""Nathan va à la bibliothèque. Il va rendre ses livres."", LIMA
  sera capable de détecter que ""Il"" réfère à ""Nathan"". Or, actuellement,
  Choral n'exploite pas cette information, pouvant éventuellement
  n'extraire que la deuxième phrase, ce qui ne permet pas de savoir au
  lecteur qui est le ""Il"" en question. Le stagiaire modifiera Choral
  pour prendre en compte cette information déjà présente dans les
  résultats de l'analyse linguistique ;

- en générant du texte permettant de synthétiser les idées principales
  situées entre les phrases retenues pour l'extraction. Cette partie
  part de la constatation qu'une phrase extraite peut perdre son intérêt
  hors de son contexte, et ce même si les idées qu'elle porte sont très
  importantes pour le texte. Il s'agira donc de réfléchir à des moyens
  de regénérer ce qu'il faudra pour rendre ce contexte intelligible. Ce
  pourra être la génération de mots-clés, le repérage et l'extraction
  des définitions de ce dont il est question dans l'extrait, etc.

Le stage se déroulera de la manière suivante:

- prise en main des outils et du code ;
- implémentation de l'exploitation des coréférences et évaluation ;
- en parallèle, bibliographie orientée sur la deuxième partie
  (génération...)  ;
- proposition de solutions pour la deuxième partie ;
- implémentation des propositions effectuées.

Le stage se déroulera dans les nouveau locaux du LVIC situés à NanoInnov
à Palaiseau (près de Polytechnique, Sup'Optique, Thales et Danone).

Durée du stage : 6 mois
Formation souhaitée : Ingénieur/Master 2

Gael de Chalendar
CEA LIST
Laboratoire Vision et Ingénierie des Contenus
(Vision and Content Engineering Laboratory)

CEA SACLAY - NANO INNOV
BAT. 861
Point courier 173
91191 GIF SUR YVETTE

Tél.:+33.1.69.08.01.50Fax:+33.1.69.08.01.15 
Email : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr"
"112","2012-01-16","CEA-LIST","Palaiseau","Stage Bac+5 : Alignement de mots à partir de corpus de textes parallèles
pour la construction et la mise à jour de dictionnaires multilingues

Lieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie
des Contenus (LVIC), 91 191 Gif sur Yvette

Sujet :

Les dictionnaires bilingues constituent les principaux composants des
systèmes de traduction automatique et de recherche d'information
interlingue. La masse de travail nécessaire pour créer manuellement les
dictionnaires bilingues est importante. C'est la raison pour laquelle
depuis quelques années de nombreuses approches de construction
automatique de ces dictionnaires ont été proposées.

L'objectif de ce stage sera, d'une part, de constituer un corpus de
référence de textes parallèles multilingues, et d'autre part, d'évaluer
les principaux composants du module de construction et de mise à jour de
dictionnaires bilingues développé au Laboratoire Vision et Ingénierie
des Contenus du CEA LIST.

Ce stage comportera les étapes suivantes:

- Appropriation des principaux composants du module de construction et
  de mise à jour de dictionnaires bilingues.

- Constitution d'un corpus de référence composé de textes parallèles
  multilingues.

- Mise en place d'outils d'évaluation du module d'alignement de mots
  simples et complexes.

- Spécification et implémentation d'un module de nettoyage des
  dictionnaires bilingues construits ou mis à jour automatiquement.

Profil recherché :

Bac+5, stage de fin d'étude dans le domaine du Traitement Automatique de
la Langue (TAL).

Compétences en informatique et en TAL

Programmation : C++, Perl ou équivalent

Langues : Maîtrise de l'anglais et du français, la connaissance de la
langue arabe est un plus

Contact  et envoi des candidatures :

Nasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr

Durée : 4 à 6 mois

Nasredine SEMMAR

CEA Saclay Nano-INNOV
Institut CARNOT CEA LIST
Laboratoire Vision et Ingénierie des Contenus (LVIC)
Point courrier n°173
91 191 Gif sur Yvette CEDEX
Tel: +33 (0)1 69 08 01 46
Fax: +33 (0)1 69 08 01 15
Email: nasredine.semmar@cea.fr"
"113","2012-01-23","LIMSI","Orsay","Proposition de stage M2R (fouille de données et parole)

Contact : Sophie Rosset (rosset@limsi.fr)

Lieu : LIMSI - CNRS, bat 508, BP 133, 91403 Orsay Cedex, groupe
Traitement du Langage Parlé

Titre : Fouilles de données appliquées à des données audio : erreurs et
entités nommées

Contexte 
Ce stage de M2 s'inscrit dans les domaines du Traitement Automatique des
Langues (TAL) et de la Parole (TAP) ainsi que celui de la fouille de
données. Nous nous intéressons plus particulièrement à la
caractérisation des erreurs d'un système de transcription de la parole
dont les sorties sont utilisées par un système de reconnaissance
d'Entités Nommées. Il s'agit de mettre en place une méthode permettant
de classifier et de caractériser les erreurs de plusieurs systèmes de
transcription de la parole en quantifiant leur impact sur un (ou
plusieurs) systèmes de reconnaissance d'Entités Nommées. Cette méthode
devra être généralisable à d'autres types d'applications comme la
traduction automatique ou un système de dialogue homme/machine.

Sujet

Les systèmes de reconnaissance de la parole sont évalués en utilisant le
taux d'erreurs de mots (WER ou Word Error Rate) qui considère chaque mot
comme ayant une importance égale. Or on constate que cette métrique
d'évaluation ne permet de mesurer la difficulté qu'aura un système
d'extractions d'information. Autrement dit, si on applique un même
système de détection d'entités nommées sur deux sorties de système de
reconnaissance ayant pourtant un même WER, le taux d'erreur du système
de détection d'entités nommées sera différent.

L'objectif de ce stage est donc de caractériser les erreurs d'un système
de reconnaissance de la parole en fonction d'une tâche de détection
d'entités nommées et de l'impact qu'ont ces erreurs.

Nous nous focaliserons au cours de ce stage sur la parole journalistique
en utilisant les données d'une campagne d'évaluation récente. Cette
campagne a mis en évidence une très grosse perte de résultats des
systèmes de reconnaissance d'entités nommées sur des sorties de système
de reconnaissance automatique de la parole (30% de perte) [1].

Les sorties de trois systèmes de transcription seront étudiées. Leur
impact devra être étudié sur au moins un système d'identification
d'Entités Nommées également fourni par le LIMSI. Ces systèmes sont à
l'état de l'art et pourront donc servir de première référence.

[1] Olivier Galibert; Sophie Rosset; Cyril Grouin; Pierre Zweigenbaum;
Ludovic Quintard. Structured and Extended Named Entity Evaluation in
Automatic Speech Transcriptions. IJCNLP 2011
(http://aclweb.org/anthology-new/I/I11/I11-1058.pdf)

Informations pratiques

Le stage, d'une durée de 5 mois, se déroulera au LIMSI, dans le groupe
Traitement du Langage Parlé et le stagiaire recevra une gratification
(de l'ordre de 480 euros/mois)."
"114","2012-01-25","IMS","Puteaux","Stage rémunéré de traitement automatique de langage naturel (TAL)

1. Cadre général

IMS Health est un partenaire privilégié des plus grands laboratoires
pharmaceutiques mondiaux et une entreprise de référence en matière de
traitement de données de santé/médicament.

Les bases de données des dossiers patients constituent une des forces
incontournables d'IMS. En France, la base Disease Analyzer (TM) contient
plus de 5 millions de patients dont certains suivis depuis l'an
2000. Cette base comporte des informations provenant du dossier
patient des médecins membre d'un panel représentatif et comprend les
diagnostics, les traitements et les caractéristiques des patients. Une
partie des informations est saisie sous forme de texte libre. Cette
partie pourrait contenir des informations d'une grande valeur sur les
résultats d'examens biologiques, orientations diagnostiques, consignes
de traitement ou encore des données sur l'observance
thérapeutique. IMS souhaite mettre en place un outil de traitement de
langage naturel (TAL) permettant le codage et la structuration de ses
données en commençant par les résultats d'examens de laboratoire.

2. Contenu du stage

Les données sont hébergées chez IMS et dans une base SQL
Server. L'objectif est d'examiner un corps de textes courts (quelques
mots à quelques phrases) saisi par les médecins dans les dossiers
patients afin détecter, codifier et structurer les informations
pertinentes: 

Dans un premier temps on cherche à examiner chaque corps de texte dans
le contexte du dossier patient pour comprendre son orientation globale
et pour le classifier selon son thème : examen clinique, imagerie,
données d'observance, décision thérapeutique, justification
diagnostique, etc.

Dans un deuxième un travail exploratoire sera réalisé autour
d'architectures pour le Traitement Automatique de la Langue (UIMA,
GATE, OpenNLP) et en fonction de leur intérêt pour structurer ces
données.

Dans un troisième temps, le stagiaire développera un programme
informatique (en Java) permettant de structurer et codifier au mieux
l'information pour une des catégories (examens laboratoire).

3. Profil

- Etudiant en informatique avec notamment des connaissances en bases
  de données

- Forte motivation, rigueur et esprit d'équipe

- Connaissance du langage médical ou une expérience précédente de TAL
  sera un plus.

4. Localisation et encadrement

Le stagiaire sera encadré par IMS et sera en contact avec un
laboratoire d'informatique médicale (LIM&BIO). D'une durée de 6 mois,
il se déroulera dans les locaux d'IMS (Puteaux, 92). En fonction des
besoins, des déplacements au laboratoire seront possibles.

5-Rémunération

Selon le profil, pouvant aller jusqu'à 1000 euros par mois.

6-Contact

Dr Massoud TOUSSI, MD, PhD
Medical Director, Health Economics & Outcomes Research
IMS Consulting Group
91, rue Jean Jaurès
92800 PUTEAUX
France
Tel: +33 (0)1-41 35 13 35
Fax: +33 (0)1-41 35 13 49
email: mtoussi@imscg.com
http://www.imsconsultinggroup.com"
"115","2012-02-01","ALPAGE","Paris","======================================== 
Stage Bac+5 : Analyse textuelle de scripts de films pour améliorer le
repérage d'actions dans les vidéos de ces films
=========================================

=========================================
Equipes, projet et lieu du stage :
=========================================
Equipes : ALPAGE (UMR-I Univ Paris Diderot/INRIA
          et WILLOW (UMR CNRS/ENS/INRIA)

Le stage sera déroulera en cotutelle par ALPAGE et WILLOW, dans le cadre
du projet ERC VideoWorld :
""Modeling, interpreting and manipulating digital video""

Lieu : Le stagiaire sera basé à Alpage :
       175 rue du chevaleret 75013 Paris

=========================================
Sujet :
=========================================
Un nombre énorme de vidéos est aujourd'hui disponible, en particulier
sur Internet, qu'il s'agisse de vidéos informatives, éducatives, de
divertissement ou autres. Ce nombre va croissant, et de ce fait l'accès
intelligent à leur contenu devient un enjeu majeur.

Un scénario de recherche au sein de vidéos peut par exemple se modéliser
comme la recherche de certaines situations ou actions précises (faire du
cheval, sortir d'un véhicule, prendre un repas ...). Pour automatiser
cette tâche par des techniques d'apprentissage supervisé, un problème
important est le fait qu'il est très fastidieux de construire des
exemples d'apprentissage où les séquences de vidéos sont couplées à des
actions précises. Une solution à ce problème est de construire
automatiquement des exemples d'apprentissage en utilisant, lorsqu'ils
existent, les textes associés aux vidéos. Ces textes sont en particulier
disponibles pour un grand nombre de films, sous la forme de scripts de
scenario.

L'objet du stage est de construire un système intégré d'analyse de
scripts (anglais) de films, en vue de permettre la classification
automatique de descriptions de scènes de films en actions, parmi un
ensemble prédéfini d'actions. Il s'agira de de coupler l'utilisation et
l'adaptation de modules de traitement existants (reconnaissance
d'entités nommées, résolution d'anaphores, tagging, parsing) à des
modules spécifiques. Deux points (de recherche) attireront notre
attention : d'une part l'utilisation du cadre FrameNet pour le repérage
des actions, d'autre part les informations de factivité (cadre FactBank)
pour savoir si une action s'est effectivement produite.

Par exemple pour la description de scène suivante issue d'un script :

"" The servants move Chang's chair back. Before he goes, however, he
turns to Conway and smiles at him. ""

Il s'agit de repérer les personnages ""the servants"", Chang, Conway;
résoudre les références de ""he"" et ""him""; repérer les actions ""move
chair"", ""turn"", ""smile"" et leurs actants; et idéalement repérer que la
mention de l'action de partir (to go) n'est pas réalisée ou pas encore
réalisée.

=========================================
Profil recherché :
=========================================
Etudiant de niveau BAC +5, avec des connaissances en Traitement
Automatique des Langues et en apprentissage automatique.
Une autonomie en programmation est indispensable, ainsi qu'une bonne
maîtrise de l'anglais (langue des textes à traiter).
Des connaissances en linguistique seraient un plus apprécié.

=========================================
Durée : 6 mois
=========================================
Rémunération : selon profil
=========================================

Envoyez CV et lettre de motivation à :
contact : marie.candito@gmail.com"
"116","2012-02-01","LIMSI","Orsay","Offre de stage de Master 1 à Orsay (91), au LIMSI.
http://www.limsi.fr/~xtannier/fr/Stages/sujet_2012_M1_phrase_saillante.html


  Sélection automatique de passage représentatif d'un événement


      Mots-clés

/traitement automatique de la langue, analyse temporelle, événements/


    Contexte

Entre autres objectifs, le projet ANR ChronoLines a pour but de créer de
façon semi-automatique des chronologies à partir de dépêches d'agences.
Étant donnés un thème fourni par l'utilisateur et un ensemble de textes,
il s'agit de retrouver dans les documents les événements les plus
importants concernant ce thème, puis de les ordonner et de les présenter
à l'utilisateur pour validation. Par exemple, pour une demande sur un
nom de personne, le système devra retracer les événements marquants de
sa vie. Pour les négociations de paix au Moyen-Orient, les principales
dates importantes s'y rattachant.

Parmi les étapes nécessaires pour atteindre ce résultat, une phase
consiste à sélectionner, parmi les événements détectés, ceux qui
semblent les plus marquants, ou les plus centraux, par rapport au thème
de la requête. Pour chacun de ces événements, il faut ensuite choisir un
texte caractéristique, expliquant de façon claire et concise de quoi il
s'agit. Ce passage de texte est à choisir parmi un ensemble de
nombreuses phrases décrivant l'événement.


    Travail à réaliser :

Durant ce stage, on partira d'un système existant. Ce système
sélectionne les phrases qui correspondent, de façon plus ou moins
précise, à chaque événement à insérer dans la chronologie. L'objectif du
stage est de :

  * Parcourir la littérature scientifique sur le sujet (sélection de
    texte, résumé automatique, agrégation de résultats, etc.) pour
    identifier les techniques existantes susceptibles d'être adapter à
    notre problème.
  * Réaliser un outil permettant de choisir (ou éventuellement de
    générer) une phrase explicative d'un événement, à partir d'un
    ensemble de courts textes à son sujet.

Le stagiaire devra avoir de bonnes compétences en informatique et un 
intérêt pour les problématiques du traitement de la langue.

*Durée* : environ 2 mois
*Niveau* : Master 1


      Contacts :

Veronique.Moriceau[at]limsi.fr
Xavier.Tannier[at]limsi.fr"
"117","2012-02-07","CEA-LIST","Gif-sur-Yvette","Stage Bac+5 : Utilisation d'un moteur de recherche interlingue et d'un
modèle statistique pour la langue cible en traduction automatique

Lieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie
des Contenus (LVIC), 91191 Gif sur Yvette

Sujet :

Il existe principalement deux types d'approches pour la traduction
automatique: celles à base de règles et celles s'appuyant sur des
corpus. La combinaison de ces approches a permis le développement de
solutions hybrides. Les approches à base de règles utilisent des
ressources linguistiques monolingues et bilingues coûteuses car
généralement construites à la main. Les approches à base de corpus
utilisent des méthodes statistiques appliquées sur des textes parallèles
pour apprendre les modèles de traduction et de langue. Ces approches
nécessitent de gros volumes de corpus parallèles qui n'existent pas pour
toutes les langues.

Le stage s'appuiera sur le prototype de traduction automatique développé
au CEA-LIST dans le cadre du projet ANR WebCrossling. Ce prototype
utilise une nouvelle approche fondée sur un moteur de recherche
interlingue et un modèle statistique de la langue cible. Cette approche
consiste à générer une base de données textuelle composée de la totalité
des phrases issues des textes accessibles sur le web dans la langue
cible et considérer la phrase à traduire comme une requête au moteur de
recherche interlingue.

L'objectif du stage consiste, d'une part, à constituer un corpus de
référence en langue arabe (langue cible) pour la génération du modèle de
langue, et d'autre part, à adapter ce prototype de traduction au couple
de langues anglais-arabe et à évaluer ses résultats de traduction par
rapport à Moses, un outil de traduction statistique sous licence libre.

Ce stage comportera les étapes suivantes:

- Appropriation des moteurs de traduction WebCrossling et Moses.

- Intégration du lexique bilingue anglais-arabe construit à l'aide
  d'outils d'alignement de mots du CEA-LIST dans les moteurs de
  traduction WebCrossling et Moses.

- Mise en place d'outils d'évaluation des moteurs de traduction
  WebCrossling et Moses.

- Développement d'une interface graphique pour le moteur de traduction
  WebCrossling destinée aux traducteurs professionnels.

Profil recherché :

Bac+5, stage de fin d'étude dans le domaine du Traitement Automatique de
la Langue (TAL)

Compétences en informatique et en TAL

Programmation : C++, Perl ou équivalent

Langues : Maîtrise de l'anglais et du français, la connaissance de la
langue arabe est un plus

Contact  et envoi des candidatures :

Nasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr

Durée : environ 6 mois

Nasredine SEMMAR
CEA Saclay Nano-INNOV
Institut CARNOT CEA LIST
Laboratoire Vision et Ingénierie des Contenus (LVIC)
Point courrier n°173
91 191 Gif sur Yvette CEDEX
Tel: +33 (0)1 69 08 01 46
Fax: +33 (0)1 69 08 01 15
Email: nasredine.semmar@cea.fr"
"118","2012-02-08","Reverso-Softissimo","Neuilly","tage linguiste / terminologue / traducteur

Type de contrat : Stage de césure ou de fin d'études (minimum 4 mois)

Lieu : Neuilly-sur-Seine

Indemnité de stage : Selon durée et expérience

Début : Dès que possible

Avantages : Tickets restaurant et 50% transport

ENTREPRISE

Editeur de logiciels à rayonnement international, Reverso-Softissimo est
l'un des leaders mondiaux des solutions Intranet et Internet de
traduction instantanée et de dictionnaires électroniques.

Son portail grand public dédié aux langues www.reverso.net génère un
très fort trafic avec 200 millions de pages vues par mois et plus de 6
millions de visiteurs uniques.

Reverso-Softissimo recherche un(e) linguiste pour participer aux travaux
de production et de recherche de notre équipe linguistique dans un
contexte professionnel motivant : haute technologie, forte croissance et
développement international.

Vous êtes intéressé(e) par notre domaine ? C'est le moment de rejoindre
notre équipe !

MISSION

Sous la direction du chef de projet linguistique, le stagiaire
effectuera les missions suivantes :

- création, mise à jour, validation de dictionnaires bilingues ;
- tests de la qualité de traduction et rédaction de rapports d'analyse ;
- recherche, évaluation et analyse de ressources terminologiques ;
- animation et développement de la communauté d'utilisateurs du
  dictionnaire collaboratif.

Cette liste n'est pas exhaustive et pourra être amenée à évoluer en
fonction de l'implication du/de la stagiaire.

PROFIL

Étudiant(e) en dernière année d'une école ou d'une université en TAL,
langues étrangères, linguistique, ingénierie linguistique ou traduction,
vous maîtrisez parfaitement l'anglais et le français à l'oral comme à
l'écrit, et idéalement une troisième langue.

Vous avez des qualités rédactionnelles ainsi qu'une grande rigueur, une
bonne méthodologie, un esprit logique et des capacités d'analyse et de
synthèse ; votre sens de l'initiative, votre dynamisme et votre
autonomie seront également des qualités appréciées dans le cadre de ce
stage.

Contact :
Juliette MORNET
01.41.43.10.31
jmornet@reverso.com"
"119","2012-02-08","I3S","Nice","Bonjour,

L'équipe KEIA (Knowledge Extraction, Integration & Algorithms) du
laboratoire I3S de l'Université de Nice Sophia-Antipolis, propose deux
stages de Master 2 recherche, financés (4200 euros pour 6 mois de
stage), dans le domaine de fouille de données appliquée au texte. Voir
fichiers attachés pour plus de détails.

Cordialement,

Célia Pereira.

------------------------------------------------------------------------

Titre : techniques d'apprentissage pour le regroupement de messages courts

Contexte du travail :

Grâce aux nouvelles technologies, les messages courts sont devenus
omniprésents dans notre société. Ils prennent la forme de SMS sur
téléphones mobiles, de micro-blogs comme Twitter, de commentaires dans
les réseaux sociaux comme Facebook ou Google+ etc. Leur particularité
consiste en une brièveté imposée à la fois par le médium et une volonté
d'échanger l'information brute et instantanée. Ces messages représentent
une richesse, en termes de quantité d'information, qui pourrait être
utilisée pour analyser un climat politique, prédire des crises ou
corriger les défauts d'un produit. En particulier, ils sont devenus un
nouvel outil de communication directe entre un vendeur et ses acheteurs,
entre les politiques et le peuple, entre les dirigeants d'entreprise et
leurs salariés. Le nombre de messages, la vitesse à laquelle ils sont
produits et leur nature spontanée nécessitent de nouveaux moyens
d'analyse pour en faire ressortir des tendances globales utiles.

Ce stage s'insère dans le contexte d'une collaboration avec l'entreprise
Succeed Together® (Semantic Grouping Company), qui est la propriétaire
de l'outil ""Meeting Software®"". Ce dernier a été conçu pour améliorer la
performance des réunions professionnelles :

- quelque soit le nombre de participants ;
- quelque soit la langue utilisée ;
- quelque soit le nombre de sites impactés.

Le but principal de ce stage est d'améliorer les performances de cet
outil afin que son utilisation permette de regrouper de façon optimale
les messages ayant le même sens. Dans sa version actuelle, le résultat
du regroupement peut éventuellement ""subir"" l'intervention d'un pilote,
personne experte dans le domaine considéré, afin d'améliorer
ultérieurement les regroupements obtenus.  Plus précisément, le travail
demandé est de fournir les moyens pour optimiser les interventions du
pilote en :

- trouvant les associations [6] entre les regroupements obtenus
  automatiquement et les interventions humaines --- dans quelles
  situations le pilote est-t-il intervenu ?

- proposant ou en adaptant un algorithme d'apprentissage [3,4,5] qui
  pourra :

- apprendre les interventions du pilote ;

- être en mesure de donner automatiquement des «conseils» à chaque fois
  qu'une une situation similaire se représente ;

- apprendre des profils d'utilisation [1] en construisant des modèles
  des interventions du pilote dans des domaines spécifiques ;

- sélectionner les caractéristiques pertinentes des textes courts à
  prendre en compte afin d'optimiser les résultats du regroupement.

L'algorithme de regroupement amélioré pourra alors soit s'auto-corriger
sans le besoin de l'intervention humaine, soit requérir une intervention
du pilote mais en la ciblant sur le cas bloquant uniquement.

Pré-requis : très bonnes capacités de programmation.

Type : Recherche

Gratification : 4200 euros pour 6 mois de stage

Bibliographie

1. Célia da Costa Pereira and Andrea Tettamanzi. An Ontology-Based
Method for User Model Acquisition. In Zongmin Ma, editor, Soft-Computing
in Ontologies and Semantic Web, vol. 204, 2006, ISBN 3-540-33472-6.

2. Christiane Fellbaum (ed.). WordNet. An Electronic Lexical
Database. The MIT Press, Cambridge, MA, 1998.

3. Thomas Mitchell. Machine Learning. Editeur : McGraw Hill, 1997, ISBN
: 0070428077.

4. Vojislav Kecman. ""Learning and Soft Computing - Support Vector
Machines, Neural Networks, Fuzzy Logic Systems"". The MIT Press,
Cambridge, MA, 2001.

5. Kenneth A. De Jong. Evolutionary Computation : A Unified
Approach. The MIT Press, Cambridge, MA, 2006.

6. Jiawei Han, Hong Cheng, Dong Xi and Xifeng Yan. Frequent pattern mining:
current status and future directions. Data Min Knowl Disc (2007) 15:55-86.

Lieu du stage : Laboratoire I3S

Contact : Célia da Costa Pereira, équipe KEIA du labratoire I3S
E-Mail : celia.pereira@unice.fr

------------------------------------------------------------------------

Titre : techniques de fouille de données pour le regroupement de
messages courts

Contexte du travail :

Grâce aux nouvelles technologies, les messages courts sont devenus
omniprésents dans notre société. Ils prennent la forme de SMS sur
téléphones mobiles, de micro-blogs comme Twitter, de commentaires dans
les réseaux sociaux comme Facebook ou Google+ etc. Leur particularité
consiste en une brièveté imposée à la fois par le médium et une volonté
d'échanger l'information brute et instantanée. Ces messages représentent
une richesse, en termes de quantité d'information, qui pourrait être
utilisée pour analyser un climat politique, prédire des crises ou
corriger les défauts d'un produit. En particulier, ils sont devenus un
nouvel outil de communication directe entre un vendeur et ses acheteurs,
entre les politiques et le peuple, entre les dirigeants d'entreprise et
leurs salariés. Le nombre de messages, la vitesse à laquelle ils sont
produits et leur nature spontanée nécessitent de nouveaux moyens
d'analyse pour en faire ressortir des tendances globales utiles.

Ce stage s'insère dans le contexte d'une collaboration avec l'entreprise
Succeed Together® (Semantic Grouping Company), qui est la propriétaire
de l'outil ""Meeting Software®"". cet outil a été conçu pour améliorer la
performance des réunions professionnelles :

- quelque soit le nombre de participants ;
- quelque soit la langue utilisée ;
- quelque soit le nombre de sites impactés.

Le but principal de ce stage est d'améliorer les performances de cet
outil afin que son utilisation permette de regrouper de façon optimale
les messages ayant le même sens.

Dans sa version actuelle, le résultat du regroupement peut
éventuellement ""subir"" l'intervention d'un pilote, personne experte dans
le domaine considéré, afin d'améliorer ultérieurement les futurs
regroupements obtenus. Plus précisément, le travail demandé est
d'explorer les méthodes de regroupement existantes [3], comme par
exemple les méthodes itératives basées sur les distances, les méthodes
hiérarchiques, les méthodes basées sur la densité, les méthodes basées
sur les modèles et les méthodes de ""Boosting"" des règles d'associations
de texte et Structural (latent) SVM [4], en les appliquant aux données
correspondant aux messages courts. Pour être en mesure d'appliquer ces
techniques, il faudra auparavant disposer d'une représentation
appropriée des textes courts. Parmi les représentations qui pourront
être utilisées, nous nous intéresserons aux représentations sémantiques
telle que celle utilisée en [1] qui s'appuie sur la base de données
lexicale WordNet [2], ou d'autres basées sur l'extraction des
caractéristiques du texte. Dans ce contexte, le stagiaire pourra
bénéficier de la collaboration en cours avec d'autres équipes
participant au projet.

Pré-requis : très bonnes capacités de programmation.

Type : Recherche

Gratification : 4200 euros pour 6 mois de stage

Bibliographie

1. C. da Costa Pereira and A. Tettamanzi. An Ontology-Based Method for
User Model Acquisition. In Zongmin Ma, editor, Soft-Computing in
Ontologies and Semantic Web, vol. 204, 2006, ISBN 3-540-33472-6.

2. Christiane Fellbaum (ed.). WordNet. An Electronic Lexical
Database. The MIT Press, Cambridge, MA, 1998.

3. Jawei Han and Micheline Kamber. Data Mining: Concepts and Techniques.
Morgan Kaufmann Publishers Inc. San Francisco, CA, USA. ISBN:
1558609016.

4. Yongwook Yoon and Gary G. Lee. Text Categorization Based on Boosting
Association Rules. Proceedings of the 2008 IEEE International Conference
on Semantic Computing, pages = {136--143}, 2008, IEEE Computer Society.

Lieu du stage : Laboratoire I3S
Contact : Célia da Costa Pereira, équipe KEIA du labratoire I3S
E-Mail : celia.pereira@unice.fr"
"120","2012-02-13","Tendances Institut","Paris","*Offre de stage*

*Tendances Institut* est un cabinet de conseil spécialisé dans l'analyse
de l'évolution des opinions et des valeurs des différents publics pour
une gestion globale de la réputation de ses clients.

*Un objectif*: Permettre aux hommes, aux entreprises et aux institutions
d'atteindre leurs publics par la maîtrise de leur environnement sociétal
en anticipant l'attitude et le comportement des leaders d'opinion.

*Une triple expertise*:

  * Réputation : veiller les éléments non maîtrisés (buzz, rumeurs,
    campagnes hostiles) et évaluer les éléments maîtrisés (efficacité
    d'une prise de parole institutionnelle et de sa diffusion dans
    l'opinion) qui concourent à l'image d'une entité publique ou privée.

  * Influence : déployer une économie du buzz sur la base de dispositifs
    souples et ad hoc qui diffusent l'information là où elle sera
    entendue et relayée.

  * Identification des microleaders d'opinion : s'appuyer sur une
    communauté d'internautes prescripteurs/diffuseurs d'information sur
    les blogs et les réseaux sociaux.

*Description de la mission* :

Dans le cadre de notre développement, nous recherchons un stagiaire
pouvant nous aider à développer des solutions de recherche, de
traitement automatisée de l'information sur internet (extraction
textuelle à partir des réseaux sociaux, blogs, sites d'information et
autres) et d'annotation de ses contenus par apprentissage automatique.

*Compétences requises* :

  * Vous suivez un cursus d'ingénierie de la langue et souhaitez
    travailler à la mise en place d'un outil d'annotation automatisé
    d'un corpus de textes venant du web.

  * Vous savez mettre en place des outils d'extraction et d'analyse
    automatisée de données textuelles.

  * Vous maitrisez différentes technologies Web (PHP/MySql, HTML, CSS,
    JavaScript, Ajax, XML....).

  * Vous êtes familiarisé avec un ou plusieurs langages de programmation
    (Perl, Python, Java).

  * Plus généralement, vous avez un goût prononcé pour le web social et
    son exploration automatisée.

*Profil* :

De formation bac +4 ou 5 informatique appliquée à la linguistique, vous
êtes passionné(e) de NTIC. Créatif, vous souhaitez développer de
nouvelles applications au sein d'une entreprise.

Eventuellement intéressé par la recherche appliquée, vous souhaitez dans
le futur poursuivre vos études dans le cadre d'un contrat Cifre.

*Durée du stage* : 6 mois

*Rémunération* : 435EUR/mois

*Contact* : Aurélien Miklas -- _amiklas@societale.com -- 06.63.03.08.32"
"121","2012-02-13","Laboratoire d'Informatique de Tours","Blois","Extraction des informations encyclopédiques pour la recherche
d'information

PROBLEMATIQUE

Le Laboratoire LI (Laboratoire d'Informatique de l'Université de Tours)
propose un sujet de stage dans le cadre de l'enrichissement de nos
ressources pour nos systèmes de reconnaissance d'entités nommées.

La reconnaissance d'entités nommées consiste à repérer automatiquement
dans des textes des unités linguistiques (noms de personnes / sociétés /
organisations, lieux, montants, dates, etc.) qui peuvent être utiles à
la recherche d'informations, à l'extraction d'informations pour
l'utilisateur ou pour des traitements ultérieurs. Nos systèmes reposent
sur l'utilisation des technologies suivantes :

- règles symboliques de reconnaissance (transducteurs),
- fouille de données et apprentissage automatique,
- hybridation des deux précédents.

Les résultats obtenus par ces systèmes, dépendent à la fois des
algorithmes qu'ils mettent en ½uvre et des ressources qu'ils
utilisent. Il est donc essentiel d'être en mesure d'enrichir et de
mettre à jour nos ressources de manière aussi automatisée que possible.

Nous nous appuyons notamment sur des lexiques qui listent des noms
propres (personnes, lieux, organisations, etc.). L'apparition
d'encyclopédies structurées à large couverture (par ex. Wikipedia) et
leur mise à disposition permet d'extraire automatiquement ces données
afin de mettre à jour nos lexiques.

Le stage que nous proposons porte sur l'automatisation de tels
traitements : navigation dans les structures des encyclopédies,
sélection et extraction des catégories et entités pertinentes,
intégration dans des lexiques, évaluation de l'impact sur les
performances de nos systèmes. Les encyclopédies mettent souvent en place
des facilités pour les récupérer et les interroger (par exemple les
dumps Wikipedia : http://dumps.wikimedia.org/backup-index.html ). Il
faut cependant veiller à la pertinence des informations extraites.

MISSION

La personne recrutée sera chargée de la conception et des développements
logiciels, en deux phases :

- phase 1 (étude de faisabilité et spécifications) : sélectionner les
encyclopédies et les outils appropriés pour leur interrogation, il
s'agit de voir comment il sera possible d'automatiser l'extraction
d'entités selon les encyclopédies,

- phase 2 (conception, prototypage et implémentation) : conception et
implémentation d'un prototype modulaire et paramétrable d'extraction,
tests, évaluation et étude de l'impact sur les performances de nos
systèmes, validation.

PROFIL RECHERCHE

Formation informatique, de bon niveau académique, compétences en
programmation (Java, Python, C++), manipulation de base de données et
XML.  A l'aise sur toutes plateformes (Windows / Linux).

CONDITIONS

Dates et durée : dès que possible, pour 3 mois
Lieu d'exercice : Blois, antenne universitaire, laboratoire LI, équipe BDTLN
Rémunération : 436,05 ¤ par mois (prévue par la règlementation),
Possibilité d'extension en CDD d'un / deux mois, selon le travail
réalisé et les perspectives

DEPOT DE CANDIDATURES

Contact : nathalie.friburger@univ-tours.fr , Jean-Yves.Antoine@univ-tours.fr,
damien.nouvel@univ-tours.fr
Procédure : Merci d'envoyer un CV mentionnant votre formation, vos
compétences, vos activités passées"
"122","2012-02-13","CNES","Toulouse","Développement d'une base de connaissances à partir de textes.

Dans le cadre de sa mission de capitalisation et de valorisation des
ressources informationnelles du CNES, le service Gestion de
l'Information et de la connaissance, propose de participer au
développement de méthodes d'enrichissement de l'ontologie utilisée pour
le classement et la recherche des documents de la mémoire d'entreprise
du CNES. La mise en ½uvre s'appuiera d'une part sur une plateforme
dédiée intégrant un moteur de recherche sémantique, d'une catégorisation
automatique et des fonctions complémentaire et d'autre part, sur des
outils d'analyse statistique et d'extraction terminologique.

Durée (mois) : 6 mois
Date de début : pas de contrainte
Ce stage vise a priori un étudiant en master 2 spécialité
linguistique (compétence en linguistique de corpus souhaitée)

Le stage se déroulera à Toulouse au Centre Spatial de Toulouse
(CST-CNES) et sera bien sûr rémunéré.

On pourra retrouver sa référence sur le site du CNES
(http://www.cnes.fr/web/CNES-fr/175-stages-2011-2012.php?view=item&item=6891),
le flèchage Informatique/réseaux n'indique pas que ce stage s'adresse en
priorité à des linguistes. Le stage comme indiqué ci-dessus, pourra
commencer dès le premier semestre.

Les modalités d'inscription se trouvent indiquées à l'adresse suivante :
http://www.cnes.fr/web/CNES-fr/712-comment-poser-votre-candidature-.php
. Il est possible d'avoir des informations supplémentaires par téléphone
en contactant le responsable du sujet au 05 61 27 32 51."
"123","2012-02-14","Airbus","Toulouse","Stage / Identification Optimisation Déploiement Outils de Veille Web 2.0 (h/f)

Reference Code : 10164312 LL FR EXT 1

Functional Area :ADMINISTRATION & GESTION D'INFRASTRUCTURES / Gestion de site

Description of the job : Airbus (Toulouse) recherche un(e) stagiaire
pour une durée de 6 mois.

Cette offre de stage est à pourvoir à compter du 1er mars 2012
(sujette à une certaine flexibilité).


Tasks & accountabilities:

Vous aurez, par exemple, les missions suivantes :
- répertorier les dernières évolutions,
- analyser et sélectionner les outils,
- étudier les coûts,
- étudier l'intégration de ces outils au sein du centre de documentation,
- participer à la mise en place.

Required skills:

Vous êtes en deuxième ou dernière année d'école d'ingénieur, en master
ou université (4ème ou 5ème année) et êtes spécialisé(e) en veille et
/ ou management des nouvelles technologies et / ou sciences de
l'information et / ou intelligence.

Vous possédez les qualités suivantes :
- organisation,
- curiosité,
- goût pour l'informatique.

Anglais : niveau intermédiaire.

Contact Data:

Merci de bien vouloir postuler en ligne en joignant votre CV sur le site :

http://www.eads.com/eads/int/en/work-for-eads/apply/search-for-vacancies.referringdivision-airbus.html

en entrant le code du stage  : 10164312 LL FR EXT 1"
"124","2012-02-15","LORIA","Nancy","L'équipe KIWI (Knowledge, Information and Web Intelligence) du
laboratoire Loria (laboratoire lorrain de recherche en informatique et
ses applications) du Loria (Laboratoire lorrain de recherche en
informatique et ses applications) propose un stage de Master 2
recherche, dans le domaine des réseaux sociaux, de la détection
d'opinions et de la e-reputation.  

Gratification : 2500 euros pour 6 mois de stage. 

Poursuite en thèse possible.

Sujet :  Apport des réseaux sociaux pour une meilleure relation client.

Encadrement : 
Anne Boyer - Professeur, Equipe KIWI, LORIA - Anne.Boyer@loria.fr 
et 
Armelle Brun - Maître de conférences, Equipe KIWI, LORIA - Armelle.Brun@loria.fr 

Contexte et Problématique

La garantie de la rentabilité des entreprises passe par une bonne
communication et propagation de l'information en interne et avec leurs
clients et leurs clients potentiels (prospects).

Les réseaux sociaux d'entreprise (RSE) sont un nouveau moyen de
favoriser la communication et la propagation d'informations au sein des
entreprises. Si ces réseaux sont en général destinés à un usage interne
aux entreprises, ils peuvent aussi être étendus à leurs clients. Dans ce
cadre, les RSE peuvent interagir avec d'autres services comme les
réseaux sociaux publics (RS) tels que Twitter ou Facebook (en exploitant
les données disponibles sur les utilisateurs). Via cette interaction,
l'entreprise cherche non seulement à mieux connaître ses clients mais
aussi à savoir ce qui se dit d'elle à l'extérieur et ainsi réagir pour
une meilleure efficacité.

La mise en place de connexions entre les réseaux sociaux (RS) et les
réseaux sociaux d'entreprise (RSE) permet donc non seulement de faire
émerger un nouveau mode de communication entre l'entreprise et ses
clients. Elle permet également à l'entreprise d'être à l'écoute de ce
qui se dit d'elle et ainsi proposer des offres adéquates à de futurs
clients.

Déroulement du stage

Le stage débutera par la réalisation d'un état de l'art sur l'analyse de
réseaux sociaux, la diffusion de l'information dans les réseaux sociaux
et dans les graphes et la détection d'opinions et de communautés
d'opinions.

Suite à cet état de l'art, l'étudiant s'intéressera à la définition d'un
modèle permettant de déterminer automatiquement, dans les réseaux
sociaux ou dans les blogs, l'activité autour d'une entreprise : ce qui
se dit d'elle. Un prototype de ce modèle devra être réalisé.

L'étudiant se penchera également sur  la détermination de l'information
pertinente à diffuser sur ces réseaux : quelle information diffuser ?
sur quel réseau la diffuser ? à quelles personnes précisément la
diffuser ? L'évaluation se fera par analyse des ""retours"" des
utilisateurs :  au travers de l'observation et de l'analyse des actions
(traces d'usage) que les clients entreprendront suite à la diffusion de
cette information : usage mining.     

Ce stage  s'appuie sur les compétences et l'expérience de l'équipe dans
les domaines comme la personnalisation [1], la modélisation utilisateurs
[2], de la détection de communautés dans les réseaux et les réseaux
sociaux de grande taille [3], la recherche de leaders dans des réseaux
[4][5], etc. 



Profil recherché :

M2 Recherche informatique ou école d'ingénieurs
Bonnes notions en apprentissage automatique
Bonnes connaissances en programmation java
Bon niveau en anglais



Références bibliographiques

[1] Modélisation de comportements et apprentissage stochastique non
supervisé de stratégies de recherche et d'accès à
l'information. Castagnos S. Thèse de l'Université Nancy 2, novembre
2008.

[2]  Compass to Locate the User Model I need: Building the Bridge
between Researchers and Practitioners in User Modeling. Brun A., Boyer
A., Razmerita L. User Modeling, Adaptation and Personalization - UMAP
2010, États-Unis (2010).

[3] From Community Detection to Mentor Selection in Rating-Free
Collaborative Filtering. Brun A., Castagnos S., Boyer A. Advances in
Multimedia Journal (2011) .

[4]  Social recommendations : mentor and leader détection to alleviate
the cold-start problem in collaborative filtering. Brun A, Castagnos, S
and Boyer A. in Social Network Mining, Analysis and Research trends :
Techniques and Applications (2011).

[5] Detecting Leaders to alleviate Latency in Recommender
Systems. Esslimani I., Brun A., Boyer A. International Conference on
Electronic Commerce and Web Technologies, Espagne (2010) 


Contact : 

Anne Boyer (anne.boyer@loria.fr) et Armelle Brun
(armelle.brun@loria.fr). 

Les personnes intéressées par le sujet devront envoyer par mail un CV,
un relevé de notes et une lettre de motivation."
"125","2012-04-02","Systran","Paris","########################

Company:        SYSTRAN
Department:     Linguistic Resources 
Location:       Paris 75002, France
Website:        www.systran.fr 

 

Internship description:

SYSTRAN has currently an opening for an internship of 4-6 months that
aims at the development and evaluation of linguistic resources for
English to Russian Machine Translation

The internship project would include the following tasks:

..  Integration and validation of dictionary entries

..  Creation of domain dictionaries using Bilingual Terminology
    Extraction on parallel domain corpora

..  Identification of invalid or wrong translations using corpus-based
    methods

..  Work on attributive translations of nouns

..  Validation and enrichment of resources used for morphological
    analysis

Required skills: 

..  Native competence of Russian and fluency in English

..  Good working knowledge of computational lexicography and NLP methods
    in general

..  Strong skills in Russian and English morphology and syntax

..  Working knowledge of Perl and scripting languages is a plus

..  Strong communication skills and ability to work in a team

 
Please send your application and cover letter to Bianka Buschbeck:
buschbeck at systran.fr"
"126","2012-04-19","LIMSI","Orsay","Proposition de stage M1 ou M2 au LIMSI-CNRS
dans le cadre de l'Action Incitative
'Transfert de connaissances linguistiques d'une langue à l'autre'


Responsables du stage : 
Pierre Zweigenbaum (groupe ILES) 
Marianna Apidianaki (groupe TLP)


Titre : Transfert de rôles sémantiques d'une langue à l'autre

Les ressources linguistiques comme les corpus annotés sont actuellement
disponibles dans peu de langues, notamment en anglais. Cependant, des
ressources de ce type sont requises pour le développement d'outils pour
de nombreuses applications du traitement automatique des langues. De ce
fait, plusieurs travaux se sont récemment intéressés au transfert
automatique de connaissances de langues riches en ressources vers
d'autres langues. Le stage proposé rejoint cette problématique.

Le transfert de connaissances linguistiques d'une langue à l'autre a
généralement lieu au sein de corpus parallèles et se base sur
l'alignement des textes. L'idée sur laquelle reposent les méthodes
proposées est que si l'on dispose de corpus annotés et de leur
traduction dans une autre langue, on peut chercher à transférer les
annotations dans cette autre langue. Par ce processus, des ressources
sont créées qui permettent d'entraîner des outils d'analyse à différents
niveaux dans les nouvelles langues (Yarowsky et Ngai, 2001; Lopez et
al. 2002).

Ce stage est plus particulièrement centré sur le transfert
d'informations de rôles sémantiques de l'anglais vers le français. Les
méthodes d'étiquetage de rôles sémantiques nécessitent des connaissances
linguistiques importantes ou de grands corpus annotés. En anglais, ces
ressources et les outils dérivés existent (Gildea et Jurafsky, 2002;
Palmer et al., 2005). Pour le français, des travaux sont en cours pour
construire de telles ressources et outils, y compris en exploitant des
corpus parallèles (Padó et Pitel, 2007; Van der Plas et al., 2011) afin
de bénéficier des outils ou annotations disponibles pour l'anglais.

L'objectif de ce stage est de mener une étude sur le processus de
transfert de rôles sémantiques de l'anglais vers le français. Plus
précisément, nous souhaitons explorer les cas où le transfert ne peut
pas être effectué. Cela peut être dû à la structure spécifique aux
langues particulières ; à des erreurs d'alignement ; ou à des
divergences de traduction observées au sein de corpus parallèles.  Les
résultats du processus de transfert proposé par Van der Plas et
al. (2011) seront analysés en comparaison avec un étiquetage de
référence (gold standard) contenant les résultats corrects. Le/la
stagiaire aura donc à étudier les cas où l'analyseur ne fournit pas les
résultats souhaités, à procéder à une analyse des erreurs, étudier
l'impact de ces sources d'erreur sur le transfert et envisager des
solutions pouvant améliorer la performance de la méthode.

Le corpus qui sera utilisé pour cette étude est la partie
anglais-français du corpus Europarl (Koehn, 2005).

Profil : le/la stagiaire devra avoir un profil linguistique multilingue
et un intérêt pour les problématiques du traitement de la langue. Des
compétences en informatique seront appréciées mais ne sont pas
indispensables.

Durée : 4 mois
Date de début : dès disponibilité
Niveau : Master 1 ou 2
Lieu : LIMSI-CNRS, Groupe ILES
rue John von Neumann,
Université Paris Sud
91403 Orsay Cedex

Salaire: le/la stagiaire recevra la gratification CNRS standard
(de l'ordre de 436 ¤/mois).

Contacts : 
Pierre Zweigenbaum (pz@limsi.fr)
Marianna Apidianaki (marianna@limsi.fr)"
"127","2012-04-26","CEA-LIST","Gif-sur-Yvette","Stage Bac+5 : Alignement de mots à partir de corpus de textes parallèles
pour la construction et la mise à jour de dictionnaires multilingues


Lieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie
des Contenus (LVIC), 91191 Gif-sur-Yvette

Sujet :

Les dictionnaires bilingues constituent les principaux composants des
systèmes de traduction automatique et de recherche d'information
interlingue. La masse de travail nécessaire pour créer manuellement les
dictionnaires bilingues est importante. C'est la raison pour laquelle
depuis quelques années de nombreuses approches de construction
automatique de ces dictionnaires ont été proposées.

Le stage consistera, d'une part, à constituer un corpus de référence de
textes parallèles et d'autre part, à évaluer les principaux composants
du module de construction et de mise à jour de dictionnaires bilingues
développé au CEA-LIST. Cette évaluation se fera selon deux approches
différentes :

- Une évaluation manuelle comparant les résultats du module d'alignement
  de mots simples, de mots composés et d'expressions par rapport à un
  alignement de référence ;

- Une évaluation automatique en intégrant les résultats du module
  d'alignement de mots dans la table de traduction du système de
  traduction statistique open source Moses.

Ce stage comportera les étapes suivantes:

- Appropriation des principaux composants du module de construction et
  de mise à jour de dictionnaires bilingues.

- Constitution d'un corpus de référence composé de textes parallèles
  multilingues.

- Mise en place d'outils d'évaluation du module d'alignement de mots
  simples, de mots composés et d'expressions.

- Spécification et implémentation du module de nettoyage des
  dictionnaires bilingues construits ou mis à jour automatiquement.

- Développement d'une interface graphique pour la gestion de la
  construction et de la mise à jour de dictionnaires bilingues.

Profil recherché :

Bac+5, stage de fin d'étude dans le domaine du Traitement Automatique de
la Langue (TAL).

Compétences en informatique et en TAL

Programmation : C++, Perl ou équivalent

Langues : Maîtrise de l'anglais et du français, la connaissance de la
langue arabe est un plus

Contact  et envoi des candidatures :

Nasredine SEMMAR, 01 69 08 01 46,
nasredine.semmar@cea.fr

Durée : 4 à 6 mois

Nasredine SEMMAR

CEA Saclay Nano-INNOV
Institut CARNOT CEA LIST
Laboratoire Vision et Ingénierie des Contenus (LVIC)
Point courrier n°173
91191 Gif-sur-Yvette CEDEX
Tel: +33 (0)1 69 08 01 46
Fax: +33 (0)1 69 08 01 15
Email: nasredine.semmar@cea.fr"
"128","2012-05-24","INRIA","Sophia Antipolis","Proposition de stage Master/Ingénieur : Étude et développement d'un
système automatique de question-réponse pour la langue française.

Lieu : INRIA Sophia Antipolis Méditerranée
Équipe : Wimmics ( http://wimmics.inria.fr )
Durée : 4-6 mois
Date limite de candidature : 15 juin 2012
Description du stage: https://wimmics.inria.fr/internship

Contacts et envoi des candidatures :
Elena Cabrio: elena.cabrio@inria.fr
Julien Cojan: julien.cojan@inria.fr


Sujet :

De nombreux travaux en cours portent sur la conception de systèmes de
réponse automatique à des questions posées en langue naturelle,
notamment l'anglais.

Le système QAKiS [1] développé dans l'équipe répond à des questions de
culture générale posées en anglais. Les réponses sont obtenues en
interrogeant avec des requêtes SPARQL DBpedia [2], qui est une base de
données extraites des pages de Wikipedia.

Le système QAKiS génère des requêtes SPARQL à partir de questions posées
en anglais puis soumet ces requêtes à DBpedia. Pour cela, il s'appuie
sur une base de motifs de phrases qui donnent différentes manières
d'exprimer une relation de DBpedia en anglais. Le système compare la
question posée aux motifs de la base pour identifier la relation de
DBpedia qui permettra d'obtenir une réponse. D'autres outils
interviennent ensuite pour identifier le type de réponse attendu et les
entités nommées de la question.

Le but de ce stage sera de porter ce système au français. En
particulier, il faudra expérimenter des méthodes d'extraction de motifs
à partir des versions francophones de Wikipédia et DBpedia. Il faudra
aussi revoir le traitement linguistique des questions, en intégrant des
outils adaptés a la langue française. Un deuxième développement envisagé
sera d'améliorer la reconnaissance des entités nommées, en intégrant au
système actuel des outils comme DBpedia Spotlight [3], qu'il faudra
aussi porter au français.


Profil souhaité :
  Ingénieur / Master.
  Intérêt pour le Web, notamment le web de données.
  Intérêt pour le traitement du langage.
  Programmation : Java, SQL, quelques connaissances sur le Web et le Web
  Sémantique (standards RDF-S/OWL/SPARQL, consommation de linked data )
  et/ou le traitement automatique des langues sont un plus.
  Bon niveau d'anglais.


[1] http://dbpedia.inria.fr/qakis (Cabrio et al., à paraître dans les
    actes de l'atelier Interacting with Linked Data 2012)
[2] http://dbpedia.org
[3] http://spotlight.dbpedia.org/


Elena Cabrio 
Postdoc Researcher, WIMMICS team 

INRIA Sophia-Antipolis Méditerranée 
2004 Route des Lucioles BP93 
06902 SOPHIA ANTIPOLIS cedex 
Tel: +33 (0)4 92 38 77 67 
email: elena.cabrio@inria.fr"
"129","2012-06-05","Homeloc","Paris","Proposition de stage

Génération automatique de texte pour le web

La société

Homeloc est un service destiné aux propriétaires de locations de
vacances, proposant de nombreuses fonctionnalités au sein d'une
interface unique :

- Multidiffusion des annonces sur de nombreux sites partenaires, avec
de fortes remises

- Création automatique d'un site dédié (ex : www.homeloc.com/test)

- Messagerie centralisée pour retrouver et traiter facilement les
demandes de réservation

- Synchronisation des calendriers de disponibilité

Pour les propriétaires, notre promesse est simple : générer plus de
réservations, tout en économisant du temps et de l'argent.

Objet du stage

L'objet du stage sera d'améliorer le système existant de génération de
descriptions en langage naturel à partir des données structurées sur
les offres de location de vacances.

Les données structurées (localisation, nombre de pièces, équipements,
etc.) sont soit saisies directement par les propriétaires sur le site
Homeloc, soit fournies sous forme de flux de données par des
partenaires. Ces données brutes peuvent, dans un premier temps, être
traitées et enrichies au moyen d'API externes et de sources de données
ouvertes (Open Data).

Ces données sont ensuite utilisées pour la génération automatique de
descriptions en langage naturel des offres de location. Ces
descriptions doivent être :

- adaptées au contexte de diffusion (site web dédié, flux pour un site
  partenaire...)

- formulées de manière unique pour chaque site, pour favoriser leur
  référencement

-écrites dans un français correct !

Intégré à l'équipe technique Homeloc, vous interviendrez sur l'amélioration et l'enrichissement des modèles de génération existants, ainsi que des règles linguistiques associées.

Votre profil

Nos attentes :

- maîtrise d'au moins un langage dynamique (Python, Ruby, Perl, PHP...)
- connaissances en traitement automatique des langues
- bonne maîtrise de la langue française
- vous êtes organisé, exigeant, curieux, et de bonne humeur
- vous avez envie d'intégrer une équipe agile

Bonus :

- expérience d'un framework de développement web (Django, Rails, Symfony...)
- familiarité avec un système de gestion de version (git, Mercurial, SVN)
- participation à des projets open-source

Notre environnement technique : Linux, Python, Tornado, MongoDB,
RabbitMQ...

Modalités du stage

Stage conventionné
Indemnité de stage : à négocier (selon profil)
Tickets restaurant
Remboursement de la carte orange (50%)
Lieu de travail : 46 rue de Provence, Paris 9e
Date de démarrage : dès que possible

Pour postuler

Par email : jobs@homeloc.com
Modalités : envoyez un CV (format PDF) ou un lien vers votre profil LinkedIn
Contact : Guillaume Cabane"
"130","2012-06-13","Systran","Paris","Internship description:

SYSTRAN has currently an opening for an internship of 4-6 months that
aims at the adaptation of its Portuguese language pairs to the new
spelling conventions for Portuguese.

The internship project would include the following tasks:

- Specification of rules to convert text according to the Portuguese
  Language Orthographic Agreement

- Adaptation of SYSTAN's lexical resources to the new spelling
  conventions

- Work on European Portuguese - Brazilian Portuguese localization of the
  Portuguese MT input and output

- Integration and testing of results

Required skills:

- Native competence of Portuguese, preferably Brazilian Portuguese, and
  fluency in English and French

- Profound knowledge of the Portuguese spelling reform and ability to
  specify rules converting text to the new spelling conventions

- Good working knowledge of computational lexicography and NLP methods
  in general

- Perl and scripting languages are a plus

- Strong communication skills and ability to work in a team

Please send your application and cover letter to Bianka Buschbeck:
buschbeck AT systran DOT fr"
"131","2012-10-18","Technicolor","Rennes","Internship position available at Technicolor R&D in Rennes.

Title
------
""Which scene are you talking about?""
Recognizing scenes discussed on cinema or TV forums.

Context
-------
For more info on Technicolor Research & Innovation, Rennes :
https://research.technicolor.com/rennes/

The internship will be hosted at Technicolor R&I in Rennes, France (500
employees, of which 130 researchers), within the Media Computing
Lab. Our lab aims at bringing modern trends in computing to the service
of novel media engines in content creation (visual effects, animation)
as well as content discovery and retrieval.
More specifically, our team focuses on Web user comments posted on
forums and social networks. We use various approaches such as data
mining, social network analysis and natural language processing.

Objective
---------
This internship aims at designing, developing and evaluating an
information extraction system for user comments. The domain is dedicated
to cinema and television. Each comment is already attached to a
particular audiovisual content (movie, TV series, TV program). One of
our goals is to detect within the comments the text segments which refer
to a particular moment in the video. For instance, users may talk about
their favorite scene or quote a famous dialogue.

Task description
-----------------
We will not analyze the audiovisual signal (image or audio), but solely
the text of comments. Comments have already been collected and saved
into a database. Hence the internship will focus on the analysis of the
dataset rather than its collection. The intern will be responsible for
choosing best techniques, based on a survey he or she will conduct on
state-of-the-art approaches.
The developed system will be evaluated by the intern, both
quantitatively and qualitatively. Depending on obtained results and
innovative ideas, this work may lead to a research publication in a
conference.

Keywords
---------
Natural language processing (NLP), machine learning, data mining, text
mining

Profile of the candidate
-------------------------
* Student in final year of master or science engineering school
* Computer science (Python, Java)
* Skills in machine learning, data mining and natural language
  processing
* Strong interest in research (will constitute a survey)
* Interest in social networks
* English mandatory
* Appreciates working with a team spirit

Internship period & duration
-----------------------------------
6 months, starting preferably around February or March 2013, depending
on the candidate's constraints.

Please email your CV and cover letter to
stage.rennes@technicolor.com<mailto:stage.rennes@technicolor.com> with
reference [TRDF-DM-029] in the subject."
"132","2012-10-31","Succeed Together","Paris","Recrutement stagiaire R&D


    Société :

PME innovante spécialisée dans le développement de la performance des 
réunions par l'accélération des échanges entre les participants, 
recherche un stagiaire pour intégrer notre pôle R&D, constitué de 2 
personnes, travaillant en lien avec des laboratoires d'informatique 
fondamentale affiliés au CNRS.

Nous développons des outils numériques de traitement de l'information 
permettant le regroupement sémantique de messages courts en temps réel.


    Poste et mission :

Nous développons un logiciel visant à synthétiser les idées exprimées 
dans des messages courts par des techniques de  TALN.
Le stagiaire aura pour mission principale de développer la performance
du système existant (clustering, utilisation de dictionnaires, mise au
point du machine learning ...).

Le stagiaire sera aussi amené à piloter le logiciel en séminaire devant
nos clients, parmi lesquels figurent de nombreux grands groupes (SNCF,
Sodexo, Safran, BNP Paribas, BPCE, Auchan, Vinci, Accor, Foncia, Crédit
Agricole...), afin de tester en situation le résultat de ce travail.


    Profil :

- Niveau Master
- Bon niveau en python
- Connaissance des systèmes GNU/linux
- Connaissances des technologies web appréciées 
  (html/javascript/jquery/css/django)

- Facilité relationnelle et bonne présentation

- Bonne approche conceptuelle de la résolution de problèmes, autonomie
  décisionnelle

- Bon niveau en anglais

- Stage d'une durée de 6 mois minimum - dès que possible

- Poste basé à Paris


Merci d'envoyer votre candidature à plloret@succeed-together.eu


Patrick LLORET
Mob : +33 (0)6 89 74 80 69
Mél : plloret@succeed-together.eu
http://www.succeed-together.eu"
"133","2012-11-09","CNES","Toulouse","Stage CNES Toulouse
Sciences de l'Univers

Utilisation des méthodes de la linguistique de corpus pour proposer
des améliorations dans la constitution et la rédaction de
L'encyclopédie d'exobiologie

""L'exobiologie est un domaine pluri disciplinaire faisant aussi bien
appel à la biologie, la chimie que la géologie, la planétologie... Une
première version de l'encyclopédie a été rédigée par les spécialistes
de ce domaine. Les travaux d'un stagiaire en linguistique ont
identifiés certaines pistes possibles d'amélioration (création d'un
indiex, d'un glossaire, clairifer les notions de mots-clés...). Une
deuxième version de l'encyclopédie est programmée pour 2014. Le but de
ce stage est d'identifier des axes concrets d'amélioration et de les
proposer aux rédacteurs de l'encyclopédie. Ce stage sera encadré par
DCT/PO/PM avec le support de DSI/SD/GI et de la faculté du Mirail. Le
stagiaire se partagera entre le CNES et la faculté du Mirail (afin
d'accéder aux outils d'analyse de corpus).

-Référence : 2013T171
-Accueil : DCT/PO/PM
-Nombre de place(s) : 1
-Durée (mois) : 6
-Date de début : 2ème semestre


Postuler en ligne sur :

http://www.cnes.fr/web/CNES-fr/175-stages-2011-2012.php?view=item&item=7352"
"134","2012-11-15","Plixee","Rouen","** Stage de M2 Recherche : Extraction automatique d'information de
contenus textuels

** Mots-clefs : Extraction de connaissances, analyse de 
dialogue/conversation, traitement automatique de la langue.

** Contexte :

Plixee est une startup fondée par trois ingénieurs de l'INSA de Rouen.
Elle développe une solution à destination du grand public, associations
et TPE visant à faciliter la communication et l'organisation de projets.
L'offre comble un manque constaté d'outils simples pour s'organiser de
manière dématérialisée. Elle permet d'éviter les discussions par emails
ou le panachage de plusieurs services dispersant l'information. Elle se
différencie des solutions existantes en ne fournissant que des outils
simples et ne se substitue pas aux logiciels avancés de gestion de
projets.
Une des grandes forces de Plixee est d'accompagner l'utilisateur dans le
processus créatif. En créant un espace dédié à leur projet, les
utilisateurs disposent d'un espace de discussion au sein duquel ils
peuvent échanger autour de leurs idées. Au fur et à mesure de leurs
discussions, les idées vont germer et amener à prendre des décisions.
Celles-ci se matérialisent par des éléments de projet que les
utilisateurs peuvent extraire directement depuis les messages
(questions, tâches, etc.). Ces éléments construisent alors petit à petit
le projet qui sera achevé au terme de leur consultation/réalisation.

** Objectif du stage :
Le processus d'extraction d'éléments au sein des discussions est pour le
moment réalisé manuellement par les utilisateurs. L'objectif de ce stage
est de faciliter ce processus en proposant des algorithmes et outils
suggérant ou extrayant automatiquement les éléments adéquats grâce à une
analyse du contenu de la discussion. On peut ainsi imaginer que dans une
conversation portant sur le choix d'une date de départ en vacances, le
système suggère automatiquement une question reprenant les différentes
possibilités évoquées dans des messages précédents.
Pour répondre à cette problématique, nous envisageons donc de recourir à
des systèmes d'analyse de contenu. Trois approches sont envisagées : Une
approche symbolique à l'aide de patrons linguistiques, qu'ils soient
construits manuellement ou automatiquement (voir [1] comme exemple
appliqué à la détection d'événements).
Une approche numérique permettant d'apprendre automatiquement les
informations à extraire (voir [2] pour une approche entièrement
automatique).
Une approche hybride, combinant les deux approches précédentes.  Par
ailleurs, la structure dialogique pourra également être exploitée afin
de faciliter l'extraction des éléments en question. [3], par exemple,
propose une méthodologie d'analyse de dialogues dont l'approche hybride
pourrait servir à détecter des structures courant sur plusieurs
messages.

** Travail à effectuer :
- Modélisation formelle du problème
- Étude bibliographique des solutions existantes
- Méthode(s) d'extraction automatique de connaissances
- Implantation et évaluation des résultats
Comme base de travail seront fournis : un corpus annoté et un prototype
simplifié issu d'un développement réalisé par deux étudiants en projet.

** Encadrement :
Vincent Durmont (Plixee) : vincent@plixee.com
Alexandre Pauchet (MIU@LITIS - INSA de Rouen) : pauchet@insa-rouen.fr
Quentin Suire (Plixee) : quentin@plixee.com

** Équipe d'accueil et déroulement du stage
Le stagiaire sera intégré dans la société Plixee et dans l'équipe
""Modélisation Interaction et Usages"" (MIU) du LITIS (EA 4108) à l'INSA
de Rouen. De façon générale, l'équipe MIU adopte une approche
pluridisciplinaire de sciences cognitives. Elle s'intéresse notamment à
la relation entre l'homme et les systèmes d'information et de sa
modélisation, posant comme axiome que les interactions sont
représentatives de l'usage. Le défi scientifique est de comprendre
comment modéliser les interactions entre l'homme et la machine ou entre
l'homme et l'homme avec la machine comme interface.
Le stage se déroulerait de février 2013 à juin 2013. L'étudiant serait
hébergé dans les locaux du laboratoire LITIS qui lui fournirait le
matériel nécessaire à son travail. La rémunération de l'étudiant serait
assurée par la société Plixee au tarif légal en vigueur (436,05EUR par
mois).

** Références bibliographiques
[1] L. Serrano, T. Charnois, S. Brunessaux, B. Grilhères, M. Bouzid.
Combinaison d'approches pour l'extraction automatique d'événements.
JEP-TALN-RECITAL'2012 - Grenoble, France.
[2] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P.
Kuksa. Natural Language Processing (Almost) from Scratch. Journal of
Machine Learning Research, 12:2493-2537, 2011.
[3] Z. Alès, G. Dubuisson Duplessis, O. Serban, A. Pauchet, A
Methodology to Design Human-Like Embodied Conversational Agents based on
Dialogue Analysis, Workshop HAIDM@AAMAS, Valencia, Spain, pp.34-49,
2012."
"135","2012-11-15","Centre de Rééducation Fonctionnelle de Kerpape","Lorient","Proposition de stage de fin d'études
""Optimisation ergonomique d'un système d'aide à la communication pour
des personnes lourdement handicapées""

Résumé
------------

Proposition de stage de recherche ou de fin d'études en informatique et
Interaction Homme-Machine pour l'aide au handicap
d'une durée de 4 mois minimum.

Version PDF : 
http://www.info.univ-tours.fr/~antoine/documents_enseignement/2013_Proposition_stage_Sibylle.pdf

Contexte scientifique
-------------------------------

En collaboration avec le Laboratoire d'Informatique de l'Université de
Tours, le laboratoire d'informatique du Centre Mutualiste de Rééducation
de Kerpape (56- Morbihan) propose un sujet de stage dans le cadre du
projet de recherche TMH (Télécommunications, Mobilité et Handicap)
financé par la société BAMSOO.

Une des actions envisagées dans le cadre du projet TMH est le
développement de solutions intégrées pour l'aide à la personne. Plus
précisément, nous nous intéressons à la mise en place de systèmes d'aide
à la communication pour des personnes souffrant de handicaps moteurs
très sévères (Infirmité Motrice Cérébrale, Scléroses Latérales
Amyotrophiques, syndrome d'enfermement...) se traduisant par une
tétraplégie ou une athétose accompagnée d'une perte de l'usage de la
parole. La communication est alors privée de son support oral habituel,
de même que les capacités très limitées de contrôle physique de
l'environnement par la personne handicapée empêchent toute saisie
directe de message sur un clavier d'ordinateur. L'aide à la personne
recherchée vise donc un objectif principal : pouvoir échanger avec
autrui par l'intermédiaire d'un système de suppléance informatique. Ce
système repose sur l'écriture de phrases à l'aide d'un clavier virtuel
affiché à l'écran. Un curseur se déplace automatiquement caractère par
caractère, le long du clavier virtuel. L'intervention de la personne
handicapée se limite à la désignation des symboles lorsque le curseur
est sur la touche ou le caractère désiré. Cette sélection est réalisée à
l'aide d'un dispositif physique qui remplace le périphérique d'entrée de
l'ordinateur (bouton pressoir, détecteur de souffle, suivi du
regard...). L'utilisation d'un module de prédiction de lettres et de
mots permet d'accélérer la saisie en évitant à l'utilisateur de saisir
tous les caractères du message.

Le laboratoire LI a déjà développé un tel système (Sibylle) qui repose
sur une prédiction de mots très efficace et est utilisé en routine dans
plusieurs centres de rééducation et laboratoires de recherche. Dans le
cadre de ce stage, la personne recrutée travaillera avec le centre de
rééducation fonctionnelle de Kerpare. Dans le cadre d'un projet
(VOLTAIRE) financé par la Fondation Motrice, une nouvelle interface de
l'application Sibylle a été développée précisément avec le centre de
rééducation de Kerpape, sans que cette dernière ne soit intégrée au
moteur de prédiction.

L'objectif de ce stage est d'élaborer une interface homme-machine
ergonomique qui facilite l'utilisation du système et permette de
bénéficier d'une manière optimale de la prédiction de mots. Cette
interface fera l'objet d'expérimentations réelles auprès de patients des
centres de Kerpape

Travail à réaliser
------------------------

La personne recrutée sera en charge à la fois de la conception et des
aspects développement logiciel mis en jeu au cours du stage, ainsi que
de la validation par tests utilisateurs réalisés à Kerpape. Le projet se
déroulera en trois phases successives :

Phase 1 - Réingénierie (1 mois 1/2) -- Reprise en main du code de
l'interface développée au cours du projet VOLTAIRE et interfaçage avec
le moteur de prédiction, documentation du code. Il s'agit d'un travail
de réingénierie qui servira avant tout au stagiaire à prendre la mesure
du projet proposé. Elle consistera à achever le travail d'intégration en
cours sur le système SIBYLLE seul.

Phase 2 - Ergonomie (2 mois 1/2) -- Evaluation d'une première maquette du
logiciel développé et analyse de ses faiblesse ergonomiques. Proposition
d'amélioration de l'interface pour optimiser le recours à la prédiction.
Plusieurs pistes d'améliorations peuvent déjà être citées :

- Renforcement des possibilités de configuration du système pour
  adaptation à l'utilisateur

- Étude du positionnement de la liste de prédiction, intégration
  éventuelle dans le clavier de lettres

- Renforcement de l'adaptation de l'interface au handicap et à
  l'utilisateur considéré

- Étude de l'adaptation de messages préenregistrés suivant le contexte
  d'utilisation. Ces phrases, composées à l'avance, servent le plus
  souvent pour la rédaction rapide de messages d'alertes ou de demandes
  pressantes. En modifiant la liste des messages suivant le contexte
  d'utilisation courant du logiciel, on augmente les possibilités de
  communication rapide

Phase 3 -- Dispositifs d'entrée intégrés ou mobile (1 à 2 mois suivant
la durée du stage) -- Cette phase est optionnelle. Elle dépendra de
l'avancée du travail et de la durée du stage. Elle consisterait soit, à
étudier l'usage du système de communication directement à partir d'un
dispositif de commande comme, par exemple, le joystick de commande du
fauteuil roulant autonome du patient, soit à travailler plus en avant
sur la portabilité du système sur des systèmes mobiles de type
smartphone ou tablet PC.

Profil recherché
-----------------------

La personne recrutée sera en cycle terminal d'études en informatique, de
niveau Bac+5 (Master informatique professionnel, recherche ou
indifférencié, école d'ingénieur). Des compétences en Interaction
Homme-Machine seront appréciées. Dans le cas d'un(e) étudiant(e) en
Master Recherche, le sujet de stage pourra être adapté aux attentes de
l'étudiant. Le cas échéant, une adaptation du sujet pourra être envisagé
pour des étudiants de Licence ou DUT informatique de très bon niveau
(mention Bien appréciée) : prévoir dans ce cas une prolongation de la
convention de stage.

Rémunération
--------------------

Rémunération maximale prévue par la règlementation à savoir 436,05 EUR
par mois durant les 4 premiers mois de stage. En cas de stage donnant
satisfaction, et/ou si l'étudiant doit/veut faire un stage d'une durée
supplémentaire, une prolongation de stage peut-être envisagée avec
rémunération au niveau du SMIC. Cette rémunération sera assurée dans le
cadre d'un projet industriel financé par la société BAMSOO.

Lieu d'exercice
-----------------------

La personne recrutée travaillera près de Lorient, au sein du Centre de
Rééducation Fonctionnelle de Kerpape. Il s'intégrera dans une équipe
projet composée de Jean-Paul Departe et Willy Allègre (Laboratoire
d'informatique du Centre de Rééducation Fonctionnelle de Kerpape) et de
Jean-Yves Antoine (Université François Rabelais de Tours).

Contact -- Dépôt des candidatures
-------------------------------------------------

Contact : Jean-Yves.Antoine@univ-tours.fr

Dépôt des candidatures : auprès de Jean-Yves Antoine. Merci de déposer
un CV détaillé de vos activités passées, accompagné d'une lettre de
motivation et de relevés de notes concernant vos deux dernières années
d'études.

Renseignements supplémentaires
--------------------------------------------------

Système Sibylle : 
http://www.info.univ-tours.fr/~antoine/SIBYLLE/Sibylle_fr/index.html
Centre de rééducation de Kerpape : http://www.kerpape.mutualite56.fr/"
"136","2012-11-15","Inbenta","Toulouse","*Société*

inbenta (http://www.inbenta.com/fr) est une société d'origine catalane
pionnière dans le Traitement Automatique du Langage Naturel (TALN) et la
recherche sémantique.  Basée sur ces concepts novateurs, inbenta
développe depuis 2005 des outils web pour les sites internet de Grands
Comptes.


Depuis 2009 et fort de son succès, inbenta étend ses activités sur le
territoire Français et a ouvert début 2012 une filiale sur Toulouse.


*Description de l'offre*

inbenta développe différents outils web qui permettent de répondre
automatiquement aux questions des internautes en puisant les réponses
dans une base de connaissances/FAQ constamment mise à jour.


Notre système de réponse repose sur un lexique basé sur la Lexicologie
Explicative et Combinatoire qui s'encadre dans la Théorie
Sens-Texte. Grâce à ce lexique et à ses fonctions lexicales, nous
pouvons générer des paraphrases. Notre algorithme va donc anticiper les
différentes formulations employées par les internautes pour exprimer une
même idée :

*J'ai perdu ma CB*

*je ne retrouve plus ma carte !!  *

*perte carte bleue*


L'objet du stage sera de participer à l'amélioration de notre système de
paraphrasage de notre système de Question / Réponse.


Le stagiaire devra comprendre et analyser la solution développée par
inbenta. Il devra s'imprégner de l'existant afin de faire évoluer
l'algorithme à travers notamment des cas clients concrets.


*Profil recherché*

Vous terminez vos études en Traitement Automatique du Langage Naturel
(Master 2) et souhaitez intégrer une structure innovante où vous pourrez
faire vos preuves et exprimer vos ambitions.


Passionné(e) par la linguistique informatique, vous avez bien entendu
une excellente maîtrise de la langue française et disposez d'un niveau
suffisamment bon en espagnol, anglais ou catalan afin de pouvoir
aisément communiquer avec les équipes de Barcelone.


Bonus :


- Maîtrise d'au moins un langage de programmation (PHP de préférence)
- Maitrise des expressions régulières et du SQL


*Modalités du poste*


- Stage de fin d'études conventionné de 6 mois (avec possibilité
  d'embauche en CDI)
- Rémunération prévue: conventionnelle + prime
- Début : à partir de Février / Mars 2013
- Lieu : Toulouse


Merci d'adresser CV et lettre de motivation par e-mail à l'adresse
suivante : *rh@inbenta.com*

Plus de détails sur cette offre de stage
ici : http://www.inbenta.com/images/france/offre-stage-tal.pdf

*Manon Quintana*
Computational linguist

*IN**B**ENTA*
+33 (0)5 31 54 94 97
www.inbenta.fr"
"137","2012-11-21","Nomao","Toulouse","Nomao SA est une start-up web innovante basée à Toulouse et fondée en
2006. Elle appartient au groupe leader européen de social media
Ebuzzing. Nomao conçoit et développe une application mobile et un site
web permettant aux gens de trouver, garder et échanger des bonnes
adresses entre amis (restaurants, bars, shopping, médecin...). C'est
un carnet d'adresse intelligent et connecté qui s'appuie sur des
technologies de pointe telle que : recherche géolocalisée, data
mining, systèmes de recommandation, traitement automatique des
langues.

Objet du stage


Dans le cadre de son développement, Nomao recherche des stagiaires R&D
de niveau M2 Informatique ou Sciences du Language avec une
spécialisation en Traitement Automatique des Langues. Les sujets de
stage à pourvoir touchent des domaines variés tels que : recherche
d'information géolocalisée, data mining, systèmes de recommandation,
traitement automatique des langues.

Déroulement du stage

Le/la stagiaire sera accueilli/e dans les locaux de Nomao (Toulouse
centre ville) et sera intégré/e dans l'équipe (5 personnes à Toulouse,
4 personnes à Paris). Le/la stagiaire recevra une indemnité de stage
(selon profil) et des titres restaurants.

Compétences requises

L'étudiant/e devra avoir de bonnes compétences en développement
logiciel et un intérêt pour le Web, les problématiques d'extraction et
d'analyse de données. La connaissance de Python, des technologies
linguistiques et la maîtrise d'une langue étrangère (hors anglais)
seront appréciées.

Contact Merci d'envoyer CV et lettre de motivation à : 
Estelle Delpech, estelle@nomao.com (responsable R&D)"
"138","2012-11-26","Reverso-Softissimo","Neuilly","Stage linguiste / terminologue / traducteur

Type de contrat : Stage de césure ou de fin d'études (minimum 4 mois)

Lieu : Neuilly-sur-Seine

Indemnité de stage : Selon durée et expérience

Début : Dès que possible

Avantages : Tickets restaurant et 50% transport

ENTREPRISE

Editeur de logiciels à rayonnement international, Reverso-Softissimo est
l'un des leaders mondiaux des solutions Intranet et Internet de
traduction instantanée et de dictionnaires électroniques.

Son portail grand public dédié aux langues www.reverso.net génère un
très fort trafic avec 200 millions de pages vues par mois et plus de 6
millions de visiteurs uniques.

Reverso-Softissimo recherche un(e) linguiste pour participer aux travaux
de production et de recherche de notre équipe linguistique dans un
contexte professionnel motivant : haute technologie, forte croissance et
développement international.

Vous êtes intéressé(e) par notre domaine ? C'est le moment de rejoindre
notre équipe !

MISSION

Sous la direction du chef de projet linguistique, le stagiaire
effectuera les missions suivantes :

- création, mise à jour, validation de dictionnaires bilingues ;
- tests de la qualité de traduction et rédaction de rapports d'analyse ;
- recherche, évaluation et analyse de ressources terminologiques ;
- animation et développement de la communauté d'utilisateurs du
  dictionnaire collaboratif.

Cette liste n'est pas exhaustive et pourra être amenée à évoluer en
fonction de l'implication du/de la stagiaire.

PROFIL

Étudiant(e) en dernière année d'une école ou d'une université en TAL,
langues étrangères, linguistique, ingénierie linguistique ou traduction,
vous maîtrisez parfaitement l'anglais et le français à l'oral comme à
l'écrit, et idéalement une troisième langue.

Vous avez des qualités rédactionnelles ainsi qu'une grande rigueur, une
bonne méthodologie, un esprit logique et des capacités d'analyse et de
synthèse ; votre sens de l'initiative, votre dynamisme et votre
autonomie seront également des qualités appréciées dans le cadre de ce
stage.

Contact :

Juliette MORNET
01.41.43.10.31
jmornet@reverso.com"
"139","2012-12-03","Orange","Eysines (33)","Intitulé : Amélioration de la qualité du moteur de recherche 118712

Mission
La direction 118712 est une entité marketing en charge de la définition,
de la conception et du déploiement des offres de renseignements annuaire
d'Orange sur différents canaux (renseignements téléphoniques, web,
mobile,...).

Le moteur de recherche du 118712 est accessible sur le web (2 millions
de visiteurs uniques par mois) et via l'appli mobile 118712.

L'objectif du stage est de définir et de mettre en ½uvre une stratégie
d'amélioration de la qualité des Listes Réponses du moteur mono champ
(Google like) du 118712.

Au moteur proprement dit est associé un analyseur de requêtes qui permet
de typer une requête utilisateur en identifiant ses différents
constituants (activité professionnelle, localité, adresse,
dénomination...) afin de lui appliquer des traitements
spécifiques. L'amélioration des réponses moteur et de l'analyseur de
requêtes sont à mener en parallèle.


L'ensemble des actions que vous mettrez en ½uvre s'articuleront en trois
étapes principales :

1- Analyse des Requêtes internautes et de leur résultat :
 - Choix d'un corpus de requêtes pour l'évaluation
 - Définition des typologies de demande
 - Evaluation de la pertinence du moteur de recherche et de l'analyse de
   requêtes


2- Analyse des anomalies de réponse aux requêtes internautes
 - Diagnostic sur les causes de non réponses (silence)
 - Diagnostic sur les causes de réponses non satisfaisantes (bruit)

3- Mise en ½uvre d'un plan d'action pour améliorer la qualité
 - Identification des leviers d'amélioration : données annuaire,
   paramétrage du moteur et de l'analyseur de requêtes, évolutions
   logicielles, ...
 - Priorisation des actions en fonction du bénéfice attendu
 - Prise en charge des paramétrages (référentiels de mots clés,
   stratégie de correction automatique de la requête, ...) et évaluation
   de l'effet sur le corpus
 - Rédaction du cahier des charges pour les évolutions logicielles

Vous mènerez à bien ces réalisations avec le soutien des équipes de
développement et dans le respect des orientations marketing.

Enfin, vous opérerez une veille technologique et concurrentielle active,
et vous vous en inspirerez pour trouver des propositions
d'améliorations.

Profil recherché
Formation bac + 5 (ingénieur, master pro ou recherche) en informatique,
technologies internet ou traitement automatique des langues. Stage de
fin d'étude ou de césure.

Compétences
- Intérêt marqué pour le web et les moteurs de recherche - Profil 
  « Ultra connecté »
- Manipulation de gros volumes de données, maîtrise d'Excel et d'outils
  de manipulation de bases de données (SQL, Access, Business Object,
  ...)
- Motivation, sens créatif et savoir être force de proposition, goût
  pour la résolution de problèmes
- Esprit d'analyse et capacité de synthèse, rigueur
- Qualités rédactionnelles et maîtrise de la langue, 
- Bonne communication

Modalités
Site de France Télécom à Eysines (Pres de Bordeaux)
6 mois à partir de mars 2010
Stage rémunéré
Contact : Laurence Grauby (mail : laurence.grauby@orange.com, Tel : 05
56 16 92 22)"
"140","2012-12-03","LeGuide.com","Paris","H/F Stage R&D/Moteur de Recherche

Contexte

Dans le cadre des évolutions de notre moteur de recherche indexant
plusieurs centaines de millions d'offres d' e-commerçants et servant
plusieurs dizaines de millions de requêtes par jour, vous êtes au c½ur
du processus d'optimisation du moteur et d'évaluation de nouvelles
solutions.

Mission

Rattaché(e) au responsable de l'équipe de moteur de recherche, ce
stage nécessitera votre implication dans les tâches suivantes :

    Tuning d'analyseurs linguistiques pour SolR dans 9 langues

    Développement de scripts en Python utilisés dans une plateforme
    d'amélioration de la pertinence du moteur de recherche

    Participation à la création d'un détecteur d'entités nommées basé
    sur le modèle de séquences CRF ( Conditional Random Field )

    Annotation d'un corpus d'apprentissage

    Développement de scripts en Python pour piloter l'apprentissage du
    détecteur

    Évaluation du modèle sur des offres d' e-commerçants

    Évaluation de l'apport du détecteur lors de la recherche

    Développement de tests

Profil

Vous suivez une formation supérieure de type ingénieur ou
équivalent. Vous avez des connaissances en languages de programmation
(C++ et/ou Java) et idéalement aussi dans un language de scripting
(Python, Shell). Vous avez un réel intérêt pour le traitement
automatique des langues et les technologies de recherche
d'information.

Votre réactivité, votre envie de participer à un projet technique
d'envergure et votre rigueur seront des atouts pour vous épanouir dans
cette mission.

Un bon niveau d'anglais lu est indispensable.  La compréhension de
l'écrit d'une ou plusieurs langues parmis allemand, danois, espagnol,
italien, néerlandais, polonais, suédois est un plus.

Conditions

Type de contrat : Stage conventionné de 6 mois idéalement

Début : janvier 2013

Indemnités de stage : selon profil et durée du stage (+ tickets restaurant et 50% Pass Navigo)

Lieu de travail: Paris 10e arrondissement


Envoyez votre CV et une lettre de motivation par mail à l'adresse
recrutement@leguide.com en précisant l'intitulé du poste."
"141","2012-12-12","Compilation","Saint-Felix (74)","Proposition de stage de M2 dans l'entreprise Compilatio (Saint-Félix,
74) :

*Extraction et modélisation de connaissances d'un document texte*

Le stage consiste à étudier les méthodes existantes pour faire de
l'analyse de documents, l'extraction de mots-clés, l'extraction de
thématiques dans le but de créer une signature sémantique du document.


Le stage de 6 mois se déroulera à Saint-Félix en Haute-Savoie (Vers
Annecy et Chambéry).
Il sera rémunéré de manière conventielle.

Renseignements et candidatures :
Alain Simac-Lejeune : alain@compilatio.net

*L'entreprise* : Compilatio est un éditeur de logiciel (entreprise
innovante) propose un service en ligne pour l'analyse de documents pour
la prévention et la détection de plagiat. Leader français de la
détection de plagiat créé en 2007, l'entreprise sert plus de 200
établissements supérieurs et analyse quotidiennement plus de 1000
documents."
"142","2012-12-12","Compilation","Saint-Felix (74)","Proposition de stage de M2 dans l'entreprise Compilatio (Saint-Félix,
74) :

*Recherche de similitudes dans Wikipedia avec SPARQL (DBPedia)*

Le stage consiste à étudier le projet DBpedia, le SPARQL et Wikipédia et
de proposer un outil permettant la recherche d'articles de Wikipédia
présentant des similitudes avec le document analysé.


Le stage de 6 mois se déroulera à Saint-Félix en Haute-Savoie (Vers
Annecy et Chambéry).
Il sera rémunéré de manière conventielle.

Renseignements et candidatures :
Alain Simac-Lejeune : alain@compilatio.net

*L'entreprise* : Compilatio est un éditeur de logiciel (entreprise
innovante) propose un service en ligne pour l'analyse de documents pour
la prévention et la détection de plagiat. Leader français de la
détection de plagiat créé en 2007, l'entreprise sert plus de 200
établissements supérieurs et analyse quotidiennement plus de 1000
documents."
"143","2013-01-09","LIMSI","Orsay","Stage M1/M2Pro/M2R : Analyse temporelle de pages web d'information.

Mots-clés : traitement automatique de la langue, classification,
analyse temporelle

Durée : 2 à 6 mois

Niveau : Master 1 ou Master 2 (professionnel ou recherche), fin
d'école d'ingénieur

Le contenu et l'ambition du stage pourront être modulés en fonction du
niveau d'étude et de la durée du stage du candidat.

Contexte

L'analyse temporelle de textes d'information a pour but général de
mieux localiser dans le temps les événements décrits dans ces textes,
et donc d'alimenter de façon plus précise des moteurs de recherche ou
des outils d'extraction d'information. Pour cela, la première étape
est de détecter correctement les expressions temporelles de ces
textes. Ces expressions temporelles peuvent être des dates absolues,
c'est-à-dire que l'on peut placer sans ambiguïté sur l'axe des temps
(par exemple, le 14 juillet 1789), mais aussi des dates relatives, qui
nécessitent une phase de résolution ou de normalisation (par exemple,
le 14 juillet dernier, mardi, il y a deux jours ou deux jours
avant). On devine que cette normalisation nécessite au minimum de
connaître la date à laquelle le document a été écrit.

Les techniques d'analyse temporelle des textes ont fortement progressé
ces dernières années, mais s'attachent en général au traitement
d'articles de journaux sous forme structurée, dans lesquels le contenu
et les metadonnées sont clairement identifiés. Dans le cas de pages
web, il est beaucoup plus difficile de distinguer les informations
pertinentes (date de création, auteurs, titre et texte de
l'article...) des données annexes comme les menus, les publicités, les
légendes d'images. Des outils de nettoyage de pages existent, mais ils
ne sont pas assez précis pour les tâches que nous souhaitons
accomplir.  Travail à réaliser :

Selon le niveau d'étude de la personne choisie, nous pourrons nous
intéresser à une ou plusieurs des problématiques suivantes :

    Extraction de la date de création des pages d'information, et
    d'autres métadonnées éventuellement pertinentes

    Améliorations ciblées du nettoyage des pages web issues des sites
    d'information

    Utilisation et adaptation des outils d'analyse temporelle sur les
    pages web nettoyées

On utilisera un corpus de plusieurs millions de pages web en français
et en anglais.

Le stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue et en
apprentissage automatique seront un plus.

Durée : 2 à 6 mois
Niveau : Master 1 ou Master 2 (professionnel ou recherche)
Contacts :
Veronique.Moriceau[at]limsi.fr
Xavier.Tannier[at]limsi.fr"
"144","2013-01-09","INRIA","Sophia-Antipolis","Proposition de stage Master/Ingénieur:
Maquettage d'un système d'interaction avec des connaissances linguistiques.

Sujet:

Ce stage à dominante IHM et Ergonomie Logicielle s'effectuera au sein de
l'équipe WIMMICS [1] de l'Inria Sophia-Antipolis. 
Les linguistes du projet RELIEF [2] développent une ressource lexicale
de nouvelle génération - le Réseau Lexical du Français (RLF) - en accord
avec la théorie Sens-Texte [3]. Pour le moment, le logiciel d'édition
développé pour le projet RELIEF, MVS Dicet, ne permet pas de représenter
les définitions des mots aussi formellement que le voudrait la théorie
Sens-Texte. Or une telle formalisation est aujourd'hui nécessaire pour
faciliter le travail des linguistes et accélérer l'élaboration du RLF. 
L'équipe WIMMICS s'inspire des Graphes Conceptuels [4], de la Théorie
Sens-Texte et des Grammaires de Dépendances [5], pour développer le
nouveau formalisme mathématique des Graphes d'Unités [6], qui a pour but
de permettre la formalisation des définitions, et plus généralement la
représentation et la manipulation de connaissances linguistiques à base
de graphes et de règles.
Ce stage s'insère donc en amont du développement de deux prototypes
d'éditeurs: un prototype d'éditeur permettant l'interaction avec des
objets du formalisme générique, et un prototype d'extension du logiciel
d'édition lexicographique Mvs Dicet développé pour le projet RELIEF.

Objectifs:

L'objectif de ce stage est de proposer des scénarios d'interaction avec
les objets de base du formalisme des graphes d'unités, et de maquetter
un prototype d'éditeur.

Durée, lieu: 

4-6 mois, rémunérés, au sein de l'équipe WIMMICS [1] de l'Inria
Sophia-Antipolis.


Profil souhaité: 

Ce stage s'adresse en priorité à des étudiant en Ingénieur / Master,
avec une dominante IHM et Ergonomie Logicielle. Un intérêt pour les
Graphes Conceptuels et/ou le traitement du langage est un plus.

Contacts et envoi des candidatures:

Maxime Lefrançois, maxime.lefrancois[at]inria.fr, Alain Giboin,
alain.giboin[at]inria.fr

Pointeurs

[1] http://wimmics.inria.fr  
[2] Projet RELIEF, Réseau Lexical du Français, et Bibliographie de
    référence http://www.atilf.fr/spip.php?article908
[3] http://en.wikipedia.org/wiki/Meaning%E2%80%93text_theory
[4] http://en.wikipedia.org/wiki/Conceptual_graph
[5] http://en.wikipedia.org/wiki/Dependency_grammar
[6] http://maxime-lefrancois.info"
"145","2013-01-09","IRISA","Rennes","*Title: Grapheme-to-phoneme conversion adaptation using conditional 
random fields*

*Description:*
Grapheme-to-phoneme conversion consists in generating possible
pronunciations for an isolated word or for a sequence of words. More
formally, this conversion is a transliteration of a sequence of
graphemes, i.e., letters, into a sequence of phonemes, symbolic units to
represent elementary sounds of a language. Grapheme-to-phoneme
converters are used in speech processing

- either to help automatic speech recognition systems to decode words
  from a speech signal

- or as a mean to explain speech synthesizers how a written input should
  be acoustically produced.

A problem with such tools is that they are trained on large and varied
amounts of aligned sequences of graphemes and phonemes, leading to
generic manners of pronouncing words in a given language. As a
consequence, they are not adequate as soon as one wants to recognize or
synthesize specific voices, for instance, accentuated speech, stressed
speech, dictating voices versus chatting voices, etc. [1].

While multiple methods have been proposed for grapheme-to-phoneme
conversion [2, 3], the primary goal of this internship is to propose a
method to adapt grapheme-to-phoneme models which can easily be adapted
under conditions specified by the user. More precisely, the use of
conditional random fields (CRF) will be studied to model the generic
French pronunciation and variants of it [4]. CRFs are state-of-the-art
statistical tools widely used for labelling problems in natural language
processing [5]. A further important goal is to be able to automatically
characterize pronunciation distinctive features of a given specific
voice as compared to a generic voice. This means highlighting and
generalizing differences that can be observed between two sequences of
phonemes derived from a same sequence of graphemes.

Results of this internship would be integrated into the speech synthesis
platform of the team in order to easily and automatically simulate and
imitate specific voices.

*Technical skills:* C/C++ and a scripting language (e.g., Perl or
 Python)

*Keywords:* Natural language processing, speech processing, machine
 learning, statistical learning

*Contact:* Gwénolé Lecorvé (gwenole.lecorve@irisa.fr)

*References:*
[1] B. Hutchinson and J. Droppo. Learning non-parametric models of
    pronunciation. In Proceedings of ICASSP, 2011.
[2] M. Bisani and H. Ney. Joint-sequence models for grapheme-to-phoneme 
    conversion. In Speech Communication, 2008.
[3] S. Hahn, P. Lehnen, and Ney H. Powerful extensions to crfs for
    grapheme to phoneme conversion. In Proceedings of ICASSP, 2011.
[4] Irina Illina, Dominique Fohr, and Denis Jouvet. Multiple
    pronunciation generation using grapheme-to-phoneme conversion based
    on conditional random fields. In Proceedings of SPECOM, 2011.
[5] John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira.
    Conditional random fields: probabilistic models for segmenting and
    labeling sequence data. In Proceedings of ICML, 2001."
"146","2013-01-09","Semantia","Marseille","Semantia est un fournisseur de services en ligne (ASP), spécialisé dans
le traitement du langage pour l'optimisation de la gestion de la
relation client.

Contexte du stage TAL
Intégré au service de Recherche et Développement, l'objectif du stage
est de participer à l'optimisation des Bases de Connaissances des
applicatifs de la société pour le traitement et l'analyse du langage.
Après s'être familiarisé avec les outils et les solutions Semantia, il
devra proposer des solutions d'optimisation du module morpho-syntaxique.

Connaissances requises et/ou acquises :

  *   Bonnes connaissances des outils disponibles en TALN, plus
      particulièrement des Grammaires
  *   Esprit d'équipe
  *   Sens de l'initiative
  *   Autonomie
  *   Rigueur
  *   Motivation

Niveau : Bac+3 minimum en Linguistique

Durée du stage : de 3 à 6 mois


Contacts

  *   drh@semantia.com
  *   Tél. : 04 42 36 80 91"
"147","2013-01-09","Sinequa","Paris","Offre de stage 2013

Sujet : Amélioration d'un module d'analyse linguistique pour la
recherche d'information en coréen ou en japonais

Lieu : Sinequa, 12 rue d'Athènes, 75009 Paris

Cadre : Master 1 ou 2 en Linguistique-Informatique ou spécialité TAL

Compétences :
- Bonnes bases informatiques, maîtrise d'un langage de script (type
  PERL).
- Maîtrise avancée du coréen ou du japonais.

Indemnités : selon niveau et expérience.

Début : dès que possible.

Contact: Frederik Cailliau, cailliau@sinequa.com"
"149","2013-01-09","LIRMM","Montpellier","l'équipe TEXTE du LIRMM (Montpellier) propose un stage de recherche
(niveau M2 ou équivalent) en Traitement Automatique des Langues
(TAL). Ce stage, d'une durée de 5 mois environ (a priori de février à
juin 2013), sera financé à hauteur du montant légal en vigueur (environ
400 ¤ net / mois).

Le stage portera sur l'un, au choix, des deux sujets proposés (cf. plus
bas).

Des candidatures rapides sont souhaitées avant le 9 janvier 2013 à 12h00
(midi). Toutefois, si le stage devait ne pas être pourvu, les
candidatures seraient considérées jusqu'à la fin janvier.

Merci de joindre à votre candidature les documents suivants :
- CV
- les notes de M1 et les modules de M2 suivis (ajouter les notes si
  elles sont connues).

Merci de préciser également quel sujet a votre préférence.

* Sujet 1 : Acquisition automatique de grammaires de contraintes

http://www.lirmm.fr/~prost/enseignement/M2R-stages/2012-2013/sujetM2R-acquisitionGP.pdf

* Sujet 2 : Détection et correction d'erreurs grammaticales
http://www.lirmm.fr/~prost/enseignement/M2R-stages/2012-2013/sujetM2R-HOO.pdf

Les candidatures doivent être envoyées à Jean-Philippe Prost
(Prost@lirmm.fr) et Mathieu Roche (Mathieu.Roche@lirmm.fr)."
"150","2013-01-09","Airbus","Toulouse","In the purpose of improving the quality and precision of oral
messages, the objective of the proposed training job is to study the
way an oral alert should be addressed in cockpit.

This study will concern Airbus Civil Aircrafts and will consist in:
 
Details of the mission :

    Defining the requirements regarding speech synthesis in order to
    ease comprehension :

    Man vs. Woman
    Prosody

    Accentuation
    Intensity
    Intonation
    Rhythm

    Speed
    Repetition

 

    Describing (in different languages) the different ways to express
    (syntax & terminology):

    Order
    Prohibition
    Advise
    Questioning
    Normal vs. Abnormal status

 
 

    Defining efficient combinations to describe emergency
    (e.g. repetition + man voice)

 

    Collecting the distinctive features of different pilots' mother
    tongues (English US, Arabic, Chinese, Russian, and Italian) in
    order to study the proximity of sounds between English US and the
    mother tongues of end users, to check the relevance of the
    new-built words.

 
Required competences :

    Linguistics
    Phonetics/phonology
    Sociolinguistics
    Pragmatics

 
Required level/diploma : BAC+5, 3ème cycle
 
Duration : 6 months (starting in April 2013)
 
Localisation :
AIRBUS France SAS
316, route de Bayonne
31060 Toulouse Cedex 03
 
To file your application, please send us your covering letter and your CV.
 
Contact:
Emmanuelle Cannesson
( 33.(0)5.67.19.97.34
emmanuelle.cannesson@airbus.com
 
Florence Beaujard
( 33.(0)5.61.93.98.14
florence.beaujard@airbus.com"
"151","2013-01-16","LIMSI","Orsay","Le LIMSI-CNRS propose le stage suivant en TAL pour un niveau M2/écoles
d'ingénieur :

Réparation d'erreurs d'apprenants d'une langue étrangère à l'aide de
systèmes de traduction automatique

URL : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2R-2013.html

Contact : Ryo Nagata (rnagata@limsi.fr), Gabriel Illouz 
(gabriel.illouz@limsi.fr) et Aurélien Max (aurelien.max@limsi.fr)

Toute personne intéressée est invitée à contacter les personnes
ci-dessus par e-mail (avec pour titre : ""Re: Stage en TAL au LIMSI-CNRS,
Orsay""), en envoyant un CV à jour (*dont le fichier porte le nom du
candidat*) et un court texte motivant l'intérêt pour ce sujet en
relation avec les études suivies.

Le groupe ILES du LIMSI propose en outre de nombreux autres sujets de
stages : http://www.limsi.fr/Scientifique/iles/propositions"
"152","2013-01-16","Onyme","Lille","------------------------------------------------------------------------
Envoyez votre candidature par email: recrute@onyme.com 
------------------------------------------------------------------------


La société Onyme (http://www.onyme.com) recherche, en *2013*, un(e)
stagiaire de*deuxième année de master en informatique*, avec un attrait
pour le traitement automatique des langues. Une embauche à l'issue du
stage est envisagée.

*Profil* : Bac +5
*Durée du stage* : de 3 à 6 mois selon le sujet choisi.
*Lieu du stage* : Onyme (http://www.onyme.com), Euratechnologies 
 (http://www.euratechnologies.com)

Le stage s'inscrit au coeur de l'équipe de R&D composée d'un doctorant
en informatique (4ème année), d'un docteur en informatique et du
directeur technique de la société.

Il se compose de *deux sujets au choix* sur le traitement de la langue
française :

  * Sujet 1 : Évaluation de différents analyseurs lexicaux et
    syntaxiques sur des textes courts
    (http://blog.onyme.com/offre-de-stage-tal-2013/#suj1)
  * Sujet 2 : Reconnaissance / Extraction de thématiques dans des textes
    courts (http://blog.onyme.com/offre-de-stage-tal-2013/#suj2)


  Sujets

      Sujet 1 : Évaluation de différents analyseurs lexicaux et
      syntaxiques sur des textes courts

*Durée souhaitée du stage* : de 4 à 6 mois, selon les connaissances du
 candidat.

*Compétences souhaitées* :

  * Connaissances théoriques sur des analyseurs syntaxiques et lexicaux
    (la pratique est un plus);
  * Connaissances sur l'étiquetage grammatical et syntaxique de corpus
    écrits;
  * Motivé et autonome.

*Description du sujet* :

Les analyseurs lexicaux, i.e. lemmatiseurs et POS annotateurs, et
syntaxiques fonctionnent soit par apprentissage, soit par règles.

Ces outils, élaborés à partir de connaissances générales (ex :
apprentissage à partir d'un gros corpus de journaux), sont sujets à
erreur quand ils sont utilisés dans un domaine spécialisé.

L'idée du stage est d'améliorer les analyses en fournissant des
connaissances spécifiques aux analyseurs.

Le sujet comporte plusieurs aspects :

  * élaboration de corpus arborés depuis les traitements clients
    destinés à l'évaluation et à l'apprentissage des analyseurs;
  * apprentissage spécifique, ou ajout/modification de règles, selon le
    type d'analyseur;
  * évaluation de différents analyseurs lexicaux sur nos données;
  * évaluation d'analyseurs syntaxiques de surface (chunker) et
    d'analyseurs partiels, ou élaboration d'un chunker.


      Sujet 2 : Reconnaissance / Extraction de thématiques dans des
      textes courts

*Durée souhaitée du stage* : de 3 à 6 mois, selon les connaissances du
candidat.

*Compétences souhaitées* :

  * Connaissances sur les analyseurs syntaxiques : délimitation de
    syntagmes;
  * Programmation en langage orienté objet. Le langage JAVA est un plus;
  * Connaissances en apprentissage artificiel (classification
    thématique);
  * Connaissances en structure du discours (Ex. : ""X mais Y"" implique
    deux idées);
  * Motivé et autonome.

*Description du sujet* :

Les textes à analyser comportent des thématiques différentes relatives à
un domaine.

Par exemple, dans le domaine de la vente, les thématiques fréquemment
abordées sont :

  * La tarification;
  * L'agencement des magasins;
  * L'implantation des magasins;
  * Le personnel.

Le sujet du stage concerne la résolution des problématiques liées 
suivantes :

  * l'évaluation du nombre de thématique abordés dans un message;
  * la détection;
  * la séparation d'un message en plusieurs syntagmes thématiques.

La liste des thèmes à détecter peut être connue à l'avance ou non. Dans
le premier cas, des techniques relevant de la supervision peuvent être
employées. Dans le second, il s'agit de découvrir de façon non
supervisée les thèmes présents dans un corpus.



Plus de détails concernant les sujets et l'offre sur notre blog : 
http://blog.onyme.com


------------------------------------------------------------------------
Envoyez votre candidature par email: recrute@onyme.com 
------------------------------------------------------------------------"
"153","2013-01-21","LIPN","Villetaneuse","stage M2 : apprentissage multi-objectif pour les données
textuelles
========================================================================

    De nombreuses applications en traitement automatique des langues et
    en extraction d'information utilisent les analyses syntaxiques des
    textes. Bien que les analyseurs syntaxiques modernes, appris sur
    corpus, atteignent des performances globales tout à fait
    satisfaisantes, on remarque souvent que les informations utiles aux
    applications sont mal analysées.

    Pour pallier ce problème, il peut être intéressant d'apprendre un
    analyseur pour une application précise, par exemple la traduction
    automatique, les systèmes de questions/réponses, ou l'extraction de
    relations/événements dans des textes.

    Récemment, Hall et al. [TDPJOMO] ont proposé une méthode
    d'apprentissage en ligne (de type perceptron) pour intégrer des
    fonctions de perte non plus strictement syntaxiques mais qui portent
    plus librement sur des structures induites par les structures
    syntaxiques, notamment les structures produites par les applications
    en aval.

    Le but de ce stage est d'étudier cette méthode, l'apprentissage
    multi-objectif, de la généraliser à d'autres algorithmes
    d'apprentissage en ligne, de l'implanter dans un analyseur standard
    -- en l'occurrence [MSTparser] -- et de l'appliquer à la tâche
    d'extraction de relations/événements sur des textes biomédicaux.

    profil recherché: Nous cherchons un candidat :
      - de niveau M2
      - compétent  en java et python
      - ayant des notions d'apprentissage automatique
      - avec un intérêt pour le traitement automatique des langues

    détails: Dans un premier temps, l'étudiant devra se familiariser
    avec :
      - la notion d'extraction de relations
      - la chaîne de traitement [TEES] qui a gagné le challenge BioNLP
        2009
      - le corpus GENIA sur lequel le travail portera
      - l'analyseur MSTParser

      Dans la suite du stage, il devra d'abord évaluer la chaîne
      d'extraction lorsqu'elle est utilisée avec le MSTParser sur une
      grammaire apprise indépendamment de la tâche. Il s'agira ensuite
      d'implanter un algorithme d'apprentissage multi-objectif de la
      grammaire et d'évaluer son incidence sur les performances du
      système.

    contexte: Équipe RCLN du LIPN, Université Paris 13.

    durée: 6 mois

    contact: Contacter Joseph Le Roux (leroux@univ-paris13.fr) et
             Antoine Rozenknop (antoine.rozenknop@lipn.univ-paris13.fr)
             en joignant un CV au mail.

    divers: Stage rémunéré dans le cadre d'une opération du labex
            [EFL]. Ce stage est susceptible de se prolonger par une
            thèse.

[TDPJOMO]: http://www.aclweb.org/anthology/D/D11/D11-1138.pdf
[MSTparser]: http://sourceforge.net/projects/mstparser/
[TEES]: https://github.com/jbjorne/TEES
[EFL]: http://www.labex-efl.org/"
"154","2013-01-21","EpticaLingway","Boulogne-Billancourt","Linguiste-informaticien pour le chinois - M2
 
Début : Mars 2013

Durée : 4 à 6 mois

Lieu : Boulogne-Billancourt

 
EpticaLingway est l'entité de R&D du groupe Eptica, principalement
orienté vers les applications de Traitement du Langage Naturel (TAL).
 
Le groupe EPTICA est un des leaders français et international de
solutions d'interactions clients en pleine croissance. Cette entreprise
à taille humaine et à dimension internationale est basée principalement
en France, Royaume Uni et Singapour. Elle édite une solution reconnue
qui s'adresse aux grands comptes et au mid-market dans les secteurs du
Retail, de la Finance, de l'Assurance, du Secteur Public. La société
compte parmi ses clients français la Société Générale, le Crédit
Agricole, la CNAM, la MAAF, MMA, Pixmania, Darty, Mercer, Carrefour, La
Redoute..., et, également à l'international Air Asia, Panasonic... Elle est
répertoriée dans le Magic Quadrant du Gartner Group depuis 2010.

Afin d'enrichir ses composants sémantiques de traitement du chinois,
EpticaLingway propose un stage conventionné niveau Master 2, basé à
Boulogne-Billancourt

Dans l'équipe EpticaLingway, Le candidat participera à l'ensemble des
tâches suivantes:

·  Évaluation/amélioration du segmenteur,
·  Constitution de ressources lexicales,
·  Mise en ½uvre de ces ressources dans le moteur de recherche,
·  Constitution d'un corpus de référence et évaluation
 
Compétences requises
·  Chinois courant,
·  Pratique du TAL (étude de corpus, moteur de recherche, grammaires
   locales)
·  Un langage de développement (Java, Groovy, Perl, ...) serait un plus
·  Facilité à travailler en équipe

Envoyer CV et lettre de motivation à hugues.de-mazancourt@eptica.com"
"155","2013-01-21","EpticaLingway","Boulogne-Billancourt","Linguiste-informaticien - constitution de référentiels en
français

Début : Mars 2013

Durée : 4 à 6 mois

Lieu : Boulogne-Billancourt

EpticaLingway est l'entité du groupe EPTICA dédiée aux applications de
Traitement du Langage Naturel (TAL).

Le groupe EPTICA est un des leaders français et international de
solutions d'interactions clients en pleine croissance. Cette entreprise
à taille humaine et à dimension internationale est basée principalement
en France, Royaume Uni et Singapour. Elle édite une solution reconnue
qui s'adresse aux grands comptes et au mid-market dans les secteurs du
Retail, de la Finance, de l'Assurance, du Secteur Public. La société
compte parmi ses clients français la Société Générale, le Crédit
Agricole, la CNAM, la MAAF, MMA, Pixmania, Darty, Mercer, Carrefour, La
Redoute..., et, également à l'international Air Asia, Panasonic... Elle est
répertoriée dans le Magic Quadrant du Gartner Group depuis 2010.

Dans le cadre d'un projet de constitution de référentiel documentaire
généraliste pour une bibliothèque, EpticaLingway propose un stage
conventionné niveau M2, basé à Boulogne-Billancourt.

Le candidat participera à l'ensemble des tâches suivantes:

·  Etude du corpus client,
·  Utilisation des outils Lingway de production/structuration des
   référentiels,
·  Validation des résultats
 
Compétences requises :
· TAL (étude de corpus, moteur de recherche, grammaires locales)
· Techniques documentaires
· Des connaissances en programmation (Java, Groovy, Perl, ...) sont un
  plus
· Facilité à travailler en équipe

Envoyer CV et lettre de motivation à hugues.de-mazancourt@eptica.com"
"156","2013-01-28","Lattice","Montrouge","Proposition de stage : acquisition semi-automatique de patrons
caractéristiques à partir de textes


* Descriptif :

Le stage vise à extraire semi-automatiquement des patrons
syntaxico-sémantiques à partir de textes. Cette tâche a plusieurs
applications possibles : les patrons peuvent servir à repérer des
éléments précis dans un texte (tâche classique d'extraction
d'information) mais ils peuvent aussi servir de base à des travaux plus
linguistiques, visant par exemple à caractériser des textes en fonction
de particularités qui ne sont pas directement observables.

Les outils existants reposent essentiellement sur des patrons très
proches des formes de surface (Hearst 1992) ou sur des méthodes à base
d'apprentissage produisant de très nombreux patrons qui sont ensuite
difficiles à trier et à analyser (Quiniou et al., 2012). Ces études ont
toutefois mis en avant des approches efficaces et reposant sur un
certain nombre de points communs (préanalyse du texte par un analyseur
morphosyntaxique, repérage de séquences continues ou non, contraintes
sur le niveau d'analyse possible). Pour aller plus loin, il semble
nécessaire de proposer des approches interactives, de sorte que
l'analyste puisse spécifier dynamiquemlent ses besoins et ainsi guider
au mieux l'analyse.


* Déroulement du stage

Le stage se déroulera suivant plusieurs étapes :

- état de l'art et choix d'une approche adéquate
- implémentation d'un algorithme interactif (en réutilisant si possible
  un logiciel existant pour l'acquisition des patrons eux-mêmes)
- validation sur une tâche à préciser (la tâche visée et le corpus
  seront discutés au début du stage)
- rédaction d'un rapport de stage

* Références


- Marti Hearst (1992). ""Automatic Acquisition of Hyponyms from Large
  Text Corpora."" In: Proceedings of the 14th International Conference on
  Computational Linguistics (COLING-1992). doi:10.3115/992133.992154.

- Solen Quiniou, Peggy Cellier, Thierry Charnois, Dominique Legallois
  (2012). What About Sequential Data Mining Techniques to Identify
  Linguistic Patterns for Stylistics? Proceedings of
  Cicling. http://hal.archives-ouvertes.fr/hal-00675578.

* Compétences requises

- bonne connaissance d'un langage de programmation (java, perl ou python
  seraient particulièrement appréciés)
- intérêt pour le traitement automatique du langage naturel
- intérêt pour l'intelligence artificielle, en particulier
  l'apprentissage automatique
- qualité de rédaction en français et en anglais


* Conditions :

Le stage se déroulera au laboratoire Lattice (à Montrouge,
http://www.lattice.cnrs.fr/) pendant 6 mois, à partir d'avril 2013. Ce
stage est indemnisé grâce au soutien du laboratoire d'excellence
""Empirical Foundations of Linguistics"" (labex EFL,
http://www.labex-efl.org/). Le stage fait partie d'un projet plus large
visant à étudier la contribution de sources de connaissances pour
l'extraction d'information, mené en commun entre le LATTICE et le LIPN
dans le cadre du labex EFL.

* Comment postuler ?

Envoyer par mail un CV et une lettre de motivation à Thierry Poibeau
(prenom.nom@ens.fr) avant le 7 février 2013. Indiquer ""stage :
acquisition semi-automatique de patrons caractéristiques à partir de
textes"" comme sujet du mail."
"157","2013-01-31","Sinequa","Paris","Offre de stage 2013

Sujet : Amélioration d'un module d'analyse linguistique pour la
recherche d'information en chinois.

Lieu : Sinequa, 12 rue d'Athènes, 75009 Paris

Cadre : Master 1 ou 2 en Linguistique-Informatique ou spécialité TAL

Compétences :
- Bonnes bases informatiques, maîtrise d'un langage de script (type
  PERL).

- Maîtrise avancée du chinois.

Indemnités : selon niveau d'études.

Début : dès que possible.

Contact: Frederik Cailliau, cailliau@sinequa.com"
"158","2013-02-04","Idiap","Martigny (CH)","Internship at the Idiap Research Institute, Martigny, Switzerland

Learning verb tense translation from parallel corpora for statistical
machine translation

http://www.idiap.ch/education-and-jobs/

Contact: Andrei Popescu-Belis


Description

Applications are invited for a 6-month internship (preferably at the
Master level) in the field of statistical machine translation (SMT).

At Idiap, we are studying methods for using text-level information to
improve SMT, in the context of the Swiss COMTIS project
(www.idiap.ch/comtis). In particular, we have successfully combined
classifiers for discourse connectives with state-of-the-art SMT systems,
showing an improvement on such particles. In collaborations with
linguists, we currently analyze the features that govern the translation
of verb tenses, mainly from English to French. The main challenge for MT
is that there is no one-to-one mapping from English to French tenses,
and the correct choice depends on the context.

The goal of the internship is to design and implement a method for
predicting the translation of verb tenses, applied to English/French
translation (or another European language). First, training data will be
generated by the word alignment of annotated parallel corpora. Then, a
classifier will be trained to predict tense translation based on lexical
and semantic features. Its output will then be used to train and test a
tense-aware SMT system, which will be evaluated in terms of BLEU
improvement but also verb-specific scores (METEOR or ACT).

The applicants should have a background in computer science or
linguistics. Knowledge of computational linguistics and machine learning
would be an advantage. Previous experience with statistical machine
translation would be highly appreciated. The applicants should have
demonstrable programming skills in at least one scripting language such
as Perl or Python, or master a programming language such as Java or
C/C++. Good command of English and knowledge of another European
language (preferably French) are mandatory.

The applications should be submitted before March 15, 2013, with
priority given to those submitted earlier. The internship can start
immediately, but no later than July 1st, 2013. The appointment is for 6
months, with a gross salary of 2000 CHF per month.

About Idiap

Idiap is an independent, non-profit research institute recognized and
supported by the Swiss Government, and affiliated with the Ecole
Polytechnique Fédérale de Lausanne (EPFL). It is located in the town of
Martigny in Valais, a scenic region in the south of Switzerland,
surrounded by the highest mountains of Europe, and offering exciting
recreational activities, including hiking, climbing and skiing, as well
as varied cultural activities. It is within close proximity to Geneva
and Lausanne. Although Idiap is located in the French part of
Switzerland, English is the working language. Free French lessons are
provided.

Idiap offers competitive salaries and conditions at all levels in a
young, dynamic, and multicultural environment. Idiap is an equal
opportunity employer and is actively involved in the ""Advancement of
Women in Science"" European initiative. The Institute seeks to maintain a
principle of open competition (on the basis of merit) to appoint the
best candidate, provides equal opportunity for all candidates, and
equally encourages both genders to apply.

APB
Idiap Research Institute  |  tel: (41 27) 721 7729
Centre du Parc, CP 592    |  fax: (41 27) 721 7712
CH-1920 Martigny          |  name.surname@idiap.ch
Switzerland               |  www.idiap.ch/~apbelis"
"159","2013-02-04","EDF","Paris","Proposition de stage opérationnel en Text-Mining

Depuis le 1er juillet 2007, le marché de l'électricité est entièrement
ouvert à la concurrence et permet au consommateur de choisir librement
son fournisseur d'énergie. Dans ce contexte, il est devenu stratégique
pour EDF de comprendre les besoins de ses clients, mais également
d'expliquer et de prédire leur comportement.

Le Domaine Analyse de la Connaissance Client au sein de la Direction des
Systèmes d'Information de la branche commerce a, pour partie, la mission
d'analyser les données provenant de nos différents systèmes
d'information et notamment les données textuelles.

Actuellement, nous utilisons des techniques de Text Mining à travers les
outils de Temis et de Noopsis pour analyser automatiquement des
commentaires provenant de nos SI mais également les réponses aux
questions ouvertes d'enquêtes de satisfaction.

Le stage que nous proposons est opérationnel et a pour objectif la mise
en place d'un modèle d'analyse automatique des réponses à des questions
ouvertes issues d'enquêtes de satisfaction.

Les tâches à réaliser comprendront :

- L'exploration de corpus avec des outils de classifications
  automatiques

- La définition d'un plan de catégorisation en coopération avec le
  métier

- L'annotation de données

- La création d'un modèle de catégorisation et de règles d'extraction de
  connaissances

Le profil recherché : 

- Etudiant de niveau BAC +5 spécialisé en Traitement Automatique du
  Langage.

- Bonnes connaissances linguistiques et informatiques

- Aisance rédactionnelle

Début de stage entre avril et juin 2013 pour une durée totale de 6 mois.
Les candidatures (CV + lettre de motivation) sont à envoyer à
anne-laure.guenet@edf.fr .


Anne-Laure GUÉNET
Chef de projet spécialisée en Text Mining
EDF - Direction Commerce - DSI
Domaine Analyse et Connaissance Client
Département Datamining et Analyse Client
20, place de la défense
92050 Paris La Défense CEDEX
 
anne-laure.guenet@edf.fr
Tél. : 01.56.65.22.87"
"160","2013-02-04","IGN","Saint-Mandé (94)","Mise à jour du glossaire de la géomatique

Contexte

La commission de terminologie du Comité Français de Cartographie (CFC) a
édité en 1981 un glossaire de la géomatique sous forme papier2. Ce
glossaire s'adresse à toute personne concernée par la géomatique,
c'est-à-dire qui travaille dans le domaine de la géographie,
l'urbanisme, l'informatique, etc.

La commission a pour objectif de réaliser une mise à jour de la version
électronique de ce glossaire pour tenir compte en particulier des
évolutions techniques du domaine de la géomatique. Ces travaux ont été
entamés en particulier sur les entrées du glossaire : termes obsolètes
et à supprimer, termes obsolètes mais présentant un intérêt historique,
termes conservés, termes à ajouter ont été listés. Le contenu du
glossaire révisé a aussi été précisé, le texte actuel devra être enrichi
pour proposer des définitions multiples, des exemples d'utilisation qui
permettraient de contextualiser les termes concernés et en donner un
contexte d'usage et des termes associés : synonyme, opposé, ""voir
aussi"".

Enfin, la mise à jour devrait s'appuyer sur des sources d'information
existantes et des travaux similaires par les thèmes abordés ou par les
modes de consultation proposés.

Sujet

L'objectif du stage est de :

- préciser la nouvelle ligne éditoriale de ce glossaire à partir des
  études préalables déjà réalisées et des préconisations déjà formulées
  par la commission,

- proposer une méthode de mise à jour qui tiendra compte en particulier
  de la cohérence, de la couverture et de la granularité des définitions

- et la tester sur un domaine thématique de la géomatique.

Le déroulement du stage pourrait être le suivant :

- analyse du glossaire existant et du projet éditorial tel qu'il est
  déjà défini afin de bien cadrer les attentes ;

- définition des principes de sélection des documents primaires qui
  pourraient être les plus intéressants à intégrer au corpus qui doit
  documenter les analyses des termes à décrire (un corpus électronique
  de la géomatique a déjà été constitué, il devra être vérifié dans
  cette étape) ;

- définition d'une méthodologie de repérage en corpus des termes absents
  du glossaire mais attestés en corpus afin de pouvoir ensuite définir
  les critères de sélection et d'intégration des nouveaux termes ;

- définition du programme d'information et de l'organisation
  structurelle des articles du nouveau glossaire ;

- élaboration du protocole de rédaction des articles (de la
  documentation des usages en corpus à leur traitement textuel et
  structurel, en envisageant éventuellement des enrichissements du type
  annotations du texte des descriptions lexicales ou introduction de
  liens) ;

- préconisations de traitements éditoriaux en fonction du ou des
  supports de publication envisagés.

Ce programme étant ambitieux, toutes les tâches prévues pourront ne pas
être traitées à la même échelle, mais il serait intéressant pour le
stagiaire comme pour la commission de terminologie de pouvoir avoir une
vue d'ensemble du projet éditorial et de la méthode de
travail préconisée. Des orientations réfléchies et argumentées seront
donc attendues pour chaque point.

Un expert de la géomatique apportera ses compétences afin d'aider le
stagiaire à maîtriser les notions fondamentales du domaine et vérifiera
régulièrement les propositions terminologiques.

Des travaux similaires par les thèmes abordés ou par les modes de
consultation proposés, ont déjà été recensés et pourront aussi
constituer des sources d'exemples.

Responsables du stage
Catherine Dominguès
IGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex
tél : 01 43 98 85 44 mél : catherine.domingues@ign.fr

Le stage sera co-encadré par : Nathalie Gasiglia
Université Lille 3, UFR Humanités, Département Sciences du langages, &
UMR Savoirs, Textes, Langage, BP 60149, 59 653 Villeneuve d'Ascq
mél : nathalie.gasiglia@univ-lille3.fr

Durée, lieu du stage, rémunération
La durée prévue est de cinq mois, avec un début en mars/avril 2013.
Le stage se déroulera au laboratoire COGIT de l'IGN à Saint-Mandé.

IGN/laboratoire COGIT
73 avenue de Paris
94160 Saint-Mandé
métro : Saint-Mandé - ligne 1 ou RER A : Vincennes
rémunération : 30% du SMIC

Compétences particulières et formation requise

Ce stage s'adresse aux étudiants de master (1 ou 2) ou de 3ème année
d'école d'ingénieurs avec une spécialisation en lexicographie,
terminologie ou en traitement automatique du langage naturel.

Prolongements éventuels
Le COGIT propose chaque année des sujets de thèse et des contrats de
post-doc.

Pour candidater

Le dossier de candidature sera envoyé par mail. Il devra se composer
d'un curriculum vitae et d'une lettre de motivation, accompagnés des
relevés de notes des années de M1 et M2 (ou deux dernières années
d'école d'ingénieurs) et d'une description des enseignements suivis (un
lien vers le site internet de la formation est le bienvenu).

1 La géomatique regroupe l'ensemble des méthodes et des outils
  informatiques qui permettent d'acquérir, représenter, analyser et
  intégrer des données géographiques.

2 Une version électronique (embryonnaire) existe, accessible à partir du
  site du CFC ; http://lecfc.fr/index.php?page=commission&commission=6"
"161","2013-02-04","INRA","Paris ou Grignon","INRA Mét@Risk
Méthodologies d'analyse de risque alimentaire
16, rue Claude Bernard
75231 Paris cedex 05

INRA GMPA
Génie et Microbiologie des Procédés Alimentaires
Avenue Lucien Brétignières
78850 Thiverval Grignon


Sujet de stage de master pro 2ème année:

Construction d'un corpus de connaissances sur un système de production
et de stabilisation de cellules microbiennes

Contacts : liliana.ibanescu@agroparistech.fr,
laurie.planes@agroparistech.fr, caroline.penicaud@grignon.inra.fr,
lydie.soler@paris.inra.fr,

La production et la stabilisation de cellules microbiennes est un
enjeu majeur pour de nombreuses bio-industries, représentant un marché
de 144 milliards de dollars en 2010 et qui devrait atteindre 259
milliards de dollars en 2016. Les procédés employés sont très
énergivores, et face au contexte énergétique actuel, des améliorations
voire des alternatives doivent être envisagées. Au-delà de la question
de l'énergie, c'est la durabilité du système qui est mise en question,
intégrant la dimension d'épuisement des ressources (énergie, eau,
matières premières) mais aussi l'impact sur l'environnement
(e.g. réchauffement climatique) ou sur la santé humaine
(e.g. production de composés toxiques). Cependant, l'amélioration de
la durabilité du procédé ne peut pas se faire sans tenir compte des
contraintes spécifiques aux bioproduits, qui sont très fragiles et
subissent de fortes dégradations au cours des procédés. Les critères
d'évaluation de la qualité du bioproduit au cours des différentes
opérations sont liés à l'état physiologique des cellules et mesurables
à différents niveaux d'échelle (génétique, moléculaire, cellulaire,
population). L'intégration des différents critères (qualité du
bioproduit, performance du procédé, impact environnemental) pour
optimiser globalement le système est nécessaire dans l'optique de
développer des procédés plus durables tout en préservant la qualité
des micro-organismes.

L'objectif de ce stage est de constituer un corpus de connaissances et
un thésaurus pour la représentation in silico globale d'un système de
production et de stabilisation de cellules microbiennes intégrant les
différentes étapes de production, les niveaux d'échelle nécessaires à
la description de la fonctionnalité du produit, et, les entrées et
sorties liées à l'impact environnemental, tout en prenant en compte la
composante économique du système.

Ce stage sera réalisé dans le cadre d'une collaboration entre deux
équipes de deux unités INRA, l'équipe « Ingénierie des connaissances »
de l'unité Mét@risk qui travaille en particulier sur la constitution
de bases de connaissances et la construction d'ontologies et l'équipe
« Bioproduits - Aliments - Micro-organismes - Procédés » de l'unité
GMPA qui travaille en particulier sur l'objet d'étude de ce stage.

Les étapes du travail seront les suivantes :
1- Extraction de connaissances issues de sources identifiées et du Web pour élaborer et enrichir
le corpus de connaissances ;

2- Prise en compte du caractère multi-échelles du système dans la construction du corpus de
connaissances ;

3- Construction d'un thésaurus permettant de représenter la connaissance du corpus de façon
structurée et hiérarchique

Lieu du stage: AgroParisTech (Paris ou Grignon), durée de 6 mois, stage rémunéré"
"162","2013-02-06","LIPN","Villetaneuse","Titre du stage M2 : Exploitation de relations sémantiques pour la
Recherche d'Information

Descriptif et contexte
La recherche d'information sémantique (RIS) a pour but de dépasser les
limites d'une recherche classique par mots-clés. Les méthodes de RIS
visent à s'affranchir de ces limites via le passage à un niveau
conceptuel par le biais d'une ressource sémantique. L'exploitation des
ressources sémantiques se limite généralement au niveau des concepts où
les mots-clés sont substitués par les concepts et où le raisonnement se
fait essentiellement sur les liens hiérarchiques entre ces concepts. Ces
méthodes ne permettent pas de prendre en compte toute la richesse des
ressources sémantiques qui ne sont considérées que comme des structures
taxonomiques.

Le stage vise à enrichir un modèle de recherche d'information sémantique
pour prendre en compte les relations sémantiques entre concepts afin
d'améliorer la qualité des documents retournés. De nombreux travaux dans
le cadre du Web Sémantique ont montré l'utilité des relations
sémantiques (i.e rôles) pour améliorer l'accès à l'information [1]. Les
rôles permettent d'appliquer des moteurs d'inférences et de répondre à
des requêtes complexes qui nécessitent du raisonnement [2]. Plusieurs
pistes sont possibles, comme l'intégration de mesures de proximité
sémantique (e.g. [2]), ou exploitation des relations sémantiques pour
ré-ordonnancer les résultats.

Le stage se déroulera au LIPN (http ://www-lipn.univ-paris13.fr/),
Université Paris 13 dans l'équipe «Représentation des Connaissances et
Langage Naturel» (RCLN). Ce stage est rémunéré grâce au soutien du
laboratoire d'excellence ""Empirical Foundations of Linguistics"" (labex
EFL, http://www.labex-efl.org/). Il fait partie d'un projet plus large
visant à étudier la contribution de sources de connaissances pour
l'extraction d'information, mené en commun entre le LIPN et le LATTICE
dans le cadre du labex EFL.

Missions
Les différentes étapes du travail à réaliser sont les suivantes :
* État de l'art
* Propositions de différents scénarios
* Intégration des propositions dans une plate-forme existante (YaSemIR
  ou TerrierSIR développées au LIPN)
* Mise en place d'une évaluation
* Analyse des résultats

Références
[1] Claudia d'Amato, Nicola Fanizzi, Bettina Fazzinga, Georg Gottlob and
Thomas Lukasiewicz. (2012) «Ontology-based semantic search on the Web
and its combination with the power of inductive reasoning» In Annals of
Mathematics and Artificial Intelligence. Vol. 65. No. 2/3. Pages 83-121.

[2] Uren, V., Sabou, M., Motta, E., Fernandez, M., Lopez, V., Lei, Y.
(2011) «Reflections on five years of evaluating semantic search
systems». In International Journal of Metadata, Semantics and
Ontologies, 5(2), p.87-98.

[3] G. Hirst et D. St-Onge. (1998) «Lexical chains as representations of
context for the detection and correction of malapropisms.» In WordNet :
An electronic lexical database. MIT Press. Pages 305-332.


Profil recherché
- De niveau Master2
- Autonome en informatique : connaissance d'UNIX, de Java
- Intérêt pour le web sémantique et la recherche d'information
- La connaissance de Lucene ou Terrier est un plus

Durée : 6 mois
Début souhaité : avril 2013

Modalité de dépôt de candidature

Merci d'envoyer un CV détaillant la formation et l'expérience acquise,
les bulletins de notes ainsi qu'une lettre de motivation à :
Haïfa Zargayouna (haifa.zargayouna@lipn.univ-paris13.fr)
Davide Buscaldi (davide.buscaldi@lipn.univ-paris13.fr)"
"163","2013-02-11","REBUZ","Strasbourg","Sujet : Observation des relations action-objet dans la perspective
d'innovation technologique dans un domaine d'activité

Lieu : Strasbourg
Société : Rebuz SAS

Rebuz est une jeune société innovante qui est spécialisée dans l'analyse
de textes pour la veille économique. 

Sa méthode originale répose sur l'analyse sémantique épaulée par des
principes de la linguistique cognitive. Le prototype du logiciel étant
en cours de construction, la société cherche un(e) stagiaire en TAL qui
contribuera à l'enrichissement des ressources lexicales et à l'étude des
structures syntaxiques reflétant les relations action-objet dans les
phrases.

Compétences recherchées :
- excellente maîtrise du français (anglais ou une autre langue sera un
  plus)
- bonnes connaissances des expressions régulières
- aisance dans programmation en Perl (ou un autre langage de scripts)
- notions en programmation orientée objet (Java)
- habitude de travail avec des outils de TAL, tels que AntConc, Unitex,
  etc.
- bonnes capacités de travail en équipe
- rigueur 
- responsabilité
- autonomie

Niveau d'études : Bac+4, Bac+5

Durée de stage : 4-6 mois

Gratification : 436,06 euros/mois  (logement possible)

Contact : Jean Marc Zuber (jm.zuber@rebuz.fr)"
"164","2013-02-11","Syllabs","Paris","------------------------------------------------------------------------
Offre de stage : Extraction et génération de descriptifs produits
(Syllabs)
------------------------------------------------------------------------

------------
Contexte
------------

Syllabs est spécialisée en analyse sémantique et en création automatique
de textes. Nos technologies sont le fruit d'années de développement et
maîtrisent toutes les étapes du processus d'analyse de données
textuelles du Web : identification des pages pertinentes, extraction et
catégorisation des informations clé.

Actuellement, nous recherchons un(e) ingénieur linguiste pour un stage
dans le domaine de la création automatique de textes en français (langue
maternelle uniquement). L'idée est de créer des descriptifs de lieux ou
de produits à partir d'une base de données existante (par exemple la
liste des caractéristiques d'un produit).

----------------------------
Description du poste
----------------------------

Les tâches principales concernent:

-  Extraction d'information des caractéristiques produits.
-  Génération automatique de descriptifs de produits.
-  Scripts pour évaluation quantitative des textes générés

-------------------
Profil souhaité
-------------------

- Excellentes qualités rédactionnelles, goût pour l'écriture.
- Aptitude pour la représentation formelle du langage.
- Excellente capacité de communication et aptitude pour le travail d'équipe.
- bon niveau en python serait un plus.

Diplôme et expérience

- Formation en cours : Linguistique Informatique ou similaire.  
- Compétences en rédaction web serait un plus.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « Stage TAL ».

Lieu : Syllabs, 53 bis rue Sedaine, 75011 Paris.

Contrat : stage conventionné rémunéré en fonction du niveau d'étude."
"166","2013-02-13","ISIR / Telecom ParisTech","Paris","Modèle d'engagement dans une interaction avec un agent virtuel

* *

*Résumé*

Le stage s'inscrit dans le projet A1:1 (Avatar échelle 1:1) qui vise à
porter l'interaction entre l'humain et un agent virtuel à un niveau
inégalé de présence, d'émotion et d'engagement...

Le projet inclus une approche nouvelle de captation des signaux de
l'humain, (y compris l'expression du visage et le regard) et
l'interprétation multimodale de ces signaux ainsi qu'un modèle d'agent
virtuel capable d'imiter des signaux de l'humain.

*Objectifs*

L'engagement est considéré, par Sidner et al. (2004), comme «the process
by which two (or more) participants establish, maintain and end their
perceived connection during interactions they jointly undertake» (le
processus par lequel deux (ou plusieurs) des participants établissent,
maintiennent et mettent fin à leur connexion perçue au cours des
interactions qu'ils entreprennent conjointement). Ainsi, pour montrer
l'engagement, un agent virtuel doit être doté de mécanismes qui lui
permettent de percevoir, d'adapter et de générer des comportements
appropriés au cours d'une interaction sociale donnée. L'engagement
englobe plusieurs phénomènes complexes tels que la notion d'alignement,
les liens sociaux, et l'empathie. Il peut être considéré comme une
mesure quantitative de la façon dont l'interaction se passe, se situe
entre les êtres humains ou entre l'homme et la machine. Il peut se
manifester à travers un large spectre d'actes intentionnels allant des
stratégies de dialogue au mimétisme du comportement (par exemple
sourire).

Le stage visera à développer un modèle d'engagement entre humain et
agent virtuel. Elle se focalisera en particulier à donner aux agents la
capacité d'imiter les comportements de son interlocuteur humain, de
répondre à ses signaux sociaux (Vinciarelli et al, à paraître) et d'en
envoyer.

Le mimétisme peut avoir lieu avec un bas niveau de conscience. Il peut
être défini comme la tendance à l'imitation des comportements lors de
l'interaction. Il s'applique surtout pour l'expression du visage, la
qualité vocale et la posture du corps (Hess et al, 1999). Alors que le
mimétisme implique la notion de comportement synchrone, la fenêtre de
temps de cette synchronicité doit être prudemment définie. Par exemple,
la plupart des imitations du sourire comme celles des gestes se
superposent dans le temps (Kimbara, 2006) ; de même l'alignement lexical
peut être vu sur plusieurs tours de parole. Le stage se focalisera sur
l'imitation d'une des modalités d'expressions.

Axe thématique du Labex correspondant au stage : Les interfaces et
l'interaction de l'humain avec des environnements numériques et des
mondes physiques distants.

Encadrants :

Mohammed Chetouani    mohamed.chetouani@upmc.fr

Chloé Clavel                  chloe.clavel@telecom-paristech.fr

Catherine Pelachaud       catherine.pelachaud@telecom-paristech.fr

Lieu du stage : ISIR et Telecom-ParisTech

Financement : 1/3 du SMIC"
"167","2013-02-18","CEA - LVIC","Palaiseau","COMMISSARIAT A L'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES
Laboratoire Vision et Ingénierie des Contenus


SUJET

Contexte

Depuis 2002, le LVIC développe l'analyseur linguistique multilingue LIMA
[1].  Il s'agit à ce jour d'un outil très modulaire capable de faire
l'analyse (tokenisation, analyse morphologique, syntaxique et
sémantique) de textes dans des langues aussi diverses que le Français,
l'Anglais, l'Arabe, le Chinois, l'Espagnol, l'Allemand ou encore
l'Italien. LIMA représente à ce jour plus de 100.000 lignes de code
(sans compter les ressources linguistiques). LIMA est déjà utilisé dans
plusieurs produits industriels, mais le CEA LIST a décidé de le diffuser
sous une licence libre pour faciliter son utilisation, sa diffusion et
obtenir des retours plus rapides d'une communauté d'utilisateurs plus
large.
LIMA est codé en C++ standard. Il utilise largement les biliothèques
boost et Qt. Il est multi-plateformes (GNU/Linux et MS Windows à ce
jour). Son architecture le rend très facilement extensible et intégrable
dans des applications.

Objectifs

Cette libération, qui se fait dans le cadre du projet ANR ASFALDA [2],
nécessite d'améliorer encore le logiciel avant de le diffuser, et ce sur
plusieurs aspects:
- documentation des API ;
- documentation utilisateur ;
- tests unitaires ;
- tests fonctionnels.

LIMA dépend de ressources linguistiques pour fonctionner (dictionnaires,
règles d'analyse,...). Même si le laboratoire est propriétaire de
certaines d'entre elles, d'autres sont issues de ressources commerciales
et ne peuvent être diffusées librement. Il faudra donc produire des
ressources de remplacement à partir de ressources linguistiques libres
disponibles.

Le travail du stagiaire consistera à intervenir sur ces différents
sujets (codage, documentation et ressources) en vue de la mise à
disposition de LIMA sur une forge logicielle à la fin du stage. Le ou la
candidat(e) retenu(e) aura un bon niveau en C++, une compréhension des
problématiques liées à la diffusion des logiciels (tests,
documentation...) et idéalement aura participé à un projet de logiciel
libre.

Le stage se déroulera dans les locaux du LVIC situés à Nano-INNOV à
Palaiseau (près de Polytechnique, Sup'Optique, Thales et Danone).

[1] 
http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=A5D66B8127851343E2F9DB107DF26034?doi=10.1.1.231.3742
[2] https://sites.google.com/site/anrasfalda/


Durée du stage : 4 à 6 mois

Formation souhaitée : Master 1 ou 2, Ingénieur 2° ou 3° année.

Contact:
Gaël de Chalendar
Mail : Gael.de-Chalendar@cea.fr
Tél. : 01 69 08 01 50"
"168","2013-03-07","LIMSI","Orsay","Titre : Définition et structuration de notions de cours pour l'EIAH

Contexte:
Afin d'exploiter au mieux les informations disponibles sous forme
textuelle, semi-structurée (Wikipédia), ou structurée (sémantique, base
de données...), il est nécessaire de créer de nouveaux outils qui ne
considèrent pas le document comme un tout, mais qui permettent d'accéder
à la connaissance qu'il véhicule. De ce fait, nous nous proposons de
considérer tous ces documents comme des sources de connaissances : il
s'agit de pouvoir les analyser dans le but d'en extraire des objets de
connaissances réutilisables par des processus automatiques, et ce dans
le cadre des environnements numériques de travail.
Nous nous focaliserons sur une tâche précise dans le cadre de systèmes
de question-réponse appliqués aux Environnements Informatiques pour
l'Apprentissage Humain (EIAH) : engendrer des questionnaires ouverts et
fermés en langue naturelle à partir et sur des documents et en corriger
les réponses données.
L'objectif du stage est de pouvoir travailler sur le volet annotation de
documents afin d'en extraire une connaissance structurée.

Objectif :
Produire des objets d'enseignements structurés correspondant à des 
notions importantes pour  le domaine enseigné et les caractériser en 
fonction de leur rôle dans l'enseignement de la matière et l'évaluation 
des apprenants.
Ce stage se décomposera en plusieurs étapes :

1) Détermination des concepts de l'étude: choisir les concepts du
domaine auxquels on s'intéresse (nous nous intéresserons plus
particulièrement à l'enseignement des bases de données en informatique),
puis les définir par des propriétés que l'on cherchera à renseigner par
l'analyse automatique des documents de cours (cf. étape 2)

2) Structuration des connaissances par :
- annotation de passages de documents par les concepts étudiés et le
  type de présentation de ces notions (définition, explication, exemple,
  etc);
- classification de ces concepts sur une échelle de difficulté et
  granularité
- création d'un graphe de prérequis.

Mots-clefs: Traitement automatique de la langue, annotation sémantique,
ontologie, environnement numérique pour l'enseignement, apprentissage

Lieu : LIMSI, Orsay
Contact : Brigitte Grau bg[at]limsi.fr"
"169","2013-03-11","Laboratoire d'Informatique de Tours","Blois","Proposition de stage : Évaluation de ressources et traitements
complémentaires pour la reconnaissance d'entités nommées

CONTEXTE

La reconnaissance automatique des entités nommées (personnes, lieux,
organisation, unités de temps, montants, etc.) est une tâche centrale
pour la recherche d'information. Dans ce cadre, les nombreux travaux
menés sur ce sujet au sien de l'équipe BDTLN du LI (université de Tours)
ont conduit à l'implémentation de deux systèmes :
- CasEN, orientés connaissances (transducteurs) [Friburger 2002]
- mXS, orientés données (motifs) [Nouvel 2012]

Ces deux systèmes sont en cours d'évaluation dans le cadre de la
campagne Etape (http://www.afcp-parole.org/etape.html en cours
d'adjudication). Ils reposent sur une base lexicale commune faite de
ressources construites semi-automatiquement [Tran & Maurel 2006], dont
Prolex ( http://www.cnrtl.fr/lexiques/prolex/). Dans la lignée des
travaux de [Bunescu & Pasca 2006] et [Charton & Torres-Moreno 2009],
nous avons développé un outil afin d'extraire automatiquement des
ressources lexicales à partir de Wikipedia. Enfin, des expériences
préliminaires ont été menées dans le cadre du projet Ancor
(http://tln.li.univ-tours.fr/Tln_Ancor.html) afin de déterminer les
interactions qui existent entre les les entités nommées et les
anaphores.

SUJET DE STAGE

Le stage proposé vise en premier lieu à déterminer les gains réalisés
par les deux systèmes lors de l'enrichissement des ressources
lexicales. Il s'agit donc de manipuler les divers outils et systèmes à
disposition et de réaliser des évaluations comparatives afin de
déterminer, dans le cadre d'Etape (émissions télévisuelles et
radiodiffusées), quelles ressources ont le plus intérêt à être
complétées, quelles configurations sont les plus avantageuses, quels
sont les avantages et les inconvénients de chaque approche.

De manière plus exploratoire, l'étudiant sera amené à approfondir nos
travaux sur les interactions entre reconnaissance d'entités nommées et
résolution d'anaphores. Il s'agira autant d'établir une base de travail
pour l'évaluation des systèmes de résolution de coréférences, que
d'étudier en quoi les mécanismes anaphoriques peuvent aider pour la
reconnaissance des entités nommées et/ou inversement.

CONDITIONS ET CANDIDATURE

Le candidat sélectionné devra disposer de solides compétences en
informatique (programmation Java et scripts Python / Shell) et avoir un
intérêt pour le traitement automatique des langues. Une attention
particulière sera portée aux capacités à mener des évaluation sur corpus
(outils d'évaluation, benchmarks, significativité). Des connaissances en
fouille de données (text mining) et/ou en paramétrage de systèmes à base
d'automates seront un plus.

Dates et durée : courant mars / début avril, pour 3 mois minimum
Lieu d'exercice : campus de Blois (antenne universitaire, 3 place
Jean-Jaurès)
Rémunération : maximale prévue selon la réglementation 436,05 ¤ par mois
(assurée dans le cadre d'un projet industriel financé par la société
BAMSOO).

Merci d'envoyer un CV détaillé de vos activités passées, accompagné
d'une lettre de motivation et de vos relevés de notes des deux dernières
années d'études à :
- Nathalie Friburger nathalie.friburger@univ-tours.fr ,
- Damien Nouvel damien.nouvel@inria.fr ,
- Jean-Yves Antoine jean-yves.antoine@univ-tours.fr .

BIBLIOGRAPHIE

[Bunescu & Pasca 2006] Using Encyclopedic Knowledge for Named entity
Disambiguation. R.C. Bunescu M. Pasca. EACL (2006).
[Charton & Torres-Moreno 2009] Classification d'un contenu
encyclopédique en vue d'un étiquetage par entités nommées. E. Charton,
J.M. Torres-Moreno.  TALN (2009)
[Friburger 2002] Reconnaissance automatique des noms propres :
application à la classification automatique de textes
journalistiques. Nathalie Friburger. Thèse de doctorat (2002).
[Friburger & Maurel 2004] Finite-state transducer cascades to extract
named entities in texts. Nathalie Friburger and Denis Maurel. TCS:313
(2004).
[Nouvel 2012] Reconnaissance des entites nommees par exploration de
regles d'annotation. Damien Nouvel. Thèse de doctorat (2012).
[Tran & Maurel 2006] Prolexbase - Un dictionnaire relationnel
multilingue de noms propres. Mickäel Tran, Denis Maurel. TAL:47-3
(2006)."
"170","2013-03-18","LexisNexis","Paris","LexisNexis en France (600 collaborateurs, 140 M¤ de CA), filiale du
groupe anglo-néerlandais Reed Elsevier, est un acteur majeur dans les
services d'information professionnelle. Ses activités couvrent trois
domaines : l'information et l'édition juridiques, la diffusion de la
presse et de l'information économique et financière sur Internet, les
logiciels professionnels.

L'entreprise s'appuie sur une expertise éditoriale centenaire et sur une
technologie de pointe pour apporter au monde du droit et aux
professionnels de tous secteurs d'activités une vaste gamme de produits
et services réputés : JurisClasseur, Litec, D.O, Bottin Administratif et
les services en ligne LexisNexis.

Mission :

Intégré(e) à l'équipe « Management de l'information» votre mission
consistera à participer aux activités relatives au textmining, qui
traitent de l'extraction d'information juridique à valeur ajoutée.

Profil :

Master 2 en linguistique informatique

Vous êtes d'une nature rigoureuse et méticuleuse

Connaissance d'Unitex obligatoire

Niveau d'étude :
Master 1 ou 2 / stage de fin d'étude.

LIEU : 
141 rue de Javel
75015 PARIS

DUREE : 
5-6 mois à partir de avril 2013

Merci d'envoyer votre candidature (CV + lettre de motivation) ainsi que
vos disponibilités par mail à : celine.aubier@lexisnexis.fr"
"171","2013-03-27","CEA - LIST","Gif-sur-Yvette","Proposition de stage : Construction automatique de lexiques bilingues à
l'aide d'outils d'alignement de mots à partir de corpus de textes
parallèles et comparables

Lieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie
des Contenus (LVIC), 91 191 Gif sur Yvette

CONTEXTE :

Les dictionnaires bilingues jouent un rôle important dans les
applications de Traitement Automatique de la Langue (TAL) telles que la
Traduction Automatique (TA) et la Recherche d'Information Interlingue
(RII). La quantité de travail nécessaire pour créer manuellement ces
dictionnaires est très importante. C'est la raison pour laquelle depuis
quelques années de nombreux travaux ont fait appel aux techniques
d'alignement pour automatiser le processus de construction de
dictionnaires bilingues. Ces techniques constituent un préalable à
l'exploitation des corpus de textes parallèles [Melamed, 2001] : qu'il
s'agisse d'aligner au niveau des paragraphes, des phrases ou d'apparier
des unités lexicales, la plupart des applications reposent sur la
possibilité d'extraire des correspondances précises entre les textes
source et cible.

SUJET DE STAGE :

Le stage consistera, d'une part, à constituer un alignement de référence
pour les mots simples et les expressions polylexicales à l'aide de
l'outil Yawat [Germann, 2008], et d'autre part, à évaluer les outils
d'alignement de mots [Mihalcea & Pedersen, 2003] [Carpuat & Diab, 2010]
à partir de corpus de textes parallèles ou comparables développés au
Laboratoire Vision et Ingénierie des Contenus (LVIC) du CEA-LIST
[Bouamor et al., 2012]. Cette évaluation sera réalisée selon deux
approches différentes : une évaluation intrinsèque à petite échelle dans
laquelle les lexiques bilingues construits automatiquement seront
comparés à un alignement de référence créé manuellement et une
évaluation extrinsèque dans laquelle l'impact d'utilisation de ces
lexiques bilingues sera étudié dans un système de traduction automatique
statistique [Ren et al., 2009] et un moteur de recherche d'information
interlingue.

Le stage comportera les étapes suivantes:

- Appropriation des principaux outils d'alignement de mots à partir de
  corpus de textes parallèles ou comparables développés au LVIC.

- Constitution de deux lexiques bilingues de référence : un pour les
  mots simples et l'autre pour les expressions polylexicales.

- Mise en place d'outils d'évaluation du module d'alignement de mots
  simples et d'expressions polylexicales.

- Spécification et implémentation d'un module pour le filtrage des
  lexiques bilingues construits automatiquement.

- Développement d'une interface web pour l'administration et la gestion
  de dictionnaires multilingues.

BIBLIOGRAPHIE :

- Bouamor D., Semmar N., Zweigenbaum P., ""Identifying bilingual
  Multi-Word Expressions for Statistical Machine Translation"",
  Proceedings of the Eight International Conference on Language
  Resources and Evaluation (LREC'12), Turkey, 2012.

- Germann U., ""Yawat: Yet Another Word Alignment Tool"", Proceedings of
  the ACL-08, Columbus, 2008.

- Melamed I.D., ""Empirical Methods for Exploiting Parallel Texts"", MIT
  Press, 2001.

- Mihalcea R., Pedersen T., ""An evaluation exercise for word alignment"",
  Proceedings of HLT-NAACL 2003 Workshop on Building and using parallel
  texts: data driven machine translation and beyond, Canada, 2003.

- Ren Z., Lu Y., Liu Q., Huang Y., ""Improving statistical machine
  translation using domain bilingual multiword expressions"", Proceedings
  of the 2009 Workshop on Multiword Expressions, ACL-IJCNLP 2009,
  Singapore, 2009.

- Carpuat M., Diab M., ""Task-based Evaluation of Multiword Expressions:
  a Pilot Study in Statistical Machine Translation"", Proceedings of
  NAACL, Los Angeles, 2010.

CONDITIONS DE CANDIDATURE :

Bac+5, stage de fin d'étude dans le domaine du Traitement Automatique de
la Langue (TAL).

Compétences en informatique et en TAL.

Programmation : C++, Perl ou équivalent.

Langues : Maîtrise de l'anglais et du français, la connaissance de la
langue arabe est un plus.

Durée : entre 4 et 6 mois.

Contact et envoi des candidatures (CV détaillé, lettre de motivation et
relevés de notes des deux dernières années d'études):

Nasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr

Nasredine SEMMAR
CEA Saclay Nano-INNOV
Institut CARNOT CEA LIST
Laboratoire Vision et Ingénierie des Contenus (LVIC)
Point courrier n°173
91191 Gif-sur-Yvette CEDEX
Tel: +33 (0)1 69 08 01 46
Fax: +33 (0)1 69 08 01 15
Email: nasredine.semmar@cea.fr"
"172","2013-04-08","LIMSI","Orsay","Proposition de stage M1 ou M2 au LIMSI-CNRS
Groupe Traitement du Langage Parlé (http://www.limsi.fr/tlp/) à Orsay

Responsable du stage : Marianna Apidianaki (CNRS-LIMSI, groupe TLP)


Titre : Acquisition de connaissances sémantiques à partir de corpus
parallèles

Les corpus parallèles multilingues offrent une solution peu coûteuse à
l'acquisition de connaissances sémantiques. Les différentes méthodes
proposées dans ce but se basent principalement sur des informations
traductionnelles (Dyvik, 1998; Ide et al., 2002; Bannard and
Callison-Burch, 2005) éventuellement combinées avec des informations du
contexte (Apidianaki, 2008; Bansal et al. 2012). Les connaissances
sémantiques acquises par ces méthodes peuvent servir à des fins
d'analyse contrastive ou être exploitées dans des applications
multilingues, comme la Traduction Automatique. Néanmoins, la nature des
connaissances obtenues varie de manière importante et dépend fortement
des informations exploitées par la méthode d'analyse sémantique
employée, des techniques utilisées et des hypothèses théoriques
sous-jacentes.

L'objectif de ce stage est d'étudier la sémantique des paraphrases
acquises par une méthode basée sur une hypothèse de correspondance
sémantique inter-langue, la méthode de paraphrasage par pivot
(Callison-Burch, 2008). Des ressources sémantiques construites par cette
méthode sont actuellement largement utilisées dans la Traduction
Automatique et son évaluation (Zhou et al. 2006; Madnani et al., 2007;
Snover et al., 2009; Denkowsky and Lavie, 2010). Nous sommes intéressés
à examiner la pertinence des descriptions sémantiques engendrées en
expérimentant avec différentes méthodes de clustering sémantique et de
représentation des connaissances. Les résultats de l'étude permettront
d'identifier les cas nécessitant une analyse plus poussée et d'estimer
leur impact dans la Traduction Automatique et son évaluation.

Le stage est rémunéré et se déroulera au LIMSI-CNRS (Orsay) dans
l'équipe Traitement du Langage Parlé (http://www.limsi.fr/tlp).

Profil : 
- Master 1 ou 2 en Traitement Automatique des Langues ou Informatique
- bonnes compétences en programmation
- connaissances en apprentissage automatique (clustering) 
- expérience avec des systèmes de Traduction Automatique serait un plus

Durée : 4 mois (plein temps)
Date de début : dès disponibilité
Lieu : LIMSI-CNRS, Groupe TLP, rue John von Neumann, Université Paris
Sud, 91403 Orsay Cedex

Rémunération : le/la stagiaire recevra la gratification CNRS standard
(environ 400 euros par mois)

Contact: Marianna Apidianaki (marianna@limsi.fr)"
"173","2013-09-16","Reverso","Neuilly","Stage linguiste / terminologue / traducteur

Type de contrat : Stage de césure ou de fin d'études (minimum 4 mois) ou
stage longue durée à temps partiel

Lieu : Neuilly-sur-Seine

Indemnité de stage : Selon durée et expérience

Début : Dès que possible

ENTREPRISE

Editeur de logiciels à rayonnement international, Reverso-Softissimo est
l'un des leaders mondiaux des solutions Intranet et Internet de
traduction instantanée et de dictionnaires électroniques.

Son portail grand public dédié aux langues www.reverso.net génère un
très fort trafic avec 200 millions de pages vues par mois et plus de 6
millions de visiteurs uniques.

Reverso-Softissimo recherche un(e) linguiste pour participer aux travaux
de production et de recherche de notre équipe linguistique dans un
contexte professionnel motivant : haute technologie, forte croissance et
développement international.

Vous êtes intéressé(e) par notre domaine ? C'est le moment de rejoindre
notre équipe !

MISSION

Sous la direction du chef de projet linguistique, le stagiaire
effectuera les missions suivantes :

- création, mise à jour, validation de dictionnaires bilingues ;

- tests de la qualité de traduction et rédaction de rapports d'analyse ;

- recherche, évaluation et analyse de ressources terminologiques ;

- animation et développement de la communauté d'utilisateurs du
  dictionnaire collaboratif.

Cette liste n'est pas exhaustive et pourra être amenée à évoluer en
fonction de l'implication du/de la stagiaire.

PROFIL

Étudiant(e) en dernière année d'une école ou d'une université en TAL,
langues étrangères, linguistique, ingénierie linguistique ou traduction,
vous maîtrisez parfaitement l'anglais et le français à l'oral comme à
l'écrit, et idéalement une troisième langue.

Vous avez des qualités rédactionnelles ainsi qu'une grande rigueur, une
bonne méthodologie, un esprit logique et des capacités d'analyse et de
synthèse ; votre sens de l'initiative, votre dynamisme et votre
autonomie seront également des qualités appréciées dans le cadre de ce
stage.

Contact :

Juliette MORNET
jmornet@reverso.com"
"174","2013-10-07","CEA LIST","Saclay","INTRODUCTION
Dans le cadre de la thèse de Quentin Pradet, sous la direction du
Pr. Laurence Danlos et du Dr. Gaël de Chalendar, le CEA LIST et l'INRIA
ALPAGE ont entamé l'adaptation au français de la ressource
lexico-syntaxique VerbNet. Le présent stage qui s'adresse à des
étudiants en linguistique se spécialisant en lexicographie vise à
contribuer à cette traduction.

CONTEXTE
VerbNet est une ressource lexicale pour les verbes anglais organisée
autour de classes sémantiques et de sous-classes syntaxiques. Cette
ressource est très utilisée, notamment pour l'annotation en rôles
sémantiques. Il paraît donc nécessaire d'avoir une ressource équivalente
pour le français. Les seuls efforts qui ont été faits pour l'instant se
limitent à des constructions automatiques bruitées dont l'évaluation se
limite à quelques verbes. De plus ces efforts font abstraction des
ressources lexicales qui existent pour le français, or celles-ci
existent et sont de qualité. Pour les verbes, nous pensons en
particulier à LVF+1, au Lexique-Grammaire et à Dicovalence. Nous avons
donc l'objectif de réaliser un VerbeNet du français semi-automatiquement
en nous appuyant sur ces ressources, en particulier sur LVF+1 et LG, la
première plus centrée sur les informations sémantiques, la seconde sur
les informations syntaxiques. Ce VerbeNet garde la hiérarchie des
classes sémantiques du VerbNet anglais, ce qui permet de garder à
l'identique les informations sémantiques, entre autres les rôles
thématiques.

OBJECTIFS
La partie automatique exploitant les liens disponibles entre ressources
et un réseau lexico-syntaxique est terminée. Le but de ce stage est de
participer en collaboration étroite avec Laurence Danlos et Quentin
Pradet à la correction manuelle de la ressource à l'aide d'une interface
Web développée en interne.  Pour chaque classe ou sous-classe VerbNet,
on dispose des constructions syntaxiques possibles en anglais, des liens
obtenus automatiquement avec les classes LVF+1 et LG correspondantes et
d'une liste de verbes pouvant appartenir à cette classe. Le travail
consiste en l'édition des frames lexico- syntactico-sémantiques en
réorganisant si nécessaire la hiérarchie de classes, en acceptant ou
refusant les verbes proposés, en modifiant les constructions syntaxiques
et en traduisant les exemples.

CANDIDAT
Nous recherchons pour ce stage un étudiant en linguistique se
spécialisant en lexicographie.

CONTACT
Gaël de Chalendar
gael.de-chalendar@cea.fr
01 69 08 01 50"
"175","2013-10-14","SFL","Paris","ANNOTATION DE LA GESTUALITÉ (logiciel : ELAN)
Stagiaire : contrat à temps plein (durée : 3 mois).
Profil : niveau Master.
Début du contrat : février 2014.

CONTEXTE
Le projet européen CorpAGEst porte sur l'étude du langage de personnes
âgées, à partir de l'analyse d'entretiens enregistrés sur support
audiovisuel (approche multimodale : texte, son, geste). Plusieurs
questions sont au c½ur du projet, telles que : « Que nous apprend
l'emploi de marqueurs de discours à haut potentiel d'expressivité (par
ex. 'm'enfin') et d'interactivité (par ex.  'tu vois') sur l'habileté
empathique des personnes âgées ? Une préférence pour l'un ou l'autre
mode langagier (verbal ou non verbal) serait-elle le signe d'une
stratégie adoptée par la personne âgée pour compenser un déficit de sa
compétence communicative ? ». Les analyses porteront en particulier sur
les marqueurs de discours et les gestes dont la fonction communicative
est (inter)subjective (par ex. : le marqueur de discours tu vois ou un
regard vers l'interlocuteur). Par ce biais, il s'agira, d'une part, de
voir comment les personnes âgées expriment leurs points de vue et leurs
émotions (fonction subjective du langage) et, d'autre part, d'examiner
la manière dont elles interagissent avec autrui en situation de
communication réelle (fonction intersubjective du langage).

PROJET EUROPÉEN MARIE-CURIE
Le projet de recherche CorpAGEst « Approche sur corpus de la compétence
pragmatique des personnes âgées » est un projet européen financé par les
Actions Marie Curie dans le cadre du 7e European Community Framework
Programme (projet N° 328282, FP7-PEOPLE-2012-IEF). Durée du projet : 2
ans (2013-2015).

LIEU
Le projet est coordonné au sein de l'unité UMR 7023 (SFL : Structures
Formelles du Langage) à Paris 8 (site Pouchet), par Catherine Bolly
(CNRS & Université catholique de Louvain) et Dominique Boutet
(Université d'Evry-Val d'Essonne & UMR 7023 SFL).

MISSION

La méthode d'analyse sur corpus multimodal adoptée implique la
constitution et l'annotation d'un corpus audiovisuel : 8 sujets d'étude,
env. 13 heures.  La personne recrutée aura pour tâche d'annoter les
corpus vidéo au niveau mimo-gestuel, au moyen du logiciel ELAN, sur la
base d'un schéma d'annotation préétabli. Des discussions et échanges
dynamiques au sein de l'équipe permettront d'optimiser la procédure
d'annotation sur la base de l'expérience de chacun.
La période de stage inclut une période de formation aux fonctions de
base du logiciel d'annotation ELAN et une période consacrée à
l'annotation des données visuelles.

COMPÉTENCES/PRÉREQUIS
Familiarité avec les outils informatiques de base (traitements de texte,
clavier, etc.). Expérience appréciée dans l'analyse impliquant la
multimodalité.
Des connaissances en annotation de corpus seraient un plus.

PROFIL
Étudiant en Master, dans le domaine des sciences humaines (langues et
lettres, sciences du langage, sciences de la communication, traitement
automatique du langage, ethnologie, etc.).
Intérêt pour les sciences du langage, la multimodalité et/ou le
vieillissement langagier.

DURÉE ET CONDITIONS

Stage de 3 mois à temps plein à partir de février 2014 (avec
prolongation possible) au sein du laboratoire de linguistique (SFL, 59
rue Pouchet à Paris) auprès d'une chercheuse en sciences du langage.
Flexibilité et adaptabilité des horaires.
Possibilité d'intégrer le travail dans le cadre d'un mémoire de Master
(à négocier).

RÉMUNÉRATION
436,05¤ net par mois.

CANDIDATURE
Lettre de motivation et CV.
A envoyer pour le 15 novembre 2013 au plus tard.

CONTACTS
catherine.bolly@uclouvain.be
catherine.bolly@sfl.cnrs.fr
dominique_jean.boutet@orange.fr"
"176","2013-10-14","SFL","Paris","TRANSCRIPTION DE L'ORAL (logiciels : Praat/Exmaralda)
Stagiaire : contrat à temps plein (durée : 3 mois).
Profil : niveau Master.
Début du contrat : février 2014.

CONTEXTE
Le projet européen CorpAGEst porte sur l'étude du langage de personnes
âgées, à partir de l'analyse d'entretiens enregistrés sur support
audiovisuel (approche multimodale : texte, son, geste). Plusieurs
questions sont au c½ur du projet, telles que : « Que nous apprend
l'emploi de marqueurs de discours à haut potentiel d'expressivité (par
ex. 'm'enfin') et d'interactivité (par ex.  'tu vois') sur l'habileté
empathique des personnes âgées ? Une préférence pour l'un ou l'autre
mode langagier (verbal ou non verbal) serait-elle le signe d'une
stratégie adoptée par la personne âgée pour compenser un déficit de sa
compétence communicative ? ». Les analyses porteront en particulier sur
les marqueurs de discours et les gestes dont la fonction communicative
est (inter)subjective (par ex. : le marqueur de discours tu vois ou un
regard vers l'interlocuteur). Par ce biais, il s'agira, d'une part, de
voir comment les personnes âgées expriment leurs points de vue et leurs
émotions (fonction subjective du langage) et, d'autre part, d'examiner
la manière dont elles interagissent avec autrui en situation de
communication réelle (fonction intersubjective du langage).

PROJET EUROPÉEN MARIE-CURIE
Le projet de recherche CorpAGEst « Approche sur corpus de la compétence
pragmatique des personnes âgées » est un projet européen financé par les
Actions Marie Curie dans le cadre du 7e European Community Framework
Programme (projet N° 328282, FP7-PEOPLE-2012-IEF). Durée du projet : 2
ans (2013-2015).

LIEU
Le projet est coordonné au sein de l'unité UMR 7023 (SFL : Structures
Formelles du Langage) à Paris 8 (site Pouchet), par Catherine Bolly
(CNRS & Université catholique de Louvain) et Dominique Boutet
(Université d'Evry-Val d'Essonne & UMR 7023 SFL).

MISSION
La méthode d'analyse sur corpus multimodal adoptée implique la
constitution et l'annotation d'un corpus audiovisuel : 8 sujets d'étude,
env. 13 heures.  La personne recrutée aura pour tâche de transcrire, au
moyen du logiciel Exmaralda ou Praat, les données audio des entretiens
effectués sur le terrain.  Les normes de transcription suivront
l'orthographe standard du français et les conventions de transcription
du centre Valibel (Université catholique de Louvain). Des discussions et
échanges dynamiques au sein de l'équipe permettront d'optimiser la
procédure de transcription sur la base de l'expérience de chacun. La
période de stage inclut une période de formation aux fonctions de base
des logiciels Exmaralda et Praat. Une réflexion sera notamment menée en
commun autour des fonctionnalités proposées respectivement par chacun de
ces logiciels.

COMPÉTENCES/PRÉREQUIS
Familiarité avec les outils informatiques de base (traitements de texte,
clavier, etc.).
Expérience appréciée dans l'analyse impliquant le langage oral.
Des connaissances en transcription et annotation de corpus oraux
seraient un plus.

PROFIL
Étudiant en Master, dans le domaine des sciences humaines (langues et
lettres, sciences du langage, sciences de la communication, traitement
automatique du langage, ethnologie, etc.).
Intérêt pour les sciences du langage, le français parlé et/ou le
vieillissement langagier.

DURÉE ET CONDITIONS
Stage de 3 mois à temps plein à partir de février 2014 au sein du
laboratoire de linguistique (SFL, 59 rue Pouchet à Paris) auprès d'une
chercheuse en sciences du langage.
Flexibilité et adaptabilité des horaires.
Possibilité d'intégrer le travail dans le cadre d'un mémoire de Master
(à négocier).

RÉMUNÉRATION
436,05¤ net par mois.

CANDIDATURE
Lettre de motivation et CV.
A envoyer pour le 15 novembre 2013 au plus tard.

CONTACTS
catherine.bolly@uclouvain.be
catherine.bolly@sfl.cnrs.fr
dominique_jean.boutet@orange.fr"
"177","2013-10-24","LIDILEM","Grenoble","Stage de recherche M1 ou M2 Traitement automatique des langues,
Lexicographie ou Linguistique appliquée

Développement d'un dictionnaire électronique de collocations du
langage scientifique

Lieu : LIDILEM, Université Grenoble 3 - Stendhal, 
Durée : de 3 à 5 mois, 
Période : janvier à juin 2014.

Stage rémunéré : indemnité (436 euros/mois)

Personnes à contacter : Agnès Tutin (agnes.tutin@u-grenoble3.fr),
Olivier Kraif (olivier.kraif@u-grenoble3.fr)

Dans le cadre du projet Termith (Projet ANR-Content :
http://www.atilf.fr/ressources/termith/) impliquant plusieurs
laboratoires de recherche (ATILF, LINA, INRIA, LORIA, LIDILEM), nous
souhaitons élaborer un lexique d'expressions spécifiques du français
scientifique, par exemple faire une hypothèse, en premier lieu,
contrairement à nos attentes ...

Cette phraséologie transdisciplinaire des écrits scientifiques
traverse en large partie les disciplines et est surreprésentée dans ce
genre (Pecman 2007 ; Tutin 2007 ; Granger & Paquot 2010). Dans le
cadre du projet Termith, ces expressions seront utilisées dans un
système d'indexation automatique des écrits scientifiques afin de
mieux repérer les concepts spécifiques des textes.

Dans cette phraséologie, les collocations, ici définies comme des
associations binaires privilégiées et compositionnelles sur le plan
sémantique, constituent les expressions les plus productives. Il
s'agit d'expressions comme faire une hypothèse, résultats
encourageants, hypothèse de travail, etc.

Le sujet du stage consistera à adapter un format d'encodage pour ces
expressions à partir des extractions effectuées automatiquement d'un
grand corpus d'écrits scientifiques. L'extraction sera réalisée
semi-automatiquement dans notre équipe à partir d'un corpus analysé
syntaxiquement en dépendances en utilisant des mesures d'association
(Kraif & Diwersy 2012 ; Cf aussi Seretan 2010). Le stagiaire sera
chargé de réfléchir au codage linguistique des propriétés pertinentes
à associer à ces collocations (Tutin 2004) (alternances syntaxiques,
détermination, information d'usage) à partir des observations en
corpus, de sélectionner les collocations adaptées et de proposer une
adaptation pour ces expressions du standard Lexical Markup Framework
(Francopoulo et al. 2006).

Francopoulo, G., George, M., Calzolari, N., Monachini, M., Bel, N.,
Pet, M., & Soria, C. (2006). Lexical markup framework (LMF). In
International Conference on Language Resources and Evaluation-LREC
2006.

Granger, S., Paquot, M., (2010. The Louvain EAP Dictionary (LEAD) »,
Proceedings of the XIV EURALEX International Congress , Leeuwarden
(The Netherlands), 6-10 July 2010, 321-326.

Kraif. O & Diwersy S. (2012). Le Lexicoscope : un outil pour l'étude
de profils combinatoires et l'extraction de constructions
lexico-syntaxiques.  Actes de la conférence conjointe JEP-TALN-RECITAL
2012, volume 2: TALN. Grenoble, France. 399-406.

Pecman, M. (2007) : Approche onomasiologique de la langue scientifique
générale. Revue française de linguistique appliquée. « Lexique des
écrits scientifiques », vol. XII-2. 79-96.

Seretan V. (2010). Syntax-based collocation extraction.  Springer.

Tutin, A. (2004). Pour une modélisation dynamique des collocations
dans les textes. In Proceedings of the Eleventh EURALEX International
Congress, Lorient, France. 207-219.

Tutin, A. (2007). Lexique et écrits scientifiques. Revue française de
linguistique appliquée, 12(2)."
"178","2013-11-04","Lattice","Paris","proposition de stage M2 recherche en informatique/TAL au Lattice
(http://www.lattice.cnrs.fr) à Montrouge (tout près de Paris)

Ce stage a pour objectifs de tester et adapter des algorithmes
d'apprentissage automatique pour le repérage des expressions
référentielles dans des textes écrits ainsi que pour l'identification
des chaînes de coréférence. Pour ce faire, le travail s'appuiera sur
l'exploitation d'un corpus de petite taille, déjà annoté en référence et
en coréférence (projet MC4, Modélisation Contrastive et Computationnelle
des Chaînes de Coréférence). Un premier aspect du travail consistera à
faire passer sur le texte de départ un ensemble d'outils libres et/ou
développés à Lattice : analyse morphosyntaxique, segmentation en chunk,
repérage d'entités nommées. Les résultats obtenus permettront d'enrichir
les données initiales, qui serviront ensuite pour la deuxième étape, au
coeur du sujet, consistant à tester différentes méthodes d'apprentissage
automatique pour l'identification des expressions référentielles et des
chaînes de coréférence (plusieurs passes pourront être nécessaires pour
cela).

Pour que ce stage de M2 puisse s'opérer efficacement, le candidat devra
avoir des connaissances solides en linguistique de corpus et traitement
automatique des langues, des compétences pour l'écriture de scripts
(PERL, PYTHON, voire JAVA : il faudra traiter des problèmes de
transformation de formats de fichiers) et des connaissances ainsi qu'un
intérêt pour les techniques d'apprentissage automatique.

Le stage peut durer de 4 à 6 mois au sein du Lattice, à partir de 2014,
il sera encadré par Frédéric Landragin (http://fred.landragin.free.fr)
et Isabelle Tellier (http://www.lattice.cnrs.fr/sites/itellier/) et sera
financé (au tarif stage : 1/3 Smic) par le projet ANR Orfeo
(http://www.projet-orfeo.fr).

envoyer CV + lettre de motivation à frederic.landragin@ens.fr et
isabelle.tellier@univ-paris3.fr"
"179","2013-11-09","Syllabs","Paris","------------------------------------------------------------------------
 Offre de stage M2 en TAL à Syllabs (Paris)
------------------------------------------------------------------------

------------------------------------------------------------------------
Caractérisation des objets touristiques pour l'extraction de facettes
dans le tourisme
------------------------------------------------------------------------

Syllabs travaille depuis un certain temps sur des outils de TAL
appliqués au tourisme, que ce soit dans un contexte de web mining, de
text mining ou de production de contenus.Dans le cadre de Tourinflux,
projet de recherche multi-partenaire en cours, Syllabs doit produire des
bases de connaissances se rapportant à des objets touristiques (hôtels,
etc.). Ce projet vise à apporter aux acteurs du tourisme (d'abord les
institutionnels mais aussi les acteurs privés) un ensemble d'outils leur
permettant de gérer à la fois leurs données internes et les informations
disponibles sur le web afin de mieux comprendre comment un territoire
est perçu et de mieux agir sur cette perception. C'est dans ce contexte
que se situe le stage. Celui-ci comporte plusieurs étapes et
objectifs. La durée du stage ne permettra peut-être pas de tout couvrir.

----------------------------
 Descriptif du stage
----------------------------

1) Modélisation d'une base de connaissances des objets touristiques

- Créer une taxonomie (simple) des différents objets touristiques et
  étudier les facettes communes à plusieurs objets.

- Déterminer les facettes utilisables pour la génération automatique des
  descriptifs

- Déterminer les facettes nécessaires pour l'analyse d'avis
  d'internautes

2) Extraction des facettes via LOL (outil dédié à base de règles
   linguistiques)

- Extraction des facettes présents dans les ""descriptifs marchands""

- Extraction des facettes présents dans les ""avis internautes""

3) Création de la base à partir de la sortie d'extraction

- Créer une base de données à partir de la sortie d'extraction,
  manipulation des objets extraits

4) Génération de descriptifs d'objets touristiques

- écrire des règles de génération pour 2 objets touristiques différents
  en fonction de la base obtenue

------------------------
  Profil souhaité
------------------------

- Aptitude pour la représentation formelle du langage.

- Excellente capacité de communication et aptitude pour le travail
  d'équipe.

- Bon niveau en python serait un plus.

- Excellentes qualités rédactionnelles, goût pour l'écriture.


Formation en cours : Linguistique Informatique, TAL ou similaire.

Durée du stage : 6 mois (début entre janvier et avril, en fonction du
cursus universitaire)

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « Stage TAL ».

Lieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris.

Contrat : stage conventionné rémunéré en fonction du niveau d'étude."
"180","2013-11-15","Lattice & LTCI Telecom-ParisTech","Paris","Proposition de stage de M2

Laboratoire Lattice & LTCI Telecom-ParisTech


Titre :

Modélisation d'actes communicatifs multimodaux pour un agent
conversationnel animé dans les dialogues humain-machine


Descriptif :

Les Agents Conversationnels Animés (ACA) sont des personnages virtuels
permettant à la machine de dialoguer avec les humains de manière
naturelle. Ils peuvent prendre le rôle d'assistant comme les agents
conversationnels présents sur les sites de vente, de tuteur dans le
cadre des Jeux Sérieux (Serious Games).

Comment obtenir chez un ACA une expression naturelle des actes
communicatifs? Avec quelles postures, quelles expressions faciales,
quels gestes, quelle intonation, doit-on faire accompagner le discours
d'un ACA dans un dialogue humain-machine ? Une attention particulière
sera donnée à l'agencement des niveaux acoustique (intonation) et visuel
(geste, regard, etc.) avec les aspects linguistiques de l'énoncé
(syntaxe, sémantique).

On interrogera notamment les analyses classiques qui tendent à
simplifier, par exemple en considérant qu'à une question est associé un
contour prosodique montant, alors qu'un contour plat est souvent bien
plus naturel. On interrogera également les matérialisations d'un ordre
en fonction du contexte socio-émotionnel : si en théorie l'ordre fait
partie des trois actes de langage classiques (par exemple au sens de la
Théorie de la Pertinence, Sperber & Wilson 1995), en pratique l'ordre
direct est ressenti comme agressif et on lui préfère un acte de langage
indirect, comme une question à valeur (cachée) d'ordre. La notion d'acte
de langage sera étendue à celle d'acte communicatif afin d'intégrer les
modalités non-verbales (Poggi et Pelachaud, 2000) et le sujet portera
sur la modélisation des actes communicatifs multimodaux, et sur les
conséquences des choix qu'un système de dialogue humain-machine peut
effectuer. Les modèles construits s'intégreront dans la plateforme Greta
(Niewiadomski et al., 2011), qui permet de communiquer avec l'humain en
générant chez l'agent une large palette de comportements expressifs
verbaux et non verbaux (Bevacqua et al., 2012). Plusieurs cas
d'application pourront être envisagés : dialogues d'entraînement de
jeunes en insertion sociale aux entretiens d'embauche (projet Tardis),
dialogues entre un ACA et les visiteurs d'un musée (projet A1:1)



Pour ce faire, le travail comportera les étapes suivantes :
- Etude de dialogues Humain-Humain (TCOF, CID...), des dialogues
  Humain-Machine (SCNF, CIO) et de dialogues humain-ACA multimodaux
  (Corpus Semaine (Schröder et al., 2011)), en comparant les actes
  communicatifs et actes de langage présents dans ces corpus et leur
  réalisation verbale et non verbale.
- Construction d'un modèle spécifiant des paramètres de synthèse
  multimodale retenus pour un ACA.
- Vérification du modèle en situations de communication (soit simulées
  soit via un paramétrage adéquat des ACA de la plateforme GRETA
  (Niewiadomski et al., 2011)).

Compétences requises :
- Connaissances en interaction homme-machine,
- Intérêt pour les aspects linguistiques et pragmatiques de la
  communication,
- Compétences en programmation (Java),
- Bon niveau en anglais.

Conditions du stage :
- Niveau requis : M2 ou diplôme d'ingénieur en informatique.
- Rémunération : 1/3 du SMIC.
- Durée : 6 mois en commençant début 2014.
- Lieu : première partie du stage au laboratoire Lattice (1 rue Maurice
  Arnoux, Montrouge - métro Porte d'Orléans ou trawmay Jean Moulin), et
  deuxième partie à Telecom Paris-Tech (37 rue Dareau, Paris 14e - métro
  Saint-Jacques ou Denfert).

Contacts :

Frédéric Landragin, chercheur CNRS, laboratoire Lattice.
Tel: +33 (0)1 58 07 66 21
E-Mail: frederic.landragin [at] ens.fr

Chloé Clavel, maître de conférences, GRETA team, Télécom ParisTech.
Tel:+33 (0)1 45 81 75 93
E-Mail: chloe.clavel [at] telecom-paristech.fr


Références :

E. Bevacqua, E. de Sevin, S.J. Hyniewska, C. Pelachaud (2012), A
listener model : Introducing personality traits, Journal on Multimodal
User Interfaces, special issue Interacting ECAs, Elisabeth André, Marc
Cavazza and Catherine Pelachaud (Guest Editors), 6:27-38, 2012
C. Kerbrat-Orecchioni (2001) Les actes de langage dans le discours.
Théorie et fonctionnement, Paris : Nathan Université.
F. Landragin (2013) Dialogue homme-machine. Conception et enjeux, Paris
: Hermès-Lavoisier.
G. McKeown, M. Valstar, R. Cowie, R., M. Pantic, M. Schroder (2012) The
SEMAINE Database: Annotated Multimodal Records of Emotionally Colored
Conversations between a Person and a Limited Agent, IEEE Transactions on
Affective Computing, Volume : 3 , Issue : 1, Page(s) : 5- 17, Jan.-March
2012
R. Niewiadomski, S. Hyniewska, C. Pelachaud (2011), Constraint-Based 
Model for Synthesis of Multimodal Sequential Expressions of Emotions, 
IEEE Transactions of Affective Computing, vol. 2, no. 3, 134-146, 
Juillet 2011
Poggi , C . Pelachaud , Performative facial Expressions in Animated 
Faces , In J . Cassell , J . Sullivan , S . Prevost , E . Churchill ( 
Eds .), Embodied Conversational Agents , Cambridge ( Mass .): MIT Press 
, 2000
Riviere, J., Adam, C., Pesty, S., Pelachaud, C., Guiraud, N., Longin, 
D., & Lorini, E. (2011). Expressive Multimodal Conversational Acts for 
SAIBA Agents, 316-323."
"181","2013-11-18","IRISA","Lorient","Proposition de stage
-------------------------------

Proposition de stage de fin d'études (Master, Ecole Ingénieur) en
informatique appliqué au Traitement Automatique des Langues Naturelles,
d'une durée minimale de 4 mois.
Titre : Enrichissement de lexique émotionnel pour l'informatique
affective

Contexte scientifique
--------------------------------

En collaboration avec le Laboratoire d'Informatique de l'Université de
Tours, le laboratoire IRISA, antenne de Lorient (56 - Morbihan) propose
un sujet de stage dans le cadre du projet de recherche DAPAI-EMO financé
par la société BAMSOO.

Le projet DAPAI-EMO fait suite à un projet (EmotiRob) concernant le
développement d'un robot compagnon affectif pour des enfants en
hospitalisation longue. Cette poursuite de travaux fait abstraction ici
de sa dimension robotique pour se concentrer sur ses aspects liés à la
compréhension émotionnelle de la langue. Au cours du projet EmotiRob,
nous avons développé EmoLogus, un système de détection des émotions qui
intervient à la suite d'un système logique de compréhension de message
appelé Logus. EmoLogus utilise la structure sémantique de l'énoncé
fourni par Logus pour mettre en ½uvre un calcul de la valence
émotionnelle portée par l'énoncé, c'est-à-dire pour savoir si celui-ci
porte une émotion positive, négative ou neutre. Ce calcul logique se
base principalement sur l'utilisation de normes lexicales émotionnelles
qui décrivent le système de valeurs du système : à chaque mot du
vocabulaire est associée une valence (positif, neutre, négatif) et une
intensité (nul, faible, fort) émotive. Le lexique émotionnel sur lequel
se base le système a été élaboré en collaboration avec l'équipe de
psycholinguistique d'Arielle Syssau, de l'Université Montpellier 2. Basé
sur des jugements évaluatifs contrôlés auprès d'une population de test
échantillonnée avec soin, il nous garantit la représentativité du
système de valeurs d'EmoLogus.

Le système a montré une bonne robustesse de détection dans le cadre
restrictif d'une communication enfantine. Il souffre toutefois du manque
de couverture de son lexique émotionnel. A l'heure actuelle, le système
EmoLogus intègre en effet un lexique limité à un millier de mots, alors
que la langue française générale compte entre 50 000 et 100 000 entrées
lexicales. Dans le cadre de ce projet, nous proposons d'utiliser des
techniques d'extension automatique de lexique émotionnel à partir d'une
ressource initiale telle que celle du système EmoLogus. Parmi les
méthodes proposées pour étendre automatiquement un lexique émotionnel
étendu, on distingue deux types d'approches :

- celles basées sur des réseaux sémantiques comme WordNet, où sont
  décrits des relations de synonymies entre tous les mots d'une
  langue. On peut alors rechercher des synonymes des mots germes
  présents dans le lexique originel et leur appliquer un algorithme de
  propagation de valence,

- celles basées sur des techniques d'analyse de données sur des corpus
  textuels. Dans ce second cas, on va étudier les cooccurrences de mots
  dans un corpus pour calculer des similarités sémantiques (remplaçant
  les liens de synonymie explicites de Wordnet) et les intégrer dans le
  calcul de la valence des mots du lexique. Dans le cadre de ce stage,
  on se propose ainsi d'utiliser la technique de l'analyse sémantique
  latente (LSA : Latent Semantic Analysis) pour calculer ces proximités
  sémantiques et s'en servir pour estimer la valence d'un mot.  Les mots
  germes déjà présents dans la norme lexicale émotionnelle actuelle
  serviront de base à l'espace vectoriel sur lequel sera opérée
  l'analyse de données permettant l'extension du lexique.

Ce stage visera à développer au moins une de ces deux techniques pour
étendre le lexique émotionnel d'EmoLogus, et tester l'apport de cette
extension sur un corpus de test. En cas d'avancée significative, ce
travail pourra donner lieu à communication dans une conférence
scientifique à laquelle sera invité à participer le stagiaire.

Travail à réaliser
----------------------

La personne recrutée sera en charge de la conception de nouvelles
techniques d'extension de lexique émotionnel, du développement d'un
lexique à large couverture pour le système EmoLogus ainsi que de la
réalisation de tests d'évaluation du système étendu obtenu. Le stage se
déroulera en trois étapes successives :

- Phase n°1 - Préparation des données (T0 - T0+1) : Veille technologie
  sur le sujet, définition des formats d'échange entre les différentes
  techniques d'extension du lexique, caractérisation d'une ou plusieurs
  application test et définition des données de test en relation et du
  protocole d'évaluation final.

- Phase n°2 - Extension de lexique par relations sémantiques (T0+1 -
  T0+3) : Extension du lexique germe par analyse des relations de
  synonymie et d'antinomie entre éléments (synsets) de Wordnet,
  évaluation de l'approche sur données de test (comparaison des
  performances d'EmoLogus avec ou sans le lexique étendu).

- Phase n°3 - Extension de lexique par analyse de données (T0+4 - T0+6)
  : Extension du lexique germe par analyse sémantique
  latente. Évaluation sur tests unitaires de l'approche, évaluation de
  l'approche sur données de test (comparaison des performances
  d'EmoLogus avec ou sans le lexique étendu). Cette phase ne sera
  abordée qu'en cas de stage de durée supérieure à quatre mois.

Profil recherché
---------------------

La personne recrutée sera en cycle terminal d'études en informatique, de
niveau Bac+5 (Master informatique professionnel, recherche ou
indifférencié, école d'ingénieur). Des connaissances en Traitement
Automatique des Langues et en analyse de données seront appréciées, sans
être un pré-requis à recrutement. Dans le cas d'un(e) étudiant(e) en
Master Recherche, le sujet de stage pourra être adapté aux attentes de
l'étudiant.

Rémunération
------------------

Rémunération minimale prévue par la règlementation à savoir 436,05 ¤ par
mois. Cette rémunération sera assurée dans le cadre d'un projet
industriel financé par la société BAMSOO.

Durée du stage et lieu d'exercice
------------------------------------------

La personne recrutée travaillera au sein du laboratoire IRISA, dans les
locaux de l'ENSIBS, à Lorient (Morbihan). Il s'intégrera dans une équipe
projet composée de Jeanne Villaneau (IRISA, équipe SEASIDE) et Jean-Yves
Antoine (Laboratoire d'Informatique de l'Université François Rabelais de
Tours, équipe BDTLN).

La durée minimale de stage sera de 4 mois. Une prolongation de stage est
envisageable à la demande du stagiaire ou de son établissement.

Contact - Dépôts de candidature
-------------------------------------------

Contact : Jeanne.Villaneau@univ-ubs.fr

Dépôt des candidatures : auprès de Jeanne Villaneau. Merci de déposer un
CV détaillé de vos activités passées, accompagné d'une lettre de
motivation et de vos relevés de notes des deux dernières années
d'études. Un développement Java sera demandé pour la sélection du
candidat.

Liens utiles
---------------

Laboratoire LI, équipe BDTLN : 
http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp

Laboratoire IRISA, équipe SEASIDE : http://www-seaside.irisa.fr/"
"182","2013-11-20","MODYCO & GREYC","NR","*** Proposition de stage de M2 en TAL ***

Le laboratoire MoDyCo (UMR CNRS-Université Paris Ouest Nanterre), en
collaboration avec le laboratoire GREYC (UMR CNRS-Université de Caen),
propose un sujet de stage en TAL de niveau Master 2 d'une durée minimale
de 4 mois, à partir de janvier 2014.

Titre : Enrichissement de ressources sémantiques pour l'analyse de la
factualité pour des systèmes de recherche d'information.

Rémunération : celle prévue par la règlementation à savoir 436,05 ¤ par
mois.

*- Contexte applicatif et enjeux théoriques *:

L'analyse automatique du degré de factualité des situations (ou
évènements) dénotées dans les textes s'impose depuis quelques années
comme un enjeu important dans le domaine de la recherche
d'information. Parmi les applications visées : les systèmes de
questions/réponses, les moteurs de recherche et, intégrés ou non à ces
derniers, les systèmes visant à proposer en sortie une visualisation des
informations sur une ligne du temps (ou *timeline*). Ces applications
visent alors à distinguer les évènements présentés comme déjà réalisés
et avérés des événements présentés comme incertains ou seulement
possibles ou encore des événements présentés par l'auteur d'un texte
comme certains selon un co-énonciateur dont l'auteur ne fait que citer
les propos en montrant qu'il n'y adhère pas lui-même.
Dans une autre terminologie, on parle de l'analyse et de la modélisation
des caractéristiques modales (voire énonciatives) des situations. Un
numéro entier de la revue *Computational Linguistics* (ModNeg, 2012) a
dernièrement été consacré à cette problématique. Il met l'accent sur sa
complexité théorique, en termes notamment de catégorisation sémantique
des divers indices (lexicaux et grammaticaux) qui participent à
l'expression du degré de factualité d'un évènement, celui-ci pouvant
être passé ou à venir. Un autre aspect fondamental, encore cependant peu
décrit dans la littérature tant linguistique que TAL, a trait aux modes
de calcul de ce degré étant donné plusieurs indices co-présents. Les
exemples ci-après donnent un aperçu des types d'énoncés qu'il s'agit de
pouvoir traiter en montrant la variation du statut véri-conditionnel
d'un même contenu propositionnel (<Pierre, venir>) fonction des indices
sous la portée sémantique desquels il tombe :

*Paul est venu*

*Paul est peut-être venu*

*Je crois que Paul est venu *

*On dit que Paul est venu *

*Il semblerait que Paul est venu *

*Selon Marie, Paul est venu *

*Selon Marie, Paul est sûrement venu *

*Marie prétend que Paul est venu*

*Paul devrait venir*

*Paul doit venir*

*Paul pourrait venir*

*- Sujet de stage :*

On note que peu de ressources ont été élaborées pour le français jusqu'à
présent. Le stage visera à combler en partie ce déficit et s'intéressera
à une analyse sémantique fine d'indices lexicaux (verbes, noms,
adjectifs, adverbes). Cette analyse s'appuiera sur une méthodologie et
des ressources déjà constituées (Battistelli et Damiani, 2012, Damiani
et Battistelli 2013, (Enjalbert et Mathet, 2013) ainsi que sur des
conceptions linguistiques issues de (Authier-Revuz, 1995) ou (Gosselin,
1999). Ces ressources et cette méthodologie seront testées et évaluées
sur deux types de corpus de textes dans une perspective comparationniste
: des dépêches d'agence journalistique et des news technologiques
publiées sur le net. Le premier type de corpus est actuellement plus
particulièrement analysé dans le cadre d'un système développé pour le
projet ANR ChronoLines dont MoDyCo est le pilote
(http://chronolines.fr/) ; le second type de corpus est lui plus
particulièrement analysé dans le cadre d'une application développée au
sein de l'entreprise Noopsis (http://noopsis.fr/), partenaire du
laboratoire GREYC. Le travail visera en outre à préciser les zones de
recouvrement théorique comme applicatives avec le domaine de
l'annotation des opinions (Béthard et al., 2004, Wilson et Wiebe, 2003).

*- Profil du candidat:*

Le candidat devra être inscrit dans un Master en traitement automatique
des langues ou en linguistique appliquée.

- Compétences demandées

* compétences en traitement automatique des langues et/ou en
  linguistique.

* compétences de base en informatique et plus spécifiquement maitrise
  des langages de type perl et python.

- Comment candidater ?

Envoyer un CV (avec le détail des cours et notes des deux années de
Master) et une lettre de motivation à :

Delphine Battistelli :

del.battistelli@gmail.com

Patrice Enjalbert :

patrice.enjalbert@unicaen.fr

*- Références *

Authier-Revuz J. (1995). Ces mots qui ne vont pas de soi, Boucles
réflexives et non-coïncidences du dire, Paris: Larousse, 1995

Battistelli D., Damiani M. (2013) - « Analyzing modal and enunciative
discursive heterogeneity: how to combine semantic resources and a
syntactic parser analysis », in Actes WAMM (Workshop on Annotation of
Modal Meaning in Natural Language), held in conjunction with IWCS'13,
Potsdam, Allemagne.

Bethard S., Yu H., Thornton A., Hatzivassiloglou V., Jurafsky D. (2004).
« Automatic extraction of opinion propositions and their holders"", in
Working Notes of the AAAI Spring Symposium on Exploring Attitude and
Affect in Text: Theories and Applications, March 22-24, 2004, Stanford

Damiani M., Battistelli D. (2013) - « Enunciative and modal variations
in newswire texts in French: From guideline to automatic annotation »,
in Actes de The 7th Linguistic Annotation Workshop & Interoperability
with Discourse, held in conjunction with ACL'2013, Sofia, Bulgarie.
 
Enjalbert, P., Mathet, Y. (2013) - « Constructions `Verbe + Verbe
infinitif': étude de corpus et lexique sémantique », Document interne
GREYC-Noopsis, Octobre 2013.

Gosselin L. (2005). *Temporalité et modalité*, Bruxelles, De Boeck
Supérieur « Champs linguistiques », 2005.

ModNeg, 2012. Modality and Negation, Computational Linguistics, Special
Issue - Volume 38, Issue 2 - June 2012
(http://www.mitpressjournals.org/toc/coli/38/2).

Sauri R., Pustejovsky J. (2007). ""Determining Modality and Factuality
for Text Entailment"", in Actes ICSC 2007, Irvine, California, 2007.

Wilson T., Wiebe J. (2003). ""Annotating opinions in the world Press"", in
Actes 4th SIGdial Workshop on Discourse and Dialogue (SIGdial-03), ACL
SIGdial, 2003."
"183","2013-11-20","Orange Labs","Lannion","Stage extraction et qualification des entités nommées du Linked Open Data (f/h)

ref : 0006799 | 13 nov. 2013



Orange


Au service de 231 millions de clients sur les cinq continents, Orange
est l'un des principaux opérateurs de télécommunications au
monde. C'est aujourd'hui un opérateur intégré, fixe, mobile, internet
et télévision.

La recherche et l'innovation du Groupe sont portées par le réseau
mondial des Orange Labs et des Technocentres. Les 5000 chercheurs,
ingénieurs, concepteurs, développeurs sont répartis sur 4 continents
pour être au plus près des besoins des pays. L'activité de Recherche
et de Développement est l'une des sources principales de l''innovation
d'Orange qui, avec près de 7500 brevets à son actif à fin 2012,
contribue à développer la nouvelle génération de services de
communication intégrés, innovants et simples d'utilisation.

L'équipe Future Architectures and Textual Technologies d'Orange Labs a
en charge des travaux de recherche et développement dans le domaine du
Traitement Automatique des Langues (TAL) pour l'écrit : analyse
sémantique du texte, extraction d'information, requêtes en langage
naturel, bases de connaissances linguistiques.

Votre rôle

Sous la responsabilité d'un ingénieur de recherche, vous participez à
l'amélioration des données nécessaires pour pouvoir extraire des
informations du texte.

Pendant le stage, 

- vous évaluez la pertinence des bases d'Entités Nommées (EN) du
  Linked Open Data (LOD, freebase, dbpedia...),

- vous récupérez et fusionnez ces Entitées Nommées en recherchant les
  doublons (SameAs) en exploitant les connaissances existantes du LOD,

- vous établissez la correspondance entre les classes des données LOD
  et les types et sous-types d'EN utilisés par les logiciels de
  l'équipe,

- vous développez des algorithmes permettant de calculer un poids par
  défaut sur les différentes EN et d'adapter ce poids au domaine
  d'application vous définissez et développez le processus
  d'intégration de ces bases d'EN pour permettre leur mise à jour
  automatique et régulière.


Votre profil

Vous préparez une formation de niveau Bac +5 ou un Master 2 dans le
domaine des technologies du langage ou du Web sémantique

Vous connaissez les formats et technologies du Web Sémantique (RDF,
ontologies, Linked Open Data). Vous maîtrisez Java ou Python

Le plus de l'offre

Vous travaillerez sur un domaine technique stimulant, au sein d'une
équipe pluridisciplinaire.

Contrat

Stage de fin d'études


Pour postuler : 

Consultez la page :

http://orange.jobs/jobs/offer.do?joid=35860&lang=fr&wmode=light"
"184","2013-11-22","INRA","Paris ou Grignon","INRA Mét@Risk
Méthodologies d'analyse de risque alimentaire
16, rue Claude Bernard
75231 Paris cedex 05

INRA GMPA
Génie et Microbiologie des Procédés Alimentaires
Avenue Lucien Brétignières
78850 Thiverval Grignon

Sujet de stage de master M2

Construction d'un corpus de connaissances sur un système de production
et de stabilisation de cellules microbiennes

Contacts : liliana.ibanescu@agroparistech.fr,
caroline.penicaud@grignon.inra.fr, lydie.soler@paris.inra.fr

La production et la stabilisation de cellules microbiennes est un
enjeu majeur pour de nombreuses bio-industries, représentant un marché
de 144 milliards de dollars en 2010 et qui devrait atteindre 259
milliards de dollars en 2016. Les procédés employés sont très
énergivores, et face au contexte énergétique actuel, des améliorations
voire des alternatives doivent être envisagées. Au-delà de la question
de l'énergie, c'est la durabilité du système qui est mise en question,
intégrant la dimension d'épuisement des ressources (énergie, eau,
matières premières) mais aussi l'impact sur l'environnement
(e.g. réchauffement climatique) ou sur la santé humaine
(e.g. production de composés toxiques). Cependant, l'amélioration de
la durabilité du procédé ne peut pas se faire sans tenir compte des
contraintes spécifiques aux bioproduits, qui sont très fragiles et
subissent de fortes dégradations au cours des procédés. Les critères
d'évaluation de la qualité du bioproduit au cours des différentes
opérations sont liés à l'état physiologique des cellules et mesurables
à différents niveaux d'échelle (génétique, moléculaire, cellulaire,
population). L'intégration des différents critères (qualité du
bioproduit, performance du procédé, impact environnemental) pour
optimiser globalement le système est nécessaire dans l'optique de
développer des procédés plus durables tout en préservant la qualité
des micro-organismes.

L'objectif de ce stage est de constituer un corpus de connaissances et
un thésaurus pour la représentation in silico globale d'un système de
production et de stabilisation de cellules microbiennes intégrant les
différentes étapes de production, les niveaux d'échelle nécessaires à
la description de la fonctionnalité du produit, et, les entrées et
sorties liées à l'impact environnemental, tout en prenant en compte la
composante économique du système.  Ce stage sera réalisé dans le cadre
d'une collaboration entre deux équipes de deux unités INRA, l'équipe «
Ingénierie des connaissances » de l'unité Mét@risk qui travaille en
particulier sur la constitution de bases de connaissances et la
construction d'ontologies et l'équipe « Bioproduits - Aliments -
Micro-organismes - Procédés » de l'unité GMPA qui travaille en
particulier sur l'objet d'étude de ce stage.

Les étapes du travail seront les suivantes:

1- Extraction de connaissances issues de sources identifiées et du Web
pour élaborer et enrichir le corpus de connaissances ;

2- Prise en compte du caractère multi-échelles du système dans la
construction du corpus de connaissances ;

3- Construction d'un thésaurus permettant de représenter la
connaissance du corpus de façon structurée et hiérarchique

Lieu du stage: AgroParisTech (Paris ou Grignon), durée de 6 mois,
stage rémunéré"
"185","2013-11-22","AERIAL","Paris","Offre de Stage en Linguistique-Informatique / Traitement automatique
des langues

Extraction automatique d'informations pertinentes et création de
thésaurus.

Référence : LGST-INF-1

Merci d'envoyer votre CV & Lettre de motivation à l'adresse suivante :
contact@aerial-group.com

Présentation d'Aerial

AERIAL a pour c½ur de métier le conseil en pilotage d'entreprise. Sa
vocation est de faire évoluer le mode de fonctionnement de
l'entreprise pour lui permettre d'obtenir une amélioration simultanée
de ses ratios de productivité et de sa capacité de croissance.  Pour
exercer cette vocation, AERIAL intervient, sans modifier en profondeur
les structures, à la fois :

- Sur le pilotage stratégique de l'entreprise pour lui apporter
souplesse et réactivité

- Sur le pilotage de son système d'information pour en faire un outil
d'amélioration de son efficience

- Sur le pilotage de l'innovation pour lui permettre d'anticiper sur
  son marché

Description du poste :

Dans le cadre de son offre DPO
(http://www.aerial-group.com/nos-approches/509-2/), vous participerez
au développement d'un système de management de l'information innovant,
permettant d'extraire automatiquement des informations pertinentes.

Pour ce faire nos clients nous confient leurs données stockées en
interne et/ou nous faisons pour eux une veille externe. Ces données
sont ensuite analysées sémantiquement en profondeur pour détecter les
informations pertinentes et les champs lexicaux utiles au domaine puis
restituées graphiquement au travail d'une plateforme SAAS.

La pertinence de l'extraction d'information dans les corpus client est
donc un enjeu très fort au sein d'Aerial.

Le stagiaire devra dans un premier temps mettre en ½uvre une analyse
de corpus pour identifier le focus ainsi que les attributs pertinents
pour le client.  Puis à partir de cette analyse, modéliser
l'information pertinente par des patrons morphosyntaxiques, et/ou par
la création de thésaurus sémantiquement pertinent pour le domaine
client.  Enfin, le stagiaire pourra intervenir sur des actions
correctrices et des paramétrages sémantiques de l'outil.

Compétences techniques :
- XML 
- Expressions régulières
- Sémantique
- Morphosyntaxe
- Traitement automatique du langage

Compétences individuelles : 
-  Analyse
- Méthode
- Rigueur
- Autonomie
- Aptitudes à travailler en équipe
- Esprit d'analyse, de synthèse
- Curiosité dans le domaine


Profil et expérience

De formation BAC+ 4/5 (école d'ingénieur ou universitaire) en
linguistique informatique, Linguistique avancée et appliquée aux
sciences et techniques de l'information et de la communication
spécialité traitement automatique du langage ou équivalent avec des
connaissances premières en Text-Mining.  Dynamique, autonome et
organisé(e), vous faite preuve de rigueur et de professionnalisme.

Type de contrat
Stage d'une durée de 6 à 12 mois

Lieu
Paris

Rémunération
En fonction du profil du candidat"
"186","2013-11-25","L3i","La Rochelle","*Sujet de stage :*

*Développement de grammaires d'extractions de descriptions temporelles.*

**

*Résumé du travail proposé :*

L'objectif de ce stage est de développer une grammaire d'extraction de 
marqueurs temporels dans le domaine du tourisme. La plupart des 
informations contenues dans une base de données touristiques 
(événements, manifestations, hôtels, restaurants, musées...) contiennent 
des marqueurs temporels (date, durée, horaires d'ouvertures, conditions 
d'ouvertures ou de tarifs...) qu'il s'agira d'identifier au moyen d'une 
grammaire adaptée.

A partir de données réelles, vous aurez à développer une grammaire
locale de reconnaissance de ces marqueurs, en utilisant les outils
Unitex (http://www-igm.univ-mlv.fr/~unitex/) et GramLab
(http://www.gramlab.org/fr/).

*Mots clés :*

Traitement automatique des langues, grammaires locales, Unitex, GramLab,
expressions temporelles

*Informations complémentaires :*

*Encadrant(s) *: Alain Couillault, Mickaël Coustaty, Jean-Marc Ogier

*Axe thématique*://IDDC/(Image, Documents, Données Complexes)/

*Axe stratégique *: Pertinence Contenu-Interaction

*Cadre de coopération* : Projet TourInflux (Investissement d'Avenir)

*Date de début du stage *: Janvier 2014

*Durée du stage *: 5 à 6 mois

*Contexte de l'étude:*

Les travaux menés par le candidat se dérouleront au sein du L3i et
s'inscriront dans le projet Tourinflux. . Le projet Tourinflux,
sélectionné dans le cadre de l'appel à projets Big Data du Fonds
National pour la Société Numérique et financé dans le programme
d'investissements d'avenir, rassemble deux entreprises, une association
d'entreprises et le laboratoire L3i, et sera réalisé en partenariat avec
plusieurs acteurs du tourisme de France. Ce projet vise à apporter aux
acteurs du tourisme (d'abord les institutionnels mais aussi les acteurs
privés) un ensemble d'outils leur permettant de gérer à la fois leurs
données internes et les informations disponibles sur le web afin de
mieux comprendre comment un territoire est perçu et de mieux agir sur
cette perception. Les outils actuellement à disposition des
institutionnels du tourisme sont insuffisants pour répondre à ce besoin
du fait des problèmes de collecte, d'analyse, de manipulation et
d'échange d'informations réalisés de manière beaucoup trop artisanale.
L'objectif de Tourinflux est de proposer un tableau de bord complet
permettant aux institutionnels du tourisme, quelle que soit leur taille,
de visualiser et interpréter l'information disponible par rapport à leur
territoire (aux niveaux micro et macro) afin de prendre les décisions
les plus efficaces.

*Le laboratoire:*

Le laboratoire L3i, EA 2118 créé en 1993, représente la seule et unique
composante de recherche du domaine STIC sur l'Université de la Rochelle
associant très efficacement les chercheurs de l'IUT de la Rochelle, et
du Pôle Sciences en informatique. Dans le cadre de la politique
quadriennale (désormais quinquennale) de l'université de la Rochelle, le
L3i vient d'être évalué A par l'AERES. Le laboratoire Informatique,
Image et Interaction a choisi d'axer son projet de laboratoire autour de
deux thèmes (Axes Thématiques) que sont « Image, Document et Données
Complexes » et « Systèmes Interactifs et Images », véritables coeurs de
métier du laboratoire. Par ailleurs, le laboratoire propose de mettre en
avant ASPIC (Axe Stratégique Pertinence Intraction/Contenus), vecteur de
visibilité de son action scientifique au sein de projets structurants et
en articulation avec le monde socio-économique. Ainsi, plus d'une
dizaine de projets sont actuellement menés autour de l'analyse de
documents et de données complexes d'une part (en lien avec le centre
européen de valorisation des contenus numériques -- Valconum), et autour
de l'interaction appliquée aux jeux vidéos et l'e-Education d'autre
part. Par ses activités de ces six dernières années, le L3i a développé
des outils et des compétences dans l'analyse de données récurrentes dans
le temps et l'espace, mais également l'analyse de contenus et de données
complexes et hétérogènes.

*Description du sujet :*

Le candidat retenu devra, à partir de corpus dans le domaine du
tourisme, développement une grammaire d'analyse d'évènements
touristiques, récurrents ou non, dans le temps et/ou dans l'espace («
tous les lundi », « tous les ans », « dans toutes les boutiques du
réseau », «tous les mardis sur la place du marché sauf veille de jours
fériés », « Hôtel ouvert toute l'année, restauration sur place seulement
en été »...).

*Qualifications :*

Le candidat devra justifier de compétences de recherche dans au moins 
deux des quatre domaines suivants :

- Traitement Automatique des Langues, Fouille de texte

- Raisonnement temporel et/ou spatial

- Annotation et évaluation

- Ecriture de grammaires d'extraction

*Contacts -- liens : *

*Email *: mickael.coustaty@univ-lr.fr ; alain.couillault@univ-lr.fr ;
jean-marc.ogier@univ-lr.fr"
"187","2013-11-25","EDF R&D","Clamart","STAGE INGÉNIERIE LINGUISTIQUE
SUJET 2014: ÉVALUATION D'OUTILS TEXT MINING
DURÉE : 6 MOIS ENVIRON

1.      CONTEXTE

Le volume des données numériques textuelles, disponibles sur l'Internet
(forums, twitters etc.) ou relatives à des contacts client (enquêtes,
centre d'appel etc.), augmente chaque année. L'analyse de ces
informations, structurées ou non, est, aujourd'hui, un impératif
stratégique pour une entreprise telle qu'EDF. Dans ce cadre, et dans
l'objectif de toujours mieux connaître les besoins des clients,
l'exploitation de ces documents implique l'utilisation de méthodes et
d'outils adaptés. Au c½ur de ces problématiques les outils de Text
Mining sont de plus en plus nombreux et performants, ainsi nous
souhaitons étudier les principaux outils évoluant sur le marché
aujourd'hui.

2.       SUJET DU STAGE

Depuis 2003, les données textuelles sont essentiellement traitées à la
R&D via des solutions développées par l'éditeur TEMIS (Text-Mining
Solution).  Ce choix fait suite à différentes campagnes de veille sur
les outils de Text Mining.  Un protocole de test d'outils de Text Mining
avait été défini et appliqué à l'étude approfondie de différents
logiciels.

Dans le cadre du suivi des évolutions des outils de Text Mining, nous
souhaitons effectuer une nouvelle évaluation des outils d'analyse de
données contenant du texte.

Ce stage se décomposera en 3 parties : 

- Veille d'outils de Text Mining : Il s'agira de mener une étude de
  marché des outils existants aujourd'hui.

- Evaluation : A partir des solutions émergentes du marché, il s'agira
  d'évaluer une sélection d'outils (entre 3 et 4) jugés à priori
  intéressants par rapport aux besoins d'EDF.

- Perspectives : Dans un second temps, il s'agira d'identifier les
  perspectives envisageables quant à l'alliance du Text Mining et du Web
  sémantique au regard des besoins EDF.

INFORMATIONS PRATIQUES

Interlocuteurs:
Delphine Lagarde        01.47.65.39.75  delphine.lagarde@edf.fr
Anne Peradotto  01.47.65.44.89  anne.peradotto@edf.fr

Lieu du stage: 
EDF R&D - Département ICAME
1, avenue du Général de Gaulle
92141 Clamart Cedex 

Date & Durée : Début 2014 - 6 mois environ

Rémunération: A définir (environ 1.000¤/mois)"
"188","2013-11-25","LGI2P","Nîmes","Le laboratoire LGI2P à Nîmes de l'École des Mines d'Ales, propose le
stage Master 2 suivant :

*Lieu : *Nîmes, site EERIE, EMA, parc Georges Besse, 30000 Nîmes

*Sujet : *SÉMANTIQUE, ÉQUILIBRES ET STABILITÉS DE CONSTRUCTION DE
COMMUNAUTÉS RECOUVRANTES DANS LES RÉSEAUX SOCIAUX

*Descriptif succinct* /(pour une description plus détaillée, voir 
adresse ci-dessous)/
Les réseaux sociaux occupent une part de plus en plus importante dans
l'échange de données sur le web. La recommandation de produits et de
services, les modèles utilisateurs enrichis par des données sociales
peuvent revêtir une grande importance.

Le sujet proposé a pour objectif de déterminer des communautés extraites
à partir de données sociales et de rechercher les optimums de stabilité
et d'équilibre tout en tenant compte de leur sémantique.

La signification et la stabilité de ces communautés ainsi constituées
n'est que peu abordée dans les travaux actuels. Les auteurs appliquent
un algorithme unique d'optimisation et observent ensuite les
performances.

Le travail de stage aura les objectifs suivants à partir des travaux
déjà effectués au laboratoire :

- Approfondir les travaux de recherche de stabilité dans la construction
  de communautés recouvrantes.
- Établir les fondements de la sémantique attachés à la construction de
  communautés
- Définir des procédures de validation de communautés
- etc.

Pour plus de détails voir la description à l'adresse suivante :
http://www.lgi2p.ema.fr:8090/plantie/site/index.php/sujet-master-recherche

*Direction de stage* (à contacter pour plus d'informations)
- Michel Plantié, LGI2P (michel.plantie@mines-ales.fr)
- Michel Crampes, LGI2P (michel.crampes@mines-ales.fr)

*Remarque importante :*
Un support financier est possible pour une poursuite en thèse de
doctorat.
Si les compétences et le niveau académique du (de la) candidat(e) le
justifient, sa candidature sera notamment soutenue pour l'obtention d'un
tel financement, afin qu'il (elle) puisse accomplir une thèse à la suite
de ce stage."
"189","2013-11-27","Inbenta","Toulouse","*Présentation société*
 ------------------------------

inbenta est une société pionnière dans le *Traitement Automatique du
Langage Naturel et la recherche sémantique*. Basée sur ces concepts
novateurs, inbenta développe depuis 2005 des solutions logicielles pour
les sites internet de Grands Comptes.

*Description de l'offre*
 ------------------------------

Inbenta a développé un moteur de recherche intelligent appelé *Inbenta
Semantic Search Engine* (ISSE). Les deux tâches principales de ce moteur
sont d'analyser les questions des utilisateurs et de trouver la réponse
appropriée à la requête en effectuant une recherche dans une base de
connaissances.


Un *module de désambiguïsation syntaxique et sémantique* est intégré
dans notre moteur de recherche. Ce module est très important car il fait
partie intégrante du bon fonctionnement de la solution. L'objet du stage
proposé par inbenta sera d'améliorer le module de désambiguïsation.


Les missions de stage seront :

   - Gestion linguistique et éditoriale d'un projet de FAQ dynamique
     afin que le stagiaire s'approprie l'existant
   - Enrichissement du module de désambiguïsation par l'ajout de règles,
     de descriptions lexicales et de grammaires locales + évaluation du
     travail
   - Réflexion d'amélioration du module de désambiguïsation à un niveau
     algorithmique


*Profil recherché*
 ------------------------------

Nous recherchons une personne enthousiaste, organisée et sérieuse et
ayant l'envie d'intégrer une équipe internationale. Le stagiaire devra
également avoir les compétences suivantes :

   - Études en Traitement Automatique du Langage Naturel
   - Excellente maîtrise de la langue française et bonne communication
     écrite et orale en espagnol, anglais ou catalan

Bonus :

   - Maîtrise d'au moins un langage de programmation (PHP de préférence)
   - Maitrise des expressions régulières et du SQL


*Modalités du poste*
 ------------------------------

   - Stage de 5 à 6 mois (avec possibilité d'embauche en CDI)
   - Rémunération prévue: 30% du SMIC (+ prime en fonction des
     résultats)
   - Début : à partir de Février / Mars 2013
   - Lieu : Toulouse


Merci d'adresser CV et lettre de motivation à Quintana Manon à l'adresse
mail suivante : *mquintana@inbenta.com*"
"190","2013-11-27","Vision Objects","Nantes","*Stage en Traitement Automatique des Langues H/F :*

*SUJET : Influence des types de corpus sur la reconnaissance d'écriture*


 Avec plus de 90% de son CA à l'international, et plus de 100 millions
d'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels
leader mondial sur le marché des interfaces homme-machine basées sur la
reconnaissance d'écriture manuscrite.


 Disponible dans plus de 85 langues, ses produits concernent les marchés
de la mobilité (saisie de texte, prise de notes, ...), de l'éducation
(apprentissage de l'écriture, des mathématiques, de la géométrie, ...) de
l'entreprise (prise de notes et traitement de formulaires), et de
l'automobile (saisie de texte à partir d'une surface tactile,
interaction avec GPS).


 Vision Objects est une entreprise d'innovation et de hautes
technologies.  Le c½ur de sa technologie MyScript est diffusé sous forme
de kit de développement logiciel, de « Cloud service », de composants à
intégrer ou sous forme d'applications prêtes à l'emploi.

Le moteur de reconnaissance de Vision Objects se classe régulièrement
aux premières places des compétitions scientifiques internationales
(cf., par exemple, ICDAR). Dans le cadre de sa forte croissance, Vision
Objects (Nantes, France) est à la recherche d'un:


 *Stagiaire Ingénieur Informaticien en Traitement Automatique des
Langues (TAL)*


 Dans l'équipe *Ressources Linguistiques*, vous serez amené à travailler
sur la mission suivante :


 *SUJET : Influence des types de corpus sur la reconnaissance
  d'écriture*

*Les nouveaux usages du Web ont fait émerger de nouveaux registres de
langue. On n'écrit pas de la même façon un e-mail, un sms, un tweet ou
un article plus formel.*

*Le stage consiste à enrichir en diversité les corpus utilisés pour la
construction des modèles de langue et à évaluer la façon de combiner ces
corpus. On s'intéresse en particulier aux contenus extractibles des
réseaux sociaux ainsi qu'aux corpus disponibles dans de nombreuses
langues car notre solution est disponible dans 64 langues, dont
certaines peu dotées en termes de ressources.*


 Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.


 Au sein de VisionObjects, vous travaillerez sur des technologies à la
pointe de la recherche et pourrez identifier les applications directes
et concrètes de votre travail.

Un ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à
l'élaboration de l'application Android MyScript Calculator: une
calculatrice manuscrite utilisant la reconnaissance d'équations de
VisionObjects. Les applications réalisées et publiées par VisionObjects
à partir du travail de ce stage ont depuis totalisé plus de 10 millions
de téléchargements.


 Vous pouvez trouver gratuitement MyScript Calculator sur les stores
Android et iOS.

 Contact : job@visionobjects.com"
"191","2013-11-27","Vision Objects","Nantes","*STAGE EQUIPE TAL - VISION OBJECTS*

 Avec plus de 90% de son CA à l'international, et plus de 100 millions
d'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels
leader mondial sur le marché des interfaces homme-machine basées sur la
reconnaissance d'écriture manuscrite.


 Disponible dans plus de 85 langues, ses produits concernent les marchés
de la mobilité (saisie de texte, prise de notes, ...), de l'éducation
(apprentissage de l'écriture, des mathématiques, de la géométrie, ...) de
l'entreprise (prise de notes et traitement de formulaires), et de
l'automobile (saisie de texte à partir d'une surface tactile,
interaction avec GPS).


 Vision Objects est une entreprise d'innovation et de hautes
technologies.  Le c½ur de sa technologie MyScript est diffusé sous forme
de kit de développement logiciel, de « Cloud service », de composants à
intégrer ou sous forme d'applications prêtes à l'emploi.


 Le moteur de reconnaissance de Vision Objects se classe régulièrement
aux premières places des compétitions scientifiques internationales
(cf., par exemple, ICDAR).


 *Stagiaire - Développement d'un outil d'analyse de résultats*


 *Une problématique de la recherche en reconnaissance d'écriture est
d'évaluer globalement les avantages et inconvénients de différents
algorithmes, tout en étudiant les comportements de ces algorithmes sur
quelques cas spécifiques. Ce passage de la vérité générale au cas
particuliers, et inversement, peut être grandement facilité par un
outillage adéquat.*

*Dans ce stage, on s'intéressera au développement d'un nouvel outil de
détection de cas intéressants à partir de bases de test globales. Au
sein du département R&D, le stagiaire aura l'occasion de comprendre le
fonctionnement du moteur de reconnaissance d'écriture, tout en acquérant
des compétences de programmation utilisables dans bien d'autres
contextes.  Le travail comprend des aspects algorithmiques et d'analyse
de données pour factoriser l'information, ainsi que des aspects
interface graphique et intégration dans les outils existants pour la
présenter de façon optimale à l'utilisateur.*


 Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.


 Rigoureux, dynamique et d'un relationnel facile, vous saurez rapidement
vous intégrer au sein d'équipes de haut niveau et dans un environnement
stimulant.


 Au sein de VisionObjects, vous travaillerez sur des technologies à la
pointe de la recherche et pourrez identifier les applications directes
et concrètes de votre travail.

Un ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à
l'élaboration de l'application Android MyScript Calculator: une
calculatrice manuscrite utilisant la reconnaissance d'équations de
VisionObjects. Les applications réalisées et publiées par VisionObjects
à partir du travail de ce stage ont depuis totalisé plus de 10 millions
de téléchargements.

Vous pouvez trouver gratuitement MyScript Calculator sur les stores
Android et iOS.

 Contact : job@visionobjects.com"
"192","2013-11-27","Vision Objects","Nantes","*Stage en Traitement Automatique des Langues H/F :*

*SUJET : Détection automatique multilingue de sous-parties de mots
(morphèmes)*


 Avec plus de 90% de son CA à l'international, et plus de 100 millions
d'utilisateurs dans le monde, Vision Objects est un éditeur de logiciels
leader mondial sur le marché des interfaces homme-machine basées sur la
reconnaissance d'écriture manuscrite.


 Disponible dans plus de 85 langues, ses produits concernent les marchés
de la mobilité (saisie de texte, prise de notes, ...), de l'éducation
(apprentissage de l'écriture, des mathématiques, de la géométrie, ...) de
l'entreprise (prise de notes et traitement de formulaires), et de
l'automobile (saisie de texte à partir d'une surface tactile,
interaction avec GPS).

Vision Objects est une entreprise d'innovation et de hautes
technologies.  Le c½ur de sa technologie MyScript est diffusé sous forme
de kit de développement logiciel, de « Cloud service », de composants à
intégrer ou sous forme d'applications prêtes à l'emploi.


 Le moteur de reconnaissance de Vision Objects se classe régulièrement
aux premières places des compétitions scientifiques internationales
(cf., par exemple, ICDAR). Dans le cadre de sa forte croissance, Vision
Objects (Nantes, France) est à la recherche d'un:


 *Stagiaire Ingénieur Informaticien en Traitement Automatique des
Langues (TAL)*


 Dans l'équipe *Ressources Linguistiques*, vous serez amené à travailler
sur la mission suivante :


 *SUJET : Détection automatique multilingue de sous-parties de mots
(morphèmes)*

*Les langues fortement agglutinantes posent des problèmes spécifiques en
modélisation statistique des langues, notamment le très grand nombre
d'unités lexicales possibles. Une approche est de découper ce qui est
couramment appelé mot en unités plus petites.*

*Le stage consiste à étudier et implémenter des algorithmes non
supervisés (sans exemples de découpage dans la langue cible) de
découpage de mots en morphèmes. Il s'agit ensuite d'appliquer ces
algorithmes dans un contexte fortement multilingue car notre solution
est disponible en 64 langues.*

*Une suite possible de ce travail sera l'étude de techniques également
non supervisées et multilingues d'analyse grammaticale (PoS tagging).*


 Stage basé à Nantes, démarrage dès que possible en 2013 ou 2014.

Rigoureux, dynamique et d'un relationnel facile, vous saurez rapidement
vous intégrer au sein des équipes.


 Au sein de VisionObjects, vous travaillerez sur des technologies à la
pointe de la recherche et pourrez identifier les applications directes
et concrètes de votre travail.

Un ancien stagiaire, promotion ECN 2010-2013, a ainsi contribué à
l'élaboration de l'application Android MyScript Calculator: une
calculatrice manuscrite utilisant la reconnaissance d'équations de
VisionObjects. Les applications réalisées et publiées par VisionObjects
à partir du travail de ce stage ont depuis totalisé plus de 10 millions
de téléchargements.

Vous pouvez trouver gratuitement MyScript Calculator sur les stores
Android et iOS.


 Contact : job@visionobjects.com"
"193","2013-12-02","Trooclick","Paris","Trooclick France is a company that specializes in the development of web
applications for the automatic processing of information. Our goal is to
create services that rebuild the user's trust in digital content. Up to
now, Web players were able to enhance the relevance of this content; we
go a step further and contribute to improve its reliability.

Trooclick was created in November 2012. Just a few months later, in
April 2013, it received financial support from the BPI (French public
investment bank) and in June 2013 the French government granted it the
Status of ""Young Innovative Company"" (JEI), recognizing its innovative
nature. It now counts twelve committed and passionate members in its
tight-knit team.

The company carries out R&D projects in search of technical solutions in
the Artificial Intelligence field. Due to its growth, Trooclick is now
looking for candidates for a 6 month internship for its office in Paris
(17ème).


Missions:

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

You will turn ideas into well-documented and reliable linguistic
resources (both dictionaries and extraction rules) to ensure efficiency,
quality, performance and scalability.

A great team player, you will interact with other departments to
understand and fine tune specifications.
You will carry out unitary testing, create and maintain our test
validation corpus and participate in editing technical documents. All
developments will be done in English.

Qualifications:

   - BSc/MSc
   - Experience with NLP tools such as Gate, Treetagger, NooJ, Stanford
     for linguistic annotation, named entity recognition, relationship
     and fact extraction, sentiment analysis, etc.
   - Experience in scripting languages such as Perl or Python as well as
     XML format to be autonomous in completing some technical tasks.
   - Experience with basic database management operations (SQL language)
     Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will
     be a plus.
   - Excellent communication skills in English and French
   - We are open to new ideas that will significantly contribute to our
     success. Our friendly team will provide the opportunity for
     valuable collaboration.
   - We offer you career perspectives in a young and dynamic company
     with an interesting and diversified scope of duties at the cutting
     edge of research. We welcome applications from highly motivated
     individuals able to learn new techniques and share knowledge and
     experience with the team.

Interested? Then send your application to jobs@trooclick.com!"
"194","2013-12-04","IRIT","Toulouse","Prédiction automatique de relations d'implication entre verbes

Encadrement : Marta Abrusan (marta.abrusan@irit.fr), Stergos Afantenos
(stergos.afantenos@irit.fr), Farah Benamara (farah.benamara@irit.fr)

Lieu : IRIT, Université Paul Sabatier
Financement : prime de stage
Durée : 5 mois

La compréhension sémantique d'un texte est l'un des enjeux majeurs du
traitement automatique du langage (TAL). Cette tâche est primordiale
pour de très nombreuses applications telles que la génération
automatique de textes et de conversations, le résumé automatique, la
paraphrase automatique d'un texte ou encore la recherche
d'information. Le but de ce stage est de contribuer à ces recherches en
se focalisant sur la prédiction de relations entre verbes.

Prédire une relation entre verbes consiste à déterminer pour un couple
de verbes (v1,v2), associé ou non à un contexte, le type de relations
sémantiques qui les relient, cf. Chklovski and Pantel (2004), Tremper
and Frank (2013). Celles ci peuvent être de différentes natures :
relations de synonymie, d'antonymie, de causalité, d'implication, etc.
Dans ce stage, nous nous focaliserons sur les relations
d'implication. Par exemple, les verbes ""se balader"" et ""bouger"" sont
reliés par une relation d'implication, ce qui permettra à un ordinateur
de répondre à une requête du type Pierre s'est-il baladé ?, sachant que
la base de connaissances indique que Pierre a bougé.

Afin d'identifier ces relations, le stagiaire devra utiliser les
méthodes d'apprentissage automatiques les plus adéquates. Le but de ces
méthodes est d'apprendre une fonction f : X --> Y où X représente un
ensemble des features (ou traits) sur les paires des verbes et Y est un
booléen représentant le fait qu'il existe ou non une relation
d'implication entre ces verbes. Différentes méthodes seront
explorées. Nous commencerons d'abord par les méthodes supervisées qui
généralisent des observations faites sur un corpus de
données. Cependant, cette approche présuppose que le nombre d'instances
d'entraînement est suffisamment grand, ce qui n'est malheureusement pas
toujours le cas pour de nombreuses tâches où le coût humain d'annotation
des instances est élevé. La seconde étape sera alors d'explorer les
méthodes d'apprentissage semi-supervisées afin de réduire ce coût.

Références

Timothy Chklovski and Patrick Pantel (2004) : VerbOcean : Mining the web
for fine-grained semantic verb relations. In Proceedings of the 2004
Conference on Empirical Methods in Natural Language Processing, pages
33-40, Barcelona, Spain, 2004.

Tremper, G. and A. Frank (2013) : A Discriminative Analysis of
Fine-Grained Semantic Relations including Presupposition : Annotation
and Classification. In : Dialogue and Discourse, 4 (2), Special Issue :
Beyond Semantics. The Challenge of Annotating Pragmatic and Discourse
Phenomena, edited by S. Dipper, H. Zinsmeister and B. Webber, 282-322."
"195","2013-12-09","LIRMM","Montpellier","Bonjour,

Un stage de M2 (Recherche) est disponible au LIRMM (U. Montpellier 2),
entre le 20 janvier et mi-juin 2014.

*Candidatures souhaitées le plus rapidement possible.*

Titre : Combining Stochastic and Knowledge-based Modelling for Natural
Language Understanding

Encadrement : Jean-Philippe.Prost (Prost@lirmm.fr)
Lieu : LIRMM, Montpellier
Durée : 5 mois
Financement : selon barèmes légaux

Possibilité de poursuite en thèse, selon résultats (candidature soumise
à sélection).

Ce sujet de stage concerne le Traitement Automatique du Langage naturel
(TAL). L'objet en est de se pencher sur une voie possible d'hybridation
entre modélisation logique et modélisation probabiliste pour la
représentation de connaissances langagières.
Le sujet porte plus particulièrement sur la dimension syntaxique.

==============

Les parseurs les plus performants du moment sont dits ""robustes"", pour
leur capacité à produire un arbre syntaxique quelle que soit la phrase
en entrée, y compris mal-formée. Ces analyseurs sont construits à base
d'algorithmes d'apprentissage automatique qui permettent de construire
l'arbre le plus probable étant donné la phrase en entrée.
Cette robustesse est acquise au détriment d'une perte d'information
conséquente. Par exemple, la question de la bonne-formation
(grammaticalité) de l'entrée est éludée, l'analyse d'une phrase
bien-formée n'ayant pas nécessairement une probabilité maximale.
Or il est possible d'apporter une réponse exacte à ce problème, en
venant simplement brancher un module à base de raisonnement logique sur
la sortie non-déterministe d'un analyseur stochastique. Mais ce qui
serait souhaitable, serait de pouvoir intégrer ce processus de
résolution exacte dans le processus d'analyse stochastique.

L'objet de ce stage est donc d'explorer différentes pistes possibles sur
cette question. On pourra, par exemple, intégrer un mécanisme de
vérification de modèle (model checking, au sens de la théorie logique
des modèles) dans le procédé de reclassement (reranking) des n
candidat-modèles les plus probables que génère un analyseur
stochastique.

Le stage comportera une partie d'état de l'art, une partie d'exploration
théorique, et une partie réalisation (programmation).

JP. Prost"
"196","2013-12-09","LIGM & Lattice","Région parisienne","Sujet de stage M2 recherche en TAL : acquisition d'un analyseur en
dépendances du français médiéval

Dans le cadre du projet ANR Syntactic Reference Corpus of Medieval
French (SRCMF, 2008-2011), un Treebank (une collection d'arbres)
d'analyses en dépendances d'énoncés du français médiéval a été
constitué. Il comprend 260 000 mots (parmi lesquels environ 27 000 têtes
verbales) annotées en étiquettes morpho-syntaxiques et reliés par des
relations de dépendances étiquetées.

L'objectif du stage est d'exploiter ce corpus par apprentissage
automatique afin d'acquérir un analyseur en dépendances du français
médiéval, éventuellement couplé à un étiqueteur morpho-syntaxique. Ces
outils pourront être exploités sur de nouveaux textes. Ils permettront
d'étudier précisément les spécificités grammaticales du français
médiéval, en comparaison avec celles du français contemporain.

Le stage bénéficiera de l'encadrement d'une spécialiste du français
médiéval (Sophie Prévost) et de spécialistes du TAL et de
l'apprentissage automatique (Matthieu Constant et Isabelle Tellier).

Compétences requises :
- niveau M2 ou ingénieur en informatique ou en TAL
- Connaissances (ou au minimum intérêt argumenté) en TAL et en
  apprentissage automatique
- Compétences en programmation

Conditions du stage :
- Rémunération : prime de stage (1/3 du SMIC).
- Durée : 4 à 6 mois en commençant dès que possible en 2014.
- Lieu : le stage sera encadré en collaboration par le LIGM à
  Marne-la-vallée (http://ligm.u-pem.fr) et le Lattice à Montrouge
  (http://www.lattice.cnrs.fr), trajets à prévoir entre les deux lieux

envoyer CV + lettre de motivation à Matthieu Constant
(Matthieu.Constant@u-pem.fr), Sophie Prévost (sophie.prevost@ens.fr),
Isabelle Tellier (isabelle.tellier@univ-paris3.fr)"
"197","2013-12-16","Stella Medica","Rueil-Malmaison","Stella Medica est un cabinet de recrutement bien implanté dans le milieu
médical.

En partenariat avec une société de conseil informatique, nous
développons pour nos propres besoins et dans une optique de
commercialisation des outils de gestion de recrutement.

Dans le cadre de ce développement vous travaillerez sur un module de
gestion d'analyse des données candidat.

Les algorithmes à intégrer ou développer porteront sur les éléments
suivants :

- Dans le cadre de l'analyse de CV :
  o Identification de la nature et de la langue du document
  o Détection des informations dans le texte tels que (exemples simples) :
    Nom, prénom, date de naissance, adresse, métier et niveau
    d'expérience
- Détection de documents similaires
- Génération de résumé, dérivation de ce résumé en plusieurs langues
  (anglais en particulier)
- Amélioration du moteur de recherches multicritères existant
- Recherche automatique dans les réseaux sociaux et mise en lumière de
  points forts ou d'incohérences

Vous travaillerez dans une équipe à dominante informatique et serez donc
assez autonome. L'équipe sera encadrée par un chef de projet
informatique expérimenté, dans une démarche de développement logiciel
professionnel : démarche CMMI, outils de gestion de projet, de partage
des sources et de gestion des tests.

La plateforme de développement est principalement Microsoft : ASP.NET MVC en
C#, composants C# ; SQL Server.

Vous cherchez idéalement un stage de fin d'études Bac +5 en Traitement
Automatique de la Langue (TAL) ou Ingenierie Linguistique. Le résultat
de votre travail devra être « convertible en programme informatique »,
phase que vous pourrez vous-même éventuellement mettre en oeuvre.

Stage de longueur modulable de 4 à 6 mois à partir de février 2014 situé
à Rueil-Malmaison.
Rémunération selon profil, tickets restaurants, remboursement de 50% du
pass Navigo.

Contactez Philippe Martin avec votre CV et en précisant votre période de
stage attendue : philippe.martin@stella-medica.fr"
"198","2014-01-06","IDIAP","Martigny (CH)","Internship in Natural Language Processing and Machine Translation 
(OP-20131220-163254)

NLP Group, Idiap Research Institute, Martigny, Switzerland

Description: 	

Applications are invited for a 6-month internship at the Master level in
the field of natural language processing and statistical machine
translation. The internship is offered in relation to the Swiss MODERN
project (www.idiap.ch/project/modern) aiming at modeling discourse
entities and relations for improving MT. The intern will work within the
NLP group at the Idiap Research Institute.

The goal of the internship is to integrate existing tools for anaphora
resolution (in-house and third party ones) with phrase-based SMT models
(mainly using the Moses open-source system). Following previous work,
the intern will examine whether statistical predictions about the
features of target pronouns (gender, number, grammatical function, and
others) can be used when training SMT and when translating (decoding)
new texts. The intern will implement methods to derive such features,
will use the features in an SMT model (e.g. a factored one), and will
measure the variation in translation quality.

The applicants should have a background in computer science or
linguistics, with previous experience in SMT and NLP being a strong
advantage. The applicants should have demonstrable programming skills in
at least one programming language such as Perl or Python, Java or C/C++.
Experience with the Moses system and/or anaphora resolution systems
would be a plus. Good command of English is mandatory and knowledge of
another European language such as French, German or Dutch would be an
advantage.

The screening of the applications will start on February 1st, 2014 and
will continue until the position is filled. The intended starting date
is in spring 2014. The appointment is for 6 months, with a gross
internship salary of 2000 CHF per month. Participation in the MODERN
project will entail interaction with project partners at the
Universities of Zurich, Geneva, and Utrecht.

How to apply:

Please fill in and submit your application through the Idiap online
recruitment system, by clicking on the position's title at
http://www.idiap.ch/education-and-jobs.

Contact information:

Further information about this position can be requested via the Idiap
online recruitment system or by contacting Dr. Andrei Popescu-Belis,
head of the NLP group.

About Idiap: 	

Idiap is an independent, non-profit research institute recognized and
supported by the Swiss Government, and affiliated with the Ecole
Polytechnique Fédérale de Lausanne (EPFL). It is located in the town of
Martigny in Valais, a scenic region in the south of Switzerland,
surrounded by the highest mountains of Europe, and offering exciting
recreational activities, including hiking, climbing and skiing, as well
as varied cultural activities. It is within close proximity to Geneva
and Lausanne. Although Idiap is located in the French part of
Switzerland, English is the working language. Free French lessons are
provided.

Idiap offers competitive salaries and conditions at all levels in a
young, dynamic, and multicultural environment. Idiap is an equal
opportunity employer and is actively involved in the ""Advancement of
Women in Science"" European initiative. The Institute seeks to maintain a
principle of open competition (on the basis of merit) to appoint the
best candidate, provides equal opportunity for all candidates, and
equally encourage both genders to apply.

Andrei Popescu-Belis"
"199","2014-01-06","MarketScience","Orléans","Titre : ""Extraction d'information dans la presse financière""

MarketScience est une start-up en finance, qui développe un centre de
Data-Mining intégré à une appli. Cette appli sera commercialisée sur la
plateforme Bloomberg, à une clientèle de professionnels de la finance.

MarketScience combine modélisation des séries financières et
media-mining. L'extraction d'information financière spécifique à nos
besoins se fait en mobilisant des algos de TAL.

Ces algos permettent de

1. déterminer la nature de l'article et sa probabilité de contenir une
   information pertinente pour notre analyse

2. isoler l'information nécessaire et la relier à l'évolution sur
   certains marchés

3. catégoriser cette information au sein de facteurs économiques
   pré-identifiés

Ce travail se faisant tout d'abord en anglais (80% de la volumétrie
journalière), mais aussi en français, allemand, italien, russe et
chinois.

Vous travaillerez essentiellement avec les outils suivants : Python,
Unitex et MySQL/ SQL.

Une connaissance des techniques du TAL (Traitement Automatique des
Langues) ou des techniques d'apprentissage et de classification (SVM,
CRF, etc.)  est considérée comme fortement souhaitable.

Ce stage se déroulera au sein d'une équipe pluridisciplinaire composée
de statisticiens, économistes, programmeurs et ingénieurs TAListes.

Durée du Stage : 4 à 6 mois à partir de février 2014. Embauche à la clé.
Lieu du Stage : Orléans (45)

Rémunération : 1200 Eur net min.

Contactez-moi sur LinkedIn : Nicolas Boitout."
"200","2014-01-08","Eptica Lingway","Boulogne-Billancourt","Début : Février/Mars 2014

Durée : 4 à 6 mois

Lieu : Boulogne-Billancourt

Eptica Lingway, filiale du groupe Eptica, développe des produits
d'analyse automatique de CV et de recherche de documents RH à
destination des recruteurs (gamme LEA). Ces outils mettent en oeuvre des
grammaires d'analyse, un réseau sémantique adapté pour le monde des RH
et des stratégies de recherche documentaire spécifiques.  L'analyseur
LeaCV est disponible en français, anglais, allemand, espagnol.

Dans le cadre des évolutions de l'offre LEA, Eptica-Lingway propose des
stages conventionnés niveau M2, basés à Boulogne-Billancourt.

Au sein de l'équipe R&D, le candidat participera aux tâches suivantes:
- Adaptation de l'analyseur de CV et d'offres à de nouvelles langues ou
  localisations,
- Amélioration du réseau sémantique orienté RH utilisé pour la recherche
  et le matching CV/offres,
- Etude et implémentation de nouvelles stratégies de recherche de
  documents,
- Constitution de corpus de référence et validation des résultats
 
Compétences requises :
- Traitement Automatique des Langues (étude de corpus, moteur de
  recherche, grammaires locales, techniques de « machine learning »)
- Des connaissances en programmation/scripting (Java, Groovy, Perl, ...)
  sont un plus ainsi que la maîtrise de plusieurs langues européennes
- Bonnes capacités d'analyse
- Facilité à travailler en équipe

Contact:
Hugues de Mazancourt
hugues.de-mazancourt@eptica.com"
"201","2014-01-13","LIMSI","Orsay","Proposition de stage Master  / Ecole d'Ingénieur
LIMSI-CNRS (Paris-Sud) et LI (Tours)

Résumé

Proposition de stage de fin d'études ou de Recherche de niveau Bac+5
(Master, Ecole d'Ingénieur) en Informatique appliquée au Traitement
Automatique des Langues d'une durée de 4 mois minimum.

Contexte scientifique

Le LIMSI-CNRS (Paris-Sud) et le LI (Tours) proposent un sujet de stage
commun dans le cadre du projet de recherche TMH (Télécommunications,
Mobilité et Handicap) financé par la société BAMSOO. Le sujet porte sur
le Traitement Automatique des Langues (TAL) par utilisation de
techniques de fouille de données. La tâche concernée est la
reconnaissance des entités nommées (REN), qui permet d'extraire les noms
de personnes, de lieux, d'organisations, d'unités monétaire ou
temporelles dans des textes. Pour cela, sont implémentés des systèmes
plus ou moins supervisés (des automates aux CRF) qui s'appuient sur
d'autres traitements TAL (morphologie, morpho-syntaxe) et/ou des
lexiques à large couverture. Ces systèmes sont régulièrement mis en
compétition lors de campagne d'évaluation.

Le système que nous avons développé (mXS) met en ½uvre des techniques de
fouille de données. Son originalité consiste à rechercher séparément les
balises de début et de fin de chaque entité nommée. Pour ce faire, le
système énumère les motifs linguistiques (séquentiels hiérarchiques) qui
forment le contexte de ces balises et filtrent les motifs d'intérêt
comme ""règles d'annotation"". mXS a obtenu de bonnes performances
(3ème/8) dans le cadre de la campagne d'évaluation ETAPE, en particulier
dans des contextes bruités (transcriptions automatiques). Cependant,
pour améliorer encore les performances du système, il s'agit de
déterminer si les choix de modélisation effectués avantagent ou
pénalisent le système. Ce stage a pour objectif de mener des travaux
expérimentaux permettant d'apporter de nouvelles perspectives sur les
avantages et inconvénients de notre approche.

Travail à réaliser

En préliminaire, la personne recrutée se familiarisera avec les
différentes briques du système, dont en particulier :

- les prétraitements (morpho-syntaxe, lexiques) qui enrichissent les
  textes,
- le programme d'extraction de motifs séquentiels hiérarchiques (fouille
  de données),
- les modèles (symboliques et/ou statistiques) qui utilisent les motifs
  pour annoter des textes.

Ensuite, une étude approfondie sera menée sur l'apport des techniques
supervisées par insertion des balises d'annotation par rapport aux
approches de classification mot-à-mot. Cette étude sera amorcée par une
comparaison des erreurs sur la campagne ETAPE commises par mXS avec
celles commises par un système à base de transducteurs et un CRF (voire
à des version hybrides). Les expérimentations et études à mener par la
suite seront décidées selon déterminées selon les résultats de cette
étude. A terme, l'objectif est de déterminer quelles sont les
perspectives d'évolution les plus prometteuses pour les systèmes de REN.

En cas d'avancée satisfaisante du travail, le stage pourra être élargi à
l'étude des méthodes utilisant les motifs séquentiels hiérarchiques pour
le traitement du langage. Par exemple, cela pourra consister en
l'implémentation d'outils qui permettent de caractériser des corpus
selon les motifs qui en ont été extraits automatiquement. De manière
plus générale, l'idée est de découvrir de nouveaux liens possibles entre
les méthodes formelles (motifs organisés au sein de treillis) et des
tâches liées au TAL.

Profil recherché

La personne recrutée sera en cycle terminal d'études en informatique, de
niveau Bac+5 (Master informatique professionnel, recherche ou
indifférencié, école d'ingénieur). Des compétences en Traitement
Automatique des Langues et/ou en Fouille de Données seront
appréciées. Dans le cas d'un(e) étudiant(e) en Master Recherche, le
sujet de stage pourra être adapté aux attentes de
l'étudiant. Potentiellement, ce travail pourra donner lieu à
communication dans des conférences scientifiques.

Rémunération

Rémunération maximale prévue par la réglementation à savoir 436,05¤ par
mois, pour une durée de 4 mois de stage minimum (prolongation de la
durée du stage jusqu'à 6 mois à la demande de l'étudiant ou de son
établissement). Cette rémunération sera assurée dans le cadre d'un
projet industriel financé par la société BAMSOO.

Lieu d'exercice

Le stage se déroulera dans les locaux du Laboratoire d'Informatique pour
la Mécanique et les Sciences de l'Ingénieur (LIMSI-CNRS), Université
Paris-Sud, Rue John von Neumann, 91403 Orsay, au sein de l'équipe ILES
(Information, Langue Ecrite et Signée). Le stage sera encadré part
Damien Nouvel, postdoc au LIMSI et Jean-Yves Antoine, professeur de
l'Université François Rabelais de Tours (équipe BDLTN).

Dépôts de candidature

Contact : damien.nouvel@limsi.fr
Merci de déposer un CV détaillé de vos activités passées, accompagné
d'une lettre de motivation et de vos relevés de notes des deux dernières
années d'études.

Liens utiles

- Système mXS : http://damien.nouvels.net/fr/mxs
- Laboratoire LIMSI (groupes ILES et TLP) : http://www.limsi.fr
- Laboratoire LI (équipe BDTLN) :
  http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp
- Campagne Etape : http://www.afcp-parole.org/etape.html"
"202","2014-01-13","Viseo","Grenoble","Début : Février/Mars 2014

Durée : 4 à 6 mois

Lieu : Grenoble

Le groupe VISEO est un des principaux acteurs multi-spécialiste des
systèmes d'information. Ce positionnement stratégique soutenu par
l'innovation technologique a conduit la société à annoncer en décembre
2011, la création de son centre de recherche et développement dans le
but d'aider Viseo à accélérer le rythme de développement de son activité
d'édition de logiciels innovants et sectoriels ainsi que de positionner
le groupe sur les axes stratégiques porteurs d'avenir. La R&D réalisée
au sein de Viseo, s'articule autour des 3 thématiques de recherche
suivantes : l'analyse de données, le génie logiciel, les interfaces et
les usages.  De façon concrète, le pôle Recherche et Innovation recense
un pool d'ingénieurs-experts et de 6 chercheurs dédiés aux activités de
R&D, et participe actuellement, conjointement à 1 projet de recherche
européen TIER (autour de la prévention des risques chimiques) et 3
projets nationaux ITM Factory (FUI14 autour de la refonte des systèmes
d'information), MALTHY (ANR autour de la vérification de logiciels
embarqués) et SYNODOS (ANR Tecsan autour de l'analyse automatique de
dossiers patients à des fins épidémiologiques).

Dans le cadre du projet SYNODOS (http://www.synodos.fr) Viseo propose un
stage conventionné niveau M2, basé à Grenoble.

Au sein de l'équipe R&D, le candidat participera aux tâches suivantes:

- développement d'un métalangage d'interrogation d'une base de
  connaissance au-dessus de SPARQL

- écriture, en collaboration avec les médecins, de règles de transition
  (entre règles experts et règles linguistiques)

- modélisation des connaissances médicales à partir de l'analyse
  linguistique (en utilisant OWL)

Compétences requises :

- Traitement Automatique des Langues (syntaxe, rôles thématiques)

- Web sémantique ( RDF,  OWL, Protégé, SPARQL)

- Bonnes capacités de modélisation des connaissances

- Facilité à travailler en équipe

Contact:

Frédérique Segond
fsegond@viseo.net

Dr Frédérique SEGOND
Le Pulsar 4 av du Doyen Louis Weil 38000 GRENOBLE
Tél.  +33 (0)9 72 31 82 50
Mob. +33 (0)6 89 44 60 88
fsegond@viseo.net
Responsable Recherche et Développement
Research & Development Manager
http://www.viseo.net/en/viseo-research-and-development
http://www.viseo.net/en/members-center-research-and-development"
"203","2014-01-16","Telecom ParisTech","Paris","*Modèle de dialogue multimodal pour recruteur virtuel*

Catherine Pelachaud, Magalie Ochs

*Résumé *

Le sujet de stage s'insère dans le projet européen Tardis « Training
young Adult's Regulation of emotions and Development of social
Interaction Skills » (tardis.project.eu).Le but du projet est de
construire une plate-forme basée sur des scénarios de simulation de jeux
sérieux pour les jeunes de 18-25 ans à risque d'exclusion. Le jeu leur
permettra d'explorer, pratiquer et d'améliorer leurs compétences
sociales. Dans le jeu, l'interaction avec les jeunes se fait par le
biais agents virtuels (AV) agissant à titre de recruteurs dans des
scénarios d'entretiens d'embauche. Les AV sont conçus pour maintenir des
interactions socio-émotionnelles crédibles avec leurs interlocuteurs. En
manipulant les paramètres de l'agent, il est possible de simuler
différents styles de recruteur. Une telle plateforme permet aux jeunes
personnes de s'exercer à passer des entretiens tout en faisant attention
à leur attitude sociale. Le but principal de la plateforme Tardis est de
permettre à des jeunes en difficulté de prendre conscience de
l'importance des comportements socio-émotionnels.

*Objectifs*

L'agent, recruteur virtuel, peut rendre l'entretien d'embauche avec un
jeune stagiaire plus ou moins difficile. L'agent peut le mettre à
l'aise, le provoquer, ou tout simplement lui demander des informations,
etc. En posant telle ou telle question, ou bien en choisissant tel ou
tel comportement, l'agent peut montrer diverses attitudes sociales au
jeune. Suivant la réaction du jeune au cours de l'entretien, en
particulier suivant son niveau d'anxiété, l'agent peut se montrer
réconfortant et rendre l'interview plus facile ; ou bien déstabilisant
et rendre l'interview plus difficile.Le type de question et la manière
de les poser (au niveau sémantique et comportementale) traduisent
l'attitude de l'agent recruteur.

L'objectif du stage est de développer un modèle de dialogue multimodal
pour un agent virtuel jouant le rôle d'un recruteur. Le recruteur peut
avoir plusieurs attitudes sociales face au jeune. Le modèle de dialogue
s'appuiera sur un premier modèle existant qu'il complètera suivant :

- Difficulté de l'entretien

- Attitude sociale de l'agent

- Représentation des connaissances (CV du stagiaire et description de la
  société pour le recrutement)

- Détection des mots clés

- Perception de l'attitude sociale du jeune stagiaire

Le modèle computationnel vise donc à définir quelle question posée et
comment la communiquer au jeune stagiaire. Il se basera sur des outils
existants :

- DISCO for games D4G, modèle de dialogue (Rich & Sidner, 12)

- Greta, plateforme d'agent virtuel (Ochs et al, 13) qui inclue aussi un
  module de détection de mots clés et un module de détection des
  expressions émotionnelles du visage

*Encadrant* : Catherine Pelachaud,
catherine.pelachaud@telecom-paristech.fr ; Magalie Ochs

*Lieu du stage* : Telecom-ParisTech

*Financement* : 6 mois de Master, 6* 1/3 du SMIC"
"204","2014-01-17","Xerox Research Centre Europe","Grenoble","Internship in NLP at Xerox Research Centre Europe, Grenoble, France


Title:  Discourse Structure Prediction of Email Replies

Description :

The goal of the internship is to learn and predict the structure of an
email reply. The internship will explore techniques for learning the
discourse structure of email replies from an existing set of email
conversations. It will also involve predicting the discourse structure
given a new conversation and guiding the reply composer appropriately
through a visually attractive interface.


The ideal candidate is a Computer Science student (preferably doing
Ph.D.) with background in Natural Language Processing and Machine
Learning. Knowledge of Java or Python is a must, and experience of web
technologies (javascript etc) is highly desirable.

Contacts : Sriram Venkatapathy  , Marc Dymetman

More information of the position and centre at :

http://www.xrce.xerox.com/About-XRCE/Internships/Discourse-Structure-Prediction-of-Email-Replies"
"205","2014-01-20","EDF R&D","Clamart","STAGE INGÉNIERIE LINGUISTIQUE
SUJET 2014: ÉVALUATION D'OUTILS TEXT MINING
DURÉE : 6 MOIS ENVIRON

1.  CONTEXTE

Le volume des données numériques textuelles, disponibles sur l'Internet
(forums, twitters etc.) ou relatives à des contacts client (enquêtes,
centre d'appel etc.), augmente chaque année. L'analyse de ces
informations, structurées ou non, est, aujourd'hui, un impératif
stratégique pour une entreprise telle qu'EDF. Dans ce cadre, et dans
l'objectif de toujours mieux connaître les besoins des clients,
l'exploitation de ces documents implique l'utilisation de méthodes et
d'outils adaptés. Au coeur de ces problématiques les outils de Text
Mining sont de plus en plus nombreux et performants, ainsi nous
souhaitons étudier les principaux outils évoluant sur le marché
aujourd'hui.

2.  SUJET DU STAGE

Depuis 2003, les données textuelles sont essentiellement traitées à la
R&D via des solutions développées par l'éditeur TEMIS (Text-Mining
Solution).  Ce choix fait suite à différentes campagnes de veille sur
les outils de Text Mining.  Un protocole de test d'outils de Text Mining
avait été défini et appliqué à l'étude approfondie de différents
logiciels.

Dans le cadre du suivi des évolutions des outils de Text Mining, nous
souhaitons effectuer une nouvelle évaluation des outils d'analyse de
données contenant du texte.

Ce stage se décomposera en 3 parties :

- Veille d'outils de Text Mining : Il s'agira de mener une étude de
  marché des outils existants aujourd'hui.

- Evaluation : A partir des solutions émergentes du marché, il s'agira
  d'évaluer une sélection d'outils (entre 3 et 4) jugés à priori
  intéressants par rapport aux besoins d'EDF.

- Perspectives : Dans un second temps, il s'agira d'identifier les
  perspectives envisageables quant à l'alliance du Text Mining et du Web
  sémantique au regard des besoins EDF.

INFORMATIONS PRATIQUES

Interlocuteurs:
Delphine Lagarde        01.47.65.39.75  delphine.lagarde@edf.fr
Anne Peradotto  01.47.65.44.89  anne.peradotto@edf.fr

Lieu du stage: 
EDF R&D - Département ICAME
1, avenue du Général de Gaulle
92141 Clamart Cedex 

Date & Durée : Début 2014 - 6 mois environ

Rémunération: A définir (environ 1.000¤/mois)"
"206","2014-01-20","LIMSI","Orsay","Stage M2 : Analyse temporelle des dossiers électronique patient.
[Analysis of temporal relations in Electronic Health Records]

Mots-clés : traitement automatique de la langue, classification, analyse
temporelle, domaine biomédical
Durée : 5 mois
Niveau : Master 2 Recherche
Lieu : LIMSI-CNRS, Orsay

Le contenu et l'ambition du stage pourront être modulés en fonction du
niveau d'étude et de la durée du stage du candidat.

Résumé :

L'objectif de ce stage M2R est d'analyser les dossiers électroniques
patient du point de vue chronologique. À partir d'un ensemble de
documents contenus dans le dossier d'un patient, ce travail permettra de
repérer les événements saillants de l'historique médical du patient
ainsi que les marqueurs temporels associés afin de les agréger dans une
chronologie synthétique.

Contexte :

L'analyse temporelle de textes d'information a pour but général de mieux
localiser dans le temps les événements décrits dans ces textes, et donc
d'alimenter de façon plus précise des moteurs de recherche ou des outils
d'extraction d'information. Pour cela, la première étape est de détecter
correctement les expressions temporelles de ces textes. Ces expressions
temporelles peuvent être des dates absolues, c'est-à-dire que l'on peut
placer sans ambiguïté sur l'axe des temps (par exemple, ""le 14 janvier
2008""), mais aussi des dates relatives, qui nécessitent une phase de
résolution ou de normalisation (par exemple, ""le 14 janvier dernier"",
""dans 6 semaines""). Dans le cadre du dossier électronique patient, des
expressions temporelles propres au domaine de spécialité, le domaine
médical, peuvent également être rencontrées (par exemple, ""à 18 semaines
d'aménorrhée"", ""à j+1"").

Les techniques d'analyse temporelle des textes ont fortement progressé
ces dernières années, mais s'attachent en général au domaine
journalistique et particulièrement au cadre des dépêches. Nous
souhaitons étudier un autre domaine de spécialité, le domaine médical,
ainsi qu'un type de document particulier, le dossier électronique
patient. Nous nous intéressons à la caractérisation et au repérage
automatique des expressions temporelles dans les dossiers électroniques
patient afin de déterminer si un traitement spécifique au domaine
médical doit être mis en ½uvre ou si des outils développés pour un autre
domaine sont directement utilisables.

Travail à réaliser :

Selon le niveau d'étude de la personne choisie, nous pourrons nous 
intéresser à une ou plusieurs des problématiques suivantes :

- Utilisation et adaptation des outils d'analyse temporelle sur les
  documents cliniques

- Réconciliation des expressions temporelles issues de documents
  différents

- Création d'une ligne temporelle pour représenter l'historique d'un
  patient

On utilisera un corpus de plusieurs centaines de documents cliniques
de-identifiés en français.

Le stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue, en terminologie
biomédicale et/ou en apprentissage automatique seront un plus.

Rémunération : gratifications (436.05 ¤ par mois + participation aux
frais de transports)

Dépôts de candidature : envoyez un CV accompagné d'une lettre de 
motivation et de relevés de notes récents à :
Aurelie.Neveol[at]limsi.fr
Xavier.Tannier[at]limsi.fr"
"207","2014-01-22","LIMSI","Orsay","Le groupe ILES du LIMSI-CNRS (Orsay) propose des stages pour différents
niveaux d'études dans les thématiques suivantes:

- Traitement des Langues Signées
- Recherche et Extraction d'Information, Question-Réponse
- Constitution de Ressources pour le TAL
- Evaluation pour le TAL
- Paraphrase et Traduction Automatique

La description des différentes propositions se trouve sur la page
suivante:

http://www.limsi.fr/Scientifique/iles/propositions

Les candidats devront contacter directement les responsables du/des
stages, en joignant un descriptif de leur parcours sous forme d'un court
CV, des relevés de notes récents, et en précisant leur motivation pour
les stages concernés.

Page du groupe: http://www.limsi.fr/Scientifique/iles
Page du laboratoire: http://www.limsi.fr"
"208","2014-01-22","STL","Lille","ÉVOLUTION ET VISUALISATION DES ÉMOTIONS

contact : Natalia Grabar (natalia.grabar@univ-lille3.fr)


Les forums issus du domaine médical permettent à des internautes
d'échanger à propos de leur santé. Intermédiaires entre discours oral et
écrit, les forums de discussion sont des espaces d'échanges asynchrones
de messages textuels. Ce nouveau mode de communication est très prisé
des patients car associé à une grande liberté du discours due notamment
à l'anonymat. Dans ce contexte éminemment subjectif, la caractérisation
et la compréhension des perceptions que les patients ont de leur maladie
et du suivi médical est difficile, mais néanmoins particulièrement
intéressante pour les professionnels de santé. De nombreux verrous sont
associés à l'analyse semi-automatique de ces forums, en particulier la
volumétrie des textes et leur hétérogénéité.

Dans le cadre du projet ANR TecSan Ravel et du projet MSHM Parlons de
nous, nous proposons un stage de Master 2. Ce stage fait suite aux
travaux déjà réalisés dans l'équipe sur la détection et l'annotation de
la subjectivité (incertitude, émotions...) dans les documents
biomédicaux (Grabar & Hamon, 2009, Périnet et al, 2011,
Chauveau-Thoumelin & Grabar, 2014).

Plus particulièrement, le stage aura pour objectif de :

- travailler avec les documents provenant de différents genres médicaux
  (cliniques, scientifiques, forum, etc.)

- exploiter et améliorer les annotations des documents avec différents
  niveaux de spécificité

- proposer une visualisation de l'évolution des émotions et une
  représentation adéquate des données

L'ensemble du travail sera effectué en collaboration avec les chercheurs
en traitement automatique de langues (TAL), en linguistique (syntaxe et
sémantique) et en informatique.

Le stagiaire sera amené à utiliser des outils existants et à développer
ses propres programmes pour mieux analyser et visualiser les données.

Prérequis:

- connaissances en TAL, informatique et linguistique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et synthèse de la littérature scientifique

Lieu du stage : Lille, Paris ou Montpellier

Le stage est rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée."
"209","2014-01-22","STL","Lille ou Paris","EXTRACTION D'INFORMATIONS LIÉES AUX CONTROVERSES

contact : Natalia Grabar (natalia.grabar@univ-lille3.fr)


Les méthodes du Traitement Automatique des Langues permettent
d'effectuer plusieurs tâches très coûteuses pour un utilisateur humain,
comme par exemple l'extraction d'information, les questions/réponses,
l'inférence textuelles et la fouille de textes de manière
générale. Cette proposition de stage Master 2 concerne la détection
automatique du risque chimique, qui crée souvent des situations de
controverse.

Le risque chimique couvre les situations où les produits chimiques sont
ou peuvent être dangereux pour la santé humaine, animale et pour
l'environnement. Une des controverses actuelles concerne le risque
chimique lié au bisphénol A et aux phtalates, qui affectent le système
hormonal des individus. Dans les situations de controverse, la détection
d'informations objectives (risque chimique) peut être brouillée par des
informations subjectives propres aux controverses (incertitudes,
opinions, etc.). L'objectif du stage est d'améliorer un système
d'extraction d'information sur le risque chimique existant.

Plus particulièrement, les tâches visées sont les suivantes :

- travailler avec les documents produits dans le domaine de chimie
  (chercheurs, institutions...)

- améliorer les ressources linguistiques existantes

- exploiter et améliorer les annotations des documents avec différents
  niveaux de spécificité

- ajuster les modèles d'apprentissage automatique

L'ensemble du travail sera effectué en collaboration avec les chercheurs
en traitement automatique de langues (TAL), en risque chimique et en
informatique.

Le stagiaire sera amené à utiliser des outils existants et à développer
ses propres programmes pour mieux analyser et visualiser les données.

Prérequis:

- connaissances en TAL, informatique et linguistique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et synthèse de la littérature scientifique

Lieu du stage : Lille ou Paris

Le stage est rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée."
"210","2014-01-31","Xerox Research Centre Europe","Grenoble","An open internship position on a mix of string algorithms, grammatical
inference and statistical machine learning


Description

We are looking for a motivated intern for a project involving the use
of sequential patterns for the inference of grammars.

The Smallest Grammar Problem is the problem of finding the smallest
context-free grammars that generates exactly one given sequence. We
plan to generalize this in order to find grammars which generate a set
of natural language documents with a strong but hidden structure. This
structure will then be converted into additional features (through
tree kernels for example) in our analytics pipeline or alternatively
as a starting template for existing multilingual authoring tools.

Requirements:

    Research-oriented master student or PhD candidate in computer
    science

    Knowledge of standard text algorithms and data structures

    Knowledge of formal grammars (a course covering the Hopcroft &
    Ullman book or equivalent for example)

    Knowledge in statistical machine learning applied to text is a
    strong plus

    Fluency in either C, C++ or Java is a plus

The intern will work closely with researchers in a very international
environment, and will be strongly encouraged to produce scientific
publications.

Duration: 5-6 months
Start Date: March-April 2014

Application instructions

Informal inquiries are welcome and can be made at
matthias.galle@xrce.xerox.com .

To submit an application, please send your CV and cover letter to both
xrce-candidates@xrce.xerox.com and matthias.galle@xrce.xerox.com .

Ideally, you will also include in your CV people we can contact for
letters of recommendation.


link: http://www.xrce.xerox.com/About-XRCE/Internships/Grammatical-Inference-with-sequential-motifs"
"211","2014-01-31","Lattice","Montrouge","Proposition de stage de Master 2e année :

Création de la maquette numérique d'une série de documents traitant
d'archéologie

Descriptif :

Le stage s'inscrit dans le domaine des humanités numériques, dans le
cadre d'un projet EITAB, PEPS PSL-CNRS, mettant en oeuvre une
collaboration entre le laboratoire Lattice (UMR8094, analyse
linguistique et traitement automatique des langues,
http://www.lattice.cnrs.fr/) et le laboratoire AOROC (UMR 8546,
archéologie, http://www.archeo.ens.fr/). Les deux laboratoires font
partie de l'Ecole normale supérieure et collaborent au sein du
laboratoire d'excellence TransferS (http://www.transfers.ens.fr/).

Le stage vise à créer, à partir d'un document textuel traitant
d'archéologie, la maquette d'un ebook. Il s'agit de mettre en place un
accès pertinent et convivial à un texte de spécialité à partir de
données extraites du texte (termes structurés en index, etc.). On
s'intéressera donc particulièrement aux outils de structuration (base
de données, mise en place de liens entre termes, etc.) et de mise en
forme (xml, html, css) des données. Une collaboration étroite avec les
interlocuteurs côté archéologie est indispensable. Le LATTICE dispose
d'un extracteur de termes et les outils classiques de structuration de
données et de création d'ontologies pourront être utilisés.

Le stage porte essentiellement sur l'interaction entre texte et
index. En fonction des compétences du candidat retenu, on pourra aussi
s'intéresser à l'interaction entre texte et cartes géographiques (pour
permettre de visualiser les principaux sites archéologiques, créer des
liens entre objets d'étude et zones géographiques, et pouvoir répondre
à des questions comme : « sur quels sites de la région tourangelle ont
été trouvées des tuiles à rebord ? »). On pourra aussi, si le temps le
permet, s'intéresser à l'adaptation du rendu final en fonction du
support (ordinateur, tablette, etc.).

Le stage a une finalité avant tout pratique : il s'agit de mettre en
place une maquette opérationnelle montrant un exemple concret de
réalisation possible. L'archéologie se prête particulièrement bien à
l'enrichissement multimédia du texte numérique.


Mission du stage

Créer la maquette numérique d'une série de documents traitant
d'archéologie.

- veiller à la cohérence des données (corriger et enrichir les index
  existants)
- structurer le document texte
- créer index et requêtes dynamiques.
- compléter des bases existantes qui génèrent des cartes en
  automatique
- intégrer les cartes aux requêtes et index.


Compétences requises

- connaissance d'outils d'édition électronique
- connaissance des langages de structuration de document (xml, html,
  css, etc)
- intérêt pour la mise en place de solutions applicatives, prise en
  compte des besoins utilisateurs
- connaissance des bases de données
- qualité de rédaction en français et en anglais
- un intérêt pour l'archéologie serait un plus

Informations complémentaires sur EITAB :
http://www.archeo.ens.fr/spip.php?article586

Conditions

Le stage se déroulera au laboratoire Lattice (à Montrouge,
http://www.lattice.cnrs.fr/) pendant 6 mois, à partir d'avril 2014 en
étroite collaboration avec le laboratoire AOROC (à l'ENS, 45 rue d'Ulm
à Paris). Ce stage est indemnisé suivant les règles en vigueur grâce à
un projet PEPS de site co-financé par le CNRS et PSL.

Lieu

Laboratoire LATTICE à Montrouge.

Encadrants

Frédérique Mélanie Becquet et Thierry Poibeau pour le LATTICE et
Katherine Gruel pour AOROC.

Comment postuler ?

Envoyer un CV et une lettre de motivation à Thierry Poibeau et
Frédérique Mélanie <prenom suivi du nom séparé par un point arobase
ens.fr> dès que possible et, dans tous les cas, avant le 15 février
2014."
"212","2014-02-03","SNCF","Paris","Intitulé : Extraction d'informations sur les pratiques de mobilité

La Direction Innovation et Recherche de la SNCF recherche un stagiaire
pour travailler sur un projet d'étude de la mobilité des voyageurs à
travers l'analyse de données textuelles.

*Activités du stage*

------------------------------

Réalisation d'une plateforme d'étiquetage sémantique de données
textuelles pour l'analyse des pratiques de mobilité.

*Thème*
------------------------------

La société connaît depuis quelques années des changements majeurs dans
les pratiques de mobilité, du fait d'autres formes d'organisation du
travail, de l'émergence de nouveaux modes de transport,... Les voyageurs
s'expriment sur le web social à propos leurs déplacements, aussi bien en
situation normale qu'en situation perturbée. Les messages contiennent
des informations sur les activités des voyageurs, leurs particularités
sociologiques ou encore leurs motivations.

Une analyse sémantique en fonction de tels critères est susceptible
d'apporter une meilleure connaissance des comportements, des besoins et
des attentes. Elle permet une compréhension nuancée et différenciée de
la mobilité.

Le stage aura pour objectif de contribuer à la mise en place d'une
plateforme d'analyse de données pour l'extraction d'informations sur les
pratiques de mobilité.

*Description *
------------------------------

Le stagiaire devra :

- prendre connaissance du contexte du stage (SNCF, Direction Innovation
  & Recherche, objectifs du stage et cadre de réalisation, situation
  actuelle et interlocuteurs sur les sujets concernés, ...)

- faire un état de l'art des outils disponibles sur le marché en
  analysant leurs possibilités, leurs avantages et leurs inconvénients.

- mettre en place une interface de gestion de la base de données
  (collecte, structuration et interface).

- Définir et implémenter des méthodes pour l'étiquetage sémantique des
  données, en fonction d'une typologie qui lui sera préalablement
  spécifiée

- Exploiter les résultats d'annotations et proposer des pistes
  d'amélioration

Présentations et rapports :

- présentation de début de stage à la SNCF (au bout d'un mois de stage) :
  contexte de stage, planning de réalisation et premiers travaux
  réalisés.

- rapport final de stage complet comprenant : méthodologie retenue,
  travaux réalisés, résultats obtenus et problèmes rencontrés...

2 soutenances de fin de stage : une à l'école et une à la SNCF.
Des présentations en interne SNCF ou externes pourront être effectuées.

*Profil recherché*
------------------------------

Niveau : De formation Bac+5 en Traitement Automatique du Langage Naturel
ou Informatique (ingénieur ou master 2).

Compétences souhaitées :

- Capacités d'analyse, de rédaction et de synthèse

- Autonomie, qualités relationnelles, qualité de présentation
  (orale/écrite).

- Manipulation et test des outils de TAL

- Connaissances en TAL et linguistique

- Bonnes compétences en informatique (programmation, gestion de bases de
  données)

- Des connaissances en statistiques seront appréciées.

 

Bonus :

   - Maîtrise d'au moins un langage de programmation (PHP de préférence)
   - Maitrise des expressions régulières et du SQL

*Modalités du poste*
------------------------------

   - Durée : 4 mois
   - Rémunération prévue: indemnités de stage + carte de circulation SNCF
   - Début : à partir de Juin 2014
   - Lieu : Paris

Merci d'adresser CV et lettre de motivation à Coralie Reutenauer à
l'adresse mail suivante : coralie.reutenauer@sncf.fr"
"213","2014-02-04","CFH & CLLE-ERSS","Toulouse","Stage de Master / Ecole d'ingénieur : paramétrage et évaluation d'un
système de classification automatique de rapports de sécurité.

L'entreprise : 

CFH (Conseil en facteurs humains)/SafetyDATA est une PME spécialisée
dans le traitement automatique des langues dans le domaine de la
sécurité. Elle travaille en collaboration avec CLLE-ERSS, un
laboratoire de linguistique, et plus particulièrement avec l'équipe
TAL (Traitement automatique des langues). Le stage sera co-encadré par
CFH et le laboratoire CLLE.

Contexte : 

CFH a conçu un système de traitement automatique des
langues (TAL) dont le but est d'analyser des rapports d'incidents
afin de proposer une ou plusieurs catégorie(s) pour leur
indexation dans une base de données. Le système est actuellement
déployé et analyse chaque mois plusieurs centaines de documents (en
français et en anglais) à l'aide de règles apprises automatiquement et
basées sur le repérage de certains termes dans les rapports
analysés. Voir plus de détails sur http://www.safety-data-analysis.com/

Le stage vise l'évolution de ce système de classification, notamment
en envisageant l'utilisation d'un système d'apprentissage supervisé
statistique. L'objectif de ce stage est double :

1/ Identifier et quantifier le gain apporté par l'utilisation d'un
modèle statistique (SVM, régression logistique, réseau bayésien,
etc.) par rapport au système actuel ;

2/ Mesurer l'impact sur les performances du système des différents
traitements linguistiques appliqués aux documents avant leur analyse
(correction des erreurs, normalisation des formes de surface,
identification d'expressions complexes, utilisation de classes
sémantiques, etc.).

Profil recherché :

Etudiant en deuxième année de master ou dernière année d'école
d'ingénieur, en informatique ou traitement automatique des langues.

Compétences requises :

Systèmes de classification automatique par apprentissage
artificiel. L'étudiant doit connaître le fonctionnement de ces
systèmes et être autonome quant à leur utilisation et évaluation (scripts, 
gestion de données volumineuses, etc.)
On attend également de l'étudiant une capacité à observer les données et à 
s'intégrer dans un environnement interdisciplinaire.

Détails :

- stage conventionné basé à Toulouse
- durée : 4 à 6 mois à partir de mars 

Contact :

Céline Raynal raynal@conseil-fh.fr
Ludovic Tanguy tanguy@univ-tlse2.fr"
"214","2014-02-06","IRIT","Toulouse","Titre : Analyse des citations et des énumérations dans les fora de santé. 
 
Lieu : Laboratoire IRIT (Institut de Recherche en Informatique de
Toulouse), Université Paul Sabatier, Equipe ELIPSE (Etude de
L'Interaction Personne SystèmE).
 
Contexte et problématique 

Ce sujet du stage se situe dans le cadre d'un projet national «
Parlons de nous »
(http://www.msh-m.fr/programmes/programmes-2013/parlons-de-nous)
où l'on étudie des fora de santé pour tenter de répondre à la question
« à quoi pensent les patients ? » et du projet interMSH qui lui fait
suite.  Les forums de santé sont des lieux où les patients échangent
de nombreux points de vues, conseils, où ils s'interrogent et
discutent, et ce dans un contexte bien différent des têtes à têtes
menées avec les professionnels de santé, qui ont lieu dans une durée
et un lieu contraint. Le relatif anonymat des échanges, l'implication
récurrente de certains dans les forums, les questions débattues
peuvent être révélatrices de points de vue, de connaissances ou
méconnaissances d'informations médicales, d'alertes, en provenance du
grand public. Dans ce contexte éminemment subjectif, la
caractérisation et la compréhension des perceptions dans les fils de
discussions des forums est difficile, mais aussi particulièrement
intéressante et instructive dans une perspective d'amélioration des
programmes de santé publique.
 
Objectif du projet 

Un des objectifs du projet est de développer une plateforme pour aider
des chercheurs (linguistes, sociologues et psychologues) et des
médecins à observer certains comportements dans les fils de
discussions dans des fora de santé. Dans le cadre d'un travail de
thèse en informatique lancé cette année sur le sujet du contexte et
des informations médicales, nous avons initié cette plateforme.  La
plateforme vise à proposer une interface qui permet de représenter et
visualiser schématiquement les fils discussions (ou extraits de ces
fils de discussions) de forums au travers de traits et critères que
les chercheurs vont choisir. On espère ainsi pouvoir associer à
certains schémas de discussions une qualité informationnelle du fil
étudié (exemple : une discussion qui diverge du thème initial et se
recentre entre 2 personnes habituées devient peut être un aparté hors
sujet). Les critères actuellement pris en compte sont de nature
contextuelle (les profils des utilisateurs (âge, sexe), le temps,
nombres d'interventions, la longueur des échanges, les
micro-échanges...). Nous souhaitons travailler sur l'exploration
d'autres critères qui prendront en considération des traitements
linguistiques des discussions afin de disposer d'un jeu de vues sur
les discussions. Nous souhaitons évaluer si ces informations
permettent de répondre à notre hypothèse de caractérisation des fils
de discussion.
 
Objectif du stage 

Ce stage vise deux objectifs :
1. Explorer des pistes linguistiques pressenties comme 

- étudier l'utilisation des citations : en effet les internautes se
citent et se répondent beaucoup au fil des discussions et visualiser
ces interconnections dans le fil de discussions nous permettraient
peut être d'en avoir une compréhension élargie ;

- connaitre les énumérations dans les fils de discussions (quels
indices discursifs et de mise en forme matérielle peut-on repérer et
qu'en déduire ?)

- analyser en utilisant les terminologies médicales existantes, les
proximités sémantiques entre les différents post de discussion dans un
fil.

2. élaborer des stratégies pour coupler les indices de l'architecture
de texte et ceux liés au contexte (profil de l'usager, thématique
abordée, statut du message dans la discussion, etc.). Ce travail se
fera en collaboration avec le doctorant.
 
Nous souhaitons en effet dans cette plateforme, en manipulant des
jauges constituées par ces critères, observer et pouvoir caractériser
comment se construisent les réponses ? Est-ce que les réponses sont
fournies par des habitués ou des béotiens ? Peut-on écarter
certaines discussions (vulgarité, éparpillement...), ou au contraire
anticiper sur des contenus plutôt informatifs voire cruciaux ? Quels
rebondissements ? Quels recentrages ?... Nous nous focaliserons sur un
sous-­-ensemble de ces besoins.  La plate-forme « configurable »
envisagée doit permettre aux chercheurs / médecins de pouvoir observer
des comportements et des « histoires de discussion » stéréotypés.

Perspectives 

Deux thèses possibles dans la continuité de ce sujet de master (1. sur
l'étude des énumérations dans les manuels scolaires d'histoire
géographie 2. sur l'amélioration de l'accessibilité textuelle pour des
personnes non-voyantes).

Modalités du stage

Encadrants : 
 Lydia-Mai Ho-Dac, CLLE-ERSS, Université Toulouse le Mirail 
 Nathalie Souf, IRIT-ELIPSE, Université Paul Sabatier et ISIS Castres 
 Mustapha Mojahid, IRIT-ELIPSE, Université Paul Sabatier 
Durée : 5-6 mois. 
Rémunération : celle prévue par la règlementation à savoir 436,05 ¤ par mois. 
Début : à partir de Mars-Avril 2014. 
 
Profil du candidat 

Le candidat devra être inscrit dans un Master 2 en traitement
automatique des langues.

Compétences demandées 

- compétences en traitement automatique des langues et/ou en
linguistique de corpus.

- compétences de base en informatique et idéalement maîtrise d'outils
pour l'analyse de corpus et/ou de langages de programmation de type
perl et python.

Comment candidater ? 

Envoyer un CV (avec le détail des cours et notes des deux années de
Master) et une lettre de motivation à : Mustapha.Mojahid@irit.fr"
"215","2014-02-10","TrooClick","Paris","Trooclick France is a company that specializes in the development of web
applications for the automatic processing of information. Our goal is to
create services that rebuild the user's trust in digital content. Up to
now, Web players were able to enhance the relevance of this content; we
go a step further and contribute to improve its reliability.

Trooclick was created in November 2012. Just a few months later, in
April 2013, it received financial support from the BPI (French public
investment bank) and in June 2013 the French government granted it the
Status of ""Young Innovative Company"" (JEI), recognizing its innovative
nature. It now counts twelve committed and passionate members in its
tight-knit team.

The company carries out R&D projects in search of technical solutions in
the Artificial Intelligence field. Due to its growth, Trooclick is now
looking for candidates for a 6 month internship for its office in Paris
(17ème).


Missions:

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

You will turn ideas into well-documented and reliable linguistic
resources (both dictionaries and extraction rules) to ensure efficiency,
quality, performance and scalability.

A great team player, you will interact with other departments to
understand and fine tune specifications.
You will carry out unitary testing, create and maintain our test
validation corpus and participate in editing technical documents. All
developments will be done in English.

Qualifications:

   - BSc/MSc
   - Experience with NLP tools such as Gate, Treetagger, NooJ, Stanford
     for linguistic annotation, named entity recognition, relationship
     and fact extraction, sentiment analysis, etc.
   - Experience in scripting languages such as Perl or Python as well as
     XML format to be autonomous in completing some technical tasks.
   - Experience with basic database management operations (SQL language)
     Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will
     be a plus.
   - Excellent communication skills in English and French
   - We are open to new ideas that will significantly contribute to our
     success. Our friendly team will provide the opportunity for
     valuable collaboration.

   - We offer you career perspectives in a young and dynamic company
     with an interesting and diversified scope of duties at the cutting
     edge of research. We welcome applications from highly motivated
     individuals able to learn new techniques and share knowledge and
     experience with the team.


Interested? Then send your application to jobs@trooclick.com!"
"216","2014-02-10","LIPN","Villetaneuse","(English version below)

Proposition de stage de master recherche

Annotation sémantique dynamique

Mots clefs : Traitement Automatique des Langues, annotation sémantique,
gestion de contenus, ingénierie des connaissances, web sémantique

Encadrants : Adeline Nazarenko et François Lévy (LIPN, Université Paris
13 - Sorbonne Paris Cité & CNRS)

Durée : 4 à 6 mois (printemps-été 2014)

Indemnités : 430¤ /mois (Labex EFL)

Problématique

L'annotation sémantique des documents joue aujourd'hui un rôle clef pour
beaucoup d'applications de gestion de contenus textuels (navigation
textuelle, recherche d'information sémantique, restructuration de
documents, etc.). L'annotation sémantique consiste à apposer sur un
texte des informations, ou métadonnées, dont la sémantique est portée
par un modèle sémantique formel (langage d'indexation, thesaurus,
ontologie, par exemple) [13, 6, 14]. On associe ainsi au texte une
représentation sémantique formelle et les moteurs de recherche ou agents
logiciels peuvent exploiter à la fois le contenu textuel (recherche en
plain texte, calculs distributionnels) et la sémantique formelle qui lui
est associée.

Les outils d'annotation de la première génération sont assez frustres,
se contentant souvent de lier les mentions des entités nommées
identifiées dans les textes à des instances existantes ou à de nouvelles
instances de concepts dans une ontologie [10, 4].

Le développement des applications spécialisées de gestion de contenus et
l'essor du web de données amènent aujourd'hui à revoir les méthodes
d'annotation sémantique : on a besoin de méthodes et d'outils qui
offrent une expressivité d'annotation plus riche (par ex. annoter des
instances de concepts mais aussi des concepts et des relations) tout en
étant robustes, génériques et adaptables à différents domaines et
contextes d'utilisation.

Objectif du stage

Le stage permettra de proposer une méthode d'annotation sémantique qui
intègre des mesures de qualité de l'annotation et qui permette de
réviser l'annotation dynamiquement. On supposera que le modèle
sémantique utilisé est de type ontologique.

Si l'on considère qu'un système d'annotation S=<O,T,A> est composé d'une
ontologie O, d'un texte T et d'un ensemble d'annotations ou de liens A
associant à des segments de T des entités de O, il faut réviser le
système S si l'un de ses composants est mis à jour (le texte est
modifié, l'ontologie est enrichie ou restructurée) ou lorsque des
incohérences ou défauts de couverture sont détectés.

Le stage consistera à étudier les différents cas de figures dans
lesquels un tel système d'annotation doit être révisé et à proposer une
méthode d'annotation dynamique intégrant des processus de révision. La
méthode d'annotation dynamique doit 1) intégrer des critères de
cohérence et des mesures de couverture pour identifier quand la révision
d'un système d'annotation est nécessaire, 2) proposer des procédures de
révision adaptées aux différents cas de figure et 3) contrôler la
convergence du processus global de révision.

En commençant par les types d'annotation les plus simples (par ex. un
texte annoté avec les instances et les concepts d'une ontologie), le
stagiaire devra proposer une méthode d'annotation dynamique. Il pourra
s'appuyer sur les outils d'annotation sémantique existants de l'équipe
RCLN, sur l'expertise des membres de l'équipe et sur des cas d'usage
réels pour évaluer l'apport de cette dynamique de l'annotation.

Il est souhaitable que la méthode proposée soit directement intégrée à
un outil d'annotation existant mais elle pourra aussi être testée en
simulation si l'intégration s'avère trop coûteuse.

Description du travail

Le stage comportera  différentes parties :

1) état de l'art sur l'annotation sémantique et veille sur les outils
   existants (outils de l'équipe RCLN ou autres) ;

2) description, modélisation et implémentation du processus d'annotation
   dynamique (pour les types d'annotations les plus simples ; en
   s'appuyant sur les outils existants et/ou sur des technologies
   sémantiques) ;

3) analyse, test et évaluation de l'approche proposée sur des cas
   d'usage réels simplifiés fournis par l'équipe RCLN.

En outre et en prévision d'une poursuite en thèse, le stagiaire pourra
chercher à spécifier une méthode d'annotation sémantique plus riche
prenant en compte une palette étendue de types d'annotations.

Contexte et informations pratiques

Le stage sera encadré par Adeline Nazarenko et François Lévy.

Le/la stagiaire sera intégré(e) à l'équipe RCLN et bénéficiera de
l'expertise de celle-ci en matière de traitement automatique des
langues, d'ingénierie des connaissances textuelles et de web
sémantique. En particulier, l'équipe RCLN a une solide expérience en
matière d'annotation sémantique (annotation manuelle [2, 3] ou
automatique, par apprentissage [8], formalismes et ressources pour
l'annotation [9, 12]) et de construction d'ontologies à partir de textes
[1]. Elle a aussi l'expérience de l'intégration de ces méthodes
d'annotation et d'acquisition dans les outils d'analyse de contenus [7,
5, 11].

Le/la stagiaire travaillera au LIPN (Université Paris 13 - Sorbonne
Paris Cité & CNRS) où il/elle se verra attribuer un bureau. Il/elle aura
accès à l'ensemble des moyens techniques et des données nécessaires à
son travail.

Le stage est prévu pour une durée de 6 mois. Il devrait débuter au
printemps 2014.

Le stage sera financé dans le cadre d'une opération de recherche de
l'axe « Analyse sémantique computationnelle » du Labex « Fondements
empiriques de la linguistique ».

Les candidatures doivent être adressées à François Lévy (francois.levy à
lipn.univ-paris13.fr) avant le 7 mars 2014 : envoyer une lettre de
motivation, un CV, les relevés de notes de master.

Références

[1] N. Aussenac-Gilles, S. Després, and S. Szulman. « The TERMINAE
Method and Platform for Ontology Engineering from texts ». In Paul
Buitelaar and Philipp Cimiano, editors, Bridging the Gap between Text
and Knowledge - Selected Contributions to Ontology Learning and
Population from Text, pages 199-223. IOS Press, janvier 2008.

[2] K. Fort. Les ressources annotées, un enjeu pour l'analyse de contenu
: vers une méthodologie de l'annotation manuelle de corpus. Thèse
d'informatique, Université Paris 13 - Sorbonne Paris Cité, Villetaneuse,
France, 2012.

[3] K. Fort., A. Nazarenko, S. Rosset. « Modeling the Complexity of
Manual Annotation Tasks: a Grid of Analysis ». In Proceedings of the
24th International Conference on Computational Linguistics (COLING
2012), Mumbai, India, December 2012.

[4] C. Giuliano, A. Gliozzo. « Instance-based ontology population
exploiting named-entity substitution ». In Proceedings of the 22nd
International Conference on Computational Linguistics (Coling 2008),
pages 265-272, Manchester, August 2008.

[5] A. Guissé, F. Lévy, A. Nazarenko. Un moteur sémantique pour explorer
des textes réglementaires. In Actes des 22èmes journées francophones
d'Ingénierie des Connaissances, Chambéry, 2011.

[6] A. Kiryakov, B. Popov, I. Terziev, D. Manov, and D. Ognyanoff.  «
Semantic annotation, indexing, and retrieval ». Journal of Web
Semantics, 2(1):49-79, 2004.

[7] F. Lévy, A. Nazarenko, A. Guissé. « Annotation, indexation et
parcours de documents numériques ». Revue des Sciences et Technologies
de l'Information, 13(3/2010):121-152, 2010.

[8] Y. Ma, F. Lévy, A. Nazarenko. Annotation sémantique pour des
domaines spécialisés et des ontologies riches. In de la 20ème conférence
du Traitement Automatique du Langage Naturel (TALN 2013), pp 464-478,
17-21 Juin 2013, Les Sables d'Olonne.

[9] Y. Ma, A. Nazarenko, L. Audibert. « Formal description of resources
for ontology-based semantic annotation ». In Proceedings of the
International Conference on Language Resources and Evaluation (LREC
2010), Malta, May 2010. ELRA.

[10] B. Magnini, A. Pianta, O. Popescu, M. Speranza. « Ontology
population from textual mentions: Task definition and benchmark ». In
Proceedings of the OLP2 workshop on Ontology Population and Learning,
Sidney, Australia, 2006.

[11] A. Nazarenko, A. Guissé, F. Lévy, N. Omrane, S. Szulman. «
Integrating Written Policies in Business Rule Management Systems ». In
Rule-Based reasoning, Programming, and Applications, volume 6826 of
Lecture Notes in Computer Science, pages 99-113, Barcelona, Espagne,
2011.

[12] N. Omrane, A. Nazarenko, P. Rosina, S. Szulman, C. Westphal. «
Lexicalized ontology for a business rules management platform: An
automotive use case ». In Proceedings of the 5th International Symposium
on Rules, International Business Rules Forum (RuleMF@BRF), Ft
Lauderdale, Florida, USA, November 2011.

[13] B. Popov, A. Kiryakov, D. Ognyanoff, D. Manov, A. Kirilov. « Kim -
a semantic platform for information extraction and retrieval ». Natural
Language Engineering, 10(3-4):375-392, 2004.

[14] V. Uren, P. Cimiano, J. Iria, S. Handschuh, M. Vargas-Vera,
E. Motta, F. Ciravegna. « Semantic annotation for knowledge management:
Requirements and a survey of the state of the art ». Journal of Web
Semantics, 4, 2006.

-------------------------------------------------------

(French version above)

Proposal for a master internship 
Dynamic semantic annotation

Keywords: Natural Language Engineering, Semantic Annotation, Content
Management, Knowledge Engineering, Semantic Web

Supervision: Adeline Nazarenko and François Lévy (LIPN, Université Paris
13 - Sorbonne Paris Cité & CNRS)

Duration: 4-6 months (spring-summer 2014)

Indemnités: 430¤ /month (Labex EFL)

Problem

The semantic annotation of documents plays a key role for many
applications of textual content management (e.g. navigation, semantic
information retrieval, publication). Semantic Annotation consists in
enriching a text with metadata which semantics is given by a formal
semantic model (e.g. indexing language, thesaurus, ontology) [13, 6 ,
14]. A formal semantic representation is thus associated with the text
so that search engines or software agents can jointly exploit the
textual content (plain text search, distributional measures) and the
formal semantics associated with it.

The first generation annotation tools are quite simple. They often
merely bind references to named entities identified in the texts to
existing instances or new instances of concepts in an ontology [10 ,
4]. However, the development of specialized applications of content
management and linked data calls for renewed methods of semantic
annotation: we need methods and tools that provide a richer
expressiveness of annotation (e.g. annotation wrt. concepts and
relations and not only instances) while being robust, generic and
adaptable to different domains and use cases.

Goal

The goal of the internship is to design a semantic annotation method
incorporating annotation quality measures and enabling the dynamic
revision of annotations, assuming that the semantic model is
ontological.

If we consider that an annotation system S = <O,T,A> consists of an
ontology O, a text T and a set of annotations or links A associating
segments of with entities of O, one must revise the system S if one of
its components is updated (the text is modified, the ontology is
enriched or restructured ) or when inconsistencies or gaps in coverage
are detected.

The Master student will study the different scenarios requiring the
revision of such an annotation system and propose a method of dynamic
annotation integrating such a revision process. The dynamic annotation
method must 1) integrate consistency criteria and coverage metrics to
identify when the revision of an annotation system is necessary, 2)
propose revision procedures adapted to different use scenarios and 3)
control the convergence of the overall revision process.

Starting with the simplest types of annotation (e.g. a text annotated
with instances and concepts of an ontology), the student will provide a
method for dynamic annotation. It will rely on existing semantic
annotation tools, on the expertise of RCLN team members and on real use
cases to assess the contribution of this dynamic annotation.

The proposed method will be directly integrated into an existing
annotation tool or tested through simulation if integration is too
complex.

Description of work 

The work will include several parts: 
- state of the art on semantic annotation and review of existing tools; 

- description, modeling and implementation of the dynamic annotation
  process (for the simplest types of annotations and based on existing
  tools and/or semantic technologies); 

- analysis, test and evaluation of the proposed approach on simple but
  real use cases provided by the RCLN team. 

In addition, and in anticipation of a PhD followup, the student may
start to specify a richer semantic annotation method taking into account
a wider range of annotation types.

Context and Practical Information

The work will be supervised by Pr. Adeline Nazarenko and Pr. Francois
Levy.

The intern will be integrated in the RCLN team and benefit from its
expertise in natural language processing, knowledge engineering and
semantic web. In particular, RCLN has a solid experience in semantic
annotation (manual annotation [2, 3] or based on machine learning [8],
formalisms and resources for annotation [9, 12]) and text-based ontology
design [1]. It also knows how to integrate those methods of acquisition
and annotation in content analysis tools [7 , 5, 11 ].

The intern will work at LIPN (University Paris 13 - Sorbonne Paris Cité
& CNRS) where he/she will be assigned a desk. He/she will have access to
local facilities and data resources.

The internship is for a period of 6 months. It should start in spring
2014.

It will be funded by the Labex ""Empirical Foundations of Language""
(research strand ""computational semantic analysis"").

Applications should be addressed to François Lévy (francois.levy to
lipn.univ - paris13.fr) before March 7, 2014 : send a cover letter, a CV
and transcripts.

References

[1] N. Aussenac-Gilles, S. Després, and S. Szulman. « The TERMINAE
Method and Platform for Ontology Engineering from texts ». In Paul
Buitelaar and Philipp Cimiano, editors, Bridging the Gap between Text
and Knowledge - Selected Contributions to Ontology Learning and
Population from Text, pages 199-223. IOS Press, janvier 2008.

[2] K. Fort. Les ressources annotées, un enjeu pour l'analyse de contenu
: vers une méthodologie de l'annotation manuelle de corpus. Thèse
d'informatique, Université Paris 13 - Sorbonne Paris Cité, Villetaneuse,
France, 2012.

[3] K. Fort., A. Nazarenko, S. Rosset. « Modeling the Complexity of
Manual Annotation Tasks: a Grid of Analysis ». In Proceedings of the
24th International Conference on Computational Linguistics (COLING
2012), Mumbai, India, December 2012.

[4] C. Giuliano, A. Gliozzo. « Instance-based ontology population
exploiting named-entity substitution ». In Proceedings of the 22nd
International Conference on Computational Linguistics (Coling 2008),
pages 265-272, Manchester, August 2008.

[5] A. Guissé, F. Lévy, A. Nazarenko. Un moteur sémantique pour explorer
des textes réglementaires. In Actes des 22èmes journées francophones
d'Ingénierie des Connaissances, Chambéry, 2011.

[6] A. Kiryakov, B. Popov, I. Terziev, D. Manov, and D. Ognyanoff.  «
Semantic annotation, indexing, and retrieval ». Journal of Web
Semantics, 2(1):49-79, 2004.

[7] F. Lévy, A. Nazarenko, A. Guissé. « Annotation, indexation et
parcours de documents numériques ». Revue des Sciences et Technologies
de l'Information, 13(3/2010):121-152, 2010.

[8] Y. Ma, F. Lévy, A. Nazarenko. Annotation sémantique pour des
domaines spécialisés et des ontologies riches. In de la 20ème conférence
du Traitement Automatique du Langage Naturel (TALN 2013), pp 464-478,
17-21 Juin 2013, Les Sables d'Olonne.

[9] Y. Ma, A. Nazarenko, L. Audibert. « Formal description of resources
for ontology-based semantic annotation ». In Proceedings of the
International Conference on Language Resources and Evaluation (LREC
2010), Malta, May 2010. ELRA.

[10] B. Magnini, A. Pianta, O. Popescu, M. Speranza. « Ontology
population from textual mentions: Task definition and benchmark ». In
Proceedings of the OLP2 workshop on Ontology Population and Learning,
Sidney, Australia, 2006.

[11] A. Nazarenko, A. Guissé, F. Lévy, N. Omrane, S. Szulman. «
Integrating Written Policies in Business Rule Management Systems ». In
Rule-Based reasoning, Programming, and Applications, volume 6826 of
Lecture Notes in Computer Science, pages 99-113, Barcelona, Espagne,
2011.

[12] N. Omrane, A. Nazarenko, P. Rosina, S. Szulman, C. Westphal. «
Lexicalized ontology for a business rules management platform: An
automotive use case ». In Proceedings of the 5th International Symposium
on Rules, International Business Rules Forum (RuleMF@BRF), Ft
Lauderdale, Florida, USA, November 2011.

[13] B. Popov, A. Kiryakov, D. Ognyanoff, D. Manov, A. Kirilov. « Kim -
a semantic platform for information extraction and retrieval ». Natural
Language Engineering, 10(3-4):375-392, 2004.

[14] V. Uren, P. Cimiano, J. Iria, S. Handschuh, M. Vargas-Vera,
E. Motta, F. Ciravegna. « Semantic annotation for knowledge management:
Requirements and a survey of the state of the art ». Journal of Web
Semantics, 4, 2006."
"217","2014-02-12","IRIT","Toulouse","Proposition de stage de M2(R)

Titre : Analyse automatique de comptes-rendus de consultations médicales

Mots-clefs : traitement automatique des langues naturelles, extraction
d'information, apprentissage automatique, médecine

Résumé :

Ce stage de M2 Recherche vise l'analyse automatique de comptes-rendus de
consultations médicales pour en extraire certaines informations
nécessaires à la réalisation d'une étude épidémiologique. Les
compte-rendus sont constitués de texte libre résumant les données
sociodémographiques, le diagnostic, les symptômes, et les résultats des
tests éventuels réalisés chez ces patients.
Deux objectifs principaux sont considérés : d'une part classifier les
comptes rendus vis à vis de l'existence ou non d'une pathologie, d'autre
part extraire un certain nombre d'informations précises en lien avec ces
maladies. Le stagiaire devra évaluer et comparer les stratégies
classiques d'extraction d'information en Traitement Automatique des
Langues en domaine spécialisé, et l'application de méthodes
d'apprentissage automatique pour les deux objectifs visés. Les données
utilisées sont un corpus de compte-rendus de consultation déidentifiés,
en français.

Encadrement :
Ce stage sera effectué à l'IRIT (Institut de Recherche en Informatique
de Toulouse), en coopération avec l'INSERM, et sera codirigé par
Philippe Muller (IRIT, équipe MELODI ""MEthodes et ingénierie des
Langues, des Ontologies et du DIscours"") et Virginie Gardette (équipe
""Vieillissement et maladie d'Alzheimer"" de l'UMR INSERM 1027
""Epidémiologie et analyses en santé publique"").

http://www.irit.fr/-Equipe-MELODI-
http://www.u1027.inserm.fr/42537678/0/fiche___pagelibre/&RH=1303915788348

Compétences requises :
Le stagiaire devra avoir une formation en M2 informatique, idéalement
avec des compétences en apprentissage automatique et/ou traitement
automatique du langage naturel.

Durée : 4-6 mois à partir de mars ou avril.

Rémunération :  436,05¤/mois, conformément à la réglementation.

Candidature : Envoyez un CV (avec relevés de notes récents) et une
lettre de motivation à philippe.muller@irit.fr et
virginie.gardette@univ-tlse3.fr"
"218","2014-02-17","Rebuz","Strasbourg","Sujet de stage en informatique
Prétraitement de données textuelles pour un système d'analyse sémantique

Entreprise : Rebuz SAS, Strasbourg
Durée : 2-5 mois
Niveau : M1-M2
Rémunération : 436,05 euros/mois
Contact : Mme Yuliya Goncharova,  4arly@bk.ru

Détails :

Rebuz est une société spécialisée dans l'analyse de textes pour la
veille économique. Le système original repose sur l'analyse sémantique
épaulée par des principes de la linguistique cognitive.

Le stage portera sur l'amélioration du module de prétraitement
existant. Ce sujet sera particulièrement intéressant pour les étudiants
souhaitant en apprendre plus sur le Traitement Automatique de Langues
(TAL) et sur la Recherche d'Information (RI).

Les tâches seront adaptées selon le niveau et les préférences du (de la)
candidat(e) sélectionné(e).
 
Objectifs du stage
* Révision du module actuel (écrit en Java)
* Nettoyage et optimisation du code
* Intégration de l'étiqueteur morphosyntaxique MACAON [1]
* Séries de tests et perfectionnement

Compétences recherchées :
- aisance dans la programmation en Java (un échantillon de code sera
  demandé)
- bonnes connaissances des tests unitaires (JUnit)
- bonnes capacités de travail en équipe
- rigueur
- responsabilité
- autonomie 
 
[1] http://macaon.lif.univ-mrs.fr/"
"219","2014-03-24","IRT SystemX","Palaiseau","Proposition de stage : Translittération des noms propres pour
l'extraction d'entités nommées

Lieu du stage : IRT SystemX, 8 avenue de la Vauve, 91190 Palaiseau

CONTEXTE :

L'IRT SystemX est un institut de R&D thématique interdisciplinaire
rassemblant les compétences de l'industrie et de la recherche publique
dans une logique de co-investissement public-privé : Alstom, Bull,
Campus Paris-Saclay, INRIA, Institut Mines Telecom, Kalray, OVH,
Renault, Sherpa, Systematic Paris-Region en sont les fondateurs. Les IRT
s'inscrivent dans le cadre du Programme Investissements d'Avenir.

Au sein de SYSTEMX, vous serez intégré dans l'équipe de l'un des projets
de recherche : Intégration Multimédia Multilingue (IMM).

Le projet IMM réunit des acteurs du monde académique (CEA, CNRS-LIMSI,
INRIA, LNE, UPMC-LIP6), des industriels (Bertin Technologie, CapGemini,
Exalead, OVH, Systran, Temis, Vecsys, Vocapia) et des utilisateurs de
référence dans le domaine de l'analyse de contenus non structurés
(texte, vidéo).

L'objectif du projet IMM est de développer de nouvelles fonctions ou
capacités pour des composants nécessaires pour des applications de
veille sur les sources ouvertes (moteur de recherche, de transcription
de la parole, de traduction...), de concevoir des environnements
d'exécution et d'intégration de ces composants et de relever un certain
nombre de défis comme par exemple réduire le temps d'adaptation à un
contexte nouveau (sources, domaine, langue).

SUJET DE STAGE :

La translittération consiste à substituer à chaque graphème d'un système
d'écriture, un autre graphème ou un groupe de graphèmes d'un autre
système d'écriture, indépendamment de la prononciation.

La translittération connait un essor important en raison du caractère de
plus en plus multilingue du Web. De nombreuses approches ont été
proposées pour développer des systèmes de translittération mais la
majorité des systèmes actuels ne prennent pas en compte la complexité
des problèmes de la transcription et de la translittération, lesquels
touchent autant à l'oralité qu'à la scripturalité des systèmes
linguistiques impliqués.

L'objectif de ce stage est de concevoir et de développer un outil de
translittération automatique de noms propres de l'arabe vers le script
latin et se déroulera selon les étapes suivantes :

- Etude, analyse et évaluation de l'existant. Cette étape permet
  d'identifier l'approche à explorer.

- Implémentation d'un outil automatique de translittération de noms
  propres de l'arabe vers le latin.

- Evaluation des résultats pour une généralisation à d'autres alphabets.

Vos missions :

- Faire un état de l'art dans le domaine : approches existantes et
  outils disponibles.

- Choix de l'approche et conception de l'outil de translitération des
  noms propres de l'arabe vers le script latin.

- Réaliser une évaluation des résultats.

Le profil recherché :

- Niveau : BAC+4 ou BAC +5, en Informatique ou Informatique Linguistique
  (Ingénieur ou Master) pour un stage de 4 à 6 mois.

Vos Compétences sont :

Obligatoires :

- Informatique : maîtrise d'un langage de programmation (C++, Java,
  Perl, Python).

- Technologies d'apprentissage.

Optionnelles :

- Technologies d'apprentissage : clustering, HMM.

- Traitement automatique des langues.

- La connaissance de la langue arabe est un plus.

BIBLIOGRAPHIE :

- ALGHAMDI M. (2005). Alghorithms for Romanizing Arabic names. Journal
  of King Saud University - Computer and Information Sciences,Volume 17,
  Riyadh, 105-128.

- AL-ONAIZAN Y., KNIGHT K. (2002). Translating named entities using
  monolingual and bilingual resources. Proceedings of the 40th ACL
  Conference, USA.

- JIANG L., ZHOU M., CHIEN L. F., NIU C. (2007). Named entity
  translation with web mining and transliteration. Proceedings of the
  20th International Joint Conference on Artificial Intelligence,
  1629-1634.

- TAO T., YOON S. Y., FISTER A., SPROAT R., ZHAI C. (2006). Unsupervised
  named entity transliteration using temporal and phonetic
  correlation. Proceedings of the Conference on Empirical Methods in
  Natural Language Processing (EMNLP'06), 250-257.

- YASER A. O., KNIGHT K. (2002). Translating named entities using
  monolingual and bilingual resources. Proceedings of the 40th Annual
  Meeting of the Association of Computational Linguistics (ACL'02),
  400-408.

CONDITIONS DE CANDIDATURE :

Contact et envoi des candidatures (CV détaillé et lettre de motivation):

Nasredine SEMMAR, 01 69 08 01 46, nasredine.semmar@cea.fr"
"220","2014-04-02","IdexLab","Paris","*Title*: Online semantic relations extraction from linguistic and
statistic patterns

*Context*: The company ideXlab implements the process that is dedicated
to the open innovation domain in order to connect experts and companies
to easy establishing collaboration between them. The aim of such
collaboration is to bring solutions to technical challenges.

For more information please check : www.idexlab.com

*Subject*: The student will analyze the extracted data from the
scientific papers and identify the linguistic patterns that describe
semantic relationship between a given query and the suggested keywords
obtained from the expert search tool. From this study, the student will
propose a semantic relation extraction approach that fits with the kind
of the used data and takes into account the constraints related to the
expert search tool performance. More specifically, it he/she propose an
implementation of the semantic relations extraction between a query and
other terms by applying the patterns, identified in the first phase, on
the content of scientific papers.


*Profil*: The desired profile is a student in a second year of Master or
Engineering school having skills on Natural Language Processing and
Information Retrieval

*Skills*:

Languages: C#, C++

Period: 6 months from May 1 2014.

*Location*: ideXlab, Immeuble Berlier - Halle B, 15, rue Jean-Baptiste
Berlier 75013 PARIS

Send CV and motivation letter  to:

- Pierre Bonnard : pierre.bonnard@idexlab.com
- Nouha Omrane : nouha@idexlab.com

*Titre* : Extraction online des relations sémantiques à partir de
patrons linguistiques et statistiques

*Contexte* : La société ideXlab travaille dans le domaine de
l'innovation ouverte. Elle propose un service d'intermédiation entre
experts et entreprises qui permet d'initier une collaboration entre ces
partenaires dans le but d'apporter des solutions à des problématiques
identifiées.


Pour plus d'information sur l'activité : www.idexlab.com

*Mission* : Le stagiaire aura à analyser les données extraites à partir
des publications scientifiques et à identifier les patrons linguistiques
qui décrivent des relations sémantiques entre une requête donnée et des
mots clés suggérés par l'outil de recherche d'experts. A partir de cette
étude, l'étudiant aura à proposer une approche d'extraction de relations
sémantiques adaptée aux types de données manipulées et aux contraintes
liées à la performance de l'outil de recherche d'experts. Plus
précisément, il aura à proposer une implémentation pour l'extractionde
relations sémantiques entre une requête et des d'autres termes à partir
de l'application des patrons identifiés dans la première phase sur le
contenu des papiers scientifiques.

*Profil* : Le profil recherché est un étudiant en 2ème année de Master
ou d'école d'ingénieur ayant des connaissances en Traitement Automatique
de la Langue et Extraction d'Information.

*Compétences recherchées* :

Langages de programmation : C#, C++

Durée : 6 mois, à partir de 1 Mai 2014



*Adresse du stage* : ideXlab, Immeuble Berlier - Halle B, 15, rue
Jean-Baptiste Berlier 75013 PARIS


Veuillez adresser votre candidature (CV + lettre de motivation) à :

- Pierre Bonnard : pierre.bonnard@idexlab.com
- Nouha Omrane : nouha@idexlab.com"
"221","2014-10-20","LIUM","Le Mans","Le LIUM, Laboratoire dâ€™Informatique de lâ€™UniversitÃ© du Maine, propose un
stage de Master 2 Recherche orientÃ© dialogue oral. Ce stage se fait en
collaboration avec lâ€™entreprise TÃ©lÃ©copolis basÃ©e au Mans, et est censÃ©
dÃ©boucher sur une thÃ¨se en contrat CIFRE dans la mÃªme entreprise.

Lâ€™objectif du stage est de contribuer au dÃ©veloppement de YADE, un
systÃ¨me de dialogue existant Ã  base de rÃ¨gles. Les problÃ©matiques
abordÃ©es seront dâ€™une part la robustesse, puisque lâ€™objectif final est
dâ€™intÃ©grer YADE au sein dâ€™une plateforme de tÃ©lÃ©phonie professionnelle,
dâ€™autre part lâ€™aide Ã  la conception des connaissance, puisquâ€™il sâ€™agit
de sâ€™adresser Ã  des utilisateurs finaux.

Un descriptif plus complet de ce stage est disponible Ã  lâ€™adresse
suivante :
=> http://www-lium.univ-lemans.fr/~lehuen/stage_M2R_LIUM.pdf

Les personnes intÃ©ressÃ©es doivent se manifester auprÃ¨s de JÃ©rÃ´me Lehuen
Ã  lâ€™adresse suivante :
=>  jerome.lehuen@univ-lemans.fr"
"222","2014-11-03","TrooClick","Paris","NLP Engineer Internship

Trooclick France is a company that specializes in the development of
web applications for the automatic processing of information. Our goal
is to create services that rebuild the userâ€™s trust in digital
content. Up to now, Web players were able to enhance the relevance of
this content; we go a step further and contribute to improve its
reliability with automated fact checking and controversy detection.

Trooclick was created in November 2012. Just a few months later, in
April 2013, it received financial support from the BPI (French public
investment bank) and in June 2013 was granted the Status of â€œYoung
Innovative Companyâ€ (JEI), recognizing its innovative nature by the
French government. It now counts fifteen committed and passionate
members in its tight-knit team.

The company carries out R&D projects in search of technical solutions
in the Artificial Intelligence field. Due to its growth, Trooclick is
now looking for candidates for its office in the â€œEspace Startupâ€ of
Bpifrance on Boulevard Haussmann in the heart of Paris.

Missions:

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

- You will turn ideas into well-documented and reliable linguistic
  resources (both dictionaries and grammars) to ensure efficiency,
  quality, performance and scalability

- A great team player, you will interact with other departments to
  understand and fine tune specifications

- You will carry out unitary testing, create and maintain our test
  validation corpus and participate in editing technical documents

- Development will be done in English

Qualifications:

- BSc/MSc

- Experience with NLP tools such as NooJ, Unitex, Gate, or Stanford
  for linguistic annotation, named entity recognition, relationship
  and fact extraction, sentiment analysis, etc.

- Experience in scripting languages such as Perl or Python as well as
  XML format to be autonomous in completing several technical tasks

- Experience with basic database management operations (SQL language)

- Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.) will
  be a plus

- Excellent communication skills in English and French

We are open to new ideas that will significantly contribute to our
success. Our friendly team will provide the opportunity for valuable
collaboration. We offer you career perspectives in a young and dynamic
company with an interesting and diversified scope of duties at the
cutting edge of research. We welcome applications from highly
motivated individuals able to learn new techniques and share knowledge
and experience with the team.

Interested? Then send your application to jobs@trooclick.com!"
"223","2014-11-24","LIMICS","Paris","Le LIMICS (Laboratoire d'Informatique Médicale et d'Ingénierie des
Connaissances en Santé) travaille sur les problématiques de l'aide à la
décision et de la représentation et l'utilisation des connaissances
(deux branches de l'intelligence artificielle) dans le domaine médical,
afin de produire des applications et méthodes pour faciliter les
processus de décisions médicaux et l'interopérabilité entre différents
services ou systèmes de santé. Une grande partie de l'équipe se focalise
sur l'utilisation des technologies du Web sémantique (graphes RDF,
ontologies, raisonneurs logiques, etc) dans des applications de santé.

Contexte du stage :
--------------------------
     Le stage, d'une durée de 5 à 6 mois, se déroulera sur le site du
Campus des Cordeliers (Odéon) sous la tutelle de Yves Parès (ingénieur
doctorant), Xavier Aimé (chercheur) et Marie-Christine Jaulent
(directrice de recherche). L'étudiant prendra part au projet ACCORDYS,
qui vise à produire un système informatique évaluant la ressemblance de
cas de dysmorphies prénatales (décrits dans des comptes rendus textuels)
afin de fournir au médecin une réponse aux questions du type « quels
foetus malformés rencontrés dans le passé ressemblent le plus à celui-ci
? ». Le but étant d'aider le diagnostic et le suivi apporté aux parents.
Ce travail contribue à la caractérisation ce qu'est une dysmorphie. On
s'intéresse donc à la sémantique et à l'évaluation de mesures de
similarités entre dysmorphie.

Objet du stage :
---------------------
     Le but du stage sera d'utiliser des outils de NLP et d'indexation
de documents textuels dans ce contexte, et d'évaluer les résultats
qu'ils fournissent en termes de pertinence. Les méthodes à explorer
seront les modèles vectoriels (tels qu'utilisés dans les systèmes de
recommandation) et la construction de clusters de mots à partir de leurs
co-occurences, afin de pouvoir évaluer la distance séparant deux comptes
rendus. Le début du stage consistera donc à rechercher parmi les outils
logiciels existants ceux qui pourraient être adaptés. Le but final est
de quantifier l'intérêt de ces méthodes pour la tâche à résoudre et de
comparer leurs résultats à ceux des méthodes déjà en cours de
développement au sein du LIMICS, ceci pouvant être pour l'étudiant
l'objet d'un article de recherche en fin de stage.

Gratification :
------------------
     La gratification sera de 436,05¤/mois, avec de plus un 
remboursement de 50 % du titre de transport.

Profil recherché :
-----------------------
     Une grande partie du stage consistant à travailler sur des fichiers
texte, l'étudiant d'un niveau M2 devra avoir suivi des enseignements sur
les méthodes de traitement automatique des langues et être intéressé par
ce domaine. Conjointement à cela, il est souhaitable que l'étudiant ait
quelques connaissances en machine learning. Il est nécessaire que
l'étudiant ait été formé à la programmation, et si possible qu'il ait
déjà utilisé des langages de scripting, adaptés au prototypage (tels que
Python, Ruby, Perl). Une connaissance de Java et des langages JVM
alternatifs (Clojure, Groovy, JRuby...) est un plus. Pour finir, un
intérêt de l'étudiant pour le Web sémantique et les ontologies est
également appréciable mais pas obligatoire.

     Selon le profil de l'étudiant (plutôt linguistique ou plutôt
développement informatique), le stage pourra être orienté différemment
mais les problématiques restent les mêmes.

Contacts :
-------------
     yves <point> pares <at> gmail <point> com
     xavier <point> aime <at> inserm <point> fr"
"224","2014-11-24","INBENTA","Toulouse","*Présentation société*
------------------------------

Inbenta est une société pionnière dans le Traitement Automatique du
Langage et la recherche sémantique. Basée sur ces concepts novateurs,
Inbenta développe depuis 2005 des solutions logicielles pour les sites
web de Grands Comptes. Inbenta est notamment le leader français des FAQ
Dynamiques pour site web de Grands Comptes.


*Description de l'offre*
------------------------------

Inbenta a développé un moteur de recherche intelligent appelé *Inbenta
Semantic Search Engine* (ISSE). Les deux tâches principales de ce moteur
sont d'analyser les questions des utilisateurs et de trouver la réponse
appropriée à la requête en effectuant une recherche dans une base de
connaissances.

L'objectif de ce stage sera d'évaluer ce moteur de recherche sémantique
de façon scientifique.

Les missions de stage seront les suivantes :

   - Faire un état de l'art des méthodes d'évaluation dans le domaine de
     la recherche d'information

   - Proposer et mettre en place une méthode d'évaluation scientifique
     du moteur de recherche sémantique d'Inbenta

   - Travailler en collaboration avec une université avec laquelle nous
     mènerons des évaluations croisées

   - En parallèle, l'étudiant devra assurer la gestion linguistique et
     éditoriale d'un projet de FAQ dynamique afin qu'il s'approprie
     l'existant en vue d'assurer, en cas d'embauche après le stage, les
     missions de production que nous attendons d'un ingénieur linguiste
     (20% du temps de travail)

*Profil recherché*
------------------------------

Nous recherchons une personne enthousiaste, organisée et sérieuse et
ayant l'envie d'intégrer une équipe internationale. Le stagiaire devra
également avoir les compétences suivantes :

   - Etudes en Traitement Automatique du Langage Naturel / Linguistique
     Informatique
   - Connaissances dans le domaine de la Recherche d'Information
   - Excellente maîtrise de la langue française et bonne communication
     écrite et orale en espagnol, anglais ou catalan


Bonus :

   - Maîtrise d'au moins un langage de programmation (PHP de préférence)
   - Maîtrise des expressions régulières et du SQL
   - Des compétences dans les méthodes statistiques serait un réel plus


*Modalités du poste*
 ------------------------------

   - Stage de 5 à 6 mois (avec *possibilité d'embauche en CDI*)
   - Rémunération prévue: 525 euros/mois (soit environ 36% du SMIC) +
     prime en fonction des résultats
   - Début : à partir de Février / Mars 2015
   - Lieu : Toulouse

Merci d'adresser CV et lettre de motivation à Quintana Manon à l'adresse
mail suivante : *mquintana@inbenta.com*
*--*
*Manon Quintana*
Computational linguist

*IN**B**ENTA*
+33 (0)5 31 54 94 97
www.inbenta.fr"
"225","2014-11-24","EPTICA","Boulogne-Billancourt","Sémantique de corpus : auto apprentissage de domaines sémantiques,
regroupements et pondération de termes à partir d'un parcours de réseau
sémantique

Début : Février 2014

Durée : 6 mois à 1 an

Lieu : Boulogne-Billancourt

Eptica est le leader français et international des solutions de réponse
client multi-canal (WCS). Principalement implanté en France, au Royaume
Uni et à Singapour, EPTICA édite une solution reconnue qui s'adresse aux
grands comptes et au mid-market dans les secteurs du Retail, de la
Finance, de l'Assurance, du Secteur Public et des Services.

Eptica compte 400 clients, parmi lesquels la Société Générale, le Crédit
Agricole, la CNAM, la MAAF, Darty, Pixmania, Carrefour, La Redoute..., en
France et aussi à l'international comme Air Asia, Panasonic...

Depuis 2013, Eptica intègre le moteur de recherche sémantique et les
outils d'extraction de contenu issus de la société Lingway. Ces outils
mettent en oeuvre des grammaires d'analyse et d'extraction
d'informations, un réseau sémantique adapté pour le monde de la relation
client, et des stratégies de recherche documentaire spécifiques.

Dans le cadre des évolutions de son offre, EPTICA propose un stage
conventionné niveau M2, basé à Boulogne-Billancourt.

Au sein de l'équipe R&D, le candidat participera aux tâches
d'exploitation des ressources sémantiques du dictionnaire Eptica, à des
fins de désambiguïsation et de regroupements syntaxiques de termes :

   - Proposition de regroupements de termes extraits, sur la base du
     parcours du réseau sémantique. Pondération sémantique des éléments
     extraits

   - Etude d'enrichissement du réseau sémantique à partir de corpus (par
     exemple Wikipedia)

   - Ciblage des domaines sémantiques à exploiter, à partir de
     probabilités calculées sur corpus d'une application donnée


Compétences requises :

   - Traitement Automatique des Langues (étude de corpus, moteur de
     recherche, grammaires locales, techniques de « machine learning »)
   - Des connaissances en programmation/scripting (Java, Groovy, Perl,
     ...)
   - La maîtrise du français et de l'anglais, la connaissance d'autres
     langues européennes serait un plus
   - Bonnes capacités d'analyse et autonomie
   - Facilité à travailler en équipe

Contact:Cécile Potier
cecile.potier@eptica.com

Cécile Potier
Chef de produit linguistique
95 bis rue de Bellevue
92100 Boulogne-Billancourt
Bureau : +33 (0)9 53 07 60 81
Fax : +33 (0)1 47 12 68 89
Email : cecile.potier@eptica.com
http://www.eptica.com/?lang=fr
http://epticaexpress.wordpress.com/
http://www.linkedin.com/company/eptica?trk=cp_followed_name_eptica
https://www.facebook.com/EpticaFrance?fref=ts
https://twitter.com/EpticaFrance"
"226","2014-11-26","Solocal","Sèvres","clustering sémantique H/F

Descriptif de l'entreprise :

Solocal Group est le nouveau nom de PagesJaunes Groupe depuis le 5 juin 2013.

N°1 de la communication locale et 1er créateur de sites web à
destination des entreprises en France et en Espagne, Solocal Group
étend avec succès son savoir-faire sur l'internet mobile au service
des entreprises.

Il fédère plus de 4900 collaborateurs - dont près de 2 200 conseillers
en communication locale en France et en Espagne pour accompagner le
développement numérique des entreprises (TPE/PME, Grands Comptes,
etc.) - 16 marques fortes et complémentaires (PagesJaunes, Mappy,
123deal, A vendre A louer, Embauche.com, Keltravo, Chronoresto,
ZoomOn, Solocal Network, ComprendreChoisir, ClicRDV, PJMS, Horyzon
Media, Leadformance, QDQ, Editus et Solocal Group) et près de 650 000
annonceurs.

Missions confiées :

SOLOCAL GROUP EST N° 1 DE LA COMMUNICATION LOCALE

Se développant selon un business modèle de média, Solocal Group est
présent dans 3 métiers complémentaires : éditeur de contenus et
services, média et conseil et régie publicitaire.

Le Groupe crée et met à disposition des services qui donnent accès à
une mine d'informations utiles et fiables. Adaptés en permanence aux
modes de consommation, ils accompagnent les citoyens partout et tous
les jours pour leur faciliter la vie : localiser et contacter un
professionnel, retrouver ses amis sur le net, obtenir un itinéraire,
visiter les boutiques des commerçants, repérer les bons plans...

Pour produire ces contenus et les diffuser, le Groupe compte plus de
4900 collaborateurs en France, Espagne, Luxembourg et Autriche, dont
2300 conseillers en communication locale et digitale et de très
nombreux talents digitaux.

Missions :

- analyse de corpus d'expressions clés

- identification des variables de clusterisation sémantique
  automatique

- mise en oeuvre des tests / mesure du taux de couverture sémantique

Profil recherché :

master Ingénierie linguistique (RI)

-- 

Pour postuler :

http://pages-jaunes.contactrh.com/jobs/440/7770386"
"227","2014-11-26","Lingua et Machina","Roquencourt ou télétravail","- Lingua et Machina -

L'écrit multilingue dans l'entreprise
Fiche de poste - stagiaires constitution de ressources
linguistiques, traduction et post-édition

La société

Lingua et Machina est un éditeur de logiciel français, spécialisé en
traitement automatisé des langues pour des applications
industrielles. L&M a été créé en 2002, a commercialisé le logiciel de
mémoire de traduction Similis en 2005 et la plateforme de gestion
linguistique Libellex en 2010. Similis, réputé pour la qualité de son
extraction terminologique bilingue, est téléchargeable gratuitement
sur notre site Web depuis 2008.

Nos solutions répondent aux problématiques suivantes :

- comment constituer et tenir à jour à faible coût des ressources
  linguistiques spécialisées (lexiques, réseaux lexico-sémantiques,
  mémoires de traduction, glossaires, etc.) pour en mutualiser l'usage
  dans l'entreprise ;

- comment améliorer la productivité d'un ou de plusieurs traducteurs
  et assurer la cohérence terminologique dans les traductions de
  documentation technique de grands projets (centrales nucléaires,
  aéronautique, chaînes de montage, etc.) ;

- comment diminuer les coûts et les délais sur des systèmes
multilingues à grand e échelle (publication de catalogues, réseaux
sociaux d'entreprise déployés à l'échelle mondiale, sites e-commerce,
etc.)

Le produit

Libellex est une plateforme d'aide à la traduction, hébergée sur un
serveur et accessible à l'utilisateur via un navigateur web. Libellex
dispose d'un moteur interne de traduction automatique entraîné
périodiquement à partir de ses mémoires. La traduction automatique est
donc spécialisée dans le domaine de l'utilisateur et ses performances
s'améliorent au fur et à mesure de l'alimentation des mémoires avec de
nouvelles traductions.  Cette traduction automatique est contrôlée par
des glossaires, ce qui permet de garantir l'homogénéité du texte
traduit par rapport aux couples de termes validés dans ces
glossaires. L'utilisation d'un moteur de traduction interne garantit
la confidentialité.  Deux modes d'accès distincts sont proposés à
l'utilisateur : d'une part une interface bureautique qui privilégie la
simplicité et l'intuitivité d'emploi pour tous (cadres, ingénieurs,
assistantes, stagiaires) et d'autre part des interfaces
professionnelles qui privilégient la puissance et la richesse des
outils et des informations proposées aux spécialistes de l'écrit
(traducteurs, terminologues, documentalistes).

Sujet de travail

Nous cherchons pour l'année scolaire 2014-2015 (perlé) ou la saison
printemps-été 2014 (temps plein) des étudiants en traduction ou en
linguistique informatique de niveau 2 ème , 3 ème ou 4 ème année (L2,
L3 ou M1) pour deux types de tâches : (i) recherche et validation
terminologique bilingue (anglais, espagnol, portugais, allemand,
chinois) pour nos projets sur les thèmes finance, tourisme, mode,
cuisine, notamment à partir des jeux sérieux de notre partenaire
JeuxDeMots et (ii) post-édition de phrases soumises à la traduction
automatique par nos clients, en vue d'améliorer le corpus
d'entraînement des traducteurs automatiques.


Conditions de stage

L'ensemble de ces tâches se fera sur la base d'un programme de travail
et d'un suivi de progression. Un fort niveau d'autonomie et de
responsabilité est attendu des candidats, en mode chef de projet en
utilisant des logiciels avancés et en proposant des modifications des
interfaces et des fonctionnalités de ces logiciels.

Dates et lieu de travail

Le stage perlé s'effectue en télétravail lors des temps libres de
l'étudiant, à tout moment de l'année.

Le stage temps plein se déroulera pendant les mois de juin et juillet
au sein de notre établissement de Rocquencourt sur le campus de
l'Inria, Domaine de Voluceau, Rocquencourt, Le Chesnay Cedex, 78153.

Gratification et avantages

Ces stages sont proposés sans gratification.
Transport par navette gratuite entre Place de l'Étoile, Porte Maillot,
Porte d'Auteuil ou Versailles et l'Inria (voir les détails sur
http://www.inria.fr/rocquencourt/ur/comment-venir/navettes).
Accès gratuit aux équipements sportifs de l'Inria (squash,
musculation, football, tennis, jogging).
Accès à la cantine de l'Inria avec participation à 50% du prix du
repas ou coin repas avec four micro-ondes.

Contact

François Brown de Colstoun - 06 80 95 94 39 - fbc@lingua-et-machina.com"
"228","2014-12-01","Eptica Lingway","Boulogne-Billancourt","Début : Février 2014

Durée : 6 mois à 1 an

Lieu : Boulogne-Billancourt

Eptica est le leader français et international des solutions de réponse
client multi-canal (WCS). Principalement implanté en France, au Royaume
Uni et à Singapour, EPTICA édite une solution reconnue qui s'adresse aux
grands comptes et au mid-market dans les secteurs du Retail, de la
Finance, de l'Assurance, du Secteur Public et des Services.

Depuis 2013, Eptica intègre le moteur de recherche sémantique et les
outils d'extraction de contenu issus de la société Lingway. Ces outils
mettent en oeuvre des grammaires d'analyse et d'extraction
d'informations, un réseau sémantique adapté pour le monde de la relation
client, et des stratégies de recherche documentaire spécifiques.

La filiale issue de cette fusion, EPTICA-LINGWAY, développe la gamme de
produits LeaCV destinée au recrutement (analyseurs de CV, d'offres,
moteur sémantique dédié RH, etc.). LeaCV est utilisé par plus de 150
clients.


Dans le cadre des évolutions de LeaCV, EPTICA-LINGWAY propose un stage
conventionné niveau M2, basé à Boulogne-Billancourt. Au sein de l'équipe
R&D, le candidat participera explorera les différentes méthodes
automatiques d'enrichissement du dictionnaire pour des langues
non-encore couvertes :

- Utilisation de ressources ouvertes existantes généralistes (wikipedia,
  wiktionnaire, ...) ou spécifiques au monde RH comme les ontologies
  métier multilingues (ISCO, etc.)
- Croisement avec les ressources existantes à Eptica-Lingway,
- Prototypage d'algorithmes d'enrichissement,
- Evaluation des ressources ainsi réalisées sur des tâches précises :
  recherche d'information, similarité documentaire

Compétences requises :

- Traitement Automatique des Langues (étude de corpus, moteur de
  recherche, grammaires locales, techniques de « machine learning »)
- Des connaissances en programmation/scripting (Java, Groovy, Perl, ...)
- La maitrise du français et de l'anglais
- Bonnes capacités d'analyse et autonomie
- Facilité à travailler en équipe
- La connaissance de langues d'Europe du Nord ou de l'Est est un véritable
  plus

Contact: Hugues de Mazancourt, Directeur Technique EPTICA-LINGWAY

hugues.de-mazancourt@eptica.com"
"229","2014-12-01","IRT System X","Palaiseau","STAGE M2: TAL, Extraction d'information pour la veille géopolitique -
IRT SystemX

durée 6 mois, démarrage février-avril 2015

Vous serez partie prenante d'une équipe projet composée de 3 étudiants à
qui nous proposons 3 stages:

- Spécifications et modèle économique d'une application de veille
  géopolitique,

- Design d'une application de veille géopolitique et enfin

- Extraction d'information pour la veille géopolitique, qui est l'objet
  de cette annonce.


Les technologies de traitement automatique de la langue (TAL) sont au
coeur de tous les métiers qui cherchent à exploiter plus efficacement
les documents non structurés disponibles sur le web ou dans des bases de
documents (articles de journaux, brevets, blogs, journaux télévisés,
articles scientifiques). Le volume de ces données ne rend possible la
consultation manuelle que d'une infime partie. Les outils de TAL vont
servir à filtrer les documents pertinents, en extraire les informations
essentielles, les structurer et les visualiser pour prendre les bonnes
décisions.

Au sein de l'IRT SystemX, Le projet de recherche intitulé IMM
(Intégration Multimédia Multilingue), est un projet tri annuel démarré
fin 2014. Il regroupe des industriels (Bertin Technologie, CapGemini,
Exalead, OVH, Systran, Temis, Vecsys, Vocapia) et des partenaires
académiques (CEA-LIST, CNRS-LIMSI, INRIA-Saclay, LNE, UPMC-LIP6) ainsi
que le Ministère de la Défense. Son objectif est de mettre en place une
plateforme qui intègre les composants des partenaires (moteur de
recherche, de transcription de la parole, de traduction...) pour des
applications de veille. L'objectif commun est de relever un certain
nombre de défis transverses: réduire le temps d'adaptation à un contexte
nouveau (sources, domaine, langue), en particulier la montée en
puissance des réseaux sociaux, spécifier et développer des fonctions de
haut niveau pour améliorer la productivité d'un professionnel de la
veille, étudier et mettre en place des stratégies pour permettre le
passage à l'échelle des solutions envisagées. Dans le cadre de ce
projet, nous proposons à 3 étudiants de développer un cas d'utilisation
civil de cette plate-forme.

L'objectif de l'ensemble des 3 stages est de créer un démonstrateur
d'application de veille dans le domaine de la géopolitique et de la
géostratégie, à l'usage des entreprises qui souhaitent investir ou
développer leurs ventes dans une région ou un pays, en s'appuyant sur
les technologies mises à disposition par la plate-forme IMM. Plus
concrètement, il s'agit donc de mettre en oeuvre les fonctions de la

plate-forme pour automatiser la collecte d'informations et de documents,
pour ensuite les analyser et produire des synthèses. Les documents sont
collectés sur le web, aussi bien depuis des sites institutionnels que
depuis des réseaux sociaux. La collecte d'information visera plus
particulièrement les textes de lois et les réglementations en cours, le
contexte plus général lié à la culture ou l'histoire du pays (par
exemple l'impact de la loi islamique sur une région particulière), mais
aussi les projets de lois (par exemple les normes en cours d'élaboration
au niveau européen) ainsi que les réactions qu'elles suscitent et les
activités de lobbying autour de ces projets.

On cherchera plus particulièrement à mettre en valeur les capacités
suivantes de la plate forme :

- Recherche d'information multilingue,
- Extraction d'information (entités nommées et relations),
- Collecte et analyse des réseaux sociaux (Le lobbying est une activité
  assez transparente et qui laisse des traces en particulier sur les
  réseaux sociaux),
- Analyse des contenus de vidéos (transcription de journaux télévisés
  par exemple),
- Visualisation innovante des données collectées analysées et indexées.


Vos missions seront les suivantes :
- Vous familiariser avec les outils mis à disposition par la plate-forme
  IMM,
- En collaboration avec l'étudiant des stages 1 et 3, contribuer à la
  spécification d'un prototype d'application de veille géopolitique, et
  en particulier élaborer la spécification fonctionnelle et technique en
  tenant compte de la plate-forme existante.
- Elaborer le modèle d'extraction d'information et en particulier
  définir quelles entités nommées et quelles relations sont déjà
  traitées par la plate-forme IMM et peuvent être réutilisées, quelles
  entités plus spécifiques au domaine de la veille géostratégique sont
  critiques pour réaliser un démonstrateur.
- Sélectionner une partie de ce modèle et enrichir les outils
  d'extraction de la plate-forme (annotation, apprentissage, évaluation
  de la qualité..)
- Collecter des corpus, les traiter pour alimenter le prototype

Le profil recherché : BAC +5, étudiant dans le domaine de l'informatique
avec une spécialisation en traitement automatique des langues, en
recherche d'information ou en apprentissage artificiel pour un stage de
6 mois environ sur le site IRT SYSTEMX à Palaiseau.

Vos Compétences sont :
- Programmation langage orienté objet (Java, C++),
- Capacité à développer et utiliser un framework/middleware (comme
  Apache Camel/ServiceMix)
- Capacité à traiter des corpus (langages perl, python) ou des
  ressources linguistiques en anglais

Vos aptitudes personnelles sont :
- Rigueur, sens des responsabilités
- Bon relationnel, capacités à travailler en collaboration


Référence : CREE_2015_IMM1_03_02_141029
Pour postuler : stages@irt-systemx.fr"
"230","2014-12-01","LIRMM","Montpellier","Vous trouverez ci-dessous la description de deux offres de stages de
Master 2 à diffuser auprès des étudiants en informatique avec une
spécialisation en fouille de textes et traitement automatique de la
langue et intéressés par les applications à la santé.

Les étudiants peuvent faire acte de candidature auprès de Jérôme Azé
(Jerome.Aze@lirmm.fr) et Sandra Bringay (Sandra.Bringay@lirmm.fr).


* Lutte contre le cyber-harcèlement -- Définition de métriques
  permettant d'évaluer l'urgence des messages postés ? *

Contexte

Le ministère de l'éducation nationale a fait de la prévention du
harcèlement entre élèves l'une de ses priorités. Avec l'utilisation
permanente des nouvelles technologies de communication (télé- phones,
réseaux sociaux numériques), le harcèlement entre élèves se poursuit en
dehors de l'enceinte des établissements scolaires. On parle alors de
cyber-harcèlement1. 
Les victimes d'une telle forme de harcèlement peuvent prendre contact
avec l'association Arrêt Demandé en envoyant un email ou un message
posté via Facebook. 
Les modérateurs de l'association traitent les messages au fur et à
mesure de leur arrivée. Sans remettre en cause l'importance des messages
d'alerte reçu par l'association, il est important d'évaluer le ""degré
d'urgence"" de l'alerte afin d'y répondre le plus rapidement et le plus
efficacement possible. 
Actuellement, les modérateurs de l'association réalisent manuellement la
tâche d'analyse des informations reçues (mails ou messages
Facebook). Compte tenu du nombre limité de modérateurs, il est impératif
de pouvoir répartir le plus efficacement possible la charge de travail
que représente la prise en charge d'une demande faite à l'association.

Missions

L'objectif du stage proposé est de pouvoir analyser automatiquement le
contenu de messages postés sur Facebook et de mettre en place une
approche permettant de prédire l'urgence du message. La prédiction devra
être restituée aux modérateurs sous la forme d'un score, mais également
sous la forme d'explications permettant de comprendre les informations
utilisées pour attribuer le score. 
Les principales actions à réaliser dans ce stage sont : 

- collecter, structurer et prétraiter les messages envoyés par les
  personnes victimes de harcèlement ; 

- comparer et combiner différents classifieurs permettant d'associer un
  score (ou une catégorie) à chaque message. Dans un premier temps, la
  boîte à outils Weka 2 sera utilisée pour obtenir rapidement un
  ensemble de classifieurs discrets ; 

- définir une métrique permettant d'évaluer l'urgence associée : 

- à un message (métrique centrée sur le contenu d'un message)

- à l'ensemble des messages envoyés par une personne et également des
  réponses déjà apportées par les modérateurs (métrique centrée sur
  l'individu) 

- adapter la métrique pour prendre en considération des informations
  nouvelles obtenues dans les messages au fur et à mesure des échanges
  (prise en considération du temps)

Une étude bibliographique sera attendue sur les deux aspects suivants :
1) la détection automatique des maladies mentales dans les réseaux
sociaux [6][2][5] ; 2) les méthodes de fouille de données temporelles
appliquées dans les réseaux sociaux [4]. 
À l'issue de cette étude, nous retiendrons un type d'approche de calcul
de score qui sera formalisée, implémentée et évaluée pendant le stage.

Compétences

- traitement semi-automatique de textes libres
- extraction de motifs syntaxiques
- apprentissage de classifieurs
- programmation et outils : Java, Weka, R, Python, Weka

Références

[1] Amayas Abboute, Yasser Boudjeriou, Gilles Entringer, Jérôme Azé,
Sandra Bringay, and Pascal Poncelet. Mining twitter for suicide
prevention. In NLDB 2014, page to be publish, 2014. 
[2] Megan A. Moreno, Lauren A. Jelenchick, Katie G. Egan, Elizabeth Cox,
Henry Young, Kerry E. Gannon, and Tara Becker. Feeling bad on facebook :
depression disclosures by college students on a social networking
site. Depression and Anxiety, 28(6) :447-455, 2011. 
[3] Loïc Paulevé, Gheorghe Craciun, and Heinz Koeppl. Dynamical
Properties of Discrete Reaction Networks. Journal of Mathematical
Biology, 69(1) :55-72, 2014. 
[4] Marian-Andrei Rizoiu, Julien Velcin, and Stéphane Lallich. How to
use temporal-driven constrained clustering to detect typical
evolutions. International Journal on Artificial Intelli- gence Tools,
23(4), 2014. 
[5] Adam Sadilek, Henry Kautz, and Vincent Silenzio. Modeling spread of
disease from social interactions. In In Sixth AAAI International
Conference on Weblogs and Social Media (ICWSM, 2012. 
[6] Xinyu Wang, Chunhong Zhang, Yang Ji, Li Sun, Leijia Wu, and Zhana
Bao. A depression detection model based on sentiment analysis in
micro-blog social network. 7867 :201-213, 2013. 





* Prévention du risque de suicide via les réseaux sociaux ? -- Détection
  de points de rupture dans le comportement des personnes à risques *

Contexte 

Le suicide est l'acte délibéré consistant à mettre fin à sa propre
vie. Le suicide révèle de graves problèmes personnels, mais est
également souvent le reflet d'une détérioration du contexte social dans
lequel vit un individu. Les facteurs de risques sont multiples et
complexes (bouleversements dans les relations personnelles, harcèlement,
addiction, chômage, dépression clinique et bien d'autres formes de
maladie mentale, etc.). Selon un rapport très récent et alarmant de
l'OMS (4 Septembre 2014)1, une personne dans le monde se suicide toutes
les 40 secondes. On estime à 804 000 le nombre de suicides survenus dans
le monde en 2012, ce qui représente un taux de suicide global
standardisé selon l'âge de 11,4 pour 100 000 habitants (15 chez les
hommes et 8 chez les femmes). 
Dans le cadre du Plan d'action pour la santé mentale 2013-2020, les
états membres de l'OMS se sont engagés à atteindre la cible mondiale
visant à réduire de 10%% les taux de suicide dans les pays d'ici 2020.

Missions 

Dans le cadre d'un TER de M2Pro, une approche permettant d'aller
identifier sur Twitter des messages à risques a été conçue et mise en
oeuvre par notre équipe [1]. Cette identification repose, entre autre,
sur la prévalence de certains mots dans les tweets de personnes étant
passées à l'acte. À partir d'un ensemble de tweets ""suspects"",
l'application développée dans le cadre de ce TER, permet de prédire si
l'auteur d'un tweet suspect risque ou non de passer à l'acte (prédiction
binaire). 

L'objectif de ce stage est de reprendre les travaux existants et de les
améliorer à différents niveaux : 

- définir un score permettant d'évaluer la ""probabilité de passage à
  l'acte"", plus finement que sur la base d'une simple prédiction binaire
  en combinant les probabilités de prédiction de différents classifieurs;

- concevoir et mettre en place une place une approche permettant de
  détecter des points de rupture dans le comportement ou dans le
  discours d'un individu. 

La notion de point de rupture correspond à la notion de transition à
caractère définitif entre deux états mentaux, avec dégradation du nouvel
état mental atteint. 

Ces changements d'états peuvent être associés à des changements de style
d'écriture, des changements de comportements : augmentation ou
diminution de la fréquence des messages, changement des heures d'envoi,
changement des lieux d'envoi, réduction ou augmentation du nombre
d'amis...

Les différents états possibles d'un individu devront être caractérisés
en accord avec les spécialistes du domaines (psychiatres ou
psychologues). Une modélisation de ces états et des changements entre
ces états pourra alors être proposée. L'étude des données réelles
permettra d'associer du vocabulaire, des comportements ... à ces
différents états et également d'apprendre les probabilités de transition
entre ces états. 
La définition d'un tel modèle spécifiquement orienté vers les médias
sociaux permettra d'affiner la détection des individus à risque. 
Une étude bibliographique sera attendue sur les deux aspects : 1) la
détection automatique des personnes suicidaires via les réseaux sociaux;
[2],[4], [5] 2) les méthodes de détection de changement d'état [3]. À
l'issu de cette étude, nous retiendrons un type d'approche qui sera
améliorée, formalisée, implémentée et évaluée pendant le stage.

Compétences 
- traitement semi-automatique de textes libres
- apprentissage de classifieurs
- programmation et outils : Java, Weka, R, Python, API Twitter

Références 
[1] Amayas Abboute, Yasser Boudjeriou, Gilles Entringer, Jérôme Azé,
Sandra Bringay, and Pascal Poncelet. Mining twitter for suicide
prevention. In NLDB 2014, page to be publish, 2014. 
[2] Megan A. Moreno, Lauren A. Jelenchick, Katie G. Egan, Elizabeth Cox,
Henry Young, Kerry E. Gannon, and Tara Becker. Feeling bad on facebook :
depression disclosures by college students on a social networking
site. Depression and Anxiety, 28(6) :447-455, 2011. 
[3] Loïc Paulevé, Gheorghe Craciun, and Heinz Koeppl. Dynamical
Properties of Discrete Reaction Networks. Journal of Mathematical
Biology, 69(1) :55-72, 2014. 
[4] Adam Sadilek, Henry Kautz, and Vincent Silenzio. Modeling spread of
disease from social interactions. In In Sixth AAAI International
Conference on Weblogs and Social Media (ICWSM, 2012. 
[5] Xinyu Wang, Chunhong Zhang, Yang Ji, Li Sun, Leijia Wu, and Zhana
Bao. A depression detection model based on sentiment analysis in
micro-blog social network. 7867 :201-213, 2013."
"231","2014-12-01","Lattice/IRIT","Paris","* Descriptif rapide
-----------------------

Le LATTICE, en collaboration avec l'IRIT, propose un stage de M2 sur
l'analyse des paramètres d'un modèle de réseau de neurones appliqué à
l'acquisition de restrictions de sélection. Un descriptif détaillé en
anglais figure ci-dessous.

Le stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à
10 mn du métro Mairie de Montrouge et à 5 mn de l'arrêt du Tram ligne 3
« Jean Moulin »). Il sera co-encadré par Thierry Poibeau et Marco
Dinarelli au LATTICE et par Tim van de Cruys à l'IRIT (les échanges avec
Toulouse se feront principalement par Skype).

Le stage est prévu pour une durée de 6 mois à compter de mars ou avril
2014. Il donnera obligatoirement lieu à la signature d'une convention de
stage et sera rémunéré suivant les règles en vigueur (523 euros / mois).

* Profil recherché 
-----------------------

M2 en informatique 
Bonne connaissance de python ou, à défaut, de perl
Intérêt pour le traitement automatique des langues
Bon niveau d'anglais (écrit / oral)
Des connaissances en matière de réseau de neurones seraient évidement un
plus

Pour candidater : envoyer un mail avec un CV et une lettre de motivation
à thierry.poibeau@ens.fr


* Descriptif détaillé
-----------------------


An Exploration of a Neural Network Model's Parameters for Selectional
Preference Acquisition

Predicates often have a semantically motivated preference for particular
arguments [1]. Compare for example the sentences in (1) and (2).

(1) The vocalist sings a ballad.
(2) The exception sings a tomato.

While both sentences are grammatically correct, the second sentence is
clearly ill-formed. This preference of a verb for particular arguments
is known as the verb's selectional preference. Recently, a neural
network approach has been shown to perform well on the modeling of
selectional preferences [2]. However, many parameters remain to be
investigated. First of all, a neural network's parameters may be
initialized in a number of different ways. For example, the parameters
might be initialized randomly, or they may be initialized using
previously constructed word embeddings. Secondly, the neural network's
architecture leaves ample space for experiments. The neural network's
architecture might be more `deep' or more `shallow', the size of the
network's layers may be varied, and certain parameters within the
network might be shared.

This internship will investigate the influence of different network
parameters on the performance of a neural network for the modeling of
selectional preferences. The student will adapt and train an existing
neural network implementation for selectional preference acquisition,
and examine the role of various model parameters for the network's
performance.

References:

[1] Van de Cruys, Tim ; Rimell, Laura ; Poibeau, Thierry and Korhonen,
Anna. 2012. Multi-way Tensor Factorization for Unsupervised Lexical
Acquisition. In Proceedings of the 24th International Conference on
Computational Linguistics (COLING), Mumbai, India.

[2] Van de Cruys, Tim. 2014. A Neural Network Approach to Selectional
Preference Acquisition. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing (EMNLP), pp. 26-35,
Doha, Qatar. Association for Computational Linguistics."
"232","2014-12-01","Xerox Research Centre Europe","Grenoble","Title: Identification of discontinuous variants of compound terms

Duration 5-6 months

Proposers:

Salah Aït-Mokhtar

Vassilina Nikoulina

Start date: January-February 2015

Description

The main theme of the internship is the identification of terms and
concepts in domain-specific texts, with a focus on medical texts in the
context of the EURECA project (http://eurecaproject.eu/). We have a
dictionary-based term identification system capable of identifying
occurrences of terms in free texts, including non-listed term variants
(e.g. inflected or misspelled terms). The task of the internship will
consist in contributing to the extension of types of variations that the
term identifier can handle. In particular, the intern will work on the
identification and normalization of discontinuous compound terms that
are involved in specific syntactic structures (e.g. coordination), using
distant supervision with existing domain terminologies. An example of
discontinuous compound terms is ""abdominal distention"" in the expression
""abdominal bloating or distention"".

Requirements

The ideal candidate is a student (MSc or PhD) in computational
linguistics, or computer science with a good background in NLP. S/he has
a good knowledge of syntactic structures and parsing. Good programming
skills, preferably in Java, are also required. Prior experience in NLP
for the healthcare domain or in terminologies/ontologies is a plus.

During the internship the candidate will acquire a significant knowledge
and practice in the use of hybrid methods for term identification,
including distant supervision based on rich terminologies and
ontologies. As well, s/he will work closely with researchers and
engineers in an international research environment.

You can find more details about this offer at

http://www.xrce.xerox.com/About-XRCE/Internships/Identification-of-discontinuous-variants-of-compound-terms"
"233","2014-12-03","Lattice","Montrouge","Proposition de stage M2 recherche en informatique/TAL au Lattice
(http://www.lattice.cnrs.fr) à Montrouge (tout près de Paris)


Reconnaissance automatique des chaînes de coréférences

La reconnaissance des chaînes de coréférences dans les textes,
c'est-à-dire des portions de textes qui réfèrent à une même entité, est
une tâche importante du TAL. Elle a des incidences sur de nombreuses
autres tâches, comme la recherche et l'extraction d'information, le
résumé automatique, etc. Cette tâche a fait l'objet de nombreux
challenges mais, faute de données de référence en français, ils
portaient jusqu'à présent principalement sur des textes en anglais. L'an
dernier, la diffusion du corpus ANCOR (ANaphore et Coréférence dans les
Corpus ORaux, cf. Lefeuvre et al. 2014), constitué d'un ensemble de
transcriptions du français parlé annotées en coréférences, a permis de
lancer des premières expériences sur le français. Elles ont donné lieu à
un premier système, CROC (Coreference Resolution for Oral Corpus),
entraîné par apprentissage automatique sur ANCOR (Désoyer at al. 2015).
Mais ce système est encore rudimentaire : il fait l'hypothèse que les
mentions d'entités ont été préalablement reconnues dans les textes et se
contente donc de prédire leur regroupement en entités coréférentes. Pour
enrichir et améliorer ce système, plusieurs travaux sont envisagés :

- reconnaître automatiquement les mentions référentielles, qui
  coïncident plus ou moins avec les groupes nominaux présents dans les
  textes,

- reprendre les expériences qui ont donné lieu à CROC pour essayer
  d'améliorer ses performances.

La méthodologie employée fera dans tous les cas appel à de
l'apprentissage automatique supervisé (méthodes de classification ou
d'annotation).

Compétences requises :

- stage de niveau M2 en informatique ou en ingénierie linguistique ou
  école d'ingénieur,

- compétences en informatique : programmation, langage de script,
  manipulation de corpus,

- intérêt pour le Traitement Automatique des Langues,

- des compétences en apprentissage automatique seraient un plus.

Références :

Désoyer A, Landragin F, Tellier I, Lefeuvre A, Antoine J-Y, ""Les
coréférences à l'oral : une expérience d'apprentissage automatique sur
le corpus ANCOR"", à paraître dans TAL en 2015.

Landragin F, Schnedecker C (Eds.) ""Les chaînes de référence"", Langages
195, numéro de septembre 2014.

Lefeuvre A, Antoine J-Y, Schang E, ""Le corpus ANCOR_Centre et son outil
de requêtage : application à l'étude de l'accord en genre et en nombre
dans les coréférences et anaphores en français parlé"", Actes 4éme
Congrès Mondial de Linguistique Française (CMLF 2014), 2014.


Le stage peut durer de 4 à 6 mois au sein du Lattice, à partir de
février/mars 2015. Il sera co-encadré par Frédéric Landragin, Isabelle
Tellier (http://www.lattice.cnrs.fr/sites/itellier/) et Marco Dinarelli,
et sera financé au tarif stage de 435 euros mensuels.

Envoyer CV + lettre de motivation à frederic.landragin@ens.fr,
isabelle.tellier@univ-paris3.fr et marco.dinarelli@ens.fr"
"234","2014-12-08","LIA","Avignon","------------------------------------------------------------------------

Stage recherche M2 : Modèles connexionnistes pour la génération 
automatique dans le cadre de l'interaction vocale

Durée : 6 mois
Démarrage : février-mars 2015
Lieu : Laboratoire Informatique d'Avignon
Encadrants: Bassam Jabaian, Stéphane Huet et Fabrice Lefèvre

Description du stage :
Les systèmes d'interactions vocales utilisés dans des applications comme
la réservation de billets d'avion ou d'hôtels, ou bien encore le
dialogue avec un robot, font intervenir plusieurs composants. Parmi
ceux-ci figurent le module de génération de texte qui produit la réponse
du système en langue naturelle à partir d'une représentation sémantique
interne créée par le gestionnaire de dialogue.

Les systèmes de dialogue actuels intègrent des modules de génération 
basés sur des règles écrites à la main à partir de patrons.
ex : confirm(type=$U, food=$W,drinks=dontcare) -> Let me confirm, you are 
looking for a $U serving $W food and any kind of drinks right ?

Ces modules gagneraient à se baser sur des méthodes d'apprentissage 
automatique afin de faciliter la portabilité des systèmes de dialogue 
vers d'autres tâches et améliorer la diversité des échanges générés. 
Parmi les méthodes d'apprentissage automatique, figurent les réseaux de 
neurones qui ont vu un regain d'intérêt depuis l'utilisation du « /deep 
learning/ ». Ces réseaux de neurones ont déjà été employés par Google 
dans une tâche similaire de génération de description d'images 
(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html). 
L'objectif de ce stage est d'étudier l'utilisation de ces modèles dans 
le cadre de l'interaction vocale.

Si un intérêt pour l'apprentissage automatique et le traitement de la
langue naturelle est souhaitable, il est attendu surtout du stagiaire de
bonnes capacités en développement logiciel.

Pour candidater : envoyer un mail avec un CV et une lettre de motivation 
à bassam.jabaian@univ-avignon.fr"
"235","2014-12-08","LIFO","Orléans","Proposition de stage M2 recherche en Informatique/Mathématiques
Appliquées au LIFO (http://www.univ-orleans.fr/lifo/) à Orléans.

=> Possibilités de poursuite en thèse (Informatique) <=

Titre du stage : Apprentissage d'espaces prétopologiques pour 
l'extraction de taxonomies lexicales

Le sujet du stage portera sur l'extraction de connaissances structurées,
c'est-à-dire modélisées sous forme de graphes (arbres, DAG ou réseaux
quelconques). Étant donné un ensemble partiel de relations déjà établi,
l'objectif est alors d'apprendre -- dans un contexte semi-supervisé --
les relations cachées structurant la globalité des éléments constitutifs
de la connaissance. Nous avons développé une nouvelle approche (LPS)
consistant à apprendre un modèle de propagation à partir de relations de
voisinages et nous avons montré que, dans le contexte décrit
précédemment, cette méthode permet d'atteindre des structurations
complexes jusqu'ici non accessibles par des méthodes classiques
d'apprentissage (statistique et/ou symbolique).

L'objectif du stage sera d'exploiter la méthode LPS décrite ci-dessus
dans un formalisme d'apprentissage différent à savoir l'apprentissage
d'une règle logique de combinaison de voisinages par une approche
gloutonne. Nous envisagerons différentes stratégies de construction
d'une DNF positive (non nécessairement linéaire) en étudiant les
propriétés des opérateurs logiques par rapport aux combinaisons de
structures qu'ils induisent.

L'efficacité de cette nouvelle stratégie d'apprentissage d'un espace
prétopologique sera étudiée tant en terme de coût d'apprentissage qu'en
terme de qualité des structurations induites, sur une série de
taxonomies dans des domaines génériques et spécialisés.


Références :

P. Velardi, S. Faralli, R. Navigli: OntoLearn Reloaded: A Graph-Based
Algorithm for Taxonomy Induction. Computational Linguistics 39(3):
665-707 (2013)

G. Cleuziou, D. Buscaldi, V. Levorato, G. Dias : A pretopological
framework for the automatic construction of lexical-semantic structures
from texts.CIKM 2011: 2453-2456

Z. Kozareva, E. H. Hovy: A Semi-Supervised Method to Learn and Construct
Taxonomies Using the Web. EMNLP 2010: 1110-1118

Ch. Largeron, S. Bonnevay: A pretopological approach for structural
analysis. Inf. Sci. 144(1-4): 169-185 (2002)


Compétences requises :

- stage de niveau M2 ou école d'ingénieur en informatique ou
  mathématiques appliquées

- compétences en : programmation, algèbre (espaces vectoriels, théorie
  des ensembles)

- intérêt pour la fouille de textes (Recherche d'Information) et
  l'apprentissage automatique.

Le stage peut durer de 4 à 6 mois au sein du LIFO, dans l'équipe CA à
partir de février/mars 2015. Il sera co-encadré par Guillaume Cleuziou
et Vincent Levorato et sera financé au tarif stage de 435 euros
mensuels.

Envoyer CV + lettre de motivation à guillaume.cleuziou@univ-orleans.fr
et vlevorato@cesi.fr."
"236","2014-12-08","LIPN & Lattice","Paris","---------------------------------------------------------
     PROPOSITION DE STAGE DE MASTER RECHERCHE REMUNERE
---------------------------------------------------------

Ce stage de Master se déroulera au sein du PRES Sorbonne Paris Cité 
entre le LIPN (http://www-lipn.univ-paris13.fr/), dans l'équipe 
«Représentation des Connaissances et Langage Naturel» (RCLN) et le 
LATTICE (http://www.lattice.cnrs.fr/).

Ce stage est rémunéré grâce au soutien du laboratoire d'excellence
""Empirical Foundations of Linguistics"" (labex EFL,
http://www.labex-efl.org/). Il fait partie d'un projet plus large sur la
découverte de patrons lexico-grammaticaux, mené en commun entre le LIPN
et le LATTICE dans le cadre du labex EFL (axe «Analyse sémantique
computationnelle » (http://www.labex-efl.org/?q=fr/recherche/axe5). Le
sujet est décrit ci-dessous.

Profil recherché : étudiant Master Recherche en TAL ou en informatique 
(avec compétences en TAL).

Les candidats doivent envoyer leur candidature (CV, Lettre de
motivation, relevés de notes,...) le plus rapidement possible par mail à
Thierry.Charnois@lipn.univ-paris13.fr

Ce stage sera déroulera à Paris, et sera co-encadré par Thierry Poibeau
(LATTICE) et Thierry Charnois (LIPN), Dominique Legallois (Crisco,
université de Caen) participera également à l'encadrement.

*SUJET : Caractérisation des genres discursifs par la méthode des motifs
séquentiels*


L'objectif de ce stage de Master 2 est l'analyse d'un genre discursif
particulier, le roman policier. Le point principal consistera à
identifier les motifs séquentiels spécifiques de ce genreen le
comparantau genre romanesque dit ""sérieux"". Les motifs sont des patrons
lexico-grammaticaux, plus abstraits que les segments répétés ou n-grams.
Ils sont de taille variable, et peuvent comporter des ""gaps"" entre les
différents éléments. Ils sont extraits de façon non supervisée.

L'approche défendue, en privilégiant des unités syntagmatiques, se veut
complémentaire de laperspective morpho-syntaxique (Malrieu et Rastier
2001) qui reste, dans le domaine de la caractérisation générique, la
méthode traditionnellement adoptée après Biber (1991).

L'extraction des motifs sera réalisée à partir de l'outil SDMC --
http://sdmc.greyc.fr -- (des fonctionnalités supplémentaires pourront
être proposées et implémentées durant le stage) ; les principales
réflexions du stagiaire porteront sur les différences de granularité des
motifs, sur la pertinence de certaines annotations sémantiques
possibles, ou sur la pertinence d'une catégorisation morpho-syntaxiques
plus fines des unités.

Malrieu D. et Rastier F. (2001) Genres et variations morphosyntaxiques,
/Traitements automatiques du langage/, 42, 2, pp. 547-577.

Biber, D. (1991). /Variation Across Speech and Writing/. Cambridge 
University Press, Cambridge, 1991.

Longrée D. et Mellet S. (2013). « Le motif : une unité phraséologique
englobante ? Étendre le champ de la phraséologie de la langue au
discours », /Langages/189 (D. Legallois & A. Tutin, coord.), p.68-80

Quiniou S. ; P. Cellier ; T. Charnois et D. Legallois (2012). « What 
About Sequential Data Mining Techniques to Identify Linguistic Patterns 
for Stylistics? ». Actes de la conférence CICLING. Springer."
"237","2014-12-08","Lattice","Montrouge","Algorithme alternatif pour le calcul des probabilités dans des champs
aléatoires conditionnels (CRF)

Les champs aléatoires conditionnels (CRF) sont actuellement un des
modèles les plus performants dans les tâches d'étiquetage de séquences
et d'analyse syntaxique [1,2]. Malgré des améliorations récentes [3],
apprendre ce modèle reste relativement coûteux, notamment à cause des
algorithmes utilisés pour le calcul des probabilités du modèle.
Cependant dans plusieurs tâches de Traitement Automatique de Langues
(TAL), l'information prédite automatiquement a une annotation assez
creuse. Ceci suggère des algorithmes alternatifs qui prennent en compte
cette caractéristique pour réduire la complexité computationnelle dans
les calculs des probabilités des CRF.

Au cours de ce stage le candidat développera un algorithme alternatif
pour le calcul des probabilités des modèles CRF. Ceci apportant deux
avantages. D'une part la possibilité d'entraîner un modèle CRF plus
rapidement. D'autre part cette réduction du coût computationnel
permettra d'entraîner des modèles plus complexes, ce qui pourra mener à
de meilleurs résultats sur une tâche donnée. Le candidat expérimentera
l'algorithme développé sur une tâche de TAL spécifique.

[1] Lavergne, Thomas and Cappé, Olivier and Yvon, François. 2010
Practical Very Large Scale CRFs.  Proceedings of the 46th Annual Meeting
of the Association for Computational Linguistics (ACL)

[2] Jenny Rose Finkel, Alex Kleeman, and Christopher D. Manning. 2008.
Efficient, Feature-based, Conditional Random Field Parsing.  Proceedings
of the 46th Annual Meeting of the Association for Computational
Linguistics (ACL)

[3] Naoaki Okazaki. 2007.  CRFsuite: a fast implementation of
Conditional Random Fields (CRFs).

Profil recherché :
- stage de niveau M2 en informatique ou école d'ingénieur,
- compétences en informatique : programmation (C), langage de script
  (lua), manipulation de corpus,
- intérêt pour le Traitement Automatique des Langues,
- compétences en apprentissage automatique avec modèles probabilistes.

Le stage peut durer de 4 à 6 mois au sein du Lattice
(http://www.lattice.cnrs.fr), à partir de mars/avril 2015. Il sera
encadré par Marco Dinarelli (www.marcodinarelli.it) et sera financé
suivant les règles en vigueur.
Envoyer CV + lettre de motivation à marco.dinarelli@ens.fr"
"238","2014-12-08","Syllabs","Paris","------------------------------------------------------------------------
Offre de stage : Développeur Python (H/F)
------------------------------------------------------------------------

Syllabs est une start-up innovante dans le domaine de la sémantique et
du web. Grâce à un gros effort de R&D, nous avons développé des
technologies de collecte, d'analyse et de génération de données
textuelles sur le Web.

La génération automatique de données textuelles consiste à transformer
une base de données en textes pour, par exemple, générer des articles de
presse (comptes rendus de rencontres sportives, rapports de tremblements
de terre...), des descriptifs de produits (appareils photo,
chaussures...) ou de lieux (destinations touristiques, hôtels...), etc.
Les utilisateurs de notre outil de génération sont nos ingénieurs
linguistes qui, via des fichiers de règles et de données structurées,
engagent le processus de génération de textes. Leurs besoins évoluent
régulièrement, au fur et à mesure des demandes de nos clients.
Possibilités d'embauche à la fin du stage.

------------------------------------------------------------------------
Description du stage
------------------------------------------------------------------------

Le stage s'inscrit dans la continuité des travaux effectués sur notre 
technologie de génération et a un objectif triple :

- L'outil doit être enrichi de nouvelles fonctionnalités afin
  d'augmenter les capacités de notre génération,
- L'automatisation des tâches les plus redondantes des linguistes sera
  menée afin d'orienter l'outil vers une autonomie et une flexibilité
  accrues,
- Aborder la mise en place d'une version simplifiée de l'outil de
  génération, dotée d'une interface intuitive et fonctionnelle.

Les tâches concernent principalement :
  - Prendre en main l'outil de génération existant et son code,
  - Interagir avec les utilisateurs afin de bien identifier leurs
    besoins et usages,
  - Mener à bien le développement de nouvelles fonctionnalités,
  - Adapter l'outil à l'autonomie de la génération automatique de
    textes,
  - Redéfinir les spécifications d'une version allégée de l'outil, et
    éventuellement l'implémenter au travers d'une interface graphique.

Ces travaux seront encadrés par l'ingénieur R&D ayant développé l'outil
existant.

------------------------------------------------------------------------
Profil recherché
------------------------------------------------------------------------

Maîtrise de la programmation Python
Autonomie et capacité à travailler en équipe
Goût pour la compilation et l'optimisation de code
Maîtrise de Linux
Notions en interface utilisateur et interface Web
Anglais technique, connaissance d'autres langues appréciée
Expérience en Traitement Automatique des Langues souhaitée

------------------------------------------------------------------------
Divers
------------------------------------------------------------------------

Durée : 6 mois

Bonne ambiance et équipe technique de grande qualité.

Stage conventionné, rémunération supérieure à la rémunération minimale +
tickets resto + remboursement à moitié du passe Navigo.

Lieu de travail : 26 rue Notre-Dame-de-Nazareth, 75003 Paris

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en 
indiquant dans l'objet du mail « Stage generation »."
"239","2014-12-11","LIDILEM","Grenoble","Commanditaire : Thomas Lebarbé (LIDILEM - U. Grenoble - Alpes)
Lieu : Université de Grenoble ou MSH-Alpes
Compétences requises : Ingénieur de développement Web
Durée du stage : 4 mois
Rémunération : gratification réglementaire (désolé de ne pouvoir faire
mieux)

Contexte :
Le domaine des humanités numériques est en plein essor depuis quelques
années mais présente encore la faiblesse d'être peu outillé pour la
production de sources textuelles (transcription de manuscrits,
enrichissement scientifique, annotation critique, intellectuelle,
etc.). L'université Stendhal s'est engagée depuis plusieurs années dans
un certain nombre de projets de valorisation de patrimoines littéraires
et développe des collaborations avec différentes universités aussi bien
au niveau national qu'au niveau international. Le projet de stage
s'inscrit dans une collaboration entre l'université Stendhal - Grenoble
Alpes et l'Université Paris VII.

Description du stage :
Le stage se décompose en deux parties :

1/ Développement d'un environnement web de production WYSIWYM (what you
   see is what you mean). Etant données une grammaire (DTD) et une
   feuille de style (CSS), il s'agit de donner un environnement de
   production de documents XML qui à la fois accompagne et contraigne le
   producteur : accompagner avec une mise en forme qui libère
   l'utilisateur des contraintes techniques et contraindre en pilotant
   la production par le biais de la grammaire.
2/ Développement d'une plateforme encapsulant l'environnement de
   production. L'objectif de l'environnement de production est de
   fournir à des équipes de recherche comme des équipes pédagogique, de
   travailler de manière collaborative autour de projets distincts. La
   plateforme devra donc permettre de gérer des utilisateurs (avec des
   rôles), des projets, des fonds.

Il ne s'agit pas de développer ces deux éléments ex nihilo, mais
éventuellement de s'appuyer sur des outillages existants pour les
adapter aux besoins et à la littératie numériques des utilisateurs
finaux.

Candidatures :
Les candidatures doivent être envoyées par mail à
thomas.lebarbe@u-grenoble3.fr avant le 31 janvier 2014 et feront l'objet
d'un accusé de réception dans les deux jours ouvrés

Le dossier de candidature contiendra :
- un cv
- une lettre de motivation
- éventuellement la recommandation d'un enseignant

Le cas échéant, nous pourrons demander un entretien téléphonique ou en
visioconférence.

Le début et la durée du stage pourront être modulée en fonction du
calendrier de formation du candidat sélectionné.

Thomas LEBARBÉ, Pr. 
http://www.u-grenoble3.fr/"
"240","2014-12-11","LIMSI","Orsay","Proposition de stage M1 ou M2 au LIMSI-CNRS

Responsable du stage : Marianna Apidianaki

Titre : Analyse sémantique de traductions automatiques

La qualité des traductions automatiquement produites ne cesse de
s'améliorer ces dernières années et les systèmes de Traduction
Automatique disponibles en ligne sont utilisés de manière régulière par
un nombre croissant d'utilisateurs. Néanmoins des problèmes sont
toujours repérés dans les textes traduits à des niveaux différents,
allant de la morphologie et la grammaire jusqu'aux choix lexicaux et
l'ordre des mots. Parmi ces sources d'erreurs la sélection lexicale est
identifiée comme la plus importante, ayant un impact fort sur
l'adéquation et la fluidité des textes traduits (Popovic, 2012;
Wisniewski et al., 2013).

L'objectif de ce stage est d'analyser d'un point de vue sémantique les
choix lexicaux effectués par les systèmes de Traduction Automatique
actuels. Cette analyse sera basée sur des données utilisées dans le
domaine de la Traduction Automatique et sera enrichie par des
ressources, des méthodes et des outils habituellement utilisés pour
l'analyse sémantique.

Le stage est rémunéré et se déroulera au LIMSI-CNRS (Orsay) dans le
groupe Traitement du Langage Parlé (TLP, http://www.limsi.fr/tlp/mt/).


Profil : 
- Master 1 ou 2 en Traitement Automatique des Langues ou Informatique
- bonnes compétences en programmation (Perl et/ou Python, connaissances
  en Java souhaitables mais pas nécessaires)
- expérience avec des systèmes de Traduction Automatique n'est pas
  nécessaire mais serait un plus

Durée : 4 à 6 mois (plein temps)
Date de début : à partir de début février 2015, selon disponibilité
Gratification CNRS standard : 536¤ + 50¤ (frais de transport) =
  586¤/mois de stage
Lieu : LIMSI-CNRS, Groupe TLP, rue John von Neumann, Université Paris
  Sud, 91403 Orsay Cedex

Contact: Marianna Apidianaki (marianna@limsi.fr)"
"241","2014-12-15","LIMSI","Orsay","Proposition de stage M1 ou M2 au LIMSI-CNRS

Responsables du stage : Aurélie Névéol et Xavier Tannier

Titre : Analyse temporelle des dossiers électroniques patient.

Le contenu et l'ambition du stage pourront être modulés en fonction du
niveau d'étude et de la durée du stage du candidat.

Contexte
L'analyse temporelle de textes d'information a pour but général de mieux
localiser dans le temps les événements décrits dans ces textes, et donc
d'alimenter de façon plus précise des moteurs de recherche ou des outils
d'extraction d'information. Pour cela, la première étape est de détecter
correctement les expressions temporelles de ces textes. Ces expressions
temporelles peuvent être des dates absolues, c'est-à-dire que l'on peut
placer sans ambiguïté sur l'axe des temps (par exemple, le 14 janvier
2008), mais aussi des dates relatives, qui nécessitent une phase de
résolution ou de normalisation (par exemple, le 14 janvier dernier, dans
6 semaines). Dans le cadre du dossier électronique patient, des
expressions temporelles propres au domaine de spécialité, le domaine
médical, peuvent également être rencontrées (par exemple, à 18 SA, à
j+1). Une deuxième étape consiste à détecter les évènements liés aux
expressions temporelles.  Dans le domaine médical, il s'agira
typiquement de maladies, de traitements médicamenteux, de procédures
chirurgicales, etc.

Les techniques d'analyse temporelle des textes ont fortement progressé
ces dernières années, mais s'attachent en général au domaine
journalistique et particulièrement au cadre des dépêches. Nous
souhaitons étudier un autre domaine de spécialité, le domaine médical,
ainsi qu'un type de document particulier, le dossier électronique
patient. Nous nous intéressons au repérage automatique des expressions
temporelles et des évènements auxquels elles se rapportent dans les
documents cliniques afin de construire automatiquement une chronologie
médicale pour chaque patient à l'échelle d'un document, puis d'un
dossier complet. L'un des objectifs cliniques de ce travail est de
faciliter les études rétrospectives réalisées par des cliniciens en
permettant une visualisation et une comparaison automatiques des
parcours de soin de différents patients, ainsi qu'une comparaison des
parcours de soin des patients avec les protocoles de référence en
vigueur.

Le travail s'appuiera sur un corpus de documents cliniques annoté en
expressions temporelles normalisées selon la norme TimeML, ainsi que sur
des outils d'analyse temporelle et d'analyse des documents cliniques en
français développés au sein du LIMSI.

Travail à réaliser :

Selon le niveau d'étude de la personne choisie, nous pourrons nous
intéresser à une ou plusieurs des problématiques suivantes :
- Utilisation et adaptation d'outils d'extraction d'évènement
  biomédicaux dans les documents cliniques
- Extraction automatique de relations temporelles dans les documents
  cliniques
- Réconciliation des expressions temporelles issues de documents
  différents
- Création d'une ligne temporelle pour représenter l'historique d'un
  patient
On utilisera un corpus de plusieurs centaines de documents cliniques
désidentifiés en français.

Profil :
- Master1, Master 2 (professionnel ou recherche) en traitement
  automatique de la langue ou informatique, école d'ingénieur
- Bonnes compétences en programmation (Perl et/ou Python, connaissances
  en Java souhaitables mais pas nécessaires)
- Des connaissances en terminologie biomédicale et/ou en apprentissage
  automatique seront un plus.

Durée : 4 à 6 mois (plein temps)
Rémunération : Gratification CNRS standard : 536¤ + 50¤ (frais de
transport) = 586¤/mois de stage
Lieu : LIMSI-CNRS, Groupe ILES, rue John von Neumann, Université Paris
Sud, 91403 Orsay Cedex

Contacts :
Aurelie.Neveol[at]limsi.fr
Xavier.Tannier[at]limsi.fr"
"242","2014-12-15","Velvet Consulting","Paris","*Sujet de stage*
Le Big Data est aujourd'hui une réalité pour nos clients. Leurs données
sont de plus en plus volumineuses, variées et volatiles. Les approches
classiques demeurent inefficaces pour traiter ces données. *Velvet
Consulting* travaille sur des approches innovantes pour répondre à ce
besoin. Le stage que nous vous proposons s'inscrit dans ce cadre et
porte sur la mise en place d'un système d'analyse de gros volume de
données textuelles dans un environnement Big Data.

*Contexte*
Système de recommandation fonctionnant avec des techniques
collaboratives classiques.

*Problématiques*
- Comment migrer ce système en mode Big Data ?
- Quel est l'apport des données textuelles dans le processus de
  recommandation ?

*Étapes*
- Étape 1 : État de l'art et amélioration d'un système de recommandation
  existant ;
- Étape 2 : Migration du système dans un environnement Big Data
  (conception et implémentation) ;
- Étape 3 : Évaluation des performances et comparaison des résultats.

*Profil recherché*
Étudiant en dernière année d'École d'Ingénieur ou de Master 2 (BAC+5)
dans le domaine de l'informatique avec des compétences en traitement
automatique des langues et intelligence artificielle.

*Compétences*
- Programmation / Technologie : Java-Eclipse, XML, SQL, GATE
- O/S : Linux, Shell, Windows Serveur
- Capacité à traiter des corpus ou des ressources linguistiques en
  anglais
- Compétences en Big Data (Hadoop, Hive, Impala, Flume) appréciées

*Qualités personnelles*
- Rigueur, sens des responsabilités
- Bon relationnel, capacité à travailler en équipe

*Encadrant *
Ph D Computer Science - Direction Data Mining

*Conditions*
Type de stage : stage de fin d'études / pré-embauche
Début du stage : entre Janvier et Avril 2015
Durée : entre 6 et 9 mois
Rémunération : 1000 nets / mois + Tickets Restaurant (9 euros / jour) +
50 % Carte Navigo
Lieu : 10-12 rue du Général Foy 75008 Paris

*Candidature*
*CV & lettre de motivation* à Stéphane Martignon, Responsable
Recrutement - smartignon@velvetconsulting.com *avant le 31 Décembre
2014*


*A propos de Velvet Consulting*

Velvet est un cabinet de conseil en stratégie marketing.  Nos
consultants accompagnent nos clients sur l'ensemble de leurs projets
Marketing, de la définition de la stratégie à sa mise en oeuvre
opérationnelle et technique.

Notre Direction Datamining aide nos clients à maximiser l'exploitation
de leurs données et à renforcer rapidement l'efficacité du marketing
client.  Nous combinons une expertise datamining, en termes d'analyses &
de modélisations statistiques complexes et une expertise marketing afin
de conseiller les directions marketing grâce à nos analyses
opérationnelles.

Nous vous proposons d'intégrer une structure à taille humaine qui vous
permettra de vous épanouir professionnellement & personnellement dans un
contexte dynamique & agréable. Vous développerez vos compétences
textmining, statistiques et marketing grâce à des projets d'envergure
orientés sur de la modélisation statistique complexe appliquée au
Marketing Client.

Nous favorisons les échanges entre Consultants & Managers et organisons
régulièrement des meetings axés sur le partage des connaissances.

Sur toutes vos missions, vous aurez également un lien direct avec nos
clients, Directions Etudes & Directions Marketing de tous secteurs
d'activité et aurez la possibilité de présenter vos études et
recommandations appuyés par nos Managers.

Intégrer Velvet, c'est aussi intégrer un cabinet proche de ses
consultants et adopter une culture d'entreprise forte. Vous partagerez
nos activités et moments de détentes tels que nos cocktails dinatoires,
nos afterworks, nos RDVs sportifs & nos séminaires annuels !"
"243","2015-01-05","Lattice","Paris","Titre: reconnaissance profonde d'expressions polylexicales par
étiquetage séquentiel supervisé

Contexte:
Les expressions polylexicales, qui forment des combinaisons de mots avec
un certain degré de non-compositionalité, posent de sérieux problèmes
pour les applications du traitement automatique des langues comme la
traduction automatique. L'apparition de corpus annotés en expressions
polylexicales a eu pour conséquence le développement de systèmes
supervisés de reconnaissance de telles expressions. Ces systèmes
reposent en général soit sur des étiqueteurs séquentiels (Vincze et
al. 2011; Constant et al. 2012; Schneider et al. 2014), soit sur des
analyseurs syntaxiques (Green et al. 2011, 2013; Kung 2014; Candito et
Constant 2014; Le Roux et al. 2014), qui peuvent être alimentés par des
lexiques. Les travaux sur le sujet sont souvent limités à une
reconnaissance de surface, même s'il existe des exceptions: par exemple,
Schneider et al. (2014) font une classification binaire des expressions
selon leur niveau d'idiomaticité (strong vs. weak); Candito et Constant
(2014) reconnaissent la structure syntaxique interne. 

Sujet:
L'objectif de ce stage est de développer un système de reconnaissance
des expressions polylexicales dans le cadre de l'étiquetage
séquentiel. Ce système devra être capable de réaliser une analyse plus
fine des expressions polylexicales que ce qui est en général réalisé. En
particulier, il devra repérer les imbrications d'expressions
polylexicales, qui sont relativement fréquentes dans les textes. Par
exemple, la séquence 'ministre français des affaires étrangères'
contient deux expressions polylexicales 'ministre des affaires
étrangères' et 'affaires étrangères'. La construction 'faire faux bond'
contient un nom composé imbriqué 'faux bond' ayant une certaine
autonomie. Ce phénomène est bien connu du domaine de la terminologie. Il
s'agira de s'inspirer des travaux existants sur le sujet.

Lieu : Lattice, CNRS
Encadrants: I. Tellier (Univ. Paris Sorbonne-Nouvelle) et M. Constant
(Univ. Paris-Est Marne-la-Vallée)

Profil du candidat:
- Master 2 ou école d'ingénieur en informatique ou TAL
- bonnes compétences de programmation,
- connaissance des outils d'apprentissage

Durée du stage : 6 mois
Rémunération : gratification réglementaire
Financement: projet AIM-WEST : http://aim-west.imag.fr

Les candidatures doivent être envoyées par mail à
isabelle.tellier@univ-paris3.fr avant le 31 janvier 2014. Le dossier de
candidature contiendra un cv, une lettre de motivation, et,
éventuellement, la recommandation d'un enseignant."
"244","2015-01-05","INaLCO","Paris","Stage M2 à l'INaLCO
Développement d'un outil de désambiguisation morpho-syntaxique pour le
bambara

Le bambara est une langue mandingue parlée en Afrique de l'Ouest et dans
la diaspora africaine. Elle fait partie des langues africaines les mieux
décrites (Dumestre 2003, Vydrine 2014). Comme pour toutes les langues et
en particulier pour les langues peu dotées, l'outillage du bambara est
une nécessité afin de permettre aux bambarophones d'utiliser leur langue
natale dans leurs interactions avec les nouvelles technologiques.

À cet effet, le Corpus Bambara de Référence (CBR), été constitué ces
dernières années (Vydrine 2013, Maslinsky 2014). Celui-ci contient
actuellement plus d'un million de mots et est géré au moyen du logiciel
NoSketchEngine (Kilgarriff 2007). Il s'appuie sur le lexique Bamadaba
afin de proposer des possibilités de catégories morpho-syntaxiques pour
les mots du corpus. Au sein de ce corpus, une sous-partie (300K mots) a
été manuellement désambiguisée.

Dans le cadre du projet MANTAL conduit par les équipes ERTIM et LLACAN
de l'INaLCO, le stage que nous proposons a pour objectif de mettre en
oeuvre et d'évaluer des approches pour désambiguiser automatiquement le
corpus. A cet effet, des modèles traditionnels à base, par exemple,
d'arbres de décision (Schmid 1995), de maximum d'entropie (Denis 2009)
ou de champs aléatoires conditionnels (Lafferty 2001), seront
évaluées. D'autres techniques seront mises à l'épreuve, dont celles
reposant sur l'utilisation conjointe de réseaux de neurones et de
techniques de sélection de features itératives.

Profil recherché :
+ Master 2 en Informatique
+ Bonnes compétences en programmation (Python, C++, Java)
+ Compréhension des approches en apprentissage automatique
+ Intérêt pour le traitement automatique des langues
+ La connaissance des langues mandingues sera vivement appréciée

Durée du stage : 5 mois à temps plein
Date de début : février ou mars 2015
Gratification : 500,51¤/mois (et rbst de 50% des transports)
Lieu : INaLCO, 2 rue de Lille, 75007 Paris
Contact: Damien Nouvel ( damien.nouvel@inalco.fr )

Références :
(Denis 2009) Denis, Pascal, Sagot, Benoît. Coupling an annotated corpus
and a morphosyntactic lexicon for state-of-the-art POS tagging with less
human effort. In Proceedings of PACLIC 2009, Hong-Kong, China, 2009.
(Dumestre 2003) Dumestre, Gérard. Dumestre, Gérard. Grammaire
fondamentale du bambara. Paris : Karthala, 2003.
(Kilgarriff 2007) A. Kilgarriff, P. Rychly, P. Smrz, D. Tugwell. The
Sketch Engine. Lexicology: Critical concepts in Linguistics Hanks,
editor.  Routledge, 2007.
(Lafferty 2001) Lafferty, John D., McCallum, Andrew, Pereira, Fernando
C.  N.. 2001. Conditional random fields: Probabilistic models for
segmenting and labeling sequence data. ICML, pp 282-289.
(Maslinsky 2014) Maslinsky, Kirill. Daba: a model and tools for Manding
corpora. Traitement Automatique des Langues Naturelles, 2014.
(Schmid 1995) Schmid, Helmut. Improvements in Part-of-Speech Tagging
with an Application to German. Proceedings of the ACL
SIGDAT-Workshop. Dublin, Ireland. , 1995
(Vydrine 2013) Vydrin, Valentin. Bamana Reference Corpus (BRC) Procedia
- Social and Behavioral Sciences, 95:25 October 2013, pp. 75-80.
http://www.sciencedirect.com/science/journal/18770428
(Vydrine 2014) Vydrin, Valentin. Projet des corpus écrits des langues
manding : le bambara, le maninka. In : Mathieu Mangeot, Fatiha Sadat
(éd.).  Actes de l'atelier sur le traitement automatique des langues
africaines TALAf 2014. http://jibiki.univ-savoie.fr/~mangeot/TALAf/2014/"
"245","2015-01-05","CEA LIST","Palaiseau","Dans le cadre du projet ANR Asfalda, le laboratoire LVIC du CEA LIST
étend son moteur de recherche crosslingue AMOSE pour lui donner des
capacités d'indexation et de recherche exploitant des informations
sémantiques issues d'outils de Semantic Role Labeling.

L'objectif premier du stage sera d'évaluer l'impact de l'intégration de
la sémantique sur les résultats de recherche. Le second objectif sera
d'améliorer le moteur de recherche au vu des premiers résultats
d'évaluation.

AMOSE est un moteur de recherche crosslingue. Il repose sur l'analyseur
linguistique libre Lima [1] qui reconnaît les termes nominaux complexes
(Multi Word Expressions ou MWE en anglais). Ces termes complexes repérés
dans les documents et les requêtes sont utilisés pour grouper les
documents résultats en classes d'équivalence en fonction des termes de
la requête qu'ils contiennent.

LIMA a récemment été enrichi d'un module effectuant de l'annotation en
rôles sémantiques (Semantic Role Labeling) et nous sommes en train de
modifier AMOSE pour indexer et utiliser dans la recherche les classes
repérées et leurs rôles.

Le travail du stagiaire consistera à évaluer la nouvelle version d'AMOSE
sur les campagnes d'évaluation classiques (CLEF, TREC) dont le
laboratoire possède les données et à rechercher quelles campagnes plus
ciblées sur la recherche sémantique pourraient exister et mettre en
ouvre AMOSE sur leurs données. Si une telle campagne a lieu durant le
stage, le laboratoire y participera.

Ces évaluations fourniront des informations permettant de mettre à jour
des pistes d'amélioration. Le stagiaire les documentera et en mettra
certaines en oeuvre.

Le stage, de 4 à 6 mois, s'adresse à des étudiants de Master 2 Recherche
en informatique ou informatique linguistique. Une bonne connaissance de
Linux et des outils de base de manipulation de corpus (bash, sed, awk,
perl, python, etc.) est indispensable ainsi qu'au moins la capacité de
comprendre du code C++.

Le stage se déroulera à Nano Innov, à Palaiseau, dans les locaux du CEA
LIST.

Mots clés: recherche d'information, évaluation, C++, Linux, corpus,
annotations


[1] https://github.com/aymara/lima/wiki

Gael de Chalendar
CEA LIST
Laboratoire Vision et Ingénierie des Contenus
(Vision and Content Engineering Laboratory)

CEA SACLAY - NANO INNOV
BAT. 861
Point courier 173
91191 GIF SUR YVETTE

Tél.:+33.1.69.08.01.50 Fax:+33.1.69.08.01.15 
Email : Gael.D.O.T.de-Chalendar.A@T.cea.D.O.T.fr"
"246","2015-01-05","Prolipsia","Besançon","*Offre de stage : Développeur web full stack H/F - Prolipsia*

Début du contrat : printemps 2015
Durée : 3 à 6 mois
Rémunération : gratification légale
Lieu : Prolipsia -  18 rue Alain Savary - Besançon (25)
Contact : candidature[at]prolipsia.com

Site : www.prolipsia.com

==================================================

Prolipsia est une jeune entreprise innovante spécialisée dans le
développement de solutions web d'aide à la rédaction (basées sur une
expertise en Traitement Automatique du Langage et en Langues
Contrôlées).  Nous venons de mettre sur le marché CAPTILO
(www.captilo.com), un service logiciel d'analyse de textes qui :

   1. identifie, dans les documents (protocoles, manuels, fiches
      techniques, consignes, contrats, etc.) les obstacles à la
      transmission d'information : ambigüités, expressions complexes,
      imprécisions, informations manquantes, etc. ;
   2. guide le rédacteur dans la correction, via des explications,
      conseils et exemples.


Utiliser CAPTILO permet de :

   - produire des documents de qualité, plus faciles à lire, comprendre,
     appliquer, et moins coûteux à mettre à jour et à traduire ;

   - optimiser transmission des connaissances, prise de décisions,
     respect de consignes, gestion des risques, etc.


*Nous sommes aujourd'hui à la recherche d'un(e) stagiaire motivé(e) pour
participer au développement du produit.*


==================================================
*Descriptif du poste*
==================================================

Vous intégrerez l'équipe R&D de Prolipsia. Dans un environnement agile
et un esprit startup, vous participerez aux différentes phases
techniques successives d'un des projets de l'écosystème CAPTILO.

Suivant vos compétences et vos souhaits, vos principales missions
peuvent porter sur :

   - la mise en place de nouvelles fonctionnalités de l'application web
     (AngularJS / Symfony2) ;

   - la réalisation d'addons CAPTILO pour les suites bureautiques Cloud,
     les éditeurs de contenu web et clients (Javascript / Java / .NET) ;

   - la consolidation et la modularisation de l'architecture technique
     (API REST, micro-services, Job queue, Docker, etc.).

Vos tâches incluront également la veille technologique et la proposition
de solutions techniques.

==================================================
*Profil recherché*
==================================================

Issu(e) d'une formation informatique de niveau bac+3/5, vous êtes
passionné(e) par le développement web, à l'aise sur un large panel de
sujets techniques et vous savez faire preuve d'initiative. Vous cherchez
un stage impliquant des challenges techniques.

Vous :

   - connaissez les concepts des architectures web ;
   - avez expérimenté un ou plusieurs frameworks PHP ;
   - possédez des connaissances en développement front-end (HTML5, CSS3,
     frameworks JS) ;
   - êtes sensible aux bonnes pratiques du développement logiciel et de
     la POO.

Autres points appréciés :

   - Vous avez des notions de DevOps.
   - Vous avez une sensibilité pour le design et UX.
   - Vous êtes familier(ère) avec les outils de gestion de code comme
     Git.
   - Vous avez une première expérience de mise en oeuvre/développement
     de projet concret.

*Si certaines de ces compétences vous manquent mais que vous avez les
capacités et l'envie d'apprendre, adressez-nous votre candidature !*"
"247","2015-01-05","CS","Le Plessis-Robinson","Référence : DEF/LPR/N°9
    Date de parution : 23/12/2014
    Localisation : Le Plessis Robinson, France
    Type de contrat : Stage
    Métier : Autre
    Secteur : Défense

Avec 1700 collaborateurs pour un chiffre d'affaires de 173 millions
d'euros, CS se positionne parmi les premières sociétés de services en
informatique en France et s'affirme comme un concepteur, intégrateur
et opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense,
aéronautique, spatial, énergie, transport, secteur public et
finance. CS réalise environ 80% de ses projets au forfait.
CS est coté sur le marché Euronext Paris.

Missions

Dans le domaine du contrôle du trafic aérien, les contrôleurs doivent
en permanence se former. CS a développé pour ce besoin un simulateur
contenant des pseudo-pilotes qui interagissent avec les contrôleurs à
travers des échanges vocaux.  Pour assurer la sécurité des vols, les
dialogues contrôleurs-pilotes sont standardisés et forment un
sous-langage. Dans notre simulateur, nous utilisons un système de
reconnaissance vocale Nuance capable d'apprendre la grammaire de ces
dialogues, ce qui simplifie le travail de la reconnaissance et
améliore les performances.

Nous souhaitons évaluer d'autres solutions de reconnaissance vocale,
en particulier Open Source, et les comparer à la solution Nuance.

Les langues utilisées pour la reconnaissance de la parole seront le
français et / ou l'anglais.


Durée du stage : 4 à 6 mois

Profil

Master 2 ou élève ingénieur 2e ou 3e année

Compétences techniques: C/C++, bash, xslt.

Compétences linguistiques: Anglais Technique

CV + LM à envoyer à l'adresse recrutement@c-s.fr à l'attention de
Gariné KELIJIAN en précisant la référence DEF/LPR/N°9."
"248","2015-01-12","Orange","Lannion","Stage : en Web sémantique

Notre équipe dispose d'une Base de Connaissances alimentée par des
entités nommées (EN : personnes, lieux, organisations, etc.) du Linked
Open Data (dbpedia, freebase, geonames, etc.) et utilisée pour enrichir
nos données pour l'extraction d'informations du texte écrit.  Dans le
cadre de ce stage :

- vous participez à la découverte des libellés de ces EN, notamment des
  variantes non standards (exemple : Paris/Paname/Villes Lumières...)

- vous participez à la découverte et à la correction des gentilés
  (St. Brieuc à briochin(e)(s))

- vous utilisez et adaptez des technologies de l'équipe ou open source
  pour le Traitement Automatique des Langues et les Bases de
  Connaissances

- vous examinez des données Linked Open Data

- vous vérifiez des échantillons des données découvertes

- vous collaborez avec les membres de l'équipe


Equipe d'accueil :
L'équipe CONTENT/FAST d'Orange Labs a en charge des travaux de recherche
et développement dans le domaine du Traitement Automatique des Langues
(TAL) appliquée aux documents écrits et au texte issu du vocal (analyse
sémantique, extraction d'information, requêtes en langage naturel,
etc.), et dans le domaine des Bases de Connaissances.


Profil :

Master 2 en Traitement Automatique des Langues ou Informatique

Contact : http://orange.jobs/jobs/offer.do?do=fiche&id=43952
Plus d'info : Johannes Heinecke (Johannes.heinecke(at)orange.com)

Stage rémunéré, à Lannion, d'une durée de 5 mois à partir de mars ou
avril 2015.

Johannes Heinecke
IMT/OLPS/OPENSERV/CONTENT/FAST
computational linguist/ingénieur de recherche TALN
tél. +33 (0)2 96 07 21 77"
"249","2015-01-12","STL","Lille","Proposition de stage de niveau Master 2

Analyse de la communication entre les patients et les médecins

http://natalia.grabar.perso.sfr.fr/stage-equ-2.html

contact : natalia.grabar@univ-lille3.fr

Le domaine médical a une terminologie spécifique, avec des termes comme
par exemple sanguin, abdominoplastie, hépatique, dermabrasion ou
hépatoduodénostomie, utilisée communément par le personnel médical.
Pour cette raison entre autre, la compréhension d'information de santé
est souvent compliquée pour les non spécialistes et pour les patients
(Patel et al., 2002; Williams et al., 1995; Rudd et al., 1999; Berland
et al., 2001). La disponibilité des informations de santé en ligne peut
aussi modifier le modèle de communication entre ces catégories de
personnes (Tran et al., 2009; Jucks & Bromme, 2007).

L'objectif de ce stage consiste à étudier la communication entre les
patients et les médecins. Le matériel traité provient des forums de
discussion et des données collectées dans un contexte clinique. Il
s'agit en particulier d'exploiter des méthodes de Traitement Automatique
de la Langue pour mener une étude contrastive des propos émis par ces
deux catégories de personnes (patients et médecins) dans un dialogue.

Plus spécifiquement, il s'agit des objectifs suivants:

- travailler avec les propos produits par les patients et les médecins
  (contexte clinique et de l'internet)
- exploiter et améliorer les annotations des documents avec différents
  niveaux de spécificité
- effectuer une analyse contrastive au sein de ces documents
- établir un lexique avec les correspondances entre les termes savants
  et les expressions des patients (méthode, analyse et lexique final)
- si nécessaire, transcrire des conversations téléphoniques entre les
  patients et les médecins

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:

     connaissances en TAL et en linguistique
     manipulation et test des outils de TAL
     habitude de Linux
     capacité de travailler en équipe et individuellement
     lecture et analyse de la littérature scientifique

Le stage est rémunéré.
Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Niveau: Master 2
Durée: 6 mois
Lieu: Lille, Paris (éventuellement)

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à
natalia.grabar@univ-lille3.fr.

Références:

1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as
   procedures : The case of pharmaceutical labels, International journal
   of medical informatics, vol. 65(3), p. 193-211, 2002

2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,
   Nurss J., Inadequate functional health literacy among patients at two
   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995

3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and
   Literacy, ch 5, 1999

4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,
   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn
   E., Health information on the Internet. Accessibility, quality, and
   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,
   2001

5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un
   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,
   vol. 53, p. 34-43, 2009

6. Jucks R., Bromme R., Choice of words in doctor-patient communication:
   an analysis of health-related internet sites, Health Commun,
   vol. 21(3), p. 267-77, 2007"
"250","2015-01-12","STL","Arras","Proposition de stage de niveau L3/M1

Sujet : Transcription des conversations téléphoniques entre les médecins
et les patients

http://natalia.grabar.perso.sfr.fr/stage-equ-1.html

contact : natalia.grabar@univ-lille3.fr

Le domaine médical a une terminologie spécifique, avec des termes comme
par exemple sanguin, abdominoplastie, hépatique, dermabrasion ou
hépatoduodénostomie, utilisée communément par le personnel médical.
Pour cette raison entre autre, la compréhension d'information de santé
est souvent compliquée pour les non spécialistes et pour les patients
(Patel et al., 2002; Williams et al., 1995; Rudd et al., 1999; Berland
et al., 2001). La disponibilité des informations de santé en ligne peut
aussi modifier le modèle de communication entre ces catégories de
personnes (Tran et al., 2009; Jucks & Bromme, 2007).

L'objectif de ce stage consiste à préparer les données pour l'étude de
la communication orale entre les médecins et les patients.

Plus spécifiquement, il s'agit des objectifs suivants:

- transcrire des conversations téléphoniques entre les patients et les
  médecins
- utiliser un outil de transcription existant : Transcriber (Barras et
  al., 1998)
- garder les traces des émotions lors de la transcription
- effectuer l'anonymisation des conversations

Un guide détaillé de transcription sera fourni.

Prérequis:

     connaissances en linguistique
     manipulation d'un outil
     capacité de travailler en équipe et individuellement

Le stage est rémunéré.

Niveau: L3/M1
Durée: 3 mois
Lieu: Arras

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts d'un référent à
natalia.grabar@univ-lille3.fr.

Références:

1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as
   procedures : The case of pharmaceutical labels, International journal
   of medical informatics, vol. 65(3), p. 193-211, 2002

2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,
   Nurss J., Inadequate functional health literacy among patients at two
   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995

3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and
   Literacy, ch 5, 1999

4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,
   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn
   E., Health information on the Internet. Accessibility, quality, and
   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,
   2001

5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un
   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,
   vol. 53, p. 34-43, 2009

6. Jucks R., Bromme R., Choice of words in doctor-patient communication:
   an analysis of health-related internet sites, Health Commun,
   vol. 21(3), p. 267-77, 2007

7. Barras C., Geoffrois E., Wu Z., Liberman M., Transcriber: a free tool
   for segmenting, labeling and transcribing speech. In: Conference on
   Language Resources and Evaluation (LREC).  1373-1376, 1998"
"251","2015-01-15","LI","Blois","Proposition de stage de niveau Master 2

SUJET : Résolution des co-références pour la recherche d'information
dans des corpus de langage parlé

Proposition de stage de recherche ou de fin d'études en Informatique en
vue de la réalisation d'un système de résolution des coréférences, outil
utile tant dans le champ de la recherche d'information que pour le
traitement automatique des langues, d'une durée minimale de 5 mois.

LIEU D'EXERCICE : Laboratoire LI, équipe BDTLN (Blois)

CONTACT : Jean-Yves Antoine  (http://www.info.univ-tours.fr/%7Eantoine/)
                             (Jean-Yves.Antoine@univ-tours.fr)
  	  Anaïs Lefeuvre     (https://sites.google.com/site/nlplefeuvreanais/home)  
                             (Anais.Lefeuvre@univ-tours.fr)

CONTEXTE

Le Laboratoire d'Informatique de l'Université de Tours, antenne de Blois
propose un sujet de stage dans le cadre du projet industriel financé par
la société BAMSOO et faisant suite à un projet (ANCOR) réalisé en
collaboration avec le Laboratoire Ligérien de Linguistique de
l'Université d'Orléans,

Le projet (ANCOR) a pour objet l'étude de toutes les formes de reprises
anaphoriques et de coéréférence dans une optique pluridisciplinaire
autour de l'étude de la langue orale. La recherche d'information et le
traitement automatique des langues sont étroitement liés, les requêtes
formulées par les utilisateurs ainsi que la représentation des
informations d'un document textuel en langue naturelle dépendant
précisément de la qualité de modélisation des phénomènes
linguistiques. Les technologies de traitement de l'oral sont à un
tournant du point de vue de ces applications : la reconnaissance vocale
est accessible à la totalité des consommateurs de smartphones (ex :
SIRI), mais la recherche d'information dans des documents sonores
n'intègre pour le moment que la musique par similarité entre requête et
réponse (ex : Shazam). Dans ce projet, nous nous intéressons ainsi à la
prise en compte de la langue orale transcrite sous forme de documents
numériques.

Un second aspect important de notre sujet se focalise sur la
représentation fine du contenu des documents plutôt que de se limiter à
une approche sac de mots. Plusieurs étapes sont nécessaires pour obtenir
une représentation pertinente et fidèle d'un document. Une de ces étapes
est la résolution d'anaphore et de co-référence, qui fait précisément
l'objet de ce stage.

On appelle co-référence, et plus généralement anaphore, la relation
entre deux items langagiers telle que l'interprétation de l'un dépend de
l'autre. Considérons l'exemple :

""Zoe est venue à la fête avec Isa. Elle ne voulait pas venir seule"".

Nous sommes en présence d'une anaphore pronominale entre le pronom
""elle"" et son antécédent ""Zoe"", relation qu'un système doit détecter
pour interpréter correctement la seconde phrase. Cette tâche n'est
jamais triviale : par exemple, dans ce cas, le système pourrait
rattacher de manière erronée le pronom à ""Isa"", voire même au nom commun
""fête"". Le développement d'outils performants de recherche d'information
dans des flux langagiers passe par une modélisation efficace de ces
relations anaphoriques et/ou de co-référence.
  
L'importance de la résolution des anaphores a conduit à l'émergence de
travaux qui ont fait l'objet de multiples campagnes d'évaluation
internationales (MUC, SemEval, ACE). Ces recherches portent toutefois
majoritairement sur les documents électroniques, la parole
conversationnelle faisant surtout l'objet de travaux sur l'anaphore
pronominale. Le projet ANCOR a permis précisément l'annotation d'un
corpus d'envergure (488 000 mots) du français oral (transcrit) annoté en
co-référence et anaphores. Ce corpus a déjà permis l'apprentissage de
CROC, le premier système francophone de résolution des coréférences
développé par le laboratoire LATTICE à Montrouge (CROC : Coreference
Resolution for Oral Corpus :
http://issuu.com/sfleury/docs/adele-desoyer-memoire-tal-rb-1314/1).

OBJECTIFS

Le stage qui vous est proposé a pour ambition de compléter le travail
déjà réalisé suivant 3 axes :

1) Achever la création d'ANCORQI, un outil de requêtage du corpus ANCOR
   (codé suivant un format XML spécifique) afin de permettre à des
   chercheurs linguistes de pouvoir extraire des statistiques utiles sur
   cette ressources linguistique de grande envergure

2) Participer à la transformation du corpus ANCOR suivant différents
   formats de représentations utilisés par la communauté scientifique du
   Traitement des Langues Naturelles.

   Ces deux premières phases seront a priori réalisées dans un langage
   de script (Python) et ne mobiliseront donc a priori pas des
   compétences informatiques complexes. Elles constituent toutefois une
   très bonne manière de s'imprégner de la problématique scientifique
   étudiée avant de passer à la troisième et principale phase du projet

3) le développement d'un système de résolution des coréférences et de
   son évaluation. Ce travail consistera à intégrer et adapter au
   français la plate-forme de développement BART
   (http://www.bart-anaphora.org/). BART est une plateforme modulaire et
   hautement adaptable proposant implémentée en Java et permettant la
   mise en oeuvre de différentes techniques d'apprentissage pour la
   résolution des coréférences. Ce toolkit distribué en open source
   intègre pour cela une large variété de classifieurs, parmi lesquels
   l'algorithme standard C4.5 et plusieurs noyaux pour machines à
   vecteur support (SVM). Il permet le développement de systèmes du
   moment où l'on dispose d'un corpus d'entrainement de taille
   suffisante. Il intègre également des modules de prétraitement qui ont
   permis le développement de systèmes pour l'anglais, l'allemand, le
   polonais et l'italien. Notre objectif est précisément d'arriver au
   développement d'un système adapté au français par entrainement sur le
   corpus ANCOR.


TRAVAIL A REALISER

La personne recrutée sera en charge d'adapter BART au français.

- Phase n°1 (T0 - T0+2) - Finalisation de l'outil ANCORQI et préparation
  des données (réalisation et applications d'utilitaires de
  transformation XML pour préparer le corpus ANCOR aux formats de
  traitement attendus). En parallèle, veille technologie sur le sujet et
  prise en main de BART

- Phase n°2 (T0+2- T0+5) - Adaptation effective de BART au français :
  Intégration de composants, test sur corpus,  et motivation des
  pipelines

- Phase n°3 (T0+5- T0+6) - Évaluation du système  : évaluation et
  comparaison au système CROC.

Ce travail sera réalisé dans un contexte collaboratif marqué :

- Laboratoire Ligérien de Linguistique (LLL, Orléans) pour les deux
  premières phases du projet,

- Laboratoire LATTICE (ENS, Montrouge) pour la partie principale
  consacrée à BART, qui sera comparé à CROC.

La personne recrutée pourra donc être amenée à participer à des réunions
de recherche chez ces partenaires. En cas d'avancée significative, ce
travail pourra par ailleurs conduire à la rédaction de publication
scientifique si le ou la stagiaire est intéressé(e).

PROFIL RECHERCHE

La personne recrutée sera en cycle terminal d'études en informatique, de
niveau Bac+5 (Master en Informatique). Un intérêt pour le Traitement
Automatique des Langues est apprécié, sans être un pré-requis à
recrutement. Capacités expertes de développement Java exigé. Dans le cas
d'un(e) étudiant(e) en Master Recherche, le sujet de stage pourra être
adapté aux attentes de l'étudiant.

REMUNERATION

436,05 ¤ par mois.

DUREE DU STAGE ET LIEU D'EXERCICE

La personne recrutée travaillera au sein du laboratoire LI, dans les
locaux de l'IUT de Blois Jean-Jaurès. Il s'intégrera dans l'équipe de
recherche BDTLN
(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) et plus
précisément l'axe TLN de cette équipe (http://tln.li.univ-tours.fr/).

La durée minimale de stage sera de 5 mois, 6 mois appréciés

DEPOT DE CANDIDATURE

Dépôt des candidatures : auprès de Anaïs Lefeuvre. Merci de déposer un
CV détaillé de vos activités passées, accompagné d'une lettre de
motivation et de vos relevés de notes des deux dernières années
d'études. Un développement Java sera demandé pour la sélection du
candidat."
"252","2015-01-15","EDF","Paris","INTITULE DE LA MISSION : Réalisation d'un modèle de catégorisation
automatique pour l'analyse automatique d'une question ouverte d'enquête
de satisfaction.

Date de début : entre avril et juin 2015

Durée du stage : 6 mois

Niveau de diplôme préparé : MASTER 2 spécialisé en Ingénierie 
Linguistique / Traitement automatique des langues

SERVICES D'ACCUEIL : EDF - Direction Commerce

- Tête de Direction :   oui        non
- Direction : Domaine Analyse Connaissance Client
- Département : Département Analyse Client et Publication (ACP)


CONTEXTE ET DESCRIPTION DU STAGE

Depuis le 1er juillet 2007, le marché de l'électricité est entièrement
ouvert à la concurrence et permet au consommateur de choisir librement
son fournisseur d'énergie. Dans ce contexte, il est d'autant plus
important pour EDF de comprendre les besoins de ses clients, mais
également d'expliquer et de prédire leur comportement.
Le département Analyse Client et Publication (ACP) a pour mission
d'analyser les données provenant des différents systèmes d'information
et notamment les données textuelles.
Actuellement, nous utilisons des techniques de Text Mining à travers les
outils de Temis pour analyser automatiquement des commentaires provenant
de nos SI mais également les réponses aux questions ouvertes d'enquêtes
de satisfaction.
Le stage que nous proposons est opérationnel et a pour objectif la mise
en place d'un modèle d'analyse automatique des réponses à des questions
ouvertes issues d'enquêtes de satisfaction.

Présentation de la mission
La mission se composera de quatre étapes :

- L'exploration de corpus avec des outils de classifications
  automatiques
- La définition d'un plan de catégorisation en lien avec les équipes
  opérationnelles
- L'annotation de données 
- La création d'un modèle de catégorisation et de règles d'extraction de
  connaissances

PROFIL RECHERCHE :

- De formation Master II spécialisé en Traitement Automatique du Langage

- Domaines de compétence requis :
  - Linguistique et informatique
  - Des connaissances en statistique seraient appréciées

- Rigueur, autonomie et aisance rédactionnelle. 



les candidatures sont à adresser à Anne-Laure GUENET :
anne-laure.guenet@edf.fr

Anne-Laure GUENET
Chef de projet Text Mining
EDF- Commerce - DSI
Domaine ACC - Département Analyses Clients et Publications
20, place de la défense
Bureau 9P06
92050 PARIS LA DEFENSE CEDEX
 
anne-laure.guenet@edf.fr
Tél. : 01.56.65.22.87"
"253","2015-01-19","CEA-LIST","Palaiseau","Proposition de stage de master 2

Identifier dans les textes les entités d'une base de connaissances

CONTEXTE
Le stage se situe dans le contexte de l'extraction d'information, dont
l'objectif est d'extraire des informations précises à partir de textes
non structurés. Parmi les nombreuses applications de ce domaine, en
particulier en contexte de veille, beaucoup nécessitent l'identification
et le typage d'entités spécifiques dans les textes, et plus précisément,
d'entités nommées, comme les noms de lieux, d'organisations, de
personnes etc.
Cette tâche est traditionnellement réalisée en s'appuyant principalement
sur la forme d'expression de ces entités. Avec l'existence de larges
bases de connaissances telles que DBpedia ou FreeBase, une nouvelle
façon d'aborder ce problème a émergé : l' Entity Linking, développée en
particulier sous l'impulsion la campagne d'évaluation TAC-KBP, a pour
objectif de faire lien entre des entités présentes a priori dans une
base de connaissances et la façon dont elles apparaissent dans les
textes.

OBJECTIF
L'objectif du stage est de mettre en place une procédure
d'identification dans des textes d'entités nommées présentes dans une
base de connaissances existante.  Cette procédure s'appuiera sur les
travaux importants qui existent dans le domaine. On cherchera en
particulier à répondre aux problèmes suivants :

- variabilité des entités : la même entité peut être présente sous de
  nombreuses formes. Par exemple, Bush, président George Bush, George
  W. Bush, George Walker Bush ou le 43ème président des Etat-Unis sont
  toutes des mentions faisant référence à la même personne ;

- ambiguïté des entités : plusieurs entités peuvent être exprimées avec
  la même forme. Par exemple, la mention George Bush peut désigner aussi
  bien le 43ème président américain que le 41ème, son père. Elle peut
  aussi faire référence au porte-avion ou à l'aéroport du même nom.

Pour le premier problème, on utilisera une combinaison d'acquisition
automatique de ressources contenant des formes connues de différentes
mentions pour les mêmes entités (par exemple à partir des liens entrants
sur les pages Wikipédia, ou de l'extraction de patrons exprimant cette
relation de reformulation), et d'une mise en correspondance automatique
de formes nouvelles par une mesure de similarité avec les formes
existantes.
Pour le second problème, on cherchera à développer une méthode de
rattachement combinant des critères généraux, comme la popularité d'une
entité, et des critères locaux, comme une mesure de la similarité entre
le contexte textuel qui entoure la mention considérée et le texte
définissant l'entité visée.
Une part du travail du stagiaire sera aussi d'explorer l'état de l'art
des méthodes et logiciels existants pour ce type de tâche, en
particulier dans le cadre de la campagne d'évaluation TAC-KBP.

Le stagiaire pourra s'appuyer sur la plate-forme d'analyse linguistique
LIMA (https://github.com/aymara/lima) développée par le LVIC et sur les
travaux réalisés par le laboratoire en matière d'extraction
d'information.

MODALITÉS
Le stage sera rémunéré et se déroulera pour une durée de 6 mois au sein
du Laboratoire Vision et Ingénierie des Contenus (LVIC) du CEA LIST,
situé sur le centre d'intégration Nano-Innov, à Palaiseau.

Les candidats intéressés par ce stage sont invités à prendre contact
avec Romaric Besançon (romaric.besancon@cea.fr) en envoyant un CV et une
lettre de motivation."
"254","2015-01-19","Syllabs","Paris","--------------------------------------------------------
Offre de stage M2 TAL : Génération automatique de textes
--------------------------------------------------------

Syllabs est spécialisée en analyse sémantique et en génération
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse de
données textuelles du Web : identification des pages pertinentes,
extraction et catégorisation des informations clés. La génération est
proposée au travers de sa solution Data2Content (data2content.fr) qui
permet, à partir d'une base de données structurées, de générer
automatiquement des textes de qualité humaine.

C'est dans le cadre de Data2Content que nous recherchons des ingénieurs
linguistes pour un stage dans le domaine de la création automatique de
textes en anglais, français, espagnol, néerlandais, portugais, italien
et allemand.
L'objet principal du stage est de travailler sur le paramétrage de notre
outil de génération (écriture de règles) dans votre langue
maternelle. Les domaines d'application peuvent par exemple être le
e-commerce (descriptifs de produits) ou encore le tourisme.

--------------------
Description du poste
--------------------
Les tâches principales concernent: 
- Génération automatique de descriptifs de produits : paramétrage de
  l'outil de génération en fonction du projet, participation aux tests
  et à l'amélioration de l'outil
- Extraction d'information : création de bases de données structurées à
  partir de données non structurées
- Ecriture de scripts pour la manipulation des bases de données

---------------
Profil souhaité
--------------- 
- Excellentes qualités rédactionnelles, goût pour l'écriture
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail en
  équipe
- Programmation en Python

---------------------
Diplôme et expérience
---------------------
- Formation en cours : Master 2 en Linguistique Informatique ou
  similaire
- Compétences en rédaction web seraient un plus

Durée de stage : 6 mois

Contrat : stage conventionné rémunéré en fonction du niveau d'étude +
qtickets resto + remboursement à moitié du pass Navigo (transport)

Lieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris (métro
République)

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage génération « langue »», par
exemple, « stage génération espagnol »."
"255","2015-01-19","LIMSI","Orsay","Aide à la rédaction pour l'adaptation de textes à différents profils de
lecteurs


niveau : M2, dernière année d'école d'ingénieur
domaine : informatique
période : à partir de mars-avril 2015
durée : 5-6 mois
URL : http://perso.limsi.fr/amax/recherche/sujet1-amax-M2-2015.html


Contexte

L'accès à l'information est primordial pour tous et celle-ci passe
souvent par l'écrit. Il existe néanmoins très souvent un décalage entre
la manière de s'exprimer du rédacteur et les capacités de compréhension
de certains lecteurs. Tout lecteur peut se trouver en situation de
difficulté, par exemple lorsqu'un niveau de technicité d'un texte n'est
pas le sien, ou que la langue utilisée est trop complexe. Les
difficultés ressenties peuvent à l'extrême couper certaines personnes de
l'accès à des informations importantes. Par exemple, des porteurs de
Trisomie 21 auront des difficultés à comprendre de nombreux textes qui
contiennent des informations qui les concernent mais qui n'ont pas été
conçus pour eux.

Il en est ainsi de leur dossier médical : il est légalement obligatoire
que celui-ci puisse être consulté et compris par le patient, mais il
contient des textes parfois rédigés dans une langue de spécialité ou
dans un niveau de langue relativement élevé. Il est donc nécessaire
d'apporter des aides efficaces pour l'aide à l'accès à l'information
pour ce type de situation. Toutefois, il serait souhaitable qu'existe
une version de ces textes multi-niveau adaptable à l'ensemble des
profils de lecteurs potentiels.

Dans le cadre d'un projet commun avec la Fédération Trisomie 21 France,
le laboratoire LIMSI-CNRS s'intéresse à la définition d'un nouveau type
de documents qui serait accessible à plusieurs profils de lecteurs,
couvrant par exemple une personne atteinte de Trisomie 21, ses aidants
et ses médecins. De nouveaux types d'aides à la rédaction sont donc
nécessaires : il doit s'agir d'aider un rédacteur à anticiper des
difficultés de lecture, et à proposer des variantes pour des fragments
non adaptés. Pour cela, un corpus de textes issus de dossiers patients
est en cours d'annotation en fragments difficiles ainsi qu'en
réécritures possibles. Les données ainsi collectées pourront servir à
(1) la détection automatique de fragments potentiellement non adaptés à
certains profils de lecteurs, et à (2) l'aide à l'écriture de variantes
pour ces fragments.


Travail à réaliser

Le stage proposé visera à obtenir un module opérationnel de détection de
fragments non adaptés, et à proposer si possible des réécritures
candidates adaptées. Il faudra tout d'abord faire une étude
bibliographique sur les domaines de la réécriture (interactive) de
textes, et notamment la simplification automatique. Une analyse de
corpus sera ensuite menée afin de comprendre les caractéristiques des
textes manipulés et proposer des indices susceptibles de guider les
décisions sur l'adéquation des fragments de textes aux profils de
lecteurs considérés.

L'acquisition de fragments difficiles et de réécritures candidates sera
menée de deux manières : (1) par collecte manuelle auprès de volontaires
de la fédération Trisomie 21 France; (2) par acquisition automatique
fondée en particulier sur le repérage de termes et de leurs variantes
dans des textes adaptés à différents profils. La dernière étape aura
pour objectif de développer un module d'apprentissage automatique pour
l'annotation de fragments de texte en fonction des profils adaptés, dont
les prédictions pourront ensuite être utilisées pour suggérer des
réécritures candidates, qui seront soit issues du dictionnaire construit
manuellement lors de la collecte d'annotations (faible rappel, mais
forte précision), soit générées automatiquement par des techniques de
paraphrase (fort rappel, précision plus faible).

Ce travail, qui pourra être poursuivi par un travail de thèse, aura
comme perspective de permettre la lecture d'un document riche en
effectuant un parcours dans un graphe de formulations possibles, en
s'adaptant (sur le long terme) au profil particulier de chaque lecteur.


Profil recherché

Etudiant(e) niveau M2, connaissances solides en informatique.
Intérêt pour les domaines du traitement automatique des langues, de la
linguistique de corpus, et de l'apprentissage automatique.


Contact

Toute personne intéressée par le stage peut prendre contact avec :

Gabriel Illouz (gabriel.illouz@u-psud.fr)
Aurélien Max (aurelien.max@limsi.fr)

en utilisant comme titre de message ""[Candidature] Aide à la rédaction"", 
et en joignant : (a) un CV à jour, (b) les résultats du M1 ou équivalent 
et ceux du M2 déjà connus, (c) une description relative à l'intérêt pour 
le sujet proposé.

Le stage aura lieu au LIMSI-CNRS (Orsay, RER ligne B) à partir de 
mars-avril 2015 pour une durée de 5-6 mois."
"256","2015-01-19","LIPN","Villetaneuse","*Repérage automatique des usages des lexies en corpus, appliqué aux
lexies verbales du français*

_*Contexte:*_

Le stage se situe dans la problématique de repérage des usages en
corpus.  Une première approche, linguistique, des usages associe à
chaque sens un ou des schémas lexico-syntaxiques, selon différents
modèles (par exemple FrameNet) et cherche à les décrire
manuellement. Mais cette approche se heurte aux limitations des
approches manuelles et notamment le temps prohibitif de développement
des ressources. Une autre approche, computationnelle, issue de
l'hypothèse distributionnelle (Harris, 1954; Firth,1957), se base sur la
répétition des séquences (n-grams avec fenêtre variable) pour extraire
les différentes séquences signifiantes, d'une part, et en déduire des
regroupements d'emplois en utilisant des métriques diversifiées. Les
métriques permettant de classer les répétitions sont nombreuses (Ramish,
2015). A partir de l'hypothèse distributionnelle initiale, les
chercheurs ont proposé un certain nombre d'alternatives au simple calcul
de séquences répétées, afin de repérer différents phénomènes
linguistiques liés au sens des lexies (Turney et Pantel, 2010; Baroni et
al., 2010 ; Clark, 2015). Il existe un certain nombre d'outils et de
platefomes développant ces calculs (Dissect, SemanticVectors, Word2vec,
SketchEngine, R...).

_*Sujet du stage:*_

Le stage portera sur la problématique de l'usage et de son repérage
automatique sur corpus, en limitant l'étude à une centaine de lexies
verbales du français.

L'objectif du stage est :

- de maîtriser la littérature TAL issue de l'hypothèse
  distributionnelle;

- d'utiliser les outils existants pour effectuer des calculs de n-grams
  sur gros corpus du français, au niveau des formes, des informations
  morphosyntaxiques, syntaxiques et d'une combinaison de ces
  informations;

- tester différentes mesures permettant d'affiner le comptage brut ;

- aboutir, pour les cent lexies données, à des ""usages"" ;

- de proposer différentes solutions afin d'améliorer l'existant et
  d'approcher du modèle plus linguistique de schéma
  syntactico-sémantique.


Lieu : LIPN équipe RCLN, CNRS UMR 7130, Université Paris 13

Encadrants: E. Cartier (Univ. Paris 13, LIPN-RCLN)


_*Profil du candidat:*_

- Master 2 TAL ou école d'ingénieur en informatique ou TAL

- bonnes compétences en programmation et en manipulation d'outils de
  TAL, notamment numériques (outils de la linguistique de corpus,
  mesures de similarité...)

- bonnes compétences en linguistique générale

Durée du stage : 6 mois, à partir de mars 2015

Rémunération réglementaire


Les candidatures doivent être envoyées par mail à

emmanuel.cartier@lipn.univ-paris13.fr avant le 15 février 2015.

Merci d'envoyer un dossier contenant un cv, une lettre de motivation +
autre(s) document(s) si jugé pertinent.


_*Bibliographie indicative :*_

Baroni, M., and Lenci A. (2010) ""Distributional Memory: A General
Framework for Corpus-Based Semantics,"" /Computational Linguistics/, 36-4
(2010), 50

Clark S. (2015) ""Vector Space Models of Lexical Meaning"", To appear in
Wiley-Blackwell /Handbook of Contemporary Semantics - second edition/,
edited by Shalom Lappin and Chris Fox

Firth, J. R. (1957). A synopsis of linguistic theory 1930-1955. In
/Studies in Linguistic Analysis/, pp. 1-32. Blackwell, Oxford.

Harris, Z. 1954. Distributional structure. /Word/, 10(2-3):1456-1162.

Kilgarriff, A., Rychly, P., Smrz, P., and Tugwell, D. (2004) The Sketch
Engine. In: Williams G. and S. Vessier (eds.), /Proceedings of the XI
Euralex International Congress/, July 6-10, 2004, Lorient, France, pp.
105-111.

Ramisch C. (2015), ""Multiword Expressions Acquisition: A Generic and
Open Framework"", /Theory and Applications of Natural Language
Processing/series XIV, Springer, ISBN 978-3-319-09206-5, 230 p., 2015.

Turney P. and Pantel P. (2010) ""From Frequency to Meaning: Vector Space
Models of Semantics"". /Journal of Artificial Intelligence Research
(JAIR)/, 37(1):141-188. AI Access Foundation."
"257","2015-01-21","LIRMM","Montpellier","Stage de Master 2 Pro ou Recherche : Visualisation de trajectoires de patients

Laboratoire : LIRMM  http://www.lirmm.fr/
Equipe : ADVANSE http://www.lirmm.fr/recherche/equipes/advanse
Lieu du stage : Montpellier

Contexte
Le Programme de médicalisation des systèmes d'information (PMSI) est un
dispositif faisant partie de la réforme du système de santé français
ayant pour but de mesurer l'activité et les ressources des
établissements de soins. Ces derniers doivent renseigner des
informations quantifiées et standardisées sur les activités des
professionnels de santé et son financés en retour. Dans le cadre d'une
collaboration avec le CHU de Nimes, nous extrayons des trajectoires de
patients à partir d'une telle base.

Mission
L'objectif de ce stage est d'extraire ces trajectoires (fouille de
données) et de définir des visualisations et des interactions pour
faciliter l'interprétation des professionnels de la santé.  
Le prototype de visualisation qui devra être mis en place sera basé sur
la bibliothèque D3 (http://d3js.org/). Le candidat devra avoir une bonne
connaissance des langages Web (et en particulier de JavaScript). Dans
l'idéal, il aura aussi déjà manipulé la bibliothèque D3 et aura quelques
connaissances dans le domaine du dessin de graphes.

Compétences
- Fouille de données
- JavaScript
- Langage Web
- Idéalement bibliothèque D3

Contacts
- Jérôme Azé : jerome.aze@lirmm.fr
- Sandra Bringay : sandra.bringay@lirmm.fr
- Jessica Pinaire : jessica.pinaire@chu-nimes.fr"
"258","2015-01-28","CLLE","Toulouse","Proposition de stages en linguistique ""Annotations de l'occitan""

- Descriptif : dans le cadre du projet RESTAURE soutenu par l'Agence
        Nationale de la Recherche, nous développons des outils de
        Traitement Automatique de l'Occitan, en particulier un OCR
        (logiciel de reconnaissance de caractères) et un analyseur
        morpho-syntaxique, dont les premières phases nécessitent
        l'annotation de textes par des linguistes

- Niveau d'études et discipline : L3 ou M1 en Linguistique, Sciences
  du Langage ou Occitan

- Durée : de 1 à 4 mois (possibilité mi-temps)

- Rémunération : environ 500 euros par mois (à temps plein)

- Période : avril-septembre 2015

- Lieu : laboratoire CLLE-ERSS, Maison de la recherche, Université
  Toulouse 2

- Compétences en langue occitane (au moins compréhension), en
  linguistique (au moins en morphologie et syntaxe), capacités travail
  en équipe

- Encadrement : Marianne Vergez-Couret, Myriam Bras, CLLE-ERSS

- Candidature : envoyer CV + lettre motivation à myriam.bras@univ-tlse2.fr, vergez@univ-tlse2.fr"
"259","2015-01-29","INRA","Jouy-en-Josas","Offre de stage recherche Master 2 informatique ou 3ème année ingénieur

Annotation sémantique fine de textes par clustering

Niveau : Master 2 informatique ou 3ème année ingénieur
Date de début : mars, avril 2015
Durée : 4-6 mois
Mots clefs: *informatique, apprentissage automatique non supervisé*, 
ontologie, sémantique distributionnelle, traitement automatique de la
langue

Contexte :

L'annotation sémantique fine de textes identifie et catégorise
automatiquement des termes dans des documents par des concepts
d'ontologies de grandes tailles. Elle est utilisée par les moteurs de
recherche sémantique, les outils d'extraction d'information et
Question-Réponse et par les méthodes de peuplement, de révision et
d'alignement d'ontologies. Les équipes de recherche en informatique
MaIAGE-Inra et LaHDAK-LRI développent des méthodes de modélisation de
connaissance à partir d'ontologies multiples par alignement et à partir
de textes pour l'acquisition de connaissance. L'objectif du stage est de
développer une méthode de sémantique distributionnelle appliquée au
texte pour (1) annoter sémantiquement des textes et (2) aligner des
ontologies en utilisant le texte.

Objectif :

L'approche proposée pour le stage est d'utiliser la sémantique
distributionnelle pour calculer une similarité sémantique entre les
termes à étiqueter et les concepts de l'ontologie. La sémantique
distributionnelle regroupe par clustering les termes sémantiquement
proches en fonction de leur contexte d'apparition dans le texte. Deux
voies seront explorées pour obtenir des distances pertinentes. Tout
d'abord, les contextes des termes seront décrits par les dépendances
syntaxiques locales. Ensuite, pour que les classes sémantiques soient
interprétables à la lumière de la structure a priori des ontologies, une
méthode de clustering semi-supervisé, comme celle de Lemaire &
Cornuejols [Ismaili et al., 2014] permettra de (1) guider la formation
des classes à l'aide de la connaissance des ontologies pour qu'elles
soient faciles à intégrer dans les ontologies et (2) d'expliquer les
classes formées pour qu'elles soient utilisables pour une éventuelle
révision de l'ontologie. Le stage sera réalisé en collaboration avec
l'unité Inra MIA Paris (Antoine Cornuéjols et Juliette Dibie).

Exemple : ""[..] /endophytic bacteria isolated from roots of coastal sand
dune plants/ [..]""
--> Le terme ""/coastal sand dune plants/"" doit être associé à la
catégorie ""/plant/"".

Données et logiciels :
Les données utilisées pour évaluer la méthode seront celles du domaine
des biotopes microbiens, développées par l'équipe Bibliome. Les méthodes
seront intégrées dans la suite AlvisNLP de l'équipe. Elles contribueront
à la préparation des données de la prochaine édition de la tâche BioNLP
Shared Task Bacteria Biotope.

Lieu : Unité MaIAGE, centre de recherche INRA, Jouy-en-Josas

Financement : Financement Labex DiGiCosme

Encadrants : Claire Nédellec, Equipe Bibliome, unité INRA MaIAGE
(http://bibliome.jouy.inra.fr) et Brigitte Safar, Equipe LahDAK, LRI,
Université Paris-Sud (http://lahdak.lri.fr)

Contact : Merci d'envoyer un CV et une lettre de motivation à
claire.nedellec[at]jouy.inra.fr et/ou brigitte.safar[at]lri.fr.


Références :

Robert Bossy, Wiktoria Golik, Zorana Ratkovic, Dialekti Valsamou,
Philippe Bessières, Claire Nédellec. An Overview of the Gene Regulation
Network and the Bacteria Biotope Tasks in BioNLP'13. BMC Bioinformatics,
à paraître en 2015.
Golik W., Warnier P., Nédellec C. ""Corpus-based extension of
termino-ontology by linguistic analysis: a use case in biomedical event
extraction. "" Ontology and Lexicon: new insights. Actes du workshop TIA
2011 : 9th International Conference on Terminology and Artificial
Intelligence, M. Slodzian et al., (eds), Paris, novembre 2011.
F. Hamdi, B. Safar, N. Niraula, C. Reynaud, TaxoMap alignment and
refinement modules: Results for OAEI 2010, Ontology Alignment Evaluation
Initiative (OAEI) 2010 Campaign - ISWC Ontology Matching Workshop,
Shanghai International Convention Center, Shanghai, Chine, 7 novembre,
2010.
Oumaima Alaoui Ismaili, Vincent Lemaire, and Antoine Cornuéjols. A
Supervised Methodology to Measure the Variables Contribution to a
Clustering. C.K. Loo et al. (Eds.): ICONIP 2014, (21th International
Conference on Neural Information Processing), Kuching, Malaisie, Part I,
LNCS 8834, pp. 159-166, Springer 2014.
V. Lemaire, O. Allaoui and A. Cornuéjols, ""Supervised pretreatments are
useful for supervised clustering"", in Proc. of the Second Conf. on Data
Analysis (ECDA-2014), Breme, Allemagne, Juillet, 2014."
"260","2015-02-02","LIMSI & CEA",NULL,"Offre de stage recherche Master 2 informatique

Combinaison de mÃ©thodes distributionnelle et d'extraction terminologique
pour l'adaptation de ressources terminologiques

Niveau : Master 2 informatique 
Date de dÃ©but : avril, mai 2015
DurÃ©e : 4-6 mois

Mots clefs: extraction terminologique, ressources linguistiques,
mÃ©thodes distributionnelles

Contexte :
L'extraction d'information mise en oeuvre sur des textes de spÃ©cialitÃ©
(articles scientifiques biomÃ©dicaux, dossiers patients, textes de loi,
etc.) s'appuie sur des corpus annotÃ©s fournissant des exemples d'entitÃ©s
Ã  retrouver. Pour amÃ©liorer leur couverture sur de nouveaux textes, il
est possible d'utiliser des ressources terminologiques recensant les
termes du domaine du corpus et des informations sÃ©mantiques associÃ©es
[2, 7]. Cependant, ces ressources ne sont pas suffisantes [1, 6] et
nÃ©cessitent un important travail d'adaptation au corpus et aux types
sÃ©mantiques des entitÃ©s devant Ãªtre identifiÃ©es. Pour rÃ©pondre Ã  cette
phase de constitution de ressources adaptÃ©es, il est envisageable
d'exploiter des mÃ©thodes d'extraction de termes et d'analyse
distributionnelle [3, 4].

Objectif :
L'objectif du stage est de proposer une approche visant Ã  combiner une
mÃ©thode d'extraction de termes avec une approche distributionnelle pour
constituer une ressource adaptÃ©e au corpus, associant des termes
extraits automatiquement et des informations sÃ©mantiques correspondant
aux types des entitÃ©s sÃ©mantiques visÃ©es. L'analyse des regroupements
distributionnels sera Ã©galement le moyen d'identifier les termes pouvant
Ãªtre polysÃ©miques.
Les contextes distributionnels exploitÃ©s pourront avoir des natures
diverses (fenÃªtres graphique [+/- n mots avant et aprÃ¨s un mot central],
fenÃªtres syntaxiques [chemins partagÃ©s dans le graphe de dÃ©pendance] ou
encore rÃ´les sÌemantiques issus d'un systÃ¨me de SRL). Ils permettront de
rapprocher des termes ou des schÃ©mas de termes prÃ©sentant des
similaritÃ©s non immÃ©diatement explicites.  L'apport de diffÃ©rentes
reprÃ©sentations sÃ©mantiques dans un contexte distributionnel sera
Ã©galement Ã©valuÃ©. Ces reprÃ©sentations sÃ©mantiques pourront Ãªtre des
ontologies ou bases de connaissances du domaine (UMLS dans le domaine
mÌedical par exemple) ou des bases de connaissances plus gÃ©nÃ©rales
(typiquement le rÃ©seau lexical WordNet).
Les traitements linguistiques seront effectuÃ©s Ã  l'aide des outils
disponibles dans les deux laboratoires (analyseur linguistique libre
LIMA [5], extracteur de termes YaTeA [8], etc.).

L'Ã©valuation de l'approche sera rÃ©alisÃ©e dans plusieurs langues
(notamment anglais et franÃ§ais), et s'appuiera sur des corpus
disponibles comme les corpus biomÃ©dicaux (I2B2, SemEval, Clef-eHealth).

Une poursuite en thÃ¨se pourra Ãªtre envisagÃ©e en fonction de l'obtention
d'un financement.

Lieu : dans l'un ou l'autre des laboratoires des encadrants, situÃ©s Ã 
       2 km l'un de l'autre,
LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann, Orsay
ou
CEA LIST, LVIC, Centre d'intÃ©gration Nano-INNOV, av. de la Vauve,
Palaiseau

Financement : Financement Labex DiGiCosme
              Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.

Encadrants : Thierry Hamon (LIMSI/CNRS) et GaÃ«l de Chalendar (CEA LIST)

Profil du candidat:
Le stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 2
informatique.
- IntÌerÃªt pour le TAL
- Connaissance (ou sensibilisation)
  - des mÃ©thodes d'acquisition terminologiques
  - des mÃ©thodes d'analyse distributionnelle
- Utilisation habituelle de Linux
- GoÃ»t pour la recherche et l'expÃ©rimentation

Contact : Merci d'envoyer un CV, une lettre de motivation, les notes
          de Master et les coordonnÃ©es de rÃ©fÃ©rents 
          Ã  thierry.hamon at limsi.fr et gael.de-chalendar@cea.fr
          avant le 21 fÃ©vrier 2015

RÃ©fÃ©rences :

[1] Olivier Bodenreider, Thomas C. Rindflesch, and Anita
    Burgun. Unsupervised, corpus-based method for extending a biomedical
    terminology. In Workshop on Natural Language Processing in the
    Biomedical Domain (ACL2002), pages 53-60, 2002.
[2] Kevin Bretonnel Cohen and Dina Demner-Fushman. Biomedical Natural
    Language Processing. John Benjamins publishing company, 2013.
[3] James R. Curran. From distributional to semantic similarity. Phd
    thesis, University of Edinburgh, 2004.
[4] R. Grishman and Y. He. An information extraction customizer. In
    P. Sojka et al., editor, Proceeedings of the conference Text, Speech
    and Dialogue, number 8655 in LNAI, pages 3-10, 2014.
[5] https://github.com/aymara/lima/wiki
[6] Alexa T. McCray, Allen C. Browne, and Olivier Bodenreider. The
    lexical properties of the gene ontology (GO). In Proceedings of the
    AMIA 2002 Annual Symposium, pages 504-508, 2002.
[7] S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and
    J. F. Hurdle. Extracting information from textual documents in the
    electronic health record: a review of recent research. IMIA Yearbook
    of Medical Informatics, 42(5):923-936, 2008.
[8] http://search.cpan.org/~thhamon/Lingua-YaTeA/"
"261","2015-02-04","MoDyCo","Nanterre","*Proposition de stage

Titre : *Construction d'une chaine de traitements linguistiques pour la
structuration de textes non structurés

*Contexte : *La ""mémoire"" est l'un des lieux où semble se jouer le lien
social contemporain. Nouvelle question sociale, elle constitue une
composante officielle de l'action municipale dans la plupart des grandes
métropoles. Qui posent ce que, dans leur diversité, l'ensemble des
acteurs qualifie de ""questions mémorielles"" ? De quels types de
régulation politique et de rapports sociaux ces ""questions mémorielles""
sont-elles la manifestation ? Comment et avec quels mots sont-elles
formulées ? Ces interrogations sont à l'origine du projet de recherche
""médiation de l'histoire locale"" rattaché au labex ""Les passés dans le
présent"" (http://www.passes-present.eu). Il est piloté par Sarah
Gensburger de l'Institut de Sciences politiques
(http://isp.cnrs.fr/?GENSBURGER-Sarah) et le laboratoire Modyco de
l'université Paris-Ouest Nanterre La défense (www.modyco.fr) y collabore
pour tout ce qui touche aux traitements de corpus.

*Objectif : *Pour avoir des éléments de réponse aux questions posées
ci-dessus, la construction d'une base de données des annonces des
associations loi 1901, créées depuis 1947, parmi lesquelles se trouvent
les associations qui s'intéressent à la ""mémoire"" est requise. En fait,
le Journal Officiel détient les archives de toutes ces déclarations qui
sont disponibles sous divers formats, dont un format text brut des pages
scannées puis océrisées de 1960 à 1984 et un format xml qui suit une DTD
commune pour la période de 1997 à 2014.

*Travail à réaliser*

Pour constituer cette BD, il faudra :

- construire une chaîne de traitements linguistiques permettant
  d'extraire de chaque page ""océrisée"" et de chaque annonce (environ 25
  annonces par page), les données utiles à la constitution d'une base de
  données à des fins d'analyse avec des outils de TDM (Text and data
  mining).

- construire une chaîne de traitements pour détecter des erreurs
  générées par l'OCR

- construire une chaîne de traitement permettant d'intégrer les fichiers
  xml à cette base de données

Une fois la base de données créée, il faudra développer une interface
d'interrogation pour extraire de cette BD, des déclarations
d'associations répondant à divers critères (dates, domiciliation des
associations, requêtes booléennes sur l'objet des associations, etc.),
convertir les résultats extraits en fichier au format CSV

*Qualifications requises*

- Connaissances des techniques du TAL

- Compétences informatiques : au moins un langage de programmation (PHP,
  Java, Python), XML, bases de données

*Modalités de recrutement*
- Type de contrat : Stage
- Durée : 3 à 4 mois à temps plein
- Rémunération : à hauteur de 600¤ euros par mois
- Date de prise de fonction : le plus tôt possible
- Lieu : Université Paris-Ouest La Défense, laboratoire Modyco (200, 
  avenue de la République, Batiment A, 92 Nanterre)

*Procédure de recrutement*
Le dossier de candidature est à envoyer avant le 20 février 2015 à
Mathilde de Saint Leger (mdesaintleger at u-paris10.fr) Ce dossier
comprendra : un curriculum vitae détaillé et une lettre de motivation.
Pour toute précision, les candidats sont invités s'ils le souhaitent, à
prendre contact au préalable avec Mathilde de Saint Leger (mdesaintleger
at u-paris10.fr) ou Sarah Gensburger (sgensburger at yahoo.fr)

Mathilde de Saint Leger"
"262","2015-02-10","Lattice","Paris","======================================================================
Visualisation d'informations extraites de corpus sous forme de graphes
======================================================================

* Descriptif rapide
-----------------------

Le LATTICE propose un stage dans le domaine des humanités numériques. On
dispose aujourd'hui d'outils efficaces pour analyser les corpus et en
extraire l'information pertinente. On peut ainsi repérer les entités
nommées et les liens entre entités, puis produire des graphes à partir
des résultats de cette analyse. Cependant, les graphes obtenus sont
fréquemment peu lisibles, voire carrément inexploitables, du fait de la
masse d'informations à représenter. Le stage porte justement sur
l'amélioration de la visualisation, ainsi que sur l'élaboration de
nouvelles méthodes de filtrage des données en fonction des besoins des
utilisateurs. On envisagera par exemple des représentations « à
profondeur variable » (ou « multi-échelle »), où des informations plus
précises peuvent apparaître dynamiquement en fonction des demandes des
utilisateurs.

Le domaine d'application est celui des humanités numériques, et on
travaillera de manière privilégiée sur des corpus de sociologie et/ou de
sciences politiques, en français et/ou en anglais.

Le stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à
10 mn du métro Mairie de Montrouge et à 5 mn de l'arrêt du Tram ligne 3
« Jean Moulin »).

Le stage est prévu pour une durée de 4 à 6 mois à compter de mars ou
avril 2015. Il donnera obligatoirement lieu à la signature d'une
convention de stage et sera rémunéré suivant les règles en vigueur.

* Profil recherché 
-----------------------

- Formation en informatique ou traitement automatique des langues (M2,
  école d'ingénieur, éventuellement M1 avec une bonne expérience de la
  programmation)
- Bonne connaissance de python ou, à défaut, de perl
- Intérêt pour le traitement automatique des langues
- Bon niveau d'anglais (écrit / oral)

Pour candidater : envoyer un mail avec un CV et une lettre de motivation
à thierry.poibeau@ens.fr"
"263","2015-02-10","Lattice","Paris","========================================================================
Analyse de corpus littéraire au moyen d'outils de traitement automatique
des langues
========================================================================

* Descriptif rapide
-----------------------

On dispose aujourd'hui de plus en plus de corpus numérisés, y compris
dans des domaines littéraires ou philosophiques. Les outils de
traitement des langues permettent de les étudier sous différents
aspects, thématiques, rhétoriques ou stylistiques par exemple, sans que
l'apport des outils existants soit encore bien connu. Le stage visera à
identifier des outils pertinents pour la tâche, examiner leurs résultats
et voir comment ils font sens pour des experts du domaine
considéré. Plusieurs corpus sont possibles : on déterminera au début du
stage lequel semble le plus intéressant, en fonction des collaborations
en cours au sein de l'Ecole normale supérieure.

Le stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à
10 mn du métro Mairie de Montrouge et à 5 mn de l'arrêt du Tram ligne 3
« Jean Moulin »).

Le stage est prévu pour une durée de 4 à 6 mois à compter de mars ou
avril 2015. Il donnera obligatoirement lieu à la signature d'une
convention de stage et sera rémunéré suivant les règles en vigueur.

* Profil recherché 
-----------------------

- Formation en traitement automatique des langues (M2, éventuellement M1
  avec une expérience de la programmation)
- Bonne connaissance de python ou, à défaut, de perl
- Intérêt pour le traitement automatique des langues
- Bon niveau d'anglais (écrit / oral)

Pour candidater : envoyer un mail avec un CV et une lettre de motivation
à thierry.poibeau@ens.fr"
"264","2015-02-10","Lattice","Paris","========================================================================
Stage sur les réseaux de neurones pour le traitement automatique des
langues
========================================================================

* Descriptif rapide
-----------------------

Le LATTICE, en collaboration avec l'IRIT, propose un stage de niveau M2
sur l'analyse des paramètres d'un modèle de réseau de neurones appliqué
à l'acquisition de restrictions de sélection. Un descriptif détaillé en
anglais figure ci-dessous.

Le stage aura lieu au laboratoire LATTICE à Montrouge, près de Paris (à
10 mn du métro Mairie de Montrouge et à 5 mn de l'arrêt du Tram ligne 3
« Jean Moulin »). Il sera co-encadré par Thierry Poibeau et Marco
Dinarelli au LATTICE et par Tim van de Cruys à l'IRIT (les échanges avec
Toulouse se feront principalement par Skype).

Le stage est prévu pour une durée de 6 mois à compter de mars ou avril
2015. Il donnera obligatoirement lieu à la signature d'une convention de
stage et sera rémunéré suivant les règles en vigueur.

* Profil recherché 
-----------------------

- Formation en informatique ou traitement automatique des langues (M2,
  école d'ingénieur, éventuellement M1 avec une bonne expérience de la
  programmation)
- Bonne connaissance de python ou, à défaut, de perl
- Intérêt pour le traitement automatique des langues
- Bon niveau d'anglais (écrit / oral)
- Des connaissances en matière de réseau de neurones seraient évidement
  un plus

Pour candidater : envoyer un mail avec un CV et une lettre de motivation
à thierry.poibeau@ens.fr


* Descriptif détaillé
-----------------------


An Exploration of a Neural Network Model's Parameters for Selectional
Preference Acquisition

Predicates often have a semantically motivated preference for particular
arguments [1]. Compare for example the sentences in (1) and (2).

(1) The vocalist sings a ballad.
(2) The exception sings a tomato.

While both sentences are grammatically correct, the second sentence is
clearly ill-formed. This preference of a verb for particular arguments
is known as the verb's selectional preference. Recently, a neural
network approach has been shown to perform well on the modeling of
selectional preferences [2]. However, many parameters remain to be
investigated. First of all, a neural network's parameters may be
initialized in a number of different ways. For example, the parameters
might be initialized randomly, or they may be initialized using
previously constructed word embeddings. Secondly, the neural network's
architecture leaves ample space for experiments. The neural network's
architecture might be more `deep' or more `shallow', the size of the
network's layers may be varied, and certain parameters within the
network might be shared.

This internship will investigate the influence of different network
parameters on the performance of a neural network for the modeling of
selectional preferences. The student will adapt and train an existing
neural network implementation for selectional preference acquisition,
and examine the role of various model parameters for the network's
performance.

References:

[1] Van de Cruys, Tim ; Rimell, Laura ; Poibeau, Thierry and Korhonen,
Anna. 2012. Multi-way Tensor Factorization for Unsupervised Lexical
Acquisition. In Proceedings of the 24th International Conference on
Computational Linguistics (COLING), Mumbai, India.

[2] Van de Cruys, Tim. 2014. A Neural Network Approach to Selectional
Preference Acquisition. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing (EMNLP), pp. 26-35,
Doha, Qatar. Association for Computational Linguistics."
"265","2015-02-10","LIMSI","Orsay","------------------------------------------------------------------------

2 offres de stages recherche TAL ukrainien, Master 1 ou 2
informatique ou linguistique informatique

 - Etiquetage morpho-syntaxique de l'ukrainien
 - Extraction de termes Ã  partir de textes ukrainiens

------------------------------------------------------------------------

Sujet: Etiquetage morpho-syntaxique de l'ukrainien

Offre de stage recherche Master 1 ou 2 informatique ou linguistique
informatique

Niveau : Master 1 ou 2 informatique ou linguistique informatique
Date de dÃ©but : avril, mai 2015
DurÃ©e : 5 mois

Mots clefs : Ukrainien, Ã‰tiquetage morpho-syntaxique, langue peu dotÃ©e,
CRF, Traitement Automatique des Langues

Contexte : Ce stage se situe dans le contexte d'un projet de
dÃ©veloppement d'outils de Traitement Automatique de la Langue
ukrainienne.

Du point de vue du TAL, l'ukrainien est une langue peu dotÃ©e.  Ainsi,
il existe trÃ¨s peu de travaux de TAL ou de ressources linguistiques
sur cette langue: le jeu d'Ã©tiquettes morpho-syntaxiques Multex-East
[1] a intÃ©grÃ© l'ukrainien en 2010 [2] ; un Ã©tiqueteur
morpho-syntaxique Ã  base de rÃ¨gles et de dictionnaires (UGtag) a Ã©tÃ©
mis au point mais sans que la dÃ©sambiguÃ¯sation des Ã©tiquettes soit
rÃ©alisÃ©e [3]; une mÃ©thode de reconnaissance des entitÃ©s nommÃ©es a Ã©tÃ©
proposÃ©e [4] ; un corpus parallÃ¨le polonais-ukrainien a Ã©tÃ© constituÃ© [5].


Objectif : L'objectif du stage est de dÃ©velopper un Ã©tiqueteur
morpho-syntaxique dans une premier temps pour la langue gÃ©nÃ©rale, puis
pour les langues de spÃ©cialitÃ©, aprÃ¨s adaptation au domaine visÃ©.

La mÃ©thodologie d'Ã©tiquetage morpho-syntaxique mise en oeuvre devra tenir
compte des particularitÃ©s de l'ukrainien. En effet, comme les autres
langues slaves, il s'agit d'une langue morphologiquement riche : les
informations flexionnelles jouent un rÃ´le important tandis que la
morphologie dÃ©rivationnelle et compositionnelle est trÃ¨s frÃ©quente dans
la formation des constructions grammaticales (par exemple, aspect,
temps) et lexicales. De plus, bien que l'ordre canonique des phrases
soit sujet-verbe-objet (SVO), Ã©tant une langue Ã  cas, l'ukrainien
autorise un ordre des mots assez libre sans introduire pour autant
d'effets stylistiques particuliers.  Ces particularitÃ©s, communes Ã  la
plupart des langues slaves, peuvent entraÃ®ner des difficultÃ©s pour les
mÃ©thodes classiques d'Ã©tiquetage.

La mise au point de l'Ã©tiqueteur morpho-syntaxique de l'ukrainien pourra
conduire Ã  la dÃ©finition de modÃ¨les CRF Ã  travers le logiciel Wapiti [6]
et en utilisant les informations fournies par UGtag [3]. Cependant, elle
pourra Ã©galement s'appuyer sur les travaux existants dans des langues
proches telles que le tchÃ¨que [7] ou le polonais [8]. De mÃªme, la faible
quantitÃ© de ressources disponibles ou de corpus annotÃ©s doit conduit Ã 
s'inspirer des mÃ©thodes d'Ã©tiquetage morpho-syntaxique dÃ©jÃ  proposÃ©es
pour des langues peu dotÃ©es, notamment en utilisant l'existant (UGtag),
en sÃ©lectionnant les exemples nÃ©cessaires Ã  l'apprentissage du modÃ¨le
[9,10,11] ou en utilisant des mÃ©thodes de transfert [12].

La mÃ©thode sera mise en oeuvre et Ã©valuÃ©e sur un corpus composÃ© de textes
de la littÃ©rature ukrainienne et des collections de documents issus des
domaines de spÃ©cialitÃ© comme l'informatique et la mÃ©decine.  Le stage
bÃ©nÃ©ficiera de collaborations existantes avec des chercheurs en TAL
parlant l'ukrainien.

Lieu : LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann,
       Orsay

Financement : Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.

Encadrants : Thierry Hamon et Thomas Lavergne (LIMSI/CNRS)

Profil du candidat:
Le stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 1 ou 2
informatique ou linguistique informatique.

- IntÃ©rÃªt pour le TAL
- Connaissance (ou sensibilisation)
  - des mÃ©thodes d'Ã©tiquetage morpho-syntaxique
  - des mÃ©thodes d'apprentissage automatique
- Connaissance de l'ukrainien
- Utilisation habituelle de Linux
- GoÃ»t pour la recherche et l'expÃ©rimentation

Contact : Merci d'envoyer un CV, une lettre de motivation, les notes de
          Master et les coordonnÃ©es de rÃ©fÃ©rents Ã  thierry.hamon at
          limsi.fr et lavergne at limsi.fr avant le 21 fÃ©vrier 2015

RÃ©fÃ©rences :

[1] http://nl.ijs.si/ME/V4/

[2] Erjavec (TomaÅ¾). -- MULTEXT-East: Morphosyntactic Resources for
  Central and Eastern European Languages. Language Resources and
  Evaluation, vol. 46 (1), 2012, pp. 131--142.

[3] Kotsyba (Natalia), Mykulyak (Andriy) et Shevchenko (Ihor V.). --
  UGTag: morphological analyzer and tagger for the Ukrainian language.
  In: Proceedings of the international conference Practical Applications
  in Language and Computers (PALC 2009).

[4] Katrenko (Sophia) et Adriaans (Pieter). -- Named Entity Recognition
  for Ukrainian: A Resource-Light Approach.  In: Proceedings of the
  Workshop on Balto-Slavonic Natural Language Processing. pp. 88--93. --
  Prague, Czech Republic, June 2007.

[5] http://www.domeczek.pl/~polukr/

[6] Lavergne (Thomas), Cappe (Olivier) et Yvon (Francois). -- Practical
  Very Large Scale CRFs. In: Proceedings the 48th Annual Meeting of the
  Association for Computational Linguistics (ACL). pp. 504--513. --
  Association for Computational Linguistics.  http://wapiti.limsi.fr

[7] Collins (Michael), Hajic (Jan), Ramshaw (Lance) et Tillmann
  (Christoph). -- A Statistical Parser for Czech. In: Proceedings of the
  37th Annual Meeting of the Association for Computational
  Linguistics. pp.  505--512. -- College Park, Maryland, USA, June 1999.

[8] [KobyliÅ„ski 2013]Kobylieski2013 KobyliÅ„ski (Åukasz). -- Improving
  the Accuracy of Polish POS Tagging by Using Voting Ensembles. In:
  Proceedings of the 6th Language Technology Conference: Human Language
  Technologies as a Challenge for Computer Science and Linguistics,
  ed. par Vetulani (Zygmunt). pp. 453--456.  -- PoznaÅ„, Poland, 2013.

[9] Goldberg (Yoav), Adler (Meni) et Elhadad (Michael). -- EM Can Find
  Pretty Good HMM POS-Taggers (When Given a Good Start). In: Proceedings
  of ACL-08: HLT. pp. 746--754. -- Columbus, Ohio, June 2008.

[10] Garrette (Dan), Mielens (Jason) et Baldridge (Jason). -- Real-World
  Semi-Supervised Learning of POS-Taggers for Low-Resource
  Languages. In: Proceedings of the 51st Annual Meeting of the
  Association for Computational Linguistics (Volume 1: Long Papers). pp.
  583--592. -- Sofia, Bulgaria, August 2013.

[11] Duong (Long), Cohn (Trevor), Verspoor (Karin), Bird (Steven) et
  Cook (Paul). -- What Can We Get From 1000 Tokens? A Case Study of
  Multilingual POS Tagging For Resource-Poor Languages. In: Proceedings
  of the 2014 Conference on Empirical Methods in Natural Language
  Processing (EMNLP).  pp. 886--897. -- Doha, Qatar, October 2014.

[12] Yarowsky (David), Ngai (Grace), Wicentowski (Richard). -- Inducing
  Multilingual Text Analysis Tools via Robust Projection across Aligned
  Corpora. In: Proceedings of the First International Conference on
  Human Language Technology Research, HLT'01, pages 1-8. -- Stroudsburg,
  PA, USA.

------------------------------------------------------------------------

Sujet: Extraction de termes Ã  partir de textes ukrainiens

Offre de stage recherche Master 1 ou 2 informatique ou linguistique
informatique

Niveau : Master 1 ou 2 informatique ou linguistique informatique
Date de dÃ©but : avril, mai 2015
DurÃ©e : 5 mois

Mots clefs : Ukrainien, Extraction de termes, langue peu dotÃ©e,
Terminologie, Traitement Automatique des Langues

Contexte : Ce stage se situe dans le contexte d'un projet de
dÃ©veloppement d'outils de Traitement Automatique de la Langue
ukrainienne.

Du point de vue du TAL, l'ukrainien est une langue peu dotÃ©e.  Ainsi, il
existe trÃ¨s peu de travaux de TAL ou de ressources linguistiques sur
cette langue: le jeu d'Ã©tiquettes morpho-syntaxiques Multex-East [1] a
intÃ©grÃ© l'ukrainien en 2010 [2] ; un Ã©tiqueteur morpho-syntaxique Ã  base
de rÃ¨gles et de dictionnaires (UGtag) a Ã©tÃ© mis au point mais sans que
la dÃ©sambiguÃ¯sation des Ã©tiquettes soit rÃ©alisÃ©e [3]; une mÃ©thode de
reconnaissance des entitÃ©s nommÃ©es a Ã©tÃ© proposÃ©e [4] ; un corpus
parallÃ¨le polonais-ukrainien a Ã©tÃ© constituÃ© [5].


Objectif : L'objectif du stage est de dÃ©velopper une extracteur de
termes pour des textes de spÃ©cialitÃ© rÃ©digÃ©s en ukrainien dans la
perspective de la constitution de terminologie et de la fouille de
textes de spÃ©cialitÃ© [6].

La mise au point de l'approche pour l'extraction de termes pourra
s'appuyer sur des travaux en extraction terminologique [7] ou plus
fondamentaux portant sur la terminologie en ukrainien [8,9]. Elle
conduira Ã  la dÃ©finition de rÃ¨gles pouvant Ãªtre intÃ©grÃ©es dans
l'extracteur YaTeA [10] tout en tenant compte des particularitÃ©s de
l'ukrainien : comme les autres langues slaves, il s'agit d'une langue
morphologiquement riche ; les informatiques flexionnelles jouent un rÃ´le
important tandis que la morphologie dÃ©rivationnelle et compositionnelle
est trÃ¨s frÃ©quente.  Dans la mesure du possible, on envisagera
d'utiliser des mÃ©thodes d'apprentissage notamment pour produire
automatiquement des rÃ¨gles d'identification ou pour effectuer une
adaptation de l'extracteur au domaine.

La mÃ©thode sera mise en oeuvre et Ã©valuÃ©e sur un corpus de textes issus
des domaines de spÃ©cialitÃ© comme l'informatique et la mÃ©decine.  Les
textes auront Ã©tÃ© Ã©tiquetÃ©s avec UGtag.  Le stage bÃ©nÃ©ficiera de
collaborations existantes avec des chercheurs en TAL parlant
l'ukrainien.


Lieu : LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann,
       Orsay

Financement : Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.

Encadrants : Thierry Hamon et Thomas Lavergne (LIMSI/CNRS)

Profil du candidat:
Le stage de recherche est destinÃ© Ã  un Ã©tudiant en Master 1 ou 2
informatique ou linguistique informatique.

- IntÃ©rÃªt pour le TAL
- Connaissance (ou sensibilisation) des mÃ©thodes d'acquisition
  terminologiques
- Connaissance de l'ukrainien
- Utilisation habituelle de Linux
- GoÃ»t pour la recherche et l'expÃ©rimentation

Contact : Merci d'envoyer un CV, une lettre de motivation, les notes
          de Master et les coordonnÃ©es de rÃ©fÃ©rents
          Ã  thierry.hamon at limsi.fr et lavergne at limsi.fr
          avant le 21 fÃ©vrier 2015

RÃ©fÃ©rences :

[1] http://nl.ijs.si/ME/V4/

[2] Erjavec (TomaÅ¾). -- MULTEXT-East: Morphosyntactic Resources for
  Central and Eastern European Languages. Language Resources and
  Evaluation, vol. 46 (1), 2012, pp. 131--142.

[3] Kotsyba (Natalia), Mykulyak (Andriy) et Shevchenko (Ihor V.). --
  UGTag: morphological analyzer and tagger for the Ukrainian language.
  In: Proceedings of the international conference Practical Applications
  in Language and Computers (PALC 2009).

[4] Katrenko (Sophia) et Adriaans (Pieter). -- Named Entity Recognition
  for Ukrainian: A Resource-Light Approach.  In: Proceedings of the
  Workshop on Balto-Slavonic Natural Language Processing. pp. 88--93. --
  Prague, Czech Republic, June 2007.

[5] http://www.domeczek.pl/~polukr/

[6] Meystre (S. M.), Savova (G. K.), Kipper-Schuler (K. C.) et Hurdle
  (J. F.). - Extracting information from textual documents in the
  electronic health record : a review of recent research. IMIA Yearbook
  of Medical Informatics, vol. 42 (5), 2008, p. 923-936.

[7] Pazienza (MariaTeresa), Pennacchiotti (Marco) et Zanzotto
  (FabioMassimo). - Terminology Extraction : An Analysis of Linguistic
  and Statistical Approaches. In : Knowledge Mining, Ed. par Sir-
  makessis (Spiros), pp. 255-279. - Springer Berlin Heidelberg, 2005.

[8] Shyshkina (Nataliia), Zorko (Galina) et Lesko (Larisa). --
  Terminology Work and Software Localization in Ukraine. In: The Third
  International Conference Problems of Cybernetics and Informatics,
  pp. 17--20. -- Baku, Azerbaijan, 2010.

[9] Mentynska (Iryna). -- Lexical and genetic characteristics of modern
  computer terminology, 2014.

[10] Aubin (Sophie), Hamon (Thierry). -- Improving Term Extraction with
  Terminological Resources. In Advances in Natural Language Processing
  (5th International Conference on NLP, FinTAL 2006). pp. 380-387. LNAI
  4139. Turku, Finland, August 2006.
  http://search.cpan.org/~thhamon/Lingua-YaTeA"
"266","2015-02-12","LIA","Avignon","Stage recherche M2 : ModÃ¨les connexionnistes pour la gÃ©nÃ©ration
automatique dans le cadre de l'interaction vocale

DurÃ©e : 5 mois
DÃ©marrage : le plus tÃ´t possible
Lieu : Laboratoire Informatique d'Avignon
Encadrants: Bassam Jabaian, StÃ©phane Huet et Fabrice LefÃ¨vre

Description du stage :
Les systÃ¨mes d'interactions vocales utilisÃ©s dans des applications comme
la rÃ©servation de billets d'avion ou d'hÃ´tels, ou bien encore le
dialogue avec un robot, font intervenir plusieurs composants. Parmi
ceux-ci figurent le module de gÃ©nÃ©ration de texte qui produit la rÃ©ponse
du systÃ¨me en langue naturelle Ã  partir d'une reprÃ©sentation sÃ©mantique
interne crÃ©Ã©e par le gestionnaire de dialogue.

Les systÃ¨mes de dialogue actuels intÃ¨grent des modules de gÃ©nÃ©ration
basÃ©s sur des rÃ¨gles Ã©crites Ã  la main Ã  partir de patrons.  ex :
confirm(type=$U, food=$W,drinks=dontcare) â†’ Let me confirm, you are
looking for a $U serving $W food and any kind of drinks right ?

Ces modules gagneraient Ã  se baser sur des mÃ©thodes d'apprentissage
automatique afin de faciliter la portabilitÃ© des systÃ¨mes de dialogue
vers d'autres tÃ¢ches et amÃ©liorer la diversitÃ© des Ã©changes gÃ©nÃ©rÃ©s.
Parmi les mÃ©thodes d'apprentissage automatique, figurent les rÃ©seaux de
neurones qui ont vu un regain d'intÃ©rÃªt depuis l'utilisation du Â« /deep
learning/ Â». Ces rÃ©seaux de neurones ont dÃ©jÃ  Ã©tÃ© employÃ©s par Google
dans une tÃ¢che similaire de gÃ©nÃ©ration de description d'images
(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html).
L'objectif de ce stage est d'Ã©tudier l'utilisation de ces modÃ¨les dans
le cadre de l'interaction vocale.

Si un intÃ©rÃªt pour l'apprentissage automatique et le traitement de la
langue naturelle est souhaitable, il est attendu surtout du stagiaire de
bonnes capacitÃ©s en dÃ©veloppement logiciel.

Pour candidater : envoyer un mail avec un CV et une lettre de motivation
Ã  bassam.jabaian@univ-avignon.fr"
"267","2015-02-12","Sinequa","Paris","*Offre de stage chez Sinequa*

Sinequa (www.sinequa.com) propose une plateforme logicielle de Search et
d'Analyse du Big Data en temps réel aux entreprises du Fortune Global
2000. Capitalisant sur 25 années d'expérience en recherche linguistique,
la puissance de la technologie Sinequa repose sur l'analyse
linguistique, sémantique et statistique qui permet aux grandes
entreprises et organisations d'apprivoiser la complexité de leurs
données, structurées ou non structurées.


Sinequa cherche un/une stagiaire pour travailler sur la langue
portugaise, essentiellement l'extraction de concepts (groupes nominaux
courts) puis l'extraction d'entités nommées en cas de stage plus
long. Le travail se déroulera au siège de l'entreprise à Paris pour une
durée de 3 à 6 mois durant le printemps et/ou l'été 2015.


::Compétences demandées::

- Profil : Etudes de linguistique ou linguistique-informatique ou cursus
  avec mention TAL

- Langues : Excellente maîtrise du portugais et du français et/ou
  l'anglais

- Connaissances en Recherche d'information et Extraction d'Entités
  Nommées appréciées


Contact: Aurélia Marcus, marcus@sinequa.com"
"268","2015-02-12","Sinequa","Paris","*Offre de stage chez Sinequa*

Sinequa (www.sinequa.com) propose une plateforme logicielle de Search et
d'Analyse du Big Data en temps réel aux entreprises du Fortune Global
2000. Capitalisant sur 25 années d'expérience en recherche linguistique,
la puissance de la technologie Sinequa repose sur l'analyse
linguistique, sémantique et statistique qui permet aux grandes
entreprises et organisations d'apprivoiser la complexité de leurs
données, structurées ou non structurées.


Sinequa cherche un/une stagiaire pour travailler sur la langue
portugaise, essentiellement l'extraction de concepts (groupes nominaux
courts) puis l'extraction d'entités nommées en cas de stage plus
long. Le travail se déroulera au siège de l'entreprise à Paris pour une
durée de 3 à 6 mois durant le printemps et/ou l'été 2015.


::Compétences demandées::

- Profil : Etudes de linguistique ou linguistique-informatique ou cursus
  avec mention TAL

- Langues : Excellente maîtrise du portugais et du français et/ou
  l'anglais

- Connaissances en Recherche d'information et Extraction d'Entités
  Nommées appréciées


Contact: Aurélia Marcus, marcus@sinequa.com

---------------

[Stage] Thaï - [Internship] Thai


[English version follows]


Offre de stage chez Sinequa

Sinequa (www.sinequa.com) propose une plateforme logicielle de Search et
d'Analyse du Big Data en temps réel aux entreprises du Fortune Global
2000. Capitalisant sur 25 années d'expérience en recherche linguistique,
la puissance de la technologie Sinequa repose sur l'analyse
linguistique, sémantique et statistique qui permet aux grandes
entreprises et organisations d'apprivoiser la complexité de leurs
données, structurées ou non structurées.


Sinequa cherche un/une stagiaire pour travailler sur la langue thaï,
essentiellement la segmentation en phrases et mots. Le travail se
déroulera au siège de l'entreprise à Paris pour une durée de 3 à 6 mois
durant le printemps et/ou l'été 2015.


::Compétences demandées::

- Profil : Etudes de linguistique ou linguistique-informatique ou cursus
  avec mention TAL

- Langues : Excellente maîtrise du thaï et du français et/ou l'anglais

- Connaissances en morphosyntaxe

Contact: Aurélia Marcus, marcus@sinequa.com"
"269","2015-02-12","LORIA","Nancy","=====================================

Offre de stage de M2 :

Lieu : LORIA, Ã©quipe SÃ©magramme (INRIA, CNRS, U. de Lorraine), Nancy

Encadrants : Maxime Amblard (UL) et Sylvain Pogodalla (INRIA)

Sujet : Grammaires CatÃ©gorielles Abstraites Ã  large couverture et
	ingÃ©nierie grammaticale

DurÃ©e : 6 mois

Contrat : stage conventionnÃ© rÃ©munÃ©rÃ©
=======================================
(version pdf : http://semagramme.loria.fr/lib/exe/fetch.php?media=projects:sujet-polymnie.pdf)

Les Grammaires CatÃ©gorielles Abstraites (ACG) sont un formalisme dÃ©diÃ© Ã 
la description de la syntaxe et de la sÃ©mantique des langues
naturelles. FondÃ©es sur le fragment implicatif de la logique linÃ©aire,
elles manipulent des Î»-termes linÃ©aires qui permettent de modÃ©liser
aussi bien les chaÃ®nes de caractÃ¨res que les arbres, deux notions
omniprÃ©sentes en linguistique informatique. Les ACG permettent d'encoder
diffÃ©rents formalismes grammaticaux, notamment les grammaires d'arbres
adjoints (TAG).

Un environnement de test et de dÃ©veloppement des ACG, ACGtk[1], a Ã©tÃ©
dÃ©veloppÃ© par l'Ã©quipe SÃ©magramme. Il dÃ©finit un langage pour la
spÃ©cification et l'utilisation d'ACG pour l'analyse grammaticale. Il a
Ã©tÃ© dÃ©veloppÃ© en Caml[2], un langage de programmation fonctionnel.

L'objectif gÃ©nÃ©ral de cette proposition de stage est de s'appuyer sur
une grammaire TAG Ã  large couverture et intÃ©grant la sÃ©mantique pour
Ã©tudier la question de l'ingÃ©nierie grammaticale pour les ACG Ã  l'aide
d'ACGtk. Cela comporte des aspects d'analyse et de conception liÃ©s aux
contraintes d'un tel environnement de dÃ©veloppement, ainsi que des
aspects liÃ©s Ã  la modÃ©lisation grammaticale.

Il s'agira dans un premier temps de bien comprendre l'utilisation qui
est faite des grammaires et de saisir les similaritÃ©s existantes avec
les langages de programmation. Pour ce faire, on s'appuiera sur les
travaux thÃ©oriques d'encodage dans les ACG des grammaires TAG. Cette
traduction conduira Ã  l'identification de caractÃ©ristiques souhaitables,
tant d'un point de vue pratique (fonctionnalitÃ©s d'ACGtk) que d'un point
de vue thÃ©orique (utilisation des structures de traits, rÃ©vision de
l'encodage).

Dans un deuxiÃ¨me temps, en s'inspirant de travaux d'environnements
semblables (comme GF[3]), il s'agira de proposer des extensions au
langage de dÃ©veloppement prenant en compte les usages et prÃ©sentant les
fonctionnalitÃ©s analysÃ©es. On mentionnera par exemple la combinaison de
lexiques, la dÃ©finition d'espaces de nommage pour les signatures et les
lexiques, etc.

Enfin, il s'agira de mettre en oeuvre tout ou partie de ce qui aura Ã©tÃ©
dÃ©fini prÃ©cÃ©demment et de l'intÃ©grer Ã  ACGtk.

Ce travail sera rÃ©alisÃ© au sein de l'Ã©quipe SÃ©magramme[4], notamment
dans le cadre du projet ANR Polymnie[5] concernant l'analyse et la
gÃ©nÃ©ration avec les ACG.

[1] http://www.loria.fr/equipes/calligramme/acg/#Software
[2] http://caml.inria.fr/ 
[3] http://www.grammaticalframework.org/
[4] http://semagramme.loria.fr/
[5] http://semagramme.loria.fr/doku.php?id=projects:polymnie"
"270","2015-02-19","IRT SystemX","Palaiseau","STAGE M2: TAL, Extraction d'information pour la veille géopolitique -
IRT SystemX

durée 6 mois, démarrage février-avril 2015

Vous serez partie prenante d'une équipe projet composée de 3 étudiants à
qui nous proposons 3 stages:
- Spécifications et modèle économique d'une application de veille
  géopolitique,
- Design d'une application de veille géopolitique et enfin
- Extraction d'information pour la veille géopolitique, qui est l'objet
  de cette annonce.

Les technologies de traitement automatique de la langue (TAL) sont au
coeur de tous les métiers qui cherchent à exploiter plus efficacement
les documents non structurés disponibles sur le web ou dans des bases de
documents (articles de journaux, brevets, blogs, journaux télévisés,
articles scientifiques). Le volume de ces données ne rend possible la
consultation manuelle que d'une infime partie. Les outils de TAL vont
servir à filtrer les documents pertinents, en extraire les informations
essentielles, les structurer et les visualiser pour prendre les bonnes
décisions.

Au sein de l'IRT SystemX, Le projet de recherche intitulé IMM
(Intégration Multimédia Multilingue), est un projet tri annuel démarré
fin 2014. Il regroupe des industriels (Bertin Technologie, CapGemini,
Exalead, OVH, Systran, Temis, Vecsys, Vocapia) et des partenaires
académiques (CEA-LIST, CNRS-LIMSI, INRIA-Saclay, LNE, UPMC-LIP6) ainsi
que le Ministère de la Défense. Son objectif est de mettre en place une
plateforme qui intègre les composants des partenaires (moteur de
recherche, de transcription de la parole, de traduction...) pour des
applications de veille. L'objectif commun est de relever un certain
nombre de défis transverses: réduire le temps d'adaptation à un contexte
nouveau (sources, domaine, langue), en particulier la montée en
puissance des réseaux sociaux, spécifier et développer des fonctions de
haut niveau pour améliorer la productivité d'un professionnel de la
veille, étudier et mettre en place des stratégies pour permettre le
passage à l'échelle des solutions envisagées. Dans le cadre de ce
projet, nous proposons à 3 étudiants de développer un cas d'utilisation
civil de cette plate-forme.

L'objectif de l'ensemble des 3 stages est de créer un démonstrateur
d'application de veille dans le domaine de la géopolitique et de la
géostratégie, à l'usage des entreprises qui souhaitent investir ou
développer leurs ventes dans une région ou un pays, en s'appuyant sur
les technologies mises à disposition par la plate-forme IMM. Plus
concrètement, il s'agit donc de mettre en oeuvre les fonctions de la
plate-forme pour automatiser la collecte d'informations et de documents,
pour ensuite les analyser et produire des synthèses. Les documents sont
collectés sur le web, aussi bien depuis des sites institutionnels que
depuis des réseaux sociaux. La collecte d'information visera plus
particulièrement les textes de lois et les réglementations en cours, le
contexte plus général lié à la culture ou l'histoire du pays (par
exemple l'impact de la loi islamique sur une région particulière), mais
aussi les projets de lois (par exemple les normes en cours d'élaboration
au niveau européen) ainsi que les réactions qu'elles suscitent et les
activités de lobbying autour de ces projets.

On cherchera plus particulièrement à mettre en valeur les capacités
suivantes de la plate forme :

- Recherche d'information multilingue,
- Extraction d'information (entités nommées et relations),
- Collecte et analyse des réseaux sociaux (Le lobbying est une activité
  assez transparente et qui laisse des traces en particulier sur les
  réseaux sociaux),

- Analyse des contenus de vidéos (transcription de journaux télévisés
  par exemple),

- Visualisation innovante des données collectées analysées et indexées.


Vos missions seront les suivantes :
- Vous familiariser avec les outils mis à disposition par la plate-forme
  IMM,
- En collaboration avec l'étudiant des stages 1 et 3, contribuer à la
  spécification d'un prototype d'application de veille géopolitique, et
  en particulier élaborer la spécification fonctionnelle et technique en
  tenant compte de la plate-forme existante.
- Elaborer le modèle d'extraction d'information et en particulier
  définir quelles entités nommées et quelles relations sont déjà
  traitées par la plate-forme IMM et peuvent être réutilisées, quelles
  entités plus spécifiques au domaine de la veille géostratégique sont
  critiques pour réaliser un démonstrateur.
- Sélectionner une partie de ce modèle et enrichir les outils
  d'extraction de la plate-forme (annotation, apprentissage, évaluation
  de la qualité..)
- Collecter des corpus, les traiter pour alimenter le prototype

Le profil recherché : BAC +5, étudiant dans le domaine de l'informatique
avec une spécialisation en traitement automatique des langues, en
recherche d'information ou en apprentissage artificiel pour un stage de
6 mois environ sur le site IRT SYSTEMX à Palaiseau.

Vos Compétences sont :
- Capacité à traiter des corpus (langages perl, python) ou des
  ressources linguistiques
- Programmation langage orienté objet (Java, C++)
- Capacité à utiliser un framework/middleware (comme Apache
  Camel/ServiceMix)

Vos aptitudes personnelles sont :
- Rigueur, sens des responsabilités
- Bon relationnel, capacités à travailler en collaboration


Référence : CREE_2015_IMM1_03_02_141029
Pour postuler : stages@irt-systemx.fr"
"271","2015-02-23","IGN","Saint-Mandé","===================================

Analyse des sentiments et des qualités sonores de lieux à partir de
cartes et de photographies
http://recherche.ign.fr/labos/cogit/
http://www.u-cergy.fr/fr/laboratoires/labo-crtf.html

Mots-clés
traitement automatique du langage naturel, traitement d'enquête,
interactions verbales

Contexte
Ce stage s'inscrit dans le cadre du projet CartASUR : CARTographie des
Ambiances Sonores URbaines. La directive européenne relative à
l'évaluation et à la gestion du bruit impose la mise en place de cartes
de bruit pour de grosses agglomérations. Ces cartes établies pour les
flux de circulation réguliers, ne reflètent pas l'ambiance sonore
ressentie par les citadins. Pourtant ces cartes doivent servir d'outil
de communication avec le public. La directive propose donc aux
états-membres d'utiliser des indicateurs qui prennent en compte des
sources, des événements ou des périodes particuliers. Dans ce contexte,
l'objectif de ce projet est de publier sur un site web des cartes
sonores construites sur des indicateurs adaptés au ressenti de la
population (et en particulier, l'indicateur agrégé d'agrément sonore) et
accessibles à tous les acteurs (aménageurs, décideurs et citadins). Les
indicateurs de ressenti de la population sont construits à partir de
mesures obtenues lors d'une enquête (la zone d'enquête couvre une partie
des 13ème et 14ème arrondissements parisiens).
Les attendus de ce projet sont multiples, et en particulier montrer que
cette nouvelle génération de cartes traduit le passage d'une politique
normative à une politique constitutive en matière de gestion des
nuisances sonores. Sur le plan opérationnel, le projet devra avoir pour
effet de : i) mettre à la disposition du public des informations
permettant une meilleure appropriation de la problématique du bruit dans
l'environnement ; ii) améliorer la connaissance de l'environnement
sonore et utiliser les résultats pour la mise en place de plans d'action
(préventifs et curatifs).

Afin d'évaluer la qualité des cartes sonores produites, une première
campagne d'entretiens a été réalisée auprès d'un échantillon de
population. Le matériel de ces entretiens consiste en des cartes et des
photographies présentées sur support papier. L'objectif est de : 

- valider les représentations associées aux cartes réalisées dans le
  cadre du projet : ces cartes montrent différentes informations, dont
  l'agrément sonore, et doivent permettre aux usagers de se représenter
  la qualité sonore des lieux ;

- évaluer la validité de la symbolisation des lieux par les cartes à
  travers le contraste d'enquêtes cartes/photos.

Les questions posées lors de ces entretiens consistent :
- à évaluer des caractéristiques des cartes réalisées (densité
  d'information, utilité, etc.) sur une échelle graduée ;

- à compter des symboles correspondant à certains types d'objets
  cartographiques sur ces cartes ;

- à évaluer la qualité des symboles utilisés sur les cartes selon les
  connotations mises en place par les lecteurs de la carte.

Certaines questions appellent aussi des réponses libres qui sont
enregistrées.

Missions confiées :
Ce stage s'intègre à cette dernière partie du projet qui concerne
l'évaluation des cartes produites. Cette évaluation se fait au travers
des résultats d'une première enquête qu'il sera nécessaire de compléter
par des questions plus ouvertes afin de produire une analyse
linguistique et lexicométrique des réponses.

Les missions contenues dans ce stage sont les suivantes :
- analyse de cette première campagne d'entretiens et réflexion sur les
  questionnaires administrés ;

- propositions de questions pour une nouvelle campagne d'enquêtes (avec
  des questions ouvertes dont les réponses seront enregistrées) ;

- aide à la passation des enquêtes (importance des connaissances
  linguistiques sur la mise en mots des données sensibles) ;

- transcription et mise en forme des résultats d'enquêtes : constitution
  d'un corpus conforme aux standards de l'équipe ;

- début des analyses sur les corpus : liens entre les cartes et les
  photographies et le ressenti (en particulier celui de l'agrément
  sonore) ; connotations des cartes et de leur symbologie ; formes de
  subjectivité dans la mise en mots des enquêtés ; sentiments et
  opinions exprimées à travers des marques énonciatives et des indices
  pragmatiques ; évaluation des cartes à travers notamment l'analyse des
  lexiques utilisés par les enquêtés.

Responsables de stage	
Catherine DOMINGUES
IGN/SR/COGIT, 73 avenue de Paris, 94165 SAINT-MANDE Cedex
mél : catherine.domingues@ign.fr	tél : 01 43 98 85 44

Julien LONGHI
IUT de Cergy-Pontoise, Dpt MMI, 34 Bd Bergson 95200 Sarcelles
mél : julien.longhi@u-cergy.fr

Compétences particulières et formation requise
Ce stage s'adresse aux étudiants de master 2 (ou formation équivalente)
avec une spécialisation en TALN, en linguistique de corpus, en analyse
des interactions verbales ou en informatique.

Durée, lieu du stage, rémunération
La durée prévue est de cinq mois, avec un début en avril/mai 2015.
Le stage se déroulera au laboratoire COGIT de l'IGN à Saint-Mandé et le
stagiaire sera amené à se rendre régulièrement à l'IUT de Cergy-Pontoise
(site de Sarcelles), ou à l'Université de Cergy-Pontoise (site de
Neuville) où se trouve Catherine LAVANDIER, la responsable scientifique
du projet CartASUR.

IGN/laboratoire COGIT
73 avenue de Paris
94160 Saint-Mandé 
métro : Saint-Mandé - ligne 1 ou RER A : Vincennes

IUT de Cergy-Pontoise (site de Sarcelles)
34 boulevard Henri-Bergson
95200 Sarcelles
RER D arrêt Garges-Sarcelles 

IUT de Cergy Pontoise (site de Neuville sur Oise)-Laboratoire MRTE
5 Mail Gay Lussac, Neuville sur Oise
95 031 Cergy Pontoise Cedex
RER A direction Cergy-le-haut, arrêt Neuville-Université

rémunération mensuelle : environ 500 euros

Prolongements éventuels
Les laboratoires proposent chaque année des sujets de thèse ainsi que
des stages de post-doctorant.

Pour candidater
Le dossier de candidature sera envoyé par mail. Il devra se composer
d'un curriculum vitae et d'une lettre de motivation, accompagnés des
relevés de notes des années de M1 et M2 (ou deux dernières années
d'école d'ingénieurs) et d'une description des enseignements suivis (un
lien vers le site internet de la formation est le bienvenu)."
"272","2015-02-26","EDF","Clamart","STAGE INGÉNIERIE LINGUISTIQUE
SUJET 2015: Catégorisation, Clustering
DURÉE : 6 MOIS ENVIRON

1.  CONTEXTE
 
Le volume des données numériques textuelles, disponibles sur l'Internet
(forums, twitters etc.) ou relatives à des contacts client (enquêtes,
centre d'appel etc.), augmente chaque année. L'analyse de ces
informations, structurées ou non, est, aujourd'hui, un impératif
stratégique pour une entreprise telle qu'EDF. Dans ce cadre, et dans
l'objectif de toujours mieux connaître les besoins des clients,
l'exploitation de ces documents implique l'utilisation de méthodes
d'extraction d'information, de classification supervisée, ainsi que des
méthodes d'analyse exploratoire. 


2.	 SUJET DU STAGE

Depuis plusieurs années, EDF utilise l'outil Luxid®, solution développée
par l'éditeur TEMIS (Text-Mining Solution). Cette technologie permet de
générer des modèles de catégorisation et des clustering à partir
d'extraction de concepts métier. Les résultats obtenus sont aujourd'hui
satisfaisants et permettent une analyse qualitative des données à
traiter. Malgré les bons résultats, nous aimerions tester des
algorithmes d'analyse alternatifs et mettre en oeuvre une nouvelle
approche grâce à des outils Open-source.

Dans le cadre de ce stage, nous aimerions mettre en place une chaîne de
traitement permettant d'utiliser les concepts métier extraits par Luxid®
comme variables d'entrée d'un classifieur et d'une méthode de
clustering. L'objectif est de valider la faisabilité tout en évaluant la
qualité des résultats obtenus. Il s'agirait aussi de mener un état de
l'art des algorithmes de classification supervisée et de clustering
existants permettant de répondre à la question : Quelle est la méthode
statistique la plus performante pour nos besoins ?

Ainsi, le stage se découpe en 3 étapes importantes :

1- Faire un état de l'art et une description précise des différents
   algorithmes possibles pour la classification supervisée et le
   clustering

2- Tester des outils Open-source capable d'utiliser les concepts métier
   extraits par Temis

   a. Avec un algorithme similaire à celui utilisé par EDF

   b. Avec d'autres algorithmes que ceux utiliser aujourd'hui par EDF

3- Mesurer la qualité des résultats et comparer les résultats avec ceux
   de Temis
 

3. INFORMATIONS PRATIQUES

Interlocuteurs	
Delphine Lagarde	01.47.65.39.75	delphine.lagarde@edf.fr 

Lieu du stage	
EDF R&D - Département ICAME
1, avenue du Général de Gaulle
92141 Clamart Cedex	

Date & Durée 
2015 - 6 mois environ

Rémunération
A définir (environ 1.000¤/mois)"
"273","2015-02-26","Grammatica","Arras","Stage de M2 Linguistique et informatique : « Constitution de corpus et
extraction d'unités lexicales »

Offre de stage de M2 : Traitement de documents écrits et vidéos

Lieu : Equipe GRAMMATICA (EA4521), Université d'Artois, Arras, France

Encadrants : Luis Meneses-Lerín (MCF) & Jean-Marc Mangiante (PR)

Sujet : Traitement/constitution de corpus & extraction de collocations
et phraséologismes

Durée : 5-6 mois

Début : mi-mars

Contrat : stage conventionné CNRS rémunéré (500¤/mois)

Descriptif :

L'objectif du corpus est double : d'une part, construire un référentiel
de compétences langagières pour certains métiers dans l'hôtellerie et
restauration pour l'enseignement du français sur objectifs spécifiques
(Mangiante, 2004) et, d'autre part, extraire et analyser le cotexte de
collocations et phraséologismes (Meneses, 2014) du point de vue
linguistique.

Qualifications requises :

- Compétences linguistiques : lexique et phraséologie

- Compétences informatiques : PHP,Perl, Python, XML, bases de données

Procédure de recrutement :

Le CV de candidature est à envoyer avant le 2 mars 2015 à Luis
Meneses-Lerín (luis_meneses_lerin@yahoo.fr). Pour toute précision, les
candidats sont invités s'ils le souhaitent, à prendre contact au
préalable avec Luis Meneses-Lerín (luis_meneses_lerin@yahoo.fr)."
"274","2015-02-26","L3i","La Rochelle","Dans le cadre d'un travail commun entre le laboratoire L3i et
Charente-Maritime Tourisme, en prolongement du projet Tourinflux, nous
proposons un stage indemnisé de 10 semaines, intitulé "" *Outil de
visualisation de données de déplacements de touristes* "", et dont un
descriptif détaillé suit.

*Résumé du travail proposé :*

Organiser les données de flux de déplacement issues d'un opérateur
mobile majeur au sein d'une solution technique permettant de mieux
visualiser les données (sous forme de tableaux, graphiques, voire
cartes) afin de définir les indicateurs en vue d'une analyse plus
détaillée de la fréquentation touristique du département et des flux de
déplacement afférents.

*Mots clés :*

Visualisation de données (tableau, carte), data mining, recherche
facettée

*Contexte de l'étude:***

*Zone d'étude*:

  * Périmètre spatial : 10 zones de Charente-Maritime (cf carte) + tests
    sur 10 zones des Deux-Sèvres
  * Périmètre Temporel : juillet 2014 à mars 2015

*Livrables*:

  * solution technique exploitable par CMT et ses partenaires (solution
    open source)
  * outil de visualisation et de rendu (tableaux, cartes, recherche
    facettée, etc.)
  * prévoir une prise en main de l'outil par CMT

*Déroulé du stage :*

  * Lieu du stage : CMT au Conseil général / Université de La Rochelle
    (en alternance)
  * Période de stage : 20 avril - 26 juin (10 semaines)
  * Indemnisation : réglementaire
  * Encadrement : en plus de CMT et de l'Université, l'étudiant sera
    amené à faire une présentation de l'état d'avancement devant les
    représentants des collectivités (réunions de travail).

**

*Description du sujet :*

Réaliser un outil de visualisation des données sous forme tabulaire et
cartographique. Cet outil, open source, devra être flexible dans la
mesure où il devra tenir compte des évolutions de segmentation des
données. Les données des Deux-Sèvres seront probablement également
intégrées à cet outil, sous réserve que la structuration des données
fournies par Orange soit identique à celles de la Charente-Maritime.Ce
sera travail s'inscrit dans le cadre d'un prolongement du projet
investissement d'avenir Tourinflux.**

**

*Prérequis et contraintes particulières :*

*Compétences techniques :*

- Programmation :

- Javascript et bibliothèque de visualisation de données (par ex. 3DJs)

- API Google Maps ou Open Street Map

- La connaissance d'un ETL et d'outils de traitement statistique serait
  un plus.

- Bonne aptitude au travail en équipe (Agilité, GIT) et à la
  communication (présentation lors de réunion...).

*Contacts - liens : *

*Email *:

CV + lettre de motivation à envoyer à : Antoine Doucet 
(antoine.doucet@univ-lr.fr), Cyril 
Faucher (cyril.faucher@univ-lr.fr),
Mickaël Coustaty (mickael.coustaty@univ-lr.fr)"
"275","2015-03-05","LI","Blois","===========================================================
Proposition de stage de Master ou de fin d'études ingénieur
===========================================================

Titre : Extraction et caractérisation automatique d'auteurs sur le Web


Responsables
-------------

Nicolas Labroche (LI, Nicolas.Labroche@univ-tours.fr)
Jean-Yves Antoine (LI, Jean-Yves.Antoine@univ-tours.fr)
Agata Savary (LI, Agata.Savary@univ-tours.fr)
Jean-Christophe Lavocat (Elokenz, jice@elokenz.com)

Résumé
------

Dans un contexte où l'information est massivement disponible et de mieux
en mieux structurée, l'extraction automatique de données n'a jamais été
aussi importante. Faisant écho à de récentes évolutions des moteurs de
recherches classiques (Google, Bing), la détection de l'auteur d'une
page devient un enjeux stratégique.
L'objet de ce stage consiste en la création d'un algorithme d'extraction
automatique de l'auteur d'une page web donnée. Les données structurées,
linguistiques et hiérarchiques seront utilisées dans un algorithme
d'apprentissage automatique pour déterminer si un nom extrait d'une page
correspond à son auteur. Le travail réalisé aura deux principaux
objectifs : (1) détecter automatiquement les auteurs d'un texte à partir
du code source d'une page web (si ils sont mentionnés) et, (2) de les
identifier (si possible) grâce à leurs profils sociaux qui pourraient
être présents sur la même page.

Contexte scientifique
----------------------
Le Laboratoire d'Informatique de l'Université de Tours, et son équipe 
Base de Données et Traitement du Langage Naturel situé à l'antenne de 
Blois (41) propose un sujet de stage dans le cadre du projet industriel 
financé par la société ELOKENZ (représentée en la personne de M. 
Jean-Christophe LAVOCAT) située à Toulon (83) et adossée à l'Incubateur 
Public Paca EST et à la structure Toulon Var Technologie (TVT).

Travail à réaliser
------------------

Le rendu de ce stage sera constitué d'un algorithme prenant comme entrée 
une page HTML ou XML et renvoyant en sortie une liste des auteurs 
détectés dans le texte, avec leur nom et si possible des liens vers des 
profils sociaux les identifiant.

- Phase n°1 - La première phase du projet consiste à prétraiter les
  ressources pour en faire des documents valides XML et à en extraire
  les noms propres. Pour ce dernier point, deux méthodes pourront être
  évaluées et comparées : d'une part, l'utilisation de bibliothèque
  d'extraction d'entités nommées (comme Balie ou Lingpipe) ou bien
  utiliser des listes de noms. Pour simplifier le problème, dans un
  premier temps on pourra ne considérer qu'une seule langue pour la
  liste de noms, mais l'algorithme proposé devra à terme pouvoir
  travailler indifféremment avec toute liste de noms fréquents passée en
  argument.

- Phase n°2 - La seconde phase du projet consiste en la création d'un
  ensemble d'apprentissage suffisamment grand contenant pour un ensemble
  de ressources la liste des noms y apparaissant et pour chacun, une
  étiquette indiquant s'il s'agit d'un nom d'auteur ou pas. On pourra
  créer un second ensemble d'apprentissage avec les informations
  sociales qui pourraient être présentes dans la page en vue du second
  objectif.

- Phase n°3 - La dernière phase du projet consiste à déterminer un
  ensemble d'attributs pour décrire chaque nom identifié dans la phase
  précédente. On pourra s'appuyer sur des travaux précédents dans le
  domaine et enrichir cela à partir de connaissances linguistiques (pour
  lesquelles un expert sera disponible). Il faudra ensuite évaluer
  différents algorithmes d'apprentissage automatique sur la base de
  cette représentation parmi les arbres de décision, les forêts
  aléatoires, les SVM, et les réseaux de neurones pour apprendre un
  modèle. On favorisera en premier lieu une méthode interprétable (comme
  les arbres de décision) de façon à pouvoir étudier les règles qui
  définissent le modèle de classification et les confronter à la
  connaissance que des linguistes pourront apporter au projet.

Profil recherché
-----------------

La personne recrutée sera en cycle terminal d'études en informatique, de 
niveau Bac+5 (Master ou Ecole d'ingénieur en Informatique).
Un intérêt pour les techniques d'apprentissage et de classification
automatiques, voire le Traitement Automatique des Langues est apprécié,
sans être un prérequis à recrutement. Dans le cas d'un(e) étudiant(e) en
Master Recherche, le sujet de stage pourra être adapté aux attentes de
l'étudiant.

Rémunération
------------

508 ¤ par mois. Cette rémunération sera assurée par la société ELOKENZ.

Durée du stage et lieu d'exercice
---------------------------------

La personne recrutée travaillera au sein du laboratoire LI, dans les
locaux de l'antenne universitaire de Blois.
Il s'intégrera dans une équipe projet de l'équipe de recherche BDTLN
(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) composée de
Nicols Labroche, Jean-Yves Antoine et Agata Savary.
Des points de rendez-vous réguliers avec la société ELOKENZ seront
prévus au cours du stage.

La durée minimale de stage sera de 5 mois (avril-août 2015).

Contact - Dépôts de candidature
-------------------------------

Contact : Nicolas Labroche (nicolas.labroche@univ-tours.fr), Jean-Yves
Antoine (jean-yves.antoine@univ-tours.fr)

Merci de déposer par courrier électronique un CV détaillé de vos
activités passées, accompagné d'une lettre de motivation et de vos
relevés de notes des deux dernières années d'études."
"276","2015-03-05","LIMSI & CEA","Orsay","Offre de stage recherche rÃ©munÃ©rÃ© Master 1 ou 2 ou ingÃ©nieur
Informatique

Combinaison de mÃ©thodes distributionnelle et d'extraction terminologique
pour l'adaptation de ressources terminologiques

Niveau : Master 1 ou 2 ou ingÃ©nieur informatique 
Date de dÃ©but : avril, mai 2015
DurÃ©e : 4-6 mois

Mots clefs: extraction terminologique, ressources linguistiques,
mÃ©thodes distributionnelles

Contexte :
L'extraction d'information mise en oeuvre sur des textes de spÃ©cialitÃ©
(articles scientifiques biomÃ©dicaux, dossiers patients, textes de loi,
etc.) s'appuie sur des corpus annotÃ©s fournissant des exemples d'entitÃ©s
Ã  retrouver. Pour amÃ©liorer leur couverture sur de nouveaux textes, il
est possible d'utiliser des ressources terminologiques recensant les
termes du domaine du corpus et des informations sÃ©mantiques associÃ©es
[2, 7]. Cependant, ces ressources ne sont pas suffisantes [1, 6] et
nÃ©cessitent un important travail d'adaptation au corpus et aux types
sÃ©mantiques des entitÃ©s devant Ãªtre identifiÃ©es. Pour rÃ©pondre Ã  cette
phase de constitution de ressources adaptÃ©es, il est envisageable
d'exploiter des mÃ©thodes d'extraction de termes et d'analyse
distributionnelle [3, 4].

Objectif :
L'objectif du stage est de proposer une approche visant Ã  combiner une
mÃ©thode d'extraction de termes avec une approche distributionnelle pour
constituer une ressource adaptÃ©e au corpus, associant des termes
extraits automatiquement et des informations sÃ©mantiques correspondant
aux types des entitÃ©s sÃ©mantiques visÃ©es. L'analyse des regroupements
distributionnels sera Ã©galement le moyen d'identifier les termes pouvant
Ãªtre polysÃ©miques.
Les contextes distributionnels exploitÃ©s pourront avoir des natures
diverses (fenÃªtres graphique [+/- n mots avant et aprÃ¨s un mot central],
fenÃªtres syntaxiques [chemins partagÃ©s dans le graphe de dÃ©pendance] ou
encore rÃ´les sÌemantiques issus d'un systÃ¨me de SRL). Ils permettront de
rapprocher des termes ou des schÃ©mas de termes prÃ©sentant des
similaritÃ©s non immÃ©diatement explicites.  L'apport de diffÃ©rentes
reprÃ©sentations sÃ©mantiques dans un contexte distributionnel sera
Ã©galement Ã©valuÃ©. Ces reprÃ©sentations sÃ©mantiques pourront Ãªtre des
ontologies ou bases de connaissances du domaine (UMLS dans le domaine
mÌedical par exemple) ou des bases de connaissances plus gÃ©nÃ©rales
(typiquement le rÃ©seau lexical WordNet).
Les traitements linguistiques seront effectuÃ©s Ã  l'aide des outils
disponibles dans les deux laboratoires (analyseur linguistique libre
LIMA [5], extracteur de termes YaTeA [8], etc.).

L'Ã©valuation de l'approche sera rÃ©alisÃ©e dans plusieurs langues
(notamment anglais et franÃ§ais), et s'appuiera sur des corpus
disponibles comme les corpus biomÃ©dicaux (I2B2, SemEval, Clef-eHealth).

Une poursuite en thÃ¨se pourra Ãªtre envisagÃ©e en fonction de
l'obtention d'un financement.

Lieu : dans l'un ou l'autre des laboratoires des encadrants, situÃ©s Ã 
       2 km l'un de l'autre,
LIMSI/CNRS, BÃ¢t. 508, UniversitÃ© Paris XI, Rue John Von Neumann, Orsay
ou
CEA LIST, LVIC, Centre d'intÃ©gration Nano-INNOV, av. de la Vauve,
Palaiseau

Financement : Financement Labex DiGiCosme
              Le stage sera rÃ©munÃ©rÃ© selon les rÃ¨gles en vigueur.

Encadrants : Thierry Hamon (LIMSI/CNRS) et GaÃ«l de Chalendar (CEA LIST)

Profil du candidat:
Le stage de recherche est destinÃ© Ã  un Ã©tudiant niveau Master 1 ou 2 
ou ingÃ©nieur informatique.
- IntÌerÃªt pour le TAL
- Connaissance (ou sensibilisation)
  - des mÃ©thodes d'acquisition terminologiques
  - des mÃ©thodes d'analyse distributionnelle
- Utilisation habituelle de Linux
- GoÃ»t pour la recherche et l'expÃ©rimentation

Contact : Merci d'envoyer un CV, une lettre de motivation, les notes
          de Master et les coordonnÃ©es de rÃ©fÃ©rents AUX DEUX ENCADRANTS :
          thierry.hamon at limsi.fr ET gael.de-chalendar@cea.fr

RÃ©fÃ©rences :

[1] Olivier Bodenreider, Thomas C. Rindflesch, and Anita
    Burgun. Unsupervised, corpus-based method for extending a
    biomedical terminology. In Workshop on Natural Language Processing
    in the Biomedical Domain (ACL2002), pages 53-60, 2002.
[2] Kevin Bretonnel Cohen and Dina Demner-Fushman. Biomedical Natural
    Language Processing. John Benjamins publishing company, 2013.
[3] James R. Curran. From distributional to semantic similarity. Phd
    thesis, University of Edinburgh, 2004.
[4] R. Grishman and Y. He. An information extraction customizer. In
    P. Sojka et al., editor, Proceeedings of the conference Text,
    Speech and Dialogue, number 8655 in LNAI, pages 3-10, 2014.
[5] https://github.com/aymara/lima/wiki
[6] Alexa T. McCray, Allen C. Browne, and Olivier Bodenreider. The
    lexical properties of the gene ontology (GO). In Proceedings of
    the AMIA 2002 Annual Symposium, pages 504-508, 2002.
[7] S. M. Meystre, G. K. Savova, K. C. Kipper-Schuler, and
    J. F. Hurdle. Extracting information from textual documents in the
    electronic health record: a review of recent research. IMIA
    Yearbook of Medical Informatics, 42(5):923-936, 2008.
[8] http://search.cpan.org/~thhamon/Lingua-YaTeA/"
"277","2015-03-13","Xerox Research Centre Europe","Grenoble","Xerox Research Centre Europe, located in Grenoble, is offering the
following internship for Spring 2015:

 

-------------------------------------------------------------------

Internship: Modeling next sentence in a dialog using vector space
models

-------------------------------------------------------------------

 

See: http://www.xrce.xerox.com/About-XRCE/Internships/Modeling-next-sentence-in-a-dialog-using-vector-space-models

 

Contacts :

                Dymetman, Marc             marc.dymetman@xrce.xerox.com  

                Venkatapathy, Sriram    sriram.venkatapathy@xrce.xerox.com

 

Please mention ""Modeling next sentence in a dialog using vector space
models"" in your subject line.

 

Duration: 4.5 months

Start Date: April - June 2015

 

Given the context of an observed dialog history up to a certain point,
the goal of this internship will be to develop predictive models for
the next utterance. A good model of the next utterance should
substantially reduce its ``perplexity'' with respect to a baseline
language model. Based on a large collection of available chats in the
customer-care domain, the feasibility of learning such models will be
explored. The perplexity score will be used to evaluate the
performance of various models that will be examined. The internship
will also involve using such models for the task of actually
predicting the next utterance, up to some limited editing actions. The
idea will be to retrieve the top candidates for the next sentence from
all the sentences that have ever been uttered. One of the criteria for
retrieval will be the perplexity of these sentences relative to the
learnt model.

 

For modelling, we will focus on models that represent the dialog
history as a real vector. Such representations have been extensively
used in recent years for encoding the semantics of words and
sentences. Several ideas will be explored using frameworks such as
Topic modelling and Deep Neural Networks.

 

The ideal candidate is a Computer Science student at the Master or
(preferably) PhD level, with a background in Machine Learning and
NLP. Strong programming skills are a requirement (Python, C++,
Java...). Conference publication of the work will be strongly
encouraged."
"278","2015-03-16","ELDA","Paris","Descriptif
-----------

- Sujet : Développement d'un outil générique d'annotation des ressources
  linguistiques

- Niveau : M2 / dernière année d'école d'ingénieur

- Domaine : informatique

- Période : à partir de mars-avril 2015

- Durée : 6 mois

Contexte
--------
Acteur majeur des technologies de la langue, ELDA (Evaluations and
Language resources Distribution Agency) est une PME dont les activités
s'articulent principalement autour de la distribution et de la
production de ressources linguistiques.Dans le cadre des projets de
production de ressources linguistiques dont elle est en charge, ELDA est
souvent amenée à des tâches de collecte, d'annotation de contrôle
qualité, de packaging, etc.).Afin de pouvoir gérer la grande variété des
différents protocoles et formats d'annotations, ELDA projette d'intégrer
en une seule plate-forme un ensemble d'outils qui permettent la gestion
homogène et transparente des ressources linguistiques annotées.

Dans ce contexte, ELDA souhaite consolider sa plate-forme, qui devrait
permettre :
- d'importer des ressources annotées déjà existantes ;
- de créer de nouvelles ressources linguistiques, y compris l'annotation
  de nouveaux corpus ;
- de naviguer dans une ressource linguistique recensée dans la
  plate-forme, ou à travers plusieurs ressources ;
- de récupérer et d'effectuer des statistiques sur des éléments des
  corpus et/ou des annotations.

Travail à réaliser
------------------

Au sein de l'équipe de développement informatique d'ELDA, sous la
tutelle d'un ingénieur spécialiste du traitement automatique des
langues, vous serez amené à participer aux travaux suivants :

- faire un état de l'art sur les outils d'annotation de ressources
  linguistiques disponibles actuellement ;

- spécifier / réviser l'architecture de l'outil d'annotation à mettre en
  place chez ELDA ;

- réaliser des développements dans des outils d'annotation, de concert
  avec les autres membres de l'équipe de développement informatique
  d'ELDA ;

- développer des composantes logicielles d'importation et d'exportation
  de données annotées depuis et vers des formats existants, autres que
  le format utilisé par l'outil d'annotation.

Vos participerez également aux réunions périodiques de l'équipe de
développements logiciels d'ELDA.


Profil souhaité
---------------

- BAC + 4/5 / Dernière année d'École d'ingénieur ;
- Bonnes connaissances pratiques de la programmation orientée objet ;
- Connaissances de base en algorithmique ;
- Connaissances de base des architectures des applications Web ;
- Connaissance pratique d'un système de gestion de bases de données ;
- Anglais technique ;
- La connaissance du langage Python sera appréciée ;
- Des notions sur le langage JavaScript seront un plus.


Candidature
-----------

Ce stage, d'une durée de 6 mois et basé à Paris dans le 13e
arrondissement (Les Gobelins), est à pourvoir au printemps 2015.

Les candidatures (CV, lettre de motivation) doivent être adressées à
Vladimir Popescu (vladimir@elda.org).

Le stage fait l'objet d'une rémunération, variable en fonction du niveau
d'études du candidat.

www.elda.org"
"279","2015-03-18","ODW",NULL,"Nous sommes une agence spécialisée dans la communication et le community
management et recrutons un(e) stagiaire ou doctorant(e) sous contrat
pour une mission de 3 à 6 mois.

Le/la candidat(e) retenu(e) sera responsable de la réalisation d'un
algorithme d'analyse sémantique et collaborera directement avec les
fondateurs d'ODW, un programmeur ainsi qu'un consultant basé à
Londres. Cette mission s'inscrit dans le cadre du développement d'un
outil d'analyse de segments d'audience.


Objectifs/responsabilités :

 1. Développer un algorithme d'extraction d'entités nommées à partir de
    texte non structuré - principalement conversations d'utilisateurs de
    réseaux sociaux :

    a) sélection des modèles

    b) Implémentation

    c) Scalability assessment

 2. Analyse des résultats produits par l'algorithme:

    a) catégorisation thématique des documents

    b) conception et réalisation de graphs et autres méthodes de
       présentation visuelle


 3. Contribuer à la réalisation du prototype:

    a) Planning et suivi des objectifs

    b) Présentation de l'outil à des utilisateurs non experts en
       linguistique informatique


Compétences:

 Requises:

 a) Maîtrise des principales méthodes de linguistique informatique

 b) Programmation Python (ou autre langage orienté objet)

 
 Recherchées mais non nécessaires pour candidater :

 a) Acquisition et stockage de données à travers des APIs (AWS, Twitter
    Search, ...)

 b) Requêtes de données au format noSQL (notamment MongoDB)

 c) Software programming

Merci d'envoyer votre CV à bonjour@odw.fr en précisant vos dates de
disponibilité."
"280","2015-04-01","Cantoche","Paris","Nous recherchons un stagiaire en traitement du langage.

Société : CANTOCHE
Intitulé du poste : Stagiaire en développement sur le traitement du langage (TAL)
Lieu de travail : PARIS
Type de contrat : Stage conventionné
Rémunération : 30% du SMIC + chèques déjeuners
Date de disponibilité : immédiate


Description du poste

Nous recherchons actuellement un Stagiaire en développement sur le
traitement du langage (TAL)

Au sein d'une équipe expérimentée et à taille humaine et en relation
avec directeur technique, vous serez amené(e) à réaliser une étude
comparative des solutions TAL existantes, et à implémenter/tester les
plus pertinentes dans le but d'enrichir le moteur sémantique du
produit d'assistance virtuelle de Living ActorTM.

Fondée en 1999, Cantoche s'est distingué comme l'un des leaders
mondiaux des agents virtuels intelligents et l'animation des avatars
dans tous types d'applications Web et mobile. Cantoche a deux domaines
d'expertise unique : la partie artistique pour la création de
personnage et le développement logiciel avec sa suite logicielle
propriétaire Living ActorTM.

Cantoche est basé en France et aux USA et plus de 1000 sociétés de
plusieurs pays utilisent nos solutions telles que BNP, GDF, EDF,
Toshiba, Natixis, Airbus, Sanofi...


Profil recherché

Vous avez un cursus TAL et vous maîtrisez les langages Java et
Linux. Vous avez un bon niveau en Anglais et de bonnes qualités de
rédaction.

Contact

Envoyer CV et lettre de motivation à : job [ chez ] cantoche.com"
"281","2015-04-16","Airbus","Toulouse","Nous proposons un stage dans le département de facteurs humains, section
linguistique à Airbus Toulouse.

Le sujet du stage porterait sur la construction (amélioration de qualité
et précision) des alertes audio dans les cockpits des avions Airbus.

Le sujet sera plutôt centré sur des recherches en linguistique : sur la
façon de donner un ordre en plusieurs langues, les paramètres
d'intonation, accentuation etc. Les recherches s'appuieront entre autre
sur la phonétique, phonologie, psycholinguistique, syntaxe, sémantique
et pragmatique.

Des connaissances en TAL seront appréciés, et une bonne maitrise de
l'anglais. 

La durée du stage est de 6 mois.
Contact : CV + lettre de motivation à envoyer à
emmanuelle.cannesson@airbus.com, nataly.n.jahchan@airbus.com,
laurent.spaggiari@airbus.com

------------------------------------------------------------------------

Description of the job:
Airbus (Toulouse) is looking for an intern for a 6-month internship.

Flight crew alerting systems make use of aural alerts in order to warn
the crew of unexpected situations or incoming events.
You will be responsible for improving the quality and precision of aural
alerts in different situations in Airbus civil aircraft.

Tasks & accountabilities:
Your responsibilities will include:

* Describing the different ways to express aurally, from a syntactical
  and terminological point of view, in different languages:
  - Order
  - Prohibition
  - Advice
  - Questioning
  - Normal vs. abnormal status
  - Studying parameters such as intonation, accentuation, speed,
    repetition, voice intensity.

Required skills:
You are completing a master degree or you are in the final year of an
engineering school or of university (5th year), specialising in
Linguistics, Phonetics/Phonology, Semantics/Syntax.
You ideally have initial experience in this field.
You have knowledge of:

 *   Linguistics
 *   Phonetics/phonology
 *   Pragmatics

You are a good team player and have excellent interpersonal skills.
English: Advanced level.

Localisation:
AIRBUS France SAS
316, route de Bayonne
31060 Toulouse Cedex 03

Nataly JAHCHAN
PhD Candidate, EYDNX
Human Factors Department
Phone: +33 5 82 05 98 39
Nataly.n.jahchan@airbus.com"
"282","2015-08-19","Xerox Research Center Europe","Grenoble","Xerox Research Centre Europe, located in Grenoble, is offering the
following internship for Fall 2015:

*----------------------------------------------------------------------*

*Weighted tree-based transducers for natural language generation in the 
context of a dialogue system*

*----------------------------------------------------------------------*

See: 
http://www.xrce.xerox.com/About-XRCE/Internships/Weighted-tree-based-transducers-for-natural-language-generation-in-the-context-of-a-dialogue-system

Contact: Marc Dymetman marc.dymetman@xrce.xerox.com 

*Duration*: 4 to 5 months

*Start Date*: As soon as possible after September 2015

Description:

In the context of a human-machine dialogue system being developed at
XRCE, the internship will have aim of exploring the applicability of
weighted/probabilistic finite-state tree transducers (and related
formalisms such as tree-to-string transducers) to the problem of
generating textual utterances from semantic representations produced by
a DM (dialogue manager).

The advantages of such transducers are that they support operations such
as composition and intersection (in particular with language models),
and are well-suited for reversible processing (parsing as the reverse of
generation).

The internship will build on work done at XRCE with string-based
transducers, which it will attempt to adapt and extend towards
tree-based machines, either based on external toolkits (such as Tiburon
[May and Knight 2006]) or on specially developed software.

The ideal candidate should be a Computer Science student at the Master
or (preferably) PhD level, with some experience of weighted tree-based
transducers (or at least string-based transducers), as well as of
associated software tools. Strong programming skills are a requirement
(Python, C++, Java...). Conference publication of the work will be
strongly encouraged.

Please note that applicants must be registered students at a university
or other academic institution and that this establishment will need to
sign an 'Internship Convention' with Xerox before the student is
accepted.

If you would like to submit your application, please send it to
marc.dymetman@xrce.xerox.com <mailto:marc.dymetman@xrce.xerox.com> or to
xrce-candidates@xrce.xerox.com <mailto:xrce-candidates@xrce.xerox.com>.
Please mention ""*Tree based transducers*"" in your subject line."
"283","2015-08-19","EC's Joint Research Center","Ispra (Italie)","EUROPEAN COMMISSION JOINT RESEARCH CENTRE

Resources Recruitment and Training

2015-IPR-G-000-5633

Position for: Trainee

Terminology discovery in Disaster Risk Management for the UNISDR
(Terminologist)

Short description of activity:

The European Commission's Joint Research Centre (JRC) in Ispra,
Italy, is looking for a trainee to work on a terminology project
supporting a world-wide team of specialists lead by the United
Nations Office for Disaster Risk Reduction (UNISDR). At the
recent UN world conference in Sendai, Japan, 187 UN member
states adopted a new 15-year framework for Disaster Risk
Reduction (DRR) with seven targets and four priorities of action.
The terms used in this framework must be defined clearly and
unequivocally in order to achieve world-wide collaboration
between scientists, policy makers, the private sector and
practitioners in countries having a rather different DRR culture,
different administrative procedures and speaking different
languages. The overall objective of this terminology project is
thus to review and update the existing defining UNISDR
vocabulary available at
http://www.unisdr.org/we/inform/publications/7817.

During the last year, the JRC has gathered and analysed DRR-
related text collections, definitions and term usage statistics,
allowing DRR specialists to understand how the terms are used in
real life in order to make informed decisions on how the terms
should be defined and how they should be distinguished from
other, similar terms. The JRC did this by analysing the gathered
data using Language Technology tools and methods used in
Computational Linguistics and Statistics. Results have been
presented in text form, tables, using graphs and further methods
for visualisation.

The successful trainee is expected to:
- continue and refine this work for English language;
- to possibly expand it to Spanish and French language;
- to use off-the-shelf software to automatically extract
terms from the document collection and to manually
curate the results;
- to produce various types of statistics on the usage of
terms in different sub-corpora;
- to prepare data and results for the DRR subject domain
specialists;
- to prepare the meetings of expert teams;
- to take minutes during the meetings;
- to act upon the requests by the specialists of the expert
teams and;
- to summarise the discussions and the work carried out.

Qualifications:

The candidate should have a degree (or an almost completed
degree) somehow related to disaster risk management,
terminology, computational linguistics or computer science; (b)
good knowledge of written and spoken English (B2 level); (c)
good communication skills, ability to work independently and as
part of a team: and (d) good knowledge of Information
Technology-related tools and formats such as internet search
engines, XML, word processing and spread sheets.
Further advantageous skills are (e) knowledge of other European
languages, especially Spanish and French; (f) experience with
terminology and the preparation of definitions; and (g)
knowledge of the field of DRR, Disaster Risk Management or
similar areas and (h) some programming skills to process and
handle large corpora, convert data formats, etc.

In your application, please state your interests and please
provide clear information on your skill set, by elaborating on the
above-mentioned list of requirements and by listing your level of
languages and your computer / programming skills.


The Joint Research Centre (JRC; http://ec.europa.eu/dgs/jrc/) is the
scientific-technical arm of the European Commission. The approximately
2200 JRC employees working in Ispra are from all EU countries and
there are also some non-EU visitors. The working environment is
multilingual, multi-cultural and multi-disciplinary. The JRC's Europe
Media Monitor (EMM) team carries out research and development in the
field of highly multilingual text mining (Language Technology;
Computational Linguistics) for the purposes of media monitoring.  EMM
gathers an average of over 200,000 online news articles per day in
over 70 languages and analyses them to help its large international
user community understand and use this enormous amount of media
information. EMM is publicly accessible via
http://emm.newsbrief.eu/overview.html.  See also
https://ec.europa.eu/jrc/en/research-topic/internet-surveillance-
systems and https://ec.europa.eu/jrc/en/language-technologies.  For
general eligibility requirements, please read the rules governing the
traineeship scheme of the JRC:
https://ec.europa.eu/jrc/en/working-with-us/jobs/temporary-positions/jrc-trainees 


duration 5 months 
Preferred starting date  As soon as possible 


Application:
http://recruitment.jrc.ec.europa.eu/"
"284","2015-09-16","Ecoles des Mines d'Ales","Nîmes","Proposition de sujet de stage dans l'équipe KID du laboratoire LGI2P à
Nîmes de l'Ecole des Mines d'Ales

EXTRACTION DE COMMUNAUTÉS RECOUVRANTES PAR COMPLÉMENTARITÉ ET ÉQUILIBRE
DE NASH DANS LES RÉSEAUX SOCIAUX

Encadrants : Michel Plantié

Laboratoire et équipe : LGI2P de l'EMA, équipe KID (Knowledge and Image
for Decision making)

Lieu : Nîmes, site EERIE, parc Georges Besse, 30000 Nîmes

Sujet

Les réseaux sociaux occupent une part de plus en plus importante dans
l'échange de données sur le web. La recommandation de produits et de
services, les modèles utilisateurs enrichis par des données sociales
peuvent revêtir une grande importance.

La recherche de communautés dans les graphes est un problème ancien, et
la grande majorité des techniques utilisées cherchent à optimiser les
temps de calcul de ces communautés et le meilleur arrangement possible
de ces communautés selon des critères de cohésion ou de modularité,
etc.[1][2][3][4]

La signification et la stabilité de ces communautés ainsi constituées
n'est que peu abordée dans les travaux actuels. Les auteurs appliquent
un algorithme unique d'optimisation et observent ensuite les
performances.

Le recouvrement revêtant des fondements sémantiques importants sont peu
étudiés. Plusieurs auteurs dont Roth [5] en construisant des communautés
épistémiques ont abordé le sujet. De même la stabilité et la répartition
équitable et équilibrée des personnes dans les communautés sont peu
étudiés. Nos travaux récents montrent la possibilité d'obtenir un
équilibre de Nash dans les constructions des communautés [6].

La complémentarité est une problématique intéressante pour montrer la
couverture sémantique de communautés.

Nous nous intéressons à ce champ de recherche qui pose de nombreuses
questions théoriques et pratiques.

Le sujet proposé a les objectifs suivants :

- Après un état de l'art, étudier et compléter les définitions de la
  complémentarité adaptée à la détection de communautés dans des grands
  volumes de données de graphes provenant des réseaux sociaux

- Etudier la stabilité et la complémentarité de communautés extraites à
  partir de données sociales

- rechercher les optimums de stabilité et d'équilibre tout en tenant
  compte de leur sémantique.

- Approfondir les travaux de recherche de complémentarité de communautés
  recouvrantes.

[1] Papadopoulos, Y. Kompatsiaris, A. Vakali, and P. Spyridonos,
""Community detection in Social Media,"" Data Mining and Knowledge
Discovery, no. June, pp. 1-40, 2011.

[2] M. F. Porter, ""An algorithm for suffix stripping,"" Program, pp. pp
130-137, 1980.

[3] B. Yang, D. Liu, J. Liu, and B. Furht, Discovering communities from
Social Networks: Methodologies and Applications. Boston, MA: Springer
US, 2010, pp. 331-346.

[4] S. Fortunato, ""Community detection in graphs,"" Physics Reports,
vol. 486, no. 3-5, p. 103, Jun. 2009.

[5] C. Roth and P. Bourgine, ""Epistemic Communities: Description and
Hierarchic Categorization,"" Mathematical Population Studies: An
International Journal of Mathematical Demography, vol. 12, no. 2, pp.
107-130, 2005.

[6] Michel Crampes and Michel Plantié, ""A Unified Community Detection,
Visualization and Analysis method. Advanced Complex Systems, World
Scientific Publishing, Imperial College Press, 2013.

[7] Michel Crampes and Michel Plantié, Organisation de communautés et
Equilibre de Nash, IC - 25èmes Journées francophones d'Ingénierie des
Connaissances, France (2014)

=====================================================
Dr. Michel Plantié - +33 466387035
Enseignant-Chercheur Laboratoire LGI2P

Ecole des Mines d'Ales, Institut Mines-Télécom
Parc scientifique Georges Besse, 30035 Nîmes Cedex 1
www.socialnetworks.wp.mines-telecom.fr
====================================================="
"285","2015-09-23","Syllabs","Paris","---------------------------
Offre de stage TAL : Analyse de tonalité
---------------------------

Syllabs est spécialisée en analyse sémantique et en création automatique
de textes. Nos technologies sont le fruit d'années de développement et
maîtrisent toutes les étapes du processus d'analyse de données
textuelles du Web : identification des pages pertinentes, extraction et
catégorisation des informations clés.
Le stage s'inscrit dans le cadre d'un projet de recherche portant sur
tourisme. L'objectif de ce projet est de produire un tableau de bord
permettant aux professionnels du tourisme de s'informer sur l'état du
tourisme sur leur territoire.
L'objet principal de ce stage sera de construire des modules
d'extraction d'information à l'aide d'un langage développé en
interne. Ces modules seront destinés à l'analyse de tonalité d'objets
touristiques (monuments, musées) à partir d'avis d'internautes.

---------------
Description du poste
---------------
Les tâches principales concernent:
- Étude de corpus
- Définition des caractéristiques des objets touristiques
- Extraction d'information (tonalité)
- Scripts de manipulation des données

---------------
Profil souhaité
---------------
- Expérience en extraction d'information
- Connaissances en morphosyntaxe et syntaxe
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail
  d'équipe
- Bon niveau en python serait un plus

-----------------
Diplôme et expérience
-----------------
- Formation en cours : Linguistique Informatique ou similaire

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage extraction tourisme»
Lieu : Syllabs, 26 rue Notre Dame de Nazareth, 75003 Paris (métro
République)
Contrat : stage à temps partiel. Début : courant octobre"
"286","2015-10-05","DGLFLF","Paris","La Délégation générale à la langue française et aux langues de France
(ministère de la Culture et de la Communication) propose un stage d'une
durée de deux à trois mois entre octobre et décembre 2015, au sein de la
mission des langues et du numérique.

Le stagiaire participera à la rédaction, relecture et mise en page de
plusieurs publications de la mission portant notamment sur les langues
régionales et les technologies du langage, et sur la saisie du français
sur les claviers. Il participera à l'animation d'un réseau d'experts sur
ces sujets et recueillera des contributions externes pour ces projets.
Il contribuera à l'organisation d'un colloque sur la thématique du
traitement automatisé des langues régionales de France en 2016.

Ses autres missions consisteront, en lien avec le chef de la mission, à 
animer les pôles ""technologies de la langue"" et ""diversité linguistique"" 
au sein de la mission des langues et du numérique, à suivre les projets 
réalisés en partenariat ou avec le soutien de la délégation dans ce 
domaine et à produire de l'information à ce sujet sur notre site internet.

Profil recherché

- Étudiant en Master 2 en linguistique, politiques linguistiques, TAL ou
  traduction
- Des compétences rédactionnelles de bon niveau sont requises ainsi que
  des aptitudes à travailler en équipe.
- Une première expérience professionnelle dans le domaine est un plus
- Un intérêt pour les langues en général, la langue française et les
  langues régionale en particulier est vivement conseillé.

Poste à pourvoir immédiatement
Lieu de travail : Paris Palais Royal (1er arrdt.)
Stage conventionné à temps plein
Indemnité de stage de 554,40 euros par mois
Candidatures / informations : thibault.grouas@culture.gouv.fr

à propos de la DGLFLF

La délégation générale à la langue française et aux langues de France
(DGLFLF) est chargée d'animer et de coordonner la politique linguistique
du Gouvernement et d'orienter son évolution dans un sens favorable au
maintien de la cohésion sociale et à la prise en compte de la diversité
de notre société.

Service à vocation interministérielle directement rattaché au ministre
chargé de la culture, la DGLFLF est constituée d'une trentaine d'agents
et mobilise pour son action un ensemble de partenaires, publics ou
privés, impliqués dans la promotion du français et de la diversité
linguistique.

à propos de la mission des langues et du numérique de la délégation

http://www.culturecommunication.gouv.fr/Politiques-ministerielles/Langue-francaise-et-langues-de-France/Politiques-de-la-langue/Langues-et-numerique 

*Thibault GROUAS*
Chef de la mission des langues et du numérique
Délégation générale à la langue française et aux langues de France
6, rue des Pyramides
75001 PARIS
tél : 01 40 15 35 90
tlc : 01 40 15 36 76
www.dglf.culture.gouv.fr"
"287","2015-10-05","Syllabs","Paris","---------------------------
Offre de stage TAL : Génération automatique de textes
---------------------------

Syllabs est spécialisée en analyse sémantique et en génération
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse de
données textuelles du Web : identification des pages pertinentes,
extraction et catégorisation des informations clés. La génération est
proposée au travers de sa solution Data2Content (data2content.fr) qui
permet, à partir d'une base de données structurées, de générer
automatiquement des textes de qualité humaine.

C'est dans le cadre de Data2Content que nous recherchons des ingénieurs
linguistes pour un stage dans le domaine de la création automatique de
textes en anglais, français, espagnol, néerlandais, portugais, italien
et allemand.
L'objet principal du stage est de travailler sur le paramétrage de notre
outil de génération (écriture de règles) dans votre langue
maternelle. Les domaines d'application peuvent par exemple être le
e-commerce (descriptifs de produits), le tourisme (par exemple,
descriptif d'un hôtel) ou les médias (brève sur les résultats des
élections, etc.).

---------------
Description du poste
---------------
Les tâches principales concernent:

- Génération automatique de textes : paramétrage de l'outil de
  génération en fonction du projet, participation aux tests et à
  l'amélioration de l'outil.
- Ecriture de scripts pour la manipulation des bases de données en
  entrée du moteur de génération.


---------------
Profil souhaité
---------------
- Formation en cours : Master 2 ou Master 1 en Linguistique Informatique
  ou similaire
- Excellentes qualités rédactionnelles, goût pour l'écriture
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail en
  équipe
- Programmation en Python
- Compétences en rédaction web seraient un plus

-----------------
Conditions
-----------------
Stage conventionné 6 mois rémunéré en fonction du niveau d'étude +
tickets resto + remboursement à moitié du pass Navigo (transport)

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage génération + (langue) » (Ex: stage
génération anglais)

Lieu : Syllabs, 82 rue du Faubourg Saint-Martin, 75010 Paris (M°
Strasbourg-Saint-Denis ou Gare de l'Est)
Contrat : stage. Début : janvier-mars 2016."
"288","2015-10-15","CEA","Saclay","Voici trois sujets de stage de M2 rÃ©munÃ©rÃ©s proposÃ©s par le Laboratoire
Vision et IngÃ©nierie des Contenus (CEA Tech, UniversitÃ© Paris Saclay) et
portant sur:

1. Ã‰valuation et amÃ©lioration d'un moteur de recherche sÃ©mantique ;
2. Ajout du support de nouvelles langues Ã  l'analyseur linguistique LIMA ;
3. Ã‰valuation d'analyseurs linguistiques du Chinois.

Merci de me contacter pour plus d'informations.

Cordialement,

GaÃ«l de Chalendar
01.69.08.01.50
gael.de-Chalendar@cea.fr


=============================================
1. Ã‰valuation et amÃ©lioration d'un moteur de recherche sÃ©mantique

Dans le cadre du projet ANR Asfalda, le laboratoire LVIC du CEA LIST a
Ã©tendu son moteur de recherche crosslingue AMOSE pour lui donner des
capacitÃ©s d'indexation et de recherche exploitant des informations
sÃ©mantiques issues d'outils de Semantic Role Labeling.

L'objectif premier du stage sera d'Ã©valuer l'impact de l'intÃ©gration de
la sÃ©mantique sur les rÃ©sultats de recherche. Le second objectif sera
d'amÃ©liorer le moteur de recherche au vu des rÃ©sultats d'Ã©valuation.

AMOSE est un moteur de recherche crosslingue. Il repose sur l'analyseur
linguistique libre Lima [1] qui reconnaÃ®t les termes nominaux complexes
(Multi Word Expressions ou MWE en anglais). Ces termes complexes repÃ©rÃ©s
dans les documents et les requÃªtes sont utilisÃ©s pour grouper les
documents rÃ©sultats en classes d'Ã©quivalence en fonction des termes de
la requÃªte qu'ils contiennent.

LIMA a rÃ©cemment Ã©tÃ© enrichi d'un module effectuant de l'annotation en
rÃ´les sÃ©mantiques (Semantic Role Labeling) et AMOSE a Ã©tÃ© modifiÃ© pour
indexer et utiliser dans la recherche les classes repÃ©rÃ©es et leurs
rÃ´les.

Le travail du stagiaire consistera Ã  Ã©valuer la nouvelle version d'AMOSE
sur les campagnes d'Ã©valuation classiques (CLEF, TREC) dont le
laboratoire possÃ¨de les donnÃ©es et Ã  rechercher quelles campagnes plus
ciblÃ©es sur la recherche sÃ©mantique pourraient exister et mettre en
oeuvre AMOSE sur leurs donnÃ©es. Si une telle campagne a lieu durant le
stage, le laboratoire y participera.

Ces Ã©valuations fourniront des informations permettant de mettre Ã  jour
des pistes d'amÃ©lioration. Le stagiaire les documentera et en mettra
certaines en oeuvre.

=============================================
2. Ajout du support de nouvelles langues Ã  l'analyseur linguistique LIMA

Le laboratoire LVIC a dÃ©veloppÃ© un analyseur linguistique multilingue
nommÃ© LIMA (LIST Multilingual Analyzer) [2]. LIMA a Ã©tÃ© placÃ© sous
licence libre (AGPL) dÃ©but 2014 [1]. Ã€ cette occasion, des ressources
linguistiques libres ont Ã©tÃ© collectÃ©es et adaptÃ©es pour le franÃ§ais et
l'anglais [3]. Mais LIMA supporte bien d'autres langues. Le laboratoire
dispose par exemple de ressources propriÃ©taires qu'il n'a pas le droit
de redistribuer sous licence libre pour des langues telles que chinois,
arabe, allemand, espagnol, italien, etc. L'objectif de ce stage est de
collecter et adapter Ã  LIMA des ressources libres pour de nouvelles
langues. On commencera par des langues latines, en particulier le
portugais (dans ses variantes portugaise et brÃ©silienne), l'espagnol et
l'italien.

Le travail du stagiaire consistera Ã  :
- se familiariser avec LIMA, son fonctionnement, ses ressources
  linguistiques et leur production ;
- rechercher et sÃ©lectionner les ressources libres nÃ©cessaires pour les
  langues sÃ©lectionnÃ©es ;
- adapter les ressources choisies et les intÃ©grer au processus de
  gÃ©nÃ©ration de LIMA.

Les ressources concernÃ©es sont:
- automate de tokenisation ;
- jeu d'Ã©tiquettes grammaticales ;
- dictionnaire de lemmes ou full-form ;
- dictionnaire 
- corpus annotÃ© pour l'apprentissage de modÃ¨les de dÃ©sambiguÃ¯sation
  morphosyntaxique ;
- rÃ¨gles (grammaire) pour l'analyse syntaxique ;
- rÃ¨gles de reconnaissance d'entitÃ©s nommÃ©es.

Bien entendu, il ne sera pas possible d'obtenir Ã  l'issue d'un tel stage
un ensemble complet de toutes les ressources pour toutes les langues
envisagÃ©es.  L'objectif sera de fournir une base utilisable pouvant Ãªtre
Ã©tendue par la suite.


=============================================
3. Ã‰valuation d'analyseur linguistiques du Chinois

Le laboratoire LVIC a dÃ©veloppÃ© un analyseur linguistique multilingue
nommÃ© LIMA (LIST Multilingual Analyzer) [1,2,3]. Son support de la
langue chinoise n'a pas Ã©tÃ© mis Ã  jour depuis de longues annÃ©es. Depuis,
de nouveaux analyseurs ont Ã©tÃ© dÃ©veloppÃ©s et ont atteint des niveaux de
performance bien plus Ã©levÃ©s. Nous dÃ©sirons Ã©valuer un certains nombre
de ces outils, aussi bien du point de vue de leur qualitÃ©s intrinsÃ¨ques
que de leurs possibilitÃ©s d'intÃ©gration avec LIMA. Le travail du
stagiaire consistera Ã  mettre en oeuvre ces outils, les Ã©valuer Ã 
diffÃ©rents niveaux (vitesse, qualitÃ© de segmentation, dÃ©sambiguÃ¯sation
morphosyntaxique, analyse syntaxique, entitÃ©s nommÃ©es, etc.) Ã  l'aide de
corpus de rÃ©fÃ©rence et enfin Ã  expÃ©rimenter leur intÃ©gration.

LIMA est dÃ©veloppÃ© en C++. Certains outils le sont aussi et
l'intÃ©gration peut alors se faire en adaptant les APIs. D'autres sont en
Java ou en Python. Il faudra alors choisir entre une intÃ©gration de bas
niveau (JNI...) ou en tant que module externe. Les critÃ¨res de choix sont
lÃ  la complexitÃ© de la mise en oeuvre vs. les performances.


=============================================
RÃ©fÃ©rences

[1] https://github.com/aymara/lima/wiki
[2] R. Besanc Ì§on, G. de Chalendar, O. Ferret, F. Gara, M. Laib,
O. Mesnard, and N. Semmar. 2010. Lima: A multilingual framework for
linguistic analysis and linguistic resources development and
evaluation. In Proceedings of LREC, Malta.
[3] G. de Chalendar. 2014. The LIMA Multilingual Analyzer Made Free :
FLOSS Resources Adaptation and Correction. In Proceedings of the Ninth
International Conference on Language Resources and Evaluation
(LREC-2014), Reykjavik, Iceland, May 26-31, 2014., pages 2932-2937."
"289","2015-11-09","INALCO","Paris","Appel à candidature : stage TAL langues peu dotées, 4 à 6 mois
Objet : recherche, inventaire et analyse d'outils de TAL langues peu
dotées
Employeur : Institut National des Langues et Civilisations Orientales
(INALCO)
Contrat : Stage M1 ou M2 de 4 à 6 mois
Lieu de Travail : Paris 7e 
Rémunération : Rémunération 554 euros + 35 de prise en charge partiel des
transport IdF
Date de début : janvier ou avril suivant les échéances universitaires

DESCRIPTION DU POSTE

Dans le cadre du projet MultiTAL (Plateforme de documentation et
d'expertise des outils et ressources pour le traitement automatique des
langues orientales et des langues peu dotées), l'ERTIM (INALCO) recrute
cinq stagiaires en TAL langues peu dotées.

Contexte : Il existe un nombre significatif d'outils de traitement
automatique des langues peu dotées qui demeurent mal connus, mal
référencés, et dont la documentation est parfois lacunaire voire
inexistante. Déjà difficiles d'accès pour les TAListes avertis, ils sont
pratiquement inaccessibles à d'autres utilisateurs pour lesquels ils
constitueraient des instruments utiles. L'objectif du projet est de
mettre à la disposition d'une communauté de non-spécialistes des
documentations actualisées et une expertise technique indépendantes
relatives aux ressources linguistiques et aux outils de fouille de
textes. A terme, la plateforme permettra de constituer une base de
connaissances structurée, évolutive et accessible en ligne qui
s'adressera non pas aux seuls linguistes, mais aux chercheurs,
universitaires non spécialistes (sciences sociales, sciences politiques)
ou industriels (veilleurs, etc.) amenés à manipuler des données
textuelles massives ou complexes à des fins de fouille de textes.

Les stagiaires recrutés auront pour mission d'identifier, de tester, de
décrire et de documenter des outils pour le traitement automatique des
langues qu'ils maîtrisent.

PROFIL ATTENDU

- M1 ou M2 en traitement automatique des langues

COMPÉTENCES REQUISES 

- compétence linguistique en une ou plusieurs langues du domaine INALCO
  (par exemple : arabe(s), chinois, coréen, japonais, persan, thaï,
  turque, etc.)
- expériences des outils de TAL,
- maîtrise des environnements : Linux et Windows
- bonnes connaissances des mécanismes d'installation, compilation,
  gestionnaires de paquets,
- familiarité avec des langages de programmation : Perl / Python, Java,
  C++, etc.

MODALITÉS DU PROJET

Les stages peuvent commencer entre janvier et avril.

Les travaux se dérouleront à la maison de la recherche de l'INALCO : 2
rue de Lille 75007 Paris.
Le traitement comprend l'indemnité de stage (554 ¤) et la prise en
charge partielle des frais de transport Ile-de-France (35 ¤).

Les candidats sont invités à prendre contact à l'adresse
mvalette@inalco.fr ou à envoyer directement une lettre de motivation et
un CV détaillé par mail.

-------------------------------------------------------------------------"
"290","2015-11-12","LIRMM","Montpellier","Titre : Déploiement d'une plate-forme web d'analyse de documents pour
identifier les caractéristiques des réseaux d'assainissement

Mots-clés : traitement automatique de la langue, fouille de données

Contexte : Le stage se déroulera dans le cadre du projet Cart'eaux porté
par le laboratoire HydroSciences Montpellier. Ce projet vise la fusion
de données pour la cartographie de réseaux enterrés, notamment les
réseaux d'assainissement. Il s'agit d'une problématique importante à la
fois dans de les pays développés et ceux en voie de développement car
souvent les réseaux sont mal identifiés.

Objectifs : Internet recèle de nombreux documents, rapports publics et
web services susceptibles de contenir une description des interventions
sur les réseaux d'assainissement (e.g. travaux, entretien,
réparation). L'objectif de ce stage est de mettre en oeuvre des
techniques de fouille de données et recherche d'information sur Internet
pour tout d'abord découvrir des documents dans différents formats
(textes html, pdf, images, plans numérisés) et successivement identifier
et extraire un maximum d'informations expertes sous la forme d'attributs
liées aux objets du réseau d'assainissement (e.g. retrouver dans un
rapport d'intervention, le diamètre d'une bouche d'égout, ou encore
retrouver la position géographique d'une intervention). Il sera
important d'associer à chaque information extraite des textes un indice
de confiance qui aidera l'expert à décider s'il conserve ou non
l'information. Le lien ci-dessous illustre un exemple de rapport
contenant des attributs intéressants dans le cadre de nos travaux :
http://www.a3w.fr/Donnees/Structures/81497/Upload/247221.pdf

Actions à mener : Dans le cadre de ce stage, l'étudiant devra concevoir
une plateforme permettant aux experts de récolter et d'analyser des
documents pour compléter leurs connaissances sur les réseaux
d'assainissement. Plusieurs aspects sont à considérer :

1/ Récolter sur le Web différents types de documents de manière
   automatique, qui parlent des bouches d'égouts et des réseaux
   d'assainissement.
2/ Catégoriser ces documents par type (e.g. rapport d'interventions,
   article de presse, appel d'offre, forum techniques ou réactions à des
   évènements).
3/ Détecter dans les textes des informations géographiques (e.g. au nord
   de la route R12 allant de Montpellier à Lunel), des dates
   (e.g. l'appel d'offre signé du 12 mai), des caractéristiques sur les
   bouches d'égouts et sur les réseaux d'assainissement (e.g. le
   diamètre des plaques, la profondeur...). Il sera nécessaire
   d'associer les informations détectées avec un niveau de confiance.
4/ Proposer une visualisation pour mettre en évidence ces informations
   dans les textes.
5/ Structurer de façon automatique, lorsque la confiance est forte, ces
   informations dans un format utilisable (e.g. table attributaire) par
   les experts.

Déroulement du stage : Le stage d'une durée de 4 à 6 mois se déroulera
dans les locaux du LIRMM à Montpellier et sera amené à se déplacer dans
le laboratoire HydroSciences de Montpellier pour discuter avec les
experts.

Compétences requises : 
- Développement web (HTML, Javascript, webGL, java)
- Notions de fouille de données
- Outils de traitements automatiques de la langue
- Développement d'interfaces
- Une bonne connaissance des API Google ou Yahoo est un plus

Encadrement
- Informatique
  *Sandra Bringay - MCF Université de Montpellier 3 - sandra.bringay@lirmm.fr
  *Maguelonne Teisseire, DR TETIS - maguelonne.teisseire@teledetection.fr
- Hydrologie
  *Nanée Chahinian - CR IRD - chahinian@msem.univ-montp2.fr
  *Carole Delenne - MCF Université de Montpellier - carole.delenne@umontpellier.fr

Contacts
* Sandra Bringay - MCF Université de Montpellier 3 - sandra.bringay@lirmm.fr
* Maguelonne Teisseire, DR TETIS - maguelonne.teisseire@teledetection.fr"
"291","2015-11-12","LATTICE","Paris","Voici trois sujets de stage de M2 en TAL proposés par le laboratoire
Lattice (Langues, Textes, Traitements Informatiques, Cognition,
http://www.lattice.cnrs.fr, Montrouge, tout près de Paris) dans le cadre
du projet ANR DEMOCRAT (description et modélisation des chaînes de
référence : outils pour l'annotation de corpus et le traitement
automatique) en collaboration avec les laboratoires LILPA (Strasbourg)
et ICAR (Lyon) :

1. Identification automatique de mentions référentielles
2. Analyse en corpus de chaînes de référence
3. Continuité référentielle et saillance : étude et modélisation

La durée est de 4 à 6 mois, à partir de février ou mars 2016, et la
rémunération au tarif stage de 554 euros mensuels.  Merci deme contacter
pour plus d'informations et pour candidater (CV + lettre de motivation) :
mailto:frederic.landragin@ens.fr

Cordialement,
Frédéric Landragin.
http://www.lattice.cnrs.fr/Frederic-Landragin/

________________________________________________________________________


1. Identification automatique de mentions référentielles

La reconnaissance des chaînes de coréférences dans les textes,
c'est-à-dire des portions de textes qui réfèrent à une même entité, est
une tâche importante du TAL. Elle a des incidences sur de nombreuses
autres tâches, comme la recherche et l'extraction d'information, le
résumé automatique, etc. Cette tâche a fait l'objet de nombreux
challenges mais, faute de données de référence en français, ils
portaient jusqu'à présent principalement sur des textes en anglais. L'an
dernier, la diffusion du corpus ANCOR (ANaphore et Coréférence dans les
Corpus ORaux), constituéd'un ensemble de transcriptions du français
parlé annotées en coréférences, a permis de lancer des premières
expériences sur le français. Elles ont donné lieu à un premier système,
CROC (Coreference Resolution for Oral Corpus), entraîné par
apprentissage automatique sur ANCOR (Désoyer at al. 2015). Mais ce
système est encore rudimentaire : il fait l'hypothèse que les mentions
d'entités ont été préalablement reconnues dans les textes et se contente
donc de prédire leur regroupement en entités coréférentes. Pour enrichir
et améliorer ce système, plusieurs travaux sont envisagés :

- reconnaître automatiquement les mentions référentielles, qui
  coïncident plus ou moins avec les groupes nominaux,
- identifier automatiquement les données nécessaires en entrée de CROC,
- reprendre les expériences qui ont donné lieu à CROC pour essayer
   d'améliorer ses performances.

La méthodologie employée fera dans tous les cas appel à de
l'apprentissage automatique supervisé (méthodes de classification ou
d'annotation). Le stage sera co-encadré par Frédéric Landragin, Isabelle
Tellier (isabelle.tellier@univ-paris3.fr) et Marco Dinarelli
(marco.dinarelli@ens.fr).

Compétences requises :
- stage de niveau M2 en informatique ou en ingénierie linguistique ou
  école d'ingénieur,
- compétences en informatique : programmation, langage de script,
  manipulation de corpus,
- intérêt pour le traitement automatique des langues,
- des compétences en apprentissage automatique seraient un plus.

Références :
Désoyer A, Landragin F, Tellier I, Lefeuvre A, Antoine J-Y, ""Les
   coréférences à l'oral : une expérience d'apprentissage automatique
   sur le corpus ANCOR"", Traitement Automatique des Langues (TAL) 55(2),
   http://www.atala.org/-Volume-55-, 2014.
Landragin F, Schnedecker C (Eds.) ""Les chaînes de référence"", Langages
   195, numéro de septembre 2014.
Lefeuvre A, Antoine J-Y, Schang E, ""Le corpus ANCOR_Centre et son outil
   de requêtage : application à l'étude de l'accord en genre et en
   nombre dans les coréférences et anaphores en français parlé"", Actes
   4éme Congrès Mondial de Linguistique Française (CMLF 2014), 2014.

________________________________________________________________________


2. Analyse en corpus de chaînes de référence

Une fois annotées en corpus, les chaînes de référenceconstituent des
ensembles de mentions - désignant le même objet ou le même personnage
humain - couvrant potentiellement toute la longueur du texte. Elles se
distinguent ainsi d'autres objets linguistiques plus locaux : quand on
tente de caractériser une chaîne de référence, on doit tenir compte non
seulement des types de mentions qu'elle regroupe, mais aussi de sa
tendance à être présente dans tout le texte ou seulement dans quelques
passages. Une analyse rationnelle des chaînes de références implique
donc, en plus des classiques décomptes et calculs de fréquences, des
calculs statistiques plus complexes. Le but de ce stage est de mettre en
place et de tester une méthodologie d'analyse numérique des chaînes de
référence. Plusieurs travaux sont envisagés :

- analyser deux corpus déjà annotés en chaînes de référence,
- écrire des scripts pour calculer à partir des données annotées un
  ensemble d'indicateurs numériques (en partant d'une spécification et
  d'une revue de travaux en statistique textuelle),
- annoter un corpus de test et mettre à l'épreuve la méthodologie
  proposée.

Compétences requises :
- stage de niveau M2 en informatique ou en ingénierie linguistique ou
  école d'ingénieur,
- compétences en informatique : programmation, langage de script,
  manipulation de corpus,
- intérêt pour le traitement automatique des langues,
- des compétences en statistique seraient un plus.

Références :
Landragin F, ""Anaphores et coréférences : analyse assistéepar
   ordinateur"", In: Fossard M, Béguelin M-J, Nouvelles perspectives sur
   l'anaphore. Points de vue linguistique, psycholinguistique et
   acquisitionnel, Peter Lang, Berne, 2014.
Landragin F, Tanguy N. & Charolles M, ""Références aux personnages dans
   L'occupation des sols : apport de la linguistique outillée"", Revue
   Sciences/Lettres 3, http://rsl.revues.org/816, 2015.

________________________________________________________________________


3. Continuité référentielle et saillance : étude et modélisation

Lorsque plusieurs phrases consécutives d'un texte parlent d'un même
référent, par exemple un personnage humain, celui-ci en devient saillant
: il occulte l'attention du lecteur, ce qui a pour conséquence d'en
faire un candidat idéal à l'interprétation de pronoms tels que
""il"". Définie ainsi, la notion de saillance est en lien direct avec la
continuité référentielle, c'est-à-dire la ""domination"" d'une chaîne de
référence sur l'ensemble des chaînes présentes dans le texte (une chaîne
par personnage mentionné). Le but de ce stage est d'explorer ce lien et
de proposer un modèle de la saillance tourné vers les références à des
humains dans des textes narratifs tels que des nouvelles de
Maupassant. Pour ce faire, la méthodologie employée sera celle de la
linguistique de corpus. Plusieurs travaux sont envisagés :

- expérimenter diverses propositions de schémas d'annotation combinant
  saillance et chaînes de référence,
- annoter un corpus regroupant plusieurs nouvelles de taille comparable,
- utiliser des outils d'interrogation de corpus et écrire des scripts
  pour extraire des annotations réalisées des observations qualitatives
  et quantitatives.

Compétences requises :
- stage de niveau M2 en linguistique ou ingénierie linguistique,
- compétences en linguistique : (co)référence, linguistique du discours,
- des compétences en informatique (manipulation de corpus, langage de
  script) seraient un plus.

Références :
Landragin F, Schnedecker C (Eds.) ""Les chaînes de référence"", Langages
   195, numéro de septembre 2014.
Boisseau M., Hamm A. (Eds.) ""Saillance. La saillance en langue et en
   discours, Volume 2"", Annales Littéraires de l'Université de
   Franche-Comté n° 940, 2015."
"292","2015-11-18","LIA","Avignon","========================================================================
Modèles connexionnistes pour la génération automatique de texte dans le
cadre de l'interaction vocale

Encadrants : Dr Stéphane Huet, Dr Bassam Jabaian, Prof. Fabrice Lefèvre

Descriptif du stage :
Les systèmes d'interaction vocales utilisés dans des applications comme
la réservation de billets d'avion ou d'hôtels, ou bien encore pour le
dialogue avec un robot, font intervenir différents composants. Parmi
ceux-ci figure le module de génération de texte qui produit la réponse
du système en langage naturelle à partir d'une représentation sémantique
interne créée par le gestionnaire de dialogue.

Les systèmes de dialogue actuels intègrent des modules de génération
basés sur des règles ou patrons lexicaux définis manuellement, par ex :

confirm(type=$U, food=$W,drinks=dontcare)
-> Let me confirm, you are looking for a $U serving $W food and any kind
of drinks right ?

Ces modules gagneraient à se baser sur des méthodes d'apprentissage
automatique afin de faciliter la portabilité des systèmes de dialogue
vers de nouvelles tâches et améliorer la diversité des réponses
générées. Parmi ces méthodes figurent les réseaux de neurones qui ont vu
un regain d'intérêt depuis l'introduction de la notion de « deep
learning ». De tels réseaux de neurones ont déjà été employés par le
laboratoire de recherche de Google pour une tâche de génération de
description d'images
(http://googleresearch.blogspot.fr/2014/11/a-picture-is-worth-thousand-coherent.html)
proche de celle qui nous intéresse ici. Ainsi l'objectif de ce stage est
d'étudier l'utilisation de ces modèles précisément dans le cadre de
l'interaction vocale.

Si un intérêt pour l'apprentissage automatique et le traitement de la
langue naturelle est souhaitable, il est attendu surtout du stagiaire de
bonnes capacités en développement logiciel. Le stagiaire travaillera
dans le contexte d'une plateforme d'interaction vocale complète et
pourra élargir son champ d'investigation aux autres composants.
Plusieurs pistes pour une prolongation en thèse sont ouvertes.


Durée du stage : 6 mois
Rémunération : Environ 529¤ / mois
Thématique associée au stage : Systèmes de dialogue homme-machine, 
génération du langage naturelle, apprentissage automatique...

========================================================================
Humour et systèmes d'interaction vocale

Encadrants : Dr Bassam Jabaian, Dr Stéphane Huet, Prof. Fabrice Lefèvre

Descriptif du stage : Automatisation de productions humoristiques.

Des travaux précédents en linguistique ont permis d'établir les bases
d'une taxonomie des mécanismes d'humour interactionnels. En partant de
cette base la question que nous souhaitons aborder dans ce travail est :
peut-on automatiser la production de traits humoristiques dans un
dialogue homme-machine finalisé et si oui quel est l'impact sur les
performances du dialogue ?

Bien sur il ne peut s'agir de reproduire exactement les capacités
générales d'un humain, qui sont très complexes à décrire et certainement
impossible à automatiser, mais plutôt d'extraire certains mécanismes
suffisamment réguliers pour les formaliser et les faire exécuter en
situation de dialogue. Cela devrait permettre de produire un effet
décalé, donnant ainsi une dimension de sympathie au système
d'interaction dans la perception de l'utilisateur.

D'un point de vue pragmatique plusieurs types de production (plus ou
moins indépendamment du mécanisme humoristique utilisé) sont déjà
envisagés, réactionnel ou générationnel :

1. Dans le premier cas on détecte une opportunité (présence de
   connecteurs), puis on réagit (génération de disjoncteurs). C'est le
   cas de l'humour basé sur les mots polysémiques, i.e. on repère un mot
   que le système fait semblant de comprendre dans son sens « gênant »
   ou inadapté.

2. Dans le second cas, on propose un trait d'humour ex-nihilo ou après
   détection d'une nécessité de facilitation, par exemple lors de
   l'apparition d'un désalignement (l'évolution normale du dialogue est
   gênée par une ou plusieurs incompréhensions). Il s'agit alors de
   calembours (« puns »), mots d'esprits ou histoires drôles (« jokes
   »). On pourra alors avoir recours à une base prédéfinie de blagues et
   les sélectionner selon le contexte de dialogue (au moyen de technique
   de recherche d'information classique).

L'objectif est de pouvoir implémenter les solutions retenues sur les
robots NAO d'Aldebaran, disponibles au laboratoire, dans le contexte
d'une tâche simple (jeux). Au-delà de l'intérêt pour la thématique de
l'intelligence artificielle sous-jacente au sujet il est principalement
attendu du stagiaire de très bonnes compétences en développement
logiciel. Ce stage ouvre sur plusieurs possibilités de poursuite en
thèse dans le domaine de la communication Homme-Machine pour
l'intelligence artificielle.

Durée du stage : 6 mois
Rémunération : Environ 529¤ / mois
Thématique associée au stage : Systèmes de dialogue homme-machine,
compréhension de la parole, gestion du dialogue, apprentissage
automatique.
========================================================================

Les étudiants intéressés sont invités à envoyer un email à
fabrice.lefevreAtuniv-avignon.fr, bassam.jabaianAtuniv-avignon.fr et
stephane.huetAtuniv-avignon.fr en indiquant le sujet visé (ou les 2) et
en joignant un dossier d'évaluation (avec au moins un CV, un relevé de
notes des 2 dernières années et une lettre de motivation).

Une première sélection aura lieu le 24/11/15."
"293","2015-11-19","LIRMM","Montpellier","Titre : Raisonnement multi-expertise (patient/médecin) pour un tâche de
recherche d'information

Mots-clés : traitement automatique de la langue, fouille de données,
vocabulaire patient/médecin

Durée : 4-6mois
Lieu : LIRMM

Contexte : Le stage se déroulera dans le cadre du projet SFIR porté par
le LIRMM (http://www.lirmm.fr/sifr/). Ce projet s'intéresse aux défis
scientifiques et techniques associés à la construction de services basés
sur des ontologies et des terminologies biomédicales pour l'indexation
et la fouille de données biomédicales françaises.

Objectifs : L'extraction d'informations dans les médias sociaux de santé
(forums, Facebook, Twitter...) est rendue difficile par la spécificité des
textes. Par exemple, l'extrait de message suivant « jen peux + de ce
crabe... je pense a arreter le tamox », on trouve des fautes
d'orthographes « jen », « arreter » des graphies « + » pour « plus » des
mots patients « crabe » pour « cancer », des abréviations « tamox » pour
« tamoxifène ». Dans de précédent travaux [Tapi Nzali 2015], nous avons
exploité l'API Wikipédia pour rapprocher des termes patients de termes
utilisés par les professionnels de santé et répertoriés dans le
thésaurus MeSH.  Dans un premier temps, l'objectif de ce stage est
d'étendre ces travaux en explorant d'autres ressources du Web (Bing,
Yahoo, Google...). Dans un deuxième temps, il s'agira d'exploiter le
vocabulaire produit pour un tâche de recherche d'informations qui
exploitera la structure de la ressource pour raisonner à la fois sur
l'expertise du patient et des professionnels de santé.

Actions à mener : 
1/ Utilisation de différentes ressources Web (Bing, Yahoo, Google...) pour
   rapprocher des termes patients et des termes de professionnels de
   santé 
2/ Comparaison des candidats obtenus grâce à différentes mesures
   sémantiques (Harispe 2014)
3/ Production d'une autre version du vocabulaire formalisée (SKOS,
   Lemon)
4/ Raisonnement multi-expertise (patient/médecin) pour un tâche de
   recherche d'information
4/ Visualisation pour mettre en évidence ces informations dans les
   textes

Déroulement du stage : Le stage d'une durée de 4 à 6 mois se déroulera
dans les locaux du LIRMM à Montpellier.

Compétences requises : 
- Développement web (HTML, Javascript, webGL, java)
- Notions de fouille de données
- Outils de traitements automatiques de la langue
- Développement d'interfaces
- Une bonne connaissance des API Google ou Yahoo est un plus

Encadrement
*Sandra Bringay - MCF Université de Montpellier 3 -
sandra.bringay@lirmm.fr

*Clément Jonquet  - MCF Université de Montpellier - jonquet@lirmm.fr

*Mike Tapi Nzali, Doctorant, Université de Montpellier -
 Mike-Donald.Tapi-Nzali@lirmm.fr

Contacts
* Sandra Bringay - MCF Université de Montpellier 3 -
  sandra.bringay@lirmm.fr

Bibliographie
Mike Donald Tapi Nzali, Sandra Bringay, Christian Lavergne, Thomas
Opitz, Jérôme Azé et Caroline Mollevi. Construction d'un vocabulaire
patient/médecin dédié au cancer du sein à partir des médias
sociaux. Ingénierie des Connaissances - IC. 2015 [Best paper award -
young researcher]

Sébastien Harispe, Sylvie Ranwez, Stefan Janaqi, Jacky Montmain: The
semantic measures library and toolkit: fast computation of semantic
similarity and relatedness using biomedical ontologies. Bioinformatics
30(5): 740-742 (2014)"
"294","2015-11-24","Xerox Research Center Europe","Grenoble","Xerox Research Centre Europe, located in Grenoble, France, is offering the following internship for early 2016:

 

--------------------------------------------------------------------------------------------------------------

Deep Recurrent Neural Networks for Dialogue Prediction and Response Generation

---------------------------------------------------------------------------------------------------------------

 

See: http://www.xrce.xerox.com/About-XRCE/Internships/Deep-Recurrent-Neural-Networks-for-Dialogue-Prediction-and-Response-Generation

 

Contact :  Marc Dymetman   marc.dymetman@xrce.xerox.com  

 

Please mention ""RNNs for Dialogue and NLG"" in your subject line.

 

Duration: around 5 months

Start date: around January/February 2016

The application of Deep Learning techniques to conversational
interactions has recently emerged as an important research topic in
the Machine Learning community, and XRCE has started to be strongly
engaged in this area.

In particular, we are actively working in the domain of task-oriented
dialogues in relation to the customer call-centers Xerox manages, and
have access to significant amounts of interaction data in these
domains.

We are looking for an intern who will help us improve some of our
current Recurrent Neural Network models for dialogue prediction and
generation for these task-oriented conversations.

The ideal candidate is Computer Science student at the Master or
(preferably) PhD level, with a background in Machine Learning
(preferably including Deep Learning techniques) and NLP. Strong
programming skills are a requirement (Python, C++, Java...) and
knowledge of such toolkits as Theano, Torch, TensorFlow would be a
plus.

Conference publication of the work will be strongly encouraged.

See XRCE's page above for more details."
"295","2015-11-30","Soyooz / LIMSI","Paris / Orsay","Recommandation de produits en langue naturelle

Développement d'un modèle de profile utilisateur pour recommandation de
produits en langage naturel

Stage Master 2 de Recherche - Soyooz - LIMSI

L'objectif du stage est de concevoir un module d'extraction de court
extraits de textes issus des réseaux sociaux et du web qui illustre au
mieux un type usage particulier du produit, pour un profile utilisateur
donné.  Ce module servira à alimenter automatiquement une base
d'extraits de textes illustratifs des usages à partir de la description
du produit, de la classe d'usage et du profile utilisateur.

Pour plus de détails voir:

https://perso.limsi.fr/pap/annonce_finale_stage_soyooz_2015_2016.pdf
ou
https://www.limsi.fr/fr/formation/offres-de-stages/details/5/11

Domaine: traitement du langage parlé, écrit et gestuel
Mots clés

  * recherche et extraction d'information
  * constitution de ressources
  * paraphrase et traduction automatique
  * Apprentissage
  * Traitement Automatique du Language Naturel Écrit

Niveau M2
Date de début 2016-01-04 (des aménagements sont possibles)
Durée 5 mois
Rémunération: ~512 euros / mois (indemnités)"
"296","2015-11-30","Xerox Research Center Europe","Grenoble","Personal Language Analytics for Emotion, Sentiment and Personality Modelling
Unit: MLDAT/PARSEM

Proposers : Caroline Brun & Scott Nowson
Duration: 4-6 months
Start Date: March 2016


Description

Personal Language Analytics (PLA) is an approach to text mining
whereby the focus is on the authors of texts rather than the texts
themselves. It is a computational field which combines aspects drawn
from natural language processing, data mining, linguistics, psychology
and sociology.

At XRCE we are interested in understanding how language can be used
across cultures to express mental states, like sentiment, emotion or
mood; to convey a sense of an individual's personality.  This
internship will explore the intersection of these areas as part of a
much larger project on customer modelling and personalisation.

We are particularly interested in the areas of:

- textual expression of emotion in human dialogue; 
- grounding and focus of this emotion;
- the relationship between the degree of emotional expression and
    personality traits of the interlocutors.

Tasks/Responsibilities

- Contribute to design of annotation schemes and corpora annotation
  for complex PLA tasks using dedicated annotation platforms.

- Work with and extend existing linguistic processing and text analytics tools

- Develop prototype text classification models and design experimental
  evaluation program.

Ideal candidates are Masters or PhD students with: a strong background
in natural language processing, experience in linguistics along with
text/data mining and machine learning; preferably an ability to script
(i.e. python); and ideally an interest in human language use.

Application instructions

Informal inquiries are welcome and can be made to
scott.nowson@xrce.xerox.com or caroline.brun@xrce.xerox.com .

To submit an application, please send your CV and cover letter to all
of: xrce-candidates@xrce.xerox.com ; caroline.brun@xrce.xerox.com and;
scott.nowson@xrce.xerox.com ."
"297","2015-12-09","Xerox Research Center Europe","Grenoble","Conversational system on a robotic platform

Unit: XTIN
 
Proposers:
Matthias Galle (Matthias.Galle@xerox.com)
Christophe Legras (Christophe.Legras@xerox.com)

Duration: 4 - 6 months
Start Date: Q1 2016

Description

The Xerox Research Centre Europe (XRCE) has a strong expertise in
Natural Language Processing and Machine Learning. We have been
applying these capabilities in many business applications and lately
have worked on developing conversational software to work in the
customer care domain.

The internship proposal aims at integrating our conversational
software to a third party robotic platform and to experiment on how to
take advantage of the robot movements and postures capacities.

 In this internship, the intern will focus on some of the following
 tasks in collaboration with the other team members:

- Integrate the current version of XRCE conversational software in the
      robotic platform and test its usability
- Tune the software components involved in the conversation (Automatic
      Speech Recognition, Natural Language Understanding, Dialogue
      Manager, Natural Language Generation and Speech Synthesis).

- Use the features offered by the robotic platform to improve the user
      experience

- Publication of findings in the form of papers and/or intellectual
      property is strongly encouraged

 
The intern will be part of a team of developers, researchers and
marketers. XRCE projects are managed with an agile methodology which
allow interns to follow all the steps of software development,
including research, design, implementation, test and integration.

 

Candidates will be:

 - Students in Computer Sciences EngineeringBscMasters
 - Experience of Object Oriented Programming: Python and C++ in
      particular
 - Knowledge in client/server architectures, web-services
 - Basic robotics knowledge
 - Knowledge in Agile methodologies and Test Driven Development is a
      plus

During her/his internship the candidate will acquire a significant
knowledge in natural language processing, machine learning techniques
and challenges linked to robotic platforms while working closely with
researchers and engineers. Her/his work will also be exposed to
feedback and suggestion from customer care experts and clients."
"298","2015-12-09","LIRMM","Montpellier","SUJET 1 - Master 2 Informatique - Stage Professionnel 

- Titre : Intégration et visualisation de données issues du projet
  Patrimoine Numérique Scientifique du Cirad
- Encadrants : Sandrine Auzoux, Sophie Fortuno,  Mathieu Roche
- Résumé : Le projet Patrimoine Numérique Scientifique (PNS) du Cirad
  (Centre de coopération internationale en recherche agronomique pour le
  développement) est un chantier d'Etablissement lancé en 2013, qui vise
  à gérer, conserver et valoriser les données scientifiques ou données
  de la recherche produites par l'établissement et ses partenaires. Dans
  ce contexte, de nombreux groupes de travail ont permis de contribuer à
  l'identification des données et d'experts pouvant porter/constituer
  des cas d'étude thématiques très prometteurs. Dans le cadre de ce
  stage, quatre tâches principales devront être réalisées :

  * Analyse et pré-traitement des données issues de l'inventaire
    Cirad. Le prétraitement sera essentiellement dédié à la normalisation
    de certaines données et/ou meta-données.
  * Mise en correspondance des données structurées et normalisées à
    l'étape précédente.  
  * Visualisation des données via la bibliothèque javascript Ext JS
    (https://www.sencha.com/products/extjs/).
  * Rédaction d'un rapport incluant la description détaillée du
    protocole reproductible (workflow) sur d'autres ensembles de données
    et métadonnées.

- Projet : Patrimoine Numérique Scientifique (Cirad)
- Description complète du stage et contacts :
  http://textmining.biz/Sujets/M2/stage_PNS2015.pdf

==========================

SUJET 2 - Master 2 Informatique - Stage Recherche 

- Titre : Nommage des clusters évoluant au cours du temps
- Encadrants : Mathieu Roche, Pascal Poncelet, Julien Velcin
- Résumé : Dans nos récents travaux menés entre l'équipe ADVANSE (LIRMM
  & TETIS) et le laboratoire ERIC (Lyon), nous nous sommes intéressés à
  l'identification conjointe des descripteurs (et en particulier le
  vocabulaire) et des catégories. Ceci permet de prendre en compte
  l'évolution des descripteurs au fil du temps mais également d'apporter
  une solution à la sélection des meilleurs descripteurs parmi un très
  grand nombre possible (par exemple, apparition de nouveaux termes,
  prise en compte des entités nommées, etc.). L'identification des
  descripteurs pertinents peut s'appuyer sur l'utilisation de ressources
  sémantiques, de systèmes d'extraction de la terminologie ou de
  méthodes probabilistes. Le stage proposé permettra de combiner les
  différentes approches précédemment citées qui sont fondées sur des
  méthodes symboliques et statistiques afin de proposer une approche
  originale de nommage des clusters au cours du temps.
- Projet : SONGES (Science des dOnnées hétéroGènES)
- Description complète du stage et contacts :
  http://textmining.biz/Sujets/M2/stage_clustering.pdf

==========================

SUJET 3 - Master 2 Informatique - Stage Recherche 

- Titre : Désambiguisation des Entités Spatiales par apprentissage actif
- Encadrants : Mathieu Roche, Maguelonne Teisseire
- Résumé : Dans le cadre de l'identification des Entités Spatiales, un
  problème difficile est en effet lié à la désambiguisation. Nos travaux
  consisteront à adapter les systèmes classiques d'apprentissage actif
  pour traiter les deux types de désambiguisations, à savoir la
  désambiguisation des toponymes (c'est-à-dire, un même toponyme peut
  correspondre à des lieux différents) et la désambiguisation entre
  types d'entités nommées (distinction Entités Spatiales /
  Organisations). Pour cela, la complexité du contexte et les
  descripteurs associés devront être pris en compte dans les modèles
  d'apprentissage actif à mettre en oeuvre. Ce contexte plus riche
  permettra d'améliorer le système de désambiguisation.
- Projet : SONGES (Science des dOnnées hétéroGènES)
- Description complète du stage et contacts : http://textmining.biz/Sujets/M2/stage_appA_ES.pdf"
"299","2015-12-09","LSIS","Marseille","Stage financé de Master de 4 à 6 mois - Marseille, DIMAG, LSIS,
Aix-Marseille Université.

*Analyse automatique des signaux socio-emotionnels dans les interactions
humain-machine*

/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)

/Autres//encadrants/ : Thierry Chaminade, Institut de Neurosciences de
la Timone

/Partenariat/: Axel Boidin, entreprise Picxel

/Contexte du stage /

Ce stage de Master se déroulera dans l'équipe DIMAG au LSIS en
partenariat avec l'entreprise Picxel et l'Institut de Neuroscience de la
Timone (INT). Au sein de l'équipe /DIMAG/, des recherches sont menées
pour développer des méthodes d'extraction automatique d'information
socio-affectives dans des corpus de données textuels ou
vidéos. L'entreprise /Pixcel /(http://www.picxel.fr/ ) travaille depuis
plusieurs années sur un logiciel de détection automatique des émotions à
partir des expressions faciales des individus.L'INT s'intéresse aux
bases physiologiques des comportements sociaux
(http://www.int.univ-amu.fr/_CHAMINADE-Thierry_?lang=fr)

/Sujet de stage /

Les ordinateurs sont aujourd'hui pour la plupart socialement et 
émotionnellement ignorants (Pentland, 2005). Or, les interactions 
humain-machine sont intrinsèquement sociales et émotionnelles, 
impliquant souvent une expérience affective de l'utilisateur pouvant 
ressentir de nombreuses émotions tant positives (joie, soulagement, 
etc.) que négatives (frustration, énervement, etc.) lors de son 
interaction avec un ordinateur (Picard, 1997). De plus, sous la forme de 
personnages virtuels ou de robot humanoïde, ces systèmes interactifs 
sont de plus en plus utilisés pour incarner des rôles sociaux 
particuliers tels que celui de tuteur, de compagnon, d'assistant, de 
conseiller ou d'acteur. Dans ces contextes d'usages, les ordinateurs 
doivent être dotés d'une certaine forme d'*intelligence sociale et 
émotionnelle* (Kihlstorm et Cantor, 2000, Salovey et al., 2000) leur 
permettant d'interagir et sociabiliser avec l'utilisateur ainsi que 
d'exprimer des émotions et gérer celles de l'utilisateur afin 
d'optimiser l'interaction (perception, motivation, performance, 
décision, autonomie, etc.).

L'objectif du stage s'intègre dans la perspective de concevoir des
systèmes interactifs capables de détecter /l'engagement de l'utilisateur
et la qualité de l'interaction/. Pour ce faire, un des enjeux
aujourd'hui est d'identifier,modéliser et détecter automatiquement les
signaux verbaux (e.g. vocabulaire) et non-verbaux(regards, expression
faciales, mouvements de tête, etc.) porteurs d'informations
socio-émotionnelles (e.g. engagement, satisfaction) dans une
interaction.

Ce stage vise à explorer des techniques de fouilles de données pour
analyser automatiquement les signaux verbaux et non-verbaux
socio-émotionnels dans des interactions humain-humain médiatisées ou
humain-machine. Plus précisément, il s'agira d'analyser les séquences de
signaux (sourires, direction du regard, froncement des sourcils,
mouvements de tête, etc.) impliquées dans les expressions d'émotions et
d'attitudes (/e.g./ l'engagement). Pour ce faire, des méthodes de «
sequences mining » seront utilisées sur un corpus de données collectés
par INT (Institut Neuroscience de la Timone). Ce corpus est composé
d'enregistrement vidéo d'interaction naturelle humain-humain médiatisé
(skype) et humain-machine (avec un personnage virtuel). Ce corpus
comporte déjà un certain nombre d'annotations (mouvements du regard,
mouvement de tête, etc.). Il sera complété par les signaux non-verbaux
des individus détectés automatiquement à partir du logiciel développé
par la société Pixcel. De plus, une analyse automatique du comportement
verbal (e.g. vocabulaire, dysfluences) dans différentes situations
d'interactions (e.g. interactions réussies versus non satisfaisantes)
permettra d'identifier des indices verbaux sur la qualité de
l'interaction.

Le stage impliquera dans un premier temps une étude de la littérature en
Sciences Humaines et Sociales et dans le domaine de l'Informatique
Affective et du Traitement Automatique des signaux sociaux (Social
Signal Processing) pour identifier les signaux verbaux et non-verbaux
pertinents et les émotions et attitudes associées. Le stage focalisera
sur un sous-ensemble restreint d'émotions et d'attitudes qu'il s'agira
de définir. Différents algorithmes de « sequences mining » et
d'apprentissage automatique seront explorés et testés sur le corpus de
données.Les résultats seront ensuite modélisés afin de concevoir un
modèle computationnel permettant de détecter automatiquement
certainesémotions et attitudes de l'utilisateur suivant les séquences de
signaux non-verbaux ou des comportements verbaux détectées.Ce modèle
sera testé sur des données réelles.

Le stagiaire devra à la fois avoir des connaissances techniques (Matlab,
Python, SQL), des connaissances en fouille de données, TAL et surtout
une ouverture pluridisciplinaire.

Les dossiers de candidatures doivent contenir un CV détaillé, les notes
de Master, ainsi qu'une lettre de motivation.

Le dossier est à envoyé à magalie.ochs(at)lsis.org"
"300","2015-12-16","SNCF","Paris","Stage de master de 6 mois à la direction Innovation et Recherche SNCF,
Paris 12.

Intitulé : Annotation riche de données web sur les itinéraires et
pratiques des voyageurs

La Direction Innovation et Recherche de la SNCF recherche un stagiaire
pour travailler sur un projet d'étude de la mobilité des voyageurs à
travers l'analyse de données textuelles.

*Activités du stage*
------------------------------
Annotation riche de données web sur les itinéraires et pratiques des
voyageurs

*Thème*
------------------------------
La société connaît depuis quelques années des changements majeurs dans
les pratiques de mobilité, du fait d'autres formes d'organisation du
travail,  de l'émergence de nouveaux modes de transport, de l'impact des
NTIC... Les voyageurs s'expriment sur le web social à propos de leurs
déplacements, aussi bien en situation normale qu'en situation
perturbée. Les messages contiennent des informations sur les activités
des voyageurs, leurs particularités sociologiques ou encore leurs
motivations.
SNCF dispose d'un corpus de données web, d'un premier modèle de
représentation des connaissances (ontologies) ainsi que d'outils
facilitant l'exploration des données.
Le stagiaire aura pour mission d'annoter une base d'exemples, puis
d'évaluer et de proposer des améliorations du modèle de représentation
des connaissances sur la base de ses observations. L'annotation visera
notamment à identifier les modes de transport et autres indices relatifs
à l'itinéraire parcouru, ainsi que des indices relatifs aux activités,
contraintes ou ressentis du voyageur.

*Description *
------------------------------
Le stagiaire devra :
- prendre connaissance du contexte du stage (SNCF, Direction Innovation
  & Recherche, objectifs du stage et cadre de réalisation, projet dans
  lequel le stage s'insère et interlocuteurs sur les sujets concernés)
- annoter une base de messages du web selon les thématiques et sujets
  spécifiés, à partir d'ontologies et taxonomies
- co-construire le modèle de représentation des connaissances, à partir
  de ses premières annotations, de ses analyses et par interaction avec
  la personne actuellement en charge de la réalisation du modèle
- évaluer la pertinence du modèle et la qualité de l'annotation

Présentations et rapports :
- présentation de début de stage à la SNCF (au bout d'un mois de stage) :
  contexte de stage, planning de réalisation et premiers travaux
  réalisés.
- rapport final de stage complet comprenant : méthodologie utilisée,
  travaux réalisés, résultats obtenus et problèmes rencontrés 2
  soutenances de fin de stage : une à l'école et une à la SNCF.

Des présentations en interne SNCF ou externes pourront être effectuées.

*Profil recherché*
------------------------------

Niveau : De formation Bac+5 en Sciences du langage/Traitement
Automatique du Langage Naturel ou Informatique (ingénieur ou master 2).

Compétences attendues :

- Capacités d'analyse, de rédaction et de synthèse
- Autonomie, qualités relationnelles, qualité de présentation
  (orale/écrite).
- Connaissances en TAL et linguistique

Compétences additionnelles souhaitées :
- Compétences en informatique (programmation, gestion de bases de
  données)
- Bonne connaissance du réseau de transport en Ile-de-France


*Modalités du poste*
------------------------------

   - Durée : 6 mois
   - Rémunération prévue: indemnités de stage (924 ¤ bruts mensuels) +
     carte de circulation SNCF sur le réseau national
   - Début : à partir d'avril 2016
   - Lieu : Paris


Merci d'adresser CV et lettre de motivation à Coralie Reutenauer et
Amélie Martin aux adresses mail suivantes : coralie.reutenauer@sncf.fr,
amelie.martin2@sncf.fr"
"301","2015-12-16","IGN","Saint-Mandé","Stage M2 : Analyse de l'emprise d'une carte à partir des toponymes d'un
texte (5 mois à placer entre avril et octobre 2016)

Mots clés
informatique, évaluation, entité nommée spatiale, géomatique, traitement
automatique du langage naturel

Contexte
Ce stage s'insère dans un thème de recherche concernant la définition
automatique de l'emprise d'une carte illustrant un article
journalistique. Une première version d'un outil d'extraction des
""toponymes importants"" d'un texte, et de calcul et visualisation de
l'emprise de la carte correspondante a été réalisée. Cette version
s'appuie sur différentes ressources (gazetiers, patrons) et outils (de
classification, de visualisation) ; elle est à améliorer et différentes
pistes d'amélioration ont été définies.

Sujet
L'objectif du stage est d'approfondir une ou plusieurs des pistes
d'amélioration proposées. Le sujet est donc très ouvert et sera défini
selon les compétences du candidat retenu.

Les pistes d'amélioration sont les suivantes :

- le corpus et la typologie des paires. Un corpus de travail de dix
  paires (texte, carte) a été défini à partir de différentes
  configurations identifiées au préalable. Cette typologie est fondée
  sur la maille de la carte (l'emprise correspond à un ou plusieurs
  continents, un ou plusieurs pays, une région, un ensemble de villes,
  etc.) et le nombre d'entités identifiées comme importantes. Il s'agit
  ici d'augmenter la taille du corpus de travail et de préciser et/ou
  enrichir la typologie déjà proposée pour pouvoir classer toutes les
  paires du corpus augmenté ;

- la définition d'indicateurs permettant de caractériser les
  paires. Différents indicateurs ont été définis qui tiennent compte des
  caractéristiques lexicométriques du texte, de la répartition
  géographique des toponymes, etc. Il s'agit ici d'analyser les
  indicateurs par rapport à la typologie des paires. L'objectif est de
  disposer d'indicateurs qui permettent de différencier les différentes
  configurations, et le cas échéant de proposer et implémenter de
  nouveaux indicateurs linguistiques ou spatiaux ;

- l'évaluation de l'annotation des toponymes et de l'emprise de la
  carte. Le corpus textuel a été annoté (deux annotateurs) et l'emprise
  de la carte qui accompagne le texte mesurée. Une première version d'un
  outil qui mesure l'accord entre les annotateurs a été mise en place,
  ainsi qu'une mesure de distance (distance surfacique) entre l'emprise
  calculée et celle de la référence (i.e. celle de la carte qui
  accompagne le texte). Pour l'évaluation des textes, il faudra mettre
  en place un accord inter-annotateurs qui prennent en compte la nature
  des étiquettes, les bornes des séquences, les enjeux des erreurs sur
  les étiquettes et les bornes. Pour la distance entre emprises, il
  faudra vérifier que les distances calculées sont cohérentes avec la
  mesure intuitive des écarts, et éventuellement proposer une nouvelle
  distance qui complète la distance surfacique pour évaluer la qualité
  de la position respective des deux emprises ;

- la prise en compte de toponymes géographiques. Pour le moment,
  l'identification des toponymes importants tient compte uniquement des
  noms de continents et d'entités administratives : pays, régions
  administratives, villes. D'autres toponymes pourraient être pris en
  compte qui désignent des entités non administratives et/ou
  d'implantation linéaire : régions géographiques à l'intérieur d'un
  pays ou qui chevauchent plusieurs pays, fleuves, chaînes de montagne,
  etc. La difficulté est que ces toponymes et leur géométrie ne sont pas
  toujours répertoriés dans les gazetiers utilisés. Il s'agit ici
  d'élargir les ressources utilisées (toponymes et géométries
  correspondantes) et d'implémenter de nouvelles méthodes de calcul de
  l'emprise qui tiennent de ces nouveaux objets et des relations
  topologiques correspondantes.


Responsables du stage
Catherine Dominguès
IGN/SR/COGIT, 73 avenue de Paris, 94160 Saint-Mandé
tél : +33 1 43 98 85 44
mél : catherine.domingues@ign.fr

Marie-Dominique Van Damme
tél : +33 1 43 98 75 84
mél : marie-dominique.vandamme@ign.fr

Pour candidater
Adresser par courriel à Catherine Dominguès un curriculum vitae et une
lettre de motivation ainsi que les notes obtenues dans les deux
dernières années et une description des enseignements suivis (un lien
vers le site internet de la formation est le bienvenu)."
"302","2015-12-16","Médecin Direct","Paris","STAGE de Master

Classification des e-consultations médecin / patient

MEDECIN DIRECT (www.medecindirect.fr) a développé son expertise dans
la mise à disposition de ressources médicales, à titre de médecins
généralistes ou spécialistes, par tout moyen utilisant les
technologies de l'information et des communications. Dans ce cadre,
elle développe des services de télémédecine, téléconseil médicalisé,
télésuivi (SYMPAD®), téléexpertise et plus généralement tout type de
services dans lequel une ressource médicale est nécessaire. Elle a
développé des outils spécifiques, une méthodologie et des procédures
complexes pour respecter les conditions exigées par l'environnement
médical, en accord avec les autorités compétentes françaises (CNOM,
CNIL, HAS etc...).

A ce titre MEDECIN DIRECT dispose de toutes les autorisations légales
et réglementaires d'exercice médical.

Deux types de e-consultations sont proposées : des interactions de
type questions/réponses (asynchrones) et des interactions
téléphoniques. Les premières sont archivées telles quelles dans une
base de données, les secondes y sont renseignées sour la forme d'un
compte-rendu rédigé par le médecin à destination du patient.

L'objectif du stage est de proposer un système de classification des
e-consultations afin d'en faciliter l'analyse soit dans un but
d'analyse globale des données, soit dans un but d'accès à une
information précise.

Les axes envisagés sont les suivants :

- Proposer une typologie opérationnelle des e-consultations basées sur
  le contenu linguistique de celles-ci : types et modalités
  d'interactions, thématiques abordées, besoin exprimé par le patient,
  types de réponses du médecin, etc.

- Définir les différents types d'e-consultations de façon
  opérationnelle en identifiant des descripteurs associés à chaque
  classe et mettre en place des techniques de classification
  automatique

- Tester l'utilisabilité de la typologie pour l'analyse globale :
  quantifier la fréquence des e-consultations portant sur un
  traitement/une maladie chronique, mesurer le aux de questions
  concernant un tiers, etc.

- Mettre en place des scénarios pour tester l'utilisabilité de la
  typologie dans des situations de besoin d'accès à une information
  précise. Cette partie se fera en lien avec les analystes du service
  et les médecins participants.

Profil

Ce stage s'adresse à un étudiant de deuxième année de master en
traitement automatique des langues.

Ce travail nécessite de la rigueur, de la créativité et de l'autonomie
dans la manipulation des données langagières.

Plus précisément, le stagiaire devra présenter :
- des compétences en linguistique, indispensables pour identifier et qualifer les différents types d'e-consultations.
- une maîtrise des méthodes d'analyse de corpus et de lingusitique
  outillée est indispensable : approches guidées par les données,
  annotation, utilisation de concordanciers
- des compétences en informatique et en TAL : création de scripts,
  annotation automatique de corpus, maniement d'expressions
  régulières, mise en place et évaluation d'outils de classification
  automatique
- une connaissance dans la gestion et l'exploitation de base de
  données et dans l'utilisation de mesures statistiques

Le stage se déroule chez la Société Médecin Direct, Incubateur
Boucicaut, 130 rue de Lourmel, 75015 PARIS

Durée de stage envisagée : 5 à 6 mois.
Début de stage prévu en mars-avril 2016
Indemnités conventionnelles

Pour contact et candidature : 
François Lescure
francois.lescure@medecindirect.fr"
"303","2016-01-04","LIMSI & INRIA","Orsay","Political Viewpoint Analysis from Social and Web Sources

Xavier Tannier (LIMSI/ U. Paris Sud, CNRS)
Ioana Manolescu (INRIA, U. Paris Sud)

Duration: 5-6 months, the starting date is flexible (ideally March
1st, 2016)

Location: Orsay, France

Keywords: Natural Language Processing, Text Mining, Information
Extraction, Information Retrieval, Social data management, Databases
(the tasks will be adapted according to interest and level of
qualification of the candidate).

The work is to be carried in close collaboration between the INRIA OAK
team, LIMSI-CNRS and the major French newspaper Le Monde. The work
is supported by a Computational Research Journalism Award from Google

Context

The French political arena comprises many political parties, spanning
from the extreme left to the extreme right. In 2012, no less than 10
candidates ran for the presidential election (12 in 2007), with
sensitivities such as communism, socialism, ecology, centre left,
centre right, right, far right, extreme right, or even one literally
called ""hunting, fishing, nature and tradition"". Further, as in any
democratic countries, ideas and values intertwine with group tactics,
personal ambitions, communication strategies, that make politicians
take stands which do not always directly copy those of their political
party.

For all these reasons, deciphering politician candidates' positions
and deciding which candidate is the closest to our own opinions is a
complex task for citizens. Similarly, analyzing statements and facts
into perspective is complex work for journalists.  The goal of the
internship is to automatically build (from a variety of sources such
as online news articles, Twitter feeds, structured databases etc.)
topical threads that will organize and visualize claims made by
politicians, in order to help journalists and citizens decode them and
distinguish between personal opinion, communication tools established
by the parties, and voluntary distortions of the reality.

Data sources. 

We will use different textual and/or structured data sources as input
to our extraction process:

â€¢ Newspaper articles from Le Monde web site and printed version.

â€¢ Social network data, that comes already endowed with metadata
specifying e.g., the author and date of every information item
published in a social context, and possibly previously published items
to which the new item refers e.g., re-tweets);

â€¢ The link structure (e.g., news articles citing each other, links
appearing in tweets), from which we will extract information on a
thread continuation;

â€¢ Background knowledge concerning political affiliations of people, as
well as their position in the political chessboard (importance and
side), can be exploited to contextualize the social item content;

â€¢ Possibly, data such as voting intention polls, in order to track
events to have an influence on them.  Scientific areas. This project
involves scientific fields such as Natural Language Processing,
Information Extraction, Information Retrieval, Social data management,
Database, Data visualization.


Description

Depending on the level of qualification and duration of the candidate
internship, (s)he will work on one or several of the following steps:

â€¢ Using existing metrics (such as mutual information, tf-idf, lexical
  specificity) for extracting differences and similarities between
  claims from different political sides, or different political
  personalities.

â€¢ Implementing and adapting unsupervised algorithms such as topic
models (e.g. LDA) on different types of claims.

â€¢ Building a unified framework for collecting, organizing and querying
claims from various sources.  

Required competencies are: good software development skills, strong
qualification in one or several of the scientific areas involved in
the project (demonstrated e.g., by academic results or past successful
projects), good communication skills and willingness to work in a
team.  On a daily basis, work will take place in a collaborative team
comprising the internship supervisors, an INRIA engineer whose task it
is to oversee and coordinate the development of our unified platform
for data-based fact checking, and probably other interns. The work is
related to a longer scientific effort within the four-years ANR
project ContentCheck (Content Management Techniques for Fact-Checking:
Models, Algorithms, and Tools); the project starts in January 2016.

The internship may lead to a PhD within the project.
 
The internship will take the form of a full-time INRIA employment
contract. The intern will be paid 1100 â‚¬/month.

Contacts

â€¢ Ioana Manolescu (ioana.manolescu@inria.fr),
  http://pages.saclay.inria.fr/ioana.manolescu/

â€¢ Xavier Tannier (xavier.tannier@limsi.fr),
  https://perso.limsi.fr/xtannier/en/"
"304","2016-01-04","LTCI","Orsay","TITRE : Gestion de l'Intra-synchronie entre gestes et contenu verbal
pour la génération de comportements chez un Agent Conversationnel Animé

ENCADREMENT : Catherine Pelachaud et Chloé Clavel

Laboratoire d'accueil : LTCI, CNRS, Télécom ParisTech, Université
Paris-Saclay,

75013, Paris, France

Durée du stage : 6 mois à partir d'avril 2016

PROFIL DU CANDIDAT: étudiant titulaire d'un master 2 recherche

- Interaction humain/machine, agents conversationnels animés

- Apprentissage statistique / reconnaissance des formes/ Traitement du
  Langage Naturel

- Bon niveau en programmation (Java, C/C++, Python)

- Bon niveau d'anglais


CANDIDATURES : à envoyer à chloe.clavel@telecom-paristech.fr ,
catherine.pelachaud@telecom-paristech.fr

- Curriculum Vitae

- Lettre de motivation personnalisée expliquant l'intérêt du candidat
  sur le sujet *(directement dans le corps du mail)*

- Relevés de notes des années précédentes

- Contact d'une personne de référence

*Les candidatures incomplètes ne seront pas examinées.*

SUJET DU STAGE : L'utilisation des robots pour des services à la
personne (ex : assistance aux personnes âgées), ou plus largement des
agents conversationnels animés pour la gestion de la relation client sur
les sites de vente en ligne (voir par exemple l'agent Yoko de Toshiba :
goo.gl/Q4wi0y) est un domaine en plein essor dans lequel l'intégration
de la composante socio-affective dans l'interaction entre l'humain et
l'agent virtuel joue actuellement un rôle central.

La plateforme GRETA développée au sein du LTCI-CNRS [Ochs et al., 2014]
est dotée de composants socio-affectifs capables d'intégrer des émotions
et des attitudes sociales dans le comportement d'un agent
conversationnel animé.  Le traitement des gestes de l'agent [Lee et
al. 2011] se fait à l'aide de marqueurs temporels (time codes) utilisés
pour synchroniser les gestes et la parole et les différents
comportements communicatifs associés aux comportements
socio-affectifs. L'encodage des gestes est réalisé au format FML-APML
[Affective Presentation Markup Language [Mancini and Pelachaud, 2008]
reposant sur le Functional Markup Language]. Un geste communicatif est
défini par la trajectoire et la forme de la main dans l'espace et par sa
structure temporelle [Kendon, 2004]. Il existe différents types de
gestes [McNeill, 1992] comme les *deictiques* (e.g. indiquer un point
dans l'espace), les *iconiques* (e.g. mimer la grandeur d'un objet), les
*métaphoriques* (e.g. figurer une idée abstraite, comme un geste de
mains circulaires pour signifier ""englober"" ) et les *battements* qui
viennent appuyer le discours.

L'enjeu global du stage est de travailler sur la génération multimodale
des énoncés de l'agent. Différentes modalités ont été étudiées au sein
de l'équipe Greta du LTCI : le geste [Le et al. 2011], la prosodie
[Bawden et al., 2015], les expressions faciales [Ding et al., 2013]. Le
stage portera sur les modalités verbale et gestuelle. En particulier,
l'objectif sera de mettre en place des méthodes de *machine learning*
permettant d'apprendre à partir d'un corpus d'enregistrements de
comportements humains les relations d'intra-synchronie entre les gestes
et le contenu verbal : à quel moment générer un geste communicatif donné
à partir des propriétés structurelles de la parole définies à partir des
contenus syntaxiques, sémantiques, prosodiques et pragmatiques? Les
corpus envisagés pour l'apprentissage sont le corpus CID (Corpus of
Interactional Data [Bertrand et al., 2008]) et le AMI meeting corpus
[McCowan, 2005].

Le stage s'articulera autour des tâches suivantes :

* définition des différentes unités de segmentation de la parole
  pertinentes (segments prosodiques ou textuels);

* analyse des corrélations entre les time codes des gestes et les time
  codes des frontières de segments;

* développement de méthodes de *machine learning* (Hidden Markov Models
  ou Conditional Random Fields [Lee and Marsella, 2012], [Levine et al.,
  2010], [Ding et al., 2013]) pour l'apprentissage de l'alignement du
  geste sur le texte en vue d'un modèle de génération de gestes
  communicatifs pour les agents virtuels conversationnels.



REFERENCES :

R. Bawden, C. Clavel, F. Landragin, Towards the generation of dialogue
acts in socio-affective ECAs: a corpus-based prosodic analysis
(http://dx.doi.org/10.1007/s10579-015-9312-9), Language Resources and
Evaluation, Springer Netherlands, 2015

R. Bertrand, P. Blache, R. Espesser, G. Ferré, C. Meunier, Béatrice
Priego-Valverde, and Stéphane Rauzy. ""Le CID-Corpus of Interactional
Data-Annotation et exploitation multimodale de parole
conversationnelle.""  Traitement automatique des langues 49, no. 3
(2008): 1-30.

Y. Ding, M. Radenen, T. Artières, C. Pelachaud. Speech-Driven Eyebrow
Motion Synthesis With Contextual Markovian Models International
Conference on Acoustics, Speech and Signal Processing (ICASSP), 2013.

A. Kendon, Gesture: Visible Action as Utterance, Cambridge University
Press, 2004.

Q. A. Le, S. Hanoune and C. Pelachaud, Design and implementation of an
expressive gesture model for a humanoid robot. 11th IEEE-RAS
International Conference on Humanoid Robots (Humanoids 2011), Bled,
Slovenia on October 26th to 28th, 2011.

J. Lee and S. Marsella. Modeling speaker behavior: A comparison of two
approaches. In IVA, pages 161-174. Springer, 2012.

S. Levine, P. Krähenbühl, S. Thrun, and V. Koltun, ""Gesture
controllers,"" ACM Trans. Graph., vol. 29, no. 4, 2010.

M. Mancini and C. Pelachaud. ""The FML-APML language."" In Proc. of the
Workshop on FML at AAMAS, vol. 8. 2008.

I. McCowan, J. Carletta, W. Kraaij, S. Ashby, S. Bourban, M. Flynn, M.
Guillemot et al. ""The AMI meeting corpus."" In Proceedings of the 5th
International Conference on Methods and Techniques in Behavioral
Research, vol. 88. 2005.

D. McNeill, Hand and Mind: What Gestures Reveal about Thought,
University of Chicago Press, Chicago, 1992.

Magalie Ochs, Yu Ding, Nesrine Fourati, Mathieu Chollet, Brian Ravenet,
Florian Pecune, Nadine Glas, Ken Prepin, Chloé Clavel et Catherine
Pelachaud, Vers des Agents Conversationnels Animés Socio-affectifs, Journal
d'Interaction Personne-Système, JIPS, 3 (2), pp.1-23, Mars 2014"
"305","2016-01-04","LATTICE","Paris","* Modélisation informatique de mécanismes d'acquisition de constructions
  lexico-syntaxiques

Dans le cadre d'un projet européen (projet ERA-NET Atlantis), en
collaboration notamment avec le centre de recherche de Sony à Paris
(Sony CSL), le Lattice propose un stage autour de la modélisation de
l'acquisition de constructions linguistiques. Le stage consistera, à
partir d'une micro-grammaire de l'anglais ou de l'allemand (la
micro-grammaire sera fournie), à élaborer des stratégies d'extension et
d'acquisition de nouvelles constructions à partir de données extérieures
(typiquement, de nouvelles phrases) et/ou de méta-connaissances sur la
grammaire elle-même. L'étude portera sur les processus d'acquisition et
sur le type de connaissance impliqué davantage que sur la couverture de
la grammaire finale.

Le stagiaire devra être inscrit dans un Master 2, en informatique,
traitement automatique des langues, intelligence artificielle ou
sciences cognitives. Tout profil présentant les compétences demandées
sera pris en considération.

Compétences exigées :
- connaissances en programmation
- maîtrise d'un langage de scripts (perl ou python)
- anglais technique
- qualités de rédaction
- aptitude au travail en équipe

Conditions

Stages normalement prévu pour 6 mois à partir du mois d'avril 2016 et
rémunéré au tarif réglementaire. Le stage devra faire l'objet d'une
convention de stage. Le lieu de travail est le laboratoire Lattice à
Montrouge, près de Paris (métro Mairie de Montrouge)


Pour candidater, merci d'envoyer un CV et un relevé de notes récent (M2
en cours ou M1) à : thierry.poibeau@ens.fr, en précisant bien quel stage
est visé."
"306","2016-01-04","LATTICE","Paris","* Acquisition de schÃ©mas prÃ©dicatifs verbaux en finnois

L'acquisition lexicale vise Ã  acquÃ©rir des informations de nature
lexicale Ã  partir de l'analyse automatique de grands corpus. Pierre
Marchal a soutenu rÃ©cemment une thÃ¨se consacrÃ©e au dÃ©veloppement d'un
tel systÃ¨me pour le japonais. L'acquisition de connaissances relatives
aux constructions verbales est en effet une question importante pour le
traitement automatique des langues, mais aussi pour la lexicographie qui
vise Ã  documenter les nouveaux usages linguistiques. L'approche repose
sur un modÃ¨le original pour la notion d'entrÃ©e lexicale et la
distinction entre arguments et circonstants : plutÃ´t qu'adopter un
dÃ©coupage binaire entre sens et antre arguments et circonstants, la
modÃ©lisation repose sur la notion de continuum. Enfin, le lexique obtenu
n'est pas figÃ© et il est possible de dÃ©river diffÃ©rents ressources, avec
diffÃ©rents degrÃ©s de granularitÃ© de description. Le but du stage
consiste Ã  reprendre la chaÃ®ne de traitement dÃ©veloppÃ©e dans le cadre de
cette thÃ¨se et Ã  l'adapter pour le traitement du finnois.

Le stagiaire devra Ãªtre inscrit dans un Master 2, en informatique,
traitement automatique des langues, intelligence artificielle ou
sciences cognitives. Tout profil prÃ©sentant les compÃ©tences demandÃ©es
sera pris en considÃ©ration. Une connaissance mÃªme minimale du finnois
est nÃ©cessaire.

CompÃ©tences exigÃ©es :
- connaissances en programmation
- maÃ®trise d'un langage de scripts (perl ou python)
- connaissance du finnois
- anglais technique
- qualitÃ©s de rÃ©daction
- aptitude au travail en Ã©quipe

Conditions

Stages normalement prÃ©vu pour 6 mois Ã  partir du mois d'avril 2016 et
rÃ©munÃ©rÃ© au tarif rÃ©glementaire. Le stage devra faire l'objet d'une
convention de stage. Le lieu de travail est le laboratoire Lattice Ã 
Montrouge, prÃ¨s de Paris (mÃ©tro Mairie de Montrouge)

- qualitÃ©s de rÃ©daction
- aptitude au travail en Ã©quipe

Conditions

Stages normalement prÃ©vu pour 6 mois Ã  partir du mois d'avril 2016 et
rÃ©munÃ©rÃ© au tarif rÃ©glementaire. Le stage devra faire l'objet d'une
convention de stage. Le lieu de travail est le laboratoire Lattice Ã 
Montrouge, prÃ¨s de Paris (mÃ©tro Mairie de Montrouge)


Pour candidater, merci d'envoyer un CV et un relevÃ© de notes rÃ©cent (M2
en cours ou M1) Ã  : thierry.poibeau@ens.fr, en prÃ©cisant bien quel stage
est visÃ©.
 

References
* P. Marchal 2015. Acquisition de schÃ©mas prÃ©dicatifs verbaux en
japonais. ThÃ¨se de l'INALCO. 
* P. Marchal, T. Poibeau et Y. Lepage (2012). ""Representing the
Continuum between Arguments and Adjuncts within
Predicate-â€‹â€‹Frames"". NINJAL International Symposium on ""Valency Classes
and Alternations in Japanese"", Tokyo, August 2012."
"307","2016-01-04","LATTICE","Paris","* Inférence de grammaire à partir de données en ancien français
* Analyse statistique des particularités de l'ancien français sur la
  base de corpus annoté

Le Lattice a contribué à développer des bases de données annotées de
l'ancien français (morphosyntaxe et syntaxe). Diverses projets utilisent
déjà ces corpus annotés pour inférer des analyseurs automatiques,
étudier l'évolution de la langue et les particularités du français en
fonction de la période considérée. Dans la continuité de ces travaux, le
Lattice propose un stage visant à mieux exploiter les ressources
existantes et à étudier leur utilisation sur d'autres corpus en
collaboration avec des laboratoires partenaires, notamment au sein de
l'Ecole Nationale des Chartes.

Le stagiaire devra être inscrit dans un Master 2, en informatique,
traitement automatique des langues, intelligence artificielle ou
sciences cognitives. Tout profil présentant les compétences demandées
sera pris en considération. Une connaissance même minimale de l'ancien
français serait un plus.

Compétences exigées :
- connaissances en programmation
- maîtrise d'un langage de scripts (perl ou python)
- si possible connaissance et intérêt pour l'ancien français
- anglais technique
- qualités de rédaction
- aptitude au travail en équipe

Conditions

Stages normalement prévu pour 6 mois à partir du mois d'avril 2016 et
rémunéré au tarif réglementaire. Le stage devra faire l'objet d'une
convention de stage. Le lieu de travail est le laboratoire Lattice à
Montrouge, près de Paris (métro Mairie de Montrouge)


Pour candidater, merci d'envoyer un CV et un relevé de notes récent (M2
en cours ou M1) à : thierry.poibeau@ens.fr, en précisant bien quel stage
est visé. 

References
* G. Guibon, I. Tellier, M. Constant, S. Prevost, K. Gerdes 15 :
Searching for Discriminative Metadata on Heterogenous Corpora, 14th
Treebank and Language Theory (TLT), Varsovie, 2015.
* G. Guibon, I. Tellier, M. Constant, S. Prevost, K. Gerdes 14 : Parsing
Poorly Standardized Language Dependency on Old French, 13th Treebank and
Language Theory (TLT), Tubingen, 2014.
* A. Simonenko, B. Crabbé, S. Prevost 15 : Morphological triggers of
syntactic changes: Treebank-based Information Theoretic approach, 14th
Treebank and Language Theory (TLT), Varsovie, 2015."
"308","2016-01-04","LIGM","Paris ou Marne-la-Vallée","Reconnaissance d'expressions polylexicales verbales et apprentissage
profond

    Domaine: traitement automatique des langues

    Lieu du stage: Alpage, UniversitÃ© Paris-Diderot ou LIGM,
    UniversitÃ© Paris-Est Marne-la-VallÃ©e

    Encadrant principal: Matthieu Constant

    DurÃ©e du stage: 6 mois

    RÃ©munÃ©ration: gratification rÃ©glementaire

    Financement: UniversitÃ© Paris-Est Marne-la-VallÃ©e

Contexte du stage

Une des tÃ¢ches fondamentales du traitement automatique des langues est
de dÃ©velopper des analyseurs produisant automatiquement une
reprÃ©sentation linguistique d'un texte donnÃ© en entrÃ©e:
ex. segmentation lexicale, Ã©tiquetage grammatical, analyse syntaxique,
analyse sÃ©mantique, â€¦ Les stages proposÃ©s ci-dessous concernent la
segmentation lexico-sÃ©mantique et, en particulier, l'identification
des expressions polylexicales, qui forment des combinaisons de mots
avec un certain degrÃ© d'idiomaticitÃ©. Ces expressions sont trÃ¨s
frÃ©quentes et extrÃªmement variÃ©es. Par exemple, pomme de terre,
prendre en grippe, alors que, en effet, en dÃ©pit de, â€¦ Elles posent de
sÃ©rieux problÃ¨mes pour les applications du traitement automatique des
langues comme la traduction automatique. Cette proposition de stage se
place dans le cadre du projet ANR PARSEME-FR qui vise Ã  intÃ©grer ce
type dâ€™expressions au sein dâ€™analyseurs syntaxiques Ã  grande
Ã©chelle. Ce stage pourra Ã©ventuellement se poursuivre en thÃ¨se.

Objectifs

L'objectif de ce stage est dâ€™incorporer dans un outil dâ€™identification
d'expressions polylexicales des techniques dâ€™apprentissage profond (ou
deep learning), afin dâ€™amÃ©liorer ses performances. Dans un premier
temps, les techniques seront mises au point pour le franÃ§ais, la
langue de travail du projet PARSEME-FR. Puis, elles seront adaptÃ©es Ã 
un certain nombre de langues europÃ©ennes avec, pour objectif, Ã  moyen
terme de participer Ã  la compÃ©tition internationale sur la
reconnaissance dâ€™expressions verbales qui se tiendra dans le cadre de
lâ€™action europÃ©enne COST PARSEME entre 2016 et 2017. Lâ€™un des enjeux
importants du stage sera de mettre en oeuvre des mÃ©thodes
dâ€™apprentissage profond tenant compte dâ€™informations linguistiques
provenant de lexiques.

Le stagiaire recrutÃ© sera amenÃ© Ã  collaborer avec des chercheurs de
lâ€™Ã©quipe Alpage de lâ€™INRIA et du laboratoire Lattice.

Candidater

Profil du candidat:

    Master 2 ou Ã©cole d'ingÃ©nieur en informatique ou TAL

    trÃ¨s bonnes compÃ©tences de programmation objet (Java ou C++),

    bonnes connaissances des techniques d'apprentissage, notamment le
    deep learning

Les candidatures doivent Ãªtre envoyÃ©es par mail Ã 
Mathieu.Constant@u-pem.fr. Le dossier de candidature contiendra un cv,
une lettre de motivation, et, Ã©ventuellement, la recommandation d'un
enseignant."
"309","2016-01-04","LIGM","Paris ou Marne-la-Vallée","Développement d'outils d'enrichissement d'un lexique d'expressions
polylexicales du français

    Domaine: traitement automatique des langues

    Lieu du stage: Alpage, Université Paris-Diderot ou LIGM,
    Université Paris-Est Marne-la-Vallée

    Encadrant principal: Matthieu Constant

    Durée du stage: 6 mois

    Rémunération: gratification réglementaire

    Financement: Université Paris-Est Marne-la-Vallée

Contexte du stage

Une des tâches fondamentales du traitement automatique des langues est
de développer des analyseurs produisant automatiquement une
représentation linguistique d'un texte donné en entrée:
ex. segmentation lexicale, étiquetage grammatical, analyse syntaxique,
analyse sémantique, ... Les stages proposés ci-dessous concernent la
segmentation lexico-sémantique et, en particulier, l'identification
des expressions polylexicales, qui forment des combinaisons de mots
avec un certain degré d'idiomaticité. Ces expressions sont très
fréquentes et extrêmement variées. Par exemple, pomme de terre,
prendre en grippe, alors que, en effet, en dépit de, ... Elles posent de
sérieux problèmes pour les applications du traitement automatique des
langues comme la traduction automatique. Cette proposition de stage se
place dans le cadre du projet ANR PARSEME-FR qui vise à intégrer ce
type d'expressions au sein d'analyseurs syntaxiques à grande
échelle. Ce stage pourra éventuellement se poursuivre en thèse.

Objectifs

L'identification des expressions polylexicales passe en général par la
consultation de ressources lexicales riches. Il existe un certain
nombre de telles ressources pour le français. Cependant, celles-ci
sont souvent incomplètes en termes de couverture, de propriétés
syntaxico-sémantiques, et ne sont pas toujours directement
exploitables pour les outils du TAL.

L'objectif du stage est de développer des outils permettant:
    d'agréger plusieurs lexiques dans un cadre unifié

    de les enrichir (semi-)automatiquement en termes de propriétés
    morphologiques, syntaxiques et sémantiques

Le stagiaire recruté sera en collaboration étroite avec des linguistes
du LIGM. Il travaillera également en collaboration avec des chercheurs
de l'équipe BdTln du Laboratoire d'informatique de l'Université
François-Rabelais.  

Candidater

Profil du candidat:

    Master 2 en TAL ou linguistique informatique
    bonnes compétences d'un langage de script (ex. python ou perl)

Les candidatures doivent être envoyées par mail à
Mathieu.Constant@u-pem.fr. Le dossier de candidature contiendra un cv,
une lettre de motivation, et, éventuellement, la recommandation d'un
enseignant."
"310","2016-01-04","Talend & LIMSI","Paris & Orsay","Stage Master 2 de Recherche 2015-2016

https://perso.limsi.fr/pap/talend_internship_2015/stage_limsi_talend_2015_2016.html

Talend - LIMSI-CNRS

Liaison Référentielle d'Entités Nommées dans un contexte Big Data

Big Data Referential Named Entity Linking

Développement d'un logiciel permettant de lier l'occurrence d'une Entité
Nommée dans un extrait de texte à la représentation de l'entité dans des
bases de connaissances en contexte Big Data

------------------------------------------------------------------------
Qui ?

Talend est une société édititrice de logiciels (http://www.talend.com/)
fondée en 2006, spécialisée dans l'Open Source pour l'intégration et la
gestion des données. Son siège social est basé à Redwood City
(États-Unis) et elle compte plus de 400 personnes, avec des bureaux dans
plusieurs pays, dont la France (https://fr.talend.com/).

Au sein du laboratoire pluridisciplinaire LIMSI-CNRS
(https://www.limsi.fr/fr/), constitué d'un département de mécanique des
fluides et d'un département Communication-Homme-Machine, le groupe
Information Langues Écrite et Signée - ILES
(https://www.limsi.fr/fr/recherche/iles), effectue depuis de nombreuses
années des recherches en Traitement Automatique des Langues Naturelles
sur l'écrit et la Langue des Signes. Le groupe étudie entre autres
domaines, les corpus et leurs représentations, l'apprentissage
automatique, l'évaluation des technologies l'analyse du langage naturel,
le multilinguisme et les paraphrases, l'extraction d'information et les
Systèmes Réponse aux Questions, la fouille d'opinion et analyse de
sentiments.

------------------------------------------------------------------------
Quoi ?

Les Entités Nommées sont des objets informationnels à la frontière de la
Linguistique, du Traitement Automatique des Langues et de la Recherche
d'Information issus des campagnes d'évaluation Nord-américaines en
Extraction d'Information. Elément essentiel de la mise en relation du
contenu informationnel d'un texte avec le monde réel, elles forment un
ensemble hétérogène, sur le plan lexical comme sur le plan sémantique et
ont connu des définitions de plus en plus riches et complexes au fur et
à mesure que leur utilisation s'est développée. Leur traitement par un
système informatique suppose que celui-ci soit capable de les:

1) détecter, c'est à dire d'identifier dans un document les empans de
   texte représentant une Entité Nommée,

2) classer selon leur type (personne, organisation, lieu géographique,
   etc.),

3) lier à leur ""referrent"", c'est à dire de les associer à la dénotation
   de l'entité réelle associée, stockée dans une base de connaissances.

Le sujet du stage sera de développer un système effectuant ces trois
tâches sur des données textuelles (données non-structurées) dans un
contexte Big Data.

La société Talend dispose actuellement, d'une part d'un prototype de
logiciel d'anonymisation de documents et d'autre part, d'un analyseur de
données structurées permettant de construire automatiquement des bases
de connaissances. En partant du prototype d'anonymiseur et des
fonctionnalités d'analyse de données structurée Talend et des ressources
linguistiques disponibles au LIMSI, le/la stagiaire fera une étude de
l'état de l'art et des solutions existantes en logiciel libre pour
développer (prototype) un système réalisant les tâches (1), (2) et (3).

Le résultat attendu est d'une part l'amélioration de l'anonymisation et
d'autre part le peuplement de bases de connaissances sur les Entités
Nommées à partir de documents ou d'extraits de documents dans un
contexte Big Data.

------------------------------------------------------------------------
Comment ?

Les prérequis. Le/la stagiaire devra être autonome en ce qui concerne la
programmation dans des langages de haut niveau et avoir soit une
expérience minimale de l'utilisation de ressources linguistiques
(lexiques, grammaires, automates de reconnaissance), soit des
connaissances théoriques en langages formels.

Une expérience des outils Big Data comme Hadhoop, Hive, SparkSQL ou au
mieux SPARK ou Talend seront des facteurs déterminants dans la sélection
des candidats.

En outre des compétences Apprentissage Automatique ou Intelligence
Artificielle ou bien encore en Statistiques seront des plus appréciés.

Bien entendu, il/elle devra disposer d'une bonne maîtrise des langues
française et anglaise pour pourvoir utiliser au quotidien la littérature
scientifique.

------------------------------------------------------------------------
Administratif

Le stage sera indemnisé à hauteur de 1000¤ par mois par Talend.

Il prendra place en alternance à Paris dans les locaux de Talend et à
Orsay, sur le plateau de Saclay, dans l'équipe ILES du LIMSI-CNRS.

Il sera co-encadré par :
- Sebastiao Correia (scorreia@talend.com) pour Talend et
- Patrick Paroubek pour le LIMSI -CNRS (pap@limsi.fr).

Les transports (mensuel ou annuel) seront pris en charge à 50% par
Talend.

Le stage se déroulera sur une période de 5 mois consécutifs.

La période initialement prévue pour le stage est de janvier à juin 2016,
mais pourra être aménagée en fonction des besoins de chacun.
------------------------------------------------------------------------"
"311","2016-01-04","SESAMm","Metz","Our team is looking for an intern in Natural Language Processing for
traditional and simplified Chinese for 6 months.

SESAMm was founded in 2014 and is one of the most dynamic FinTech
startups in France and Luxembourg. SESAMm develops and commercializes
stock market forecasting tools based on social media and other textual
data sources.These products are used by banks and hedge funds. The
company provides financial trading indicators which have been created
using Big Data methods and allowing new approaches for trading
strategies. We develop many new products based on our clients' needs.

SESAMm aims at becoming the international leader of Big Data
technologies for stock market professionals.

Internship Goal: development of new text-analysis and sentiment analysis
methods to create financial trading indicators based on information from
Chinese social media and social trading platforms.

Major Duties:
- Participate in existing and future research projects: analyze existing
  methods, develop original solutions and evaluate them, present results
- Identify relevant sources of information and extract data. Crawling &
  scraping of several data sources.
- Filter and prepare data
- Develop NLP algorithms for traditional and simplified Chinese.
- Write analysis reports

Education Requirements
- Engineering school or university master student: Computer Science,
  Natural Language Processing or similar.

Work Experience and Skills Requirements
- Work Experience: 0-1 year in NLP or computer science.
- Knowledge in NLP, Machine Learning, crawling and scraping.
- Demonstrate ability to create lexical semantic resources for NLP-based
  applications.
- Languages: native Mandarin, traditional and simplified Chinese
  written.
- Programming Skills : Java and scripting languages

The applicant should be able to work in a team and show high
motivation. This internship requires autonomy and curiosity toward a
changing environment. The intern will contribute to the company's most
important technical decisions; thereby this internship will be a
high-level entrepreneurial experience.

Working Conditions
- Percent Time: 100%
- Location: Metz (France)
- Duration: 6 months, starting in February 2016.
 

Join SESAMm, an innovative and ambitious FinTech startup with high
potential.
More information: www.sesamm.com
Please send your application to contact@sesamm.com
Application: resume, interview"
"312","2016-01-08","Inalco","Paris","Stage M2 TAL Ã  l'Inalco
DÃ©sambiguisation lexicale pour les langues mandingues

Le stage proposÃ© vise Ã  dÃ©velopper des outils de dÃ©sambiguisation
lexicale (tonalitÃ©s et gloses) en exploitant des corpus et des mÃ©thodes
d'apprentissage statistique. Il portera sur deux langues africaines, le
bambara et le maninka, des langues mandingues parlÃ©es en Afrique de
l'Ouest et dans la diaspora africaine. Il s'agit de dÃ©terminer, pour
chaque token du corpus, l'entrÃ©e lexicale concernÃ©e, en s'appuyant sur
des mÃ©canismes liÃ©s Ã  la tonalisation (partiellement codÃ©es ou annotÃ©es
et au glosage (annotÃ©).

Deux corpus sont collectÃ©s depuis plusieurs annÃ©es et continuellement
alimentÃ©s : le Corpus Bambara de RÃ©fÃ©rence (CBR,
http://cormand.huma-num.fr) et le Corpus Maninka de RÃ©fÃ©rence (Vydrine
2013, Maslinsky 2014). Le premier est codÃ© avec un alphabet latin, le
second avec le systÃ¨me d'Ã©criture N'ko. Une sous partie du CBR (425K
mots) a Ã©tÃ© annotÃ© manuellement, ce qui permettra de faire appel Ã 
techniques d'apprentissage supervisÃ©. Ces deux corpus ayant des textes
en commun (la Bible, le Coran), la construction d'un corpus parallÃ¨le
est Ã©galement envisagÃ©e.

L'objectif du stage est de dÃ©terminer la faisabilitÃ© d'un systÃ¨me pour
rÃ©aliser automatiquement la tonalisation et le glosage (de maniÃ¨re
sÃ©quentielle ou jointe) sur ces corpus, en exploitant plusieurs critÃ¨res
linguistiques : morphologie des tokens, contextes et informations
distributionnelles, dictionnaires existants, etc. Il serait intÃ©ressant
de mettre en Ã©vidence et d'exploiter les proximitÃ©s entre ces deux
langues pour ces tÃ¢ches. Suite aux Ã©valuations, l'approche donnant les
meilleurs rÃ©sultats sera dÃ©veloppÃ©e sous la forme d'un module Ã  intÃ©grer
Ã  la plateforme TAL en cours de dÃ©veloppement pour ces langues
(Maslinsky 2014).

Profil recherchÃ© :
+ Master 2 en informatique et/ou en linguistique
+ IntÃ©rÃªt pour le traitement automatique des langues
+ CompÃ©tences en programmation (Python)
+ Connaissance des approches utilisÃ©es en apprentissage automatique
+ La connaissance des langues mandingues sera un plus

Pour candidater, merci d'envoyer votre CV, vos relevÃ©s de notes, vos
motivations et tout autre Ã©lÃ©ment utile Ã  Damien Nouvel
(damien.nouvel@inalco.fr).

DurÃ©e du stage : 5 mois Ã  temps plein
Date de dÃ©but : fÃ©vrier ou mars 2016
Gratification : 554â‚¬/mois (et rbst de 50% des transports)
Lieu : Inalco, 2 rue de Lille, 75007 Paris
Contact: Damien Nouvel (damien.nouvel@inalco.fr)

RÃ©fÃ©rences :

(Nouvel et. al. 2015) Traitement automatique du bambara - Objectifs et
premiers rÃ©sultats. SÃ©minaire LIMSI-CNRS ILES, 2015.
(Maslinsky 2014) Maslinsky, Kirill. Daba: a model and tools for Manding
corpora. Atelier TALAF, Traitement Automatique des Langues Naturelles,
2014.
(Vydrine 2013) Vydrin, Valentin. Bamana Reference Corpus (BRC) Procedia -
Social and Behavioral Sciences, 95:25 October 2013, pp. 75-80.
http://www.sciencedirect.com/science/journal/18770428
(Vydrine 2014) Vydrin, Valentin. Projet des corpus Ã©crits des langues
manding : le bambara, le maninka. Atelier TALAF, Traitement Automatique
des Langues Naturelles, 2014."
"313","2016-01-08","INRA","Avignon","Le Pôle Gestion des connaissances (GeCo) de la DIST de l'INRA propose un
stage de 4 à 6 mois sur l'amélioration du thésaurus VocINRA en utilisant
des outils et standards du web sémantique.


Le thésaurus VocINRA sert à l'indexation de l'Archive Ouverte Prodinra
(http://www.prodinra.fr), spécialisée en agronomie et domaines associés
tels que l' environnement, les sciences sociales, la génomique, les
biosciences, etc. Il est multilingue, principalement français et
anglais.

VocINRA a été constitué à partir de différentes sources et est en
constante évolution puisque les documentalistes de l'Inra proposent de
nouveaux mots clés selon un workflow de validation/enrichissement. Des
travaux d'alignement de VocINRA avec des thésaurus de référence comme
Agrovoc/GACS ont démarré et seront poursuivis, en particulier dans le
cadre d'une collaboration avec l'Embrapa Brésil. La publication d'une
version en Linked Open Data est également prévue. VocINRA est
actuellement maintenu et exploité à l'aide d'un outil développé
spécifiquement en interne et nous étudions la possibilité d'utiliser
VocBench (http://aims.fao.org/fr/vest-registry/tools/VocBench-2) pour le
remplacer

L'objectif de ce stage est d'améliorer VocINRA à l'aide de VocBench :

  * Réorganiser   l'arborescence
  * Regrouper les termes synonymes ou très proches autour du même
    concept
  * Enrichir les concepts avec des liens vers des concepts dans d'autres
    ressources (ex: Agrovoc)
  * Rédiger des documents d'accompagnement de l'utilisation de VocINRA
    sur VocBench.

En fonction de l'avancement du stage et des motivations du stagiaire,
d'autres sujets pourront être abordés tels que :

  * Etablir une démarche qualité pour la gestion de VocInra
  * Accompagner la publication en Linked Open Data


*Formation et profil requis*

- Master 2 en cours (4 à 6 mois) avec une spécialité ingénierie
  linguistique ou terminologique

- Connaissances de la gestion des vocabulaires et des technologies du
  web sémantique (format SKOS et RDF, Linked Open Data, Ontologies).

- Capacité pour la prise d'initiative

- Autonomie

- Créativité

- Facilité relationnelle


*Encadrement :*

Pascal Aventurier - Responsable de ERIST (Equipe Régionale d'Information
scientifique et Technique) du centre INRA Paca (Avignon).  Animateur du
pôle Technologies de l'IST Pascal.Aventurier@paca.inra.fr tel 04 32 72
20 13

Sophie Aubin - Animatrice du pôle GeCo (Gestion des Connaissances) DIST
INRA Versailles sophie.aubin@versailles.inra.fr (tel 01 30 83 34 20)


*Conditions du stage*

- Stage conventionné (4 à 6 mois).

- Gratification de stage : 554,50 euros  pour un temps plein

- Prise en charge partielle du coût du repas de midi dans la cantine
  d'entreprise.

- Participation aux frais de transport (trajet domicile/travail en
  transport public).

- possibilité éventuelle d'hébergement en chambre de stagiaire

- Lieu de travail : INRA Centre de Recherche PACA. Avignon, Domaine St 
  Paul - AgroParc"
"314","2016-01-08","L3i","La Rochelle","Stage Master 2 au L3i

Modèle décisionnel basé sur un entrepôt de données au sein d'un système
d'information stratégique

Contexte du stage :

Actuellement, les technologies décisionnelles permettent aux structures
d'organiser leurs masses de données et d'en tirer le meilleur
parti. Dans ce stage, l'objectif est de construire un modèle décisionnel
basé sur un entrepôt de données au sein d'un système d'information
stratégique. Ce modèle décisionnel porte sur les données du système de
gestion de la scolarité.


Objectif :

Le système de gestion de la scolarité est une partie importante du
système d'information d'un établissement d'enseignement, en particulier
dans le supérieur. Les processus métiers du système de gestion de la
scolarité sont souvent une affaire de spécialistes dû à : 

- la complexité des données : elles sont thématiques, historisées et non
  volatiles ; 
- la diversité des sources de données : Application Post-Bac (APB),
  Campus France, bases de données locales, Open-Data, etc. ;
- des processus métiers avec des règles précises : notamment celles
  liées à des textes réglementaires ; 
- des processus métiers avec des règles utilisateurs : liées à des
  usages et des procédures internes définies au sein de la structure. 

Les responsables de ces structures sont souvent amenés à extraire des
indicateurs complexes portant sur différentes phases de la scolarité
(candidature, inscription, validation de semestres, etc.). En général,
ces indicateurs sont formellement bien définis. On les retrouve dans
divers tableaux de bords, ou des rapports d'activités pour un usage
interne à la structure, pour l'université, pour des regroupements
régionaux ou lors de dossiers demandés par le Ministère de
tutelle. Toutefois, les responsables des structures sont aussi
conscients de la capacité expressive des données et souhaitent tirer
plus d'informations pertinentes en particulier celles qui sont liées au
territoire.

Le schéma opérationnel de réalisation du travail demandé se résume comme
suit :

- Concevoir un business model de la reprise de données des applications
  de scolarité : il s'agit d'automatiser l'ensemble des processus
  constituant la reprise de données pour  l'alimentation de l'entrepôt. 
- Concevoir un modèle de vérification, de consolidation et d'intégration
  des données : modèle basé sur des procédures dites « data checking
  tests ». 
- Concevoir le modèle décisionnel : il s'agit en fait d'une
  instanciation du modèle décisionnel défini dans le système décisionnel
  actuel. 
- Implanter les indicateurs métiers : cette phase nécessite une
  connaissance approfondie du méta-modèle utilisé par le modèle
  décisionnel. On s'intéresse en particulier aux problèmes des mesures
  semi-additives, et particulier les mesures dites KPI (key performance
  indicators).  

Prérequis :

Ce sujet d'adresse aux étudiants en Master 2 Informatique, ou élève de
dernière année d'une école d'ingénieur en informatique. Vous êtes
rigoureux dans votre travail mais aussi créatif avec une forte envie
d'apprendre et de vous investir dans un projet décisionnel de taille
réelle au sein d'un environnement professionnel regroupant divers
acteurs.

Les technologies utilisées dans le cadre de la mise en oeuvre sont :

- Programmation : Java - JEE (ejb, seam, jsf, xml, ajax, webservices, etc.) 

- Modélisation dimensionnelle : Mondrian - Données multidimensionnelles : 
  MDX, XQuery 

- Solution d'informatique décisionnelle : Pentaho CE (Kettle, BI Server,
  Report Designer, Shema Workbench ...)

- Base de données : PostgreSQL (avec la cartouche spatiale) 

- Gestion et automatisation du projet : Maven, Redmine 

Informations complémentaires :

Encadrant(s) : Jamal Malki*, Olivier Sauzet** et Patrice Joubert** 

Cadre de coopération : L3i (*) - IUT La Rochelle (**) 

Date de début du stage : à partir du début de l'année 2016 

Durée du contrat : 5 mois (minimum) 

Stage rémunéré

Candidature :

Merci d'adresser votre dossier de candidature à : jamal.malki@univ-lr.fr
Le dossier de candidature doit contenir : 

- le CV

- les relevés de notes des 2 dernières années (M1 et M2)

- la lettre de motivation

- tout autres documents pouvant appuyer la candidature 


Jamal MALKI
Laboratoire L3i, Université de La Rochelle
Département Informatique
IUT La Rochelle 
jmalki@univ-lr.fr <mailto:mickael.brasebin@ign.fr>"
"315","2016-01-08","ERIC","Lyon","Stage recherche de Master au laboratoire ERIC (université de Lyon)

Détection de métaphores dans le discours scientifique

CONTEXTE

La métaphore est une figure de rhétorique largement utilisée dans le
langage courant (par exemple « j'y crois dur comme fer » ou « les
acteurs de la politique de transport »).  Elle est fondée sur l'analogie
; elle permet à un mot de recevoir, dans une phrase, un sens différent
du sens courant en lui donnant le sens que l'on attribue généralement à
un autre mot.  La métaphore est également très utilisée dans le discours
scientifique notamment en Sciences Sociales où elle est au coeur du
raisonnement intellectuel. Nous pensons d'abord par des images. Cela
fait de la métaphore un domaine de recherche importante non seulement en
sciences du langage, en sciences cognitives mais en géographie où elle
est très utilisée par les chercheurs. 

La détection et l'interprétation automatique de métaphores est également
une tâche critique pour le traitement automatique de la langue (TAL) et
l'extraction d'information.

Les travaux sur la détection et la modélisation de métaphores en  TAL et
en intelligence artificielle ont certes commencé dans les années 80,
nous fournissant une foule d'idées sur la structure et les mécanismes du
phénomène. La dernière décennie a été en revanche témoin d'un saut
technologique avec un nombre croissant d'approches exploitant des
techniques statistiques. Par rapport aux approches plus traditionnelles
issues des connaissances codées manuellement, ces méthodes plus récentes
tendent à avoir une couverture plus large ; elles sont souvent moins
précises mais elles sont aussi plus efficaces et robustes. Ainsi,
plusieurs approches de détection de métaphores ont été proposées
(Gedigian et al., 2006; Krishnakumaran and Zhu, 2007; Shutova et al.,
2010) et elles reposent sur l'utilisation d'une ressource lexicale de
type WordNet, TreeBank, etc. Ces ressources lexicales existent
essentiellement pour l'Anglais, le Français ou l'Espagnol. Pour les
autres langues, elles n'existent pas ou elles sont de moindre qualité.
Yulia Tsvetkov et al., 2013 proposent  alors une méthode de détection
des métaphores sans utiliser de ressource lexicale.

Nous nous plaçons dans un cadre récent qui est celui de l'utilisation de
méthodes d'apprentissage automatique pour la détection et
l'interprétation de métaphores. Dans le cadre du stage, nous nous
intéressons à une science sociale particulière qui est la géographie car
nous nous basons sur l'hypothèse que le raisonnement scientifique
géographique s'est en grande partie construit à partir de figures de
rhétorique. 

OBJECTIF DU STAGE

Il sera demandé au stagiaire de :

- réaliser un état de l'art sur les différentes méthodes de détection
  automatique de métaphores,

- mener une étude comparative sur les outils utilisables,

- finaliser la construction d'un corpus d'articles scientifiques en
  géographie,

- tester les méthodes et outils existants sur le corpus d'articles.

COMPETENCES

Le sujet de stage s'adresse à des étudiants de master en informatique
décisionnelle, en fouille de données, en intelligence artificielle ou en
traitement automatique des langues. Des compétences en statistique, en
apprentissage automatique et/ou en TAL seraient particulièrement
appréciées.

REFERENCES

Matt Gedigian, John Bryant, Srini Narayanan, and Branimir
Ciric. Catching metaphors. Proceedings of the 3rd Workshop on Scalable
Natural Language Understanding, pages 41-48. 2006.

Saisuresh Krishnakumaran and Xiaojin Zhu. Hunting elusive metaphors
using lexical resources. Proceedings of the Workshop on Computational
approaches to Figurative Language, pages 13-20. 2007

Shutova Lin Sun and Anna Korhonen. Metaphor identification using verb
and noun clustering. Proceedings of the 23rd International Conference on
Computational Linguistics, pages 1002-1010. 2010.

Yulia Tsvetkov, Elena Mukomel, Anatole Gershman. Cross-Lingual Metaphor
Detection Using Common Semantic Features. First workshop on Metaphor in
NLP (Meta4NLP). 2013.


INFORMATIONS COMPLEMENTAIRES

Lieu : laboratoire ERIC (Lyon, France)

Encadrants : Sabine Loudcher et Julien Velcin (laboratoire ERIC),
             Isabelle Lefort (laboratoire EVS).

Durée : 4 mois à partir de mars ou avril 2016

Rémunération : 554¤ par mois

Merci d'adresser votre candidature avec un CV, une lettre de motivation
ainsi que vos notes de l'année universitaire en cours et de l'année
dernière à Sabine Loudcher (sabine.loudcher@univ-lyon2.fr) et Julien
Velcin (julien.velcin@univ-lyon2.fr)"
"316","2016-01-11","Object'ive","Paris","== Titre ==

Stage R&D - Data Scientist : détection de tendances à partir d'articles
de presse en ligne.

== Contexte ==

Object'ive est une entreprise spécialisée dans l'intégration de solution
d'analyse avancée (sémantique, prédictif) et dans les migrations
architecturales complexes (http://www.object-ive.com/). Elle a notamment
développé Cognit'ive, une solution d'analyse sémantique (
http://www.object-ive.com/index.php?option=com_content&view=article&id=47&Itemid=109).
Vous serez recruté au sein d'Object'ive en tant que stagiaire Data
Scientist, rattaché à la Recherche et au Développement (R&D) pour les
solutions d'analyse sémantique. Vous travaillerez dans une petite
structure avec une ambiance conviviale, au sein de nos locaux situés à
Paris, près de Nation.

La solution Cognit'ive recherche, enrichit, et indexe des contenus texte
de formats divers. Ces contenus proviennent de sources hétérogènes,
comme des articles de presse en ligne, ou des bases de données
internes. Les informations sont rassemblées dans un système de gestion
de contenu, et consultables sous la forme d'un site web. Les opérations
d'analyse sémantique réalisées par Cognit'ive reposent sur des
algorithmes de Fouille de Données texte (text-mining), et utilisent des
modèles d'Apprentissage Automatique (machine learning).

== Mission ==

Nous cultivons un esprit d'innovation, et nous travaillons constamment
au développement de nouvelles solutions d'analyse. Vous contribuerez à
cette dynamique, en concevant un module d'analyse sémantique pour la
détection de tendances à partir d'articles de presse en ligne. Votre
stage sera appliqué au domaine des architectures logicielles
(frameworks) et des langages de programmation. Vous adopterez une
démarche R&D, et vous utiliserez des méthodes statistiques et des
méthodes d'apprentissage automatique. Vous serez encadré dans votre
travail par une Data Scientist ( scampano@object-ive.com) et un
Architecte Logiciel (fstepho@object-ive.com).

== Objectifs ==

Afin de mener à bien votre mission, vous suivrez des étapes
correspondant à votre rôle de Data Scientist :

- vous recueillerez et nettoierez des données sur des sites de presse en
  ligne. Pour réaliser cette tâche, vous utiliserez la plate-forme
  Cognit'ive, qui dispose d'un module de parcours de site web (crawling)
  et d'extraction de contenu (scraping).

- vous réaliserez une analyse exploratoire des données collectées, pour
  les décrire et proposer des premières hypothèses de modélisation de
  tendance.

- vous proposerez et implémenterez un modèle d'analyse de tendances basé
  sur des mesures statistiques et / ou de l'Apprentissage Automatique
  (Machine Learning). Vous travaillerez de façon itérative, en proposant
  rapidement une première version, puis en améliorant progressivement
  votre modèle.

- vous concevrez et vous implémenterez la visualisation graphique des
  tendances détectées par votre modèle.

En fonction de votre profil et de vos centres d'intérêt, certaines
étapes pourront être plus approfondies. Vous serez accompagné par vos
encadrants dans chacune de ces étapes.

== Profil attendu ==

En Master 2 ou en dernière année d'école d'Ingénieur, vous êtes
intéressé par le domaine de la Data Science, et du Web Sémantique. Vous
êtes autonome, vous aimez tester des hypothèses, et vous avez le sens de
l'analyse. Vous souhaitez apprendre, et partager vos connaissances.

Compétences techniques attendues :

- vous avez impérativement des connaissances en statistiques et en
  Machine Learning, que vous avez déjà mis en pratique lors d'un projet
  d'études ou en entreprise.

- vous savez impérativement programmer en Python ou Java
- si vous avez des connaissances en Traitement Automatique du Langage ou
  Fouille de Données Texte, c'est un plus
- si vous avez une première expérience impliquant une démarche R&D
  (stage R&D en entreprise ou stage de recherche en laboratoire), c'est
  un plus

== Perspectives ==

En fonction des résultats obtenus, le stage aura la possibilité d'être
poursuivi par une thèse CIFRE, en partenariat avec Télécom ParisTech.

== Durée du stage ==

Vous effectuerez un stage de 6 mois, avec la possibilité de commencer à
partir de février 2016.

== Lieu du stage ==

Object'ive
96-98 rue de Montreuil
75011 Paris

== Gratification de stage ==

Vous recevrez une gratification définie selon votre profil et vos
compétences. Vous bénéficierez de tickets restaurant et d'un
remboursement partiel de votre titre de transport.

== Processus de candidature ==

Vous êtes intéressé ? Nous serons ravis d'étudier votre candidature.
Envoyez une lettre de motivation et un cv aux contacts suivants :

Sabrina Campano, Data Scientist
Object'ive
scampano@object-ive.com


Fabien Stepho, Architecte Logiciel
Object'ive
fstepho@object-ive.com

Marion Huet, Assistante Ressources Humaines
Object'ive
mhuet@object-ive.com"
"317","2016-01-13","LIMSI","Orsay","Stage Master 2 de Recherche en Traitement automatique des
langues/Extraction d'information

Intitulé : Reconnaissance des Entités Nommées MÉDicales dans l'Oral
(REMEDO)

Durée : 5 mois
Lieu : LIMSI-CNRS, Orsay, France
Rémunération : 554¤ par mois plus participation aux frais de transport
en commun


*Contexte*
------------------------------
Devant l'augmentation toujours croissante de la masse de documents
produits dans le domaine médical, il devient de plus en plus difficile
d'accéder aux informations nécessaires au traitement et à la prise en
charge des patients. Le recours à des méthodes automatiques pour accéder
aux informations contenues dans les textes devient alors inévitable. Les
méthodes d'extraction d'information sont aujourd'hui largement utilisées
afin d'identifier des données médicales comme des noms de patients, de
médicaments ou de maladies : ""La patiente <nom>Anne Onyme</nom> a été
admise pour une <symptome>réaction allergique</symptome> à la
<traitement>pénicilline</traitement> le <date>21 janvier 2015</date>"".

Cette tâche se révèle toutefois particulièrement ardue lorsqu'il s'agit
de traiter des textes transcrits par des systèmes de reconnaissance de
la parole. La qualité variable des transcriptions automatiques et la
variation terminologique compliquent la reconnaissance des entités.


*Description du stage*
------------------------------
Nous posons l'exploitation de la dimension multimodale comme une piste
d'amélioration des systèmes d'extraction. Une hypothèse est que des
paramètres acoustiques comme le rythme ou l'intensité de la parole
peuvent constituer des indices permettant d'aider le repérage des
entités nommées. Le but du stage sera d'éprouver cette hypothèse.

Le travail du stagiaire s'appuiera principalement sur les données issues
de la tâche 1a du challenge CLEF eHealth 2015, soit 200 enregistrements
de dossiers de soins lus par une infirmière ainsi que leur transcription
annotée. NB : ces données sont en anglais, une bonne connaissance de la
langue est donc attendue.

Les tâches dévolues au stagiaire sont les suivantes :
  - rédiger un état de l'art sur la reconnaissance des entités nommées
    dans la parole
  - corriger les annotations préexistantes
  - développer une chaîne d'extraction d'entités nommées multimodale
    (qui s'appuiera notamment sur le logiciel Wapiti)
  - utiliser des outils TAL et de traitement du signal pour extraire des 
    traits multimodaux
  - évaluer et analyser l'influence des traits implémentés

*Profil recherché*
------------------------------
M2 Informatique ou linguistique avec parcours TAL

Compétences attendues :
  - Connaissances en programmation (langages de script)
  - Expérience avec des outils de TAL courants (étiqueteurs
    morphosyntaxiques, analyseurs syntaxiques, ...) et avec des outils
    de traitement du signal (Praat)
  - Expérience des méthodes d'apprentissage automatique
  - Intérêt pour le traitement de l'audio et du texte
  - Compétences en anglais
  - Familiarité avec l'environnement Linux
  - Créativité et autonomie

NB : Aucune expérience du domaine médical n'est attendue.


*Encadrement*
------------------------------
Eva D'hondt
François Morlane-Hondère
Sophie Rosset
Pierre Zweigenbaum


*Pour candidater*
------------------------------
Merci d'adresser votre candidature avec un CV, une lettre de motivation
ainsi que vos notes de l'année universitaire en cours et de l'année
dernière à Eva D'hondt (eva.dhondt@limsi.fr) et François Morlane-Hondère
(francois.morlane-hondere@limsi.fr)"
"318","2016-01-13","ELDA","Paris","Sujet: Développement d'un moteur de recherche robuste pour naviguer dans
des collections de documents

Niveau : L3 ou M1 / première ou deuxième année d'école d'ingénieur

Domaine : informatique

Période : à partir de mi-janvier 2016

Durée : 4-6 mois

*Travail à réaliser*

Au sein de l'équipe de développement informatique d'ELDA, sous la
tutelle d'un ingénieur spécialiste des technologies de la langue et du
développement d'applications Web, vous serez amené à participer aux
travaux suivants :

  * faire un état de l'art exhaustif sur les possibilités actuelles
    offertes par les moteurs de recherche les plus puissants, tels que
    Solr, Elastic, ou bien les facilités de recherche textuelle offertes
    par des SGBD (Système de Gestion des Bases de Données) tels que
    PostgreSQL.
  * participer à la spécification des besoins de recherche textuelle
    dans les actes de la conférence LREC ;
  * participer au choix de la solution technique la plus appropriée pour
    les actes de LREC ;
  * participer à la conception de la structure d'une base de données
    (schéma de données) pour modéliser le contenu des sites Web
    recensant les articles de la conférence LREC ;
  * extraire les informations pertinentes des sites recensant les
    articles de la conférence LREC et réaliser la mise en données de ces
    informations, utilisant le schéma de données mentionné ci-dessus;
  * implémenter un moteur de recherche exhaustive à travers tous les
    actes de la conférence LREC, compte tenu des contraintes dégagées
    lors des étapes antérieures ;

Vos participerez également aux réunions périodiques de l'équipe de
développements logiciels d'ELDA.


*Profil souhaité*

  * Bac + 3 ou 4 / Première ou deuxième année d'École d'ingénieur ;
  * Connaissances de base en algorithmique ;
  * Connaissances de base des architectures des applications Web ;
  * Connaissance pratique d'un système de gestion de bases de données
    (PostgreSQL de préférence) ;
  * Anglais technique ;
  * La connaissance d'un moteur de recherche (Solr, Elastic, Lucene)
    sera appréciée ;
  * La connaissance des langages JavaScript et / ou Python sera un plus.


*Candidature*

Ce stage, d'une durée de 3 mois et basé à Paris dans le 13e 
arrondissement (Les Gobelins), est à pourvoir en janvier 2016.

*Les candidatures (CV, lettre de motivation) doivent être adressées à 
Vladimir Popescu (vladimir@elda.org).*

Le stage fait l'objet d'une rémunération, variable en fonction du niveau
d'études du candidat.

-*-*-*-*-*-*-*-

Acteur majeur des technologies de la langue, ELDA (Agence pour la
distribution des ressources Linguistiques et l'Evaluation) est une PME
dont les activités s'articulent principalement autour de la distribution
et de la production de ressources linguistiques.

À ce titre, ELDA assure le fonctionnement opérationnel d'ELRA (European
Language Resource Association), association européenne à but
non-lucratif assurant la promotion des ressources linguistiques dans un
contexte européen.

Depuis 1998, ELRA organise une conférence internationale bisannuelle,
LREC (Language Resources and Evaluation Conference), qui réunit, à
chaque édition, des centaines de chercheurs de premier rang du monde
entier, qui y présentent des articles de recherche scientifique.

Afin de faciliter la navigation dans ce thésaurus d'articles
scientifiques, ELDA a mis au point un ensemble de sites Web recensant
ces articles, ainsi que des informations les concernant (auteurs,
titres, résumés des articles, etc.).

Dans ce contexte, ELDA souhaite consolider ces sites, et notamment
permettre aux utilisateurs d'effectuer des recherches robustes et
exhaustives à travers ses collections d'articles correspondant à toutes
les éditions de la conférence LREC.

www.elda.org"
"319","2016-01-13","MyScript","Nantes","Pionnier d'une technologie permettant la reconnaissance d'écriture 
manuscrite et la gestion de l'encre digitale, MyScript 
(http://myscript.com/) développe de nouvelles possibilités pour entrer 
et modifier vos données. Notre technologie permet un niveau de 
performance inégalé, une intégration sous toute plateforme ainsi qu'une 
reconnaissance multi-domaines (100 langues, 200 symboles mathématiques, 
100 notations musicales, 25 formes géométriques). MyScript intègre déjà 
cette haute technologie dans des équipements tels que des tablettes, 
smartphones, tableaux interactifs, système de commande du GPS, etc.


Stage - Moteur de reconnaissance d'écriture pour des langues peu dotées
H/F
http://myscript.com/careers/internship-nlp-low-resourced-languages-support/

Le développement de modèles de langues riches et robustes pour la
reconnaissance d'écriture nécessite de gros volumes de textes (plusieurs
dizaines de millions de mots).
Le nombre de langues dans lesquels de tels corpus sont disponibles étant
limité, MyScript souhaite expérimenter les méthodes alternatives de
modélisation pour les langues dites peu dotées.

Au sein de l'équipe Natural Language Processing, le stagiaire aura les
missions suivantes:

- travailler au traitement de corpus pour une liste définie de langues
  peu dotées ;
- déployer le moteur de reconnaissance sur ces langues et mettre en
  place des tests de qualité ;
- expérimenter diverses techniques de modélisation de langues (notamment
  au niveau caractères) pour améliorer les résultats.

Ce stage de 6 mois au niveau M2 est une bonne opportunité d'acquérir une
première expérience de R&D en entreprise.

Profil:
- Etudiant en M2, option TAL, école d'ingénieur ou assimilé
- Connaissance d'au moins un langage de programmation
- Des expériences antérieures en NLP ou statistiques seraient un plus
- Anglais courant

Stage de 6 mois basé à Nantes

Dans un contexte international, notre offre est la suivante: challenges
techniques, réalisations concrètes et convivialité.

Au sein de MyScript, vous travaillerez sur des technologies à la pointe
de la recherche et pourrez identifier les applications directes et
concrètes de votre travail.
Vous intégrerez une structure à taille humaine qui valorise et promeut
la créativité, les initiatives, le partage d'expérience et la
convivialité.

Contact: job@myscript.com"
"320","2016-01-18","Viseo R&D","Grenoble","Stage Master 2 de Recherche
Viseo R&D, à Grenoble (France)
http://www.viseo.com/fr/offre/recherche-et-innovation

SUJET : Normalisation de messages issus de la communication électronique
médiée

CONTEXTE
Au départ contraint par le nombre de caractères maximum utilisables pour
la rédaction d'un SMS et par la difficulté de maniement des claviers,
l'écriture SMS apparaît et se développe rapidement sur les supports de
communication du Web (réseaux sociaux, fora, blogs, etc.). Par exemple,
l'écriture SMS se caractérise par la présence de formes scripturales
très riches : squelettes consonantiques (""slt"" (salut)), apocopes
(""ordi"" (ordinateur)), substitutions phonétisées (""2m1"" (demain)),
binettes/emoji (""^^"", "":)"", :)) - la liste est longue.
Ce non-respect des règles de la langue implique une réelle difficulté
lorsqu'il s'agit d'analyser ces textes avec des outils de traitement
automatique de la langue qui sont généralement conçus pour traiter du
texte correctement écrit, ce qui implique un impact négatif sur la
qualité des résultats à l'issue du traitement. Pour pallier à cette
difficulté, on peut envisager soit d'adapter les outils d'analyse, soit
de normaliser le texte qui sera passé en entrée des outils
d'analyse. Nous choisissons cette deuxième approche dans le cadre de ce
stage.

OBJECTIF DU STAGE
L'objectif de ce stage est de développer un outil performant de
normalisation automatique de texte pour le français. Par exemple, «a2min
lami» devra être normalisé en «à demain l'ami».

Pour atteindre ce but, il sera demandé à l'étudiant de :
1) dresser une typologie des erreurs détectées dans les ressources
   fournies, pour le français (Tweets, Messages de forums, SMS), en
   s'appuyant sur les typologies déjà existantes.
2) proposer des méthodes automatiques de normalisation en fonction des
   types d'erreurs définis à la première étape, avec un intérêt
   particulier porté sur les types d'erreur les plus fréquents. On
   s'inspirera des méthodes déjà existantes (par exemple, fondées sur
   les principes de la traduction automatique, de la reconnaissance de
   la parole, la correction orthographique, ...).
3) évaluer les méthodes proposées en fonction des différents types de
   textes (Tweets, Messages de forums, SMS).

PREREQUIS
Ce sujet est destiné aux étudiants de Master 2 Informatique ou de
dernière année d'une école d'ingénieur en informatique, avec une
spécialité ingénierie linguistique ou terminologique.  Profil recherché :

- Traitement automatique des langues
- Compétences en programmation (Java souhaité)
- Expérience minimum de l'utilisation de ressources linguistiques
  appréciée
- Bonne maîtrise du français et anglais

INFORMATIONS COMPLEMENTAIRES
Unité d'accueil : Viseo R&D
http://www.viseo.com/fr/offre/recherche-et-innovation
Lieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble
Encadrant principal : Cédric Lopez
http://www.viseo.com/fr/recherche/cedric-lopez
Durée du stage : 6 mois
Stage rémunéré

Merci d'envoyer votre candidature à
cedric.lopez@viseo.com<mailto:cedric.lopez@viseo.com> constituée du CV,
de la lettre de motivation, des relevés de notes des 2 dernières années
(M1 et M2)

A PROPOS DE VISEO
Viseo est une entreprise française de services du numérique qui compte
1200 employés en France, Allemagne, Etats Unis, Singapour, Hong Kong et
Maroc. Son centre R&D est situé à Grenoble, à deux minutes à pieds de la
gare. De nombreux projets de recherche collaboratifs y sont menés, avec
un intérêt particulier pour l'analyse de données textuelles : projet
SMILK (LabCom ANR)
http://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER
(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)
http://www.synodos.fr<http://www.synodos.fr/> , SOMA (EUROSTARS)
http://www.viseo.com/fr/recherche/le-projet-soma, ...
Pour en savoir plus : www.viseo.com<http://www.viseo.com>,
http://www.viseo.com/fr/offre/recherche-et-innovation


Cédric LOPEZ

Le Pulsar 4 av du Doyen Louis Weil 38000 GRENOBLE
Tél.  +33 (0)9 72 31 82 46
Mob. +33 (0)6 72 64 25 77
cedric.lopez@viseo.com
Research Scientist
Research & Development
http://www.viseo.com/en/recherche/cedric-lopez

SMILK (LabCom ANR) : Joint Laboratory between INRIA-Wimmics and Viseo :
http://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk
Viseo is partner of the TIER Project (EU)
http://www.viseo.com/en/offre/tier-project
Viseo is partner of the SYNODOS Project (ANR) :
http://www.synodos.fr<http://www.synodos.fr/>"
"321","2016-01-18","STL","Lille ou Paris","Extraction d'informations pour enrichir les guides touristiques
http://natalia.grabar.perso.sfr.fr/stage2016t.html

De plus en plus de gens voyagent et sont consommateurs d'informations
touristiques. Cependant, les intérêts touristiques varient en fonction
des personnes et des régions. Ils peuvent par exemple concerner la
découverte de villes ou de paysages, la dégustation de nouveaux plats
culinaires, la visite des vestiges historiques, les pèlerinages, la
visite des lieux liés à des personnalités ou événements, des objets ou
événements endémiques, etc. Des informations associées sont aussi
appréciées (hôtels, parkings, campings, auberges, chemins de randonnées,
restaurants, marchés...)

Cela offre une large palette d'informations à proposer aux touristes
afin de les aider dans l'élaboration des voyages.

L'objectif de ce stage consiste à traiter les informations provenant de
différentes sources afin d'enrichir les guides existants. Plus
particulièrement, le cadre du stage est lié à la Via Francigena, qui est
un des itinéraires les plus fréquentés. De plus, il passe par plusieurs
pays Européens, dont la France et bénéficie d'une communauté de
randonneurs et touristes très active. Entre autre, l'Association Via
Francigena coordonne les efforts de plusieurs contributeurs.

Pour la réalisation du stage, des méthodes de Traitement Automatique de 
la Langue et de fouille de textes seront utilisées.

Plus spécifiquement, il s'agit des objectifs suivants:

- travailler avec des corpus de textes de différents types et provenant
  de différentes sources
- exploiter et améliorer les annotations des textes avec différents
  niveaux de spécificité
- exploiter, adapter ou développer des méthodes pour l'extraction
  d'informations
- faire le lien avec les guides existants
- évaluer les méthodes et résultats

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:

  - connaissances en TAL et en linguistique
  - manipulation et test des outils de TAL
  - habitude de Linux
  - capacité de travailler en équipe et individuellement
  - lecture et analyse de la littérature scientifique

L'encadrement sera assuré par des chercheurs de différentes disciplines
(TAL, STIC, humanités numériques).

Le stage est rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

     Niveau: Master 2
     Durée: 6 mois
     Lieu: Lille, Paris (éventuellement)

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à
natalia.grabar@univ-lille3.fr"
"322","2016-01-18","STL","Lille","Vers la simplification de textes techniques

Le domaine médical a une terminologie spécifique, avec des termes comme
par exemple /sanguin, abdominoplastie, hépatique, dermabrasion ou
hépatoduodénostomie/, utilisée communément par le personnel
médical. Pour cette raison entre autre, la compréhension d'information
de santé est souvent compliquée pour les non spécialistes et pour les
patients [1-4]. La disponibilité des informations de santé en ligne peut
aussi modifier le modèle de communication entre ces catégories de
personnes [5-6].

L'objectif de ce stage consiste à proposer des méthodes pour simplifier
les documents spécialisés et pour les ""traduire"" dans une langue plus
facilement compréhensible par les non spécialistes, et de tester ces
méthodes. Le matériel traité est de différents types :

- textes spécialisés qui proviennent des publications scientifique,
  documents cliniques ou sites web spécialisés,
- ressources linguistiques qui alignent les termes techniques avec des
  expressions moins techniques (infarctus du myocarde/crise cardiaque)
  [7],
- éventuellement, des documents parallèles ou comparables contenant les
  textes spécialisés et leurs équivalents moins spécialisés.

En utilisant des méthodes de Traitement Automatique de la Langue, il
s'agit plus spécifiquement des objectifs suivants :

- travailler avec les documents produits par les médecins,
- prendre en main les ressources linguistiques alignant les termes
  avec différents niveaux de spécificité,
- si les corpus parallèles/comparables sont disponibles, effectuer une
  analyse contrastive de ces documents,
- proposer des règles pour déclencher les modifications/substitutions
  lexicales,
- exploiter le lexique avec les correspondances entre les termes savants
  et les expressions des patients pour effectuer les
  modifications/substitutions lexicales.

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:
- connaissances en TAL et en linguistique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique

Le stage est rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Niveau: Master 2
Durée: 6 mois
Lieu: Lille, Paris (éventuellement)


Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à
natalia.grabar@univ-lille3.fr


Bibliographie:
1. Patel V., Branch T., Arocha J., Errors in interpreting quantities as
   procedures : The case of pharmaceutical labels, International journal
   of medical informatics, vol. 65(3), p. 193-211, 2002
2. Williams M., Parker R., Baker D., Parikh N., Pitkin K., Coates W.,
   Nurss J., Inadequate functional health literacy among patients at two
   public hospitals, JAMA, vol. 274(21), p. 1677-82, 1995
3. Rudd R., Moeykens B., Colton T., Annual Review of Adult Learning and
   Literacy, ch 5, 1999
4. Berland G., Elliott M., Morales L., Algazy J., Kravitz R., Broder M.,
   Kanouse D., Munoz J., Puyol J., Lara M., Watkins K., Yang H., McGlynn
   E., Health information on the Internet. Accessibility, quality, and
   readability in English ans Spanish, JAMA, vol. 285(20), p. 2612-2621,
   2001
5. Tran T., Chekroud H., Thiery P., Julienne A., Internet et soins : un
   tiers invisible dans la relation médecine/patient ?, Ethica Clinica,
   vol. 53, p. 34-43, 2009
6. Jucks R., Bromme R., Choice of words in doctor-patient communication:
   an analysis of health-related internet sites, Health Commun,
   vol. 21(3), p. 267-77, 2007
7. Grabar N., Hamon T. Extraction automatique de paraphrases grand
   public pour les termes médicaux. TALN 2015: Traitement Automatique
   des Langues Naturelles. 14 p."
"323","2016-01-20","CEA LIST","Palaiseau","SUJET: Utiliser des contraintes discursives pour améliorer le résumé
automatique

CONTEXTE:

Le stage se focalise sur les systèmes de résumé automatique par
extraction, c'est-à-dire les systèmes réalisant des résumés en extrayant
des documents sources les unités, le plus souvent des phrases, les plus
représentatives de leur contenu. Les approches les plus récentes dans ce
domaine posent ce problème comme un problème d'optimisation consistant à
trouver le compromis le plus intéressant entre le respect d'une
contrainte de taille maximale du résumé à produire et la maximisation du
contenu informationnel de ce dernier, représenté de façon non structurée
par un ensemble de mots ou de séquences de mots [Gillick and Favre
(2009)].

OBJECTIFS:

La maximisation du contenu informationnel n'est pas le seul critère
intéressant à considérer pour produire un résumé. Elle intègre de façon
indirecte une prise en compte de la redondance informationnelle mais
n'exploite pas la hiérarchisation des informations mise en avant par les
documents. Savoir qu'une phrase donne un exemple ou une justification en
relation avec le contenu d'une autre phrase est dans cette optique un
élément intéressant à exploiter pour sélectionner l'information à faire
apparaître dans un résumé. Dans le cas de la phrase ""Most of our
children are living in California now ; Judy, for instance, lives in
Berkeley"" [Foster (1984)], la détection de la relation d'exemplification
unissant les deux propositions peut ainsi être mise à profit pour
laisser de côté la seconde proposition.

Sur un plan général, cette hiérarchisation des informations peut être
caractérisée au travers d'une analyse discursive des documents. De ce
point de vue, la Rhetorical Structure Theory (RST) [Mann and Thompson
(1988)] est l'une des théories discursives parmi les plus connues et les
mieux outillées. En outre, des travaux de recherche existants ont déjà
démontré la capacité de la RST à sélectionner les segments de textes les
plus pertinents dans un contexte de résumé automatique [Marcu (1998,
1997)].

Le stage s'inscrira donc dans ce cadre et se donnera les trois objectifs
principaux suivants :

- en s'appuyant notamment sur [Marcu (1998, 1997)], faire une étude des
  relations rhétoriques intéressantes du point de vue du résumé
  automatique ;

- analyser le repérage de ces relations pour les outils existants [Joty
  et al. (2013); Feng and Hirst (2014)] et proposer le cas échéant des
  stratégies permettant de pallier de façon ciblée certaines de leurs
  insuffisances ;

- proposer une méthode de prise en compte des relations rhétoriques
  ciblées dans un cadre d'optimisation de contraintes fondée sur la
  programmation linéaire en nombres entiers (ILP) dédié au résumé
  automatique, avec une extension possible vers les techniques de
  décomposition (dual decomposition) [Rush and Collins (2012)].

Les travaux s'effectueront prioritairement dans un cadre de résumé
mono-document pour des documents en anglais de type articles de
journaux, avec une extension possible au multi-document. Ils seront
évalués en reprenant les protocoles et les données des campagnes
d'évaluation DUC (Document Understanding Conference) et TAC
Summarization (Text Analysis Conference).

- Domaine de spécialité requis: Informatique
- Spécialité complémentaire: Linguistique
- Langages de programmation: Python, bash, éventuellement Perl ; la
  connaissance de C++ est un plus
- Niveau souhaité: Master 2
- Durée: 6 mois
- Employeur: Laboratoire LVIC du CEA/LIST
- Stage rémunéré : entre 700 et 1300 euros selon la formation + prise en
  charge à 75% des transports en IdF.
- Lieu du stage: dans les locaux du LVIC à Nano Innov à Palaiseau.

Les candidatures sont à envoyer à Maâli Mnasri à l'adresse :
maali.mnasri@cea.fr
Stage co-encadré par Gaël de Chalendar et Olivier Ferret.

RÉFÉRENCES:

Dan Gillick and Benoit Favre. A Scalable Global Model for
Summarization. In Proceedings of the Workshop on Integer Linear
Programming for Natural Langauge Processing, ILP '09, pages 10- 18,
Boulder, Colorado, 2009. ISBN 978-1-932432-35-0. URL
http://dl.acm.org/citation.cfm?id=1611638.1611640.

William C. Mann and Sandra A. Thompson. Rhetorical Structure Theory :
Toward a functional theory of text organization. Text, 8(3) :243-281,
1988.

Susan H. Foster. Teun A. van Dijk, Studies in the Pragmatics of
Discourse. the hague : Mouton, 1981. pp. xii + 331. Language in Society,
13 :369-375, 9 1984.  ISSN 1469-8013. doi : 10.1017/S0047404500010563.

Daniel Marcu. Improving summarization through rhetorical parsing
tuning. In Proceedings of The Sixth Workshop on Very Large Corpora,
pages 206-215, Montreal, Canada, August 1998.

Daniel Marcu. The rhetorical parsing, summarization, and generation of
natural language texts. Technical Report CSRG-371, Computer Systems
Research Group, University of Toronto, 1997.

Shafiq Joty, Giuseppe Carenini, Raymond Ng, and Yashar Mehdad. Combining
Intra- and Multi-sentential Rhetorical Parsing for Document-level
Discourse Analysis.  In Proceedings of ACL, 2013.

Vanessa Wei Feng and Graeme Hirst. A linear-time bottom-up discourse
parser with constraints and post-editing. In Proceedings of the 52nd
Annual Meeting of the Association for Computational Linguistics, pages
511-521, June 2014.  URL http://www.aclweb.org/anthology/P14-1048."
"324","2016-01-25","LIA","Avignon","======================================================
UAPV - Laboratoire Informatique d'Avignon
Sujet : Extraction et exploitation de l'information des CV
Stagiaire :    Étudiant de M2
Co-encadrement :
   Juan-Manuel Torres-Moreno (juan-manuel.torres@univ-avignon.fr)
   Marc El-Bèze (marc.elbeze@univ-avignon.fr)
   Luis Adrián Cabrera Diego (luis-adrian.cabrera-diego@univ-avignon.fr)

Les cabinets de recrutement doivent aujourd'hui traiter des volumes de
données de plus en plus importants (candidatures électroniques, variété
des formats, des sources des candidatures, etc). Par ailleurs, le
rapport entre toutes les candidatures et les candidats non qualifies a
augmenté. Ceci rend évident l'intérêt majeur d'un système automatique
offrant une aide efficace pour sélectionner, dans des masses de
candidatures celles qui méritent d'être retenues en vue d'un examen
approfondi. Grâce à une convention CIFRE obtenue en 2005 et une autre en
2012, le LIA s'est déjà fortement impliqué dans des travaux de
recherches visant à proposer des algorithmes permettant de mettre au
point quelques-uns des composants d'un tel système [1-5]. Dans la
prolongation de ces travaux, nous projetons de nous intéresser aux
problèmes d'extraction et de valorisation de l'information provenant des
curriculums vitæ (CV).

La société Adoc Talent Management et le Laboratoire d'Informatique
d'Avignon (LIA), partenaires pour l'encadrement de ce stage de M2,
proposent de traiter les questions fondamentales suivantes :

     * Extraction automatique des termes (mono ou multi-mots) qui
       contribuent le plus au processus de recrutement ;

     * Impact des priorités données à certains de ces termes sur le
       classement des candidatures ;

     * Étude et mise en place des algorithmes pour la génération
       automatisée de portrait-robots (ainsi que des anti
       portrait-robots).

Pour la réalisation de ce stage de M2, l'étudiant devra, a priori,
utiliser les méthodes liées à l'apprentissage automatique, la fouille de
texte (représentation des textes, classifications, distances, etc.), le
résumé automatique. Parmi les outils dont le développement est attendu,
se trouve un extracteur de termes à partir des CV et des offres
d'emploi.  La liste des termes tels qu'ils ont été extraits et ordonnés
automatiquement devra pouvoir être modifiée manuellement ou
automatiquement de telle sorte que l'on se donne la possibilité
d'étudier l'impact de cette nouvelle sélection dans le processus de
relevance feedback [1,4,6].
Les outils pourront être implémentés dans différents langages, notamment
Python, Perl et R. La partie recherche de ce stage est susceptible de
donner lieu à des publications dans un congrès international.

Ce stage se déroulera au LIA, à Avignon. Sera envisagée la possibilité
de continuer en thèse ces travaux dans le cadre d'une convention CIFRE,
en fonction des résultats obtenus.

Dates : entre début février et fin juillet 2016
Durée : entre 4 et 5 mois
Gratification mensuelle : 554 euros

Contact : Juan-Manuel Torres-Moreno (juan-manuel.torres@univ-avignon.fr)


Références
[1] R. Kessler, N. Béchet, M. Roche, J.-M. Torres-Moreno, and M.
    El-Bèze, 2012. A hybrid approach to managing job offers and
    candidates.  Information Processing & Management 48(6), 1124-1135.
[2] R. Kessler, N. Béchet, J.-M. Torres-Moreno, M. Roche, and M.
    El-Bèze, 2009. Job offer management: how improve the ranking of
    candidates. In Foundations of Intelligent Systems, 431-441. Springer
    Berlin Heidelberg.
[3] R. Kessler, J. M. Torres-Moreno, and M. El-Bèze, 2008a. E-gen:
    Profilage automatique de candidatures. TALN 2008, Avignon, France,
    370-379.
[4] L. A. Cabrera-Diego, B. Durette, M. Lafon, J.-M. Torres-Moreno, M.
    El-Bèze, 2015. How Can We Measure the Similarity Between Résumés of
    Selected Candidates for a Job? Proceedings of the 11th International
    Conference on Data Mining (DMIN'15), Las Vegas, 99-106.
[5] L. A. Cabrera-Diego, J.-M. Torres-Moreno, M. El-Bèze, 2013. SegCV :
    traitement efficace de CV avec analyse et correction d'erreurs. TALN
    2013, Les Sables d'Olonne, France, 707-714
[6] L. A. Cabrera-Diego, Automatic Methods for Assisting RH Recruitment,
    Thèse UAPV 2015."
"325","2016-01-28","LIMSI & INRA","Orsay ou Jouy","Normalisation : projection de termes médicaux vers un référentiel

* Contexte *
------------------------------

La quantité de documents textuels produits et utilisés dans les
organisations et sur le web a explosé ces dernières décennies. Ces
documents recèlent une grande quantité d'informations et de
connaissances dont l'exploitation et le partage nécessite la
représentation sous une forme normalisée, appelée indexation sémantique
ou conceptuelle, selon un référentiel partagé tel qu'un thésaurus ou une
ontologie. Ces référentiels recensent et structurent les concepts d'un
domaine, qui y sont caractérisés par un identifiant, et sont associés à
un ensemble de mentions (expressions linguistiques) qui y font référence
dans un texte. La représentation normalisée sous forme d'identifiants de
concepts rend possibles les opérations d'agrégation (quelle est la
proportion des décès par maladie cardiovasculaire en France) et rend
plus pertinentes les opérations de recherche (quels articles dans
MEDLINE portent sur des traitements antihypertenseurs) et plus
généralement de fouille de données (quelles caractéristiques
phénotypiques sont associées à une différence génétique donnée [1] -
études PheWAS).

La normalisation constitue un verrou fondamental dans l'analyse et la
compréhension de textes, car elle vise à passer d'une expression en
langue, non formelle, avec sa plasticité (source d'ambiguïté) et ses
multiples possibilités d'expression d'une même information (paraphrase),
à une représentation normalisée et non ambiguë permettant des
traitements automatisés. De plus, la normalisation est rendue plus
difficile si le référentiel visé (thésaurus ou ontologie) possède un
très grand nombre de classes (des dizaines de milliers dans le thésaurus
MeSH utilisé pour indexer les articles scientifiques de la base MEDLINE
ou dans la Classification internationale des maladies CIM 10). Malgré
cette taille considérable, les référentiels spécialisés ne couvrent pas
des concepts qui sont hors du domaine de spécialité concerné, et il faut
alors en rendre compte.

La normalisation de concepts dans des textes biomédicaux repose
majoritairement sur deux grandes classes de méthodes : (a) la détection
approchée d'entrées de grands lexiques et terminologies en employant des
connaissances linguistiques ou un modèle de type recherche
d'information, et (b) l'apprentissage supervisé à partir de corpus
annotés, la combinaison des deux étant fréquente. Ce problème a été bien
étudié dans le domaine biomédical sur des textes cliniques ou de la
littérature en anglais, notamment grâce à la disponibilité de ressources
annotées permettant de développer et d'évaluer diverses méthodes
[2,3]. Pour le français, le LIMSI a contribué au développement d'un
corpus annoté, utilisé dans le cadre de la campagne CLEF eHealth [4].

Dans ce contexte, nous prévoyons de confier au stagiaire de M2 une étude
exploratoire utilisant cette nouvelle ressource pour faire une
évaluation systématique des méthodes de normalisation connues. De plus,
la généralisation des méthodes pour la prise en charge de plusieurs
langues pourra également être étudiée.

* Description du stage *
------------------------------

L'objectif du stage est une analyse systématique des méthodes de
normalisation de concept dans le domaine biomédical. Il s'agit
d'analyser un terme dans son contexte phrastique afin de le mettre en
correspondance avec un concept normalisé présent dans un référentiel du
domaine biomédical - si un tel concept existe.

Ce stage abordera l'analyse de termes du domaine biomédical sous l'angle
de la désambiguïsation. Il s'agira d'une analyse systématique et
comparative de méthodes à base de connaissances expertes et de méthodes
d'apprentissage afin de faire un état des lieux et de définir des lignes
de recherche futures. Le résultat principal de ce stage sera un bilan
exploratoire permettant de défricher le terrain et de décider des
méthodes à développer pour la normalisation. Les méthodes suivantes
seront notamment évaluées :1/ projection d'un dictionnaire monolingue
français 2/ prise en compte de la variation terminologique dans le
dictionnaire et le texte 3/ utilisation de ressources multilingues et
d'outils de traduction automatique 4/ adaptation de la méthode
statistique DNorm [5] et de la méthode d'analyse terminologique ToMap
[6] pour le français 5/ utilisation des représentations continues
apprises par des méthodes neuronales. Ce travail permettra de contribuer
à l'état de l'art en normalisation de concepts du domaine biomédical.

Durée : 5 mois
Lieu : LIMSI-CNRS, Orsay, France ou INRA, Jouy, France
Gratification mensuelle : 554¤ par mois plus participation aux frais de
transport en commun


*Profil recherché*
------------------------------
M2 Informatique ou linguistique avec parcours TAL

Compétences attendues :
  - Connaissances en programmation (langages de script)
  - Expérience avec des outils de TAL courants (étiqueteurs
    morphosyntaxiques, analyseurs syntaxiques, ...)
  - Expérience de l'utilisation de méthodes d'apprentissage automatique
  - Familiarité avec l'environnement Linux
  - Créativité et autonomie

Aucune expérience du domaine médical n'est attendue, mais une
familiarité avec des ressources terminologiques sera un plus.

*Encadrement*
------------------------------
Louise Deléger
Claire Nédellec
Aurélie Névéol
Pierre Zweigenbaum

*Pour candidater*
------------------------------
Merci d'adresser votre candidature avec un CV, une lettre de motivation
ainsi que vos notes de l'année universitaire en cours et de l'année
dernière à Aurélie Névéol (aurelie.neveol@limsi.fr) et Louise Deléger
(louise.deléger@jouy.inra.fr)


Références
------------------------------
[1] Neuraz A, Chouchana L, Malamut G, Le Beller C, Roche D, Beaune P,
    Degoulet P, Burgun A, Loriot MA, Avillach P. Phenome-wide
    association studies on a quantitative trait: application to TPMT
    enzyme activity and thiopurine therapy in pharmacogenomics. PloS
    Comput Biol.  2013;9(12):e1003405.
[2] Pradhan, S., Elhadad, N., South, B.R., Martinez, D., Christensen,
    L., Vogel, A., Suominen, H., Chapman, W.W., Savova, G. Evaluating
    the state of the art in disorder recognition and normalization of
    the clinical narrative. J. Am. Med. Inform. Assoc. 2014;22:143-154.
[3] Leaman R, Khare R, Lu Z. Challenges in clinical natural language
    processing for automated disorder normalization. J Biomed
    Inform. 2015 Jul 14. pii:S1532-0464(15)00150-1.
[4] Névéol A, Grouin C, Tannier X, Hamon T, Kelly L, Goeuriot L,
    Zweigenbaum P. CLEF eHealth Evaluation Lab 2015 Task 1b: clinical
    named entity recognition. CLEF 2015, Online Working Notes, CEUR-WS
    1391. 2015.
[5] Leaman R, Islamaj Dogan R, Lu Z. DNorm: disease name normalization
    with pairwise learning to rank. Bioinformatics. 2013 Nov
    15;29(22):2909-17.
[6] Golik W, Warnier P, Nédellec C. Corpus-based extension of
    termino-ontology by linguistic analysis: a use case in biomedical
    event extraction. In 9th International Conference on Terminology and
    Artificial Intelligence 2011 Nov 10 (p. 37)"
"326","2016-01-28","IGN","Saint-Mandé","Appariement spatial qualitatif pour la résolution d'entités spatiales nommées

Mots-clés : Résolution d'entités spatiales nommées, linked data,
interconnexion de données, relations spatiales, graphe RDF.

Contexte:

De plus en plus de sources de données sont publiées sur le Web des
données selon les recommandations du W3C comme DBpedia, Pleiades ou
des jeux de données des institutions comme la BNF, l'INSEE ou l'IGN
(Atemezing et al., 2014).  

Ainsi publiées selon des standards facilitant leur réutilisation, ces
sources peuvent être mises à profit notamment pour des applications de
Traitement Automatique du Langage Naturel comme la résolution
d'entités nommées. En effet, la résolution d'entités nommées consiste
à associer à chaque mention d'entité nommée, préalablement identifiée
dans un texte, l'identifiant de l'entité du monde réel à laquelle elle
fait référence, décrite par une ressource dans un jeu de données du
Web. Dans le cas de textes spécialisés, l'absence de textes
préalablement annotés conduit à adopter des approches non supervisées
afin d'identifier les ressources de référence adéquates. C'est le cas
notamment de l'approche implémentée par l'application REDEN (Brando et
al., 2015). Dans le cadre de ce stage, on s'intéresse plus
particulièrement aux entités spatiales nommées qui peuvent être très
nombreuses dans certains textes spécialisés comme des guides de
voyage, de randonnées, des descriptions de paysage, des textes
historiques, etc.

Sujet :

L'objectif du stage est de proposer une extension de REDEN dédiée à la
résolution d'entités spatiales nommées identifiées dans des textes
spécialisés et préalablement tagués. Il s'agira de s'appuyer sur les
approches de résolutions d'entités spatiales nommées de la littérature
afin de proposer et d'implémenter des solutions pour:

- constituer un dictionnaire d'entités spatiales candidates à partir
de ressources externes du Web des données,

- mettre en correspondance les entités spatiales nommées identifiées à
partir des textes avec ces entités candidates,

- classer les entités candidates à l'aide d'une approche d'appariement
de graphes de relations entre entités spatiales (à définir).

Selon l'avancement des travaux on pourra envisager d'étendre le sujet à la
désambiguisation des relations spatiales identifiées dans les textes.

Compétences particulières et formation requises :

Informatique (programmation Java), données géographiques, linked data.
Master 2 ou troisième année d'école d'ingénieur en informatique ou en
géomatique avec une forte composante informatique.

Durée de stage : 5 mois

Période de stage: printemps/été 2016

Encadrement de stage : Carmen Brando (Valilab), Nathalie Abadie
(COGIT)

Lieu de stage : Service de la recherche de l'Institut National de
l'Information Géographique et Forestière (IGN), à Saint-Mandé (métro
1, station Saint Mandé).  Le COGIT est un des quatre laboratoires du
service de la recherche. Il est en charge des recherches liées à la
gestion, la diffusion, la représentation et l'utilisation de données
géographiques sous forme de référentiels vectorisés et à grande
échelle.  Le Valilab est un service de la Direction de la Recherche et
de l'Enseignement de l'IGN destiné à favoriser la collaboration entre
utilisateurs d'informations géographiques et les équipes de recherche
et d'enseignement de l'IGN.

Indemnités de stage: Stage gratifié.

Modalités de candidature : Envoyer par email et au format PDF en un
seul fichier :

- CV
- Lettre de motivation ciblée sur le sujet
- Relevés de notes des deux dernières années d'études
- Liste des enseignements suivis et validés au cours des deux
dernières années d'études

Contacts: carmen.brando[at]ign.fr, nathalie-f.abadie[at]ign.fr

Bibliographie :

Atemezing, G.A., N. Abadie, R. Troncy and B. Bucher (2014) Publishing
Reference Geodata on the Web: Opportunities and Challenges for IGN
France. , Terra Cognita 2014, 6th International Workshop on the
Foundations, Technologies and Applications of the Geospatial Web. In
Conjunction with the 13th International Semantic Web Conference,
http://event.cwi.nl/terracognita2014/terra2014_1.pdf

Brando, C., Frontini, F., Ganascia, J.G. (2015): Linked Data for
toponym linking in French Literary texts, in Proceedings of the 9th
Workshop on Geographic Information Retrieval, ACM, New York, NY, USA

Brando, C., Frontini, F., Ganascia, J.G. (2015): Disambiguation of
named entities in cultural heritage texts using linked data sets. In:
Proceedings of the First International Workshop on Semantic Web for
Cultural Heritage in Conjunction with 19th East-European Conference on
Advances in Databases and Information Systems, New Trends in Databases
and Information Systems, Springer, 539, Poitiers, France,
http://link.springer.com/chapter/10.1007%2F978-3-319-23201-0_51"
"327","2016-01-28","TEMIS / Expert System","Paris","Appel à candidature : Stage de lexicographie (Enrichissement de réseau
sémantique)

Sujet : Evaluation, amélioration de la qualité et enrichissement d'un
réseau sémantique pour la langue française.

Employeur : TEMIS  / EXPERT SYSTEM
Contrat : Stage M1 ou M2 de 3 à 6 mois

Lieu de Travail : TEMIS / EXPERT SYSTEM France (Paris)
TOUR MATTEI - 207 rue de Bercy
75012 Paris

Rémunération : Oui, à discuter

Date de début : dès que possible suivant les échéances universitaires

DESCRIPTION


Le réseau sémantique Sensigrafo est au coeur de la technologie sémantique
multilingue et brevetée Cogito (http://www.expertsystem.com/cogito/)
d'Expert System.

Sensigrafo est consitutée d'une ontologie qui contient des millions de
concepts et de relations. Ces capacités conjointes offrent des
fonctionnalités efficaces d'analyse linguistique et de désambiguïsation
automatique qui sont à la base de moteurs de classification automatique
et d'extraction d'entités, de relations et de métadonnées.

Expert System souhaite améliorer fortement la qualité de son réseau
sémantique en langue française pour l'amener au niveau de ses versions
anglaises, italiennes et espagnoles.

Pour cela, sous la supervision de notre équipe de linguistes, vous serez
amenés à suivre une procédure d'évaluation de la qualité sur divers
corpus généraux ou thématiques, qui permettront d'identifier une
typologie des anomalies les plus fréquentes et d'appliquer des
stratégies d'amélioration diverses (enrichissement lexical, pondération
de sens en fonction de domaines, regroupement/séparation de sens, etc...)

Ce stage demande une parfaite connaissance de la langue française, de sa
grammaire et de sa syntaxe. Une bonne connaissance des théories et des
outils de traitement automatique des langues naturelles est un plus.

Il peut convenir à des élèves de type Master en lexicographie ou en
traitement des langues naturelles.

Le stage est prévu pour une durée de 3 mois mais peut s'adapter aux
contraintes de l'étudiant.

Le stage se déroule dans les locaux d'Expert System à Paris.

CANDIDATURE

Les candidats sont invités à prendre contact par mail à l'adresse :
christian.lautier@temis.com"
"328","2016-02-03","Syllabs","Paris","---------------------------
Offre de stage TAL M2 : Génération automatique de textes en français
---------------------------

Syllabs est spécialisée en analyse sémantique et en génération
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse de
données textuelles du Web : identification des pages pertinentes,
extraction et catégorisation des informations clés. La génération est
proposée au travers de sa solution Data2Content (data2content.fr) qui
permet, à partir d'une base de données structurées, de générer
automatiquement des textes de qualité humaine.

C'est dans le cadre de Data2Content que nous recherchons un(e)
ingénieur(e) linguiste pour un stage dans le domaine de la création
automatique de textes en français (langue maternelle).
L'objet principal du stage est de travailler sur le paramétrage de notre
outil de génération (écriture de règles). Les domaines d'application
peuvent par exemple être le e-commerce (descriptifs de produits), le
tourisme (par exemple, descriptif d'un hôtel) ou les médias (brève sur
les résultats des élections, etc.).

--------------
Description du poste
---------------
Les tâches principales concernent:
- Génération automatique de textes : paramétrage de l'outil de
  génération en fonction du projet, participation aux tests et à
  l'amélioration de l'outil.
- Ecriture de scripts pour la manipulation des bases de données en
  entrée du moteur de génération.


---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique ou similaire
- Excellentes qualités rédactionnelles, goût pour l'écriture
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail en
  équipe
- Programmation en Python
- Compétences en rédaction web seraient un plus

-----------------
Conditions
-----------------
Stage conventionné 6 mois rémunéré en fonction du niveau d'étude +
tickets resto + remboursement à moitié du pass Navigo (transport)

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage génération français ».
Lieu : Syllabs, 82 rue du Faubourg Saint-Martin, 75010 Paris
Contrat : stage. Début : mars-avril 2016."
"329","2016-02-03","Airbus","Toulouse","Internship / Voice to Text, Text to Speech, Voice recognition (m/f)

Airbus Toulouse

Airbus Group is a global leader in aeronautics, space and related
services. In 2014, the Group - comprising Airbus, Airbus Defence and
Space and Airbus Helicopters - generated revenues of ¤ 60.7 billion
and employed a workforce of around 138,600.

Description of the job

Airbus (Toulouse) is looking for an intern for a 6-month internship.

This internship will start on 4th April 2016 (subject to some
flexibility).

Tasks & accountabilities

Your main tasks will include:

- Performing a state of the art of the different industries which
  develop Voice to Text, Text to Speech and Speech Recognition
  software,

- Investigating the use and reliability of existing Voice to Text,
  Text to Speech and Speech Recognition software to help pilots in
  operation (considering also, for example, the use of technical
  terms, the ambient noise, the use of abbreviations/acronyms),

- Defining interesting operational use-cases in which the use of such
  software would be interesting,

- Performing operational tests on a platform to prove the relevance of
  using such software for pilots in operation.

Required skills

You are in the 2nd year of a master's degree or in the 5th year of
university, specialising in Phonetics or phonology.

You ideally have initial experience in this field and you have:

    Knowledge of Natural Language processing,
    Knowledge of Phonetics and phonology.

You are a good team player and have excellent interpersonal skills.

English: intermediate level,
French: intermediate level.


Apply online:

http://www.airbusgroup.com/int/en/people-careers/jobs-and-applications/search-for-vacancies~jobid=001A4B0A914A1ED59FC91E2B50CA460A~.html"
"330","2016-02-03","STL","Lille","Extraction d'informations pour construire une base de connaissances sur
le patrimoine industriel textile à partir de sources de données
hétérogènes


Riche d'une histoire de plus de dix siècles, les différentes régions du
territoire français sont jalonnées de prestigieux monuments, de
bâtiments industriels et d'espaces naturels témoins de leurs influences
historiques successives. Pour sauvegarder et valoriser ce patrimoine,
différentes métropoles et notamment celle de Lille, particulièrement
touchée par les vicissitudes de l'Histoire dans le domaine de
l'industrie textile au XXe siècle, développe une politique de
restauration ambitieuse. Nous assistons ainsi à un accroissement
prodigieux des contenus numériques décrivant ce patrimoine et de la
puissance des techniques de production et de diffusion, et ceci à
différentes échelles du territoire et notamment à l'échelle des
régions. Il s'agit d'un processus dont l'importance et la rapidité sont
probablement sans précédent dans l'histoire de l'humanité. En effet, ce
que promet la société du numérique et qui se dessine sous nos yeux,
c'est une toute autre façon de nous représenter et de concevoir
l'espace, le temps, et plus généralement l'ensemble des connaissances
relatives au territoire. Dans ce sens, différents territoires telles que
la Région Nord Pas de Calais (NPDC) ont engagé une démarche de réflexion
sur le numérique et son impact sur les usages dans des domaines variés :
l'éducation, le transport, les infrastructures, le tourisme, la culture,
les villes intelligentes.

Le projet interdisciplinaire TECTONIQ s'inscrit pleinement dans cette
démarche en proposant de définir une méthodologie semi-automatique
reproductible permettant la diffusion, le partage et la valorisation des
connaissances patrimoniales présentes dans les nombreux documents
numériques hétérogènes mis à disposition dans les bases de données et/ou
sur le Web par les acteurs locaux (centres documentaires tels que les
musées et médiathèques, collectivités territoriales, la presse, et les
citoyens eux-mêmes notamment par l'intermédiaire des blogs). Ce
mouvement, au coeur du domaine des Humanités Numériques et fédérant des
chercheurs en Sciences de l'Information et de la Communication (SIC), en
Linguistique, en Histoire ainsi qu'en Informatique et des experts des
collectivités territoriales, est l'occasion d'échanger sur la gestion et
l'appropriation des documents numériques pour répondre à une demande
d'accès rapide et simplifié à des contenus volumineux et
hétérogènes. Les objectifs du projet sont tout d'abord (1) de construire
une base de connaissances pour valoriser le patrimoine industriel
textile (matériel et immatériel) disponible à l'échelle des régions tout
d'abord, puis à l'échelle nationale ensuite, et (2) d'analyser finement
les usages des données existantes par les différents acteurs (citoyens,
entreprises, scientifiques, collectivités, etc.) afin de mettre en place
un moteur de recherche d'information adapté. Le territoire
d'expérimentation est composé pour 2016 des régions Nord Pas de Calais
(NPDC) et Picardie, dans lesquelles sont localisés de nombreux acteurs
importants du domaine.

L'objectif de ce stage consiste à répondre au premier objectif du projet
visant à traiter les informations provenant de différentes sources afin
de construire une base de connaissances relative au domaine
d'étude. Plus particulièrement, le cadre du stage est lié au patrimoine
industriel textile dans la région Nord Pas de Calais, qui est une des
régions les plus dynamiques dans le domaine. De plus, de nombreux
acteurs régionaux (bibliothèques, musées, etc.) participant au projet
mettent à disposition leurs compétences pour aider à la valorisation du
travail d'annotation réalisé sur les corpus mis à disposition. 

Pour la réalisation du stage, des méthodes de Traitement Automatique de
la Langue, de fouille de textes et de construction d'un vocabulaire
contrôlé de type ontologie seront utilisées. Plus spécifiquement, il
s'agit des objectifs suivants:

- travailler avec des corpus de textes de différents types et provenant
  de différentes sources ;

- exploiter et améliorer les annotations des textes avec différents
  niveaux de spécificité ;

- exploiter, adapter ou développer des méthodes pour l'extraction
  d'information. Les informations à extraire ici sont les thématiques
  propres au domaine du patrimoine industriel textile. Des lexiques,
  définis dans le cadre du projet, pourront être utilisés ;

- Structurer les thématiques extraites dans une ontologie de domaine,
  offrant une première représentation du domaine sur la base des
  documents traités ;

- évaluer les méthodes et résultats

Le stagiaire sera amené à utiliser des outils TAL et fouille de textes
existants et à développer ses propres programmes pour mieux analyser les
données. La base de connaissances sera formalisée selon le formalisme
OWL CIDOC-CRM, défini pour structurer les connaissances liées au
patrimoine. Il sera force de proposition tout au long du stage et
participera aux différentes réunions plénières du projet.

Prérequis:
- connaissances en TAL, en fouille de textes et en structuration des
  connaissances (thesaurus, ontologie OWL)
- manipulation et test des outils de TAL & fouille de textes (exemple
  GATE, Weka...)
- des connaissances du langage ontologique OWL, et plus précisément du
  formalisme CIDOC-CRM seront appréciés.
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique

Le stage est rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Niveau: Master 2
Durée: 6 mois
Lieu: Lille

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à
natalia.grabar@univ-lille3.fr, eric.kergosien@univ-lille3.fr"
"331","2016-02-08","TrooClick","Paris","NLP Engineer Internship at Trooclick

-----
Context
-----

Trooclick France is a company that specializes in the development of web
applications for the automatic processing of information.  Our goal is
to rank news articles exclusively by quality, to help people find a
variety of high quality content quickly, easily, and transparently.
More generally, we want to create a new and better user experience for
online news consumption via text analysis and automated restructuring of
the news. By automatically extracting quotes and tweets around a story
and generating short summaries we build a different, more engaging, view
of news events.

Trooclick was created in November 2012. Just a few months later, in
April 2013, it received financial support from the BPI (French public
investment bank) and in June 2013 was granted the Status of ""Young
Innovative Company"" (JEI), recognizing its innovative nature by the
French government. It now counts fifteen committed and passionate
members in its tight-knit team.
The company carries out R&D projects in search of technical solutions in
the Artificial Intelligence field. Due to its growth, Trooclick is now
looking for candidates for its office in the ""Incubateur Boucicaut"" on
rue de Lourmel in Paris.

-----
Missions
-----

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

- You will turn ideas into well-documented and reliable linguistic
  resources (both dictionaries and grammars) to ensure efficiency,
  quality, performance and scalability
- A great team player, you will interact with other departments to
  understand and fine tune specifications
- You will carry out unitary testing, create and maintain our test
  validation corpus and participate in editing technical documents

Development will be done in English.

-----
Qualifications
-----

- BSc/MSc
- Experience with NLP tools such as NooJ, Unitex, Gate, or Stanford for
  linguistic annotation, named entity recognition, relationship and fact
  extraction, sentiment analysis, etc.
- Experience in scripting languages such as Perl or Python as well as
  XML format to be autonomous in completing several technical tasks
- Experience with basic database management operations (SQL language)
- Knowledge of Semantic Web technologies (RDF, OWL, SKOS, etc.)  will be
  a plus
- Excellent communication skills in English and French

We are open to new ideas that will significantly contribute to our
success.
Our friendly team will provide the opportunity for valuable
collaboration.
We offer you career perspectives in a young and dynamic company with an
interesting and diversified scope of duties at the cutting edge of
research.

We welcome applications from highly motivated individuals able to learn
new techniques and share knowledge and experience with the team.

-----
Contact
-----

Interested? Then send your application to jobs@trooclick.com !"
"332","2016-02-08","LIMSI","Orsay","- Titre : Etude des représentations distribuées pour l'extraction de
  relations

- Descriptif

Le sujet proposé se focalise sur le problème de l'extraction de
relations binaires au sein de phrases. La tâche considérée se définit
plus précisément comme une forme de validation : partant d'un type de
relation défini a priori et d'une phrase au sein de laquelle deux
arguments possibles de la relation sont identifiés, l'objectif est de
déterminer si une relation du type considéré est véritablement exprimée
dans la phrase entre les deux arguments repérés. Dans le cadre du stage
proposé, nous nous concentrons plus particulièrement sur les relations
correspondant à des attributs de personnes (date de naissance, conjoint
...) ou d'organisations (siège, nombre d'employés ...), à l'instar des
relations considérées dans la tâche Slot Filling des évaluations TAC,
mais aussi sur les relations correspondant aux rôles associés à un type
d'événement (par exemple la personne jouant le rôle d'accusé dans un
procès) et sur les relations issues de bases de connaissances telles que
DBPedia.

Cette tâche a fait l'objet d'un large ensemble de travaux explorant en
particulier les différents types d'information pouvant être exploités
par des classifieurs statistiques de différentes natures. Une vague
encore récente de travaux en relation avec l'apprentissage profond (Deep
Learning) a mis sur le devant de la scène une perspective un peu
différente. Dans ce contexte, l'objectif n'est plus de sélectionner des
traits fournis par des outils de traitement automatique des langues mais
de construire ou d'apprendre des représentations lexicales distribuées
caractérisant les relations de proximité des mots. Ces représentations
peuvent être générales ou liées à la tâche particulière pour laquelle
elles sont utilisées.

L'objectif du stage est d'étudier l'impact de telles représentations sur
la tâche d'extraction de relations considérée ici. Un premier travail
très préliminaire a déjà été réalisé sur l'utilisation de
représentations neuronales pour l'extraction de rôles événementiels. Le
sujet se propose d'étendre ce travail dans la perspective de l'analyser,
le généraliser et le systématiser. Plus précisément, les tâches
suivantes sont envisagées :

- application de différents types de représentations lexicales
  distribuées au problème considéré (représentations neuronales,
  clusters de Brown, espaces issus de techniques de réduction de
  dimensions, représentations distributionnelles) ;

- analyse fine de l'apport des représentations distribuées et de leurs
  limites en fonction du type des relations et de leurs arguments ;

- étude de l'adéquation entre le type de représentation et le type de
  classifieur l'exploitant. Dans ce cadre, l'intérêt de l'utilisation de
  réseaux de neurones profonds pour l'adaptation de représentations
  générales à un domaine particulier sera considéré.

Le stage se déroulera au sein du laboratoire LIMSI et sera encadré
conjointement par Brigitte Grau et Romain Beaumont du LIMSI ainsi
qu'Olivier Ferret du CEA LIST.


Durée : 4-5 mois
Lieu : LIMSI-CNRS, Orsay
Gratification : 554¤ par mois plus participation aux frais de transport
en commun

Profil recherché
- Niveau : Master 2 ou ingénieur dernière année
- Domaine de spécialité requis: Informatique, avec connaissances en 
  apprentissage ou traitement automatique des langues
- Langages de programmation: Python, Bash, éventuellement Perl, Java ou
  C++
- Environnement : Linux

Candidature : envoi d'un CV (en PDF) à brigitte.grau@limsi.fr et
olivier.ferret@cea.fr accompagné d'une lettre de motivation ainsi que
des notes de l'année universitaire en cours et de l'année dernière."
"333","2016-02-08","Télécom Bretagne","Brest","--------------
Offre de stage TAL M2 : Étude de l'apport des dépêches AFP à un corpus
de textes de la presse écrite
--------------
Stage financé par le Labex ICCA,  projet structurant «Plateformes» 2016
--------------

Le projet 2PI (Modèles économiques de la presse en ligne & pluralisme de
l'information) se propose de comparer, à différents niveaux
linguistiques, des textes provenant de l'agence de presse AFP et
d'autres titres de presse.

Les étapes d'analyse des textes seront :
- extraction terminologique
- analyse morphosyntaxique
- annotation sémantique
- extraction d'entités nommées
- analyse rhétorique (selon la théorie des arbres discursifs de Marcu
  [1,2]).

Selon les outils à disposition, ces étapes seront automatiques ou
semi-automatiques.  L'analyse rhétorique nécessitera le développement
d'outils ad hoc, basés sur des méthodes de machine learning détectant
des marqueurs syncatégorématiques et d'autres propriétés du texte, à
établir. Les données étant temporalisées on étudiera également
l'évolution des propriétés des textes.

En représentant toutes les propriétés linguistiques extraites des textes
du corpus sous forme de graphes, il s'agira de mesurer l'apport des
textes de l'AFP vis-à-vis de celui des textes des autres médias et de
caractériser/quantifier ainsi la notion de «pluralisme des médias».

--------------
Description du poste
---------------
Les tâches principales concernent :
- Analyses et annotations automatiques ou semi-automatiques des textes.
- Développement et évaluation de l'outil d'analyse rhétorique.
- Modélisation des résultats sous forme de graphes et application de
  différentes mesures de similarité entre les sous-graphes induits par
  les données AFP et leurs compléments.

---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique ou
  similaire.
- Programmation en Python (principalement NLTK).
- Curiosité et capacité d'explorer des nouveaux domaines en linguistique
  et/ou informatique.
- Des connaissances en théorie des graphes seraient un plus

-----------------
Conditions
-----------------
Stage conventionné 6 mois rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Merci d'envoyer votre candidature à l'adresse
yannis.haralambous@telecom-bretagne.eu

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : Département Informatique, Télécom Bretagne, Brest.

Encadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285
             Lab-STICC)
             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)

Contrat : stage. 

Début : mars-avril 2016.

[1] MARCU Daniel, 2000. The Theory and Practice of Discourse Parsing and
    Summarization, MIT Press.

[2] ROZE, Charlotte, 2013. Vers une algèbre des relations du discours,
    thèse de doctorat, université Paris VII."
"334","2016-02-08","Voxygen","Rennes","Offre de Stage :

Voxygen est une entreprise dédiée au développement et à la valorisation
des technologies de Synthèse Vocale, de Reconnaissance Vocale et
d'Identification de locuteur.
Issue des laboratoires d'Orange Labs, les solutions vocales de Voxygen
s'appliquent à de nombreux domaines, pour des besoins aussi spécifiques
que variés : Télécoms, Transports, Accessibilité, Santé, Médias,
Formation et Jeux, etc. Ces solutions sont déclinées dans plusieurs
langues dont les principales langues européennes, l'anglais US, l'arabe
standard et certaines langues subsahariennes comme le hausa, le zarma et
le wolof.

Mots clés : traitement automatique de l'arabe, synthèse vocale

Contexte:
Dans le cadre de ses activités de recherche et développement, Voxygen
travaille sans cesse à l'amélioration des traitements linguistiques mis
en oeuvre dans ses systèmes. Parmi ces travaux figure la langue arabe qui
présente une difficulté majeure en traitement automatique liée à
l'absence des signes diacritiques (voyelles brèves) dans la plupart des
textes écrits. Voxygen a développé un voyelleur automatique de textes
arabes basé sur un lexique de mots, une analyse morphologique et
l'application d'un modèle de langue probabiliste. Néanmoins, et en
raison de la complexité de cette tâche, des erreurs de voyellation
subsistent et impactent directement la prononciation des mots.

Sujet :
Amélioration de la voyellation automatique de l'arabe

Le but de ce stage est l'amélioration des traitements linguistiques mis
en oeuvre pour la voyellation automatique de l'arabe. En particulier :

- Identifier les erreurs, déterminer leurs origines (analyse
  morphologique, lexique, désambiguïsation, etc.)

- Proposer des solutions d'amélioration. Plusieurs pistes sont
  envisagées :
    *Optimisation du processus de génération du modèle de langue
    *Mise en place d'une stratégie pour le traitement des mots hors
     lexique
- Adapter la voyellation automatique de l'arabe au contexte de la
  synthèse vocale

Compétences :
- bonne connaissance de la langue arabe
- traitement automatique de la langue écrite
- morphologie, lexique, syntaxe
- élaboration de scripts (Shell, Python ou Perl)

Durée du stage : 4 à 6 mois, à partir de mars-avril 2016

Lieu du stage : Rennes

Merci d'adresser votre candidature (CV + motivations) à jobs@voxygen.fr"
"335","2016-02-12","Succeed Together","Paris","Proposition de stage

Sujet: Développement d'une API de catégorisation de textes courts.

Type de poste : Stage 6 à 12 mois
Lieu de travail : Succeed Together, 60 bis rue de Rochechouart, 75009
                  Paris

Contexte

Au sein du pôle recherche et développement de l'entreprise Succeed
Together, nous orientons nos recherches sur le regroupement sémantique
ultra rapide de messages courts.

Dans le domaine de l'analyse de textes, Succeed Together recherche
un/une stagiaire pour travailler sur des techniques de classification
(supervisée et non supervisée ) de messages courts :

   - classification par polarité : Il s'agit pour des messages courts,
     de juger de leur subjectivité dans un premier temps, et de détecter
     leurs polarités (positive/négative) dans un second temps.

   - classification par thématique : Il s'agit ici pour des messages
     courts d'identifier leurs thématiques associées. C'est l'exemple de
     messages ""être proche de son client"" et ""privilégier la proximité""
     qui appartiennent à la thématique ""proximité avec les clients"".

Objectifs

A partir de messages courts provenant de plusieurs sources (réponses à
des questions, réseaux sociaux, ...), pouvant être de langues
différentes, l'application visée a pour but de regrouper
automatiquement, de produire une classification par thématique et/ou par
polarité.

La tâche du stagiaire consistera donc en particulier à :

   - Étudier et tester les algorithmes de classification par thématique
     (respectivement par polarité) des messages courts ;

   - Assister les développeurs dans la mise en place de l'API ;

   - Évaluer les différentes solutions sur des données de référence ;

Profil recherché:

   - Compétences en traitement automatique des langues / recherche
     d'information / mesures de similarité textuelle

   - Connaissances des techniques de clustering / classification

   - Langage de programmation utilisé: python, java

   - Compétences en statistique seraient un plus

Les candidats intéressés doivent envoyer un email de candidature à
gdurand@succeed-together.eu avec un CV détaillé (pdf) et une lettre de
motivation."
"336","2016-02-17","LIGM","Marne-la-vallée","--------------
Offre de stage TAL M2 : POS tagging hybride avec Gate et Unitex/GramLab

--------------
Stage financé par le projet CRC de la Hankuk University of Foreign 
Studies (HUFS, Corée du Sud)
--------------

Le LIGM est un laboratoire CNRS de recherche en informatique inclus dans
le LabEx (Laboratoire d'excellence) Bézout. Le LIGM a 70 membres
permanents. La communauté des utilisateurs et développeurs du système
Unitex/GramLab est coordonnée par le LIGM.

Le projet de recherche CRC financé par le gouvernement coréen se propose
entre autres de développer un POS tagger hybride en combinant Gate et
Unitex/GramLab.

Gate et Unitex/GramLab sont deux systèmes open source complémentaires
qui couvrent un large éventail de tâches du traitement automatique des
langues (TAL), qui sont documentés et réunissent chacun une communauté
structurée.

Les étapes du tagging seront :
- tokenisation et découpage en phrases sous Unitex/GramLab
- génération d'étiquetages candidats par analyse morphologique
  symbolique sous Unitex/GramLab
- transfert des candidats vers Gate
- sélection du meilleur candidat par un modèle probabiliste entrainé sur
  un corpus annoté
- transfert vers Unitex.
Cette chaine de traitement convient pour toute langue nécessitant une
analyse morphologique, comme le coréen et l'arabe.

L'objectif du stage est de développer les fonctionnalités nécessaires
pour mener à bien cette expérience.

--------------
Description du poste
---------------
Les tâches principales concernent :
- Développement sous Unitex/GramLab de fonctionnalités d'exportation de
  corpus annotés vers Gate : d'une part, corpus étiquetés à la main
  (pour l'apprentissage du tagger) et d'autre part, étiquetages
  candidats obtenus par analyse morphologique. Le format cible est le
  format XML de sérialisation de Gate (C/C++, Java).
- Développement sous Gate d'un programme d'entrainement du tagger à
  partir d'un corpus en coréen annoté à la main par l'HUFS (Java).
- Développement sous Gate d'un programme d'application du tagger aux
  étiquetages candidats (Java).
- Développement sous Unitex:GramLab d'une fonctionnalité d'import de
  corpus annotés depuis Gate (C/C++, Java).

---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique ou
  similaire.
- Programmation en Java et C/C++.
- Intérêt pour le développement open source.
- Curiosité et capacité d'explorer de nouvelles méthodes statistiques en
  TAL.
- Une expérience d'Unicode serait un plus.

-----------------
Conditions
-----------------
Stage conventionné de 4 à 5 mois, 554,40 euros/mois net.

Nombre de postes : 1 poste

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Merci d'envoyer votre candidature à l'adresse
eric.laporte@univ-paris-est.fr

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : LIGM, Université Paris-Est Marne-la-Vallée.

Encadrants : Eric Laporte (Université Paris-Est Marne-la-Vallée et UMR
CNRS 8049 LIGM)
Matthieu Constant (INRIA Alpage)
Cristian Martinez (LIGM)

Contrat : convention de stage.

Début : mars ou avril 2016."
"337","2016-02-23","Alkemics","Paris","Stage Ontologie

Paris, Île-de-France, France

Description

À propos d'Alkemics

Alkemics connecte les marques (Unilever, Nestlé, P&G...) et les
distributeurs (Auchan, Casino...) à l'aide d'un service collaboratif
dédié à la grande distribution.

Nous proposons Product Stream, une plateforme qui permet aux marques
de grande consommation et aux distributeurs de centraliser et partager
toute l'information produit sur un unique canal de
communication. Grâce au réseau des clients d'Alkemics (plus de 800
marques et 6 grandes enseignes distributeurs), Product Stream permet
aux marques d'enrichir et d'uniformiser les fiches produits sur
l'ensemble des sites e-commerce en un clic.

Alkemics, start-up innovante et en pleine croissance (effectif triplé
en 1 an, 50 personnes à date) recherche un étudiant en linguistique ou
TAL afin de travailler sur la refonte de son ontologie.


Description de la mission

Vous serez intégré à l'équipe R&D, et travaillerez en étroite
collaboration avec des personnes ayant une forte connaissance produit
dans le cadre de la grande distribution. Le but du stage est de
retranscrire dans notre ontologie les problématiques de classification
et de normalisation de l'ensemble de l'offre produit de grande
consommation afin d'alimenter nos technologies applicatives qui
proposent des solutions marketing intelligentes.

Une analyse des différentes catégories de produits de la grande
consommation vous sera confiée : vous mènerez dans le cadre de votre
mission une étude complète pour classifier et faire ressortir tous les
attributs ontologiques indispensables pour modéliser chaque catégorie
de produit dans le cadre des applications développées par Alkemics.

Cette étude aura un volet formel et un volet pratique :

    Volet formel : en vous appuyant sur une version existante de notre
    ontologie, vous proposerez un scénario d'évolution de cette
    dernière afin de mieux répondre aux besoins métiers en interne.

    Volet pratique : vous participerez à des entretiens avec les
    principaux acteurs de la grande consommation (marques et
    distributeurs) et procéderez à des recherches documentaires
    (connaissances marketing, réglementaire et encyclopédique du
    produit) afin de consolider l'aspect fonctionnel de la ressource.

Vous aurez à l'issue de ce stage une excellente expérience en
""ontologie de terrain"" appliquée au monde de la grande distribution.

Requirements

- Vous avez des connaissances en ontologie(format OWL, logiques de description)
- Vous savez utiliser Protégé, NeOn ou tout autre éditeur d'ontologie.
- Vous êtes autonome dans votre travail
- Vous êtes pragmatique et savez prioriser vos missions
- Vous arrivez à comprendre et décortiquer rapidement des informations
  sur un domaine inconnu
- Vous arrivez à modéliser et hiérarchiser un grand nombre de
  connaissances relatives à un même concept
- Un premier stage en ontologie ou concernant des produit grande
  consommation serait un plus
- Excellent niveau de français, bon niveau d'anglais.

Benefits

 - Rémunération en fonction du profil.
 - Pas de bureaucratie : vos contributions auront un véritable impact.
 - Vous ne serez pas oublié dans un coin : notre mode de
     fonctionnement en petites équipes vous permettra de monter en
     compétence rapidement, et de ne pas rester bloquer sur un
     problème trop longtemps.
 - Notre start-up en phase de fort développement : si vous menez à
     bien votre mission, il y aura une possibilité d'embauche à
     l'issue du stage.
 - Nos bureaux sont en plein coeur du 9ème arrondissement
 - Extras : sessions de sport hebdomadaires, séances de méditation,
     ateliers sur différents sujets, etc.


Candidature en ligne sur :

https://alkemics.workable.com/jobs/206262"
"338","2016-02-23","SESAMm","Luxembourg & Metz","Hello,

Our team is looking for an intern or a graduate in Natural Language
Processing for Japanese for 6 months (internship or 6 months contract
before a permanent contract if results are satisfactory):

http://www.sesamm.com/wp-content/uploads/2016/02/SESAMm_Internship-Description_NLP_Japanese.pdf

SESAMm was founded in 2014 and is one of the most dynamic FinTech
startups in France and Luxembourg. SESAMm develops and commercializes
stock market forecasting tools based on social media and other textual
data sources.These products are used by banks and hedge funds. The
company provides financial trading indicators which have been created
using Big Data methods and allowing new approaches for trading
strategies. We develop many new products based on our clients' needs.

SESAMm aims at becoming the international leader of Big Data
technologies for stock market professionals.

Internship Goal: development of new text-analysis and sentiment analysis
methods to create financial trading indicators based on information from
Japanese social media and social trading platforms.

Major Duties:
- Participate in existing and future research projects: analyze existing
  methods, develop original solutions and evaluate them, present results
- Identify relevant sources of information and extract data. Crawling &
  scraping of several data sources.
- Filter and prepare data
- Develop NLP algorithms for Japanese
- Write analysis reports

Education Requirements
- Engineering school or university master student: Computer Science,
  Natural Language Processing or similar.

Work Experience and Skills Requirements
- Work Experience: 0-1 year in NLP or computer science.
- Knowledge in NLP, Machine Learning, crawling and scraping.
- Demonstrate ability to create lexical semantic resources for NLP-based
  applications.
- Languages: native japanese, French or Enhlish spoken
- Programming Skills : Java and scripting languages

The applicant should be able to work in a team and show high
motivation. This internship requires autonomy and curiosity toward a
changing environment. The intern will contribute to the company's most
important technical decisions; thereby this internship will be a
high-level entrepreneurial experience.

Working Conditions
- Percent Time: 100%
- Location: Luxembourg (Boulevard Royal, City Center) and Metz (France)
- Duration: 6 months, starting in April 2016.


Join SESAMm, an innovative and ambitious FinTech startup with
high potential.
More information: www.sesamm.com
Please send your application to contact@sesamm.com
Application: resume, interview"
"339","2016-02-23","MoDyCo","Nanterre","Bonjour,

Un sujet de stage est proposé dans le cadre plus large d'un projet de
recherche réunissant plusieurs laboratoires : LORIA (Nancy), GREYC
(Caen) - LIPN (Paris 13), INSERM (Paris) et MoDyCo (Paris 10). Ce projet
a pour objectif d'extraire des informations à partir de textes
biologiques et médicaux sur les maladies orphelines (dites aussi
maladies rares) pour apporter une aide automatique à l'enrichissement
d'une base de connaissances, notamment du site d'information Orphanet
dédié à ce type de maladies. Pour une présentation générale du projet et
de quelques résultats en particulier, on pourra consulter le site dédié :
http://hybride.loria.fr/

Le stage portera plus précisément sur le repérage des symptômes liés à
ces maladies dans des textes scientifiques en anglais. Plusieurs
techniques ont été déjà développées dans le cadre du projet, notamment
la fouille de données, l'analyse syntaxique et les CRF (Conditionnal
Random Fields). Les programmes informatiques développés et des jeux de
corpus seront fournis.  Il s'agira de les expérimenter afin de comparer
leurs avantages et leurs défauts, puis on cherchera à améliorer les
résultats en proposant une combinaison de ces techniques.

Quelques références bibliographiques :

Laure Martin, Delphine Battistelli, Thierry Charnois (2014). Symptom
recognition issue, in Proceedings BioNLP 2014 (13th Workshop on
Biomedical Natural Language Processing), held in conjunction with
ACL'2014 (52nd Annual Meeting of the Association for Computational
Linguistics), 26-27 juin 2014, p.107-111, Baltimore, USA.

Laure Martin, Delphine Battistelli, Thierry Charnois (2014). Mise en
place d'une méthode de reconnaissance des symptômes dans le contexte des
maladies rares, in Actes Atelier Ingénierie des Connaissances et Santé,
IC 2014 (25es Journées francophones d'Ingénierie des Connaissances), 13
mai 2014, 8 pages, Clermont-Ferrand.

Jean-Philippe Métivier, Laurie Serrano, Thierry Charnois, Bertrand
Cuissart and Antoine Widlöcher (2015). Automatic symptom extraction from
texts to enhance knowledge discovery on rare diseases, in proceedings of
the Conference on Artificial Intelligence in Medicine (AIME 2015),
Lecture Notes in Computer Science 9105, Springer 2015, pp.  249-254,
Pavia, Italy, June 17-20, 2015.

Encadrement : Delphine Battistelli (Laboratoire MoDyCo, Université Paris
10) et Thierry Charnois (Laboratoire LIPN, Université Paris 13)

Rémunération : selon la réglementation en vigueur, soit environ 540
euros mensuel, plus prise en charge partielle des frais de transport
(50% de l'abonnement navigo entre la résidence et le lieu du
stage). Durant le stage, des réunions de travail pourront avoir lieu sur
le site des partenaires du projet. Ces déplacements seront entièrement
pris en charge financièrement.

Durée : 4-5 mois

Profil recherché :
- Niveau : Master 2 ou ingénieur dernière année
- Domaine de spécialité requis: TAL ou Informatique avec connaissances
  en  apprentissage ou TAL

Candidature : envoi d'un CV à delphine.battistelli@u-paris10.fr et
Thierry.charnois@lipn.univ-paris13.fr accompagné d'une lettre de
motivation ainsi que des notes de l'année universitaire en cours et de
l'année dernière."
"340","2016-03-07","CS","Le Plessis Robinson","Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les contrôleurs à travers d'échanges vocaux. Dans ce
contexte, CS conçoit et réalise une gamme de produits : systèmes de
communication vocale (VCS), enregistreurs et simulateurs. Pour d'autres
applications comme la recherche d'informations de parole dans des
enregistrements, les services de communication multilingue pour les
compagnies aériennes ou la traduction multilingue de grosses
documentations techniques (Rafale pour l'Inde/l'Égypte..., par exemple),
il est nécessaire de traiter non seulement la voix (signal audio) mais
aussi la parole, c'est à dire le contenu sémantique du signal audio, ou
le texte écrit.

Dans ce but, nous souhaitons étudier la faisabilité d'un enconvertisseur
du français, c'est-à-dire un analyseur produisant des graphes UNL
(Universal Networking Language) à partir de textes en français. Cet
enconvertisseur nous permettra par la suite d'évaluer la pertinence des
graphes UNL à la fois comme représentation source pour générer du texte
dans plusieurs langues (déconversion) ou pour faire des inférences
(ontologies) et aussi comme interlingua pour de la traduction
automatique (enconversion + déconversion).

Pour transformer des phrases en graphes UNL, nous suivons la méthode du
GETA : utiliser un transducteur générique  qui produit les graphes UNL à
partir des représentations profondes (« structures  multiniveaux de
Vauquois », ou plus simplement « arbres de Vauquois ») obtenues par des
analyseurs existants. Plusieurs tels analyseurs produisant des
structures de Vauquois ont été développés sous Ariane  et sont
disponibles en sources ouvertes.

Travail à réaliser :

Nota : Le sujet est composé de deux parties principales indépendantes
qui pourront être traitées par deux stagiaires différents, selon la
durée du(des) stage(s) et le profil du(des) stagiaire(s).

1) Transducteur générique « arbre de Vauquois -> graphe UNL »

Après une phase de prise de connaissance des principes d'UNL et des
structures multiniveaux de Vauquois, le stagiaire étudiera l'algorithme
simplifié du transducteur actuellement utilisé pour transformer les
structures multilniveaux en graphes UNL dans l'enconvertisseur du
français. Il  l'étendra ensuite :

- en intégrant un traitement actuellement réalisé sous Ariane
  (transfert),
- en prenant en compte les scopes, qui sont des entités sémantiques
  autonomes actuellement non prises en compte .

le stagiaire clarifiera les éventuelles contraintes que doivent
respecter les structures multiniveaux présentées en entrée du
transducteur arbre-graphe puis il programmera l'algorithme spécifié.

2) Génération automatique d'un analyseur du français à partir d'un
dictionnaire français-UNL

D'importantes ressources bilingues NL-UNL, avec NL = anglais (83507
entrées), russe (63287 entrées), français (51352 entrées),  hindi (50391
entrées),  malais (31406 entrées),  espagnol (21874 entrées), vietnamien
(10150 entrées) sont maintenues par Vyacheslav Dikonov, au laboratoire
LCL de l'institut IPPI de l'Académie des Sciences de Moscou . Dans le
but de tirer le meilleur parti de ces dictionnaires, le stagiaire
étudiera un programme générant automatiquement les fichiers source d'un
analyseur morphologique Ariane du français cohérent avec ces données en
croisant les dictionnaires français-UNL de l'IPPI avec (1) des
ressources lexicales libres telles que Lexique 3.81
(http://www.lexique.org/) et (2) les mots présents dans des corpus
techniques de CS. Pour cela, il pourra s'appuyer sur des programmes déjà
existants, générant des analyseurs morphologiques Ariane à partir de
bases de données lexicales.

3) Expérimentations (selon le temps disponible)

Le stagiaire testera ensuite la chaîne d'analyse intégrant (1) l'analyse
morphologique qu'il aura produite, (2) l'analyse structurale qui produit
les structures de Vauquois (phase existante) et (3) la transformation
arbre-graphe qui produira les graphes UNL des phrases soumises à
l'analyseur.

 Résultats attendus :
- Rapport d'étude sur l'algorithme du transducteur arbre-graphe.
- Programme implémentant l'algorithme du transducteur arbre-graphe.
- Base lexicale extraite des corpus techniques de CS.
- Programme de génération de l'analyseur morphologique.
- Rapport d'évaluation de la chaîne français-UNL (selon le temps
  disponible).

Durée du stage: 4 à 6 mois

De formation Master 2 ou élève ingénieur en 2e ou 3e année, vous
recherchez un stage en développement avec les langages suivants:
- C/C++.
- Java.
- Sqlite3.
La maîtrise de l'anglais est indispensable pour ce stage.

Pour postuler: CV + LM à envoyer à l'adresse recrutement@c-s.fr à
l'attention de Gariné Kelijian"
"341","2016-03-07","XRCE","Grenoble","Internship on ""CV Mining for Selection in Hiring Processes"" at XRCE
-------------------------------------------------------------------
UNIT: XRCE/ADL/TPI

PROPOSERS: Caroline Privault, Fabien Guillot

DURATION: 6 months - Dates confirmed after interview based on 
availability of the candidate

START DATE: April 2016- Date confirmed after interview based on 
availability of the candidate

REFERENCE : 
http://www.xrce.xerox.com/About-XRCE/Internships/CV-Mining-for-Selection-in-Hiring-Processes

The Text processing & Interaction group in ADL brings together
competencies in text mining, user interaction & design, and advanced
engineering, in order to prototype and transfer technologies to Xerox
business groups and customers. The main focus for this internship is on
the development of specific language resources and tools for application
to CV mining in the Human Resources domain: the goal is to contribute to
the development of a system for supporting recruiters in the review of
applicants' CVs received for a published job vacancy. The candidate will
have the possibility to work on some of the following tasks in
collaboration with other team members:

** Generating Linguistic Resources

- generate linguistic resources for semantic relatedness such as
  semantic taxonomy
- exploit public corpora and free databases, to build linguistic
  resources

*** Mining Candidate Personality Traits
- investigate the state of the art in related fields such as
  psycho-linguistics or social linguistics to understand possible
  relationships between specific personal expressions (syntax, word
  usage, etc) and personality traits of the candidates
- develop tools for parsing resume text contents to detect specific
  personal expressions such as usage of pronouns, passive/active form,
  etc

The candidate will contribute to the design of annotation schemes and
corpora annotation as part of the above tasks. You will be part of a
team of developers and researchers, on a project managed with an agile
methodology.

REQUIREMENTS:
- Master Student or PhD
- Knowledge/practice of an Annotation Tool e.g. Brat or other
- Experience in developing linguistic resources
- Experience in using scripting languages (e.g. Python, Perl). Practice
  of JAVA is a plus
- Knowledge of some Natural Language Processing tools, (e.g. Named
  Entity Recognizers, Syntactic Parsers, POS Taggers, CRF, etc.)
- Verbal and written communication skills in English
- Knowledge of XML, or other structured format is a plus
- Knowledge in Machine Learning (e.g. Deep learning), Ontology/Semantic
  web are a plus

To submit an application:
Please send your CV and cover letter to xrce-candidates@xrce.xerox.com. 
Please specify ""CV Mining for Selection in Hiring Processes"" in your 
subject line.

Full proposal at:
http://www.xrce.xerox.com/About-XRCE/Internships/CV-Mining-for-Selection-in-Hiring-Processes

~~~~~~~~~~
About XRCE:

Xerox Research Centre Europe (XRCE) is a young, dynamic research
organization, which creates innovative technologies to support growth in
Xerox business process outsourcing and document management services
businesses.

Our domains of research stretch from the social sciences to computer
science. We have renowned expertise in machine learning, natural
language processing, computer vision, ethnography and services
computing.

XRCE is part of the Xerox Innovation group made up of 650 researchers
and engineers in four world-renowned research and technology centres.
Our goal is to make Xerox a great place to work. Through a comprehensive
set of employee-focused initiatives, we promote diversity by nurturing a
culture of inclusion and opportunity, and through measurable actions."
"342","2016-03-09","INALCO","Paris","CADRE DU STAGE

Dans le cadre d'une collaboration entre les équipes ERTIM et CERMOM de
l'Inalco autour du projet ALIENTO, nous proposons une offre de stage à
l'intersection entre la linguistique et l'informatique.

SUJET DU STAGE

Le projet ANR ALIENTO vise à apparier par calcul des énoncés sapientiels
brefs (proverbes, sentences, maximes, aphorismes...) médiévaux
multilingues (arabe, hébreu, latin et espagnol) à partir des annotations
standardisées trilingues (français, anglais et espagnol) portant sur
leur sens (sens propre, sens figuré, leçon ou morale, mots-clés
conceptuels) et sur leur forme (lemmatisation, structure type ou
pattern, structure linguistique, structure formelle, type de discours,
figures de style).

Le stage portera sur deux aspects de l'exploitation du corpus, présentés
ci-dessous.

1/ Fouille de motifs sapientiels

Les corpus collectés et annotés à divers niveaux linguistiques et
sémantiques permettent d'envisager l'utilisation de techniques de
fouille de texte afin d'isoler des motifs lexicaux-grammaticaux
représentatifs des énoncés sapientiels. Il s'agit de conduire plusieurs
analyses :
- des motifs peuvent-ils être extraits sur le corpus dans sa globalité,
  en retenant à la fois des critères liés à leur fréquence et à leur
  spécificité (il pourra être utile de confronter les motifs concernant
  les énoncés sapientiels à la totalité des textes),
- par comparaison entre les langues des énoncés : présentent-ils les
  mêmes caractéristiques d'une langue à une autre, peut-on les
  rapprocher ou les contraster ?

2/ Mécanismes pour la translittération arabe

La plateforme disponible pour mener le projet ALIENTO permet la saisie
et la consultation de documents dans leur forme d'origine. Cependant,
les utilisateurs qui y accèdent peuvent avoir besoin de comparer les
rythmes (phonétiques) des énoncés sans nécessairement savoir lire
l'écriture arabe.

Dans ce contexte, la base de données permet la saisie des
translittérations des textes vers un alphabet latin (système de
romanisation simplifié pour Aliento ou norme Arabica). Ce travail, long
et fastidieux lorsqu'il est réalisé manuellement, peut être grandement
facilité par l'utilisation d'un logiciel de translittération automatique
à la plateforme.

Il s'agira donc d'établir une liste d'outils capables de réaliser une
translittération automatique, de les évaluer, et de déterminer dans
quelle mesure ils peuvent être intégrés à l'architecture logicielle du
projet. Il sera vraisemblablement nécessaire de réaliser des
développements spécifiques et des adaptations selon les attentes et les
types de textes (médiévaux) fournis en entrée.

COMPÉTENCES REQUISES

- Connaissance des outils TAL
- Connaissance de l'arabe
- Maîtrise des environnements : Linux et Windows
- Familiarité avec des langages de programmation : Perl / Python / Java

MODALITÉS

Démarrage du stage : avril 2016
Employeur : Institut National des Langues et Civilisations Orientales
(INALCO)
Contrat : Stage M1 ou M2 de 4 mois
Lieu de Travail : Maison de la recherche de l'INALCO, 2 rue de Lille,
75007 Paris
Rémunération : 554¤ + prise en charge partielle des transport IdF

CONTACT

Merci d'envoyer votre CV et vos motivations à damien.nouvel@inalco.fr et
varol@noos.fr"
"343","2016-03-09","Akio","Paris","Titre: Interprétation sémantique de la relation client

Descriptif: 
Le sujet proposé traite de l'interprétation sémantique des informations
échangées entre une entreprise et ses clients. Le mode opératoire est
omnicanal dans le sens où quelque soit le moyen choisi par le client,
l'entreprise doit pouvoir faire le lien entre le contact présent et
l'historique des interactions passées, même si elles sont de nature
différente, que ce soit la voix, un tchat, le courriel ou les réseaux
sociaux.  La chaîne de traitement actuelle comporte plusieurs étapes
allant de l'analyse morphosyntaxique, le redressage orthographique, le
chunking statistique, l'analyse syntaxique suivies de l'interprétation
sémantique. Le stage portera essentiellement sur la partie sémantique
des composants logiciels de calcul des thématiques, des opinions et des
modalités d'expression.

Description du poste:
L'objectif du stage est d'apporter un regard extérieur sur la chaîne de
traitement actuelle afin de l'améliorer à la fois en français et en
anglais, via une qualification quantitative. Nous sommes ouverts à de
nouvelles idées qui peuvent contribuer à notre succès au sein d'une
équipe dynamique.

Profil recherché:
- Niveau Master 2 ou ingénieur dernière année.
- Spécialité requise: traitement automatique de la langue.
- Bonne expérience des mails et des réseaux sociaux.
- Langage de programmation Java. 
- Bonne connaissance du français et de l'anglais.
- Créativité, esprit d'équipe.

Durée: 
3 mois, de manière préférentielle en juin, juillet et août.
Des adaptations (avant/après/plus long) sont possibles.

Lieu:
Bureaux Parisiens d'Akio.
43 rue de Dunkerque, 75010 Paris.
www.akio.com

Gratification:
Indemnité légale de stage en vigueur.

Encadrement:
Le stage sera encadré par Gil Francopoulo.

Candidature:
Merci d'envoyer un CV à gil.francopoulo arobase akio.com 
accompagné des notes de l'année universitaire en cours 
et de l'année dernière."
"344","2016-03-15","LIPN","Villetaneuse","Offre de stage : Réingénierie du site web de l'association pour le
Traitement Automatique des Langues

CONTEXTE

L'Association pour le Traitement Automatique des Langues (ATALA) est une
association savante fondée en 1959 et qui fédère la communauté
scientifique du Traitement Automatique des Langues (TAL). À ce titre,
elle dispose d'un site web pour faire la promotion de ses
activités. Parmi celles-ci figurent : la conférence TALN, la revue TAL,
les journées d'étude, les inscriptions, la gestion de liste de
diffusion, le recensement d'outils, de formations et d'équipes de
recherche, etc.

Le site actuel, réalisé il y a plusieurs années avec le système de
gestion de contenus SPIP, n'est plus adapté aux besoins actuels de
l'ATALA. Il a donc été décidé de migrer vers un nouveau CMS afin de
satisfaire aux besoins de l'association et de faciliter le plus possible
les opérations courantes. Parmi les fonctionnalités à améliorer ou
mettre en place figurent : la gestion des activités scientifiques
(articles, annonces de séminaires, etc.) la gestion fine des
utilisateurs (visiteurs, membres, responsable d'activités de l'ATALA,
webmestres), l'intégration d'une interface de paiement en ligne pour les
inscriptions. Pour cela, la migration vers le nouveau CMS devra
récupérer aussi automatiquement que possible les données présentes dans
le CMS actuel (par requêtes SQL), puis en les insérant dans le nouveau
CMS (par API). Le renouvellement de la charte graphique n'est pas un
besoin prioritaire, mais une adaptation du rendu graphique à la nouvelle
plate-forme technologique sera bienvenue.

OBJECTIFS

Le premier objectif du stage est de mieux recenser et qualifier les
besoins en gestion collaborative du site afin d'évaluer quels systèmes
de gestion de contenu (CMS) répondent le mieux à ces exigences. Une
étude des données à migrer de l'ancienne base de données SPIP devra être
menée, pour estimer quelles données peuvent facilement être importées
vers le nouveau CMS. Un premier prototype sera présenté au CA de
l'association pour valider les fonctionnalités, le rendu visuel sur des
différents supports (écran d'ordinateur et mobile). Il s'agira ensuite
de conduire la migration à proprement parler et les tests nécessaires
afin de s'assurer que le nouveau CMS soit opérationnel. Enfin, de
nouvelles fonctionnalités seront progressivement ajoutées au site
(connexions aux réseaux sociaux, espaces dédiés aux évènements liés à
l'association, gestion fine des droits utilisateurs, etc.). Un accent
sera mis sur la fluidité de l'interface et l'évolutivité des
fonctionnalités proposées par le site.

Référence : actuel site web de l'ATALA: http://www.atala.org/

COMPÉTENCES

Compétences requises :
- Expérience en développement de sites web
- Bootstrap, React, node.js
- Linux, Mysql, Apache, PHP.

Compétences souhaitées :
- Expérience avec des plate-formes de gestion de contenu (CMS)
- Connaissances de SPIP

MODALITÉS

Lieu du stage: LIPN, 99 avenue Jean-Baptiste Clément, Villetaneuse
Durée : 6 mois (avril - septembre 2016)
Rémunération : 546¤ par mois
Contexte administratif : Le stage sera directement encadré par Jorge
Garcia Flores (LIPN) et suivi par Damien Nouvel (INaLCO) et Cyril Grouin
(LIMSI), responsables web du conseil d'administration de l'ATALA.

CONTACT

Merci d'envoyer CV et motivations à : jgflores@lipn.univ-paris13.fr"
"345","2016-03-21","Telecom Bretagne","Brest","--------------
Offre de stage TAL M2 : Pluralisme des médias : analyse comparée de
textes de la presse écrite et de dépêches AFP
--------------
Stage de 4 mois, financé par le Labex ICCA,  projet structurant
«Plateformes» 2016
--------------

Le projet 2PI (Modèles économiques de la presse en ligne & pluralisme de
l'information) se propose de comparer, à différents niveaux
linguistiques, des textes provenant de l'agence de presse AFP et
d'autres titres de presse.

Les étapes d'analyse des textes seront :
- extraction terminologique
- analyse morphosyntaxique
- annotation sémantique
- extraction d'entités nommées

Selon les outils à disposition, ces étapes seront automatiques ou
semi-automatiques.

En représentant toutes les propriétés linguistiques extraites des textes
du corpus sous forme de graphes, il s'agira de mesurer l'apport des
textes de l'AFP vis-à-vis de celui des textes des autres médias et de
tenter de caractériser/quantifier ainsi la notion de «pluralisme des
médias».

--------------
Description du poste
---------------
Les tâches principales concernent :
- Analyses et annotations automatiques ou semi-automatiques des textes.
- Modélisation des résultats sous forme de graphes et application de
  différentes mesures de similarité entre les sous-graphes induits par
  les données AFP et leurs compléments.

---------------
Profil souhaité
---------------
- Master 2 en Linguistique Informatique ou similaire (en cours, ou plus
  ancien).
- Programmation en Python (principalement NLTK).
- Curiosité et capacité d'explorer des nouveaux domaines en linguistique
  et/ou informatique.
- Des connaissances en théorie des graphes seraient un plus

-----------------
Conditions
-----------------
Stage conventionné 4 mois rémunéré.

Merci d'envoyer votre candidature à l'adresse
yannis.haralambous@telecom-bretagne.eu

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : Département Informatique, Télécom Bretagne, Brest.

Encadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285
             Lab-STICC)
             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)

Contrat : stage. 

Début : avril 2016."
"346","2016-04-11","INALCO","Paris","Offre de stage : stage TAL arabizi tunisien, 4 à 6 mois 

Objet : normalisation de l'écriture de l'arabe tunisien sur les réseaux
sociaux

Employeur : Institut National des Langues et Civilisations Orientales
(INALCO)

Contrat : stage M1 ou M2 de 4 à 6 mois

Lieu de Travail : Maison de la recherche de l'INALCO, 2 rue de Lille
75007 Paris

Rémunération : 554 ¤ / mois + prise en charge partielle des transports
IdF

Date de début : dès que possible

CONTEXTE 

Le projet a pour cadre général le traitement automatique de l'arabe
tunisien, langue peu dotée et non codifiée dont l'écriture sur les
réseaux sociaux est diverse (arabizi, alphabet arabe, emprunts,
etc.). Le tunisien est peu étudié malgré une quantité grandissante de
données disponibles notamment grâce à l'essor des réseaux sociaux.

OBJECTIF 

Le stage vise à effectuer :
- un état de l'art approfondi sur la standardisation de l'arabizi, 
- la normalisation d'un corpus issu des réseaux sociaux en arabe
  tunisien (arabizi) : définition d'une norme orthographique de
  l'arabizi, identification des formes les mieux attestées, correction
  du corpus en fonction de la norme établie,
- l'implémentation d'un algorithme de correction orthographique. 

PROFIL ATTENDU 

- M1 ou M2 en Traitement Automatique des Langues, linguistique ou
  informatique, - maîtrise de l'arabe tunisien (arabizi), 
- connaissances en sciences du langage (morphologie, lexicologie), -
  connaissances des problématiques du TAL,
- maîtrise d'un langage de programmation (de préférence Python). 

Pour des raisons pratiques, le/la candidat-e doit déjà être en France ou
doit avoir le droit de travailler en France.

La convention de stage est obligatoire.

CANDIDATURE 

Pour candidater, merci d'envoyer un CV et une lettre de motivation à
asma.zamiti@inalco.fr et mathieu.valette@inalco.fr"
"347","2016-05-26","Lexis Nexis","Paris","STAGE LINGUISTE

LexisNexis France (650 collaborateurs, 150 M¤ de CA), filiale du groupe
Reed Elsevier (30000 collaborateurs, 6,7 milliards de CA et leader de
l'information professionnelle) est un acteur majeur dans les services
d'informations professionnelles. Ses activités couvrent cinq domaines :
l'information et l'édition juridiques, la diffusion de la presse et de
l'information économique et financière sur internet, les formations et
conférences, les logiciels professionnels et les solutions de gestion du
risque, de veille et d'analyse stratégique de l'information.

L'entreprise s'appuie sur une expertise professionnelle centenaire, un
fonds documentaire inégalé et une technologie de pointe pour apporter au
monde du droit et aux professionnels une vaste gamme de produits et
services réputés : JurisClasseur, Litec, Bottin Administratif, D.O et
les services en ligne LexisNexis.

MISSION :
Intégré(e) à l'équipe « Management de l'information»  votre mission
consistera à participer aux activités relatives au textmining, qui
traitent de l'extraction d'information juridique à valeur ajoutée.

PROFIL :

Master en linguistique informatique, avec une forte composante TAL

Compétences requises : 

- Traitement automatique des langues (étude et constitution de corpus,
  moteur de recherche, grammaires locales ...)
- Des connaissances en programmation serait un plus (perl, python)
- Aptitude pour le travail en équipe
- Vous arrivez à comprendre et décortiquer rapidement des informations
  sur un domaine inconnu.
- Vous êtes d'une nature rigoureuse et méticuleuse. Une sensibilité pour
  l'étude du langage juridique serait un plus.
 
LIEU : 
141 rue de Javel
75015 PARIS

DUREE : 
4 mois

MODALITES:
Indemnité mensuelle de 436,05 euros 
50% du titre de transport
Ticket restaurant
Convention de stage obligatoire

CONTACT :
Merci d'envoyer votre candidature (CV + lette de motivation) ainsi que
vos disponibilités par mail à Pascaline BOISSAY :
pascaline.boissay@lexisnexis.fr"
"348","2016-10-03","Viseo R&D","Grenoble","Stage Master 2 (ou équivalent) de Recherche 2016-2017

Viseo R&D, à Grenoble (France)
http://www.viseo.com/fr/offre/recherche-et-innovation

SUJET
Normalisation de messages issus de la communication électronique médiée

CONTEXTE
Au départ contraint par le nombre de caractères maximum utilisables pour
la rédaction d'un SMS et par la difficulté de maniement des claviers,
l'écriture SMS apparaît et se développe rapidement sur les supports de
communication du Web (réseaux sociaux, fora, blogs, etc.). Par exemple,
l'écriture SMS se caractérise par la présence de formes scripturales
très riches : squelettes consonantiques (""slt"" (salut)), apocopes
(""ordi"" (ordinateur)), substitutions phonétisées (""2m1"" (demain)),
binettes/emoji (""^^"", "":)"", :)) - la liste est longue.
Ce non-respect des règles de la langue implique une réelle difficulté
lorsqu'il s'agit d'analyser ces textes avec des outils de traitement
automatique de la langue qui sont généralement conçus pour traiter du
texte correctement écrit, ce qui implique un impact négatif sur la
qualité des résultats à l'issue du traitement. Pour pallier à cette
difficulté, on peut envisager soit d'adapter les outils d'analyse, soit
de normaliser le texte qui sera passé en entrée des outils
d'analyse. Nous choisissons cette deuxième approche dans le cadre de ce
stage.

OBJECTIF DU STAGE
L'objectif de ce stage est de développer un outil performant de
normalisation automatique de texte pour le français. Par exemple, «a2min
lami» devra être normalisé en «à demain l'ami».

Pour atteindre ce but, il sera demandé à l'étudiant de :

1) dresser une typologie des erreurs détectées dans les ressources
   fournies, pour le français (Tweets, Messages de forums, SMS), en
   s'appuyant sur les typologies déjà existantes.
2) proposer des méthodes automatiques de normalisation en fonction des
   types d'erreurs définis à la première étape, avec un intérêt
   particulier porté sur les types d'erreur les plus fréquents. On
   s'inspirera des méthodes déjà existantes (par exemple, fondées sur
   les principes de la traduction automatique, de la reconnaissance de
   la parole, de la correction orthographique, ...).
3) évaluer les méthodes proposées en fonction des différents types de
   textes (Tweets, Messages de forums, SMS).

PROFIL
Ce sujet est destiné aux étudiants de Master 2 (ou équivalent) ayant une
double compétence en Informatique et en Linguistique.

INFORMATIONS COMPLEMENTAIRES
Unité d'accueil : Viseo R&D
  http://www.viseo.com/fr/offre/recherche-et-innovation
Lieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble
Encadrant principal : Cédric Lopez
  http://www.viseo.com/fr/recherche/cedric-lopez
Durée du stage : 6 mois
Stage rémunéré

Merci d'envoyer votre candidature à
cedric.lopez@viseo.com constituée du CV,
de la lettre de motivation, des relevés de notes des 2 dernières années
(M1 et M2)

A PROPOS DE VISEO
Viseo est une entreprise française de services du numérique qui compte
1200 employés en France, Allemagne, Etats Unis, Singapour, Hong Kong et
Maroc. Son centre R&D est situé à Grenoble, à deux minutes à pied de la
gare. De nombreux projets de recherche collaboratifs y sont menés, avec
un intérêt particulier pour l'analyse de données textuelles : projet
SMILK (LabCom ANR)
http://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER
(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)
http://www.synodos.fr, SOMA (EUROSTARS)
http://www.viseo.com/fr/recherche/le-projet-soma, ...
Pour en savoir plus :
http://www.viseo.com/fr/offre/recherche-et-innovation"
"349","2016-10-24","TETIS","Montpellier","Stage de Master Recherche 2016-2017 :
Détermination des itinéraires migratoires contextualisés à partir de récits de vies

Responsables de stage locaux (TETIS) : Mathieu Roche, Maguelonne Teisseire
Autre encadrant (MIGRINTER) : Nelly Robin

Localisation :
UMR TETIS (AgroParisTech, Cirad, Cnrs, Irstea)
500, rue J.F. Breton, 34093 Montpellier Cedex 5, France

Contact :
mathieu.roche@cirad.fr
maguelonne.teisseire@irstea.fr
nelly.robinsn@orange.fr


Contexte du projet QDoSSI

Les migrations internationales ont pris dans le monde contemporain une
ampleur inédite. Cela pose de nouveaux défis à la communauté
scientifique en terme d'analyse et de compréhension des phénomènes
migratoires. Le premier est celui des données et de leurs qualités. En
effet, nombreuses sont les bases de données statistiques sur les
migrations internationales.  Pour aller plus loin dans l'analyse de ce
phénomène complexe et multidimentionnel, la mise en synergie d'autres
types de données est nécessaire. Le projet QDoSSI 1 propose d'étudier
les parcours migratoires d'un point de vue du migrant, considéré comme
un acteur clé dont les droits doivent être respecter et la protection
assurée en toutes circonstances Notre champ d'analyse porte sur
différents types de données collectées par le laboratoire MIGRINTER :
(1) affaires judiciaires (100 000 enregistrements par an sur 10 ans),
(2) corpus juridique des pays d'Afrique de l'Ouest et des Balkans,
carrefours important des circulations migratoires vers l'Europe, (3)
récits de vie (plus de 300), notamment des mineurs en mobilité et des
migrants de Calais, (5) recensement effectué récemment auprès des
personnes déplacées en Syrie (200 000/ 250 000 individus).


Contexte du stage et état de l'art

Dans le cadre du stage, le travail se concentrera sur l'identification
automatique d'""itinéraires contexualisés"" à partir des corpus de
récits de vie par des méthodes de fouille de textes.  De nombreuses
méthodes permettent de reconnaitre les Entités Nommées (EN) en général
et les Entités Spatiales (ES) en particulier (Nadeau & Sekine,
2007). On trouve des approches statistiques consistant généralement à
étudier les termes co-occurrents par analyse de leur distribution dans
un corpus (Agirre et al., 2000) ou par des mesures calculant la
probabi- lité d'occurrence d'un ensemble de termes (Velardi et al.,
2001). On trouve également des méthodes de fouille de données fondées
sur l'extraction de motifs. Ces derniers permettent de déterminer des
règles de transduction utilisant des informa- tions syntaxiques
propres aux phrases pour repérer les ENs (Nouvel et al., 2011). La
plupart des méthodes d'extraction et de désambiguisation d'entités
spatiales exploitent des méthodes mixtes (symboliques et statistiques)
(Kergosien et al., 2014).  Plusieurs travaux se sont intéressés à
l'étude des trajectoires (Yuan & Raubal, 2012) mais peu se concentrent
sur leur identification automatique à partir de données textuelles,
tâche éminemment difficile. Un tel processus s'appuie sur
l'identification de descripteurs linguistiques, en particulier les
verbes (Talmy, 2000) et les indicateurs spatiaux (Zenasni et al.,
2015) et également l'utilisation de connaissances et ressources
externes (gazetteers, ontologies, etc.) (Lieberman & Sa- met,
2012). Dans ce cadre, les travaux de (Moncla, 2015) utilisent ces
différents éléments pour identifier les itinéraires à partir des
textes. L'approche proposée consiste à identifier les informations qui
décrivent les itinéraires dans les textes (entités spatiales,
expressions de déplacement ou de perception) afin de les reconstruire
automatiquement en exploitant des informations géographiques
(latitude/longitude, altitude) et les informations contenues dans les
textes (par exemple, l'ordre d'apparition des entités spatiales)
(Moncla et al., 2016).


Travail à réaliser

Le travail de stage qui sera effectué dans le cadre des projets QDoSSI
et Songes 2 (Science des Données Hétérogènes) s'articulera autour des
tâches suivantes :

1. Il s'agira, dans un premier temps, de compléter l'état de l'art des
approches les plus récentes ayant adopté une démarche similaire.

2. Dans un deuxième temps, une évaluation des approches de l'état de
l'art appliquées aux données des récits de vies sera conduite.

3. Puis des informations thématiques liées à chaque parcours (par
exemple, ""parcours dangereux"", intervention d'une dimension familiale,
financière, etc.) seront extraites à partir des textes et intégrés aux
itinéraires.

4. Enfin, une représentation et une visualisation cartographique des
""itinéraires contexualisés"" sera alors mise en oeuvre.

Références

AGIRRE E.,  ANSA O.,  HOVY E. H. &  MARTÍNEZ D. (2000). Enriching
very large ontologies using the www. In ECAI Workshop on Ontology
Learning.

KERGOSIEN E., LAVAL B., ROCHE M. & TEISSEIRE M. (2014). Are opinions
expressed in land-use planning documents ? International Journal of
Geographical Information Science, 28(4), 739-762.

LIEBERMAN M. D. &  AMET H. (2012). Adaptive context features for
toponym resolution in streaming news. In Proceedings of the 35th
International ACM SIGIR Conference on Research and Development in
Information Retrieval, SIGIR '12, p. 731-740, New York, NY, USA : ACM.

MONCLA L. (2015). Automatic reconstruction of itineraries from
descriptive texts. (Reconstruction automatique d'itinéraires à partir
de textes descriptifs). PhD thesis, University of Pau and Pays de
l'Adour, France.

MONCLA L., GAIO M., NOGUERAS -ISO J. & MUSTIÈRE
S. (2016). Reconstruction of itineraries from annotated text with an
informed spanning tree algorithm. International Journal of
Geographical Information Science, 30(6), 1137-1160.

NADEAU D. & SEKINE S. (2007). A survey of named entity recognition
and classification. Lingvisticae Investigationes, 30(1), 3-26.

NOUVEL D., ANTOINE J.-Y., F RIBURGER N. & SOULET
A. (2011). Recognizing named entities using automatically extracted
transduction rules. In (LTC'2011).

TALMY L. (2000). Toward a Cognitive Semantics. Number vol. 1 in
Bradford book. MIT Press.

VELARDI P., FABRIANI P. & MISSIKOFF M. (2001). Using text
processing techniques to automatically enrich a domain ontology. In
FOIS, p. 270-284.

YUAN Y. & RAUBAL M. (2012). Extracting Dynamic Urban Mobility Patterns
from Mobile Phone Data, In N. XIAO , M.-P. KWAN , M. F. GOODCHILD &
S. SHEKHAR , Eds., Geographic Information Science : 7th International
Conference, GIScience 2012, Columbus, OH, USA, September 18-21,
2012. Proceedings, p. 354-367. Springer Berlin Heidelberg : Berlin,
Heidelberg.

ZENASNI S., KERGOSIEN E., ROCHE M. & TEISSEIRE M. (2015). Discovering
types of spatial relations with a text mining approach. In Foundations
of Intelligent Systems - 22nd International Symposium, ISMIS 2015,
Lyon, France, October 21-23, 2015, Proceedings, p. 442-451."
"350","2016-10-24","TETIS","Montpellier","Stage de Master Recherche 2016-2017 :
Titrage automatique des thématiques identifiées dans les corpus

Responsables de stage locaux (TETIS & LIRMM) : Mathieu Roche, Pascal
Poncelet

Autres encadrants (ERIC & Hubert Curien) : Julien Velcin, Christophe
Gravier

Localisation :

UMR TETIS (AgroParisTech, Cirad, Cnrs, Irstea) 500, rue J.F. Breton,
34093 Montpellier Cedex 5, France

Contact :
mathieu.roche@cirad.fr
pascal.poncelet@lirmm.fr
julien.velcin@univ-lyon2.fr
christophe.gravier@univ-st-etienne.fr


Contexte

De nombreux travaux de fouille de textes permettent (i) de faire
émerger les descripteurs linguistiques les plus significatifs (mots,
syntagmes) à partir d'un corpus puis (ii) de les regrouper. Ceci
permet de mettre en exergue, de manière automatique, les thématiques
abordées dans les textes facilitant l'organisation et l'indexation des
documents, la recherche d'information, la compréhension et l'analyse
des textes, ou même les résumer.  La réalisation du premier point
s'appuie, en grande partie, sur l'utilisation de méthodes d'extraction
de la terminologie à partir de textes (Hasan & Ng, 2014). Les
approches de la littérature combinent des méthodes linguistiques et
statistiques (Frantzi et al., 2000; Pazienza et al., 2005). De tels
travaux ont récemment été proposés dans le cadre d'une collabora- tion
de quatre laboratoires : ERIC (Lyon), Laboratoire Hubert Curien
(Saint-Etienne), LIRMM (Montpellier) et TETIS (Montpellier) (Velcin et
al., 2016).  La deuxième étape du processus consiste à regrouper les
descripteurs linguistiques permettant de mettre en relief les
différentes thématiques abordées dans les textes. Pour découvrir des
structures thématiques ""cachées"" dans les corpus, les méthodes
appelées ""topic models"" sont largement utilisées comme le modèle
probabiliste génératif LDA, i.e. Latent Dirichlet Allocation (Blei et
al., 2003).  Une fois les thématiques identifiées, une des
problématiques aujourd'hui réputée difficile consiste à leur attribuer
un titre à partir de l'ensemble des descripteurs linguistiques
identifiés. Une telle tâche a des similitudes avec les travaux sur le
titrage automatique de textes qui s'appuie sur des méthodes
d'extraction de la terminologie et de génération de textes (Lopez et
al., 2014).


Travail à réaliser

Le travail de stage qui sera effectué dans le cadre du projet Songes 1
(Science des Données Hétérogènes) s'articulera autour des tâches
suivantes :

1. Compléter l'état de l'art des approches les plus récentes ayant adopté une démarche similaire.

2. Proposer et mettre en oeuvre une approche qui se déclinera selon les 4 étapes suivantes :

- Identifier les descripteurs linguistiques (mots, syntagmes) propres
  à chaque topic obtenus avec différentes approches de l'état de l'art ;

- Sélectionner les descripteurs les plus pertinents par filtrage
  statistique et/ou sémantique ;

- Identifier les phrases les plus pertinentes au regard des
  descripteurs sélectionnés à l'étape précédente (approche de
  Recherche d'Information) ;

- Extraire les syntagmes les plus pertinents à partir des phrases
  identifiées à l'étape précédente.

3. Expérimenter les propositions sur des données réelles issues de
divers domaines (actualités, agriculture, etc.). Dans ce contexte, un
protocole d'évaluation devra être défini et mis en oeuvre.  Notons que
la méthodologie proposée pourrait avoir des applications directes pour
d'autres tâches comme le titrage de clusters ou le titrage de nuages
de mots.

Références

BLEI D. M., NG A. Y. & JORDAN M. I. (2003). Latent dirichlet
allocation. Journal of Machine Learning Research, 3, 993-1022.

FRANTZI K. T., ANANIADOU S. & MIMA H. (2000). Automatic recognition of
multi-word terms : the c-value/nc-value
method. Int. J. on Digital Libraries, 3(2), 115-130.

HASAN K. S. & NG V. (2014). Automatic keyphrase extraction : A survey
of the state of the art. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics (Volume 1 : Long
Papers), p. 1262-1273, Baltimore, Maryland : Association for
Computational Linguistics.

LOPEZ C., PRINCE V. & ROCHE M. (2014). How can catchy titles be
generated without loss of informativeness ?  Expert Syst. Appl.,
41(4), 1051-1062.

PAZIENZA M. T., PENNACCHIOTTI M. & ZANZOTTO F. M. (2005). Terminology
Extraction : An Analysis of Linguistic and Statistical Approaches, In
S. S IRMAKESSIS , Ed., Knowledge Mining : Proceedings of the NEMIS
2004 Final Conference, p. 255-279. Springer Berlin Heidelberg :
Berlin, Heidelberg.

VELCIN J., ROCHE M. & PONCELET P. (2016). Shallow text clustering does
not mean weak topics : How topic identification can leverage bigram
features. In Proceedings of the Workshop on Interactions between Data
Mining and Natural Language Processing, DMNLP 2016, co-located with
the European Conference on Machine Learning and Principles and
Practice of Knowledge Discovery in Databases, ECML-PKDD 2016, Riva del
Garda, Italy, September 23, 2016., p. 25-32."
"351","2016-10-24","Cirad","Montpellier","Stage de Master et d'Ingénieur 2016-2017 :

Intégration et visualisation de données issues du projet Patrimoine Numérique
Scientifique du Cirad

Sandrine Auzoux, Sophie Fortuno, Mathieu Roche

Cirad - Campus de Lavalette

sandrine.auzoux@cirad.fr, sophie.fortuno@cirad.fr, mathieu.roche@cirad.fr


Contexte

Le projet Patrimoine Numérique Scientifique (PNS) du Cirad 1 est un
chantier d'Établissement lancé en 2013, qui vise à gérer, conserver et
valoriser les données scientifiques ou données de la recherche
produites par l'établissement et ses partenaires. Dans ce contexte, de
nombreux groupes de travail ont permis de contribuer à
l'identification des données et d'experts pouvant porter/constituer
des cas d'étude thématiques très prometteurs (Roche et al., 2015).  De
manière concrète, les unités de recherche du Cirad 2 se sont fortement
mobilisés pour constituer un inventaire précis de données importantes
du Cirad (cf. Figure 1). Les jeux de données inventoriés contiennent
un certain nombre d'informations (meta-données), par exemple, type de
données, pays d'exécution, couverture temporelle, thématiques Cirad,
auteurs, etc.

FIGURE 1: Interface de l'inventaire des données du Cirad.


Travail à réaliser

Le travail demandé dans le cadre de ce stage, détaillé en section 2,
consiste à (a) intégrer et normaliser les données structurées issues
de l'inventaire et de fournir des visualisations adaptées (Liu et al.,
2014), (b) mettre en relation les données de l'inventaire avec les
publications scientifiques issues d'Agritrop 3 via plusieurs entrées :
informations thématiques (mots-clés), auteurs, informations spatiales,
informations temporelles.

Dans le cadre de ce stage, quatre tâches principales devront être
réalisées :

- Analyse et pré-traitement des données issues de l'inventaire
Cirad. Le prétraitement sera essentiellement dédié à la normalisation
de certaines données et/ou meta-données (par exemple, les mots-clés).

- Mise en relation des données de l'inventaire avec les publications
  d'Agritrop (cf. Figure 2).

- Visualisation des données via les bibliothèques javascript Ext JS 4
  et D3.js (https ://d3js.org/ - cf. Figure 3).

- Rédaction d'un rapport incluant la description détaillée du
protocole reproductible (workflow) sur d'autres en- sembles de données
et métadonnées.

FIGURE 2: Exemple de publication issue d'Agritrop (archive ouverte des
publications scientifiques du Cirad).

L'application sera développée à partir des données de l'inventaire, en
particulier les données de UPR AIDA (Agroécologie et intensification
durable des cultures annuelles) 5 qui a recensé 146 jeux de
données. La généralisation aux autres unités de recherche sera
également effectuée. Une réflexion pour intégrer ces propositions dans
le cadre du projet étendard S TRADIV (System approach for the
TRAnsition to bio-DIVersified agroecosystems) sera également menée.

Références

LIU S., CUI W., WU Y. & LIU M. (2014). A survey on information
visualization : recent advances and challenges. The Visual Computer,
30(12), 1373-1393.

ROCHE M., FORTUNO S., LOSSIO -VENTURA J. A., AKLI A., BELKEBIR S.,
LOUNIS T. & TOURE S. (2015). Ex- traction automatique des mots-clés à
partir de publications scientifiques pour l'indexation et l'ouverture
des données en agronomie. Cahiers Agricultures, 24(5), 313-320.


FIGURE 3: Librairie javascript D3.js."
"352","2016-11-14","Storyzy","Paris","NLP Engineer Internship at Storyzy

-----
Context
-----

Storyzy (http://storyzy.com/) is a startup based in Paris that creates
structured data from the text of news articles by extracting all
information linked to influencers in the news. It is the first 100%
automated content technology driven by what people say thru quotes.

Storyzy (previously Trooclick) was created in November 2012.  Just a few
months later, in April 2013, it received financial support from the BPI
(French public investment bank) and in June 2013 was granted the Status
of ""Young Innovative Company"" (JEI), recognizing its innovative nature
by the French government. Storyzy has invested $3 million in R&D, raised
$900k in August 2016, and employs 12 people (6 engineers).

Due to its growth, Storyzy is now looking for candidates for its office
in the ""Incubateur Boucicaut"" on rue de Lourmel in Paris.

-----
Missions
-----

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

- You will turn ideas into well-documented and reliable linguistic
  resources & code to ensure efficiency, quality, performance and
  scalability
- A great team player, you will interact with other departments to
  understand and fine tune specifications
- You will carry out unitary testing, create and maintain our test
  validation corpus and participate in editing technical documents

Development will be done in English.

-----
Qualifications
-----

- Experience with NLP tools such as NooJ, Unitex or Stanford for
  linguistic annotation, named entity recognition, relationship and fact
  extraction, sentiment analysis, etc.
- Experience in scripting languages such as Perl or Python and with
  database management
- Knowledge of Java and Semantic Web technologies (RDF, OWL, etc.)  will
  be a plus
- Excellent communication skills in English and French

We are open to new ideas that will significantly contribute to our
success.  Our friendly team will provide the opportunity for valuable
collaboration.  We offer you career perspectives in a young and dynamic
company with an interesting and diversified scope of duties at the
cutting edge of research.

We welcome applications from highly motivated individuals able to learn
new techniques and share knowledge and experience with the team.

-----
Contact
-----

Interested? Then send your application to jobs@storyzy.com!

*Audrey Champeau *
*NLP Engineer *
------------------------------
+33 6 86 61 36 50
audrey.champeau@storyzy.com
*Storyzy *Incubateur Boucicaut
130 rue de Lourmel 75015 PARIS storyzy.com (http://www.storyzy.com/)"
"353","2016-11-14","Telecom Bretagne","Brest","--------------
Offre de stage TAL M2 : Étude de l'apport des dépêches AFP à un corpus
de textes de la presse écrite
--------------
Stage financé par le Labex ICCA, projet structurant «Plateformes» 2016
--------------

Le projet 2PI (Modèles économiques de la presse en ligne & pluralisme de
l'information) se propose de comparer, à différents niveaux
linguistiques, des textes provenant de l'agence de presse AFP et
d'autres titres de presse.

Les étapes d'analyse des textes seront :
- extraction terminologique,
- analyse morphosyntaxique,
- annotation sémantique,
- extraction d'entités nommées,
- analyse rhétorique (selon la théorie des arbres discursifs de Marcu).

Selon les outils à disposition, ces étapes seront automatiques ou
semi-automatiques.  L'analyse rhétorique nécessitera le développement
d'outils ad hoc, basés sur des méthodes de machine learning détectant
des marqueurs syncatégorématiques et d'autres propriétés du texte, à
établir. Les données étant temporalisées on étudiera également
l'évolution des propriétés des textes.

En représentant toutes les propriétés linguistiques extraites des textes
du corpus sous forme de graphes, il s'agira de mesurer l'apport des
textes de l'AFP vis-à-vis de celui des textes des autres médias et de
caractériser/quantifier ainsi la notion de «pluralisme des médias».

--------------
Description du poste
---------------
Les tâches principales concernent :
- Analyses et annotations automatiques ou semi-automatiques des textes.
- Développement et évaluation de l'outil d'analyse rhétorique.
- Modélisation des résultats sous forme de graphes et application de
  différentes mesures de similarité entre les sous-graphes induits par
  les données AFP et leurs compléments.

---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique ou
  similaire.
- Programmation en Python (principalement NLTK).
- Curiosité et capacité d'explorer des nouveaux domaines en linguistique
  et/ou informatique.
- Des connaissances en théorie des graphes seraient un plus.

-----------------
Conditions
-----------------
Stage conventionné 6 mois rémunéré

Merci d'envoyer votre candidature à l'adresse
<yannis.haralambous@telecom-bretagne.eu>

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : Département Informatique, Télécom Bretagne (à partir du 1er
janvier 2017 : IMT Atlantique), Brest.

Encadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285 Lab-STICC)
             Inna Lyubareva (Télécom Bretagne et GIS M@rsouin)

Contrat : stage. 

Début : 1er février ou 1er mars 2017, selon les disponibilités du
candidat."
"354","2016-11-14","ELDA","Paris","ELDA recherche un stagiaire (H/F) pour le *Développement d'un moteur de
recherche robuste pour naviguer dans des collections de documents, *à
partir de janvier 2017 pour une durée de 6 mois.

*Profil souhaité*

  * BAC + 5 / Dernière année d'École d'ingénieur ;
  * Connaissances de base en algorithmique ;
  * Connaissances de base des architectures des applications Web ;
  * Maîtrise d'au moins un des langages Python et / ou JavaScript ;
  * Connaissance pratique d'un système de gestion de bases de données
    (PostgreSQL de préférence) ;
  * Anglais technique ;
  * La connaissance d'un moteur de recherche (Solr, Elasticsearch,
    Lucene) sera appréciée.

*Travail à réaliser*

Au sein de l'équipe de développement informatique d'ELDA, sous la
tutelle d'un ingénieur spécialiste des technologies de la langue et du
développement d'applications Web, vous serez amené à participer aux
travaux suivants :

  * faire un état de l'art exhaustif des possibilités offertes
    aujourd'hui par les moteurs de recherche les plus puissants, tels
    que Solr, Elasticsearch, ou bien les facilités de recherche
    textuelle offertes par des SGBD (Système de Gestion des Bases de
    Données) tels que PostgreSQL ;
  * participer à la spécification des besoins de recherche textuelle
    dans les actes de la conférence LREC ;
  * participer au choix de la solution technique la plus appropriée pour
    les actes de LREC ;
  * participer à la conception de la structure d'une base de données
    (schéma de données) pour modéliser le contenu des sites Web
    recensant les articles de la conférence LREC ;
  * extraire les informations pertinentes des sites recensant les
    articles de la conférence LREC et réaliser la mise en données de ces
    informations, utilisant le schéma de données mentionné ci-dessus ;
  * implémenter un moteur de recherche exhaustive à travers tous les
    actes de la conférence LREC, compte tenu des contraintes dégagées
    lors des étapes antérieures ;

Vos participerez également aux réunions périodiques de l'équipe de
développements logiciels d'ELDA.

*Candidature*

Ce stage, d'une durée de 6 mois et basé à Paris dans le 13e
arrondissement (Les Gobelins), est à pourvoir en*janvier 2017*.

Les candidatures (CV, lettre de motivation) doivent être adressées à
Vladimir Popescu (vladimir@elda.org).

Le stage fait l'objet d'une rémunération, variable en fonction du niveau
d'études du candidat.

http://www.elra.info/en/opportunities/internships/
http://www.elda.org"
"355","2016-11-21","Airbus","Toulouse","Internship on ""Natural Language & Speech processing for Virtual
Assistants""

Airbus Human Factor's department is offering an internship on the
topic of ""Natural Language & Speech processing for Virtual Assistants""
(6 months between February and September 2017, located in Toulouse,
France).

We are targeting 2nd- year master students with knowledge and prior
experience in one or several of these domains: natural language
processing, artificial intelligence, human-computer interaction,
psycholinguistics, cognitive science, applied linguistics, computer
science.

Expected soft skills are: multidisciplinarity, scientific rigor,
autonomy, English spoken - fluent French is not required.

The final topic will be decided with the candidate depending on
his/her skills and interests. Possible topics may be (non-exhaustive):

· Definition of test protocols to measure maturity of on-the-shelf
          solutions;

· Comparative study of human-human vs human-machine communications;

· Dialog modelization and creation of resources for human-machine
          dialog systems.

To apply for the position, the candidate should both apply online at
airbus job portal and send an email to Emmanuelle CANNESSON
(Emmanuelle.cannesson@airbus.com) and Estelle DELPECH
(estelle.e.delpech@airbus.com) before end of December 2016.

Link to airbus job portal:

http://www.airbusgroup.com/int/en/people-careers/jobs-and-applications/search-for-vacancies~lang=en~jobid=001A4B0A914A1ED6AAE68925418D010B~.html"
"356","2016-11-23","LSIS","Marseille","Stage financé de Master de 4 à 6 mois - Marseille, DIMAG, LSIS, 
Aix-Marseille Université.

*/De la fouille de données d'interaction médecin-patient à un modèle
computationnel des feedbacks pour un patient virtuel /*

/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)
(LSIS, DIMAG), Roxane Bertrand (LPL http://www.lpl-aix.fr/), Grégoire de
Montcheuil (LPL), et Philippe Blache (LPL).

/Financement /: Projet ANR Acorformed 
(http://www.lpl-aix.fr/~acorformed/index.html)

/Contexte du stage /

Le stage se déroule dans le cadre du projet ANR /Acorformed/qui vise à
développer une plateforme de réalité virtuelle pour former les médecins
à l'annonce d'évènements indésirables graves avec un patient virtuel. Un
des enjeux majeurs de ce projet est de développer un patient virtuel
capable de simuler le comportement d'un patient réel auquel on annonce
une mauvaise nouvelle. Dans ce contexte, le comportement non-verbal du
patient virtuel (mouvements de tête, expressions faciales, postures,
gestes, directions du regard, etc.) joue un rôle prépondérant pour
apporter de la crédibilité au personnage virtuel. L'objectif de ce stage
est de développer un modèle qui permettrait de déterminer à quel moment
le personnage virtuel devrait exprimer quel comportement non-verbal en
réponse au comportement du médecin.

/Sujet de stage /

L'objectif du stage est de développer un */modèle computationnel de
feedbacks pour un personnage virtuel/* qui permettrait de calculer
automatiquement et en temps réel les feedbacks que devait exprimer le
personnage virtuel suivant le comportement de l'utilisateur
(automatiquement détecté dans la plateforme de réalité virtuelle) et le
contexte de l'interaction. Les feedbacks se définissent comme des
réponses multimodales de celui qui écoute suite au message de
l'interlocuteur. Les feedbacks peuvent être verbaux (e.g. humhum, oui)
ou non-verbaux (e.g. mouvements de tête, sourire). Plusieurs travaux de
recherche dans le domaine des personnages virtuels montrent que les
feedbacks permettent d'améliorer la satisfaction et l'engagement de
l'utilisateur. Les feedbacks dépendent du contexte de l'interaction.
Dans le cadre de ce projet, il s'agira de déterminer automatiquement à
quel moment durant l'interaction avec le médecin, le patient virtuel
doit exprimer quel type de feedback.

/Méthodologie/

La méthodologie utilisée pour construire ce modèle reposera sur une
analyse de données réelles. En effet, un corpus de données
audiovisuelles a été collecté dans le cadre du projet ANR Acorformed. Ce
corpus regroupe 2 heures d'interaction entre un médecin et un acteur
jouant le rôle d'un patient à qui on annonce un évènement indésirable
grave. Ce corpus a été entièrement retranscrit et le comportement
non-verbal du médecin et du patient ont été annotés.L'objectif est
d'explorer ce corpus, et en particulier les relations temporelles entre
les signaux verbaux et non-verbaux du médecin (e.g. mouvements de tête,
direction du regard, vocabulaire médical complexe)et les signaux
non-verbaux du patient. Il s'agira par cette analyse de comprendre ce
qui déclenche les feedbacks (signaux verbaux et non-verbaux) du patient
(e.g. est-ce que un changement de direction de regard du médecin
implique un changement de regard du patient ?). Différents algorithmes
de « sequences mining » pourront être explorés pour extraire du corpus
les relations temporelles entre les signaux. Les mesures de qualité des
règles extraites pourront être exploitées pour développer un modèle
stochastique de génération de feedbacks.

/Compétences requises /

Le stagiaire devra à la fois avoir des connaissances techniques (Python,
éventuellement Java), des connaissances en fouille de données et en TAL,
et surtout une ouverture pluridisciplinaire.


Les dossiers de candidatures doivent contenir un CV détaillé, les notes
de Master ainsi qu'une lettre de motivation.

Le dossier est à envoyé à magalie.ochs(at)lsis.org"
"357","2016-11-23","Orange labs","Lannion","Stage sur l'évaluation de librairies open-sources
dans le domaine du Deep-Learning pour le
traitement des séquences ou des textes

ref : 0014352 | 19 oct. 2016

date limite de candidature : 16 déc. 2016

2 avenue Pierre Marzin 22300 LANNION - France

votre rôle

Les récents progrès des techniques d'apprentissage artificielles dites
""Deep Learning"" ont été largement relayés dans les média
récemment. Citons rapidement à titre d'exemple, hors application de
reconnaissance d'image : Watson, pour lequel IBM intègre de nombreuses
techniques différentes dans sa technologie d'assistant intelligent;
les assistants orientés smartphone ou OS de type SIRI, Cortana...; le
nouvel assistant pour mail ""Allo"" de Google, etc... Ces différents
succès reposent en partie sur de nouveaux composants d'apprentissage
artificiels, et pour une autre partie sur les très grandes bases
d'apprentissage maintenant disponibles chez les grands acteurs de
l'internet pour entraîner ces systèmes. Parmi les nouveaux composants,
la classe des LSTM networks (Long Short-Term Memory Networks) et leurs
variantes (GRU...) nous intéressent ici tout particulièrement.

Nous souhaitons répondre à certaines questions quant à la mise en oeuvre
des composants de type LSTM et/ou variantes et leur intérêt à Orange :
Quelles sont les librairies de type LSTM qui pourraient être utilisées
chez Orange ? Quel est le degré de maturité de ces librairies ? Quelles
sont les difficultés de mise en oeuvre ? Comment se comportent les LSTM
sur quelques tâches simples de prédiction de séquences, de Q/A, et
d'extraction d'information ? Pour chaque problème type, et selon les
types de LSTM, comment évoluent les courbes des performances en fonction
du nombre d'exemples ? Peut-on entraîner des LSTM sur des bases de
taille limitées ou moyennes ? Si oui quels types de LSTM le permettent,
avec quels paramètres et quelles performances ?

Nous souhaitons à l'issu de ce stage avoir un premier retour sur
expérience sur l'utilisation de composants de type LSMT, des avantages
et inconvénients des librairies disponibles, leur facilité de mise en
oeuvre, les performances qu'on peut en escompter avec un investissement
de quelques mois (nous ne visons pas l'exhaustivité dans cette étude :
la liste des tâches de tests sera adaptée au format du stage et aux
contraintes techniques rencontrées au fur et à mesure).

Ce stage de 6 mois (durée impérative) sera donc composé des étapes
suivantes :

1. Prises en main et compréhension des LSTM : 1,5 mois.

Un premier compte-rendu sur la prise en main sera effectué à la fin de
cette étape.

2. Construction du benchmark des tâches de test : 1,5 mois.

A partir des jeux de données et des tâches précisées en entrée,
concevoir et coder les scripts d'enchaînement des traitements et
intégrer les composants nécessaires à chaque tâche.

Effectuer les tests unitaires.

Un document technique présentant le code développé sera effectué à la
fin de cette étape.

3. Passage des tests et variations itératives sur le benchmark : 2 mois.

Une fois le benchmark bien rôdé, les campagnes de tests, en faisant
varier les paramètres et les tailles des jeux de données, seront
lancées. Tous les résultats seront consignés et analysés tout au long de
cette étape.

4. Rédaction finale du rapport : 1 mois.

Le rapport compilera les livrables intermédiaires et un bilan des études
effectuées.

Le rapport devra entre autres contenir les points suivants :

- Présentation pédagogiques des LSTM et/ou variantes vues et les
  librairies utilisées,

- Synthèse des difficultés rencontrées aux différentes étapes, synthèse
  des résultats obtenus.

votre profil

Elève ingénieur en 3ème année ou Master recherche en informatique ou
traitement du signal ou équivalent.

Une spécialisation en machine learning sera un plus appréciable.

Vous avez de bonnes connaissances en développement, notamment en Java et
Python.

le plus de l'offre

Afin de gagner du temps, seront donnés dès le début du stage :

- une courte bibliographie sur les LSTM et leurs principales variantes.

- la short-list des librairies à évaluer.

- la description des tâches de tests pour le benchmark.

- pour les tâches portant sur du texte, les éventuels outils de
  prétraitement nécessaires.

entité

Orange Labs Products and Services (OLPS) mobilise désormais l'expertise
de plus de 3300 personnes réparties sur 14 villes en France et à
l'international dans 11 pays.  Elles porteront la responsabilité
technique globale des produits et services proposés par notre Groupe, de
la stratégie à la maintenance des solutions mises en oeuvre partout dans
le monde.

Un challenge de taille que nous relevons tous ensemble dans une logique
de maîtrise des coûts et des délais, avec un environnement de travail
centré autour du client et de l'innovation au service des pays.

Proche de la mer, vous serez dans l'équipe de traitement des données
d'Orange Labs directement en lien avec des problématiques
opérationnelles d'Orange sur le CRM et l'Audience.  Vous évoluerez dans
un contexte très recherche sur un sujet porteur. Vous serez intégré-e au
sein d'une équipe recherche.

contrat

Stage

Durée du stage : 6 mois

Niveau d'études préparées pendant ce stage : Bac+5

Candidatez sur Orange Jobs :

https://orange.jobs/jobs/offer.do?joid=57292&lang=FR"
"358","2016-11-23","Syllabs","Paris","------------------------------------------------------------------------
  Offre de stage : Modélisation d'une base de connaissances (H/F)
------------------------------------------------------------------------

Syllabs est une start-up innovante en plein développement dans le
domaine de la sémantique et du Web. Grâce à un gros effort de R&D et à
une expertise dans le domaine du traitement de l'information, nous avons
développé un ensemble technologique unique au monde comprenant des
solutions de collecte (web mining), d'analyse (text mining) et de
génération de textes (robots rédacteurs). Syllabs développe actuellement
une offre verticale dans le domaine des médias permettant la collecte,
l'agrégation et l'enrichissement de contenus issus de différentes
sources.
Nous développons des outils pour plusieurs acteurs médias (Les Echos, Le
Monde, Slate, Radio France...) dans leur stratégie d'innovation et de
gestion des contenus de même que des sites leaders de l'e-commerce et du
tourisme en France.
Syllabs recrute un(e) stagiaire(e) dont le rôle sera d'organiser les
données d'une base de connaissances afin de mutualiser les données
réutilisées à travers les projets actuels. Les projets de Syllabs étant
de plus en plus complexes, l'organisation des connaissances est un enjeu
fondamental pour nos futurs projets.

--------------------------------
  Description du stage
--------------------------------

La base de connaissance s'appuiera sur un modèle de graphes :
l'information n'est pas seulement portée par des noeuds mais aussi par
les liens.

Plusieurs tâches sont considérées afin de constituer une base de
connaissances fiable :

- Prise en main de la base de connaissances existante, apprentissage des
  bases de graphes,
- Définition des besoins utilisateurs avec les ingénieur linguistes de
  Syllabs
- Identification des domaines et sujets pertinents dans le cadre des
  travaux menés par Syllabs,
- Analyse des données existantes, annotation des sources en domaine,
  sujet, etc.
- Modélisation d'une base de connaissance,
- Intégration des données dans la base de connaissance avec des
  perspectives d'automatisation et/ou d'interfaces d'aide à
  l'intégration
- Éventuellement, collecte de données et cas d'usages avec du datamining.

--------------------------
 Profil recherché
--------------------------

- Méthodique et rigoureux
- Une première expérience de modélisation de base de données est
  souhaitable
- Connaissance d'un langage de script, de préférence Python
- Capacité d'organisation
- Curiosité
- Bonne culture générale et bon sens
- La connaissance des bases de graphes serait un plus

------------
  Divers
------------

- Durée : 6 mois
- Stage conventionné, rémunération supérieure à la rémunération minimale
  + tickets resto + remboursement de la moitié du passe Navigo.
- Télétravail possible le mercredi.
- Bonne ambiance, coin canapé et équipe technique de grande qualité.
- Nos locaux sont situés dans le très agréable quartier de Charonne,
  entre Bastille et Nation, au 35 rue Chanzy (75011), que nous
  partageons avec d'autres start-ups innovantes.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant le titre du stage."
"359","2016-11-23","Syllabs","Paris","------------------------------------------------------------------------
Offre de stage : Ingénieur R&D (H/F) - Recherche d'informations sur le
Web
------------------------------------------------------------------------

Syllabs est une start-up innovante en plein développement dans le
domaine de la sémantique et du Web. Grâce à un gros effort de R&D et à
une expertise dans le domaine du traitement de l'information, nous avons
développé un ensemble technologique unique au monde comprenant des
solutions de collecte (web mining), d'analyse (text mining) et de
génération de textes (robots rédacteurs). Syllabs développe actuellement
une offre verticale dans le domaine des médias permettant la collecte,
l'agrégation et l'enrichissement de contenus issus de différentes
sources.  Nous développons des outils pour plusieurs acteurs médias (Les
Echos, Le Monde, Slate, Radio France...) dans leur stratégie
d'innovation et de gestion des contenus de même que des sites leaders de
l'e-commerce et du tourisme en France.

Syllabs recrute un(e) ingénieur(e) R&D en stage afin de réaliser un
outil de recherche d'informations sur le Web. Possibilité d'embauche à
la fin du stage.

--------------------------------
  Description du stage
--------------------------------

Le stage a pour principal objectif le développement d'un outil qui, à
partir d'une information donnée, ira collecter sur le Web des
informations complémentaires afin de créer une base de connaissance.

Les tâches concerneront principalement :
- la définition d'informations structurées pertinentes par rapport aux
  travaux à Syllabs,
- le déployement d'un outil de collecte de données sur le Web à partir
  de l'existant,
- le développement d'un outil d'extraction d'informations,
- l'analyse et la représentations des informations obtenues,
- les travaux se font sur du français, mais pourraient, si le temps le
  permet, être adaptés à une ou plusieurs autres langues.

Vous intégrerez une équipe dynamique dans un environnement et une
méthodologie de travail structurés : intégration continue (Jenkins),
pull requests via BitBucket, code review, méthodologie Scrum avec des
stand-ups quotidiens.

--------------------------
 Profil recherché
--------------------------

- Bon niveau en programmation Python
- Connaissance de Linux
- Expérience en Traitement Automatique des Langues ou goût pour les
  langues serait un plus

------------
  Divers
------------

- Durée : 6 mois
- Stage conventionné, rémunération supérieure à la rémunération minimale
  + tickets resto + remboursement de la moitié du passe Navigo.
- Télétravail possible le mercredi.
- Bonne ambiance, coin canapé et équipe technique de grande qualité.
- Nos locaux sont situés dans le très agréable quartier de Charonne,
  entre Bastille et Nation, au 35 rue Chanzy (75011), que nous
  partageons avec d'autres start-ups innovantes.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en indiquant
le titre du stage."
"360","2016-11-23","Tracksens","Metz","Offre de stage Ingénieur NLP / Linguistique

Présentation de la société :

TrackSens est une start-up lancée en 2016 qui se spécialise dans le
développement d'outils de traitement automatique du langage à
destination du grand public et des PME. Elle a aujourd'hui identifié
des besoins spécifiques, et doit augmenter ses compétences en
linguistique et en informatique pour pouvoir y répondre.

Domaine de formation recherché :
Linguistique, linguistique informatique.

Mission :

Participer au développement d'outils de traitement automatique du
langage, qui devront permettre l'analyse et la classification
automatique de documents textes aux formats HTML et PDF. Vous
travaillerez en collaboration directe avec un développeur
informatique.

Déroulement du stage :

- Etat de l'art autour de la thématique de la fouille de texte et de
  l'extraction des descripteurs linguistiques d'un corpus de
  documents,
- Evaluation des solutions techniques proposées par les outils
  existants tels que Solr,
- Développement d'un outil de filtration et d'un outil de
  classification automatique de documents,
- Validation sur un corpus de test,
- Programmation en Java et JavaScript,
- Participation aux développements de bases de données.

Le stage permettra d'intégrer une start-up innovante et de participer
à son développement, ainsi que de travailler suivant une méthodologie
Agile avec des outils de gestion de projets informatiques (Jira, SVN
et Maven).

Résultats attendus : 

Une synthèse exhaustive des méthodologies existantes de
classification. Et le développement d'un d'outil simple permettant de
présenter, à termes, un prototype fonctionnel.

Profil recherché : 

Master 2 en Linguistique/Informatique

Compétences en :
o Analyse sémantique et syntaxique
o Statistique
o Algorithmique
o Connaissance de XML, OWL, RDF et SKOS
Bon niveau d'anglais,
Maitrise des outils de bureautique
Connaissance en développement informatique (Java ou C++, base de
données, JavaScript)

Encadrant : Sébastien Albouze, Ingénieur Civil des Mines - fondateur
de TrackSens

Divers : 

Date : à partir du 1er février 2017 (date exacte à définir selon
convenance),

Stage de 6 mois rémunéré (800 ¤ brut/mois)

Lieu : Metz, au sein du tiers-lieu de création et d'innovation de
Metz-Blida (lien),

Stage proposé dans l'objectif d'une embauche.

Contact

CV + lettre de motivation à envoyer à :
Sébastien Albouze
TrackSens SAS
E-mail : sebastien.albouze@orange.fr
Tel : 06-17-07-30-42"
"361","2016-11-28","ELDA","Paris","ELDA recherche un stagiaire pour travailler à la mise en place et au
déploiement d'un framework de services Web pour le TAL. D'une durée de 6
mois, le stage commence en janvier 2017.

*Profil*

 * Niveau : M2 / dernière année d'école d'ingénieur
 * Domaine : informatique
 * Période : à partir de janvier 2017
 * Durée : 6 mois

*Travail à réaliser*

Au sein de l'équipe de développement informatique d'ELDA, sous la
tutelle d'un ingénieur spécialiste des technologies de la langue et du
développement d'applications Web, vous serez amené à participer aux
travaux suivants :

 * faire un état de l'art rapide sur les solutions de déploiement de
   services Web de traitement du langage naturel ;
 * faire un état de l'art sur les gestionnaires de flux de traitement ;
 * participer à la mise en production et au déploiement chez ELDA d'une
   solution à base de services Web orientée traitement des langues ;
 * participer à la spécification d'un ensemble de services Web
   réunissant des traitements spécifiques à certaines plates-formes de
   production d'ELDA ;
 * implémenter les connecteurs entre ces plates-formes de production et
   la solution de déploiement de services Web mise en production chez
   ELDA ;
 * implémenter un moteur de recherche exhaustive à travers tous les
   actes de la conférence LREC, compte tenu des contraintes dégagées
   lors des étapes antérieures ;
 * exposer les plates-formes de production choisies sous forme de
   services Web ;
 * documenter rigoureusement toutes les étapes de ce processus.

Vos participerez également aux réunions périodiques de l'équipe de
développements logiciels d'ELDA.

*Profil souhaité*

 * BAC + 5 / Dernière année d'École d'ingénieur ;
 * Connaissances solides en algorithmique ;
 * Connaissances de base des architectures des applications Web ;
 * Intérêt pour le domaine du Traitement automatique des langues (TAL) ;
 * Connaissances pratiques de programmation en Java (ou Scala, Clojure)
   et / ou Python ;
 * Connaissance pratique d'un logiciel de gestion de versions (Git,
   Mercurial ou SVN) ;
 * Capacités rédactionnelles en anglais technique ;
 * Nationalité d'un pays membre de l'Union Européenne ou droit au
   séjour en France pendant toute la durée du stage.

*Candidature*

Ce stage, d'une durée de 6 mois et basé à Paris dans le 13e
arrondissement (Les Gobelins), est à pourvoir en*janvier 2017*.

Les candidatures (CV, lettre de motivation) doivent être adressées à
Vladimir Popescu (vladimir@elda.org).

Le stage fait l'objet d'une rémunération, variable en fonction du niveau
d'études du candidat.

www.elda.org

*-*-*-*-*-*-*-*-*

Acteur majeur des technologies de la langue, ELDA (« Agence pour la
Distribution des ressources Linguistiques et l'Evaluation ») est une PME
dont les activités s'articulent principalement autour de la distribution
et de la production de ressources linguistiques. ELDA prend en charge
ces activités pour le compte d'ELRA, l'Association européenne pour les
ressources linguistiques, association européenne à but non-lucratif
assurant la promotion des ressources linguistiques dans un contexte
européen.

Ainsi, ELDA apporte son soutien à ELRA pour l'organisation de LREC, la
conférence pour les ressources linguistiques et l'évaluation. Depuis
1998, cette conférence bisannuelle de portée internationale réunit, à
chaque édition, des centaines de chercheurs de premier rang du monde
entier, qui soumettent et présentent des articles de recherche
scientifique.

Afin de faciliter la navigation dans ce thésaurus d'articles
scientifiques, ELDA a mis en place un ensemble de sites Web recensant
ces articles-mêmes, ainsi que des informations les concernant (auteurs,
titres, résumés des articles, etc.).

Dans ce contexte, ELDA souhaite consolider ces sites, en permettant à
l'utilisateur d'effectuer des recherches exhaustives au moyen d'un
moteur robuste dans la totalité des collections d'articles correspondant
à toutes les éditions de la conférence LREC."
"362","2016-11-28","Lab-STICC","Brest","--------------
Offre de stage M2 : Extraction de connaissances dans un corpus de
publications scientifiques et modélisation ontologique des contextes de
citation
--------------
Stage financé par le Lab-STICC UMR CNRS 6285
--------------

Le Lab-STICC (http://www.lab-sticc.fr/) est une UMR CNRS de grande
taille. Ses effectifs atteignent les 600 personnes, reparties dans toute
la Bretagne Océane. Les publications des membres du Lab-STICC ont un
impact important dans un grand nombre de disciplines scientifiques.

Le présent stage vise à modéliser et à qualifier cet impact à travers
les citations des publications des membres du Lab-STICC dans la
littérature scientifique.

Il s'agira donc, dans un corpus de publications tel que ACM Digital
Library ou IEEE Explore, ou HAL/arXiv (en consultant également DBLP,
Google Scholar, etc.), de détecter les publications d'une personne
donnée dans les listes de références bibliographiques, d'accéder au
texte intégral des articles citant la personne en question, d'analyser
par des techniques du traitement automatique de langue (en anglais ou
français) les contextes de citation et de s'en servir pour alimenter une
ontologie ad hoc.

En particulier, il s'agira d'évaluer l'appréciation (explicite ou
implicite) de la citation par l'auteur de l'article.

Différentes mesures seront appliquées à une représentation sous forme de
graphe conceptuel de l'ontologie en question, et permettront d'obtenir
une vision plus riche de l'impact de la recherche des membres du
laboratoire, à divers niveaux de granularité : ils sera possible de
former des requêtes concernant une ou des personne(s), des termes, des
thématiques ou des domaines, et d'obtenir des résultats métrologiques
concrets sur les activités de recherche correspondantes.

--------------
Description du poste
---------------
Les tâches principales concernent :
- Développement de l'outil d'extraction des contextes de citation.
- Analyse linguistique des contextes de citation :
   - morphosyntaxe, 
   - entités nommées, 
   - résolution d'anaphores,
   - alignement avec des ontologies spécifiques au domaine scientifique
     en question,
   - alimentation d'une ontologie ad hoc,
   - détection de sentiment.
- Modélisation des résultats sous forme de graphes contextuels avec
  possibilité de formation de requêtes.
- Comparaison de différentes mesures de graphes pour caractériser
  l'impact scientifique d'une publication, d'une personne ou d'une
  équipe du Lab-STICC.

---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique, Ingénierie
  linguistique, ou similaire.
- Bonnes connaissances en Python (notamment NLTK).
- Curiosité et capacité d'explorer des nouveaux domaines en linguistique
  et/ou informatique.

-----------------
Conditions
-----------------
Stage conventionné 6 mois rémunéré

Merci d'envoyer votre candidature à l'adresse
yannis.haralambous@telecom-bretagne.eu

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : Département Informatique, Télécom Bretagne (à partir du 1er
janvier 2017 : IMT Atlantique), Brest.

Encadrants : Yannis Haralambous (Télécom Bretagne et UMR CNRS 6285
             Lab-STICC)
             Gilles Coppin (Télécom Bretagne et UMR CNRS 6285 Lab-STICC)
             Emmanuel Boutillon (Université de Bretagne-Sud et UMR CNRS
             6285 Lab-STICC)


Contrat : stage. 

Début : 1er février ou 1er mars 2017, selon les disponibilités du
candidat.

-------------------------------------------------------------------------
Message diffuse par la liste Langage Naturel <LN@cines.fr>
Informations, abonnement : http://www.atala.org/article.php3?id_article=48
English version       : 
Archives                 : http://listserv.linguistlist.org/archives/ln.html
                                http://liste.cines.fr/info/ln

La liste LN est parrainee par l'ATALA (Association pour le Traitement
Automatique des Langues)
Information et adhesion  : http://www.atala.org/

ATALA décline toute responsabilité concernant le contenu des
messages diffusés sur la liste LN
-------------------------------------------------------------------------"
"363","2016-11-28","Meteojob","Paris","Meteojob est une société en forte croissance devenue l'un des leaders du
recrutement sur internet en France. Meteojob a pour ambition de
révolutionner la recherche d'emploi en mettant en oeuvre les technologies
les plus avancées dans les domaines du matching, du big data, des
entretiens vidéo différés... Notre vocation est de créer des
applications remarquables qui permettent à des millions de personnes de
trouver plus rapidement un emploi.

Fort de 2,7 millions d'inscrits, et de plus de 600 000 offres d'emploi
par an, le site meteojob.com compte 1 million de VU par mois.

Nous recrutons aujourd'hui de nouveaux talents qui veulent participer à
une aventure humaine et être les moteurs d'un développement important
dans les années à venir.

http://bfmbusiness.bfmtv.com/mediaplayer/video/la-vidaco-va-complatement-transformer-les-processus-de-recrutement-marko-vujasinovic-0405-807438.html

Durée: 6 mois, à commencer suivant disponibilité
Stage conventionné niveau M2
Les travaux s'effectueront au siège de la société, à Paris (M°
Miromesnil)

Ce stage pourra se poursuivre par une embauche dans le pôle
sémantique/big-data de Météojob.

Le candidat participera aux tâches suivantes :
- étude du référentiel existant,
- extraction linguistique à partir des offres d'emploi de compétences
  potentielles,
- mise en correspondance avec les éléments à extraire des offres,
- comparaison/extension avec les données ouvertes (linked-data)
- amélioration des chaînes d'extraction,
- validation

Le référentiel visé est en français mais la méthodologie suivie doit
l'être dans une optique multilingue.

Compétences requises :
- TAL (étude de corpus, moteur de recherche, grammaires locales,
  apprentissage)
- Programmation Java
- Maîtrise de l'anglais
- Des connaissances en langage de scripts (Perl, Groovy), en Spark en
  UIMA ou en bases de données sont des plus
- Facilité à travailler en équipe

Merci d'envoyer votre candidature à juliette.naux@m-executives.com"
"364","2016-11-29","Université de Cergy-Pontoise","Cergy-Pontoise","Analyses sémantiques, linguistiques et statistiques de tweets
politiques : création d'un outil d'analyse lors de campagnes
politiques

Offre de stage de 6 mois (à partir de janvier 2017) en informatique,
linguistiqueinformatique, fouille de données, constitution de corpus,
bases de données

Ce stage se situe dans le cadre du projet de recherche ""#Idéo2017 :
contribution à la création d'un outil d'analyse des tweets politiques
lors de campagnes politiques"" 

http://ideo2017.ensea.fr/

financé par la Fondation de l'université de Cergy-Pontoise

Description :

Twitter est un medium incontournable dans la communication
politique. Dans ce contexte, le projet #Idéo2017 souhaite (1) mieux
connaître et décrire les messages politiques envoyés sur Twitter, mais
aussi (2) rendre ces résultats disponibles pour les citoyens.

Ce projet consiste en la création d'une application web en ligne qui
permettrait de traiter, avec des délais relativement courts, les
messages produits en lien avec l'actualité politique (meetings,
débats, émissions télévisées, etc.). Cet outil s'appuiera sur la
méthodologie de constitution de corpus élaborée dans un précédent
projet (corpus Polititweets) et l'implémentation d'outils de
statistique textuelle et de visualisation de données. Les citoyens ou
journalistes pourraient ainsi effectuer leurs propres requêtes et
obtenir des résultats compréhensibles grâce à cette interface qui
rendra accessible des analyses et critères linguistiques et
informatiques complexes.

Objectifs : 

Les objectifs de se projet concernent deux axes de travail. Dans le
premier axe, l'étudiant devra faire une étude sur les analyses qui
peuvent être réalisées sur des tweets politiques, et éventuellement en
suggérer des nouvelles. Dans le deuxième axe, l'étudiant devra mettre
en place ces analyses sélectionnées dans le cadre d'un site web. Pour
cela, un ensemble de compétences sont requises.

Les objectifs se décrivent de la manière suivante :

1. Etudier l'ensemble d'analyses linguistiques qui existent dans la
littérature et faire une étude comparative.

2. Choisir parmi les analyses étudiées en point 1 celles qui
s'intégreraient dans le futur système d'analyse.

3. Proposer de nouvelles analyses basées sur des techniques de fouille
de données ou apprentissage automatique.

4. Travailler sur la mise en place du système (site web) en suivant les étapes
suivantes :

a. Faire une veille sur tous les frameworks CSS responsive design
(bootstrap, skeleton, Isilex ...) et réaliser une grille comparative
pour expliquer le choix de la solution retenue ;

b. Utiliser l'architecture REST (Representational State Transfer) pour
construire une application type Web Service avec mise à disposition
d'une API vers des partenaires extérieurs ;

c. Installation du serveur elasticsearch et d'un gestionnaire de BD
SQL et NoSql type mysql, mongodb ;

d. Relier dynamiquement les résultats d'Elasticsearch avec des outils
de visualisation, de cartographie, d'analyse de graphes comme Gephi,
et de reporting sous formes de dashboards, de graphiques et de
statistiques comme kibana.

5. Participer à la constitution d'un corpus de tweets #Idéo2017 qui
sera mis en ligne sur un site spécifique du projet hébergé par l'UMR
ETIS http://ideo2017.ensea.fr/ (corpus au format tei-cmc).

Compétences souhaitées :

Compétences dans l'usage des services de Twitter, des notions de
dataviz et de machine learning

Connaissances en fouille de données et bases de données

Usage d'outils de fouille de données textuelles et/ou textométrie

Adaptabilité, curiosité, esprit d'initiatives pour acquérir les
compétences non déjà acquises

Profil : étudiant de M2 en informatique, TAL, fouille de données, ou d'autres
domaines qui couvriraient une partie des compétences attendues.

Responsables de l'encadrement

Julien Longhi, AGORA, julien.longhi@u-cergy.fr (porteur du projet)

Claudia Marinica, ETIS, claudia.marinica@u-cergy.fr

Boris Borzic, ETIS, boris.borzic@u-cergy.fr"
"365","2016-11-30","HumanRoads / LIA","Avignon ou Paris","Offre de sujet Master 2
===

Sujet Stage Master 2 / PFE IngÃ©nieur 2017

HumanRoads / Laboratoire d'Informatique d'Avignon (LIA)

Data mapping d'itinÃ©raires de formation et d'Ã©volution 
professionnelleSystÃ¨mes de recommandations

BenoÃ®t Bonteâ€‹ (HumanRoads), Marc El-BÃ¨ze (LIA), Juan-Manuel Torresâ€‹ (LIA)

HumanRoads (â€‹ http://www.humanroads.comâ€‹ ) cartographie les itinÃ©raires
d'Ã©tudes et d'Ã©volutions professionnelles en se basant sur l'analyse de
millions de CV. Cette carte interactive permet de dÃ©couvrir ses propres
possibilitÃ©s d'emploi ou de formation grÃ¢ce Ã  l'expÃ©rience des autres,
par exemple de voir ce que les autres ont fait aprÃ¨s une formation ou
comment ils sont arrivÃ©s Ã  exercer un mÃ©tier.

Encadrement

Le stage est rÃ©alisÃ© au sein de la sociÃ©tÃ© MillionRoads, Ã©ditrice de la
solution Saas HumanRoads et est encadrÃ© par deux chercheurs du
Laboratoire d'Informatique d'Avignon (â€‹ http://lia.univ-avignon.frâ€‹ ). Il
peut Ãªtre rÃ©alisÃ© de prÃ©fÃ©rence Ã  Avignon mais aussi Ã  Paris.  Un des
objectifs du stage peut-Ãªtre la cartographie des itinÃ©raires des Ã©lÃ¨ves
et anciens Ã©lÃ¨ves de l'Ã©tablissement oÃ¹ l'Ã©lÃ¨ve est inscrit.

ExposÃ© du sujet

Les trajectoires se rÃ©partissent le plus souvent en 2 tronÃ§ons, celui
concernant la formation (label Â« diploma Â») et celui relatif aux
expÃ©riences professionnelles (label Â« job Â»). Il se peut que pour
certaines personnes un de ces 2 tronÃ§ons soit manquant.  Chaque tronÃ§on
s'il est prÃ©sent peut Ãªtre composÃ© d'une ou plusieurs Ã©tapes. Une Ã©tape
est dÃ©crite par deux champs (le contenu et le lieu) auxquels se
rajoutent des Ã©tiquettes temporelles (â€‹ timestamps ) qui sont censÃ©es
indiquer les dates de dÃ©but et fin de l'Ã©tape.  En s'inspirant du
fonctionnement des systÃ¨mes de recommandations (SR), on voudrait Ãªtre
capable de proposer automatiquement une liste courte de propositions Ã 
une personne qui cherche Ã  complÃ©ter sa formation voire Ã  entamer ou
prolonger son parcours professionnel.

Il n'est pas Ã©vident d'Ã©valuer les performances d'un tel SR dans le
domaine des ressources humaines tant qu'il n'est pas encore utilisÃ© sur
une longue pÃ©riode par des milliers de personne. On se contentera de
vÃ©rifier â€‹ a posteriori Ã  quel point on peut prÃ©dire ce qu'une personne a
pu faire Ã  chaque Ã©tape de son parcours.Le problÃ¨me n'est pas simple.

Aussi, pour tenir compte de la durÃ©e impartie Ã  un stage, on se limitera
au dÃ©veloppement de mÃ©thodes que l'on peut qualifier
d'Ã©lÃ©mentaires. Nous allons comparer et combiner plusieurs points de vue
pour tenter d'amÃ©liorer les rÃ©sultats obtenus.  La premiÃ¨re mÃ©thode Ã 
laquelle on pense consiste Ã  ne faire Ã  chaque Ã©tape qu'une proposition,
toujours la mÃªme quelle que soit la personne Ã  laquelle on s'adresse et
quelle que soit sa demande de conseil (job ou diploma). Dans ce cas, il
est clair que pour maximiser les chances de retrouver la bonne Ã©tape, il
faut proposer l'Ã©tape la plus frÃ©quente. On peut d'ailleurs en dÃ©duire
que le taux de succÃ¨s est (avec ou sans biais?)  exactement Ã©gal au
pourcentage d'apparition de cette Ã©tape dans le corpus global.  Pour
engager la responsabilitÃ© des utilisateurs, l'usage s'est plus ou moins
imposÃ© de faire une liste de plusieurs propositions ordonnÃ©es (et non
pas une seule). Si l'Ã©tape rÃ©ellement effectuÃ©e est positionnÃ©e en rang
1 de cette liste on marque un point.  Si elle se trouve en rang 2, on
marque un demi point, en rang 3 un tiers, et ainsi de suite, en suivant
la loi d'une sÃ©rie harmonique. Pour ne pas surcharger l'utilisateur les
listes seront bornÃ©es par une taille maximale (20 par exemple).

La premiÃ¨re idÃ©e qui vient Ã  l'esprit pour amÃ©liorer cette premiÃ¨re
mÃ©thode consiste Ã  trouver un critÃ¨re pour dÃ©couper la population
Ã©tudiÃ©e en plusieurs segments (par exemple deux dans un premier temps :
S1 et S2).

Pour les Ã©tapes de S1, un histogramme plus appropriÃ© que celui de S2 est
utilisÃ© et vice versa. Il s'agit donc de trouver comment subdiviser au
mieux la population des Ã©tapes ou des utilisateurs pour optimiser le
fonctionnement des SR. â€‹ Pour cela, on pourra tenir compte Ã©ventuellement
des indices temporels, et surtout on tentera de s'appuyer sur des
Ã©lÃ©ments clefs (Ã  dÃ©terminer) qui figurent dans les descriptifs du
passÃ©. â€‹ On cherchera par la suite Ã  subdiviser la population en un plus
grand nombre de segments (en veillant Ã  maintenir une taille minimale
dans chaque segment).

Dernier objectif : si dans les stades prÃ©cÃ©dents on a pu employer des
mÃ©thodes qui tiennent compte du passÃ© (par exemple KMeans, Arbres de
dÃ©cision) pour prÃ©dire le prÃ©sent, on veut Ã  prÃ©sent imaginer une
approche qui s'appuie toujours sur l'historique du cursus mais Ã©galement
sur une ou 2 intentions futures. Il conviendra de proposer une mÃ©thode
pour abstraire un point clef du futur, et observer Ã  quel point cette
information additionnelle malgrÃ© ses aspects gÃ©nÃ©riques et donc flous
permet d'amÃ©liorer les performances.

NB : Une Ã©tape de prÃ©-traitement s'avÃ¨re nÃ©cessaire afin d'uniformiser
(normaliser) les multiples variantes de l'information disponible
(majuscules, acronymes, chiffres, dates, etc). Ce prÃ©traitement fera
appel Ã  un nombre limitÃ© de ressources linguistiques, en s'appuyant
surtout sur des techniques statistiques de traitement de l'information.

RÃ©fÃ©rences
Chris Manning and â€‹ Hinrich SchÃ¼tzeâ€‹ , â€‹ Foundations of Statistical 
Natural Language
Processing, MIT Press. Cambridge, MA: May 1999.
http://nlp.stanford.edu/fsnlp/

Contact candidatures

benoit@humanroads.com
marc.elbeze@univ-avignon.fr
juan-manuel.torres@univ-avignon.fr"
"366","2016-12-06","IGN","Saint-Mandé","Annotation automatique en noms de lieux d'un corpus de récits de vie de
migrants

Mots clés
Informatique, TAL, entité nommée spatiale, nom de lieu, apprentissage
automatique

Contexte
Ce stage s'intègre au projet Matriciel : ""Lieux des migrants à travers
des récits de vie : perceptions, émotions, mots, cartes"". Le Réseau
aquitain pour l'histoire et la mémoire de l'immigration (RAHMI) dispose
d'un corpus sonore de nombreux récits de vie de migrants arrivés en
Aquitaine à des époques différentes. Les récits des Espagnols arrivés au
moment de la guerre civile, et ceux des Portugais venus en France pour
travailler à partir de la fin des années 50, ont été regroupés en deux
corpus. Ces entretiens ont été transcrits et l'objectif est de fournir
des outils automatiques pour aider à leur analyse. Dans cette analyse,
l'accent est mis sur l'articulation entre le singulier (le récit d'un ou
quelques individus) et le commun (un lieu, éventuellement associé à un
événement, qui a concerné un ou plusieurs groupes de population), et la
mise en évidence d'éventuels régularités dans les corpus et contrastes
entre les corpus, dans les lieux, les événements, les conditions
d'intégration. Pour cela, un des objectifs du projet Matriciel est de
segmenter le texte sous forme d'épisodes. Les résultats seront ensuite
restitués dans un format cartographique qui permettra de présenter sous
forme synoptique les épisodes dispersés dans les différents récits.
L'analyse s'attache au texte des récits de vie pour y identifier les
lieux et les perceptions associées. Le lieu est ici compris dans un sens
large : le lieu désigné par un toponyme répertorié dans un dictionnaire
de toponymes (le plus souvent un nom propre, par exemple France) mais
aussi celui désigné par un nom générique, éventuellement précisé par un
nom propre et qui permet par exemple d'évoquer les lieux d'arrivée, de
transit, d'asile ; le type d'habitation : la maison, l'appartement, le
meublé, le garni, etc. ; les noms donnés aux lieux de résidence : le
quartier, la cité, etc. La perception associée est, pour le moment, vue
comme une polarité (deux valeurs : positive ou négative) qu'il faut
attacher à un lieu ou à un segment de texte.

Sujet
Le sujet du stage est d'avancer dans l'identification automatique des
désignations des lieux dans les récits transcrits, ainsi que des
sentiments associées à ces lieux. Une première tâche (Brando et
al. 2016) dans ce sens a été fondée sur l'apprentissage supervisé à
l'aide de l'outil Stanford Named Entity Recognition (approche fondée sur
les champs aléatoires conditionnels ou CRF) . Des modèles pour cet outil
ont été entrainés à partir de corpus annotés traitant de thématiques
diverses. Les résultats ont été mesurés à l'aide des mesures de rappel,
précision et F-mesure.
L'objectif du stage est d'améliorer ces résultats. Pour cela, deux
pistes sont envisagées qui conduiront le stagiaire à implémenter deux
types d'expérimentation (il est souhaité que l'ensemble des outils
développés au cours de ce stage soit intégré à l'environnement GATE ) :

- dans l'identification des lieux : le modèle d'apprentissage pourrait
  être amélioré grâce à la personnalisation et la meilleure utilisation
  des différents paramètres de l'apprentissage : étiquettes
  grammaticales, largeur de la fenêtre d'observation, prise en compte
  des variantes orthographiques ;

- dans l'identification des sentiments : des outils fondés sur la
  syntaxe ont été conçus pour l'anglais (Andreevskaia & Bergler 2007 ;
  Ozdemir & Bergler 2015) afin d'identifier automatiquement des termes à
  prendre en compte pour définir la polarité de segments de textes. Ces
  outils seront testés et adaptés pour le français.

Compétences particulières et formation requise
Ce stage s'adresse aux étudiants de master 2 ou de 3ème année d'école
d'ingénieurs avec une spécialisation en informatique (avec un intérêt
réel pour le TAL) ou en TAL (avec une compréhension approfondie du point
de vue informatique des outils de TAL).

Lieu du stage
Institut national de l'information géographique et forestière
73 avenue de Paris
94165 Saint-Mandé Cedex
métro : Saint-Mandé - ligne 1 ou RER A - Vincennes

Durée et rémunération
durée : 5 à 6 mois
début : mars 2017
rémunération : environ 550 euros mensuels

Prolongements éventuels
Le COGIT propose chaque année des sujets de thèse ainsi que des stages
de post-doctorant. Un projet de l'université Concordia à Montréal sur la
thématique de la représentation cartographique des récits de vie de
migrants a débuté en 2016.

Encadrement du stage
Catherine Dominguès
IGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex
mél : catherine.domingues@ign.fr

Carmen Brando
EHESS, 190-198 Avenue de France, 75013 Paris
mél : carmen.brando@ehess.fr

Sabine Bergler
Concordia University, 1455 de Maisonneuve Blvd., Montreal, Canada
mél : bergler@cse.concordia.ca

Pour candidater
Le dossier de candidature sera envoyé par mail à Catherine Dominguès. Il
devra se composer d'un curriculum vitae et d'une lettre de motivation,
accompagnés des relevés de notes des années de M1 et M2 (ou deux
dernières années d'école d'ingénieurs) et d'une description des
enseignements suivis (un lien vers le site internet de la formation est
le bienvenu).

Références
Andreevskaia A., Bergler S. (2007) CLaC and CLaC-NB: Knowledge-based and
corpus-based approaches to sentiment tagging, In: Proceedings of
SemEval-2007: 4th International Workshop on Semantic Evaluations at ACL
2007, Prague
http://www.aclweb.org/anthology/S/S07/S07-1022.pdf
Brando C., Dominguès C., Capeyron M. (2016) Evaluation of NER systems
for the recognition of place mentions in French thematic corpora, In:
Proceedings of the 10th Workshop on Geographic Information Retrieval
(GIR '16). ACM, New York, NY, USA, article 7, 10 pages
DOI: 10.1145/3003464.3003471
Ozdemir C., Bergler S. (2015) A Comparative Study of Different Sentiment
Lexica for Sentiment Analysis of Tweets. In: Proceedings of the
International Conference on Recent Advances in Natural Language
Processing (RANLP 2015), Hissar, Bulgaria
https://www.aclweb.org/anthology/R/R15/R15-1064.pdf"
"367","2016-12-07","INIST","Nancy","L'INIST - INstitut de l'Information Scientifique et Technique du CNRS -
recherche un stagiaire (H/F) pour le ** Test d'outils d'exploration de
corpus textuels **

Mission

Au sein d'une équipe projet, vous participerez à l'exploration et à
l'évaluation de la qualité de corpus textuels issus du fonds
documentaire ISTEX, en testant et en comparant différents outils dédiés
(TXM, TextObserver, Iramuteq, ezvis, etc.).

Profil

De formation documentaire ou TAL, vous êtes à l'aise dans la
manipulation de documents XML et vous êtes intéressé par les méthodes de
statistiques appliquées aux données textuelles (pour aider au
paramétrage des outils et à l'interprétation des résultats).

Dynamique et motivé, vous souhaitez participer à des projets utilisant
des méthodes et des technologies innovantes.

Vous avez le sens du service, une bonne capacité d'assimilation et
d'adaptation, un bon relationnel et l'aptitude à vous intégrer
rapidement dans une équipe préexistante réunissant informaticiens,
documentalistes & utilisateurs.

Vous êtes prêt à travailler en forte interaction au sein d'une équipe
agile selon la méthode Scrum.

Modalités

Stage de 4 à 6 mois, gratification prévue.

Lieu

CNRS - Inist  - http://www.inist.fr/
2, allée du parc de Brabois
CS 10310
F-54519 Vandoeuvre-lès-Nancy
Tél : +33 (0)3 83 50 46 00

Contact

Envoyer CV et lettre de motivation à tania.sourdot@inist.fr"
"368","2016-12-07","Synapse Développement","Toulouse","Offre de stage TAL - Ingénieur / M2R
Sujet: Détection d'incohérences liées à la pragmatique dans un texte

Lieu : Synapse Développement - Toulouse centre
Contact : camille.pradel@synapse-fr.com
Durée : 6 mois
Rémunération conventionnelle + prime sur objectifs

---------------
Contexte
---------------

La société Synapse Développement est leader sur le marché du logiciel
d'analyse de la langue française. Société innovante d'une dizaine de
personnes, Synapse travaille pour le grand public et les grands comptes
comme Microsoft ou Amazon.

Depuis plusieurs années, les activités de R&D de Synapse Développement
s'orientent naturellement vers la compréhension du texte écrit. La
société est notamment identifiée comme un acteur majeur des systèmes de
question-réponse en français et en anglais. Son savoir-faire a récemment
été illustré au cours de la campagne d'évaluation Entrance Exams, dans
laquelle les systèmes sont soumis au test de compréhension de l'anglais
pour l'entrée à l'Université au Japon. Aux deux dernières éditions de la
compétition, la Reading Machine de Synapse a occupé la première
position, à la fois pour le test original en anglais et pour son
adaptation en français (pour laquelle textes et questions ont été
traduits à la main) ; elle est la seule à dépasser la moyenne dans les
deux langues et est donc admise à l'Université !

Au cours des dernières décennies, les travaux de recherche visaient à
surmonter le caractère informel et donc ambigu de la langue
naturelle. On peut considérer que ce verrou a désormais sauté, même si,
sur le plan pratique, le problème est toujours présent lors de
l'implémentation d'un système analysant le langage (la récente
banalisation de l'argot, du langage sms, et la multiplication des
erreurs dans les écrits n'aident pas à la tâche).

Une approche combinant une analyse syntaxique performante, des
ressources linguistiques de qualité et des outils statistiques permet
donc d'extraire de façon efficace la sémantique de ce texte. Cependant,
certains mécanismes cognitifs mis en oeuvre lors de la lecture d'un texte
par un humain sont encore mal imités par la machine, ce qui rend la
lecture automatique d'un texte moins performante d'un point de vue
qualitatif.

La principale limite à la compréhension de textes par la machine est
maintenant pour nous liée au mode d'expression du locuteur humain,
celui-ci ayant tendance à se dispenser de communiquer explicitement des
informations qui sont soit déjà connues du destinataire, soit inférables
par celui-ci.  Il est donc nécessaire pour une machine d'identifier et
de mobiliser ces informations implicites.

---------------
Objectifs
---------------

Dans le cadre du projet DIT (Détection d'Incohérences Textuelles),
Synapse veut concevoir, mettre en place et évaluer une méthode de
détection des incohérences liées à la pragmatique dans un texte. Dans ce
contexte, nous appelons une incohérence liée à la pragmatique une
contradiction entre une assertion d'un texte et des informations issues
d'une base de connaissance considérées comme vraies (ground truth).

Cette base de connaissances sera exprimée selon un formalisme de graphes.
Elle peut être :
 - externe et établie a priori (par exemple DBpedia),
 - ou construite par Machine Reading, soit sur une grande quantité de
   textes selon des approches statistiques, structurant alors des
   connaissances de fonds (background knowledge), soit au fur et à
   mesure de la lecture du texte, ce qui permettrait d'identifier des
   contradictions entre plusieurs assertions d'un même texte.

---------------
Verrous
---------------

Nous identifions deux difficultés majeures dans le travail demandé. La
construction d'une base de connaissances de fond uniquement par Machine
Reading sur de gros volumes de texte soulève le problème de la gestion
de la masse de données et celui de la prise en compte de données
contradictoires et leur fusion dans la base de connaissances. Le premier
problème est déjà en partie résolu par l'utilisation de la base de
données orientée graphe Neo4j, supportant une optimisation verticale.

Au niveau pragmatique, le risque tient à la complexité de la tâche
cognitivo-linguistique d'élaboration d'un schéma de représentation du
texte à des fins de comparaison sémantique. L'analyse du discours se
situe à la frontière de plusieurs disciplines, entre autres de la
psycholinguistique et de l'intelligence artificielle, et la stratégie et
les heuristiques utilisées sont cruciales pour des résultats
pertinents. Une approche agile (succession d'itérations intégrant des
tests et améliorant progressivement l'ensemble du process développé)
permettra de limiter les conséquences de cette difficulté.

---------------
Déroulement
---------------

Intégré-e à l'équipe R&D, le/la stagiaire portera ces thématiques de
recherche en tirant parti des technologies et savoir-faire Synapse. Un
découpage prospectif du travail demandé a permis de définir les tâches
suivantes :

1. Etat de l'art sur la détection d'incohérences liées à la pragmatique.
2. Contributions scientifiques :
    a. Identification ou proposition d'un format pivot de représentation
       d'une base de connaissances.
    b. Proposition du modèle d'intégration des connaissances issues du
       Machine Reading vers le format pivot.
    c. Proposition d'une méthode d'identification de contradictions.
3. Contributions pratiques :
    a. Export d'une base de connaissances externe type DBpedia vers le
       format pivot.
    b. Constitution d'une base de connaissances de fonds par Machine
       Reading.
    c. Implémentation du module de détection d'incohérences
       pragmatiques.
    d. Tests qualitatifs des résultats sur un corpus restreint annoté.

Un article scientifique sera rédigé avec l'équipe R&D et soumis en
atelier ou en conférence, selon l'avancement des travaux."
"369","2016-12-14","LATTICE","Paris","Veuillez trouver ci-dessous plusieurs sujets de stages proposés par le
laboratoire LATTICE.

Pour postuler sur un des stages, merci d'envoyer un CV, un relevé de
notes récent (de préférence M1) et une lettre de motivation (quelques
éléments disant pourquoi vous postulez sur un stage donné dans le corps
du mail suffisent) directement aux personnes indiquées comme
contacts. Tous les stages commenceront début 2017 (entre février et
avril 2017) : il est donc conseillé de postuler rapidement et en tout
état de cause avant la fin décembre 2016. 

Les stages se dérouleront au laboratoire LATTICE, à Montrouge (à 5 mn à
pied de la station de métro Mairie de Montrouge, sur la ligne 4).

Cordialement, 

Thierry Poibeau

-----


- Analyse et suivi de la présidentielle 2017 sur Twitter

Le stage concerne la participation à un projet de suivi de l'actualité
politique, essentiellement à travers le suivi de messages émis sur
Twitter. Le stagiaire sera plus particulièrement en charge de l'analyse
sémantique (en premier lieu à travers les entités nommées) du fil
Twitter (a priori plutôt en français). Les données (tweets) seront
fournies et le travail se concentrera sur les aspects linguistiques et
informatiques. A plus long terme, on s'intéressera aux flux
d'information entre médias sociaux et médias traditionnels.

Stage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant
les règles en vigueur
Compétences en programmation (scripts) et en TAL nécessaires
Contact : Clément Plancq (clement.plancq@ens.fr) et Isabelle Tellier
(isabelle.tellier@sorbonne-nouvelle.fr)


- Annotation d'un corpus de français médiéval au format « Universal
  Dependencies »

Le corpus SRCMF (Syntactic Reference Corpus of Medieval French) est un
corpus arboré en dépendances (Stein & Prevost 2013). Il contient des
phrases annotées en parties du discours et analysées syntaxiquement,
extraites de différents textes en français médiéval datant du 10ème au
13ème siècles. Des expériences d'apprentissage automatique ont commencé
à être menées sur ce corpus pour étudier sa variabilité suivant
différents critères (date d'écriture, domaine, dialecte, forme) : dans
ces expériences, une partie du corpus servait de donnés d'apprentissage
pour un étiqueteur POS et un parser, une autre partie servait de données
de test (Guibon et al. 2014, 2015, 2016). L'objectif de ce stage est
d'abord de transformer ce corpus au format désormais plus standard des «
universal dependencies » (UD : http://universaldependencies.org/
<http://universaldependencies.org/>). Les distinctions prises en compte
dans SRCMF sont en général plus fines que celles requises par les UD, la
transformation ne devrait donc pas poser trop de difficultés. Le stage
se poursuivra en reprenant les expériences d'apprentissage automatique
sur ce nouveau format, pour mesurer son impact sur les résultats.

Stage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant
les règles en vigueur
Compétences en programmation (scripts) et en TAL nécessaires
contact : Isabelle Tellier (isabelle.tellier@sorbonne-nouvelle.fr) et
Sophie Prévost (sophie.prevos@ens.fr) 


- Recherche de motifs pour la caractérisation de corpus

Plusieurs outils de recherche de motifs (ou séquences) dans les textes
par des méthodes non ou peu supervisées ont été mis au point ces
dernières années. Leurs résultats sont souvent difficiles à évaluer car
chaque outil fournit des résultats différents et surtout fournit une
quantité de motifs en général extrêmement volumineuse. Le stage
consistera à partir d'un de ces outils d'extraction de motifs, à
l'appliquer à un ensemble de trois corpus différents (romans
sentimentaux vs romans policiers vs romans contemporains classiques)
pour essayer de proposer une méthodologie permettant d'extraire de la
manière la plus automatique possible les caractéristiques des différents
corpus (caractéristiques propres de chaque corpus, traits communs entre
deux corpus, etc.). Le stage vise à faire des propositions allant dans
le sens d'une stylistique appliquée. On pourra aussi, le cas échéant,
s'intéresser à la représentation des données (cartographie du corpus,
modélisation de liens de proximité entre genres textuels ou entre les
différents romans considérés, etc.)

Stage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant
les règles en vigueur

Compétences en programmation (scripts) et en TAL nécessaires
Intérêt pour la stylistique et la littérature
Contact : Frédérique Mélanie (frederique.melanie@ens.fr) et Thierry
Poibeau (thierry.poibeau@ens.fr)


- Analyse automatique de langues à morphologie riche (komi ou oudmourte)

Le Lattice s'intéresse depuis de nombreuses années aux langues
finno-ougriennes, pour lesquels peu d'outils automatiques sont
disponibles à l'heure actuelle. C'est en particulier le cas de langues
comme le komi ou l'oudmourte (votiak) parlées en Russie. On dispose
actuellement de données relativement volumineuse pour ces langues, de
dictionnaires mais il n'y a pas encore d'analyseurs automatiques (en
particulier de taggeurs), mis à part des outils assez partiels à base de
règles mises au point manuellement. Ces langues posent en outre des
problèmes particuliers dans la mesure où leur morphologie est
particulièrement riche. Le stage vise donc à développer un taggeur pour
une de ces langues (komi ou oudmourte) en reprenant le logiciel SEM
conçu au LATTICE pour l'analyse du français (Dupont et Tellier,
http://apps.lattice.cnrs.fr/sem/).

Stage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant
les règles en vigueur
Compétences en programmation (scripts) et en TAL nécessaires
Connaissance d'une langue finno-ougrienne, si possible komi ou oudmourte
Contact : Thierry Poibeau (thierry.poibeau@ens.fr)



- Modélisation automatique de l'évolution des langues (et application
  aux langues finno-ougriennes)

Le Lattice s'intéresse depuis de nombreuses années aux langues
finno-ougriennes et plus récemment à la modélisation de l'évolution des
langues et des relations entre langues au sein de la famille
finno-ougrienne. Le stage consistera à utiliser des modèles connus, en
particulier le modèle MDL (Minimum Description Length (Grünwald,
2007). On s'inspirera aussi de travaux récents dans le domaine comme
ceux de Nouri et Yangarber (""Modeling language evolution with codes that
utilize context and phonetic features"", CoNLL 2016) et ceux du groupe
Bedlan (http://kielievoluutio.uta.fi/doku.php?id=en:start
<http://kielievoluutio.uta.fi/doku.php?id=en:start>). Le stage vise à
repartir des travaux mentionnés ci-dessus afin de proposer de nouveaux
modes d'analyse et de visualisation des relations entre ces langues.


Stage de 6 mois maximum, de niveau M2, conventionné et indemnisé suivant
les règles en vigueur
Compétences en programmation (scripts) et en TAL nécessaires
Connaissance d'une langue finno-ougrienne
Contact : Thierry Poibeau (thierry.poibeau@ens.fr) et Benjamin Fagard
(benjamin.fagard@ens.fr)"
"370","2016-12-14","ALPAGE","Paris","RÉSOLUTION D'ENTITÉS SCIENTIFIQUES POUR LE TEXT MINING

Type d'offre : Stage M2/Ingénieur en informatique, 6 mois,
avril-septembre 2017, environ 512¤ par mois.

Lieu de travail: INRIA Paris, 2 rue Simone Iff, 75012 Paris

Mots-clés : résolution d'entités, text mining, machine learning,
information scientifique.

À propos d'Inria : INRIA, institut de recherche dédié au numérique,
promeut « l'excellence scientifique au service du transfert
technologique et de la société ». INRIA emploie 2700 collaborateurs
issus des meilleures universités mondiales, qui relèvent les défis des
sciences informatiques et mathématiques. Son modèle ouvert et agile
lui permet d'explorer des voies originales avec ses partenaires
industriels et académiques. INRIA répond ainsi efficacement aux enjeux
pluridisciplinaires et applicatifs de la transition numérique. INRIA
est à l'origine de nombreuses innovations créatrices de valeur et
d'emplois.

Description du stage :

Ce stage a pour cadre un projet retenu dans les « chantiers d'usage »
d'ISTEX au sein du groupe de Laurent Romary (équipe INRIA
Alpage). Notre projet vise à enrichir à grande échelle les corpus
scientifiques ISTEX à l'aide de techniques d'extraction et
d'annotations de documents que nous développons, basées sur des
algorithmes d'apprentissage automatique. Le but de ces traitements est
d'utiliser la littérature scientifique comme une base de connaissance
permettant la génération automatique d'hypothèses scientifiques et
d'assister les scientifiques dans leur travail de recherche.

Les extractions d'information réalisées sur les corpus scientifiques
ISTEX nous permettent d'identifier de façon fiable un volume très
important de métadonnées telles que le nom des auteurs, leurs
affiliations ou encore des mentions de concepts ou de nomenclatures
scientifiques (substances, procédés, etc.). Cependant, au delà de
l'extraction automatique de telles informations brutes, la valeur
ajoutée devient maximale en identifiant de façon univoque à quelles
entités il est fait référence, c'est-à-dire en les liant à des bases
de connaissance faisant autorité (souvent nommées « référentiels » :
base d'auteurs, bases d'institutions, bases de composés chimiques,
etc.).

Notre groupe développe une bibliothèque générique de résolution
automatique d'entités basée sur de l'apprentissage automatique,
impliquant matching flou, graphe, et distances entre structures
hétérogènes. Le travail proposé consiste à appliquer et optimiser
cette bibliothèque sur certaines données extraites du corpus ISTEX et
de l'archive scientifique nationale HAL.

Le stage s'effectuera au sein de l'équipe Alpage de l'Inria Paris.

Formation et expérience souhaitées :

    Dernière année master ou école d'ingénieur en informatique
    Compétences en programmation Java
    Intérêt pour le machine learning
    Capacité à travailler en équipe
    Bon niveau d'anglais 

Contacts : Luca Foppiano - luca.foppiano@inria.fr 
Patrice Lopez - patrice.lopez@inria.fr"
"371","2016-12-14","ALPAGE","Paris","TEXT MINING APPLIQUEÌ AUX ACCORDS D'ENTREPRISE

Type d'offre : Stage M2/IngeÌnieur en informatique, 6 mois,
avril-septembre 2017, environ 500â‚¬ par mois

Lieu de travail: INRIA Paris, 2 rue Simone Iff, 75012 Paris

Mots-cleÌs : text mining, recherche d'information, entiteÌs nommeÌes,
accords d'entreprise

AÌ€ propos d'Inria : INRIA, institut de recherche deÌdieÌ au numeÌrique,
promeut Â« l'excellence scientifique au service du transfert
technologique et de la socieÌteÌ Â». INRIA emploie 2700 collaborateurs
issus des meilleures universiteÌs mondiales, qui releÌ€vent les deÌfis des
sciences informatiques et matheÌmatiques. Son modeÌ€le ouvert et agile
lui permet d'explorer des voies originales avec ses partenaires
industriels et acadeÌmiques. INRIA reÌpond ainsi efficacement aux enjeux
pluridisciplinaires et applicatifs de la transition numeÌrique. INRIA
est aÌ€ l'origine de nombreuses innovations creÌatrices de valeur et
d'emplois.

Description du stage :

Ce stage a pour cadre une collaboration avec la DARES (Direction de
l'animation de la recherche, des eÌtudes et des statistiques) du
ministeÌ€re du travail, de la formation professionnelle et du dialogue
social. La DARES dispose d'un corpus national exhaustif d'accord
d'entreprise d'environ 1 million de documents, qui s'enrichit de
80.000 nouveaux documents par an. Cette base documentaire offre donc
la possibiliteÌ d'analyser et de mieux comprendre les meÌcanismes et
eÌvolutions du dialogue sociale en France sur une base quantitative, et
dans un contexte d'eÌvolution leÌgislatif important. Exploiter au mieux
un tel volume de documents suppose cependant l'utilisation de
techniques de fouille et d'analyse automatiques de textes aÌ€
relativement grande eÌchelle.

L'objectif du stage est d'expeÌrimenter des outils de text mining et de
recherche d'information deÌveloppeÌs par notre eÌquipe INRIA Alpage sur
un sous-ensemble de ce corpus. Nos outils se basent sur des techniques
d'apprentissage automatiques et ne sont pas deÌpendantes d'un domaine
particulier. Cette collaboration est l'opportuniteÌ d'eÌvaluer
l'application de ces outils geÌneÌriques sur le domaine speÌcifique des
accords d'entreprise, ceci recouvrant en particulier la reconnaissance
d'entiteÌs nommeÌes, la disambiguisation et la reÌsolution d'entiteÌs par
rapport aÌ€ un reÌfeÌrentiel comme Wikipedia, l'extraction automatique de
termes et cateÌgories clefs et l'indexation du sous-corpus annoteÌ pour
une interface de recherche seÌmantique. IdeÌalement ce travail mettra en
eÌvidence les capaciteÌs et les limites de nos algorithmes, et donc les
besoins en customisation et reconnaissances d'entiteÌs plus
speÌcifiques.

Le stage s'effectuera au sein de l'eÌquipe Alpage dans les locaux de
l'Inria Paris.

Formation et expeÌrience souhaiteÌes :

    DernieÌ€re anneÌes master ou eÌcole d'ingeÌnieur en informatique
    CompeÌtences en programmation, Java eÌtant un plus
    InteÌreÌ‚t pour l'apprentissage automatique et la recherche d'information
    CapaciteÌ aÌ€ travailler en eÌquipe
    Bon niveau de francÌ§aise et d'anglais technique 

Contacts : Patrice Lopez - patrice.lopez@inria.fr"
"372","2016-12-14","LIMSI","Orsay","Stage de master 2 / Graduate internship
Distant supervision for event extraction from a
newswire corpus

Keywords: natural language processing, text mining, machine learning, distant
supervision.
Ideal starting date: March/April 2017
Duration: 4-6 months
Advisor: Xavier Tannier (LIMSI-CNRS), Olivier Ferret (CEA-LIST)
Location: LIMSI, Orsay, Univ. Paris-Saclay

1 Context

1.1 ANR Project ASRAEL

Information and communication society led to the production of huge volumes
of content. This content is still generally non-structured (text, images, videos)
and the promises of a ""Web of Knowledge"" are still long ahead. This situation evolves with the development of Open Data portals or resources such as
DBPedia, that have made easier the access to information stored in databases
(economic or demographic statistics, world knowledge contained in Wikipedia
infoboxes, etc). However, most of the knowledge is still produced by textual
data. Among the information concerned by the difficulty of accessing textual
data, those related to events are of great interest, notably in the context of
the emergence of data journalism. Data journalism has been fed until now by
publicly available, statistical data, but it has paradoxically made only little use
of the very journalistic materials that are events. The project ASRAEL aims
at bridging this gap.
Our proposal comes within the scope of the general scientific framework of
information extraction (IE). We aim at extracting events from a large set of
textual documents, without prior knowledge about them, and at populating
and publishing a knowledge base of events. This knowledge base will be the
support of a dedicated event search engine.

1.2 Event extraction

We define event in a traditional information extraction way. An event
is a structured representation of something that happens, with a
nucleus, a spatiotemporal context and some arguments. The ""event type""
gathers comparable instances of events, as ""earthquake"", ""election"" or
""car race"". Arguments are attribute/value pairs that characterize an
event type (for an earthquake, its location, date, magnitude,
casualties...). A template is the set of arguments that can describe
an event type (earthquake template, election template). The generic
representation of an event is based on the rule of the ""5 Ws"" (What,
Who, Where, When, Why) that prevails in the ""Anglo-Saxon"" way of
writing articles. This rule stipulates that a good description of an
event must make these five elements explicit.

In automatic information extraction, the information about ""Who"",
""Where"" and ""When"" are extracted by a traditional and quite generic
named entity recognition approach. On the other hand, the ""What"" is
very domain-specific.  For this reason, traditional IE systems lean on
templates predefined by experts and identify events in texts with
either rule-based systems or statistical models.

However, in the general domain, where the huge number of possible
events makes the manual definition of these templates impossible,
information retrieval (""bag of words"") methods take over, but do not
provide a structured answer.

2 Description

The global aim of the ASRAEL project is to build a fully-unsupervised
event extraction system. However, the goal of this proposed internship
can be seen as an intermediate goal, seeking at reducing the amount of
necessary supervision in event extraction.

Agence France Presse (AFP) is one of the partners of the project. They
provide us with their newswire article corpus from 2004 to present, as
well as textual chronologies of events and a few structured datasets
containing the attributes of events of the same kinds (for example, a
list of plane crashes, together with their date, location, plane type,
casualties, cause, etc.).

The intern will work on a distantly supervised system aiming at
consolidating and updating such datasets. The different steps of such
a system will be the following:

1. Use structured instances of events as described in the existing
datasets as seed for a bootstrapping approach;

2. Find textual descriptions of these events in the newswire corpus;

3. Build a classifier from these descriptions;

4. Run the classifier on the entire corpus to find new instances or
news descriptions of existing instances;

5. Build an update procedure for the analysis of new articles.

Two main differences exist between the proposed approach and existing distant
supervision approaches [1, 3]:
- The eventive nature of the relations, making them temporally constrained
and not always true (also explored in [2]);
- The fact to some attributes may not been named entities (e.g. the cause
of a crash).

3 Application

We are particularly interested in candidates with a solid background
in computer science and strong programming skills, having a good
knowledge of machine learning and/or natural language processing.
As most of the data are in French, knowledge of French basics is a plus.
Applications should include:
- Cover letter outlining interest in the position
- Names of two referees
- Curriculum Vitae (CV)
The intern will be given a ""bonus"" (was 546,01 e in 2016) + half a ""Navigo""
(or ""Imagine R"") pass.

Contact for questions and applications:
Xavier.Tannier[at]limsi.fr

3 References
[1] Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. Distant supervision
for relation extraction without labeled data. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing of the AFNLP: Volume
2 - Volume 2, pages 1003-1011, Suntec, Singapore, 2009. Association for
Computational Linguistics.
[2] Kevin Reschke, Martin Jankowiak, Mihai Surdeanu, Christopher Manning,
and Daniel Jurafsky. Event Extraction Using Distant Supervision. In
Proceedings of the 9th International Language Resources and Evaluation
(LREC'2014), Reykjavik, Iceland, May 2014.
[3] Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. Distant Supervision
for Relation Extraction via Piecewise Convolutional Neural Networks. In
Lluis Marquez, Chris Callison-Burch, and Jian Su, editors, Proceedings of
the Conference on Empirical Methods in Natural Language Processing, Lisbon, Portugal, September 2015. Association for Computational Linguistics,
Morristown, NJ, USA."
"373","2016-12-14","LIMSI","Orsay","Stage de master 2 / Graduate internship

Automatic Classification of Claims from Political Debates and
Declarations

Keywords: natural language processing, text mining, machine learning,
computational journalism, fact-checking.

Ideal starting date: March/April 2017
Duration: 4-6 months
Advisor: Xavier Tannier (LIMSI-CNRS)
Location: LIMSI, Orsay, Univ. Paris-Saclay1

Context (ANR Project ContentCheck)

Fact checking is the task of assessing the factual accuracy of claims,
generally made by public figures such as politicians, entrepreneurs,
etc. Fact-checking is part and parcel of journalists' everyday work,
either while working independently on an article, or as part of
vetting done in the newsroom before publication, to prevent the
publication of innacurate information. Modern factchecking is faced
with a triple revolution in terms of scale, complexity, and
visibility: many more claims are made and disseminated through Web and
social media, they represent a complex reality and their investigation
requires using multiple heterogeneous data source. Our project
(https://team.inria.fr/cedar/contentcheck/) brings together academic
labs with expertise in data management, natural language processing,
automated reasoning and data mining, and a fact-checking team of
journalists from a major French Web media.

In recent years, journalists and the computer scientists started
talking to each other in order to identify which technologies could
help journalists' everyday work. This space of exchanges is known as
Computational Journalism [1]. At this level, it encompasses very
diverse uses and tools such as learning how to correctly or better use
a database, producing simple spreadsheet-based visuali1 sations that
are however personalized or better adapted to Web format, optical
character recognition for scanned texts in order to conduct
computer-based keyword search or using statistics to analyse public
data from an interesting point of view, thus highlighting interesting
trends. These latter uses are referred to by the term Data Journalism
[2].

Description

The process of fact checking requires many challenging steps; one of
them is to separate factual claims from opinions, beliefs, hyperboles,
questions, etc. and to discern which are ""check-worthy"", i.e. deserve
to be considered and checked by the journalists [3].

The intern will work on this particular task: (s)he will build a tool
extracting automatically the check-worthy claims and classifying them
between different predefined classes (such as ""doubtful number"",
""doubtful fact"", ""opinion"", ""contextualization needed"", etc.), in
order to make the watch easier for the journalist.

Examples of claims to classify could be:

- ""40 % de la taxe ont été détourné pour rémunérer le capital d'une
société italienne privée"" (number to check)

- ""25 % du chiffre d'affaires d'Amazon se fait le dimanche."" (number
to check) ""On peut continuer à ne vouloir laisser travailler que les
multinationales anglo-saxonnes qui paient peu d'impôts dans notre pays
le dimanche mais ça n'est pas la bonne solution."" (opinion, need for
contextualization)

- ""J'ai été le premier avec Wolfgang Schäuble à signer une lettre pour
que nous soyions capables de mettre en place cette coopération
renforcée à onze."" (fact to check)

- ""Je veux abroger le droit du sol"" (possible contradiction with a
former claim by the same person)

- ""Je ne peux pas accepter que les Etats-Unis soient devenus du point
de vue de l'énergie indépendants grâce au gaz de schiste et que la
France ne puisse pas profiter de cette nouvelle énergie"" (opinion,
need for contextualization)

2 Dataset

A labeled dataset in French will be provided by our partners from the newspaper
Le Monde. It will contains political claims coming from different sources:
- Newspaper articles
- Debates
- Speeches
- Twitter and other social networks
- etc.

Approach

We will model this problem as a classication task and follow a
supervised learning approach to tackle it.

Application

We are particularly interested in candidates with a solid background
in computer science and strong programming skills, having a good
knowledge of machine learning and/or natural language processing.

As most of the data are in French, knowledge of French basics is a plus.
Applications should include:
- Cover letter outlining interest in the position
- Names of two referees
- Curriculum Vitae (CV)
The intern will be given a ""bonus"" (was 546,01 e in 2016) + half a ""Navigo""
(or ""Imagine R"") pass.
Contact for questions and applications:
Xavier.Tannier[at]limsi.fr

3 References
[1] Sarah Cohen, James T. Hamilton, and Fred Turner. Computational Journalism. Communications of the ACM, 54(11):66-71, 2011.
[2] Jonathan Gray, Lucy Chambers, and Liliana Bounegru. The Data Journalism Handbook. O'Reilly, 2012.
[3] Naeemul Hassan, Chengkai Li, and Mark Tremayne. Detecting Checkworthy Factual Claims in Presidential Debates. In Proceedings of the 24th
ACM International Conference on Information and Knowledge Management
(CIKM 2015), Melbourne, Australia, October 2015."
"374","2016-12-14","LIMSI","Orsay","Stage de master 2

Retrouver la source des trending topics sur les réseaux sociaux ou sur le web

Mots-clés : traitement automatique des langues, extraction d'information,
propagation d'information, graphes, Twitter, réseaux sociaux.
Date de démarrage : Mars/avril 2017
Durée : 4-6 months
Encadrant : Xavier Tannier (LIMSI-CNRS)
Lieu : LIMSI, Orsay, Univ. Paris-Saclay1

Contexte 

Les réseaux sociaux tels que Twitter ou Facebook, mais également
certains sites web, sont devenus des sources d'information et de
désinformation massive. De nombreuses rumeurs y sont lancées, des
faits y sont déformés ou manipulés, et ce dans de nombreux domaines,
dans le but de nuire à des personnes ou à des organisations, mais
également de servir des idées politiques.  Le ""fact-checking"" est une
discipline consistant à vérifier la véracité des déclarations faites
par des personnalités publiques ou des rumeurs qui se propagent,
notamment sur les réseaux sociaux. Une tâche importante est de
remonter jusqu'à la source d'une information, pour vérifier si cette
source est unique ou multiple et si elle est digne de confiance ou
pas.

Description

Le travail proposé consiste à réaliser un système semi-automatique
permettant, a partir d'un thème ou d'un document fourni par
l'utilisateur, de remonter dans la mesure du possible jusqu'à la
source de cette information (un tweet, un blog, etc.).  Il s'agira
donc de construire un graphe de citation et de référence basé sur le
contenu textuel des documents (principalement, issus de réseaux
sociaux et de pages web). Des outils déjà existants, comme un
extracteur de citations et de sources dans les articles, pourront être
utilisés.  L'automatisation complète d'un tel système étant un
problème très complexe, nous considérons que la construction de ce
graphe pourra être guidée par l'utilisateur, qui validera ou
invalidera les propositions du système, guidant ainsi la progression
vers la source supposée de l'information.

Profil

Nous recherchons un(e) étudiant(e) intéressé(e) par le traitement de
contenu en langage naturel et par la manipulation de données issue des
réseaux sociaux.  La personne retenue devra avoir des compétences
solides en programmation et la volonté d'apprendre de nouveaux outils
et de nouvelles approches. Elle manipulera les API d'interrogation
Twitter et/ou Facebook ainsi que des outils de traitement automatique
des langues. Les compétences en programmation ne sont cependant pas le
seul critère, et la personne retenue devra également faire preuve de
créativité et d'esprit d'analyse.

Les candidatures doivent comporter :
- Une lettre de motivation
- Le nom de deux personnes référentes
- Un curriculum citae (CV)
Le stagiaire retenu recevra une ""gratification"" (qui était de 546,01 ¤ en 2016)
ainsi que le remboursement de la moitié du pass ""Navigo"" ou ""Imagine R"".
Pour toute question ou candidature: Xavier.Tannier[at]limsi.fr"
"375","2016-12-14","EDF R&D","Chatou","OFFRE DE STAGE : Text-mining (TALN/Analyse sémantique) pour la
maintenance d'éoliennes

SUJET : Fouille de Textes non structurés pour constituer des bases de
données d'événements de maintenance et d'exploitation avec des
techniques de text-mining Traitement Automatique du Langage Naturel
(TALN) et Analyse sémantique.

CONTEXTE
Sur les éoliennes des paramètres issus de capteurs permettent de réguler
et de surveiller le fonctionnement des différents composants de
l'installation et sont historisés dans des entrepôts de données. Lors de
l'observation d'un phénomène inhabituel ou d'un paramètre proche des
limites prévues de fonctionnement, l'exploitant consulte notamment ces
séries de données numériques pour établir un diagnostic et un pronostic
sur le phénomène sous-jacent et ses conséquences prévisibles. Son
objectif est de déterminer si l'exploitation doit être adaptée ou
interrompue pour maintenance ou si elle peut continuer jusqu'à la
prochaine période de maintenance prévue. Pour interpréter les évolutions
de ces paramètres dans le temps, il a besoin de prendre en compte des
informations de contexte sur les opérations de maintenance (c'est-à-dire
événements de maintenance) qui ont été réalisées sur l'installation
ainsi que les événements d'exploitation subis par l'installation. Une
grande partie de ces événements sont présents dans des documents
textuels non structurés ou dans du texte libre d'outils de maintenance.

L'objectif du stage est de contribuer à la reconstitution de bases
d'événements de maintenance et d'exploitation à partir de corpus
textuels non structurés. Il s'agit de mettre en oeuvre des techniques de
fouille de données textuelles ou text-mining non pas statistiques (ou
pas uniquement) mais de traitement automatique du langage naturel (TALN)
et d'analyse sémantique afin de retrouver ces évènements présents dans
les textes pour reconstituer ces bases d'évènements de maintenance et
d'exploitation des installations.

Un événement est une combinaison d'informations, comme par exemple pour
la maintenance, une date, un composant d'un matériel, un type
d'opération de maintenance et une action (prescription, réalisation,
...). Certaines de ces informations peuvent être corroborées par des
informations structurées disponibles dans d'autres parties du système
d'information (base de données de pièces de rechange...). Des documents
peuvent ne contenir aucune des informations recherchées alors que
d'autres documents peuvent en contenir plusieurs qu'il ne faudra pas
mélanger.

OBJECTIF ET DESCRIPTIF DU STAGE
L'objectif est de réaliser un démonstrateur d'extraction d'informations
complexes (événements, ou combinaisons d'informations) à partir de
documents textuels non structurés de maintenance et d'exploitation pour
constituer des bases de données en utilisant des techniques de fouille
de texte de type TALN et d'Analyse Sémantique.

Le travail de stage consiste à :
- modéliser le domaine, la structure des textes, la structure cible des
  données à trouver dans les textes pour constituer les bases.

- mettre en oeuvre les éléments nécessaires dans un ou des outils et
  notamment de réaliser des pré-traitements sur les corpus à analyser,
  d'utiliser des ressources, modèles, annexes, ontologies et notamment
  d'écrire des règles dans le formalisme du logiciel utilisé (logiciel
  de text mining TALN/analyse sémantique).

- positionner la solution mise en oeuvre dans l'étude vis-à-vis des
  autres solutions déjà mises en oeuvre par EDF sur d'autres projets.

ETUDIANTS CONCERNES : MASTER, ou Fin d'études ingénieur.

COMPETENCES SOUHAITEES : La réalisation de cette étude nécessite des
compétences en modélisation des connaissances, en techniques de fouille
de textes, en text-mining de type Traitement Automatique du Langage
Naturel et d'Analyse Sémantique, ainsi que des techniques et outils du
web sémantique, notamment RDF).

INFORMATION ET CANDIDATURE :
En postulant sur cette offre sur le site internet edf recrute :
https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres
La référence de cette offre est : ST-16-8884-SME
Lien vers cette offre :
https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-16-8884-SME

CONDITIONS DU STAGE : Le stage se déroulera au sein des locaux d'EDF R&D
à Chatou et sera rémunéré.

DUREE : 5 mois."
"376","2016-12-14","Forma Libre / LIG","Grenoble","Sujet de stage Master 2 / PFE ingénieur
Prolongement possible avec thèse en contrat CIFRE

Claroline.com http://claroline.com/ / Laboratoire d'Informatique de
Grenoble

Étude et usages d'un système de gestion lexicale intégré à une
plateforme d'apprentissage des langues et acquisition du lexique

Mathieu Mangeot (LIG), Mathieu Loiseau (LIDILEM), Pauline Ballot (Forma Libre)

Encadrement
 
Le stage est réalisé à Grenoble :
- 1 jour par semaine dans l'entreprise Forma Libre
  (http://claroline.com), éditrice de la plateforme http://claroline.net

- 4 jours par semaine au laboratoire LIG, sur le campus de St Martin
  d'Hères.

Il sera encadré par un chercheur du LIG et un chercheur du LIDILEM ;
Une réunion mensuelle de tous les acteurs sera planifiée. Des réunions
supplémentaires pourront être programmées en fonction de l'avancement
des travaux.

Contexte

Le projet de recherche LexInnova est né d'un constat dans le cadre du
projet IDEFI Innovalangues initié en 2012 : le besoin de lexiques dans
les environnements d'apprentissage en ligne. En effet, de nombreux
usages des lexiques ont émergé au cours du projet. Dans le cadre de jeux
où les informations morphologiques sont primordiales, les informations
sémantiques comme la définition ont également été utilisées. Dans
certaines approches, la progression des étudiants est strictement
indexée sur l'acquisition du lexique (Goudin et Lê, 2016). En outre, les
apprenants de langues consultent fréquemment des dictionnaires et, au
fur et à mesure de leurs apprentissages, ils se constituent également un
lexique personnel sur des supports disparates (flash cards, bristol) ou
sur support dématérialisé (Quizzlet, Anki). En classe, des enseignants
distribuent des listes de vocabulaire et créent des exercices à partir
de ces listes. Le lexique apparaît ainsi comme un élément central de
tout environnement d'apprentissage des langues. Par conséquent, la mise
en place d'un lexique commun offrirait des avantages considérables. Les
outils de lexique peuvent être également utilisés par des apprenants
pour toute activité d'apprentissage de manière générale. En effet, la
découverte d'un nouveau domaine est facilitée par la création d'une
terminologie appropriée (Yassine-Diab, Alazard-Guiu et Loiseau,
2016). Par ailleurs, la prise en charge du lexique par l'environnement
d'apprentissage permet à l'apprenant de se focaliser sur d'autres
opérations beaucoup plus fonctionnelles que le recensement du
vocabulaire à des fins d'évaluation sommative. Enfin, un tel outil
permet à la communauté enseignante et apprenante de mutualiser et
réutiliser les données antérieures et/ou partagées.

Enjeux de recherche

Ce constat, effectué dans un premier temps par Emmanuelle Eggers,
enseignante d'espagnol, a donné lieu à la création d'un chantier
émergent au sein du projet Innovalangues et a regroupé une équipe
d'enseignants et chercheurs des laboratoires LIDILEM et LIG travaillant
sur les thématiques de la didactique des langues, des jeux sérieux et
des bases lexicales.

Dans le paradigme institutionnel de la généralisation et de la
massification des apprentissages en ligne, l'enseignement-apprentissage
des langues demeure le parent pauvre comme l'illustre remarquablement
l'existence d'un modeste glossaire sur les plateformes telles que
Moodle. Un tel outil est conçu pour recenser et définir la terminologie
associée à un cours donné, mais pas pour les réutiliser dans d'autres
formations et encore moins pour constituer un lexique systématique dans
le cadre de l'apprentissage d'une langue. Et c'est d'autant plus
dommageable au regard des enjeux de la formation des étudiants à leur «
langue de spécialité »

La mise en oeuvre d'un lexique intégré à une plateforme d'apprentissage
permet d'obtenir un module central au coeur des enjeux et des usages
aussi bien de la communauté apprenante qu'enseignante. En se basant sur
l'observation des pratiques relevées ci-dessus, l'analyse des outils
existants et les premiers résultats du chantier déjà lancé depuis
l'automne 2014, il s'agirait de valider l'hypothèse selon laquelle la
mise à disposition des étudiants d'un outil intégré faciliterait le
développement de la compétence lexicale en langue-cible et
l'autonomisation de l'apprentissage.

Quelques premiers scénarios d'utilisation ont été établis. Ceux-ci ont
donné lieu à la définition de plusieurs concepts liés aux ressources
lexicales : le dictionnaire de référence, somme des informations
validées de la base lexicale ; le lexique institutionnel qui synthétise
le point de vue sur le lexique d'une institution ; le lexique de groupe,
un lexique dynamique qui peut être modifié par un ensemble
d'utilisateurs (groupe d'apprenants) ; le lexique personnel, lexique
d'un apprenant, qui seul pourra modifier son contenu et décider de sa
visibilité.

À la suite de ces réflexions, un premier prototype fonctionnel2 a été
développé en utilisant la plateforme Jibiki (Zhang et
al. 2014). L'interface homme-machine reprend pour l'instant celle de
l'environnement en cours de développement dans le projet
Innovalangues. Seules les fonctionnalités de consultation du
dictionnaire de référence et d'accès au lexique personnel (consultation,
ajout, modification) ont été implantées. Une démonstration a été
effectuée lors du comité de pilotage du projet Innovalangues de janvier
2016. Les réactions du public ont été très encourageantes.

Une publication décrivant ces travaux (Mangeot et al., 2016) a été
également acceptée à l'atelier ELTAL 2016 (Enseignement des Langues et
Traitement Automatique des Langues).

Le projet est maintenant à un tournant : il a montré son intérêt
scientifique à travers une publication et sa faisabilité avec un premier
prototype. Il a ouvert de nombreuses pistes de réflexion pour la
suite. Pour les approfondir dans une démarche de
recherche-développement, il faut intégrer ce prototype à une plateforme
afin d'en observer les usages et de les lier aux retombées en termes
d'acquisition. Pour ce faire, nous nous sommes adressés à l'entreprise
Forma-Libre (dont une antenne a été établie à Grenoble) assurant le
développement et le maintien de la plateforme Claroline Connect utilisée
au sein d'Innovalangues. L'Université Grenoble Alpes (UGA) est également
membre du consortium Claroline Connect.

Intérêt des industriels pour l'outil et l'usage

Si notre problématique majeure ici est celle de l'apprentissage des
langues, la gestion d'un lexique d'apprentissage dépasse largement le
cadre de la didactique des langues. En effet, la généricité de la base
lexicale Jibiki permettra de créer des glossaires techniques pour
n'importe quel domaine de compétence.

Pour l'entreprise Forma-Libre, il s'agit d'une opportunité d'intégrer à
ses produits des outils issus de la recherche de différents laboratoires
de l'UGA, qui bénéficieront ainsi d'une communautés
d'usagers. Forma-Libre pourra ainsi se positionner en tant qu'acteur
majeur du e-learning à travers des outils nettement plus avancés que la
concurrence. Toutefois, le recours exclusif à des technologies libres
permet de ne pas limiter les possibilités de transfert à l'entreprise en
question (il est imaginable que Moodle intègre nos technologies).

L'obtention de financements pour ce projet permettrait de conforter la
dynamique qui s'est mise en place dans le cadre d'Innovalangues et
donnerait un cadre à une collaboration plus poussée sur ces thématiques
entre le LIDILEM, le LIG et des acteurs industriels tels que le
consortium Claroline Connect à travers Forma-Libre.

Travail envisagé

Le travail envisagé dans le contexte du stage de master 2 de 6 mois est
le suivant :

- consolidation et extension du prototype actuel pour une utilisation
  dans des conditions réelles en classe de langue. Emmanuelle Eggers a
  lancé une expérimentation de création de lexique collaboratif avec ses
  étudiants de L2. Celle-ci se fait actuellement avec des fichiers
  Excel. L'objectif est d'utiliser le prototype consolidé pour la
  rentrée de septembre 2017. A des fins comparatives, un relevé
  similaire de ces données - augmentées d'une granularité plus fine avec
  les sinogrammes - est effectué en parallèle en L0 de
  mandarin. Certaines fonctionnalités telles que la gestion des lexiques
  de groupe, la recherche multicritères, les exports de sélections de
  données pour impression, etc. sont indispensables. Pour cette partie,
  il est nécessaire de recueillir les besoins des utilisateurs
  principaux (enseignants de langue) avant l'implémentation.

- réimplémentation du prototype actuel comme module de la plateforme
  Claroline Connect. Dans les deux cas, le langage utilisé est
  PHP. Cette partie pourra se faire dans les locaux de l'entreprise
  Format Libre pour plus de proximité avec les développeurs de la
  plateforme.

- expérimentation : l'utilisation en classe de langue dans les groupes
  d'Emmanuelle Eggers et dans le cadre des cours de mandarin permettra
  le recours à des groupes contrôles pour mesurer les acquisitions (le
  partenariat fort avec des enseignants permettra également d'estimer la
  pérennité des dites acquisitions en réeffectuant nos post-tests de
  manière longitudinale).

Ce travail pourra éventuellement être poursuivi et élargi dans le cadre
d'un doctorat en contrat CIFRE entre l'entreprise Forma Libre et les
laboratoire LIG et LIDILEM (en co-encadrement).

Références
Goudin, Y. et Lê, T.M. (2016). « Jouer avec le sacré ? Le sinogramme à
l'ère du jeu sérieux » Haydée Silva et Mathieu Loiseau (dir.),
Recherches et applications, n°59, pp. 145-160.

Loiseau, M., Zampa, V. et Rebourgeon, P. (2015). « Magic Word : premier
jeu développé dans le cadre du projet Innovalangues », ALSIC, vol. 18,
n°2. DOI :10.4000/alsic.2828. Disponible en ligne :
http://alsic.revues.org/2828.

Mangeot, M., Bellynck, V., Eggerss, E., Loiseau, M. et Goudin,
Y. (2016). « Exploitation d'une base lexicale dans le cadre de la
conception de l'ENPA Innovalangues » Ivan Smilauer et Jovan Kostov
(dir.), Actes de la conférence conjointe JEP-TALN-RECITAL 2016, vol. 9 :
ELTAL, pp. 48-64. Disponible en ligne :
https://jep-taln2016.limsi.fr/actes/Actes%20JTR-2016/V09-ELTAL.pdf.

Zhang Y., Mangeot M., Bellynck V. et Boitet C. (2014). Jibiki-LINKS : a
tool between traditional dictionaries and lexical networks for modelling
lexical resources. Proceedings of the 4th Workshop on Cognitive Aspects
of the Lexicon (CogALex) 2014 (Eds. Michael Zock, Reinhard Rapp, Chu-Ren
Huang), Dublin, Ireland, 23 August 2014, 12 p.

Contact candidatures

Mathieu.Mangeot@imag.fr"
"377","2016-12-19","Cirad","Montpellier","(Version PDF disponible sur http://textmining.biz/Staff/Roche/STAGES/Stages2017/PADI-web_Stage_Master_2017.pdf)

Stage Professionnel de Master 2 (Informatique) - 2017 :

Extension de PADI-Web1

Extension d'un logiciel de veille sanitaire pour analyser
l'émergence et la propagation de maladies animales

Responsables Inra et Cirad : Sylvain Falala, Mathieu Roche
Encadrants liés au projet : Alizé Mercier, Jocelyn de Goër de Hervé
Cirad, Campus de Baillarguet, Montpellier
sylvain.falala@cirad.fr, mathieu.roche@cirad.fr, alize.mercier@cirad.fr,
jocelyn.degoer@inra.fr

1) Contexte

La veille en santé animale, et notamment la détection précoce
d'émergences au niveau mondial d'agents pathogènes, est l'un des
moyens permettant de prévenir l'introduction en France de dangers
sanitaires.

Dans le cadre de la thématique ""Veille sanitaire internationale"" de la
Plateforme nationale d'épidémiosurveillance en santé animale
(Plateforme ESA)4, le Cirad, l'Anses5 et la DGAl6 développent depuis
2013 un système de veille automatique du Web qui effectue : (1) le
recueil quotidien de dépêches épidémiologiques provenant de sources
non officielles, incluant les médias électroniques, (2) l'extraction
automatique d'informations (nom de maladie ou symptômes, lieu, date et
espèce touchée) issues de ces dépêches et (3) une restitution
synthétique et agrégée de l'information : cartes, séries
spatiotemporelles.

Actuellement, cinq maladies animales exotiques sont ainsi surveillées,
mais d'autres pourraient l'être aisément, car l'outil est développé de
façon générique. Ce système sera utilisé par la Plateforme ESA pour la
France et par le réseau de vétérinaires CaribVet situé dans les
Caraibes.

2) Approche et technologies utilisées

Le recueil des dépêches s'appuie sur des requêtes constituées de
mots-clés de maladies, d'hôtes et de symptômes pour collecter, avec un
script PHP, des articles issus de Google News. Ces mots-clés ont été
définis par des experts et/ou par des méthodes de fouille de textes
(Arsevska et al., 2016).  Chaque article est prétraité et normalisé
(suppression de balises HTML, reconnaissance de la langue, etc.) avant
d'être stocké dans une base de données MySQL.  L'extraction
d'information dans les dépêches collectées identifie les éléments clés
(noms de maladies, lieux, dates, nombres et espèces d'animaux
touchées). Elle repose sur des dictionnaires dédiés et des règles
préalablement construites par un processus de fouille de données. La
technologie utilisée est Java.  Une interface Web (développée avec
PHP, HTML, CSS, JavaScript et Ajax) permet de paramétrer le processus
de recueil, de consulter les articles collectés et de récupérer sous
forme de tableaux les informations extraites (cf. Figure 1 et 2).

Figure 1 : interface de recherche multicritères (nom de maladie,
symptôme, hôte, source, période...) pour consulter les articles
recueillis

Figure 2 : interface de consultation d'une dépêche avec identification
automatique des informations clés (lieu, date, maladie, espèce, nombre
de cas...)

3) Travail à réaliser

Plusieurs tâches de différentes natures sont à effectuer, par ordre de
priorité :

1-Gestion des langues (Technologies à utiliser : PHP, Java)
Intégration du français et de l'espagnol au niveau des requêtes et de
l'extraction d'information.

2-Extension de l'interface (Framework Bootstrap, PHP, HTML, CSS,
JavaScript, Ajax) 
Ajout d'outils visuels, notamment une carte mondiale
dynamique indiquant les foyers émergents en temps réel.

3-Classification automatique des documents (Java) 
Intégration de briques logicielles de méthodes de classification
automatique afin d'identifier les documents pertinents à traiter.

4-Optimisation du recueil des documents (PHP)
Parallélisation du moteur de webscraping.
Extensions de la collecte via des réseaux sociaux, en particulier Twitter.

4) Cadre et environnement de travail

Le stage se déroulera au Cirad, sur le campus de Baillarguet, à
Montferrier-sur-Lez, dans l'Unité Animal, Santé, Territoires, Risques
et Ecosystèmes (ASTRE). Le site est accessible depuis Montpellier par
2 lignes de bus.  Le (la) stagiaire sera encadré(e) par des
informaticiens du Cirad et de l'Inra, ainsi que des épidémiologistes
du Cirad et de l'Anses.  Une gratification mensuelle sera attribuée au
stagiaire. Un restaurant d'entreprise sera à sa disposition.

Référence sur la plateforme de veille PADI
http://www.cirad.fr/nos-recherches/resultats-de-recherche/2016/veille-sanitairesur-le-web-un-outil-pour-prevenir-la-propagation-des-maladies-animales

Références

ARSEVSKA E., ROCHE M., HENDRIKX P., CHAVERNAC D., FALALA S., LANCELOT
R. & DUFOUR B. (2016). Identification of terms for detecting early
signals of emerging infectious disease outbreaks on the web. Computers
and Electronics in Agriculture, 123, 104 - 115.

FALALA S., DE GOER DE HERVE J., ARSEVSKA E., ROCHE M., RABATEL J.,
CHAVERNAC D., HENDRIKX P., DUFOUR B., LANCELOT R., LEFRANCOIS T.
(2016). Système de veille sanitaire pour analyser l'émergence et la
propagation de maladies animales. Atelier IN-OVIVE 4ème édition,
Conférence IC2016, 7 juin 2016, Montpellier."
"378","2016-12-19","LATTICE","Paris","Offre de stage en TAL (M1 ou M2) : développement d'un chunker propre à
l'oral à partir d'un corpus de référence corrigé manuellement.

----------------------------------

Au cours des dernières décennies, un nouveau système, les shallow
parsers (analyseurs peu profonds) a été développé pour l'analyse
syntaxique. Aussi appelés chunkers, l'objectif de ces parseurs est de
segmenter l'énoncé en constituants minimaux (chunks) tout en analysant
leur structure interne. Il s'agit d'une analyse syntaxique qui se base
sur les parties du discours, donc sur un étiquetage morphosyntaxique
préalable.

 

Objectif : développer un nouveau chunker par apprentissage automatique
avec les CRFs.

Les données de référence : transcriptions de l'oral annotées en chunks
par TreeTagger, corrigées et adaptées à de nouvelles conventions

Les informations (features) qui peuvent être exploitées pour
l'apprentissage sont :

- mot (token) : Moti-2, Moti-1, Moti , Moti+1, Moti+2

- étiquette POS non corrigée attribuée par un étiqueteur le plus récent
  propre à l'oral :

POSi-2, POSi-1, POSi, POSi+1, POSi+2

- chunk correct : Chunki-2, Chunki-1, Chunki, Chunki+1, Chunki+2

D'autres propriétés seront définies au cours du stage.

---------------------------

Encadrement du stage : Isabelle Tellier (LaTTiCe) et Iris
ESHKOL-TARAVELLA (LLL)

Financement : Projet ANR franco-allemand SegCor

Durée : 6 mois

Début du stage : avril

Lieu : laboratoire LaTTiCe, Paris

------------------------------

Les CV sont à envoyer à isabelle.tellier@univ-paris3.fr et
iris.eshkol@univ-orleans.fr"
"379","2016-12-19","IRSTEA / LIPN","Clermont-Ferrand ou Villetaneuse","Deux stages M2 en Ingénierie des Connaissances et Traitement Automatique
des Langues sont proposés par l'équipe COPAIN de l'IRSTEA
(http://www.irstea.fr/la-recherche/unites-de-recherche/tscf/systemes-information-communicants-agri-environnementaux)
et l'équipe RCLN du LIPN (https://lipn.univ-paris13.fr/fr/rcln-3). Ils
se dérouleront au choix soit à l'IRSTEA à Clermont Ferrand, soit au LIPN
à Villetaneuse (banlieue de Paris).

Au moins une thèse financée démarrera en septembre 2017 sur ces sujets.

Les stages doivent durer 6 mois au maximum. Ils seront conventionnés et
indemnisés suivant les règles en vigueur. Les stages commenceront entre
février et avril 2017, la sélection se fera courant janvier.

Pour postuler sur un des stages, merci d'envoyer un CV, un relevé de
notes récent et des éléments de motivation à Catherine Roussey ET Haïfa
Zargayouna.

Contacts : catherine.roussey@irstea.fr et
haifa.zargayouna@lipn.univ-paris13.fr

Contexte des stages: En France, le Grenelle de l'environnement et le
plan Ecophyto ont renforcé les réseaux nationaux de surveillance sur les
cultures et les pratiques agricoles. Les Bulletins de Santé du Végétal
sont une des modalités mises en place par ces réseaux de
surveillance. Le Bulletin de Santé du Végétal (BSV) est un document
d'information à la fois technique et réglementaire, qui présente une
synthèse interprétée des observations effectuées sur les cultures. Les
informations contenues dans les BSV intéressent les experts en agronomie
pour suivre l'évolution de l'état sanitaire des cultures en France. Dans
le projet VESPA (2012-2016), l'équipe COPAIN a travaillé sur la collecte
du corpus des BSV disséminé sur le Web, puis leur annotation semi
automatique pour permettre de rechercher facilement des BSV répondant à
certains critères (culture, lieu, période, etc.). Le corpus, un
thésaurus des cultures, un jeux de données représentant les régions de
France et des annotations spatio-temporelles ont déjà été publiés sur le
Web des données liées (http://ontology.irstea.fr/).

Sujet 1 : Annotation sémantique de BSV

Le but de ce stage est d'enrichir la base d'annotations existante en
s'aidant d'outils d'annotations automatiques (ou semi-automatiques)
travaillant sur le contenu des BSV. Il s'agit, dans un premier temps, de
déterminer les différents types d'annotations nécessaires, puis de les
classer, par exemple, selon le nombre d'arguments (unaire, binaire,
ternaire), la portée (locale, globale) et la difficulté (en fonction du
traitement/raisonnement requis). En fonction de cette première analyse,
des traitements sur le corpus seront à implémenter afin d'identifier les
structures utiles pour la génération des annotations.

Dans un deuxième temps, il faudra tester des outils de l'état de l'art
(tel que l'outil OMTAT développé au LIPN
http://tal.lipn.univ-paris13.fr/omtat/). Ces tests ont un double
objectif : d'une part, repérer les types d'annotations traités par ces
outils et d'autre part évaluer la couverture des référentiels dont nous
disposons. 
La phase de test sera suivie par une phase d'enrichissement
semi-automatique des annotations.


Sujet 2 : Alignement de référentiels agricoles fondé sur les textes

Le but du stage est de développer des bases de connaissances intégrant
des référentiels déjà disponibles sur le LOD. 
Il s'agit, dans un premier temps, d'extraire des relations de
correspondance (autres que l'équivalence) entre les référentiels
sémantiques existants (thésaurus des cultures, plant trait ontology, ..)
au regard du corpus BSV. 

Ce travail s'appuiera sur les méthodes et outils développés au LIPN et
plus particulièrement la méthode d'alignement d'ontologies à partir de
textes (TOM : Text-based Ontology Mapping) proposée dans le cadre de la
thèse de Sarra Ben Abbes [Ben Abbes, 2013].

Dans un deuxième temps, il s'agit de s'appuyer sur les correspondances
produites pour proposer des transformations de sources en s'aidant de
patrons de conception ontologique du domaine (thèse de Fabien Amarger
[Amarger, 2015]) ainsi que des anti-patrons destinés à détecter les
erreurs et anomalies dans les ressources."
"380","2017-01-03","IRIT","Toulouse","Offre de stage M2 :

Détection automatique de comportements dépressifs dans les réseaux
sociaux

Encadrement : Farah Benamara (benamara@irit.fr), Josiane Mothe 
(josiane.mothe@irit.fr),
Véronique Moriceau (moriceau@limsi.fr) & Faneva Ramiandriosa 
(r.faneva.mahery@gmail.com)

Localisation : IRIT, Toulouse

La dépression est une affection courante qui concerne environ 350
millions de personnes dans le monde selon les estimations de l'OMS
(Organisation Mondiale de la Santé). La détection de ce trouble est donc
un enjeu majeur de santé publique.  Plusieurs recherches ont démontré
l'existence d'un lien fort entre l'état dépressif d'un individu et son
expression langagière, comme l'usage excessif de pronoms personnels,
l'expression d'émotions négatives ou encore le changement brusque dans
la communication [1][2]. Nous proposons dans ce stage de repérer
automatiquement ces indices dans le but de détecter les comportements
dépressifs à partir de messages postés sur les réseaux sociaux. Les
données utilisées seront issues de collections existantes en particulier
en lien avec le challenge CLEF [3].
Un des enjeux est de détecter le moment à partir duquel la personne peut
être reconnue comme dépressive si elle l'est. Une soumission à la tâche
correspondant du programme international CLEF sera envisagée, en
fonction des résultats obtenus.

Contact : envoyer CV à josiane.mothe@irit.fr, benamara@irit.fr,
moriceau@limsi.fr


Références
[1] J. W. Pennebaker, M. R. Mehl, and K. G. Niederho er. Psychological
aspects of natural language use: Our words, our selves. Annual Review of
Psychology, 54(1):547--577, 2003.
[2] Munmun De Choudhury, Michael Gamon, Scott Counts, Eric Horvitz:
Predicting Depression via Social Media. Proceedings of the Seventh
International AAAI Conference on Weblogs and Social Media. 2013
[3] David Losada, Fabio Crestani, A Test Collection for Research on
Depression and Language Use, Conference and Labs of the Evaluation
Forum, 2016."
"381","2017-01-03","LIPN","Villetaneuse","Stage M2: Entraînement LASO pour l'analyse en dépendances ""easy-first""
------------------------------------------------------------------------

1 Contexte scientifique
-------------------------

  L'algorithme /easy-first/ pour l'analyse en dépendances [1]est un
  algorithme glouton qui construit les arbres d'analyse de manière
  ascendante en prenant les décisions les plus faciles, celles qui
  nécessitent le moins de contexte, en premier de façon à donner plus
  d'informations aux décisions ultérieures. Durant la phase
  d'apprentissage, on cherche des séquence d'actions de construction qui
  soit en accord avec les arbres observés dans le corpus
  d'entraînement. Si l'une des actions génère un sous-arbre invalide,
  alors le modèle est mis à jour (par exemple par une mise à jour de
  type perceptron). L'algorithme d'apprentissage proprement dit
  (ex. perceptron) se combine donc à une exploration des différentes
  possibilités de construction incrémentale des structures.

  Dans ce stage, on propose de reformuler le problème de l'apprentissage
  pour ce type de problème en suivant le paradigme LaSO (/learning as
  search optimization/)[2] qui modélise précisément les problèmes
  d'apprentissage structuré nécessitant la recherche d'une structure
  intermédiaire avant sa validation par une observation, ici la séquence
  d'actions permettant de construire un arbre d'analyse. le stage aura
  aussi pour but de mesurer l'apport de l'utilisation d'un réseau de
  neurones récurrent pour la prédiction de la séquence d'actions à
  effectuer.

  Profil recherché: Niveau M2, bonne connaissance d'un langage de
                    programmation (python ou c++ idéalement), un intérêt
                    fort pour l'apprentissage automatique appliqué au
                    traitement automatique des langues.


2 Administratif
-----------------

  Le stage aura lieu au LIPN (CNRS - Université Paris13 - Paris Sorbonne
  Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le Roux
  et/ou Nadi Tomeh.  Le/La stagiaire fera partie de l'équipe de
  recherche RCLN, membre du labex EFL (axe ""sémantique
  computationnelle""), dans la structure de recherche fédérative MathSTIC
  de CNRS/Paris 13 (axe ""Optimisation et Apprentissage pour les contenus
  numériques"").

  Les candidatures (CV et lettre de motivation) doivent être adressées à
  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17."
"382","2017-01-03","LIPN","Villetaneuse","Stage M2: Paramétrisation CRF neuronal pour les analyseurs en
dépendances de type graphe


1 Contexte scientifique
-------------------------

  L'analyse syntaxique en dépendances est une tâche essentielle en
  traitement automatique des langues. Récemment, l'utilisation de
  réseaux de neurones récurrents a permis un regain d'intérêt pour les
  modèles d'analyse structurellement plus simples, par exemple le
  système de Kiperwasser et Goldberg[3]. la notion de contexte étendu
  est très bien gérée par les réseaux, et le système grammatical n'a
  plus à prendre en compte ces contextes en interne, puisqu'ils lui sont
  donnés via les plongements lexicaux (/word embeddings/).

  Le but de ce stage est d'étudier la paramétrisation d'un analyseur en
  dépendances projectives par un modèle probabiliste de type CRF (champs
  de Markov aléatoire), où les potentiels sont calculés par des réseaux
  de neurones. Un tel système a déjà été proposé pour les grammaires
  syntagmatiques. D'autre part des systèmes neuronaux ont déjà été
  proposés pour l'analyse syntaxique en dépendances mais jamais avec un
  modèle probabilistes global.

  Profil recherché: Niveau M2, bonne connaissance d'un langage de
                    programmation (python ou c++ idéalement), un intérêt
                    fort pour l'apprentissage automatique appliqué au
                    traitement automatique des langues.


2 Administratif
---------------

  Le stage aura lieu au LIPN (CNRS - Université Paris13 - Paris Sorbonne
  Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le Roux
  et/ou Nadi Tomeh.  Le/La stagiaire fera partie de l'équipe de
  recherche RCLN, membre du labex EFL (axe ""sémantique
  computationnelle""), dans la structure de recherche fédérative MathSTIC
  de CNRS/Paris 13 (axe ""Optimisation et Apprentissage pour les contenus
  numériques"").

  Les candidatures (CV et lettre de motivation) doivent être adressées à
  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17."
"383","2017-01-03","LIPN","Villetaneuse","Stage M2 : Réseaux de neurones avec attention pour la correction
d'orthographe et de grammaire


1 Contexte scientifique
-------------------------

  La correction automatique d'orthographe et de grammaire est un
  problème difficile et important en traitement automatique des
  langues. Elle facilite la construction de logiciels d'aide à
  l'apprentissage de langues étrangères, comme elle permet de réduire le
  bruit dans l'entrée des outils de TAL ainsi améliorant leurs
  performance, notamment sur les textes non-édités que l'on peut trouver
  sur le web. La difficulté de cette tâche provient de la grande
  variabilité dans les types d'erreur ainsi que leur dépendance
  syntaxique et sémantique vis-à-vis du contexte.

  Étant donné une phrase potentiellement erronée en entrée, certaines
  approches utilisent des classifieurs (à base de règles ou appris
  automatiquement) pour générer des corrections, en modélisant leurs
  interactions avec, par exemple, un modèle de langue N-gram ou un
  CRF. Les systèmes de traduction automatique statistique dits
  phrase-based ont été utilisés avec succès dans ce contexte, notamment
  grâce à la disponibilité croissante de données corrigées
  manuellement. Néanmoins, leur défaut majeur est la difficulté de
  modéliser proprement des corrections à différentes granularités
  (caractères/mots/etc.) qui s'avère nécessaire pour réduire le taux de
  mots inconnus nuisibles à leur bon fonctionnement. Plus récemment,
  l'utilisation de réseaux de neurones a entraîné des gains
  significatifs pour les tâches de ""mapping"" entre paires de séquences,
  y compris celles de la traduction et de la correction d'orthographe,
  ceci grâce à leur capacité d'apprendre une meilleure représentation
  des données ainsi qu'une meilleur prise en compte du contexte.

  Dans ce stage, on propose d'étudier une nouvelle architecture de
  réseau de neurones combinant des informations au niveau des caractères
  et des mots grâce à la possibilité d'empiler facilement différents
  réseaux. En particulier, un réseau convolutif peut être utilisé pour
  apprendre des embeddings à partir des caractères, que l'on combine
  avec des embeddings de mots pour alimenter une ou plusieurs couches de
  réseaux récurrents de type encodeur-décodeur. On propose également de
  comparer différents modèles d'attention (global, local, etc.)  pour
  mieux modéliser le contexte.

  Profil recherché: Niveau M2, bonne connaissance d'un langage de
                    programmation (python ou c++ idéalement), un intérêt
                    fort pour l'apprentissage automatique appliqué au
                    traitement automatique des langues.


2 Administratif
---------------

  Le stage aura lieu au LIPN (CNRS - Université Paris 13 - Sorbonne
  Paris Cité) du 01/04/2017 au 30/09/2017 et sera encadré par Joseph Le
  Roux et Nadi Tomeh. Le/La stagiaire fera partie de l'équipe de
  recherche RCLN, membre du labex EFL (axe ""sémantique
  computationnelle""), dans la structure de recherche fédérative MathSTIC
  de CNRS/Paris 13 (axe ""Optimisation et Apprentissage pour les contenus
  numériques"").

  Les candidatures (CV et lettre de motivation) doivent être adressées à
  Joseph Le Roux (leroux@lipn.fr) avant le 15/1/17."
"384","2017-01-03","IDIAP","Martigny (CH)","Internship in Natural Language Processing: DNN-based coreference models

NLP Group, Idiap Research Institute, Martigny, Switzerland


Applications are invited for a 6-month internship at the Master level in
the field of natural language processing with neural networks, in the
NLP group of the Idiap Research Institute (www.idiap.ch/nlp).

The goal of this internship is to explore new data structures that would 
enable a better modeling of co-reference by using (deep) neural networks 
(DNNs).  Co-reference is the relation between words or phrases in a text 
that refer to the same entity.  DNNs have been successfully applied to a 
variety of NLP tasks, but for coreference resolution such approaches 
have shown limited improvement and a suitable model remains to be found. 
  The goal of this internship is to go beyond classifiers that decide 
whether a pair of phrases is co-referent or not, and instead learn to 
represent, in the output layer, each of the entities of a text.  In 
collaboration with a PhD student and a postdoc, the model will be 
applied to document-level machine translation.  The work will thus 
relate to the EU SUMMA and SNSF MODERN projects.

The applicants should have a background in natural language processing,
machine learning, or computer science. They should have demonstrable
programming skills in at least one language such as Perl, Python, Java
or C/C++.  Previous experience with coreference or anaphora resolution
would be a plus. Good command of English is mandatory and knowledge of
another European language such as French, Spanish, or German would be
appreciated.

The screening of the applications will start on January 15, 2017, and
will continue until the position is filled.  The preferred starting time
is in spring 2017.  The appointment is for 6 months, with a gross
internship salary of 2000 CHF per month.


*How to apply*

Please fill in and submit your application through the Idiap online 
recruitment system, by clicking on the position's title at 
http://www.idiap.ch/education-and-jobs.


*Contact information*

Further information about this position can be requested via the Idiap
online recruitment system or by contacting Dr. Andrei Popescu-Belis,
head of the NLP group (Andrei.Popescu-Belis@idiap.ch).

Idiap Research Institute
Rue Marconi 19 - CP 592
CH-1920 Martigny, Switzerland


*About the host institution*

Idiap is an independent, non-profit research institute recognized and 
supported by the Swiss Government, and affiliated with the Ecole 
Polytechnique Fédérale de Lausanne (EPFL) and the University of Geneva. 
Idiap is located in the town of Martigny in Valais, a scenic region in 
the south of Switzerland, surrounded by the highest mountains of Europe, 
and offering exciting recreational activities, including hiking, 
climbing and skiing, as well as varied cultural activities. It is within 
close proximity to Geneva and Lausanne. Although Idiap is located in the 
French part of Switzerland, English is the working language. Free French 
lessons are provided.

Idiap offers competitive salaries and conditions at all levels in a 
young, dynamic, and multicultural environment. Idiap is an equal 
opportunity employer and is actively involved in the ""Advancement of 
Women in Science"" European initiative. The Institute maintains a 
principle of open competition (on the basis of merit) to appoint the 
best candidate, provides equal opportunities for all candidates, and 
equally encourages both genders to apply.

Keywords: natural language processing, machine learning, coreference 
resolution, machine translation."
"385","2017-01-03","Sewote","Paris","Sewote est une start-up spécialisée dans la R&D en ingénierie
linguistique. Nous développons des logiciels applicatifs sémantiques
dans l'optique de proposer des solutions clés en main aux structures
souhaitant perfectionner leurs processus métier. Notre équipe est
composée d'experts du traitement de l'information et du Traitetement
Automatique des Langues.

Nous sommes à la recherche d'un linguiste pour un stage de 6 mois en vue
de travailler à l'élaboration de ressources électroniques en anglais et
en français.

- Début de stage : 1er mars 2017
- Indemnités de stage : 554 ¤ + remboursement de 50% du ticket de
  transport
- Compétences requises :
  o Technologie : NOOJ et/ou UNITEX
  o TAL et Machine Learning
  o Langage Python et/ou Java
  o OS : Linux et Windows
  o Langues : anglais courant (anglais des affaires) et français courant

Si vous êtes intéressé par cette offre, merci d'envoyer votre
candidature à info@sewote.com ."
"386","2017-01-03","IRIT","Toulouse","Titre du stage : Réseaux de neurones et plongements de mots pour la
détection automatique de l'ironie

*
*

*Encadrement :*Farah Benamara (benamara@irit.fr),Véronique Moriceau
 (moriceau@limsi.fr), Tim Van de Cruys (tim.vandecruys@irit.fr)

*Lieu de stage : *IRIT-UPS 118 Route de Narbonne
*Durée : *5 mois
*Financement :* prime de stage

L'ironie est un phénomène linguistique complexe qui peut être défini
comme une incongruité entre le sens littéral d'un énoncé et son sens
voulu. Ainsi, une opinion visiblement positive peut s'avérer négative en
contexte, comme dans le cas d'un locuteur qui prononce la phrase ''
/Merci les bleus pour ce super match/'' alors que l'équipe de France
vient de perdre un match. La détection de l'ironie est un sujet
d'actualité en traitement automatique des langues en raison de son
importance pour une analyse efficace des opinions et sentiments (Ghosh
et al., 2015). La plupart des travaux se concentrent sur la détection de
ce phénomène sur les réseaux sociaux tels que Twitter, où les
utilisateurs ont tendance à utiliser des hashtags spécifiques (#ironie,
#sarcasme, #sarcastique) pour aider les lecteurs à comprendre que leur
message est ironique. Ces hashtags sont utilisés comme une étiquette de
référence pour la détection de l'ironie dans un cadre d'apprentissage
supervisé.

Ce stage se focalise sur la détection de l'ironie dans des tweets écris
en français et en anglais. L'objectif est de développer un modèle fondé
sur les réseaux de neurones afin d'identifier des expressions ironiques
de manière automatique. On étudiera l'utilité de diverses
représentations de mots (word embeddings ou plongements de mots ;
Mikolov et al. 2013), et on examinera leur utilisation dans les réseaux
de neurones récurrents (Mikolov et al. 2010). Une telle approche permet
de construire une représentation de la phrase globale à partir de
représentations de mots individuelles, qui peut ensuite être utilisé
pour la classification de tweets ironiques. L'approche sera comparée à
un modèle de classification supervisé déjà développé au sein de l'équipe
MELODI (Karoui et al, 2015).

*Compétences requises*

Bases de l'apprentissage automatique.


*Contact : *envoyer CV (+ relevés de notes du master) à Farah Benamara
(benamara@irit.fr), Véronique Moriceau (moriceau@limsi.fr), Tim Van de
Cruys (tim.vandecruys@irit.fr)


*Références*

/G/HOSHA., LIG., VEALET., ROSSOP., SHUTOVAE., BARNDENJ. & REYESA.
(2015). Semeval-2015 task 11 : Sentiment Analysis of Figurative Language
in Twitter. In Proceedings of SemEval 2015, Co-located with NAACL , p.
470-478 : ACL.

Jihen Karoui, Farah Benamara, Véronique Moriceau, Nathalie
Aussenac-Gilles, Lamia Hadrich Belguith: Towards a Contextual Pragmatic
Model to Detect Irony in Tweets. ACL (2) 2015: 644-650

Mikolov, Tomas, et al. ""Recurrent neural network based language model.""
/Interspeech/. Vol. 2. 2010.

Mikolov, Tomas, et al. ""Distributed representations of words and phrases
and their compositionality."" /Advances in neural information processing
systems/. 2013."
"387","2017-01-05","Viseo","Grenoble","Stage master 2 (ou équivalent) professionnel 2016-2017

Viseo R&D, à Grenoble (France)
http://www.viseo.com/fr/offre/recherche-et-innovation

Sujet : création d'une plateforme de démonstration d'outils
linguistiques.

Contexte

L'équipe R&D produit plusieurs outils basés sur l'analyse de données
textuelles : reconnaissance d'entités nommées, classification,
structuration de données... Ces outils sont hétérogènes, ils prennent la
forme de bibliothèques logicielles, web service, site web... Ils sont
écrits en Java ou en Python.

Pour montrer son savoir-faire et ses domaines de compétences ; l'équipe
souhaite se doter d'une plateforme de démonstration de ses outils. Cette
plateforme prend la forme d'un site web au sein duquel un visiteur peut
interagir avec les outils, en soumettant ses propres jeux de données.

Objectif du stage

L'objectif de ce stage est de réaliser un site web vitrine permettant
d'interagir avec les outils produits par l'équipe.

Pour atteindre cet objectif, il est demandé à l'étudiant de :

- modifier les outils pour les mettre sous forme de services web
  facilement déployables. Si nécessaire, produire des propositions
  d'évolution comprenant une analyse d'impact.

- proposer des maquettes du site web permettant d'interagir avec les
  différents outils de manière ergonomique,

- développer le site web (front et back).

Profil

Ce sujet est destiné aux étudiants de master 2 (ou équivalent) en
informatique.
Environnement technique : Java, Maven, git, Jenkins, Docker, Linux,
Angular, Spring, Python

Informations complémentaires
Unité d'accueil : Viseo R&D http://www.viseo.com/fr/offre/recherche-et-innovation
Lieu : Viseo R&D, 3 avenue Doyen Louis Weil, Grenoble
Encadrant principal : Pierre-Alain Avouac
Durée du stage : 6 mois
Stage rémunéré

Merci d'envoyer votre candidature à pierre-alain.avouac@viseo.com
constituée du CV, de la lettre de motivation, des relevés de notes des 2
dernières années (M1 et M2)

À propos de Viseo
Viseo est une entreprise française de services du numérique qui compte 1
200 employés en France, Allemagne, États-Unis, Singapour, Hong Kong et
Maroc. Son centre R&D est situé à Grenoble, à deux minutes à pied de la
gare. De nombreux projets de recherche collaboratifs y sont menés, avec
un intérêt particulier pour l'analyse de données textuelles : projet
SMILK (LabCom ANR)
http://www.viseo.com/fr/partenaire/le-laboratoire-commun-smilk, TIER
(EU) http://www.viseo.com/en/offre/tier-project, SYNODOS (ANR)
http://www.synodos.fr, SOMA (EUROSTARS)
http://www.viseo.com/fr/recherche/le-projet-soma, ...

Pour en savoir plus :

- www.viseo.com 

- www.viseo.com/fr/offre/recherche-et-innovation"
"388","2017-01-09","LIGM","Marne-la-Vallée","--------------
Offre de stage de M2 de linguistique : Étude et documentation de 
propriétés syntaxiques d'expressions verbales figées
--------------
Stage financé par le projet PARSEME-FR de l'Agence nationale de la
recherche (ANR)
--------------

Le projet PARSEME-FR (Syntactic Parsing and Multiword Expressions in
French) http://parsemefr.lif.univ-mrs.fr/doku.php vise à améliorer la
représentativité linguistique, la précision, la robustesse et
l'efficacité informatique des applications du traitement automatique des
langues (TAL), notamment l'analyse syntaxique du français. Il cible un
des principaux défis que rencontrent ces applications : les expressions
polylexicales (EPL), c'est-à-dire les groupes de mots qui doivent être
traités comme des unités à un niveau ou à un autre du traitement
linguistique, comme ""coup de pouce"", ""disque dur"", ""sauter le pas"",
""Nations unies"" et ""faire attention"". Le projet vise à concilier
précision linguistique et efficacité informatique dans les applications
du TAL, en travaillant, entre autre choses, sur la représentation
syntaxique et sémantique des EPL dans les dictionnaires. Ce projet se
rattache à PARSEME, une action européenne de type COST sur le même
sujet.

--------------
Description du poste
---------------
Les tâches principales concernent les tables de lexique-grammaire des
expressions figées verbales. Ces tables listent des entrées lexicales
d'expressions et leur attribuent des propriétés. Les objectifs seront
les suivants :

1) mettre en place une documentation sur les propriétés codées,
   notamment une formalisation des constructions syntaxiques, tout en
   harmonisant les notations sur toutes les tables ;

2) sélectionner des entrées en fonction des critères définis dans les
   directives de PARSEME-FR.

La recherche se fera en équipe avec deux chercheurs du LIGM, et en
parallèle avec un projet équivalent de l'Institute for Language and
Speech Processing (ILSP, Athènes) sur le grec moderne.

---------------
Profil souhaité
---------------
- Formation en cours : Master 2 en Linguistique Informatique ou similaire.
- Curiosité et capacité d'explorer de nouveaux domaines en linguistique.
- Des connaissances en lexicologie et syntaxe seraient un plus.

-----------------
Conditions
-----------------
Contrat : stage conventionné 6 mois rémunéré.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Merci d'envoyer votre candidature à l'adresse
eric.laporte@univ-paris-est.fr

Documents souhaités : CV, lettre de motivation, relevé de notes.

Lieu : LIGM, Université Paris-Est Marne-la-Vallée, Champs-sur-Marne.

Encadrant : Eric Laporte (Université Paris-Est Manre-la-Vallée)

Début : mars ou avril 2017."
"389","2017-01-13","Evea Cognitive","Saint-Cloud","Offre de stage : Mise en place de solutions cognitives 
 
Ingénieur Linguiste Junior

Contexte du stage :
 
EVEA COGNITIVE est la filiale du Groupe Evea technologies, notre
métier est d'accompagner les entreprises dans leur transformation
digitale. Nous réalisons 28M¤ de CA ; 95 salariés ; Siège à Saint
Cloud 92 - 2 Agences en France : Lille - Nantes - Partenaires
certifiés IBM depuis plus de 10 ans sur les technologies AS400/ Power
et stockage de données.
 
Nous sommes la filiale SSII spécialisée dans la Business Intelligence
et les technologies cognitives. Depuis 2015 EVEA COGNITIVE a commencé
une collaboration avec IBM sur la plateforme cognitive Watson : un
ensemble de technologies de pointe du traitement de données
textuelles. Afin de renforcer ses équipes linguistiques EVEA COGNITIVE
recrute un(e) stagiaire dont le rôle sera de contribuer à la mise en
place des solutions cognitives.

Vous participerez dans la collaboration avec nos partenaires et
développerez vos compétences dans ce domaine en pleine croissance.


Description du stage :

Vous participerez au développement de projets ou d'expérimentations
sur les technologies WATSON et autres technologies cognitives. Vous
serez intégré(e) au sein de l'équipe de EVEA COGNITIVE et
interviendrez sur les missions suivantes :

- Récupération de données textuelles de sources hétérogènes (fichiers,
  bases de données, emails, pages web).

-Normalisation, nettoyage et extraction de métadonnées de documents
 collectés, création de scripts (en Perl et/ou Python) pour faciliter
 le traitement de données textuelles.

- Analyse sémantique de données textuelles, création et gestion de
  ressources linguistiques : dictionnaires, expressions régulières,
  graphes UNITEX, grammaires locales, règles de parsing.
 
- Analyse de catalogues, préparation des bases de connaissances
  structurées pour l'analyse (ontologies etc)

- Acquisition d'une expertise technologique sur Watson et sur les
autres produits d'IBM, développement d'un savoir-faire méthodologique
et technique

Stage proposé dans l'objectif d'une embauche.

Profil recherché :

- Formation en cours : Master 2 en Linguistique Informatique ou
  similaire.
- Méthodique et rigoureux, capacité d'organisation
- Compétences en analyse sémantique et syntaxique, bonne connaissance
  d'outils et logiciels TAL
- Connaissance d'un langage de script (de préférence Python) et de
  XML, XPath, XSLT
- Capacité d'explorer de nouvelles méthodes statistiques en TAL serait
  un plus
- Connaissance en programmation orientée objet (Java, C#, C++, etc.)
  et en programmation Web (node.js) appréciée

Divers : 

- Début du stage : entre février 2017 et avril 2017 (date exacte à
  définir selon convenance)
- Stage de 6 mois rémunéré ( 800  mois)
- RIE et remboursement de la moitié du passe Navigo.
- Nos locaux sont situés à Saint Cloud (92213)
- Bonne ambiance et équipe technique de grande qualité.
- Contrat : convention de stage

Contact :

CV + lettre de motivation à envoyer à :

yulia.koloskova@3ws.fr"
"390","2017-01-16","SNCF","Paris","La Direction Innovation et Recherche de la SNCF recherche un stagiaire
pour travailler sur l'étude des solutions d'agents conversationnels
(chatbots) disponibles sur le marché et le test de certaines d'entre
elles.

*Activités du stage*
------------------------------

- Veille et état de l'art sur les chatbots

- Test et évaluation de plateformes permettant d'implémenter des agents
  conversationnels

*Thème*
------------------------------
Les agents conversationnels existent depuis longtemps. Ils déferlent
aujourd'hui sur le marché sous la désignation de chatbots. Les grands
acteurs tels que Facebook, IBM ou Microsoft favorisent aujourd'hui leur
diffusion massive en ouvrant des plateformes pour les développeurs. Les
industriels s'en emparent massivement et misent sur leur potentiel pour
améliorer la relation client.
La Direction Innovation et Recherche cherche à faire un état des lieux
sur la diffusion de ces solutions, leurs usages et leurs limites.

*Description *
------------------------------
Le stagiaire devra :

- prendre connaissance du contexte du stage (SNCF, Direction Innovation
  & Recherche, objectifs du stage et cadre de réalisation)

- réaliser un état de l'art et du marché sur les chatbots (agents
  conversationnels)

- tester et évaluer des solutions disponibles en interne ou open-source
  sur un cas d'usage simple (solution bluemix, wit.ai, pandorabots,
  solutions sur étagère dont startups, ...)


Présentations et rapports :
- Présentation de début de stage à la SNCF (au bout d'un mois de stage) :
  contexte de stage, planning de réalisation et premiers travaux
  réalisés.
- Etat de l'art et du marché sur les chatbots
- Rapport final de stage complet comprenant : méthodologie utilisée,
  travaux réalisés, résultats obtenus et problèmes rencontrés

2 soutenances de fin de stage : une à l'école et une à la SNCF.
Des présentations en interne SNCF ou externes pourront être effectuées.

*Profil recherché*
------------------------------

Niveau : en dernière année d'école d'ingénieur ou en Master 2
Informatique spécialisé dans le domaine du traitement automatique de la
langue ou de l'intelligence artificielle.

Compétences attendues :

- Capacités d'analyse, de rédaction et de synthèse
- Curiosité
- Autonomie, qualités relationnelles, qualité de présentation
  (orale/écrite).
- Connaissances en intelligence artificielle, traitement du langage
  naturel
- Bon niveau en programmation (Java, C/C++, php, Python, Node.js, Linux)
- Bon niveau d'anglais
- Une expérience sur les agents conversationnels et/ou systèmes de
  dialogue homme/machine est un plus

*Modalités du poste*
------------------------------

- Durée : 6 mois
- Rémunération prévue: indemnités de stage (924 ¤ bruts mensuels) +
  carte de circulation SNCF sur le réseau national
- Début : souhaité à partir d'avril 2017. Envisageable dès février 2017.
- Lieu : Paris


Merci d'adresser CV et lettre de motivation à Coralie Reutenauer à
l'adresse mail suivante : coralie.reutenauer@sncf.fr"
"391","2017-01-16","MoDyCo / IRISA","Nanterre ou Vannes","Offre de stage de M2 de linguistique : Étude des descripteurs
linguistiques à l'oeuvre dans la perception de registres de langue
différents en français

--------------

Stage financé par le projet ANR TREMoLo (/Tr//ansformation de Registres 
par Extraction de Motifs Langagiers/)

--------------

Le projet TREMoLo étudie l'emploi de différents registres dans la
langue française et vise à développer des méthodes automatiques de
transformation de textes d'un registre vers un autre. La notion de
registre ou niveau de langue [1, 2] renvoie à la façon dont, au sein
d'une même communauté linguistique - celle du français par exemple -,
des locuteurs évaluent et catégorisent des productions linguistiques.
C'est ainsi que l'on est intuitivement amené à distinguer différents
registres, souvent considérés sur une échelle de niveaux (soutenu,
standard, familier, populaire...). Le projet TREMoLo propose de
s'appuyer sur l'extraction de motifs langagiers spécifiques à
des registres donnés et sur l'intégration de ces motifs dans un
processus probabiliste de production automatique de paraphrases. Le
projet se situe dans une optique de recherche exploratoire visant la
production de connaissances fondamentales en linguistique française et
une ouverture à terme vers d'autres types de variations stylistiques.

Mots-clés : Registres de langue, Linguistique française, Traitement 
automatique des langues (TAL), Fouille de données

--------------

Description du poste

---------------

L'objectif de ce stage est de répertorier les descripteurs, c'est-à-dire
les traits ou phénomènes linguistiques, qui permettent de distinguer
entre eux des textes de registres différents. Sans exclure l'approche
paradigmatique, nous privilégions une approche syntagmatique pour
aborder - mais aussi renouveler - la problématique. En considérant des
corpus textuels de registre familier, courant ou soutenu (fournis par
les encadrants), il s'agira de commencer par exploiter les résultats des
travaux issus de la linguistique [3, 4] et de l'étude des styles en TAL
[5, 6]. Les faits grammaticaux seront plus particulièrement étudiés dans
la mesure où ils peuvent être discriminants par rapport à ce qui relève
de l'analyse thématique d'un texte, elle-même directement liée à
l'analyse du lexique /strico sensu/. Certains faits grammaticaux non
sollicités par un registre mais susceptibles de l'être dans un autre
seront ainsi considérés (par exemple, les nominalisations déverbales ou
l'adjonction du préfixe autonome de pluriel à une racine comme dans «
zyeuter ») ; puis les faits remarquables par leur absence ou leur
surreprésentation (par exemple, l'emploi de « on » dans le registre
familier, celui de la conjonction de coordination « car » et du passé
simple dans le registre soutenu...). Sur le plan plus strictement lexical,
à titre d'exemple, le phénomène d'emprunt à des langues étrangères, les
métaphores ou encore le verlan [7] seront intéressants à prendre en
compte.

Dans une moindre mesure, le stage a également pour objectif
d'identifier, parmi les nombreux outils existants en TAL, ceux
permettant l'annotation automatique de textes en français pour les
différents descripteurs retenus au fil du stage. La fiabilité des outils
pourra être étudiée et prise en compte pour leur sélection mais il ne
s'agit pas ici de développer de nouveaux outils.

---------------

Profil souhaité

---------------

- Formation en cours : Master 2 en Linguistique ou linguistique
  informatique.

- Curiosité et capacité d'explorer de nouveaux domaines en linguistique.

- Des connaissances en TAL seront un plus, mais ne sont
  aucunement prérequises. Un soutien sera assuré par les encadrants an
  cas d'absence de connaissances en TAL. Du reste, le sujet sera adapté
  en fonction du niveau et des types de compétences en TAL du (de la)
  candidat(e).

-----------------

Conditions

-----------------

Contrat : stage conventionné 6 mois rémunéré.

Début : mars ou avril 2017.

Lieu : laboratoire MoDyCo (site : Université de Paris Ouest Nanterre) ou
laboratoire IRISA (site : Université de Bretagne Sud)

Encadrants : Delphine Battistelli (MoDyCo), Nicolas Béchet (IRISA),
Gwénolé Lecorvé (IRISA)

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Merci d'envoyer votre candidature aux trois adresses suivantes :

delphine.battistelli@u-paris10.fr

nicolas.bechet@irisa.fr

gwenole.lecorve@irisa.fr

Documents souhaités : CV, lettre de motivation, relevés de notes M1 et
                      M2.


    Bibliographie

[1] D. Biber et E. Finegan. /Sociolinguistic Perspectives on Register/,
Oxford University Press, 1994.

[2] G. Petiot. Langue Française. N°33, sur les exercices de grammaire,
pp. 68-78, Armand Colin, 1977.

[3] D. Biber, /Variation across speech and writing/, Cambridge
University Press, 1988.

[4] F. Gadet. Niveaux de langue et variation intrinsèque, dans
Palimpseste « Niveaux de langue et registres dans la traduction », vol.
10, 1996.

[5] E. Stamatatos. /A survey of modern authorship attribution methods/,
Journal of the American Society for information Science and Technology,
60(3), 2009.

[6] M. Koppel et J. Schler. /Exploiting stylistic idiosyncrasies for
authorship attribution/, dans Proceedings of IJCAI'03 Workshop on
Computational Approaches to Style Analysis and Synthesis, 2003.

[7] F. Gadet. /Is there a French theory of variation?/, dans
International Journal of the Sociology of Language, vol. 160, 2003."
"392","2017-01-27","SNCF","Paris","Stage ingénieur ou M2 : fouille de textes appliquée à des documents
métiers SNCF

Contexte : SNCF dispose actuellement d'une base documentaire de
référentiels métiers. La Direction Innovation et Recherche souhaite
appliquer des méthodes de fouille de texte pour améliorer la gestion des
documents, l'accès aux contenus et la navigation dans cette base
documentaire.

Activités du stage :
Le stagiaire devra :

- prendre connaissance du contexte du stage (SNCF, Direction Innovation
  & Recherche, objectifs du stage et cadre de réalisation)
- Préparer les données en vue de leur réutilisation dans différents
  outils (adapter le format, structurer les contenus)
- Appliquer des traitements de data et text mining pour classer,
  visualiser et enrichir les documents.


Présentations et rapports :
- Présentation de début de stage à la SNCF (au bout d'un mois de stage) :
  contexte de stage, planning de réalisation et premiers travaux
  réalisés.

- Rapport final de stage complet comprenant : méthodologie utilisée,
  travaux réalisés, résultats obtenus et problèmes rencontrés

2 soutenances de fin de stage : une à l'école et une à la SNCF.
Des présentations en interne SNCF ou externes pourront être effectuées.

Profil souhaité :

Niveau : dernière année d'école d'ingénieur ou M2 en traitement
automatique des langues ou en informatique spécialisé en ingénierie des
connaissances ou fouilles de données (text mining).

Compétences requises :

- Traitement automatique des langues
- Apprentissage statistique / Machine learning
- Maîtrise de R
- Développement informatique (Java, Python...)
- Autonomie
- Capacités d'analyse, de rédaction, de synthèse

Horaires : 35 h hebdomadaires

Lieu de travail : Paris 12ème

Durée : 6 mois

Date de début : à partir du 20/02/2016

Rémunération prévue : indemnités de stage (924 ¤ bruts mensuels) + carte
de circulation sur le réseau national

Veuillez adresser votre CV et lettre de motivation à
coralie.reutenauer@sncf.fr"
"393","2017-01-30","LIMSI","Orsay","Offre de stage de niveau Master 2

Fouille de bases bibliographiques pour extraire les interactions entre
l'alimentation et les médicaments

Grâce aux avancées de la recherche, l'activité des professionnels et la
participation de la communauté, les informations et les connaissances
concernant une question donnée sont actuellement distribuées entre
différentes sources, comme par exemple les bases bibliographiques, les
bases de connaissances ouvertes, les réseaux sociaux, etc. Il se pose
alors la question de l'accès efficace et rapide à ces informations et
connaissances et à leur croisement [1].

Le contexte du travail s'inscrit dans le domaine médical. L'intérêt
central concerne l'extraction des informations sur les interactions
entre l'alimentation et les médicaments. Les aliments peuvent en effet
avoir des interactions avec les médicaments et cela peut mener à des
conséquences malheureuses pour le patient. Ces interactions sont très
peu étudiées. DrugBank [2], qui est la base de connaissances la plus
complète sur cette question, propose des informations textuelles sur les
interactions pour moins de 10 % de médicaments. De plus, ces
informations concernent essentiellement le moment de prise des
médicaments (par exemple, pendant le repas).

De manière générale, il peut exister trois types d'interactions: (1)
diminution ou suppression de l'action du médicament sous l'effet d'un
aliment ; (2) augmentation de l'effet du médicament ; (3) apparition de
nouveaux effets indésirables du médicament.

Le pomelo, qui est un exemple bien connu, a des interactions avec
plusieurs médicaments à cause de son principe actif qui inhibe les
enzymes des médicaments, ce qui peut causer le surdosage de ces
médicaments [3,4]. D'autres aliments peuvent avoir des interactions,
comme par exemple l'alcool, les cranberries, les tomates, le thé vert,
les épinards ou le curcuma.

Ce stage s'inscrit dans le projet ANR MIAM (Maladies, Interactions
Alimentation-Médicaments). Pour la réalisation du stage, des méthodes de
Traitement Automatique de la Langue et de fouille de textes seront
utilisées.

Plus spécifiquement, il s'agit des objectifs suivants:
- travailler avec des corpus de textes de différents types et
  provenant de différentes sources
- exploiter et améliorer les annotations des textes avec différents
  niveaux de spécificité
- exploiter, adapter ou développer des méthodes pour l'extraction
  d'informations
- faire le lien avec les bases de données et de connaissances
  existantes
- évaluer les méthodes et les résultats

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:
- connaissances en TAL et en informatique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique
- maîtrise de l'anglais
- autonomie

Le stage est rémunéré selon les règles en vigueur.

Selon les résultats du stage, une poursuite en thèse pourra être
envisagée.

Niveau: Master 2
Durée: 6 mois
Lieu: Orsay
Début du stage : Mars ou avril 2017

Pour présenter une candidature: envoyer un CV, la lettre de
motivation, le relevé de notes et les contacts de deux référents à
thierry.hamon@limsi.fr et natalia.grabar@univ-lille3.fr


REFERENCES

1. J. Kozák, M. Necaský, J. Dedek, J. Klímek, and J. Pokorný. Linked
open data for healthcare professionals. In Proceedings of
International Conference on Information Integration and Web-based
Applications & Services, IIWAS'13, pages 400:400-400:409, New York,
NY, USA, 2013. ACM.
2. http://www.drugbank.ca/
3. Duke Med Health News. Grapefruit: enemy of many medications. in
some patients, the interaction of fruit and drug may put their life
and health at risk. Duke Med Health News, 19(2):1-2, 2013.
4. D. Greenblatt and H. Derendorf. Grapefruit-medication
interactions. CMAJ, 185(6):507, 2013."
"394","2017-01-31","Wiidii","Bordeaux","WIIDII RECRUTE !

Stage durée de 6 mois - début : 13/03/2017
Date limite de candidature le 20/02/2017
Offre publiée le 02/02/2017
Référence de l'annonce : SLI022017

Qui est Wiidii ?

Nom : Wiidii
Adresse : 56 rue de Tivoli 33000 BORDEAUX
Site Web : www.wiidii.com
Wiidii est une jeune start-up bordelaise créée
en 2014 qui commercialise une application de
conciergerie combinant l'intelligence artificielle
et le savoir-faire humain.
La conciergerie privée propose à ses clients de gérer et
simplifier leur quotidien, tel un assistant personnel.

Missions détaillées

Au sein d'une équipe d'une dizaine de personnes, et encadré par la
chef de projet, nous proposons un stage de linguiste
informaticien. Vos missions seront de deux natures :

Conception de base de données

- Mener une étude sur la création d'une base de données (BDD)
alimentant le moteur de l'application : recherche de sources de
BDD. Au-delà des données pures, il s'agit d'élaborer une BDD dynamique
autour du langage sur des schémas syntaxiques (combinaison de mots sur
des principes de AND, OR, NOT).
- Architecturer et construire la BDD
- Importer et tester la BDD dans le moteur de l'application

Suivi client

- Prendre en charge les demandes* des clients en français et en
  anglais, via l'application
- Poursuivre et améliorer l'envoi des notifications aux clients
- Gérer le suivi des bugs
- Créer, envoyer et suivre les campagnes d'emailing
- Analyser l'activité cliente : profil des clients, nature des
demandes et en sortir des données statistiques

*Les demandes sont de toutes sortes : conseiller des
lieux à visiter, organiser des voyages, réserver des
restaurants, prendre des rendez-vous chez le coiffeur,
médecin, trouver un garagiste...

Wiidii : comprendre la demande du client afin de lui apporter la
réponse la plus pertinente possible.


Profil et Compétences

- Wiidii cherche un(e) candidat(e), maîtrisant les tableurs (Excel) et
possédant une très forte agilité en informatique et sur Internet. La
structuration du langage vous passionne et vous connaissez les
principes de base des langages SQL, Script, HTML. Rigueur,
organisation, innovation, implication et adaptation sont les qualités
requises pour occuper ces missions.
- L'anglais écrit est un atout supplémentaire.
- De formation en langue et informatique, sur les sciences du langage ou
en ingénierie des langues.


Rémunération & Avantages

- Gratification conventionnelle
- Participation au titre de transport, tickets restaurant

Temps de travail

35 heures du lundi au samedi en horaire variable (8h - 22h)

Personne à contacter

Envoyez CV et lettre de motivation en français par mail
à Johanna PICAUD, Responsable administrative et financière :
johanna.picaud@wiidii.com"
"395","2017-02-01","INALCO","Paris","Stage M2 au laboratoire ERTIM (INALCO)
Traitements TAL pour le bambara et le maninka

Le projet MANTAL vise à implémenter des traitements TAL aux langues
mandingues (bambara et maninka) qui disposent déjà d'assez conséquents
volumes de données annotées (Vydrine 2013, 2014 et 2016) : 3M de mots
pour chaque langue annotés automatiquement en morpho-syntaxe,
tonalisation et gloses, dont 500K ont été désambiguisés manuellement
pour le bambara. Le bambara s'écrit avec des caractères latins, tandis
que le maninka utilise le système d'écriture écrit en N'ko, qui se
transcrit assez facilement en caractères latins.

Ces travaux sont essentiels pour apporter une existence numérique à ces
langues parlées par 20 à 30 millions de locuteurs en Afrique et dans la
diaspora africaine. L'objectif du stage est d'améliorer les traitements
TAL pour ces langues dans plusieurs directions.

1/ En collaboration avec un partenaire allemand, nous souhaitons étendre
les travaux à la construction d'analyseurs syntaxiques pour ces langues
selon un format interopérable du web sémantique (NIF). Ce travail pourra
être exploité pour des applications de plus haut niveau, comme la
traduction.

2/ Les corpus pour ces deux langues sont aujourd'hui hébergés sur une
infrastructure technique identique, et tout traitement fonctionnel pour
une langue peut potentiellement être porté à l'autre. La constitution de
corpus parallèles bamara / français (et éventuellement maninka /
français) apportera ressource supplémentaire à forte valeur ajoutée pour
le projet.

3/ Le corpus maninka ayant été constitué récemment, un travail est
nécessaire afin d'en contrôler la qualité et de l'enrichir. Cette tâche
sera réalisé par extraction de textes en maninka depuis internet
(crawling) et par une vérification automatique de la cohérence des
corpus avec les ressources linguistiques existantes (corpus et
dictionnaires), ce qui permettra aussi d'apporter aux linguistes des
suggestions de mots à ajouter aux dictionnaires ou de segments à
corriger dans les corpus.

Profil recherché :
+ Master 2 en TAL
+ Bonnes compétences en programmation (Python)
+ Compréhension des approches en apprentissage automatique
+ La connaissance du bambara / maninka est bienvenue mais pas
  obligatoire

Contexte
+ Durée du stage : 4 ou 5 mois à temps plein
+ Date de début : mars ou avril 2017
+ Rémunération : tarif en vigueur (510¤/mois, rbst de 50% navigo)
+ Lieu : INaLCO, 2 rue de Lille, 75007 Paris

Merci d'envoyer votre CV et de faire part de vos motivations à Damien
Nouvel ( damien.nouvel@inalco.fr ).

Références :
(Maslinsky 2014) Kirill Maslinsky. Daba: a model and tools for Manding
corpora. TALAf 2014. http://talaf.imag.fr/2014
http://talaf.imag.fr/2014/Actes/MASLINSKY%20-%20Daba%3B%20a%20model%20and%20tools%20for%20Manding%20corpora.pdf

(Vydrine 2013) Valentin Vydrin. Bamana Reference Corpus (BRC) Procedia -
Social and Behavioral Sciences, 95:25, pp. 75-80.
http://www.sciencedirect.com/science/journal/18770428

(Vydrine 2014) Valentin Vydrin. Projet des corpus écrits des langues
manding : le bambara, le maninka. TALAf 2014. http://talaf.imag.fr/2014
http://talaf.imag.fr/2014/Actes/MASLINSKY%20-%20Daba%3B%20a%20model%20and%20tools%20for%20Manding%20corpora.pdf

(Vydrine 2016) Valentin Vydrin, Andrij Rovenchak, Kirill Maslinsky. Maninka
Reference Corpus: A Presentation. TALAf 2016. http://talaf.imag.fr/2016"
"396","2017-02-01","LATTICE","Paris","Proposition de stage de 6 mois au laboratoire LATTICE : adaptation au
français d'un outil d'analyse des chaînes de coréférence 

Dans le cadre d'un projet d'analyse d'un corpus de presse en français
couvrant plusieurs dizaines d'années, le LATTICE souhaite recruter un
stagiaire (niveau M2 en Informatique ou IA ou TAL avec une forte
composante informatique) pour une durée de 6 mois à partir de mars ou
avril 2017. Plusieurs tâches sont envisageables mais le thème privilégié
sera l'analyse de chaînes de coréférence (afin par exemple d'identifier
des informations importantes dans des phrases où le nom des acteurs ne
serait  pas immédiatement reconnaissable). 

Une piste permettant d'avancer sans avoir à développer un système
complètement nouveau serait d'essayer d'adapter au français la chaîne de
traitement BART (http://www.bart-coref.org/) qui est largement utilisée
dans divers cadres. Ce stage demande un bon niveau en informatique.

Le stage se déroulera au LATTICE, à Montrouge (à 10mn de la station de
métro « Mairie de Montrouge », ligne 4)

- Stage de 6 mois maximum, de niveau M2 (Informatique ou IA ou TAL avec
  une forte composante informatique), conventionné et indemnisé suivant
  les règles en vigueur

- Très bon niveau en programmation (scripts et programmation pure) et en
  TAL nécessaire

- Contact : Thierry Poibeau (thierry.poibeau@ens.fr) et Frédéric
  Landragin (frederic.landragin@ens.fr)"
"397","2017-02-01","LLL","Orléans","Offre de stage pour trois mois (mars/avril-mai 2017)

Prise en main et utilisation d'une base de données et d'un logiciel de
repérage automatique d'opérations de réécriture

Contexte

Ce stage s'intègre dans les recherches menées par des laboratoires des
universités d'Orléans (LLL) et de Bordeaux, en lien avec la Maison
Interdisciplinaire des Systèmes Complexes (universités d'Orléans et de
Tours) dans le cadre du projet régional ECRISA (MSH Val de Loire) 
(En savoir plus sur http://ecrisa.msh-vdl.fr).

À partir de l'analyse d'expérimentations en cours, l'objectif central
de ces recherches, qui s'inscrit dans le champ des littéracies
universitaires, est de montrer comment des outils conceptuels élaborés
dans le cadre d'une didactique de l'écrit(ure) référée à des
disciplines scolaires peuvent permettre de construire, dans
l'enseignement supérieur, des dispositifs d'accompagnement des
pratiques littéraciées visant la construction de savoirs, et
d'envisager un transfert didactique dans les disciplines scolaires,
lorsque le public visé est constitué de (futurs) enseignants. L'étude
s'appuie sur l'analyse de déclarations et de productions d'écrits
d'étudiants insérés dans des contextes de formation différents, tant
sur le plan des systèmes universitaires (France, Québec) que sur celui
des filières (technologique, linguistique, formation des maitres,
etc.). Pour faciliter l'analyse des écrits recueillis sous la forme de
deux versions, une base de données a été constituée dans le cadre du
projet « Prise en compte de la complexité dans les pratiques
littéraciées de l'enseignement supérieur » soutenu par la Maison
Interdisciplinaire des Systèmes Complexes des universités d'Orléans et
de Tours (http://www.univ-orleans.fr/misc-orleans-tours/projets).

En savoir plus sur
http://ecrisa.msh-vdl.fr/index.php/lecrit-comme-produit-derivepratiques-litteraciees-de-haut-niveau-et-prise-en-compte-du-sujet/

Structure d'accueil : Laboratoire Ligérien de Linguistique, université
d'Orléans ; des missions à Bordeaux sont à prévoir.

Responsable de la recherche : Jacqueline Lafont-Terranova -
Laboratoire Ligérien de linguistique, Université d'Orléans
(jacqueline.lafont@univ-orleans.fr)

Missions

Améliorer et alimenter une base de données de textes produits et
enregistrés sous forme de deux versions (V1/ Version définitive) ;
utiliser le logiciel Medite (qui repère automatiquement les opérations
de réécriture qui font passer d'un texte à un autre).  (Une formation
au maniement de ce logiciel sera assurée).

Le/la stagiaire devra :

- Vérifier les fiches présentes dans la base de données (41 mémoires
de recherche V1/Version définitive),
- Effectuer des tests de repérage des opérations de réécriture au
niveau textuel (remplacements, suppressions, ajouts, déplacements) sur
un échantillon,
- Affiner le paramétrage en fonction des tests,
- Repérer des opérations de réécriture au niveau textuel sur
l'ensemble du corpus,
- Réaliser des statistiques à partir des résultats obtenus,
- Effectuer une étude qualitative des effets des opérations de
réécriture repérées sur un mémoire,
- Ajouter des nouveaux corpus dans la base de données.

Profil recherché

-Étudiant(e) en M2 professionnel ou recherche en sciences du langage,
sciences de l'éducation, MEEF

- Bonne connaissance des logiciels bureautiques,

- Formation ou sensibilisation à la didactique souhaitable

Structure de recrutement : Maison des Sciences de l'Homme Val de
Loire, Tours

Durée : 3 mois

Compensation : selon les normes en vigueur

Prise de fonction : à partir de mars 2017

Encadrement : Jacqueline Lafont-Terranova, Flora Badin, Guillaume Chevrot

Candidature :

Envoyer CV et lettre de motivation avant le 25 février 2017 à
Jacqueline Lafont-Terranova - Maitre de conférences au Laboratoire
Ligérien de linguistique (Université d'Orléans) :
jacqueline.lafont@univ-orleans.fr et Giulia Ventrella-Proust - Chargée
de la gestion du projet ECRISA à la Maison des Sciences de l'Homme Val
de Loire : giulia.ventrella@univ-tours.fr"
"398","2017-02-08","Prosodie","Boulogne-Billancourt","Filiale du groupe Capgemini depuis juillet 2011, Prosodie conçoit et
héberge les services Front Office des grands comptes. Elaborées à partir
de technologies propriétaires innovantes, les solutions de Prosodie
répondent à chacune des étapes du parcours numérique de leurs
utilisateurs. Proposés en mode cloud, les services fournis en  temps
réel s'appuient sur une plate-forme technique hautement disponible et
sécurisée. Grâce à la dimension internationale de Capgemini,  Prosodie
est en mesure de déployer son offre à l'international aux côtés des
autres entités du Groupe. Prosodie est déjà présente en France, en
Espagne, en Italie et au Benelux.

« Le groupe Capgemini est signataire de la Charte de la diversité en
entreprise »

Nous recherchons un(e) :
Stagiaire Linguiste H/F
Boulogne-Billancourt
Votre mission
Au sein de la Direction du Développement, vous participez à
l'amélioration des services notamment en reconnaissance vocale (langage
naturel, langage dirigé) sur les aspects ergonomie vocale, traitements
linguistiques (analyse et constitution de corpus (catégorisation de
phrases), préconisation afin d'optimiser des services existants, ...). 


Profil recherché

De formation Bac + 4/5 en ingénierie linguistique, sciences du langage
ou en sciences cognitives, vous recherchez un stage d'une durée de 6
mois.

Vous maîtrisez :
- Les logiciels de la suite Microsoft Office (word, excel, powerpoint).

Doté(e) de bonnes capacités à communiquer, votre sens de l'organisation,
votre esprit d'analyse, votre rigueur et votre créativité seront autant
d'atouts qui vous permettront d'être performant et de réussir votre
stage. 

En nous rejoignant vous serez intégré(e) aux équipes projets de Prosodie
basées à Boulogne-Billancourt, qui vous permettront de développer vos
compétences autour des process et méthodologies de développement, les
bonnes pratiques dans un contexte professionnel motivant.

Merci beaucoup pour votre aide."
"399","2017-02-20","LI & LIFO","Blois ou Orléans","------------------------------------------------------------------------
PROPOSITION DE STAGE : Techniques de classification pour la résolution 
des coréférences
------------------------------------------------------------------------

RESUME
------

Stage à connotation recherche sur la réalisation d'un système de
résolution des coréférences à l'aide de techniques de classification
automatique.

Durée : 4 mois minimum (stage de fin d'études)

Lieu d'exercice : Blois (LI) ou Orléans (LIFO)

Profil recherché : stagiaire en Master 2 informatique ou
linguistique-informatique, voire, à des étudiants de Licence 3
informatique d'excellent niveau académique.

CONTEXTE
--------

Le Laboratoire d'Informatique de l'Université de Tours (LI) et le
laboratoire LIFO (Université d'Orléans) proposent un stage financé par
la fédération Informatique Centre Val de Loire (LIFO), portant sur
l'utilisation de techniques de classification et d'apprentissage
automatique pour la résolution automatique des coréférences. Le travail
proposé par ces deux laboratoires fait suite au projet régional ANCOR
réalisé en collaboration avec le Laboratoire Ligérien de Linguistique
(LLL) de l'Université d'Orléans, et est réalisé en marge du projet ANR
DEMOCRAT (porté par le LATTICE) sur un sujet proche, auquel participent
également les laboratoires LI et LIFO.

La résolution de la coréférence constitue une barrière technologique
importante pour la recherche d'information, alors même que les moteurs
de recherche essaient de représenter de plus en plus finement le contenu
des documents textuels indexés qu'ils interrogent . On appelle
coréférence, et plus généralement anaphore, la relation entre deux items
langagiers telle que l'interprétation de l'un dépend de
l'autre. Considérons l'exemple : Zoe est venue à la fête avec Isa. Elle
ne voulait pas venir seule. Nous sommes en présence d'une anaphore
pronominale entre le pronom elle et son antécédent Zoe, relation qu'un
système doit détecter pour interpréter correctement la seconde
phrase. Cette tâche n'est jamais triviale : par exemple, dans ce cas, le
système pourrait rattacher de manière erronée le pronom à Isa, voire
même au nom commun fête. Le développement d'outils performants de
recherche d'information dans des flux langagiers passe par une
modélisation efficace des anaphores.

L'importance de la résolution des anaphores a conduit à l'émergence de
travaux qui ont fait l'objet de multiples campagnes d'évaluation
internationales (MUC, SemEval, ACE). Le projet ANCOR, porté par le LI, a
permis récemment la création d'un corpus d'envergure (488 000 mots) du
français oral (transcrit) annoté en coréférence et anaphores. Sans
équivalent au niveau mondial pour l'oral, ce corpus constitue une
ressource incontournable pour des approches par apprentissage (machine
learning) de résolution.  Il a ainsi déjà permis l'apprentissage de
CROC, le premier système francophone de résolution des coréférences
développé par le laboratoire LATTICE à Montrouge
(http://issuu.com/sfleury/docs/adele-desoyer-memoire-tal-rb-1314/1).

Le stage qui vous est proposé a pour ambition de réaliser un travail
comparable de développement d'un système de résolution, qui tiendra lieu
de système de référence (baseline) pour la comparaison des recherches
francophones sur le sujet. En particulier, il vous sera demandé de
développer un système de résolution des coréférences par apprentissage
sur le corpus ANCOR. Ce travail consiste à appliquer sur ce corpus
francophone des techniques d'apprentissage automatique (classifieurs SVM
en particulier) afin d'identifier automatiquement les paires de mentions
(termes) co-référentes. On utilisera pour cela une plate-forme générique
de classification automatique (Weka).

TRAVAIL A REALISER
------------------

PHASE 1 - Développement d'un système francophone de référence de 
résolution des coréférences (T0 - T0+3)

Le système sera basé sur l'utilisation d'un classifieur SVM disponible
sur la plate-forme Weka et entrainé sur le jeu de traits d'apprentissage
présents dans le corpus annoté ANCOR. Ce travail s'inspirera des
recherches menées avec le système CROC et se concentra sur la question
de la détection de relations de coréférence entre mentions préalablement
identifiées. On pourra toutefois viser la réalisation d'un système
complet (end-to-end) par intégration des travaux récents menés au
LATTICE sur la détection automatique des mentions.

PHASE 2 - Amélioration et évaluation du système (T0+3 - T0+4 ou T0+5)

Evaluation et optimisation du système : on étudiera l'influence de
différents classifieurs (SVM, arbre de décisions, classifieur bayésien
naïf...), des méthodes de classification (mention-pair, twin-candidate,
entity mention), des différents traits d'apprentissage, le tout
permettant une comparaison avec le système CROC.

RESULTATS ATTENDUS
------------------

*    Système de résolution des coréférences, qui sera diffusé en open source
*    Evaluation expérimentale du système

L'étape d'évaluation comparative avec le système CROC devrait donner
lieu à une publication scientifique à laquelle participera la personne
recrutée. L'ensemble du code développé sera diffusé en open source.

ENCADRANTS
----------

Jean-Yves Antoine (Jean-Yves.Antoine@univ-tours.fr) LI, U.
François-Rabelais Tours
Anaïs Lefeuvre-Halftermeyer (anais.halftermeyer@univ-orleans.fr) LIFO,
U. Orléans

Autre participants au projet :

Nicolas Labroche     LI, U. François-Rabelais Tours
Sylvie Billot        LIFO, U. Orléans
Marcilio de Souto    LIFO, U. Orléans

PROFIL RECHERCHE
----------------

Idéalement, la personne recrutée terminera des études de niveau Master
(Master 2) et disposera de connaissances théoriques et pratiques sur les
techniques de classification automatique. Un intérêt pour la langue et
son traitement automatique serait apprécié, sans être un pré-requis à
recrutement.
Cependant, ce stage est également proposé à des étudiants en fin d'étude
de Licence (Licence 3) qui disposeraient d'un excellent niveau
académique (mention B en licence au minimum) et désireraient découvrir
la problématique du TALN et de l'apprentissage automatique.  Date et
lieu de stage

La personne recrutée travaillera, à sa convenance, au sein du
laboratoire LI (antenne universitaire de Blois) ou du LIFO (Campus de la
Source, Orléans). Il s'intégrera à la fois dans l'équipe BDTLN
(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) du LI, et
plus précisément dans l'axe TLN de cette équipe
(http://tln.li.univ-tours.fr/) ainsi que dans l'équipe Contraintes et
Apprentissage (http://www.univ-orleans.fr/lifo/equipes/CA/) du LIFO.

DUREE ET PERIODE DE STAGE
-------------------------

La durée minimale du stage sera de 4 mois et pourra être prolongée à 5
mois si l'étudiant le désire. Début de stage possible à partir du
27/02/2017.

REMUNEREE
---------

La personne recrutée recevra une gratification mensuelle correspondant à
la réglementation, à savoir 15% du plafond horaire de la sécurité
sociale, soir 3,66 euros par heure de stage. A titre d'exemple, cette
gratification représente un montant de 554 ¤ pour un mois avec 22 jours
ouvrés, et 504 ¤ pour un mois avec seulement 20 jours ouvrés (jours
fériés, par exemple). Pourra également se rajouter une indemnité de
transports en commun correspondant à 50% d'un abonnement mensuel
étudiant.

La personne recrutée participera aux réunions de l'équipe projet. Les
frais de mission induits par ces déplacements seront remboursés.

CONTACT - DEPOTS DE CANDIDATURES
--------------------------------

Dépôt des candidatures par courrier électronique auprès de Jean-Yves
Antoine et Anaïs Lefeuvre-Halftermeyer, avant le 2 mars 2017 inclus,
délai de rigueur. Merci de déposer :

* Un CV détaillé de vos activités passées
* Une lettre de motivation
* Vos relevés de notes des deux dernières années d'études
* Lettres de recommandation (2 lettres minimum appréciées)

Le cas échéant, un développement Java et/ou une lecture critique
d'article scientifique pourront être demandé pour la sélection.

Nous restons à votre écoute pour tout renseignement sur ce stage.

LIENS UTILES
------------

Corpus ANCOR : 
http://www.info.univ-tours.fr/~antoine/parole_publique/ANCOR_Centre/index.html
Plate-forme Weka : http://weka.wikispaces.com/


Références

Desoyer A., Landragin F., Tellier I., Lefeuvre A., Antoine J.-Y. (2014)
Les coréférences à l'oral : une expérience d'apprentissage automatique
sur le corpus ANCOR, Traitement Automatique des Langues, TAL, vol. 55,
55(2), pp.97-121. [http://www.atala.org/Les-coreferences-a-l-oral-une]

Désoyer A., Landragin F., Tellier I., Lefeuvre A., Antoine J.-Y.,
Dinarelli M. (2016) Coreference Resolution for French Oral Data: Machine
Learning Experiments with ANCOR. Proc. 17th International Conference on
Intelligent Text Processing and Computational Linguistics, CICLing'2016.
Konya, Turkey. [https://hal.archives-ouvertes.fr/hal-01344977]

Muzerelle J., Lefeuvre A., Schang E., Antoine J.-Y., Pelletier A.,
Maurel D., Eshkol I., Villaneau J. (2014) ANCOR_Centre, a Large Free
Spoken French Coreference Corpus: Description of the Resource and
Reliability Measures. Proc. LREC'2014, Reykjavik, Islande.
[https://halshs.archives-ouvertes.fr/hal-01075679]"
"400","2017-02-20","Geriico & TVES","Lille","************************************************************************
OFFRE DE STAGE MASTER 1ère ou 2ème - OHM-Littoral Méditerranéen - LabEx
DRIIHM, RATTACHÉ A LA MESHS de Lille (USR 3185 CNRS) 
************************************************************************

************************************************************************
INTITULÉ DU STAGE : EXTRACTION ET ANALYSE D'INFORMATION A PARTIR DES
RESEAUX SOCIAUX : APPLICATION AUX DONNEES DU PARC NATIONAL DES
CALANQUES.
************************************************************************

CONTEXTE SCIENTIFIQUE : Ce stage de Master 1 ou 2 s'inscrit dans le
projet de recherche intitulé « Les réseaux numériques : un tournant pour
l'analyse des relations homme-milieux ? Application au parc national des
calanques » RENUROHM. Ce projet a été sélectionné dans le cadre de
l'Appel à Projets de Recherche 2016 du LabEx DRIIHM (Dispositif de
Recherche Interdisciplinaire sur les Interactions Hommes-Milieux), au
titre de l'Observatoire Hommes-Milieux Littoral
Méditerranéen. L'Observatoire Hommes-Milieux ""Littoral méditerranéen""
est un dispositif de recherche interdisciplinaire du CNRS (INEE et
INSHS). Son projet scientifique est l'étude de l'urbanisation et de
l'anthropisation côtière en Méditerranée. Dans un contexte de changement
des modes de gestion du littoral (GIZC), il s'intéresse à quatre
systèmes socio-écologiques littoraux inégalement soumis à
l'artificialisation et aux fréquentations touristiques et récréatives :
le littoral marseillais, le Golfe d'Aigues-Mortes et les rivages corses
de Balagne et du sud Bastia. Depuis une quinzaine d'années, on constate
un développement des humanités numériques provoquant l'émergence d'un
nouveau champ de recherche interdisciplinaire, la création de nouveaux
corpus de données numérisées et la reconfiguration des pratiques ou des
objets de recherche sous l'impact des contenus numériques diffusés sur
le web et les réseaux sociaux numériques. La mobilisation des corpus de
données numériques rassemblées sur le web et les réseaux sociaux peut
représenter une nouvelle approche de recherche des relations entre
l'environnement et la société. Des recherches récentes ont analysé le
processus de création du Parc national des calanques (Deldrève et
Deboudt, 2012 ; Deboudt et Deldrève, 2015). Dans le cadre du projet
RENUROHM, un premier travail est en cours pour réaliser la cartographie
des acteurs en lien avec le Parc national des calanques afin
d'identifier les acteurs qui s'expriment sur des blogs, sites web ainsi
que sur les réseaux sociaux, à propos de différents sujets en lien avec
ce territoire. Nous nous appuyons pour cela sur une méthodologie pour la
cartographie semi-automatisée des acteurs de domaine (Berthelot et al.,
2016). Ce premier travail permettra de produire une première liste
d'acteurs qui sera utilisée pendant le stage pour réaliser des tâches de
fouille textuelle (Text Mining).


************************************************************************
OBJECTIFS : TRAVAUX ATTENDUS : A partir d'un corpus déjà constitué
(sites web et tweets), il s'agit de réaliser une analyse
semi-automatique des contenus des tweets afin d'identifier les entités
nommés (organisation, personnes et lieux) et les thématiques abordées
dans le texte des tweets. Plus précisément, le stage consistera à
intégrer et enrichir des chaines traitement automatique pour : 

- Extraire des entités nommées à partir de listes préalablement fournies
  d'acteurs et de lieux et en se basant sur la méthode décrite dans
  (Zenasni et al., 2016) qui permet l'extraction de nouvelles formes de
  lieux dans les messages courts ;
- Extraire des thématiques en se basant sur des approches fouilles de
  textes (Pak et al. 2014) ;
- Evaluer les résultats obtenus ;
- Réaliser différentes analyses qualitatives et quantitatives sur les
  résultats obtenus et notamment répondre aux questions suivantes :
  Quels sont les acteurs qui s'expriment sur ces lieux/sujets ? Quelles
  sont les relations entre ces acteurs ? Quelles sont les évolutions
  observées selon différentes temporalités ?
- Participer au travail de valorisation des résultats en enrichissant le
  site Web du projet (en cours de construction).  

INDEMNISATION, DURÉE ET LIEUX DE TRAVAIL :
- Gratification : 554,40 euros par mois ;
- Ce stage d'une durée de 4 mois (1er avril 2017 - 31 juillet 2017) se
  déroulera de manière partagée à l'Université Lille 3 et à l'Université
  Lille 1, dans les locaux du laboratoire Geriico (Lille 3 ;
  http://geriico.recherche.univ-lille3.fr/) et du laboratoire TVES
  (Lille 1 ; http://tves.univ-lille1.fr/)

************************************************************************
PROFIL DU CANDIDAT : 

- Master 1ère ou 2ème année en cours ;

- Formation, compétences et qualités requises : Linguistique ;
  Traitement Automatique des Langues (TAL); Fouille de textes ; la
  maîtrise d'un langage de programmation est indispensable (java) ; la
  maîtrise du logiciel R serait un plus. Capacité à travailler en équipe
  et à distance. Une connaissance préalable de l'outre mer ou du Brésil
  sera appréciée.

CONTACTS ET CALENDRIER : Envoyer un CV détaillé, par mail (1 fichier
PDF), avant le lundi 6 mars 2017 à Eric Kergosien
(eric.kergosien@univ-lille3.fr) et Amel Fraisse
(amel.fraisse@univ-lille3.fr).


Bibliographie : 

- Arsène S., 2013, Vers une recomposition des pouvoirs : Internet et
  réseaux sociaux, CERISCOPE Puissance, ; 
- Deldrève V., Deboudt P. (dir.), 2012, Le parc national des calanques :
  construction territoriale, concertation et usages, QUAE, 231 p. ; 
- Deboudt P., Deldrève V., 2015, Inégalités et concertation « encastrée
  » : le projet du parc national des calanques, in L. Mermet et
  D. Salles (dir.), Environnement et transition écologique, De Boeck
  éd., coll. Ouvertures Sociologiques, p. 151-166.
- Berthelot M.-A., Severo M., Kergosien E., 2016, , Cartographier les
  acteurs d'un territoire : une approche appliquée au patrimoine
  industriel textile du Nord-Pas-de-Calais, In 3ème colloque
  international du CIST (CIST 2016), pp.6, Grenoble.
- Zenasni S., Kergosien E., Roche M., Teisseire M., 2016, Extracting new
  Spatial Entities and Relations from Short Messages, In the 8th
  International ACM Conference on Management of Digital EcoSystems
  (MEDES'2015), pp. 8, Hendaye (France).
- Alexander Pak and Patrick Paroubek and Amel Fraisse and Gil
  Francopoulo (2014). Normalization of Term Weighting Scheme for
  Sentiment Analysis. Book Chapter, Human Language technology Challenges
  for Computer Science and Linguistics. Series: Lecture Notes in
  Artificial Intelligence, Springer, Vol. 8387. ISBN
  978-3-319-08957-7. Vetulani, Zygmunt, Mariani, Joseph (Eds.). May 27,
  2014. 
- Amel Fraisse and Patrick Paroubek (2014). Twitter as a Comparable
  Corpus to build Multilingual Affective Lexicons. In proceedings of the
  7th International Workshop on Building and Using Comparable Corpora at
  LREC 2014 (BUCC 2014), pages 17-21. May 26-31, 2014. Reykjavik,
  Iceland."
"401","2017-02-20","EDF","Paris","INTITULE DE LA MISSION : Déterminer la polarité de données textuelles
issues de réseaux sociaux.

Date de début : à partir d'avril 2017

Durée du stage : 6 mois
Niveau de diplôme préparé : MASTER 2 spécialisé en Traitement
automatique des langues / Ingénierie Linguistique

CONTEXTE ET DESCRIPTION DU STAGE

Le volume des données numériques textuelles, disponibles sur l'Internet
(forums, twitter etc.) augmente chaque année. L'analyse de ces
informations, structurées ou non, est, aujourd'hui, un impératif
stratégique pour une entreprise telle qu'EDF.

A l'ère du tout numérique, il devient stratégique d'exploiter
l'expression spontanée issue des réseaux sociaux dans des délais de plus
en plus courts. Ces derniers sont d'autant plus importants aujourd'hui
qu'ils représentent une mine de précieuses informations.  Etre à
l'écoute de ses clients, est un des enjeux majeurs de la Direction
Commerce d'EDF. Dans cette optique, que l'équipe Text Mining collecte,
analyse et restitue l'expression des réseaux sociaux sur EDF.

Le stage que nous proposons est opérationnel est a pour objectif de
constituer une classification en polarité (positif, neutre, négatif) de
données textuelles issues du réseau social Twitter.

Les objectifs de la mission seront de :

* Constituer un état de l'art rapide sur la classification en polarité.
* Prendre en main l'outil d'extraction de connaissance XIP de Xerox qui
  sera utilisé pour classifier les données.
* Elaborer le modèle de classification et évaluer ses performances.
* Intégrer le modèle dans les chaines de traitement existantes.

PROFIL RECHERCHE :

* De formation Master II spécialisé en Traitement Automatique du Langage
* Domaines de compétence requis :
  - Linguistique et informatique
  - Bonnes connaissances en Python
  - Des connaissances en statistique seraient également appréciées
* Rigueur, autonomie et aisance rédactionnelle.

CONDITIONS DU STAGE :

Le stage se déroulera au sein des locaux d'EDF à La Défense et sera
rémunéré.

Les candidatures sont à adresser à Sofiane KERROUA :
mohamed-sofiane.kerroua@edf.fr"
"402","2017-02-23","XiKO",NULL,"XiKO développe un outil d'analyse de données textuelle robuste que nous
éprouvons quotidiennement sur le web. Nous sommes confrontés à de
multiples problématiques techniques (performance, passage à l'échelle,
qualité, testabilité) et scientifiques (traitement automatique des
langues, apprentissage automatique).

Dans le cadre d'un nouveau projet de traitement automatique des langues,
nous cherchons un stagiaire afin d'appuyer l'équipe R&D sur des
problématiques d'inférence et de Machine Learning.

En collaboration avec l'équipe R&D le travail du stagiaire consiste à :

   - Comprendre les enjeux du projet.
   - Effectuer un travail de recherche bibliographique afin de situer le
     problème par rapport à l'état de l'art en traitement automatique
     des langues.
   - Choisir les outils adaptés afin de résoudre le problème.
   - Implémenter et tester la solution retenue.

Notre environnement technique est celui proposé par la boite à outil du
Cloud Google. Nous codons en Java, nous déployons nos applications dans
Google AppEngine et nous faisons un usage intensif des bases de données
BigQuery et Datastore. Ce stage est donc une opportunité de s'initier
aux technologies du cloud Google.

Nous cherchons un stagiaire avec un goût pour les statistiques et le
Machine Learning. Une expérience avec un outil d'analyse de donnée
(Matlab, Octave, R) et/ou une librairie de machine learning
(scikit-learn, Torch, TensorFlow) serait très appréciée.

Vous intégrerez une startup innovante, en plein développement et avec
une hiérarchie aussi horizontale que possible. La rémunération mensuelle
est de 1 200¤ net par mois (à négocier en fonction du profil) avec
Ticket Restaurant à 10¤/j. Une réelle opportunité d'emploi pourra être
proposé à l'issu du stage.

Merci d'envoyer votre candidature à l'adresse contact@xiko.fr ou
gael.patin@xiko.fr"
"403","2017-03-01","Softlaw",NULL,"Softlaw développe un logiciel à destination des professionnels du
droit. Cet outil permet l'analyse et l'extraction automatisée de données
à partir de documents juridiques. 

Dans le cadre d'un projet de traitement automatique des langues, nous
cherchons un stagiaire afin de consolider l'équipe R&D sur des
problématiques d'extraction de texte, de classification et de Machine
Learning.

En collaboration avec l'équipe technique le travail du stagiaire
consiste à :

   - Comprendre les enjeux du projet.
   - Effectuer un travail de veille technologique afin de résoudre un
     problème en suivant l'état de l'art en matière de traitement
     automatique des langues.
   - Choisir les outils adaptés afin de résoudre le problème.
   - Implémenter et tester la solution retenue.

Notre environnement technique s'articule aujourd'hui principalement
autour des technologies .NET C# et Sql Server. Nous prévoyons également
des développements autour des technologies ElasticSearch et React.

Nous cherchons un stagiaire avec un goût pour les challenges techniques
et le Machine Learning ayant utiliser au moins un des languages de
programmation suivant (Python, R). Une expérience avec un outil NLP
(Gate, Unitex ou Rake) et/ou une des librairies suivantes (scikit-learn,
word2vec, nltk) serait très appréciée.

Vous intégrerez une startup innovante, en plein développement et avec de
multiples opportunités pour la suite.

Merci d'envoyer votre candidature à l'adresse suivante
a.labrousse@softlaw.digital."
"404","2017-03-07","Advanced Decision","Paris","Advanced Decision est une startup spécialisée en intelligence
artificielle.

Nous développons une plateforme de composition d'offre sur mesure dans
le domaine du tourisme.

Elle intègre un module d'enrichissement sémantique des données d'une
ontologie.
 
Le stage a pour but d'annoter les corpus sociaux :
- Définition d'étiquettes thématiques 
- Segmentation et annotation des corpus
- Réalisation d'une maquette 
- Modélisation pour la phase d'apprentissage
 
Niveau : 
- Minimum M1 de TAL, outils d'annotation
- Connaissances requises en ontologies
- Ingénierie linguistique
  
Durée : entre 3 et 6 mois
Date de début : dès que possible
Indemnité : 554 ¤ / mois
Lieu : Paris
 
Merci de fournir un CV et une lettre de motivation ainsi que vos relevés
de notes à isabelle.tellier@sorbonne-nouvelle.fr"
"405","2017-03-07","Expert system","Paris","Expert System (ex Temis) est une société spécialisée dans l'extraction
d'information.

Expert System propose d'extraire des textes des informations structurées
pour alimenter différents flux de données des entreprises comme le
routage de mails, la detections de molecules pour de nouveau
traitements, l'anonymisation des personnes dans les décisions de
justice.

Mission

Au sein d'une équipe R&D, vous allez pouvoir travailler sur :

- l'anonymisation des personnes au sein des décisions de justice. Il
  s'agit de detecter les personnes impliquées dans une décision en
  séparant d'un côté les personnes de la cours (avocats, juges etc) des
  personnes impliquées dans les faits.

- l'identification des données chiffrées des décisions de justice. Il
  s'agira de détecter par exemple les personnes et les renseignements
  qui les caractérisent comme les revenus, la situation géographique,
  matrimoniale afin d'aider les personnes à homogénéiser les jugements
  en fonction de la jurisprudence.

La base consistera en premier lieu à bâtir un prototype basé sur la
boite à outil maison basée sur des CRF et si le temps le permet, bâtir
d'autres prototypes à base de réseau de neurones.

Les responsabilités

Traitement et analyse des données
Veille sur les différents algorithmes (CRF, NN)


Profil

Diplômé en informatique avec une option Traitement du langage Naturel :

Connaissances en Java
Connaissances en [CL] machine learning CRF (Wapiti), en reseau de
  neurones (Torch)
Connaissances en python

Durée : entre 4 et 6 mois
Date de début : dès que possible
Indemnité : 554 ¤ / mois
Lieu : Paris
 
Merci de fournir un CV et une lettre de motivation ainsi que vos relevés
de notes à isabelle.tellier@sorbonne-nouvelle.fr et
christian.lautier@temis.com."
"406","2017-03-08","Université de Paris 13","Villetaneuse","Dans le cadre du projet ADADA (Analyse Diachronique Automatique du
Discours sur les jeux d'Argent), nous proposons un stage de 4 mois.

Sujet : Analyse Diachronique de Corpus

Lieu du stage : Université Paris XIII (Villetaneuse)

Début du stage : Avril/Mai 2017

Mots clés : Analyse Diachronique, Analyse d'Opinion, Classification 
Temporelle, Traitement Automatique des Langues

Détails :

  Le projet ADADA est financé par le GIS ""Jeu et Sociétés"" et la
Française des Jeux. Le stage concerne le suivi dans le temps de
l'actualité concernant les jeux de Hasard et d'Argent (JHA).

  Il s'agit d'étudier le regard de la société sur les jeux d'argent et
sur la communauté des personnes qui les pratiquent.

  Nous souhaitons comparer l'évolution du discours (polarité,
intensité...) autour des JHA à la réalité des pratiques (quantité d'argent
parié, évolution de la législation, disparition de certains jeux...).

  Nous recherchons un candidat niveau Master, informaticien ou linguiste
possédant des connaissances en TAL et ayant une expérience de l'analyse
de corpus. Des compétences en sociolinguistique, classification ou
apprentissage automatique seraient un plus.

Contacts :
Gaël Lejeune (LIPN) : gael.lejeune@lipn.univ-paris13.fr
Lichao Zhu (LLSHS) : lichao.zhu@univ-paris13.fr"
"407","2017-03-14","Ixxo","Lyon","Descriptif de stage

Améliorations d'un outil d'extraction d'entités nommés et de relations

Le Stage

La société édite et commercialise une solution en mode SaaS (Software as
a Service) chargée de collecter de l'information pertinente sur le
web. Des traitements d'analyse sont réalisés sur cette masse
d'information collectée, et en particulier des traitements d'extraction
d'entités nommées (Named Entity Recognition).

Le but du stage est de contribuer à améliorer et enrichir le modèle
d'extraction existant et à proposer des solutions pour l'extraction de
relations.

Le stage comprend plusieurs phases :

- Prise en compte de l'existant, analyse du besoin
- Propositions fonctionnelles
- Développement des améliorations

Les compétences

Une formation informatique en traitement automatique des langues est
exigée (bac +4, ou +5), avec les compétences techniques suivantes :

- Traitement automatique des langues
- Machine learning
- Programmation Orientée Objet (JAVA)

Connaissance HTML

Le candidat devra être capable d'intégrer des besoins exprimés par
l'entreprise, et de les traduire en étant force de proposition dans les
solutions envisagées.

Bien que le stage soit encadré pendant toute sa durée, le candidat devra
faire preuve d'une capacité d'autonomie dans le travail cadré qui lui
sera confié. Il devra également faire preuve d'organisation et de
rigeur.

La compréhension de l'anglais technique est indispensable.

L'entreprise

La société ixxo est une entreprise innovante dans le domaine de
l'Intelligence Economique et de la Gestion des Connaissances située à
Lyon.

Durée du stage : 3 mois

Contact :
  Email : cv@ixxo.fr"
"408","2017-03-20","CEA-LIST","Gif-sur-Yvette","Proposition de stage : Utilisation d'un réseau de neurones récurrent
pour la réévaluation des n-meilleures hypothèses d'un moteur de
traduction à base d'exemples

Lieu du stage : CEA Saclay Nano-INNOV, Laboratoire Vision et Ingénierie
des Contenus (LVIC), 91 191 Gif sur Yvette

CONTEXTE :

Le stage s'appuiera sur le moteur de traduction à base d'exemples
développé au CEA LIST dans le cadre du projet ANR WEBCROSSLING (Semmar
et al., 2016). Ce moteur utilise la recherche d'information interlingue
et ne nécessite qu'un corpus de textes en langue cible. Il est composé
d'un moteur de recherche interlingue, d'un reformulateur bilingue et
d'un générateur de traductions. Le rôle du moteur de recherche
interlingue est d'extraire pour chaque phrase à traduire (la requête de
l'utilisateur) des phrases ou des sous-phrases depuis un corpus
monolingue indexé dans la langue cible. Ces phrases ou sous-phrases
correspondent à une traduction totale ou partielle de la phrase à
traduire. Le reformulateur bilingue consiste, d'une part, à produire
pour chaque phrase à traduire un ensemble d'hypothèses de traduction en
transformant dans la langue cible la structure syntaxique de la phrase à
traduire, et, d'autre part, à traduire les mots de cette phrase. Le rôle
du générateur de traductions est de produire les n-meilleures
traductions en utilisant les traductions candidates fournies par le
moteur de recherche interlingue, les hypothèses de traduction produites
par le reformulateur bilingue et le modèle de langue appris à partir du
corpus en langue cible.

SUJET DE STAGE :

Le stage consistera à développer un module basé les réseaux de neurones
récurrents LSTM (Jozefowicz et al., 2015) pour la réévaluation des
n-meilleures hypothèses produites par le générateur de traductions.

Le stage comportera les étapes suivantes:

- Appropriation du moteur de traduction à base d'exemples développé au
  CEA LIST.

- Développement d'un module basé les réseaux de neurones récurrents pour
  la réévaluation des n-meilleures hypothèses produites par le
  générateur de traductions.

- Intégration du module de réévaluation des n-meilleures hypothèses dans
  le moteur de traduction à base d'exemples.

- Evaluation du moteur de traduction à base d'exemples anglais-français
  en comparant ses résultats avec les résultats produits par le système
  de traduction libre Moses (Koehn et al., 2007).

- Réalisation d'une interface graphique pour l'utilisation du moteur de
  traduction à base d'exemples.

BIBLIOGRAPHIE :

- N. Semmar, O. Zennaki, M. Laib. Etude de l'impact d'un lexique
  bilingue spécialisé sur la performance d'un moteur de traduction à
  base d'exemples. TALN 2016, Paris, France, 2016.

- R. Jozefowicz, W. Zaremba, I. Sutskever. An Empirical Exploration of
  Recurrent Network Architectures. 32nd International Conference on
  Machine Learning, Lille, France, 2015.

- P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico,
  N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar,
  A. Constantin, E. Herbst. 2007. Moses: Open source toolkit for
  statistical machine translation. ACL 2007, demo session, Prague, Czech
  Republic, 2007.

CONDITIONS DE CANDIDATURE :

Bac+5, stage de fin d'étude dans le domaine du Traitement Automatique de
la Langue (TAL).

Compétences en informatique et en TAL.

Programmation : C/C++, Python, Perl, Java.

Langues : Maîtrise de l'anglais et du français.

Durée : entre 4 et 6 mois.

Contact et envoi des candidatures (CV détaillé, lettre de motivation et
relevé de notes de la dernière année d'études):

Nasredine SEMMAR, Email: nasredine.semmar@cea.fr, 
Tél: +33 (0)1 69 08 01 46"
"409","2017-03-23","Université de Lille","Lille","Stage: Perception de villes et objets intelligents

http://natalia.grabar.free.fr/stage2017vi.php

Les villes et objets intelligents font doucement leur émergence dans
nos vies. Un des objectifs poursuivi par leurs créateurs consiste à
améliorer la qualité du service mais aussi à réduire les coûts. Par
exemple, dans les villes intelligentes, on cherche à optimiser et à
réduire la consommation d'eau et d'électricité, à améliorer et à
optimiser le système de transport, à rendre des objets et services
plus ergonomiques et plus facilement utilisables, sans oublier
l'aspect esthétique (voir les références). Différentes technologies
sont alors de rigueur, allant de l'ingénierie et la construction,
nécessaires par exemple pour l'installation et la maintien de
capteurs, vers les sciences de l'information et de la communication,
nécessaires pour la transmission et analyse des informations.

Il s'agit d'un domaine d'activité récent et nos connaissances sur
l'acception et la perception des objets et villes intelligents par le
grand public ne sont pas très évoluées. Nous supposons cependant que
les informations disponibles en lignes (forums de discussion, réseaux
sociaux, instagrammes, tweets...) peuvent fournir ce type
d'information.

L'objectif de ce stage consiste donc à explorer différentes sources
d'informations disponibles en ligne afin d'étudier différents
aspects. Parmi les questions que l'on pourrait se poser, mentionnons
par exemple :

- Comment sont perçus les objets et les villes intelligents ?
- Que pensent les citoyens et les consommateurs de ces objets ?
- Quels sentiments et opinions ces objets provoquent auprès de la population ?
- Quelles sont les pistes d'amélioration potentielles ?

Plus spécifiquement, les tâches abordées lors du stage sont :

- travailler avec des corpus de textes de différents types et
  provenant de différentes sources
- constituer et faire évoluer le corpus
- exploiter et améliorer les annotations des textes avec différents
  niveaux de spécificité
- exploiter, adapter ou développer des méthodes pour l'extraction
  d'informations
- évaluer les méthodes et les résultats

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:

- connaissances en TAL et en informatique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique
- maîtrise de l'anglais

Le stage est rémunéré.

Niveau: Master 1, Master 2 ou niveau ingénieur
Durée: 6 mois
Lieu: Lille

Pour présenter une candidature: envoyer un CV, la lettre de
motivation, le relevé de notes et les contacts de deux référents à
Natalia Grabar (natalia.grabar@univ-lille3.fr) et Isam Shahrour
(isam.shahrour@univ-lille1.fr)

RÉFÉRENCES

    Leyla Zhuhadar, Evelyn Thrasher, Scarlett Marklin, Patricia
    Ordóñez de Pablos. The next wave of innovation - Review of smart
    cities intelligent operation systems. Computers in Human Behavior
    66: 273-281 (2017)
    http://www.sciencedirect.com/science/article/pii/S0747563216306574

    Albert Meijer, Manuel Pedro Rodríguez Bolívar. Governing the smart
    city: a review of the literature on smart urban
    governance. International Review of Administrative Sciences 82(2)
    (2016)
    http://journals.sagepub.com/doi/pdf/10.1177/0020852314564308

    Annalisa Cocchia. Smart and Digital City: A Systematic Literature
    Review.
    http://www.springer.com/cda/content/document/cda_downloaddocument/9783319061597-c2.pdf?SGWID=0-0-45-1464919-p176692586

    Tim Smedley. Top-down or bottom-up? Two visions of smart
    cities. New Scientist, 4 December 2013.
    https://www.newscientist.com/article/mg22029465-000-top-down-or-bottom-up-two-visions-of-smart-cities/

    Shannon Mattern. A City Is Not a Computer. Places February 2017
    https://placesjournal.org/article/a-city-is-not-a-computer/?gclid=CMqjwcOw29ICFawW0wodx00IRg"
"410","2017-03-27","E Motion Analysis","Paris","ENTREPRISE

E Motion Analysis est une jeune entreprise innovante, composée de jeunes
diplômés, passionnés d'analyse sémantique de données textuelles dans le
secteur de l'hôtellerie, santé et recrutement.
Notre métier consiste à mettre en place une plateforme d'annotation,
d'analyse et de visualisation de données pour aider les professionnels à
prendre les bonnes décisions en innovant sans cesse.

POSTE

Nous recherchons actuellement un(e) stagiaire Ingénieur(e) linguiste
maîtrisant l'arabe (lu, parlé, écrit).

Vous souhaitez participer à l'aventure E Motion Analysis,
Allier votre appétence pour la linguistique et vos compétences
techniques ?
Rejoignez-nous ! 

Au sein de notre Pôle R&D et rattaché au Manager Data Scientist, vous
aurez l'occasion de :
- Développer des règles sémantiques 
- Enrichir le lexique métier
- Valider les résultats (précision et rappel).
- Formé à nos produits et aux méthodes de création de règles
  sémantiques, vous évoluerez au sein d'une équipe à taille humaine,
  dans un environnement dynamique et challengeant.
Vous bénéficierez d'un accompagnement au quotidien.
Votre manager s'engage à ce que vous disposiez des outils nécessaires
pour atteindre vos objectifs.

PROFIL
Vous justifiez idéalement d'une formation de traitement automatique du
langage naturel
Vous maîtrisez le français, l'anglais et l'arabe 
Vous maitrisez un langage de programmation : Python, PHP, Perl...
Ce Stage est à pourvoir dès que possible au sein de nos bureaux situés
dans le 15ème arrondissement de Paris.

CONTACT

contact@e-motion-analysis.com"
"411","2017-04-18","RégionsJob","Paris","*Ingénieur Linguiste Stagiaire H/F*
Entreprise RegionsJob.

En 16 ans, nous sommes devenus un acteur incontournable du monde digital
français de l'emploi.
N°2 français, notre croissance continue dans un marché en perpétuel
mouvement repose sur trois fondamentaux :

- Notre vision d'un marché de l'emploi fragmenté qui rend chaque
  personne unique.
  Chacune de nos marques (Regionsjob, Parisjob, Cadreo, le Blog du
  Modérateur) est la référence auprès de ceux qui cherchent à bouger
  professionnellement.

- Notre accompagnement terrain au plus près des entreprises.
  Notre équipe commerciale de 95 personnes accompagne, partout en
  France, les entreprises pour trouver les meilleures solutions pour
  recruter toujours dans une logique forte de ROI.

- Notre forte agilité technologique qui nous permet d'innover
  constamment et de proposer en permanence des solutions adaptées à
  l'évolution des usages.

L'organisation interne : un fonctionnement en mode startup.  Nous sommes
plus de 170 collaborateurs mais nous avons conservé notre esprit et
notre agilité propre aux startup.
Les niveaux hiérarchiques sont réduits à leur minimum, notre
communication est transparente, notre curiosité est continuellement
stimulée et notre envie d'être meilleur est notre moteur.  Poste

Au sein de l'équipe technique et R&D, vous serez en charge d'étudier et
de définir des méthodes permettant d'enrichir nos différents
référentiels : compétences, métiers, écoles, diplômes, entreprises.

En collaboration avec notre chef de produit, vous identifiez, analysez
et proposez les différentes sources disponibles : données ouvertes et/ou
données issues de nos bases.
Votre travail sera donc consacré à la conversion de données brutes ou
balisées (CSV, XML) vers des données sémantiques liées entre elles
(RDF).
Cette mission implique de :

- Comprendre l'organisation des données existantes.
- Identifier les jeux de données ouverts intéressants à exploiter ainsi
  que les outils/librairies/plateformes qui pourraient être utilisés.
- Définir les types d'enrichissement possibles et réfléchir aux
  problèmes éventuels qui peuvent être rencontrés (travail de
  normalisation préalable avant conversion, gestion des doublons, etc.).
- Proposer et mettre en place des solutions d'enrichissement à partir
  des sources de données qui ont été préalablement identifiées.
  En fonction de vos compétences et intérêts, vous pourrez également
  participer :
- À la mise à jour des interfaces qui permettent de consulter ce
  référentiel ou à la définition d'usages potentiels permis par l'ajout
  de nouveaux types d'information fournis.
- Aux différents travaux effectués par l'équipe technique concernant
  l'extraction de données au sein de CV, offres d'emploi ou offres de
  formation.

Technologies utilisées : XML, Linked Data (SKOS, RDF, SPARQL,
triplestore).  Profil recherché

Vous êtes actuellement en formation d'ingénieur linguiste ou ingénieur
en traitement automatique des langues open data ou en ingénierie des
connaissances et vous souhaitez compléter votre formation par un stage
résolument tourné vers l'opérationnel.
Notre chef de produit vous permettra de monter en compétences et de
travailler ainsi en autonomie sur un sujet majeur pour notre business.

Ce poste est basé à Rennes au sein de notre siège social. Stage de 3 à 6
mois.

Salaire : Non précisé.
Annonce en ligne

http://www.ouestjob.com/emplois/offre-1291242.html
ContactCécile bagot (cbagot@regionsjob.com)"
"412","2017-05-09","Playbots","Paris","Stage Linguiste

PlayBots personnalise l'expérience client grâce à l'intelligence
artificielle. Nous créons pour des marques prestigieuses (Fnac, Bouygues
Immobilier...) des assistants personnels dotés d'une véritable personnalité
et capables de nouer des relations durables avec les utilisateurs. PlayBots
a été fondé par 2 experts du mobile et du divertissement : Jonathan Stock
(ex Studio Manager Gameloft Toronto) et Charles-Antoine Gabrielli (ex Game
Designer Ubisoft).

Mission

Pour le développement de notre plateforme de création de chatbots, nous
recherchons un/une linguiste passionné(e) par les nouvelles technologies
et l'intelligence artificielle. Véritable pilier de l'équipe, vous
travaillerez en étroite collaboration avec les fondateurs et serez
impliqué sur tous les aspects du projet. Les tâches seront nombreuses :
- Développement de modèles grammaticaux
- Construction de lexiques sur des sujets spécifiques
- Automatisation de la construction de dialogues en langage naturel

Profil

Il est indispensable que vous maitrisiez les domaines suivants :
- Français et anglais : connaissance professionnelle de la grammaire et
  de la sémantique
- Sémantique formelle
- Linguistique structurale
- Langages formels

Outre vos réalisations et projets personnels, des connaissances dans un
ou plusieurs des domaines suivants seront un vrai plus :

- Expérience avec les services de NLP : api.ai, wit.ai, MS LUIS, Nuance
  Mix, Amazon LEX
- Fouilles de texte
- Expression rationnelle

Nos locaux se situent dans l'incubateur Paris&Co du CARGO (75019),
véritable centre d'accélération des jeunes entreprises innovantes autour
des contenus numériques et des industries créatives.
Participer à l'aventure PlayBots, c'est la garantie de rejoindre une
équipe talentueuse et ambitieuse dans une startup en croissance !

Date de début et durée : Dès que possible, pour 4 à 6 mois
Rémunération : selon profil
Contact : adresser CV + quelques lignes sur vos motivations à
jonathan@playbots.io"
"413","2017-05-30","I3S","Sophia Antipolis","M2 internship offer: Design of an interface for the visualization of argumentation graphs to explore argumentative structures in natural language.

Argument mining involves the automatic identification of the
argumentative structures in text, such as premises, conclusions and
the argumentation patterns, as well as the relations between the
arguments (support, attack). To date, researchers have studied methods
for extracting arguments in areas such as legal documents, online
debates, product reviews, academic literature, user reviews and
newspaper articles.

Given the output of an argument mining system, the goal of this
internship is to design and implement an interactive visualization
tool for argument graphs with textual arguments as nodes of the graph,
and the relations between the arguments as edges.

Candidate's profile
---------------

- Current curriculum: Master 2 in Computer Science, Human Computer
  Interaction or similar.
- Programming skills
- French is not mandatory

Conditions
-----------------
Paid internship of a duration of three months
Deadline for applications: June 15, 2017.
To apply, please contact: elena.cabrio@unice.fr ; villata@i3s.unice.fr

Needed documents: CV, statement of intention, marks.

Hosting team:
 
WIMMICS (http://wimmics.inria.fr/) is a research team of Université
Côte d'Azur (UCA). The research fields of this team are graph-oriented
knowledge representation, reasoning and operationalization to model
and support actors, actions and interactions in web-based epistemic
communities.

Location: I3S laboratory, Sophia Antipolis, France.

Contract type: internship.

Start: July-August 2017"
"414","2017-06-26","Softlaw","Paris","Offre de stage : Ingénieur Data Science / Machine Learning

SOFTLAW est une jeune start-up dans le secteur des legaltech. Nous
développons un logiciel de revue automatique de documents juridiques
utilisant l'intelligence artificielle pour extraire automatiquement les
informations clés des documents juridiques et les analyser.

MISSIONS :

Dans le cadre d'un projet de traitement automatique des langues et de
Machine Learning, le stagiaire participera avec l'équipe technique à
plusieurs des travaux et activités suivantes :

- Développement Machine Learning en Python : collecte, nettoyage,
  classification des données grâce aux algorithmes ML supervisé/non
  supervisé, analyse des métriques, recherche et développement des
  techniques de détection de similarité;

- Création, implémentation et tests d'algorithmes de Machine Learning et
  d'analyse sémantique en langage naturel et traitement automatique de
  la langue;

- Réalisation d'outils de text mining utilisant des techniques NLP;

- Création, implémentation et tests de modèles d'extraction et d'analyse
  de données + mesure de la qualité de ces modèles;

Ce poste est basé à Paris 13 (proche 14ème). 
Stage de 3 à 6 mois


Axel Labrousse <a.labrousse@softlaw.digital>

http://www.softlaw.digital/"
"415","2017-06-26","Sewote","Paris","Offre de stage « ingénieur linguiste junior »

Créée en avril 2016, Sewote est une start-up spécialisée dans la R&D en
linguistique informatique. Nous développons des logiciels applicatifs
sémantiques dans l'optique de proposer des solutions clés en main aux
organisations souhaitant perfectionner leurs processus métier. Notre
équipe est composée d'experts et de professionnels de l'information et
de la linguistique informatique.
Nous sommes à la recherche d'un ingénieur linguiste un stage de 6 mois
afin de travailler à l'élaboration de ressources électroniques en langue
anglaise.

Début de stage : 1er octobre 2017

Compétences requises :
Traitement Automatique des Langues 
OS : Linux et Windows
Technologie : NOOJ et/ou UNITEX
Langages informatiques : Perl/Python/Java
Langues : anglais courant (anglais des affaires)

Lieu du stage : Pépinière 27 - 27 rue du Chemin Vert 75011 Paris
Indemnités de stage : 554 ¤ + remboursement de 50% du ticket de
transport

Si vous êtes intéressé par cette offre, merci d'envoyer votre
candidature à julien.letailleur@sewote.com"
"416","2017-08-16","EDL","Berre L'étang (13)","*Analyse de fonctionnement de la reconnaissance vocale*

(TAL ou Linguistique avec des compétences informatiques)

*Mots clés :* *reconnaissance vocale, correction orthographique et
syntaxique, transcription phonétique, recherche textuelle avec REGEX*

Société leader des solutions informatiques pour les services d'Imagerie
Médicale publics et privés recherche un(e) stagiaire niveau M1 ou M2.

Le stage consiste en l'analyse des erreurs textuelles de la
reconnaissance vocale. Le stagiaire effectuera la comparaison des
résultats issus du moteur de la reconnaissance avec les fichiers son. Le
résultat de l'analyse aboutit en un feedback avec une typologie
d'erreurs récurrentes.

*Compétences requises : *

- linguistique (phonétique, orthographe et syntaxe),

- très bonne maitrise de la grammaire française

- rigueur et attention aux détails

- compétences informatiques

- maitrise de REGEX ainsi que d'un langage de programmation serait un
  plus

- la connaissance du domaine médical serait un plus


*Début de stage :* dès que possible

*Durée de stage :* 6 mois

*Lieu de stage :* Berre L'Etang

Rémunération selon profil


Adresser CV + lettre de motivation à : mtaranina@edl.fr"
"417","2017-10-16","Inalco","Paris","*Ingénierie R&D pour une BDD web de textes historiques en quechua et en
guarani*
Stage au laboratoire ERTIM (INALCO)

*Contexte*

Le projet ANR LANGAS (http://www.langas.cnrs.fr, 2014-2017) a permis la
constitution d'une volumineuse base de textes (125 documents, ~290K
mots) en quechua et en guarani, liés à la colonisation espagnole et
portugaise de l'Amérique du Sud.

Cette base documentaire a été constituée par des anthropologues à l'aide
d'un site web adapté à leurs besoins, notamment en proposant
d'enregistrer les textes alignés en trois versions : paléographique,
translittérée et traduite en espagnol. Ces enregistrements ont
l'avantage d'être correctement stockés et alignés, mais des
améliorations de la BDD sont nécessaires, avec en prolongement un
possible travail en appui à la recherche.

En collaboration avec l'équipe LANGAS du laboratoire CREDA UMR 7227,
l'équipe ERTIM propose un stage de 3 mois sur le sujet, qui vise à
répondre à ces besoins, prioritairement en développement, mais avec
aussi des perspectives en matière de recherche, selon l'avancement.

*Objectifs principaux*

1/ Ré-encodage cohérent de la BDD pour faciliter son interrogation
2/ Adaptation des scripts Angular pour les recherches (classes de
   caractères, prise en charge de diacritiques, collations)
3/ Implémentation d'un script de pré-translittération automatique (par
   règles de transduction, par ex. extraites semi-automatiquement)
4/ Fouille des données (text mining) en interaction avec les
   anthropologues dans une perspective socio-linguistique.

*Profil recherché*

- Informatique avec des connaissance web (idéalement Angular)
- Connaissance des BDD (MySQL) et des encodages (UTF8)
- Un intérêt pour le TAL et pour les sciences humaines est un plus
- La connaissance de l'espagnol ou de langues sudaméricaines est un plus

*Contexte*

- Durée du stage : 3 mois à temps plein
- Date de début : dès que possible
- Rémunération : tarif en vigueur (510¤/mois, rbst de 50% navigo)
- Lieu : INALCO, 2 rue de Lille, 75007 Paris

*Candidature*

Merci d'envoyer votre CV et de faire part de vos motivations à Damien
Nouvel (damien.nouvel@inalco.fr), Marie-Anne Moreaux
(marie-anne.moreaux@inalco.fr), Capucine Boidin
(capucine.boidin@univ-paris3.fr."
"418","2017-10-23","Clesthia & Lidilem","Paris et Grenoble","************************************************************************

Offre de stage

Dans le cadre d'un financement CORLI-Ortolang obtenu conjointement par
les laboratoires CLESTHIA et LIDILEM, nous recherchons 2 stagiaires pour
la période de décembre 2017 à Février 2018 (durée 2 mois et demi,
gratification de 1800¤/brut au total). L'un des stagiaires sera rattaché
au laboratoire CLESTHIA (Paris Sorbonne), l'autre au laboratoire LIDILEM
(Campus de Grenoble).

Contexte

Les deux laboratoires ont constitué et continuent d'alimenter des corpus
d'écrits d'élèves :

- pour Lidilem, un corpus longitudinal couvrant l'ensemble de l'école
  élémentaire (du Cours Préparatoire au Cours Moyen 2) : corpus Scoledit
  ; ce corpus est constitué de productions suscitées par la recherche ;

- pour Clesthia, un corpus reflétant le développement des compétences
  scripturales du début de l'école primaire à l'université : corpus
  Ecriscol ; ce corpus est constitué de productions écologiques.

Ces deux corpus sont déjà en partie accessibles, avec les
enrichissements disponibles :

- Ecriscol : http://syled.univ-paris3.fr/ecriscol/CORPUS-TEST/
- Scoledit : http://otus.u-grenoble3.fr/scoledit

Les caractéristiques des corpus réunis ainsi que les objets de recherche
privilégiés par les équipes ont conduit à élaborer des procédures de
traitement différentes dont les résultats sont dans des formats
spécifiques que l'on veut faire converger vers un format partagé
(XML-TEI).

Missions

- Analyse des spécificités du corpus Ecriscol (stagiaire Clesthia) ou du
  corpus Scoledit (stagiaire Lidilem).
- Mise en commun de ces analyses
- Étude du standard XML-TEI
- Proposition d'un format commun, pour les deux corpus
  Ecriscol/Scoledit, aux normes TEI
- Conception et développement de routines de conversion ou d'aide à la
  conversion pour le passage des formats actuels des corpus au format
  commun.

Profil demandé

- Niveau master 2 en Traitement Automatique des Langues
- Compétences XML
- Compétences en développement informatique (langage non défini mais
  adapté au développement de routines d'extraction et de conversion du
  type Python, Perl, Java...).
- Une connaissance de la TEI serait un plus.

Contacts

- CLESTHIA : Serge Fleury (sergefleury@gmail.com)
- LIDILEM : Claude Ponton (claude.ponton@univ-grenoble-alpes.fr)"
"419","2017-10-24","LIDILEM","Grenoble","Offre de stage - Master 2 - Industries de la langue, TAL, linguistique
informatique, Technologies du langage


Nom du projet  : Projet LaST : Lexique aligné Scientifique Transdisciplinaire.

Vers l'élaboration d'une ontologie interlingue pour le Lexique
Scientifique Transdiciplinaire (LST) à partir d'un lexique bilingue
aligné avec des techniques de traitement automatique du langage.


Compétences requises : La/le candidat.e devra être titulaire d'un
master 1 en Industries de la langues ou Traitement automatique des
langues (ou domaine voisin : linguistique informatique, humanités
numériques, etc.) et suivre un M2 correspondant. Elle/il aura des
compétences en traitement de corpus au format XML, ainsi que des
compétences en programmation (Perl ou Python) afin de mettre en oeuvre
des chaînes de traitement complexes (étiquetage, alignement,
projection d'un lexique sur un corpus, etc.).


Durée du stage : 3 mois et demi


Gratification : 554,4 euros mensuels (Financement Neurocog/Pôle cognition)


Objectifs du projet

Le discours scientifique intègre un lexique relevant de catégories
sémantiques et épistémologiques spécifiques, le lexique scientifique
transdisciplinaire (Pecman 2004, Paquot 2010, Hatier et al. 2016). Ce
lexique intègre des unités lexicales comme hypothèse, montrer,
quantitatif mais aussi des expressions polylexicales et des routines
plus larges comme obtenir des résultats encourageants, comme on l'a vu
précédemment, les résultats montrent que ... La constitution d'un tel
lexique est particulièrement utile pour plusieurs types
d'applications. En traitement automatique des langues, il peut être
exploité dans plusieurs types d'applications comme l'indexation
automatique et la fouille de données. Les applications didactiques
sont également nombreuses : aide à la rédaction scientifique, outils
d'aide à la lecture de textes scientifiques, outil d'aide à la
traduction, entre autres.

Dans le cadre du projet ANR Termith (2012-2016), le LIDILEM a élaboré
un lexique sémantique de ce type discours intégrant des étiquettes
sémantiques et une organisation ontologique, à partir d'informations
obtenues à partir de techniques distributionnelles appliquées à des
corpus du français (Hatier et al. 2016). Dans le cadre du présent
projet, nous souhaitons étendre ce lexique à une version anglaise, en
exploitant des techniques d'alignement de corpus (Schulz et al. 2016,
Kraif, 2015, Och et al. 1999) et des méthodes d'analyse
distributionnelle sémantique, permettant de caractériser le sens des
mots à partir de leurs contextes phrastiques (Mikolov et al. 2013,
ltszyler et al., 2016). Le lexique constitué pourra servir de base à
un projet d'aide à la rédaction scientifique (projet de soumission de
thèse dans le cadre de l'IDEX IRS).


Missions

La/le stagiaire partira du corpus existant afin de mettre en place une
chaîne de traitement permettant l'alignement des textes
parallèles. Elle/il effectuera une évaluation préalable de deux
aligneurs (Yasa et Hunalign) sur les textes du corpus, afin de
sélectionner le plus adapté des deux. Elle/il effectuera dans un
second temps un alignement au niveau lexical (avec Giza++) et un
étiquetage des parties françaises et anglaises du corpus.

Partant de ces alignements, elle/il effectuera une projection du LST
du français vers l'anglais (mots simples mais aussi collocations), et
étudiera les meilleurs critères pour effectuer le filtrage des
candidats à la traduction. Les résultats seront comparés à
l'interlexique élaboré par F. Gilles dans sa thèse.

La chaîne de traitement devra être conçue pour autoriser le traitement
rapide de nouveaux textes alignés (un autre stagiaire se chargera de
l'augmentation du corpus, en parallèle).

Les questions de recherches liées au stage auront trait à la
description et à la structuration sémantique de ce lexique
interlingue.

Pour candidater :

Envoyer un CV et une lettre de motivation à
olivier.kraif@univ-grenoble-alpes.fr avant le 10 novembre 2017.

Références

Gilles, F. (2017) Valorisation des analogies lexicales entre l'anglais
et les langues romanes : étude prospective pour un dispositif
plurilingue d'apprentissage du FLE dans le domaine de la santé, Thèse
de doctorat, sous la dir. de C. Degache et O. Kraif, Université
Grenoble Alpes

Hatier, S., Augustyn, M., Tran, T. T. H., Yan, R., Tutin, A., Jacques,
M.-P. (2016). ""French Cross-disciplinary Scientific Lexicon:
Extraction and Linguistic Analysis"", Euralex 2016, Tbilissi, Géorgie,
6-10 September 2016.

Altszyler, E., Ribeiro, S., Sigman, M., Fernández Slezak, D. (2016)
""Comparative study of LSA vs Word2vec embeddings in small corpora: a
case study in dreams database"". arXiv:1610.01520

Och, F.J. and Tillmann, C. and Ney, H. and others (1999) Improved
alignment models for statistical machine translation, Proc. of the
Joint SIGDAT Conf. on Empirical Methods in Natural Language Processing
and Very Large Corpora

Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean J. (2013)
Distributed representations of words and phrases and their
compositionality, Advances in neural information processing systems.

Paquot, M. (2010). Academic vocabulary in learner writing: From
extraction to analysis. London: Continuum.

Pecman M. (2004). Phraséologie contrastive anglais-français : analyse
et traitement en vue de l'aide à la rédaction scientifique, Thèse en
Sciences du Langage, Université Sophia Antipolis, UFR Lettres, Arts et
Sciences Humaines

Schulz, P., Wilker A. and Sima'an, K. (2016): Word Alignment without
NULL Words, Proceedings of the 54th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Papers)"
"420","2017-10-30","Météojob","Paris","*Infolinguiste (stage de fin d'études) H/F*

Vous connaissez le groupe Meteojob? Nous sommes une entreprise en forte
croissance dont la vocation est d'aider les recruteurs et les candidats
à se rencontrer plus rapidement, et plus efficacement. Notre groupe,
c'est notamment le site internet Meteojob.com avec 3.2 millions
d'inscrits, 1.5 million d'offres d'emploi par an et VisioTalent, une
plateforme d'entretiens video différés qui change la vie des candidats
et des recruteurs. Mais notre groupe c'est bien plus encore : Notre
vocation est de créer des applications remarquables qui permettent à des
millions de personnes de (re)trouver un emploi.

Nous recrutons aujourd'hui de nouveaux talents qui veulent rejoindre
notre aventure humaine et être les moteurs d'un développement important
dans les années à venir.


Description du poste :

Pour alimenter son processus de matching, Meteojob développe des outils
d'analyse sémantique avancée des contenus des CV et offres ainsi que des
référentiels métiers. Pour renforcer son équipe, Meteojob propose un
stage de fin d'études en traitement automatique des langues, basé à
Paris, au sein du pôle sémantique/big data.

Vos principales missions seront:

- Le développement et la maintenance des composants d'analyse des CV et
  offres (basés sur des grammaires locales et de l'apprentissage
  machine)

- Le portage de ces composants sur des langues étrangères (à commencer
  par l'anglais)

- Le maintien de la cohérence des référentiels existant

- L'enrichissement (multilingue) de ces référentiels

- La validation des composants produits


Vous travaillerez en relation étroite avec les autres membres du pôle
sémantique/big data et serez intégré(e) à l'ensemble de l'équipe de
développement de Meteojob.

Description du profil :

Compétences requises:

- TAL (étude de corpus, moteur de recherche, grammaires locales,
  apprentissage)

- Exploitation de données ouvertes (open data)

- Connaissance du developpement Java et des outils de développement en
  équipe (gestion de versions, d'anomalies, développement agile, etc...)

- Maîtrise de l'anglais (la connaissance d'autre langues européennes est
  un plus)

- Des connaissances en language de scripts (Perl, Groovy, Python),
  Spark, UIMA ou bases de données sont des plus

- Facilité à travailler en équipe


N'hésitez pas à envoyer votre candidature à benedicte.buchet@meteojob.com"
"421","2017-11-06","Sewote","Paris","Offre de stage 
« Ingénieur linguiste junior »

Créée en avril 2016, Sewote est une start-up spécialisée dans la R&D en
linguistique informatique. Nous développons des logiciels applicatifs
sémantiques dans l'optique de proposer des solutions BtoB de traitement
automatique des données écrites. Notre équipe est composée de
développeurs informatiques, de professionnels de l'information et de
linguistes informaticiens.

Nous sommes à la recherche d'un ingénieur linguiste pour un stage de 6
mois afin de travailler à la réalisation de nos projets sémantiques
ainsi qu'à l'élaboration de nos différentes ressources électroniques en
langue française et anglaise.


Début de stage : 1er janvier 2018

Compétences requises :
Traitement Automatique des Langues
Gestion de projet 
OS : Linux et Windows
Technologie : NOOJ et/ou UNITEX
Langages informatiques : Perl/Python/Java
Langues : anglais courant (anglais des affaires)

Lieu du stage : Pépinière 27 - 27 rue du Chemin Vert 75011 Paris
Indemnités de stage : 554 ¤ + remboursement de 50% du ticket de
transport

Si vous êtes intéressé par cette offre, merci d'envoyer votre
candidature à julien.letailleur@sewote.com"
"422","2017-11-09","GREYC","Caen","Proposition de stage de recherche M2
Laboratoire GREYC - Equipe HULTECH - UniversitÃ© Caen Normandie

DÃ©sambiguÃ¯sation des structures prÃ©dicatives basÃ©es sur ""devoir"" ou
""pouvoir"" : constitution d'un corpus, apprentissage et Ã©valuation

Le stage proposÃ© se situe dans le cadre d'un projet en cours menÃ© par
des membres de l'Ã©quipe HULTECH du GREYC avec l'entreprise Noopsis
(Caen, essaimage du GREYC) sur la recherche et l'extraction
d'informations dans des textes de `news' de type journalistique. Plus
spÃ©cifiquement, notre collaboration concerne des constructions
linguistiques dans lesquelles un verbe (conjuguÃ© en gÃ©nÃ©ral, le coverbe)
commande un verbe Ã  l'infinitif (le prÃ©dicat). Le coverbe apporte une
information importante, une Â« qualification Â» sur l'Ã©vÃ©nement exprimÃ©
par le prÃ©dicat, telle que : temporalitÃ© ou phase (exemple 1), intention
(2), modalitÃ© d'exÃ©cution (3), obligation ou possibilitÃ© (4), etc.

(1) Jean va/vient de/commence Ã ...travailler 
(2) Jean espÃ¨re/ redoute de/ veut/ne veut pas...travailler
(3) Jean se hÃ¢te de/s'efforce de/peine Ã ...travailler
(4) Jean doit/devrait/devait/peut/pourra/n'a pas pu...travailler

Dans ce cadre gÃ©nÃ©ral, on s'intÃ©ressera dans le stage aux deux derniers
coverbes : devoir et pouvoir : extrÃªmement frÃ©quents dans nos corpus,
ils reprÃ©sentent une fraction trÃ¨s importante (jusqu'Ã  un tiers) des
constructions Ã  infinitive. Or ils sont l'un comme l'autre
fondamentalement ambigus, avec chacun deux pÃ´les de signification,
illustrÃ©s par les exemples ci-dessous (extraits de nos corpus).

- Pour devoir : valeurs d'obligation (dÃ©ontique) (5) et de plausibilitÃ©
  (Ã©pistÃ©mique) (6).
  
- Pour pouvoir : valeurs de capacitÃ© - matÃ©rielle, juridique,
  logique...- (dite aussi radicale) (7) et Ã©pistÃ©mique (8) les deux
  pouvant facilement coexister (9)
  
(5) Il s'agirait d'un vÃ©hicule conÃ§u pour le marchÃ© nord-amÃ©ricain;
cependant, avant de passer Ã  l'Ã©tape de la commercialisation, il devra
passer les tests de collision du gouvernement des Etats-Unis.

(6) Les premiers vÃ©hicules de ce modÃ¨le, Ã©quipÃ©s de moteurs Ã©lectriques
Siemens, devraient commencer les premiers essais sur route Ã  la fin de
l'annÃ©e 2011

(7) D'autre part, elle peut aller jusqu'Ã  205 km/h avec une batterie au
nickel-cadmium.

(8) L'essence peut monter en bourse, Ã§a ne fera qu'augmenter le prix du
carburant.

(9) Sur la durÃ©e de vie de la voiture, un conducteur pourrait Ã©conomiser
plus de 22.000 litres d'essence.


Ce phÃ©nomÃ¨ne a de longue date fait l'objet de recherches en sÃ©mantique
linguistique [Fuchs, 1989] mais pas Ã  notre connaissance en termes de
traitements automatiques visant une dÃ©sambiguÃ¯sation en contexte. Tel
est a contrario l'objet de ce stage.
Une prÃ©-Ã©tude a permis d'identifier un certain nombre de traits,
morphosyntaxiques ou autres, aiguillant de maniÃ¨re plus au moins marquÃ©e
vers un sens ou un autre. A titre d'exemple : le conditionnel et
l'imparfait de devoir (devrait, devait) orienterait trÃ¨s fortement vers
un sens Ã©pistÃ©mique, le futur et le passÃ© composÃ© (devra, a dÃ» vers un
dÃ©ontique. De mÃªme le conditionnel de pouvoir (pourrait) tire fortement
vers l'Ã©pistÃ©mique et les temps autres que le prÃ©sent (pourra, pouvait,
a pu) vers la capacitÃ©, le prÃ©sent peut Ã©tant plus indÃ©terminÃ©.


Notre objectif dans ce stage sera de valider, prÃ©ciser,
systÃ©matiser... ces premiÃ¨res analyses Â« manuelles Â» en appliquant des
mÃ©thodes d'apprentissage automatique. Pour ce faire, deux Ã©tapes sont
nÃ©cessaires :

1. Ã‰tablissement d'un Gold Standard
Pour mener Ã  bien l'Ã©valuation d'un tel systÃ¨me, il sera nÃ©cessaire de
disposer d'un corpus annotÃ© de rÃ©fÃ©rence (Gold Standard) auquel
confronter les productions de ce dernier. La constitution de ces
annotations de rÃ©fÃ©rence pourra s'appuyer, de faÃ§on assez classique, sur
des annotations manuelles multiples (plusieurs annotateurs annotent
manuellement et indÃ©pendamment le mÃªme corpus) en vÃ©rifiant, grÃ¢ce Ã  une
mesure d'accord inter- annotateurs, qu'un consensus entre annotateurs se
dÃ©gage, et que les annotations de ces derniers peuvent servir (moyennant
un Ã©ventuel ajustement) de rÃ©fÃ©rence. Ce stage pourra Ã©ventuellement
constituer un premier pas vers une thÃ¨se concernant la constitution
d'annotations et les mesures d'accord inter-annotateurs, notamment
autour des travaux actuellement menÃ©s au GREYC [Mathet et al., 2015,
2016, 2017].

2. Application de technique(s) d'apprentissage automatique
Une fois le corpus annotÃ© de rÃ©fÃ©rence (Gold Standard) Ã©tabli, celui-ci
sera exploitable par des techniques d'apprentissage (en tant
qu'Ã©chantillon d'apprentissage). Pour reprÃ©senter chaque exemple de
l'Ã©chantillon, des attributs pertinents seront Ã  dÃ©finir (temps du
coverbe, mode, type de prÃ©dicat...) et Ã  extraire automatiquement des
textes. Diverses techniques d'apprentissage [CornuÃ©jols et Miclet, 2010]
pourront Ãªtre exploitÃ©es - tÃ¢che pour laquelle des procÃ©dures ont dÃ©jÃ 
Ã©tÃ© dÃ©veloppÃ©es au GREYC [Alec et al., 2014, 2016, Govind et Spaniol,
2017] -, aussi bien du type Â« boÃ®tes noires Â» (telles que les SVM) que
des techniques plus lisibles pour un Ãªtre humain (telles que les arbres
de dÃ©cision).

Ce stage est susceptible de bÃ©nÃ©ficier d'un financement, en fonction
notamment de la qualitÃ© de la candidature.

Contact : yann.mathet@unicaen.fr"
"423","2017-11-20","LIUM","Le Mans","Le Laboratoire d'Informatique de l'UniversitÃ© du Mans (LIUM) recherche
un stagiaire de Master (6 mois) pour un projet en lien avec l'indexation
et la fouille de documents d'un corpus mÃ©tier SNCF.

*Sujet *: Apprentissage automatique et TAL pour l'indexation de
documentation technique

*Contexte du stage* : Au Mans, laboratoire LIUM, Ã©quipe LST, financement
sur projet encollaboration avec la SNCF

*Mots-clÃ©s :* Apprentissage supervisÃ©, traitement automatique de la
langue naturelle, indexation, lexique technique, documentation mÃ©tier

------------------------------------------------------------------------

Sujet de stage recherche Master 6 mois

Titre : Apprentissage automatique et TAL pour l'indexation de
documentation technique

Encadrant(s) : Nathalie Camelin nathalie.camelin@univ-lemans.fr, Nicolas
               DuguÃ© nicolas.dugue@univ-lemans.fr

Contexte du stage : Au Mans, laboratoire LIUM, Ã©quipe LST, financement
sur projet en collaboration avec la SNCF

Mots-clÃ©s : Apprentissage supervisÃ©, traitement automatique de la langue
naturelle, clustering

Sujet du stage

Le groupe SNCF connaÃ®t actuellement une transformation digitale et se
tourne de plus en plus vers des technologies susceptibles de faire appel
Ã  de l'intelligence artificielle appliquÃ©e au traitement d'informations
Ã©crites ou orales. La documentation mÃ©tier est aujourd'hui en pleine
mutation, avec des mÃ©tiers qui se digitalisent, plus mobiles et de
nouveaux modes de consommation de l'information. Divers projets internes
ont permis d'enclencher une transition vers le numÃ©rique, pour trouver
la juste information au bon moment. Au-delÃ  de la numÃ©risation des
documents se pose la question de nouveaux systÃ¨mes intelligents d'accÃ¨s
aux contenus, d'aide Ã  l'interprÃ©tation et Ã  la saisie. L'objectif du
projet dans lequel s'inscrit ce stage est ainsi d'identifier, de
maquetter et d'Ã©valuer des solutions capables d'enrichir les initiatives
actuelles de documentation numÃ©rique. Les champs d'application sont
l'aide Ã  la rÃ©daction, la recherche d'information et la navigation dans
les contenus textuels.

Dans ce contexte, le stage a pour objectif d'Ã©tudier des mÃ©thodes pour
l'indexation fine de cette documentation numÃ©rique. En particulier, il
s'agit d'Ã©tudier les mÃ©thodes existantes (tf idf, zipf law, glove, lsa)
et de fournir des outils capables de dÃ©crire ces documents au contenu
technique via des mots-clÃ©s issus du vocabulaire mÃ©tier. Cette
description doit pouvoir ensuite Ãªtre utilisÃ© pour rÃ©aliser des
traitements tels que des regroupements thÃ©matiques de documents.

Pour rÃ©aliser ce travail, nous disposerons d'un lexique incomplet qui
pourra notamment Ãªtre utilisÃ© comme base d'apprentissage pour entraÃ®ner
un algorithme Ã  dÃ©tecter le vocabulaire technique. Dans ce cas, nous
pouvons reformuler ce problÃ¨me comme un problÃ¨me de dÃ©tection d'entitÃ©s
nommÃ©es spÃ©cifiques liÃ©es au vocabulaire technique de la SNCF.

Bibliographie

Pennington, J., Socher, R., & Manning, C. (2014). Glove: Global vectors
for word representation.  In Proceedings of the 2014 conference on
empirical methods in natural language processing (EMNLP) (pp. 1532-1543)

Ferrer i Cancho, R., & SolÃ©, R. V. (2001). Two Regimes in the Frequency
of Words and the Origins of Complex Lexicons: Zipf's Law
Revisited. Journal of Quantitative Linguistics, 8(3), 165-173.

Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &
Harshman, R. (1990). Indexing by latent semantic analysis. Journal of
the American society for information science, 41(6), 391.

Leaman, R., & Gonzalez, G. (2008, January). BANNER: an executable survey
of advances in biomedical named entity recognition. In Pacific symposium
on biocomputing (Vol. 13, pp. 652- 663)."
"424","2017-11-20","LIMSI","Saclay","Analyse d'un corpus clinique traduit en français

[Analysis of a clinical corpus translated from English to French]

Mots-clés : Traitement automatique de la langue, traduction, classification
automatique, domaine biomédical

*Contexte*

*Création d'un corpus clinique du français partageable*

La création d'un corpus de documents cliniques en français partageable
avec la communauté scientifique afin de soutenir la recherche en
traitement automatique de la langue clinique est soumise à la
réglementation française en lien avec le secret médical et la protection
des données personnelles.  La transcription des directives européennes
en droit français marque actuellement une évolution forte des
règlementations. En accord avec la protection des individus offerte par
la législation francaise et européene en cours de construction, nous
proposons d'utiliser un corpus de documents synthétiques, issu de la
traduction de document américains (en anglais) désidentifiés et
bénéficiant d'une autorisation de diffusion à des fins de recherche dans
un cadre très strict (Johnson et al. 2016).

*Validation du corpus pour le traitement automatique de la langue *

Afin de valider cette approche, il est nécessaire de réaliser une étude
comparative entre le corpus synthétique et un corpus de documents natifs
issu d'hôpitaux français. Cette analyse a pour objectif de caractériser
les différences qui peuvent exister entre les deux types de texte. Ces
différences peuvent être d'ordre syntaxique ou lexical, induites par les
phénomènes de simplification et d'explicitation (Volansky et
al. 2015). Les différences peuvent également résulter de différences
culturelles dans la pratique médicales en France et aux Etats-Unis. Par
exemple, certains médicaments prescrits aux Etats-unis ne bénéficient
pas d'autorisation de mise sur le marché en France. De même, certaines
pratiques médicales comme les ordonnances de non ressuscitation n'ont
pas cours en France. Par ailleurs, des travaux en traductologie ont
montré que les textes traduits pouvaient être automatiquement distingués
de textes natifs avec de bonnes performances (Rabinovich & Wintner,
2015). Nous prévoyons d'appliquer ces méthodes sur nos données de
spécialité à différents niveaux de granularité (texte complet, section,
phrase) afin d'apprécier le degré de différence entre textes traduits et
texte natifs, sachant qu'une grande partie des travaux en TAL clinique à
l'heure actuelle s'appuie sur une analyse au niveau de la phrase ou de
la section - selon la définition de la typologie internationale LOINC
(Reich et al. 2017).

*Travail à réaliser :*

L'objectif du stage est une analyse comparative de documents cliniques
en français natif vs. traduit de l'anglais.

Ce travail s'appuiera notamment sur les recherches actuelles en
traductologie et en linguistique de corpus (Rabinovich & Wintner, 2015 ;
Volansky et al. 2015).

Les objectifs suivants seront notamment poursuivis : 1/ évaluer la
granularité permettant de distinguer automatiquement des textes natifs
de textes traduits puis adaptés dans un domaine de spécialité (analyse
au niveau de la phrase, de la section, du document) 2/ caractériser les
différences et similitudes entre textes natifs et textes traduits du
point de vue stylistique, linguistique, structurel et culturel 3/
évaluer la pertinence du corpus issu de la traduction pour l'évaluation
de méthodes de traitement automatique de la langue clinique, par exemple
la reconnaissance d'entités nommées.

Le/la stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue, en traduction
automatique ou traduction assistée par ordinateur seront un plus.

*Durée* : 5 mois
*Niveau* : Master 2 (professionnel ou recherche)
*Rémunération* : 546,01 euros net /mois + participation au forfait de
transport

*Candidature:*

Envoyer à Aurelie.Neveol[at]limsi.fr:

- un CV

- une lettre de motivation

- les coordonnées d'au moins deux référents (par exemple: ancien maitre
  de stage, ou professeur pouvant commenter votre travail).


*Références*
Johnson AEW, Pollard TJ, Shen L, Lehman L, Feng M, Ghassemi M, Moody B,
Szolovits P, Celi LA, and Mark RG. *MIMIC-III, a freely accessible
critical care database*. Scientific Data (2016).

Ella Rabinovich and Shuly Wintner. *Unsupervised Identification of
Translationese*. *Transactions of the Association for Computational
Linguistics* 3:419-432, 2015.

Christian Reich, Patrick Ryan, Rimma Belenkaya, Karthik Natarajan and
Clair Blacketer. *OMOP Common Data Model v5.2 Specifications*. Rapport
Technique.  20/07/2017

Vered Volansky, Noam Ordan and Shuly Wintner. *On the features of
translationese*. *Digital Scholarship in the Humanities* 30(1):98-118,
April 2015."
"425","2017-11-20","TrackSens","Metz","Offre de stage

Ingénieur NLP / Linguistique

Créée en décembre 2016, TrackSens est une jeune start-up spécialisée dans le développement d'outils de traitement automatique du texte. Elle développe actuellement un logiciel de classification automatique de documents.

Dans cet objectif, nous sommes à la recherche d'un(e) ingénieur
linguiste pour un stage de 6 mois avec l'ambition de réaliser un état
de l'art autour de la problématique de la classification des documents
et de développer un premier prototype.

Objectifs principaux :

1.  Réalisation d'un état de l'art autour de la classification
    automatique des documents

2.  Identification des méthodes et des algorithmes adaptés afin de
    résoudre notre problème

3.  Implémentation et test de la solution retenue

4.  Développement d'un premier prototype

Profil souhaité :

1. Formation en cours : Master 2 en Linguistique Informatique

2. Curiosité et capacité d'explorer de nouveaux domaines en Traitement
   Automatique des Langues

3. Autonomie et créativité

Compétences requises :
1.  Connaissances en Traitement Automatique des Langues
2.  Compétences et goût pour la recherche et le développement
3.  Langages Informatiques : bon niveau en développement (Python/Java)
4.  Langues : anglais courant et français

Contexte :

Début de stage : Février 2018 (date exacte à convenir)

Lieu de stage : 7, av. de Blida 57000 Metz (dans le tiers-lieu de
création TCRM-Blida ) 2

Indemnités de stage : 800 ¤ brut

Vous intégrerez une start-up innovante, en plein développement et avec
de multiples opportunités pour la suite. Participer à l'aventure
TrackSens, c'est la garantie de rejoindre une équipe dynamique et une
start-up en croissance !

Si vous êtes intéressé par cette offre, merci d'envoyer votre
candidature (CV, lettre de motivation et relevé de notes) à
contact@tracksens.com."
"426","2017-11-30","Inbenta","Toulouse","Stage de fin d'étude en TAL

Qui est Inbenta ?

Créée en 2005, Inbenta est une entreprise internationale en pleine
expansion : Etats-Unis, Espagne, Singapour, Brésil, France ... Nous
développons des outils basés sur le Traitement Automatique du Langage
comme notamment des moteurs de recherche sémantiques.  Installés
depuis 5 ans à Toulouse, les 25 inbentors français sont réunis en 5
équipes : projets, commercial, marketing, technique, et linguistique.
Avec une moyenne d'âge de moins de 30 ans, l'équipe bénéficie d'un
cadre de travail propice au bien-être, afin de préserver notre
capacité d'innovation.

Nos valeurs : INNOVATION, AUTONOMIE, SOLIDARITE et CONVIVIALITE

Sujet du stage

Les chatbots d'Inbenta incluent une couche conversationnelle « sociale
» pour gérer les interactions de type phatique.  L'objectif du stage
est de trouver une méthode pérenne pour enrichir cette couche sociale
de façon semi automatique.

Missions

- Prendre connaissance de l'existant
- Faire un état de l'art des méthodes et ressources disponibles
- Définir une méthodologie d'enrichissement de la couche sociale
- Rédaction d'une documentation
- En parallèle, l'étudiant devra assurer la gestion linguistique et
  éditoriale d'un projet de FAQ dynamique afin qu'il s'approprie
  l'existant en vue d'assurer, en cas d'embauche après le stage, les
  missions de production que nous attendons d'un ingénieur linguiste
  (20% du temps de travail)

Profil recherché

- Bac +5 en linguistique informatique
- Connaissances en recherche d'information
- Connaissances en lexicographie
- Goût pour la Recherche et Développement
- Excellente maîtrise du français et bonne communication en anglais
- Maîtrise des expressions régulières

En plus de ces compétences, nous recherchons une personne organisée et
autonome. Elle devra avoir un bon relationnel pour communiquer
régulièrement avec les clients.

Modalités

- Stage de 5 à 6 mois (avec possibilité d'embauche en CDI)
- Rémunération prévue: 525 euros/mois + prime en fonction des résultats
- Début : à partir de Janvier/Février 2018
- Lieu : Toulouse

Postuler en ligne sur 
https://www.inbenta.com/fr/a-propos/carrieres/"
"427","2017-11-30","MoDyCo / IRISA","Paris ou Rennes","Offre de stage de M2 : « Langage enfantin » : aide rédactionnelle pour
le récit d'événements à des enfants

Stage financé par le projet ANR TREMoLo et en partenariat avec
Libération.

--------------
Contexte 
--------------

Le projet TREMoLo étudie l'emploi de différents registres dans la
langue française et vise à développer des méthodes automatiques de
transformation de textes d'un registre vers un autre. Un des registres
étudiés est celui qui correspond au « langage enfantin ». L'une des
visées applicatives envisagées concernant l'analyse de ce registre est
celle du récit d'événements à destination des enfants. La maîtrise de
plus en plus précoce par les enfants des outils informatiques et
d'Internet impulse en effet un intérêt grandissant sur la thématique
STIC pour les enfants, notamment au travers de questions liées à
l'adéquation de contenus textuels à des enfants (Eickhoff et coll.,
2010) ou à l'adaptation aux enfants du processus de recherche
d'information, y compris sur les aspects liés au filtrage ou au
réordonnancement de résultats (Gossen et Nürnberger, 2013).

  Mots-clés : Registres de langue, langage enfantin, récit
  d'évènements, Traitement automatique des langues (TAL), Fouille de
  données
  

--------------
Description du stage
---------------

L'objectif de ce stage est tout d'abord de répertorier les
descripteurs, c'est-à-dire les traits ou phénomènes linguistiques -
sur les plans morphologique, syntaxique, sémantique et discursif - qui
permettent de caractériser un langage approprié pour s'adresser à des
enfants de 7 à 10 ans et donc de clarifier les différences entre la
langue parlée par les adultes et celle produite par des enfants de
cette tranche d'âge. Il s'agira ensuite de caractériser finement ces
traits au regard de la tâche de mise en récit d'un événement (et donc
en mettant l'accent sur des descripteurs de types temps verbaux,
connecteurs temporels, cadres temporels discursifs, etc.).

  

En linguistique, les travaux classiques sur le langage adressé à
l'enfant (Saint-Georges et coll., 2013) s'intéressent à la manière
dont l'adulte adapte sa langue en s'adressant à des enfants de moins
de 3 ans. Ces travaux portent beaucoup sur les formes sonores
(phonèmes et intonation) et sur la notion d'interaction, sachant que
les formes produites sont très différentes d'un adulte à l'autre. On
sait en outre que les productions de l'enfant s'inspirent énormément
de celles de l'adulte (Tomasello, 2003) mais on ne sait pas comment
l'adulte pourrait s'adapter à l'enfant plus âgé. Or l'enfant de 7 ans
est encore en plein développement langagier, notamment au niveau des
formes verbales encore peu fréquentes, des connecteurs, de l'accord
temporel entre énoncés. L'enfant de 7 ans n'a pas encore fini sa
maturation cérébrale, en particulier en terme de mémoire et
d'attention, et ceci a des conséquences sur son langage et la manière
dont il peut par exemple raconter une histoire (Gathercole, 1999). Des
étapes développementales vis-à-vis des modes linguistiques de
référence au temps ont quant à elles été clairement mises au jour dans
des travaux comme Tartas (2001) ou Vion et coll. (1999).

Dans une moindre mesure, le stage a également pour objectif
d'identifier, parmi les nombreux outils existants en TAL, ceux
permettant l'annotation automatique de textes en français pour les
différents descripteurs retenus au fil du stage. La fiabilité des
outils pourra être étudiée et prise en compte pour leur sélection mais
il ne s'agit pas ici de développer de nouveaux outils.

Le support d'étude se fera en partie au regard de productions
journalistiques destinées à des enfants dans le cadre d'un partenariat
avec le journal Le P'tit Libé de Libération. Le travail inclura donc
des échanges avec des journalistes de leur rédaction.

---------------
Profil souhaité
---------------

- Formation en cours : Master 2 en Linguistique ou linguistique
  informatique.

- Curiosité et capacité d'explorer de nouveaux domaines en
  linguistique.

- Des connaissances en TAL seront un plus, mais ne sont aucunement
  prérequises. Un soutien sera assuré par les encadrants an cas
  d'absence de connaissances en TAL. Du reste, le sujet sera adapté en
  fonction du niveau et des types de compétences en TAL du (de la)
  candidat(e).
 
-----------------
Conditions
-----------------

Contrat : stage conventionné 6 mois rémunéré.

Début : février, mars ou avril 2018.

Lieu : laboratoire MoDyCo (site : Université de Paris Nanterre) ou
laboratoire IRISA (site : Université de Rennes 1)

Encadrants : Delphine Battistelli (MoDyCo), Gwénolé Lecorvé (IRISA)

Selon les résultats du stage, une poursuite en thèse pourrait être envisagée.

Merci d'envoyer votre candidature aux deux adresses suivantes :

delphine.battistelli@parisnanterre.fr
gwenole.lecorve@irisa.fr

Documents souhaités : CV, lettre de motivation, relevés de notes M1 et M2.

-----------------
Bibliographie indicative
-----------------

De Belder & Moens (2010). Text simplification for children. In
Proc. of the SIGIR worksh. on accessible search
systems. https://lirias.kuleuven.be/bitstream/123456789/276005/1/beldersigir-as.pdf

Eickhoff, Serdyukov & de Vries (2010). Web page classification on
child suitability. In Proc. of the ACM international conference on
Information and knowledge
management. http://dmirlab.tudelft.nl/sites/default/files/cikm331s-eickhoff.pdf

Gathercole (1999). Cognitive approaches to the development of
short-term memory. Trends in Cognitive
Sciences. https://faculty.biu.ac.il/~armonls/924/NWR/gathercole%2520(1999).pdf

Gossen & Nürnberger (2013). Specifics of information retrieval for
young users: A survey. Information Processing &
Management. http://wwwiti.cs.uni-magdeburg.de/iti_dke/Pdf/GossenIPM.pdf

Saint-Georges, Chetouani, Cassel, Apicella, Mahdhaoui, Muratori,
Laznik, Cohen (2013). Motherese in Interaction: At the Cross-Road of
Emotion and Cognition? (A Systematic Review). PLoS
ONE. https://pdfs.semanticscholar.org/a37f/8fc857d4e7c435e6d645bc3a37ddd517c308.pdf

Tartas (2010). Le développement de notions temporelles par l'enfant,
Développements. https://www.cairn.info/article.php?ID_ARTICLE=DEVEL_004_0017

Tomasello (2003), Constructing a language, a usage-based theory of
language
acquisition. http://journals.lww.com/jonmd/Citation/2005/06000/Constructing_a_Language__A_Usage_Based_Theory_of.12.aspx

Vion & Colas (1999). L'emploi des connecteurs en français :
contraintes cognitives et développement des compétences narratives (le
cas de la narration de séquences arbitraires d'événements). Prof. of
Conference of the International Association for the Study of Child
Language. https://hal.archives-ouvertes.fr/hal-00241527/document"
"428","2017-11-30","LIMSI / AP-HP","Orsay / Paris","Stage Master 2 / ingénieur: Adaptation d'un système d'apprentissage
neuronal à de nouveaux domaines
LIMSI-CNRS / AP-HP

Mots-clés : apprentissage automatique, traitement automatique des
langues, réseaux de neurones, adaptation au domaine, domaine médical,
analyse de dossiers patients

Lieu : LIMSI (Orsay), AP-HP (Paris, campus Picpus)

Durée : 4 à 6 mois
Date de début : printemps 2018

Contexte

Le parcours de soin d'un patient dans un hôpital est documenté par des
données numériques et structurées (résultats d'analyse, prescription de
médicaments, etc.) mais également par un grand nombre de documents
textuels rédigés par le personnel soignant : comptes-rendus
d'hospitalisation, comptes-rendus d'opérations chirurgicales, lettres
entre médecins, etc.
Être capable d'extraire de l'information pertinente de ces documents
textuels pour enrichir les connaissances sur le patient et son
itinéraire (par exemple, l'histoire de sa maladie, ses antédécents, ceux
de sa famille, ses facteurs de risque) permet d'accumuler des données
pertinentes sur les parcours de soin. Ces données peuvent par la suite
être utilisées dans toutes sortes d'études visant à mieux adapter la
prise en charge aux spécificités de chaque patient.
Une des approches populaires pour l'extraction d'information dans les
textes consiste à constituer des corpus annotés à la main par des
experts et à mettre en oeuvre des outils d'apprentissage
automatique. C'est cette piste qui est suivie au LIMSI avec
l'élaboration d'un système à base de réseaux de neurones [1][2][3] et
l'utilisation d'un corpus annoté en français [4].

Deux difficultés se présentent alors :
- d'une part, l'annotation manuelle est longue et coûteuse, et donc
  nécessairement faite en quantité limitée.
- d'autre part, les comptes-rendus médicaux utilisent un vocabulaire et
  une structure propre à chaque domaine (cancérologie, endocrinologie,
  gastro-entérologie, etc.) et, dans une moindre mesure, à chaque
  service ou hôpital. Il est impossible à l'heure actuelle d'envisager
  l'annotation de données de chaque domaine en quantité suffisante pour
  les modèles d'apprentissage.

Dans le but de réaliser des campagnes d'annotation aussi pertinentes et
ciblées que possible, nous souhaitons donc quantifier précisément les
besoins et les capacités de nos systèmes à s'adapter à des domaines
nouveaux ou faiblement couverts par les annotations manuelles.

Travail attendu

Le ou la stagiaire recruté(e) devra prendre en main les corpus et les
systèmes existants en interne. Ces systèmes permettent d'annoter des
entités de différents types (procédures, symptômes, maladies,
médicaments, etc.) dans les comptes-rendus médicaux. Il réalisera des
études sur les différents points suivants :

- quantité des données annotées nécessaires pour obtenir des résultats
  satisfaisants
- configuration optimale et/ou changements nécessaires aux modèles pour
  garantir une adaptation efficace à un domaine nouveau comportant peu
  ou pas de données annotées
- comparaison avec d'autres approches (application de dictionnaires,
  systèmes à bases de règles)

Compétences souhaitées

Nous recherchons un(e) étudiant(e) ayant des compétences solides en
programmation et en apprentissage automatique, intéressé(e) par le
traitement de contenu en langage naturel et par une application
médicale.  Les compétences en programmation ne sont cependant pas le
seul critère, et la personne retenue devra également faire preuve de
créativité et d'esprit d'analyse.

Les candidatures doivent comporter :

- Une lettre de motivation
- Un relevé de notes récent
- Les noms et coordonnées de deux personnes référentes
- Un curriculum citae (CV)

Contacts

nicolas.paris@aphp.fr (AP-HP)
aurelie.neveol@limsi.fr (LIMSI-CNRS)
xavier.tannier@upmc.fr (UPMC, LIMICS)

Références

[1]: https://github.com/jtourille/yaset
[2]: Julien Tourille, Olivier Ferret, Xavier Tannier, Aurélie
Névéol. Neural Architecture for Temporal Relation Extraction: A Bi-LSTM
Approach for Detecting Narrative Containers. in Proceedings of the 55th
Annual Meeting of the Association for Computational Linguistics (ACL
2017).
[3]: Julien Tourille, Olivier Ferret, Xavier Tannier, Aurélie
Névéol. LIMSI- COT at SemEval-2017 Task 12: Neural Architecture for
Temporal Information Extraction from Clinical Narratives. in
*Proceedings of the 11th International Workshop on Semantic Evaluation
(SemEval 2017).
[4]: Campillos L, Deléger L, Grouin C, Hamon T, Ligozat AL, Névéol A. A
French clinical corpus with comprehensive semantic annotations:
development of the Medical Entity and Relation LIMSI annOtated Text
corpus (MERLoT).  Lang Resources & Evaluation. Springer, Berlin
Heidelberg, Germany. 2017:1-31"
"429","2017-11-30","ERIC","Lyon","Sujet de stage : apprentissage de représentations pour la détection de
nouveauté dans les flux textuels

Durée du stage : 5 à 6 mois

Rémunération mensuelle : gratification standard ~600 euros

Lieu du stage : laboratoire ERIC (plusieurs séjours à EDF prévus)

Orientation du stage : recherche et professionnelle

Encadrants : J. Cugliari et J. Velcin (ERIC), P. Suignard et
M. Boumghar (EDF)

Problématique générale

Le stage se déroulera dans le contexte du projet DyNoFlu, financé par
le programme Gaspard Monge et faisant intervenir des chercheurs du
laboratoire ERIC et de l'équipe ICAME d'EDF Labs. L'objectif principal
du projet consiste à modéliser conjointement l'évolution des
thématiques abordées dans des flux textuels (fournis par le partenaire
industriel) et l'apparition des documents nouveaux annonciateurs de
changement. Un budget est ainsi prévu pour faire annoter certains
textes comme présentant un caractère nouveau, soit parce qu'ils
introduisent une nouvelle thématique, soit parce qu'ils changent la
configuration des données (par ex. la fusion de deux thématiques déjà
existantes). Ces indications supervisées doivent permettre d'apprendre
un espace de représentation adapté à la tâche de détection de la
nouveauté tout en la reliant à la dynamique de l'évolution des
thématiques.

Dans ce contexte, la stage consiste tout d'abord à tester l'apport
d'espaces de représentation des mots et/ou des documents déjà appris
sur d'autres corpus (à l'instar de word2vec ou doc2vec) comme une
alternative aux modèles thématiques déjà utilisé dans le cadre du
projet. Une piste intéressante, et encore relativement nouvelle,
consiste à combiner les deux approches afin d'améliorer les
performances finales. Cette partie est encore non supervisée et
l'évaluation pourra être réalisée sur des corpus dans lesquels la
nouveauté est simulée de manière artificielle. Dans un second temps,
il est demandé d'expérimenter des techniques d'apprentissage profond
(deep learning) afin d'apprendre des espaces de représentation adaptés
à la tâche de détection de la nouveauté en étant guidé, cette fois,
par les étiquettes fournies par l'annotation manuelle.  L'évaluation
finale devra reposer sur au moins deux jeux de données : un jeu de
données fourni par l'entreprise et un second jeu de données public.

Organisation du stage

Le stage se passera principalement dans les locaux du laboratoire ERIC
avec plusieurs séjours prévus dans les locaux d'EDF Labs en région
parisienne. Il profitera également d'une thèse CIFRE actuellement en
cours entre les deux partenaires.

Quelques précisions sur le contexte industriel :

EDF surveille l'évolution des thématiques discutées dans différents
types de corpus textuels : tweet, blogs,réclamations, etc. Un plan de
classement prédéfini permet de recourir à des algorithmes de
classification supervisée performants, mais de nombreux documents se
retrouvent mal ou même non classés. Cela peut être dû au fait que les
catégories évoluent au fil du temps (principe de « dérive de concepts
» ou concept drift), par exemple avec l'apparition de nouveaux termes
dans le vocabulaire, ou au fait que de nouvelles catégories
thématiques apparaissent. Dans ce contexte, l'analyse des signaux
faibles sur la base des documents non classés est une piste envisagée
sérieusement pour mieux appréhender ces évolutions. De manière plus
générale, l'entreprise souhaite être en mesure de suivre les
thématiques des textes dans le temps, que celles-ci soient récurrentes
ou qu'elles apparaissent et disparaissent au fur et à mesure du temps.

Profil requis :

- connaissances avancées en fouille de données, fouille de textes /
traitement automatique de la langue, modèles probabilistes
d'apprentissage automatique

- compétences en programmation sous Python, si possible avec une
première expérience avec les librairies de deep learning (Tensor Flow,
Theano, Keras...)

Pour candidater :

Merci d'envoyez les documents suivants à Jairo.Cugliari@univ-lyon2.fr :
- Curriculum Vitae
- Lettre de motivation
- Derniers bulletins de note
- Lettres de recommandation éventuelles

Références bibliographiques

Das, R., Zaheer, M., & Dyer, C. (2015, July). Gaussian LDA for Topic
Models with Word Embeddings.  In ACL (1) (pp. 795-804).

Kusner, M., Y. Sun, N. Kolkin, et K. Weinberger (2015). From word
embeddings to document distances. In International Conference on
Machine Learning, pp. 957-966.

Le, Q., & Mikolov, T. (2014). Distributed representations of sentences
and documents. In Proceedings of the 31st International Conference on
Machine Learning (ICML-14) (pp. 1188-1196)."
"430","2017-11-30","Synapse Développement","Toulouse","Offre de stage IA et TAL - Ingénieur / M2R

Sujet: Apprentissage automatique pour la classification des intentions
d'utilisateurs en interaction avec un chatbot

Lieu : Synapse Développement - Toulouse centre 
Contact : camille.pradel@synapse-fr.com 
Durée : 6 mois 
Rémunération conventionnelle + prime technique + tickets restaurants

Mots-clés : Machine/Deep Learning, Traitement Automatique des Langues,
Chatbots, Classification multi-labels de textes

--------------- 
Contexte
---------------

Spécialiste de l'Intelligence Artificielle appliquée au traitement du
langage, Synapse Développement est une société innovante d'une dizaine
de personnes et travaille pour le grand public et les grands comptes
comme Microsoft ou Amazon.

En pleine croissance, la société place l'expertise technique et
l'excellence R&D au coeur de son activité. Nous participons régulièrement
à des projets innovants avec les meilleures universités européennes et
construisons des solutions opérationnelles pour nos clients. Nous
offrons des challenges épanouissants, des solutions technologiques
innovantes, des opportunités de réalisation et une ambiance de travail
jeune et créative.

Reconnue pour ses technologies de compréhension profonde du langage,
Synapse Développement est identifié comme un acteur majeur de
l'écosystème des agents conversationnels (ou chatbots) actuellement en
pleine effervescence.  Notre solution permet à nos clients de créer
automatiquement un chatbot capable d'orienter des utilisateurs et de
répondre à des questions portant sur des textes issus de leur
documentation. Le chatbot est ainsi créé et déployé en quelques clics
puis s'améliore progressivement en interagissant avec les utilisateurs.

---------------
Votre mission
---------------

Les chatbots sont des interfaces qui permettent de rendre des services
aux utilisateurs en interagissant avec du langage naturel. Ces services
peuvent être codifiés et classés dans des catégories, mais le chatbot
doit d'abord ""comprendre"" le message des utilisateurs pour saisir son
intention. Votre objectif sera d'explorer les méthodes de machine
learning et de traitement automatique des langues qui permettent de
caractériser les intentions d'utilisateurs (classification
multi-labels).

Exemple : ""Bonjour, quel temps fera-t-il demain ?"" doit être reconnu
comme une intention de salutation et de demande de pronostiques météo.

Nous vous confierons la conduite des 4 étapes de ce projet :

1. État de l'art de la classification d'intentions

2. Choix de modes d'évaluation et de métriques approprié

3. Expérimentation d'algorithmes de l'état de l'art (e.g. random
   forest/gradient boosting avec tf-idf, doc2vec+régression
   logistique...)

4. Déploiement de l'approche retenue et itérations avec l'équipe pour
   améliorer le système dans son environnement réel.

Selon le profil et la motivation, des approches nouvelles pourront être
mises au point, notamment basées sur des réseaux de neurones.

--------------- 
Votre profil
--------------- 

Vous recherchez un stage de fin d'étude pour clôturer votre Master 2 ou
votre école d'Ingénieur (bac+5).

Vous disposez d'une expérience sur des projets de Machine Learning ou de
Deep Learning.

Vous justifiez d'un bon niveau de programmation et d'une capacité à
travailler en autonomie.

Les compétences suivantes sont considérées comme un plus :

* Traitement automatique des langues
* Connaissances de Python/Sklearn/Tensorflow/Keras
* Curiosité et ouverture d'esprit."
"431","2017-11-30","LIG","Grenoble","Génération de pictogrammes à partir de la parole pour la mise en place
d'une communication médiée par la machine

Encadrants

Didier Schwab (didier.schwab@imag.fr), maître de conférences à
l'Université Grenoble-Alpes

Benjamin Lecouteux (benjamin.lecouteux@imag.fr), maître de conférences à
l'Université Grenoble-Alpes

Lieu du stage

LIG (Laboratoire d'Informatique de Grenoble), équipe GETALP (Groupe
d'Étude en Traduction Automatique/Traitement Automatisé des Langues et
de la Parole), campus Universitaire de Saint-Martin d'hères.

Description du projet

On estime que 0,5 % à 2 % de la population mondiale âgée de plus 4 ans a
un trouble grave de la communication. À cause de ces difficultés, ces
personnes ont un cercle social très restreint composé essentiellement de
leur famille proche ce qui pose d'énormes contraintes d'accessibilité et
d'intégration. Ces personnes, que seule leur famille proche est en
mesure de comprendre, sont ainsi entre 30 et 120 millions, soit environ
800 000 rien que pour la France. Parmi elles, on distingue :

- les personnes souffrant d'un trouble du développement. Les difficultés
  surviennent dès la naissance ou peu de temps après. Ces personnes
  n'ont pratiquement rien pu acquérir de manière classique. On trouve
  dans cette catégorie des maladies génétiques (syndrome de Rett,
  leucodystrophies,...), certains autismes,... ;

- les personnes ayant une déficience acquise. Dans ce cas, la personne a
  vécu un développement normal et un évènement est survenu (Accident,
  maladie) ;

Ces personnes ne peuvent pas communiquer avec leur environnement de
manière classique grâce à leur voix, ni même parfois avec des
gestes. Toute la méthode d'apprentissage doit être repensée en fonction
des capacités des apprenants. Leurs capacités cognitives diffèrent mais
la mise en place d'un système de communication même rudimentaire est
dans la quasi-totalité des cas possible.

Le projet s'intéresse à rendre la communication possible au travers
d'une interaction médiée par la machine (beaucoup utilisé avec certaines
pathologies du spectre de l'autisme, notamment avec des
robots). Cependant, comme nous nous intéressons aux troubles du langage
(physique et cognitif) qui sont accompagnés de troubles moteurs, une
interaction vocale et tactile n'est pas envisageable. Nous nous
concentrons donc sur l'interaction visuelle grâce à ce que l'on appelle
des oculomètres (eye-trackers).

C'est autour de cette problématique que nous travaillons depuis
plusieurs mois en nous focalisant sur les jeux qui offrent au moins deux
avantages aux personnes : 1) les divertir ; 2) leur permettre de
s'entraîner afin de leur offrir la possibilité d'acquérir des
interactions plus complexes.

Il s'agit ainsi d'une première étape visant la possibilité de mettre en
place une véritable communication basée sur des pictogrammes par
exemple.

Notre équipe a mis à disposition de la communauté GazePlay
(http://gazeplay.net) , un logiciel libre et gratuit qui rassemble
plusieurs mini-jeux jouables grâce à un oculomètre (Eye-tracker). Le
prix des oculomètres peut varier de quelques centaines à plusieurs
milliers d'euros ; et à ce prix, les familles intéressées par ce type de
jeux doivent ajouter les logiciels généralement vendus à plusieurs
milliers d'euros (en plus d'être dépendants du type d'oculomètre
utilisé). À notre connaissance, notre équipe est la première au monde à
porter le prix d'entrée à une telle technologie de plusieurs milliers
d'euros à un peu plus d'une centaine (le prix de l'oculomètre le moins
cher), en témoignent les retours positifs, le nombre de téléchargements
et les contacts établis (professionnels, journaux spécialisés,
parents,...) depuis. Une communication scientifique sur ce sujet [Schwab,
2017] a été acceptée et sera présentée aux professionnels comme aux
parents en novembre prochain lors du congrès européen sur le syndrome de
Rett. Nous souhaitons essayer de développer une communauté
d'utilisateurs et à partir de cette communauté nous permettre d'établir
des contacts qui nous permettront de développer recherches et outils.

L'idée est de développer un outil d'assistance à la communication
associé à Gazeplay. Cet outil serait basé sur l'utilisation de
pictogrammes, couramment utilisés dans ce type de contexte. Il doit
fonctionner dans deux sens :

- La génération vocale à partir des pictogrammes : Il permet à la
  personne d'utiliser un ensemble de pictogrammes (images) et de les
  associer entre eux pour qu'une synthèse vocale énonce le message à
  destination de l'entourage : cela permet d'utiliser le
  vocabulaire. Cet aspect de génération vocale existe déjà.

- La génération de pictogrammes à partir du langage naturel : associer
  les pictogrammes au discours correspondant est essentiel à la
  réalisation du premier point [Cataix, 2017]. Pour quelqu'un qui doit
  tout apprendre ou réapprendre à partir de zéro, il s'agit de
  comprendre qu'une image est associée à un certain mot. Ainsi, il faut
  qu'il associe le terme de `piscine' avec l'image de la `piscine', le
  terme `aller' avec le pictogramme `aller'. Cela peut se faire
  évidemment par des jeux mais la mise en oeuvre en situation réelle est
  essentielle [Beukelman & Mirenda, 2017]. Cette association se
  complique lorsque l'on souhaite projeter une représentation textuelle
  complexe sous la forme d'un ensemble de pictogrammes : le problème
  peut alors être vu comme un cas particulier de la langue des signes
  avec une notion de simplification du message en sus ; il s'agit alors
  de traduire une langue complexe dans une représentation simplifiée. Il
  ne semble pas exister un moyen de le faire le plus naturellement
  possible, c'est-à-dire à partir de la voix de l'aidant, dans les
  outils ou recherches dont nous avons connaissance.

Ainsi, l'objectif de ce projet est d'étudier et de proposer des
solutions permettant de réaliser une projection du langage naturel en un
ensemble de pictogrammes, de manière automatique et à partir de la
voix. Les connaissances de l'équipe dans les domaines de la traduction
automatique de la parole seront un fort atout dans la réalisation de ce
projet.

Sujet du Master

Dans un schéma classique, les aidants (famille, professionnels) parlent
à la personne en situation de handicap et elle devient ainsi capable de
comprendre de nombreux messages, en tous cas ceux qui sont simples. Il
faut qu'elle arrive à associer à chaque mot, un pictogramme afin de
pouvoir comprendre comment les employer. Ainsi, les aidants doivent
arriver à jongler avec des centaines d'images à chaque instant de la
vie. Ils mettent au point des stratégies souvent basées sur le contexte
qui réduisent en partie la complexité de cette tâche. En effet, les
pictogrammes utilisés au moment des repas, se recoupent assez peu avec
ceux du moment du bain ou ceux pour aller au parc. Malheureusement, il
n'est évidement pas rare que tel ou tel pictogramme ne soit pas présent
dans le classeur utilisé. De plus la sélection rapide de pictogramme
peut raréfier l'utilisation de certains.

Une solution pourrait être d'utiliser la reconnaissance vocale pour la
constitution du message sous forme de pictogramme. Il s'agit d'un
problème qui ne semble n'avoir jamais été attaqué sous cet angle, nous
n'avons pas trouvé de littérature concernant la génération automatique
de pictogrammes à partir de la voix ni même à partir de texte. Une seule
thématique nous a paru relativement proche, la génération de langue des
signes destinées aux personnes sourdes et malentendantes mais ce
problème nous paraît bien plus complexe car les pictogrammes et les
associations possibles sont bien plus restreintes que celles offertes
par une vraie langue comme la langue des signes. A contrario, la
restriction dans le langage cible nous oblige à simplifier le message
initial. Les techniques de traduction automatique, dont l'équipe est
experte, permettront d'apporter des solutions dans la traduction de la
parole vers les pictogrammes.

Une difficulté qui sera abordée dans ce sujet sera l'évaluation de la
solution : comment vérifier la pertinence des pictogrammes choisis ? Ce
sujet portera sur la constitution d'un corpus d'évaluation, étape qui
sera essentielle au développement des méthodes évoquées précédemment.

Références

[Cataix, 2017] Communiquer autrement: Accompagner les personnes avec des
troubles de la parole ou du langage Elisabeth Cataix Nègre, De Boeck
Superieur, 12 juin 2017 - 336 pages

[Beukelman & Mirenda, 2017] Communication alternative et augmentée :
Aider les enfants et les adultes avec des difficultés de communication,
David Beukelman, Pat Mirenda, De Boeck Superieur, 13 octobre 2017 - 384
pages

[Gatt & Portet, 2015] Multilingual generation of uncertain temporal
expressions from data: A study of a possibilistic formalism and its
consistency with human subjective evaluations Albert Gatt, François
Portet

[Lecouteux et al., 2013] Benjamin Lecouteux, Georges Linares, Yannick
Estève, Guillaume Gravier. Dynamic Combination of Automatic Speech
Recognition Systems by Driven Decoding. IEEE Transactions on Audio,
Speech and Language Processing, Institute of Electrical and Electronics
Engineers, 2013.

[Lecouteux et al., 2016] Ngoc-Tien Le, Benjamin Lecouteux, Laurent
Besacier. Joint ASR and MT Features for Quality Estimation in Spoken
Language Translation. International Workshop on Spoken Language
Translation, Dec 2016, Seattle, United States

[Morel et al. 2017] Cognition sociale dans les troubles neuro-génétiques
de l'enfant : revue de la littérature A. Morel*, C. Demily, Archives de
Pédiatrie Volume 24, Issue 8, August 2017, Pages 757-765

[Schwab, 2017] GazePlay: Creation of a community to help the development
of a Free and Open-source plateform to make eye- tracker Video Games
accessible to everyone. European Rett-Syndrome Congress, 2-4 novembre
2017, Berlin, Allemagne"
"432","2017-11-30","ATILF","Nancy","Outil d'exploration d'expressions polylexicales dans un lexique et
dans un corpus annotÃ©

    Domaine: traitement automatique des langues
    Lieu du stage: ATILF, Nancy
    Encadrants: Mathieu Constant et Agata Savary
    DurÃ©e du stage: 4 Ã  6 mois
    RÃ©munÃ©ration: gratification rÃ©glementaire
    Financement: CNRS

Contexte du stage

Le stage se dÃ©roulera dans le cadre du projet ANR PARSEME-FR qui
Ã©tudie les liens entre expressions polylexicales et l'analyse
syntaxico-sÃ©mantique automatique. Les expressions polylexicales (EP),
comme pomme de terre, se voiler la face, Afrique du Sud, prendre une
dÃ©cision, sont des groupes de mots aux propriÃ©tÃ©s imprÃ©visibles. En
particulier, leur sens ne peut souvent Ãªtre directement calculÃ© Ã 
partir du sens de leurs composants. Pour cette raison, elles posent
des problÃ¨mes majeurs au traitement automatique et leur traitement
nÃ©cessite une description explicite dans un lexique. Un des objectifs
du projet PARSEME-FR est de construire Ã  la fois un lexique d'EP
incluant des descriptions linguistiques fines, et un corpus annotÃ© en
EP pour le franÃ§ais. Un des rÃ©sultats les plus notables jusqu'Ã 
prÃ©sent est l'annotation des donnÃ©es franÃ§aises (Candito et al. 2017)
pour la Shared Task PARSEME sur l'identification des expressions
verbales (Savary et al. 2017). Les deux ressources crÃ©Ã©es ont pour but
d'Ãªtre exploitÃ©es dans des applications du traitement automatique des
langues telles que l'analyse syntaxique et sÃ©mantique, mais aussi
d'Ãªtre explorÃ©es pour des Ã©tudes linguistiques.  Objectifs

L'objectif principal du stage est de dÃ©velopper des outils pour lier
et explorer le corpus annotÃ© et le lexique, construits dans le projet
PARSEME-FR. Le travail Ã  rÃ©aliser comportera les tÃ¢ches suivantes:

- Ã©tudier les propriÃ©tÃ©s linguistiques des expressions polylexicales
     du franÃ§ais, en explorant le lexique des expressions verbales
     extrait des tables du lexique-grammaires (Gross 1984)

- dÃ©velopper un outil pour lier automatiquement les expressions
     verbales annotÃ©es et leurs entrÃ©es correspondantes dans le
     lexique, en s'appuyant sur des procÃ©dures de normalisation des
     expressions. Par exemple, les expressions annotÃ©es sur corpus Luc
     a cassÃ© du sucre sur le dos de Paul, du sucre a Ã©tÃ© cassÃ© sur son
     dos devront Ãªtre liÃ©e Ã  l'entrÃ©e casser du sucre sur le dos [de]
     du lexique.

- dÃ©velopper une interface web avec l'objectif de chercher des
     expressions annotÃ©es via des filtres multicritÃ¨res et visualiser
     leur description linguistique arborescente

- Ã©ventuellement, Ã©tendre le travail Ã  toutes les expressions
     polylexicales, ce qui impliquera la conversion automatique d'un
     dictionnaire existant de composÃ©s nominaux, adjectivaux et
     adverbiaux dans le format arborescent PARSEME-FR, en particulier
     en utilisant les informations syntaxiques fournies dans le corpus
     annotÃ©.

RÃ©fÃ©rences

Marie Candito, Mathieu Constant, Carlos Ramisch, Agata Savary, Yannick
Parmentier, Caroline Pasquer, and Jean-Yves Antoine. Annotation
d'expressions polylexicales verbales en franÃ§ais. In Jean-Yves Antoine
Iris Eshkol, editor, 24e confÃ©rence sur le Traitement Automatique des
Langues Naturelles (TALN), Actes de TALN, volume 2 : articles courts,
pages 1-9, OrlÃ©ans, France, 06 2017.

Maurice Gross. Lexicon-grammar and the syntactic analysis of
French. In Proc. of COLING-ACL 1964, pages 275-282, Stanford, CA,
1984. Association for Computational Linguistics.

Agata Savary, Carlos Ramisch, Silvio Cordeiro, Federico Sangati,
Veronika Vincze, Behrang QasemiZadeh, Marie Candito, Fabienne Cap,
Voula Giouli, Ivelina Stoyanova, and Antoine Doucet. The PARSEME
shared task on automatic identification of verbal multiword
expressions. In Proc. of EACL 2017 Workshop on MWEs, pages 31-47,
Valencia, April 2017.  Candidater

Profil du candidat:

- Master ou Ã©quivalent en traitement automatique des langues ou en
      informatique en prioritÃ© (mais la liste n'est pas fermÃ©e)

- CompÃ©tences: bonne maÃ®trise de la programmation, notamment la
      programmation en python et la programmation web. GoÃ»t pour la
      linguistique.

ProcÃ©dure de candidature:

    Les candidatures doivent Ãªtre envoyÃ©es par mail Ã 
    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature
    contiendra un cv, une lettre de motivation, et, Ã©ventuellement, la
    recommandation d'un enseignant.

    Date limite de candidature: 15 janvier 2018 (ou jusqu'Ã  ce ce que le poste soit pourvu)"
"433","2017-11-30","ATILF","Nancy","Stage: annotation syntaxique de Frantext

Lieu: ATILF, Nancy
Durée: 4 à 6 mois
Gratification réglementaire

Encadrement: Mathieu Constant, Christophe Benzitoun

En collaboration avec l'équipe Ressources de l'ATILF

Contexte:

Frantext est une base de données textuelles incluant plus de 5000
références (soit près de 300 millions de mots) s'échelonnant du Xe au
XXIe siècle (avec une majorité de textes en français moderne). Cette
base est hébergée, maintenue et enrichie à l'ATILF. Elle dispose d'un
moteur de requêtes qui permet de faire des recherches fines dans ce
corpus. Avec l'objectif de permettre d'affiner encore plus ces
requêtes, l'ATILF s'est lancé dans une vaste campagne d'annotation
linguistique de la base textuelle, en commençant par l'étiquetage
morphosyntaxique et la lemmatisation. La prochaine étape est
l'annotation syntaxique.

L'analyse syntaxique automatique de Frantext fait face à de nombreuses
difficultés. Tout d'abord, Frantext n'appartient pas au même
domaine/genre que les jeux de données traditionnellement utilisés pour
l'entraînement des analyseurs existants, ce qui cause des divergences
lexicales et syntaxiques. Par ailleurs, la tokenisation est
différente, ce qui est un obstacle important pour prédire la bonne
structure syntaxique. Bien que l'on ne considère que les textes en
français moderne (à partir de 1850), l'évolution lexicale et
syntaxique doit être prise en compte. Enfin, Frantext n'a pas de
section déjà annotée et manuellement validée ce qui est problématique
pour l'évaluation.

L'objectif principal du stage est d'explorer différentes techniques
d'adaptation et de combinaison d'analyseurs pour annoter
automatiquement Frantext en syntaxe de dépendance, en utilisant des
analyseurs existants entraînés principalement sur des corpus
journalistiques. Le résultat attendu est une chaîne de traitement
permettant de réaliser une analyse syntaxique automatique de qualité.

 
Travail à effectuer

Le stage se divisera en plusieurs tâches:

- lire les références bibliographiques sur les techniques d'adaptation
    au domaine - ex. utilisation de représentation abstraite des mots
    (Seddah et al., 2014) - et sur les techniques de combinaison
    d'analyseurs - ex. reparsing (Sagae et Lavie 2006), reranking
    (Charniak et Johnson 2005), tri-learning à la Weiss et al (2015) ;

- se familiariser avec des analyseurs en constituants et en
      dépendances existants, à entraîner sur le French Treebank
      (Abeille et al. 2003), le Sequoia (Candito et Seddah 2012) et/ou
      Question Bank (Seddah et Candito 2016) ;

- construire et évaluer de manière incrémentale la chaîne de
      traitement en commençant par les analyseurs de base ;

- éventuellement, participer à la campagne d'annotation pour
      construire rapidement un petit corpus d'évaluation.

Profil du candidat

-     Formation: Master 2 traitement automatique des langues (ou équivalent) en priorité, mais la liste n'est pas fermée ;

-     Compétences: langages de script (python, perl), développement de chaînes de traitement, connaissance des méthodes d'analyse syntaxique en dépendances (optionnel).

Procédure de candidature:

    Les candidatures doivent être envoyées par mail à
    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature
    contiendra un CV, une lettre de motivation, et, éventuellement, la
    recommandation d'un enseignant.

    Date limite de candidature : 15 janvier 2018 (ou jusqu'à ce ce que
    le poste soit pourvu).

Références:

Anne Abeillé, Lionel Clément, François Toussenel. Building a Treebank
for French, pages 165-187. Springer Netherlands, Dordrecht, 2003.

Eugene Charniak, Mark Johnson. Coarse-to-fine n-best parsing and
maxent discriminative reranking. In Proceedings of the 43rd Annual
Meeting on Association for Computational Linguistics, ACL '05, pages
173-180, Stroudsburg, PA, USA, 2005. Association for Computational
Linguistics.

Marie Candito and Djamé Seddah. Le corpus sequoia : annotation
syntaxique et exploitation pour l'adaptation d'analyseur par pont
lexical (the sequoia corpus : Syntactic annotation and use for a
parser lexical domain adaptation method) [in french]. In Proceedings
of the Joint Conference JEP-TALN-RECITAL 2012, volume 2: TALN, pages
321-334, Grenoble, France, June 2012. ATALA/AFCP.

Djamé Seddah and Marie Candito. Hard time parsing questions: Building
a QuestionBank for French. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Sara Goggi, Marko Grobelnik, Bente
Maegaard, Joseph Mariani, Helene Mazo, Asuncion Moreno, Jan Odijk, and
Stelios Piperidis, editors, Proceedings of the Tenth International
Conference on Language Resources and Evaluation (LREC 2016), Paris,
France, may 2016. European Language Resources Association (ELRA).

Djam Seddah, Marie Candito, and Enrique Henestroza Anguiano. A word
clustering approach to domain adaptation: Robust parsing of source and
target domains. J. Log. Comput., 24(2):395-411, 2014.

Kenji Sagae and Alon Lavie. Parser combination by reparsing. In
Proceedings of the Human Language Technology Conference of the NAACL,
Companion Volume: Short Papers, NAACL-Short '06, pages 129-132,
Stroudsburg, PA, USA, 2006. Association for Computational Linguistics.

David Weiss, Chris Alberti, Michael Collins, and Slav
Petrov. Structured training for neural network transition-based
parsing. In Proceedings of the 53rd Annual Meeting of the Association
for Computational Linguistics and the 7th International Joint
Conference on Natural Language Processing of the Asian Federation of
Natural Language Processing, ACL 2015, July 26-31, 2015, Beijing,
China, Volume 1: Long Papers, pages 323-333, 2015."
"434","2017-11-30","ATILF","Nancy","Étiquetage sémantique faiblement supervisé à partir de dictionnaires -
application à la lemmatisation et à l'identification d'expressions
polylexicales

    Domaine: traitement automatique des langues
    Lieu du stage: ATILF, Nancy
    Encadrants: Mathieu Constant et Sandrine Ollinger
    Durée du stage: 4 à 6 mois
    Rémunération: gratification réglementaire
    Financement: CNRS

Contexte du stage

Frantext est une base de données textuelles incluant plus de 5000
références (soit près de 300 millions de mots) s'échelonnant du Xe au
XXIe siècle (avec une majorité de textes en français moderne). Cette
base est hébergée, maintenue et enrichie à l'ATILF. Elle dispose d'un
moteur de requêtes qui permet de faire des recherches fines dans ce
corpus. Avec l'objectif de permettre d'affiner encore plus ces
requêtes, l'ATILF s'est lancé dans une vaste campagne d'annotation
linguistique de la base textuelle, en commençant par l'étiquetage
morphosyntaxique et la lemmatisation. Si l'étiquetage morphosyntaxique
réalisé offre de bons résultats (précision estimée à 98 %), la
lemmatisation s'appuyant sur une simple consultation de dictionnaire
pose de nombreux problèmes à cause de l'ambiguïté.

Par ailleurs, le projet ANR PARSEME-FR coordonné par l'ATILF étudie
les liens entre expressions polylexicales et analyse syntaxique et
sémantique. En particulier, dans ce cadre, plusieurs méthodes
supervisées ont été mises au point pour identifier les expressions
polylexicales (Al Saied et al. 2017, Scholivet et Ramisch
2017). Cependant, de telles approches souffrent d'un manque de
couverture, car elles sont très contraintes par les données
d'entraînement. À la place, nous souhaiterions explorer des approches
faiblement supervisées guidées par des dictionnaires, offrant une plus
grande couverture en expressions polylexicales.

L'objectif de ce stage est de développer des méthodes faiblement
supervisées d'étiquetage sémantique reposant sur des graphes
sémantiques, avec pour but d'améliorer à la fois la lemmatisation et
l'identification des expressions polylexicales. En supposant que l'on
dispose d'une étiquette morphosyntaxique pour le mot en entrée, la
lemmatisation consiste à trouver le bon ensemble de sens partageant le
même lemme. Si l'on considère un ensemble d'expressions polylexicales
candidates dans une phrase en entrée, identifier les expressions
polylexicales de la phrase consiste à déterminer si les expressions
candidates ont un sens compositionnel ou pas. Pour résumer, les deux
tâches consistent à faire un étiquetage sémantique gros grain. Dans
cette approche, les dictionnaires sont représentés comme des graphes
sémantiques et des algorithmes random walk sont utilisés pour activer
les bonnes analyses (lemme et segmentation lexicale) parmi les
analyses possibles décrites dans le dictionnaire.  Objectifs

L'objectif du stage est d'appliquer diverses techniques d'étiquetage
sémantique reposant sur des graphes, à la lemmatisation et à
l'identification d'expressions polylexicales, qui peuvent être
considérés comme des sous-tâches de l'annotation sémantique. Les
expériences seront de préférence réalisées sur le français, mais
d'autres langues sont aussi possibles. Le travail sera divisé en
plusieurs tâches :

- Lecture des principales références bibliographiques sur l'étiquetage
      sémantique à base de graphes ;

- Construction d'un graphe sémantique à partir de plusieurs
      dictionnaires et éventuellement depuis des corpus ;

- Implémentation de l'algorithme de Lesk algorithm (Lesk 1986), afin
      de s'en servir comme point de comparaison ;
 
- Implémentation de plusieurs techniques à base de graphes comme le
      PageRank personnalisé (Agirre et al 2014) ;

- Évaluation sur des données d'évaluation existantes pour la
      lemmatisation et l'identification des expressions polylexicales

Références

Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. Random walks for
knowledge-based word sense disambiguation. Comput. Linguist.,
40(1):57-84, March 2014.

Hazem Al Saied, Marie Candito, and Matthieu Constant. The atilf-llf
system for parseme shared task: a transition-based verbal multiword
expression tagger. In Proceedings of the 13th Workshop on Multiword
Expressions (MWE 2017), pages 127-132, Valencia, Spain, April
2017. Association for Computational Linguistics.

Michael Lesk. Automatic sense disambiguation using machine readable
dictionaries: How to tell a pine cone from an ice cream cone. In
Proceedings of the 5th Annual International Conference on Systems
Documentation, SIGDOC '86, pages 24-26, New York, NY, USA, 1986. ACM.

Manon Scholivet and Carlos Ramisch. Identification of ambiguous
multiword expressions using sequence models and lexical resources. In
Proceedings of the 13th Workshop on Multiword Expressions (MWE 2017),
pages 167-175, Valencia, Spain, April 2017. Association for
Computational Linguistics.  Candidater

Profil du candidat:

    Master 2 ou école d'informatique, traitement automatique des
    langues en priorité, mais la liste n'est pas fermée.

    Compétences: algorithmique des graphes, calcul matriciel, maîtrise
    d'un langage de programmation (python de préférence), intérêt pour
    la linguistique.

Procédure de candidature:

    Les candidatures doivent être envoyées par mail à
    Mathieu.Constant@univ-lorraine.fr. Le dossier de candidature
    contiendra un cv, une lettre de motivation, et, éventuellement, la
    recommandation d'un enseignant.

    Date limite de candidature: 15 janvier 2018 (ou jusqu'à ce ce que
    le poste soit pourvu)"
"435","2017-12-04","Yseop","Paris","Yseop (www.yseop.com) propose un stage conventionné de 6 mois pour un-e
infolinguiste niveau M2, basé à Paris.

Créée en 2007, Yseop compte aujourd'hui une trentaine de collaborateurs
répartis entre Lyon, Paris, Londres, Dallas et New-York. En 2016, Yseop
a été reconnue meilleure innovation IT aux USA, et cette année nous
avons rejoint le TOP 100 des compagnies les plus disruptives au monde,
aux côtés de Tesla et SpaceX !

Grâce au logiciel d'Yseop, nos clients monétisent leurs données et
digitalisent leurs processus métier pour gagner en performance. Notre
technologie est unique au monde : le logiciel d'Yseop raisonne,
interagit, rédige et conseille automatiquement et en plusieurs langues.

Au sein de l'équipe R&D, vous participerez à la conception et au
développement de la nouvelle version de notre module de NLU. Vous
interviendrez en particulier sur les tâches de modélisation des
interactions courantes avec les chatbots (salutations, remerciements,
etc.), la constitution des ressources linguistiques associées, la
constitution de corpus de référence et l'évaluation des résultats. Vous
participerez également au développement du noyau de compréhension.

Compétences requises :

- Traitement Automatique des Langues (étude de corpus, grammaires
  locales, text-mining, extraction d'information, techniques de machine
  learning)

- Programmation Java,

- Maîtrise de l'anglais,

- La connaissance d'un langage de scripts (Python, Groovy, Perl) ainsi
  que du framework UIMA sont des plus,

- Bonnes capacités d'analyse,

- Facilité à travailler en équipe

Stage à pourvoir à partir de début Mars 2018

Merci de transmettre votre CV à hugues@mazancourt.com"
"436","2017-12-04","Sinequa","Paris","Stage : Amélioration de l'analyse linguistique de documents en langue
japonaise

Sinequa cherche un linguiste informaticien de langue maternelle
japonaise pour un stage d'une durée de 3 à 6 mois dans ses locaux à
Paris. Faisant partie de l'équipe linguistique au sein du département de
R&D, le stagiaire testera et améliorera l'analyse linguistique de
documents en langue japonaise du produit de Sinequa. Si ce stage vous
intéresse, merci d'envoyer votre CV à Frederik Cailliau
(cailliau@sinequa.com).

http://www.sinequa.com"
"437","2017-12-04","Lattice","Paris","***Stage M2 au Laboratoire Lattice - UMR 8094****
""Désambiguïsation des entités nommées : une approche fondée sur les
connaissances""

* Profil recherché *
+ Master 2 en Informatique
+ Bonnes compétences en programmation (Java)
+ Connaissances en web sémantique
+ Intérêt pour le traitement automatique des langues
+ Bonne connaissance de l'anglais et du français


* Contexte et objectif *

La désambiguïsation des entités nommées (personnes, lieux,
organisations) est un problème récurrent en traitement automatique des
langues. Elle vise à identifier l'entité du monde réel qui est désignée
par un segment de texte. Elle est souvent décomposée en deux phases : la
recherche des candidats suivie par la sélection du meilleur
candidat. Ces algorithmes s'appuient souvent sur des bases de
connaissances (KB) comme DBpedia/Wikidata ou encore data.bnf.fr qui
décrivent les entités ainsi que leurs propriétés et relations selon un
modèle de graphes RDF. Ces KB sont davantage nombreuses et volumineuses
dans le contexte du Big Data.  Néanmoins, l'exhaustivité de ces données
peut parfois être insuffisante. En effet, il est souvent nécessaire de
compléter et d'enrichir la KB quand il n'y a aucun candidat ou bien le
bon candidat n'est pas présent.

Un outil de désambiguïsation d'entités nommées, baptisé REDEN, a été
développé dans le contexte des humanités numériques. Cet algorithme est
non supervisé, fondé sur l'analyse de graphes et les standards du web
sémantique, indépendant de la langue, et s'appuie sur des KB distribuées
sous forme de données liées. Par rapport à des approches existantes
telles que DBpedia Spotlight ou Babelnet, REDEN est plus flexible dans
le choix d'adaptation de la KB.

L'objectif du stage est d'adapter REDEN à des nouveaux domaines. En
effet, il est envisagé d'expérimenter avec plusieurs corpus textuels, en
particulier des textes littéraires et historiques, issus des projets de
recherche en humanités numériques en cours. Il serait nécessaire
d'effectuer un état de l'art des approches existantes en
désambiguïsation des entités nommées. Il est également important de
proposer un protocole d'évaluation de la solution proposée, un corpus
d'évaluation (gold standard) devra donc être constitué. Pour cela, il
est souhaitable d'utiliser le framework GERBIL
(http://aksw.org/Projects/GERBIL.html), il est donc nécessaire d'adapter
l'outil développé afin de permettre son intégration dans GERBIL. Il est
également nécessaire de rendre interopérable l'outil avec des
algorithmes de reconnaissance des entités nommées existants, en
particulier le système SEM (Dupont 2017,
http://apps.lattice.cnrs.fr/sem/) développé au Lattice.

*Bibliographie*

Dupont, Yoann (2017). Exploration de traits pour la reconnaissance
d'entités nommées du Français par apprentissage
automatique. TALN-RECITAL, p. 42.

Carmen Brando, Francesca Frontini, Jean-Gabriel Ganascia (2016) REDEN:
Named-Entity Linking in digital Literary Editions using Linked Data
Sets, Complex Systems Informatics and Modeling Quarterly CSIMQ, Issue 7,
June/July 2016, pp. 60-79, RTU Press

Pablo Ruiz, Thierry Poibeau, Frédérique Mélanie (2015). ELCO3 : Entity
Linking with Corpus Coherence Combining Open Source Annotators. In
Proceedings of the Demonstrations at NAACL 2015. Denver, U.S.


*Localisation*

Le stage aura lieu au Laboratoire LATTICE - Langues, Textes, Traitements
informatiques, Cognition - UMR 8094.
Durée du stage : 5 mois à temps plein
Date de début : printemps (entre février et avril)  2018
Gratification : suivant les règles en vigueur
Adresse : Ecole Normale Supérieure, 1 rue Maurice Arnoux - F-92120
Montrouge France

Pour candidater à ce stage, merci de transmettre un CV et une lettre
motivation à :
carmen.brando@ehess.fr,
francesca.frontini@univ-montp3.fr,
thierry.poibeau@ens.fr"
"438","2017-12-04","Fortia","Paris","DATA SCIENTIST


Fortia Financial Solutions	

Description du poste

Fortia Financial Solutions est une RegTech labélisée OSEO créée en
2012, basée à Paris.

Les RegTech proposent aux acteurs financiers des solutions
technologiques destinées à gérer leurs activités « compliance », ou
conformité, c'est-à-dire le respect des dispositions législatives et
réglementaires ainsi que des normes internes et statutaires. Fortia
Financial Solutions développe la plate-forme logicielle Innova, une
solution innovante reposant sur le machine-learning et l'intelligence
artificielle, dédiés aux métiers de la Finance. Rejoindre Fortia
Financial Solutions c'est rejoindre une équipe jeune, dynamique et
passionnée.

Sous la supervision d'une Chief Research Scientist, vous rejoindrez
une équipe R&D dédiée à l'analyse sémantique de texte dans le contexte
spécifique de la finance. Vous travaillerez sur l'analyse des
sentiments, la reconnaissance d'entités nommées et l'extraction
d'informations en général.

Vous serez amené(e) à travailler sur des problèmes d'analyse
syntaxique de dépendance, de marquage de POS et d'analyse syntactique
en utilisant des méthodes de deep learning ( CNN, LSTM, bi-lstm, word
embeddings comme word2vec ou GLOVE) ou de méthodes plus classiques
d'apprentissage automatique (svm, knn,...).

- Modélisation, implémentation et testing des algorithmes.
- Veille constante sur les nouveautés dans le domaine et état de l'art
      d'articles de conférences et journaux.
- Participation et rédaction de brevets et spécifications techniques.

 
Le profil recherché

    Diplômé(e) d'une école d'ingénieur ou équivalent avec une
    spécialisation en data science/machine learning

    Vous avez d'excellentes capacités d'analyse et de réflexion afin
    de résoudre des problématiques complexes en lien avec le deep
    learning et le NLP.

    Vous étudiez et proposez des solutions d'améliorations.

    Vous effectuez une veille active concernant les dernières avancées
    en matière de machine learning.

    Vous êtes curieux(se), passionné(e) et ouvert(e) d'esprit.

    Vous justifiez au minimum de 2 ans d'expérience (travaux d'études
    compris) sur les frameworks Python en lien avec des problématiques
    de NLP (analyse des sentiments, reconnaissance d'entités nommées
    et extraction d'informations en général).

 
Nous vous proposons

    Une dimension internationale de votre travail (échanges avec des
    collaborateurs, des clients étrangers).

    Une plate-forme répondant à des exigences techniques très
    avancées.

    Un travail orienté vers l'interactivité avec les collaborateurs de
    toutes les équipes, Développeurs, Data Scientists, Experts Data.

    Un environnement intellectuellement stimulant.


Postuler en ligne : 
http://fortia.fr/poste/data-scientist/"
"439","2017-12-04","Syllabs","Paris","------------------------------------------------------------------------
Offre de stage TAL M2 : Génération automatique de textes en français,
espagnol, anglais ou allemand
------------------------------------------------------------------------

Syllabs est spécialisée en analyse sémantique et en génération
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse de
données textuelles du Web : identification des pages pertinentes,
extraction et catégorisation des informations clés. La génération est
proposée au travers de sa solution data2content qui permet, à partir
d'une base de données structurées, de produire automatiquement des
textes de qualité humaine. Nos robots rédacteurs écrivent pour des
médias de référence français comme Le Monde ou Radio France.

C'est dans le cadre de data2content que nous recherchons un·e
ingénieur·e linguiste pour intégrer l'équipe actuelle et participer au
paramétrage du moteur de rédaction. Les domaines d'application sont
principalement les médias, les sites d'informations et les sites
d'e-commerce.

-----------------------------
 Description du poste
------------------------------
Les tâches principales concernent:
- Prise en main de notre moteur de rédaction.
- Écriture des règles pour alimenter notre moteur de rédaction et
  produire des contenus pour nos clients.
- Pour les personnes natives de la langue anglaise, espagnole ou
  allemande : adaptation des règles existantes en français vers la
  langue maîtrisée.
- Préparation des bases de connaissances structurées utilisées par les
  règles.

-----------------------
 Profil recherché
------------------------

- Étudiant·e en Linguistique Informatique, Traitement automatique des
  langues ou Traduction
- Excellentes qualités rédactionnelles, goût pour l'écriture
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail en
  équipe
- Programmation en Python
- Compétences en rédaction web seraient un plus

-----------------
 Conditions
-----------------
- Stage conventionné 6 mois rémunéré en fonction du niveau d'étude
- tickets resto + remboursement à moitié du pass Navigo (transport)
- Bonne ambiance, coin canapé et équipe technique de grande
  qualité. Apéro mensuel

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage génération ».

Lieu : Quartier de Charonne (Paris 11), entre Bastille et Nation. Locaux
conviviaux partagés avec d'autres start-ups data-lovers."
"440","2017-12-11","LIASD","Paris","------------------------------------------------------------------------
Offre de stage de Master 2 : Deep learning pour le résumé automatique
par filtrage puis génération

LIASD - Université Paris 8 - IUT de Montreuil
------------------------------------------------------------------------

---------------------
 Notre laboratoire
---------------------

Le LIASD est un laboratoire d'intelligence artificielle à cheval sur le
campus de Saint-Denis de l'Université Paris 8 et le site de l'IUT de
Montreuil. Nous développons au sein de l'IUT de Montreuil un axe de
recherche lié au texte, à la représentation des connaissances et à la
recherche et à l'extraction d'information.


---------------------
 Contexte du stage
---------------------

Nous disposons d'un financement de l'Agence Nationale de la Recherche,
le projet ASADERA (http://linc.iut.univ-paris8.fr/asadera), dont
l'objectif est d'explorer de nouvelles modalités et méthodes de résumé
automatique. Dans ce cadre, nous voulons explorer des méthodes
génératives de résumé automatique. Le résumé automatique a longtemps été
cantonné à des approches purement extractives (l'extraction de fragments
de texte depuis les documents à résumer), puis a évolué vers plus
d'abstraction grâce aux approches de compression de phrases (les phrases
sont compressées puis une étape d'extraction extrait les meilleures
d'entre elles). Aujourd'hui, la communauté scientifique s'intéresse de
plus près aux approches génératives (voir par exemple
http://aclweb.org/anthology/D17-1221), notamment grâce à l'apport des
réseaux de neurones profonds récurrents. Cependant, la complexité de
l'apprentissage de la génération d'un texte court depuis un texte
beaucoup plus long fait qu'une approche purement générative reste
impensable. De plus, puisque les résumés à générer diffèrent par leur
sujet et donc les mots utilisés des résumés sur lesquels un modèle peut
être appris, le mécanisme de génération doit faire appel à des
techniques particulières afin d'éviter d'intégrer des mots issus du
vocabulaire spécifique des sujets du corpus d'apprentissage dans les
résumés générés sur de nouveaux sujets.


------------------------
 Description du stage
------------------------

Nous proposons ici de réduire la complexité du problème en procédant en
premier lieu à une approche de filtrage des phrases : seules les phrases
les plus pertinentes doivent servir de base à l'apprentissage de la
génération. Puis l'apprentissage, à base de réseaux de neurones profonds
récurrents, doit incorporer un mécanisme de copie
(https://arxiv.org/abs/1603.06393) afin d'éviter l'intégration de mots
hors sujet dans les résumés générés.

Le stagiaire devra donc implémenter ces différentes couches de
traitement afin de produire puis d'évaluer un système de résumé
automatique par filtrage/génération. Les corpus ainsi que les outils
d'évaluation sont prêts à utiliser, et les mécanismes de filtrage
également. Différentes implémentations des RNN avec mécanisme par copie
sont également disponible, mais externes à l'équipe.

Le stage est d'une durée de 6 mois.


---------------------------------------
 Compétences/Connaissances requises
---------------------------------------

- Niveau Master 2
- Maîtrise des frameworks Keras/Tensorflow
- Forte compréhension des mécanismes d'apprentissage des réseaux de
  neurone
- Intérêt pour le traitement automatique du langage
- Parfaite maîtrise des systèmes Linux
- Maîtrise des langages Python et Java


-----------------
 Lieu du stage
-----------------

IUT de Montreuil
140 rue de la Nouvelle France
93100 Montreuil
Métro Mairie de Montreuil + bus (15 minutes)


--------------------
Références utiles
--------------------

Jiatao Gu, Zhengdong Lu, Hang Li, and Victor OK Li. 2016. Incorporating
copying mechanism in sequence-to-sequence learning. In ACL, pages
1631-1640

Chen Li, Fei Liu, Fuliang Weng, and Yang Liu. 2013.  Document
summarization via guided sentence compression.  In EMNLP, pages 490-500.

Alexander M Rush, Sumit Chopra, and Jason Weston.  2015. A neural
attention model for abstractive sentence summarization. EMNLP, pages
379-389.

Ramesh Nallapati, Bowen Zhou, Caglar Gulcehre, Bing Xiang, et
al. 2016. Abstractive text summarization using sequence-to-sequence rnns
and beyond.  arXiv preprint arXiv:1602.06023.


Merci d'envoyer votre candidature à aurelien.bossard@gmail.com en
indiquant en objet ""Candidature stage résumé"". N'oubliez évidemment pas
de joindre un CV et une lettre de motivation."
"441","2017-12-11","Synapse Développement","Toulouse","Titre : Stage Knowledge Manager

Durée du stage : 6 mois
Localisation : Toulouse centre
Rémunération : rémunération légale + prime + tickets restaurants 

*** Contexte ****
Synapse Développement est une société qui développe et édite des
solutions d'intelligence artificielle. Parmi ses activités, Synapse
Développement propose un chatbot alliant approche linguistique (NLP) et
intelligence artificielle. Ce Chatbot est généré en 3 clics sur la base
de la documentation client. Une vraie révolution dans le monde de la
gestion de la connaissance et celui des chatbots !
En pleine croissance, la société place l'expertise technique et
l'excellence R&D au coeur de son activité. Nous offrons des challenges
épanouissants, des solutions technologiques innovantes, des opportunités
de réalisation et une ambiance de travail jeune et créative.


*** Mission ***

Au sein de notre équipe de développement, vous deviendrez le créateur et
« l'éleveur » de nos agents conversationnels.

Pour ce faire, vous travaillerez sur la plateforme propriétaire Chatbot
by Synapse, un chatbot innovant capable de générer automatiquement sa
base de connaissances à partir d'une documentation. Vous interviendrez
sur la phase de mise en oeuvre et d'optimisation du Chatbot, en
collaboration avec nos experts en Intelligence Artificielle et notre
équipe produit.

Votre rôle consistera notamment à :
- Étudier d'un point de vue linguistique les jeux de Question/Réponse
  générés automatiquement par le système
- Proposer des pistes d'améliorations en interaction avec l'équipe R&D
- Optimiser l'Intelligence Artificielle du système avant son déploiement
- Suivre l'utilisation réelle du chatbot dans nos outils de suivi afin de
  proposer des améliorations
- Formaliser un reporting interne et externe sur le suivi effectué

L'objectif global de la mission est d'augmenter le périmètre
d'intervention du chatbot tout en veillant à la pertinence des réponses
apportées.

*** Les apports du stage ***
- Acquérir au contact de l'équipe de développement de la plateforme
  Chatbot by Synapse une première expérience en tant que Knowledge
  Manager
- Accompagner la transformation digitale de nos clients 
- Être accompagné et progresser à son rythme dans un contexte
  bienveillant et responsabilisant.

*** Profil recherché ***
Si : 
- Vous possédez une double compétence (et appétence  ) en informatique
  et en linguistique ;
- Vous êtes en dernière année d'une formation TAL ou des métiers du
  digital ;
- Vous savez être autonome, force de proposition et êtes doté de très
  bonnes qualités relationnelles ;
- Vous avez un côté hacker et êtes passionné par les nouvelles
  technologies ;
- Vous parlez anglais very well.

N'hésitez plus, et rejoignez l'équipe Synapse !

Candidature

Envoyez-nous votre CV et votre lettre de motivation à l'adresse :
mailto:direction@synapse-fr.com
Tel. 0561636909

Patrick Séguéla
Directeur Général
Tel  : +33 (0)6 63 38 69 06
Skype : PatrickSynapse
Twitter : @patrickseguela

www.synapse-developpement.fr"
"442","2017-12-11","STL","Lille","http://natalia.grabar.free.fr/stage2018incer.php
*Modèle pour la fiabilité des informations et des connaissances*

Avec l'accumulation des informations, grâce à l'existance de différentes
sources et bases, comme par exemple les bases bibliographiques, les
bases de connaissances ouvertes, les réseaux sociaux, etc., il devient
important non seulement de pouvoir accéder à ces informations mais aussi
de statuer sur leur valeur et fiabilité. Cela peut en effet moduler leur
fiabilité et exploitation.

Le contexte du travail se situe dans le domaine médical. L'intérêt
principal consiste à proposer un modèle de fiabilité des
informations. Il s'agit en particulier des informations sur les
interactions entre l'alimentation et les médicaments. Différents
critères peuvent être pris en compte : internes (valeurs de négation,
d'incertutude ou d'imprécision contextuelles...) et externes (type de
source, données bibliographiques associées...) au texte.

Ce stage s'inscrit dans le projet ANR MIAM (Maladies, Interactions
Alimentation-Médicaments). Pour la réalisation du stage, des méthodes de
Traitement Automatique de la Langue et de fouille de textes seront
utilisées.

Plus spécifiquement, il s'agit des objectifs suivants:
- travailler avec des corpus de textes de différents types et provenant
  de différentes sources
- exploiter et améliorer les annotations des textes avec différents
  niveaux de spécificités
- proposer et modéliser les critères internes de la certitude
- proposer et modéliser les critères externes de la certitude
- exploiter, adapter ou développer des méthodes pour le calcul du statut
  des informations
- évaluer les méthodes et les résultats

Le stagiaire sera amené à utiliser des outils TAL existants et à
développer ses propres programmes pour mieux analyser les données.

Prérequis:
- connaissances en TAL et en informatique
- connaissances de méthodes et d'outils d'apprentissage automatique
- manipulation et test des outils de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique
- maîtrise de l'anglais
- autonomie

Le stage est rémunéré selon les règles en vigueur.

Selon les résultats du stage, une poursuite en thèse pourrait être
envisagée.

Niveau: Master 2
Durée: 6 mois
Lieu: Lille

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à
eric.kergosien@univ-lille3.fr et natalia.grabar@univ-lille3.fr"
"443","2017-12-11","SNIPS","Paris","Snips is an Artificial Intelligence startup based in Paris. We are
building a technology in order to add voice interfaces to connected
devices, and we are doing this by protecting users' privacy. To protect
personal data, all of our algorithms are embedded into the connected
devices themselves. This also makes Snips one of the rare GDPR compliant
technologies when applied to voice assistants. You can find out more on
https://snips.ai/.

Aspects of our solutions are Automatic Speech Recognition (ASR), and
Natural Language Understanding (NLU). In the past year, we have designed
state-of-the-art solutions to these matters in French, English,
Mandarin, Korean, and German.

We are now looking for an awesome linguist for Japanese to help us
extend our solution to Japanese.

We are offering a 3-month position in our NLU team. It will involve:

   - training us and teaching us some basics about the Japanese
     language;
   - helping us develop our different algorithms in Japanese;
   - helping us define our Japanese crowdsourcing strategy;
   - testing our technology.


Job requirements: - Bachelor's degree in linguistics or natural language
processing;

   - Native or fluent in Japanese;
   - Fluent in English and/or French;
   - Knowledge in formal grammars and/or regular expressions is a plus;
   - Knowledge in command line is a plus (unix-style terminal);
   - Interest in the Internet of Things and/or personal assistants is a
     plus!

Job details: - Location: Paris;
   - Contract: can be either an internship, a commercial or freelance
     contract;
   - Duration: 3 months (~35 hours per week);
   - Start date: between January 5th and January 22th;
   - Gross salary: calculated from a yearly basis from ¤17000 to ¤40000
     depending on the type of contract, the experience and the level of
     education;
   - Plus: learning fun stuff such as regular expressions, command line,
     context-free grammars, etc. and being an actual actor of our
     solution!
   - Last but not least: free food and drinks!


If you are interested and/or you want more details about the position
feel free to email me at anais.chanclu@snips.ai. I will be delighted to
discuss further details with you or to welcome you in our office for a
little chat.

To apply, please proceed to our website:
https://snips.welcomekit.co/jobs/linguist-for-japanese_paris"
"444","2017-12-11","Sinequa","Paris","Stage : Amélioration de l'analyse linguistique de documents en langue
japonaise

Sinequa cherche un linguiste informaticien de langue maternelle
japonaise pour un stage d'une durée de 3 à 6 mois dans ses locaux à
Paris. Faisant partie de l'équipe linguistique au sein du département de
R&D, le stagiaire testera et améliorera l'analyse linguistique de
documents en langue japonaise du produit de Sinequa. Si ce stage vous
intéresse, merci d'envoyer votre CV à Frederik Cailliau
<cailliau@sinequa.com>.

Internship: Enhancement of Japanese NLP capabilities on documents in
Japanese

Sinequa is seeking a native Japanese computational linguist for an
internship of 3 to 6 months at its office in Paris. As part of the
linguistic team within the R&D department, the intern will test and
enhance the Japanese NLP capabilities of Sinequa's product. Candidates
should send their curriculum vitae to Frederik Cailliau
(cailliau@sinequa.com).

http://www.sinequa.com"
"445","2017-12-11","Eptica","Boulogne-Billancourt","Offre de Stage en TAL: Analyse Sémantique des Conversations Digitales en
Langue Anglaise.

Stage de 6 mois.

EPTICA.

Leader européen des solutions conversationnelles, collaboratives et
cognitives de l'expérience client multicanale : email, web social, chat,
Gestion de bases de connaissances & voix du client, Eptica permet de
créer des synergies entre le web et le Service Client d'une entreprise
dans le but d'améliorer la qualité des conversations avec les clients,
de leur fournir des informations pertinentes, de répondre rapidement et
de manière personnalisée à leurs questions et de favoriser chaque
opportunité de vente pour un service client d'excellence. Eptica est
référencée dans le Magic Quadrant du Gartner depuis 2011.

Eptica intègre dans toutes ses lignes de produit, un moteur multilingue
d'analyse et de recherche sémantique.


PRODUITS.

Eptica Enterprise Suite(TM) est une plate-forme intégrée permettant aux
entreprises d'appréhender le cycle client dans sa globalité, à travers
les solutions suivantes :

- Eptica Web Self-service pour apporter un service client en ligne 24/7
- Eptica Email Management pour la gestion des emails entrants ;
- Eptica Chat pour établir un dialogue proactif avec les internautes par
  chat et co-navigation
- Eptica Contact Assistant pour permettre aux conseillers d'améliorer le
  taux de résolution au premier contact
- Eptica Fax-Letter-SMS pour prendre en charge la gestion des demandes
  par fax, courrier et SMS
- Eptica Analytics pour synthétiser et analyser les données du service
  client grâce à un outil décisionnel.

Dans le cadre de ses activités de R&D, au sein de l'équipe NLP & AI,
Eptica propose une offre de stage en TAL (Traitement Automatique des
Langues) pour le développement de services d'analyses en langue
anglaise, pour la compréhension des conversations client.

*NOS VALEURS*

Ténacité - Innovation - Loyauté - Diversité

MISSION.

Les candidats doivent développer et maintenir les fonctionnalités
sémantiques d'analyse des conversations client en langue anglaise,
intégrées dans la solution logicielle éditée par Eptica.

ACTIVITÉS PRINCIPALES
   - Réalisation des fonctionnalités sémantiques de la solution ELS
     (Eptica Linguistic Services): Analyse du contenu des
     conversations. Participer aux analyses préparatoires des
     fonctionnalités, en langue anglaise.
   - Transmission de la connaissance nécessaire à l'exploitation :
     s'assurer que les ressources développées puissent être maintenues
     par des personnes tierces grâce à la documentation technique.
   - Organisation agile.


PROFIL RECHERCHE
 - Formation en Master 2 en TAL & Sciences du langage.
   - Formation initiale en TAL & Sciences du langage, langue anglaise.
   - Connaissance des plateformes TAL : NooJ, TreeTagger, Stanford,
     Gate, TXM
   - Connaissances en Javascript, Perl,Groovy


MODALITES
 - Stage de 6 mois (Possibilité d'embauche en CDI)
   - Rémunération prévue: 525 euros/mois + prime en fonction des
     résultats
   - Période: à partir de Janvier/Février 2018.
   - Lieu : Boulogne-Billancourt


Merci d'adresser vos candidatures à melanie.lefeuvre@eptica.com !"
"446","2017-12-11","Eptica","Boulogne-Billancourt","Offre de Stage en TAL: Modèles de Parcours Clients, basés sur l'Analyse
Sémantique des Conversations Digitales.

Stage de 6 mois.

EPTICA.

Leader européen des solutions conversationnelles, collaboratives et
cognitives de l'expérience client multicanale : email, web social, chat,
Gestion de bases de connaissances & voix du client, Eptica permet de
créer des synergies entre le web et le Service Client d'une entreprise
dans le but d'améliorer la qualité des conversations avec les clients,
de leur fournir des informations pertinentes, de répondre rapidement et
de manière personnalisée à leurs questions et de favoriser chaque
opportunité de vente pour un service client d'excellence. Eptica est
référencée dans le Magic Quadrant du Gartner depuis 2011.

Eptica intègre dans toutes ses lignes de produit, un moteur multilingue
d'analyse et de recherche sémantique.

PRODUITS.

Eptica Enterprise Suite(TM) est une plate-forme intégrée permettant aux
entreprises d'appréhender le cycle client dans sa globalité, à travers
les solutions suivantes :

- Eptica Web Self-service pour apporter un service client en ligne 24/7
- Eptica Email Management pour la gestion des emails entrants ;
- Eptica Chat pour établir un dialogue proactif avec les internautes par
  chat et co-navigation
- Eptica Contact Assistant pour permettre aux conseillers d'améliorer le
  taux de résolution au premier contact
- Eptica Fax-Letter-SMS pour prendre en charge la gestion des demandes
  par fax, courrier et SMS
- Eptica Analytics pour synthétiser et analyser les données du service
  client grâce à un outil décisionnel.

Dans le cadre de ses activités de R&D, au sein de l'équipe NLP & AI,
Eptica propose une offre de stage en TAL (Traitement Automatique des
Langues) pour le développement de services d'analyses en langue
anglaise, pour la compréhension des conversations client.

Nos valeurs

Ténacité - Innovation - Loyauté - Diversité

MISSION.

Les candidats doivent développer et maintenir des fonctionnalités
sémantiques d'analyse des conversations client pour 2 secteurs
d'activité (ecommerce et Banques & Assurances), intégrées dans la
solution logicielle éditée par Eptica.

ACTIVITÉS PRINCIPALES
   - Réalisation des fonctionnalités sémantiques de la solution ELS
     (Eptica Linguistic Services): Analyse du contenu des
     conversations. Participer aux analyses préparatoires des
     fonctionnalités, en langue anglaise.
   - Transmission de la connaissance nécessaire à l'exploitation :
     s'assurer que les ressources développées puissent être maintenues
     par des personnes tierces grâce à la documentation technique.
   - Organisation agile.


PROFIL RECHERCHE
 - Formation en Master 2 en TAL & Sciences du langage.
   - Formation initiale en TAL & Sciences du langage, langue anglaise.
   - Connaissance des plateformes TAL : NooJ, TreeTagger, Stanford,
     Gate, TXM
   - Connaissances en Javascript, Perl,Groovy


MODALITES
 - Stage de 6 mois (Possibilité d'embauche en CDI)
   - Rémunération prévue: 525 euros/mois + prime en fonction des
     résultats
   - Période: à partir de Janvier/Février 2018.
   - Lieu : Boulogne-Billancourt


Merci d'adresser vos candidatures à *laura.noreskal@eptica.com !*"
"447","2017-12-11","Santé Publique France","Saint-Maurice (94)","Offre de stage M2 Linguistique informatique

Titre : Classement automatisé des décès en regroupements pertinents pour
l'alerte sanitaire à partir des causes médicales inscrites en texte
libre dans les certificats de décès

Contexte

Suite à la canicule d'août 2003, Santé publique France a mis en place
dès 2004 le système de surveillance syndromique SurSaUD (Surveillance
Sanitaire des Urgences et des Décès), ayant pour objectif la détection
précoce et réactive de variations inhabituelles de pathologies ou
symptômes dans les recours aux soins d'urgences et la mortalité, ainsi
que l'évaluation d'impact en santé publique d'évènements (épidémies,
phénomènes émergents tels que les épidémies de chikungunya, phénomènes
environnementaux (canicule, inondations, incendies, ouragans), accidents
industriels, grands rassemblements de population (Euro de football 2016,
Sommets du G8/G20, ...).

La certification électronique des décès constitue l'une des 4 sources de
données du système SurSaUD. Les données démographiques et les causes
médicales de décès inscrites dans le certificat de décès sont transmises
à l'Inserm-CépiDc et à Santé publique France dès la validation du
certificat par le médecin qui constate le décès. Les causes médicales de
décès sont exprimées sous forme de texte libre (Cf. exemple dans le
tableau 1).

La surveillance réactive de la mortalité à visée d'alerte à partir de
ces données consistera à suivre des indicateurs syndromiques, définis
comme des regroupements de causes exprimant une même pathologie que l'on
voudra suivre en routine, afin de détecter une hausse inhabituelle de
cette pathologie et alerter le cas échéant les autorités sanitaires pour
qu'elles prennent les mesures de gestion adaptées. A titre d'exemple, on
cherchera à suivre en routine les décès dont les causes médicales
expriment la survenue d'une grippe ou d'infection respiratoire aigüe,
afin d'identifier un éventuel phénomène émergent en dehors d'une
épidémie de grippe.


Proposition de stage

Le stage s'inscrit dans un travail de recherche démarré en octobre 2016,
s'intitulant « construction et validation d'indicateurs syndromique de
la mortalité fondés sur les causes médicales de décès et à partir de
méthodes de traitement automatique des langues ».

Il consistera à effectuer :

- un pré-traitement des causes médicales de décès qui arrivent en texte
  libre,

- le classement des causes médicales de décès issues des certificats
  électroniques dans les différents indicateurs syndromiques qui auront
  été préalablement identifiés et définis pour la surveillance et
  l'alerte, à partir d'une ou deux méthodes de TAL supervisées.

- d'évaluer les performances de ce classement sur un à trois indicateurs
  syndromiques (en fonction du temps). Cette étape pourra également
  inclure l'exploration des causes médicales de décès mal définies ou
  non classées, afin de disposer d'outils d'exploration ou d'aide à
  l'interprétation de ces catégories.

Le pré-traitement et le classement pourront s'appuyer sur un
dictionnaire des causes médicales de décès construit par
l'Inserm-CépiDc.

Le stagiaire pourra également s'appuyer sur les nombreux développements
proposés par les équipes ayant participé à des campagnes Clef E-Health
(https://sites.google.com/site/clefehealth2017/), visant à obtenir la
meilleur méthode d'identification de codes CIM-10 dans un corpus de
textes issus des certificats électroniques.

Résultats attendus

La démarche devra être effectuée dans l'objectif final de mettre en
place ce pré-traitement et la classification des causes de façon
automatisée pour l'utilisation en routine pour la surveillance réactive
à visée d'alerte de la certification électronique des décès.

Le travail sera valorisé par la rédaction d'un article scientifique.

Déroulement du stage 

Ce stage d'une durée de 5/6 mois sera co-encadré par l'équipe de
surveillance syndromique de Santé publique France et l'équipe du LIMSI
(Laboratoire d'informatique pour la Mécanique et les Sciences de
l'Ingénieur) au CNRS.

Divers

- Date : à partir de février/mars 2018 (date exacte à définir selon convenance),
- Stage de 6 mois rémunéré (à préciser avec RH)
- Lieu : Direction Appui, Traitements et Analyses de données de Santé publique France à Saint-Maurice (94) et CNRS-Limsi à Orsay (91)

Contact:

CV + lettre de motivation à envoyer à :
Anne Fouillet
Santé publique France
E-mail : anne.fouillet@santepubliquefrance.fr"
"448","2017-12-12","Storyzy","Paris","NLP Engineer Internship

Storyzy is a startup based in Paris that monitors and detects fake
news sites through its unique AI technology. Specializing in automated
quote extraction through NLP, Storyzy develops a database of fake news
sites ensuring a safer advertising environment for brands/advertisers
and platforms.

Storyzy (previously Trooclick) was created in November 2012. Just a
few months later, in April 2013, it received financial support from
the BPI (French public investment bank) and in June 2013 was granted
the Status of ""Young Innovative Company"" (JEI), recognizing its
innovative nature by the French government.  Storyzy has invested $3
million in R&D, raised $900k in August 2016, and employs 12 people (6
engineers).

Due to its growth, Storyzy is now looking for candidates for its office in the ""Incubateur Boucicaut"" on rue de Lourmel in Paris.

Missions:

As a member of the technical team, you will benefit from ongoing
training and you will help us design and build our information
extraction framework based on advanced NLP technologies.

- You will turn ideas into well-documented and reliable linguistic
resources & code to ensure efficiency, quality, performance and
scalability

- A great team player, you will interact with other departments to
understand and fine tune specifications

- You will carry out unitary testing, create and maintain our test
validation corpus and participate in editing technical documents

- You will evolve in a DevOps culture

Qualifications:

- Experience with NLP tools such as NooJ, Unitex or Stanford for
  linguistic annotation, named entity recognition, relationship and
  fact extraction, sentiment analysis, etc.

- Java programming experience on Linux platforms (ORM & Spring
  Framework will be a plus)

- Experience in scripting languages such as Perl or Python and with
  database management

- Machine Learning knowledge

- Excellent communication skills in English and French

We are open to new ideas that will significantly contribute to our
success. Our friendly team will provide the opportunity for valuable
collaboration. We offer you career perspectives in a young and dynamic
company with an interesting and diversified scope of duties at the
cutting edge of research.

We welcome applications from highly motivated individuals able to
learn new techniques and share knowledge and experience with the
team. Interested? Then send your application to jobs@storyzy.com!"
"449","2017-12-12","Idiese","Nantes","PROPOSITION DE STAGE

Traitement du Langage Naturel - H/F

Présentation  de  la  société

L'entreprise Idiese est un cabinet d'études créé en 2014 dans
l'optique d'apporter aux industriels des solutions en matière
d'intervention consultant.  Nous intervenons auprès de nos clients à
travers des contrats d'étude au forfait ou des missions d'assistance
technique.  Nous développons également nos propres solutions
techniques grâce à notre pôle R&D pour les industriels mais aussi le
grand public .

Contexte  de  la  mission

Dans le cadre du développement de notre Pôle Informatique, nous
recherchons un Etudiant(e) en formation supérieure d'informatique,
spécialisé en intelligence artificielle / traitement automatique du
langage.

Détails des missions

Au sein de l'équipe R&D et en collaboration avec le responsable
technique, vous serez en charge des missions suivantes :

- Conception et développement d'un parseur sémantique
- Intégration du parseur dans une chaîne de traitement existante
- Test et évaluation de modèles
- Validation fonctionnelle de modèles

Compétences  souhaitées
- Python
- Programmation  Logique
- Machine  Learning
- Analyse  linguistique
- Linux  (Debian/Ubuntu)

Informations  de  l'offre
- Contrat : stage
- Dates : à partir du 1er Janvier 2017

Durée : 4 à 6 mois

Lieu : Idiese - 1 rue jean rouxel, 44700 Orvault

Rémunération : gratification de stagiaire

Contact :

Stéphane MBINKY

Responsable Pôle Vision - stephane.m@idiese.com"
"450","2017-12-13","Telecom ParisTech","Paris","*Internship and PhD position in machine learning for multimodal
engagement analysis *

*in human-robot interactions (HRI)*

Telecom ParisTech [1],  LTCI lab [2]

Duration: 6-month internship to be continued as 3-year PhD contract
Start: Any date from February 1st, 2018

Salary: according to background and experience

****Position description**

The internship/PhD project will take part in a collaboration between
Softbank Robotics and Télécom ParisTech on the topic of engagement
analysis in interactions of humans with Softbank's robots.

The role of the intern/PhD student will consist in developing robust
machine learning systems able to effectively take advantage of the
multimodal signals acquired by the robot's sensors during its
interaction with a human. The work will include:

- the design of appropriate elicitation protocols and multimodal data
  acquisition procedures ;

- the development of multimodal feature learning and dynamic
  classification procedures capable of handling noisy observations with
  missing values, especially exploiting deep learning techniques ;

- the evaluation of the system in realistic scenarios involving
  end-users.

The PhD project will be hosted at Telecom ParisTech department of
images, data and signals of [3], jointly by the social computing [4] and
the audio data analysis and signal processing [5] teams.

* *Candidate profile**

As a minimum requirement, the successful candidate will have:

- A Master's degree (possibly to be granted in 2018) in one of the
  following areas: computer science, artificial intelligence, machine
  learning, signal processing, affective computing, applied mathematics

- Excellent programming skills (preferably in Python)

- Good command of English

The ideal candidate will also (optionally) have:

- Knowledge in deep learning techniques

-- More about the position

- Place of work: Paris, France

- For more information about Télécom ParisTech see [1]

-- How to apply

Applications are to be sent to Chloé Clavel [6], Giovanna Varni [7] and
Slim Essid [8] by email (using
{firstname.lastname}@telecom-paristech.fr)

The application should be formatted as a single *pdf file* and should
include:

- A complete and detailed curriculum vitae

- A letter of motivation

- Academic records of the last two years

- The names and addresses of two referees

[1] http://www.tsi.telecom-paristech.fr

[2] https://www.ltci.telecom-paristech.fr/?lang=en

[3] http://www.tsi.telecom-paristech.fr/en/

[4] https://www.tsi.telecom-paristech.fr/recherche/themes-de-recherche/analyse-automatique-des-donnees-sociales-social-computing/

[5] http://www.tsi.telecom-paristech.fr/aao/en/

[6] https://clavel.wp.mines-telecom.fr/

[7] http://sites.google.com/site/gvarnisite/

[8] http://www.telecom-paristech.fr/~essid"
"451","2017-12-13","AIZIMOV","Paris","------------------------------------------------------------------------
Offre de Stage en TAL: Compréhension de texte multi-langue basés
sur des corpus spécialisés
et participation à la création d'interface utilisateur d'apprentissage

AIZIMOV - Jeune start-up Parisienne
------------------------------------------------------------------------

---------------------
 Notre start-up
---------------------

AiZimov aide à adresser les bons messages, aux bonnes personnes, aux
bons moments et avec la forme qui convient. Il s'agit d'une entreprise
axé sur les données personnelles, les réseaux sociaux et les
entreprises. Notre outil s'appuie sur l'Intelligence Artificielle pour
automatiser la prospection.

C'est donc un vrai assistant qui rédige pour ses utilisateurs les
meilleurs emails prospectifs qui soient et traite les réponses.  En
bref, nous aidons les entreprises à déceler de nouvelles opportunités,
optimiser le temps de prospection et protéger la réputation en
harmonisant la qualité des messages sortants.

---------------------
 Contexte du stage
---------------------

Nous disposons d'un financement de la Banque Publique d'Investissement,
AiZimov est une société qui développe et édite une application
d'intelligence artificielle. Notre objectif est d'améliorer constamment
l'expérience client et réduire les incohérences entre les messages
commerciaux et les attentes des prospects.

AiZimov propose un assistant alliant approche linguistique (NLP) et
intelligence artificielle. Cet assistant est disponible sans aucun
effort de la part de l'utilisateur. Une vraie révolution dans le monde
de la vente et celui des entreprises !

En plein amorçage, la société place l'expertise technique et
l'excellence R&D au coeur de son activité. Nous offrons pour nos équipes
des challenges épanouissants, des responsabilités fortes, des
opportunités de réalisation et une ambiance de travail jeune et
créative.

------------------------
 Description du stage
------------------------

Nous proposons ici un stage opérationnel d'analyse de texte automatisé.
En premier lieu le stagiaire devra proposer une approche de filtrage du
contenu.
Seul le contenu pertinent devra être conservé.
Puis l'apprentissage, à base de technologie open source de NLU pour
appréhender
et catégoriser ce contenu extrait.
Enfin, un outil de validation et d'enrichissement sera créer pour
administrer cet outil.

Le stagiaire devra donc implémenter ces différentes couches de
traitement afin de produire puis d'évaluer un système de traitement
automatique par filtrage/génération.

Le stage est d'une durée de 6 mois et peut déboucher sur un CDI.

---------------------------------------
 Compétences/Connaissances requises
---------------------------------------

- Niveau Master 2 ou équivalent
- Passion pour la compréhension de texte automatisée
- Maîtrise de frameworks NLP (au choix : NooJ, TreeTagger, Stanford,
  Gate, TXM)
- Mi-hacker mi-structuré
- Plus: Maîtrise des langages Python et JS
- Non obligatoire : compréhension autour du digital en général et des
  technos du web en particulier (Php, reactJS ...)

-----------------
 Lieu du stage
-----------------

62 Rue Jean-Jacques Rousseau
75001 Paris

--------------------
Références utiles
--------------------

FrenchWeb :
https://www.frenchweb.fr/fw-radar-aizimov-lintelligence-artificielle-au-service-des-mails-prospectifs/305202

Industrie Technologie :
https://www.industrie-techno.com/aizimov-l-intelligence-artificielle-qui-m-a-adresse-un-mail-personnalise-et-accrocheur.51847

Fast Company :
https://www.fastcompany.com/40494268/four-new-ai-tools-will-help-you-be-more-productive

--------------------
Contact
--------------------

Merci d'envoyer votre candidature à jerome.devosse@aizimov.com en
indiquant en objet ""Candidature NLP stage"". N'oubliez évidemment pas de
joindre un CV ou un lien vers votre profil linkedin et un email
présentant vos attentes pour votre stage et vos motivations."
"452","2017-12-18","LIMSI","Orsay","Stages pour M1 et M2, profils TAL sémantique, représentation des
connaissances

Contexte : synthèse et traduction assistée vers la langue des signes

Lieu : LIMSI, Orsay (91)

Gratifications de stage

Dates et durée flexibles, courant 2018, à définir selon niveau et
contenu


Les traducteurs en langue des signes (LS) pratiquent la déverbalisation,
c'est-à-dire une abstraction du sens du texte source, et ont souvent
recours ensuite à des schémas représentant les entités du discours et
les liens entre elles pour organiser la formulation du message
équivalent en LS. Des sourds et natifs de la LS utilisent aussi ce type
de schémas comme forme écrite, néanmoins comparable à une représentation
sémantique.

Cependant, aucun standard n'existe pour la composition de ces schémas.

Ce stage propose d'en constituer un corpus et d'en étudier les 
régularités par alignement manuel avec des textes sources. Pour un M2 
(stage en principe plus long), on propose de procéder à une prenière 
étude du corpus constitué, et de suggérer des éléments de formalisation 
en vue d'une éventuelle standardisation.

Un PDF détaillé est proposé sur le site du laboratoire à la page du
stage :

https://www.limsi.fr/fr/formation/offres-de-stages/details/5/53

Pour répondre à cette offre, contacter Michael Filhol 
(michael.filhol@limsi.fr)"
"454","2017-12-18","Aix-Marseille Université","Aix-Marseille","Nous proposons le sujet de stage ci-dessous à Aix-Marseille Université.

*_Titre _**: /De la détection des signaux sociaux des médecins à un 
modèle computationnel des feedbacks pour un patient artificiel /*

/Encadrement principal/ : Magalie Ochs (http://www.lsis.org/ochsm/)
(LSIS, DIMAG), Roxane Bertrand (Laboratoire Parole et Langage), Grégoire
de Montcheuil (Laboratoire Parole et Langage), et Philippe Blache
(Laboratoire Parole et Langage).

/Financement /: Projet ANR Acorformed (http://www.lpl-aix.fr/~acorformed
)

/Contexte du stage /
Le stage se déroule dans le cadre du projet ANR /Acorformed/qui vise à
développer une plateforme de réalité virtuelle pour former les médecins
à l'annonce d'évènements indésirables graves avec un patient virtuel. Un
des enjeux majeurs de ce projet est de développer un patient virtuel
capable de simuler le comportement d'un patient réel auquel on annonce
une mauvaise nouvelle. Dans ce contexte, le comportement non-verbal du
patient (mouvements de tête, expressions faciales, postures, gestes,
directions du regard, etc.) joue un rôle prépondérant pour apporter de
la crédibilité au personnage virtuel. L'objectif de ce stage est
d'intégrer un modèle computationnel qui permettrait de déterminer
automatiquement durant l'interaction à quel moment un agent artificiel
doit exprimer quels feedbacks (verbaux et non-verbaux) en réponse au
comportement du médecin.

/Sujet de stage /
L'objectif du stage est d'intégrer un */modèle computationnel de
feedbacks pour un agent artificiel /*(personnage virtuel et robot
humanoïde)*//*qui permettrait de calculer automatiquement et en temps
réel les feedbacks que devrait exprimer l'agent artificiel suivant le
comportement de l'utilisateur (mouvements de tête, direction du regard,
gestes, vocabulaire, etc.).

Les feedbacks se définissent comme des réponses multimodales de celui
qui écoute suite au message du locuteur. Les feedbacks peuvent être
verbaux (e.g. humhum, oui) ou non-verbaux (e.g. mouvements de tête,
sourire). Plusieurs travaux de recherche dans le domaine des agents
artificiels montrent que les feedbacks permettent d'améliorer le degré
de satisfaction et d'engagement de l'utilisateur. Les feedbacks
apparaissent en réponse au comportement verbal et non-verbal du locuteur
(e.g. mouvements de tête, sourire). Dans le cadre de ce projet, il
s'agira à la fois d'intégrer des outils permettant de reconnaître les
comportements verbaux et non-verbaux de l'utilisateur potentiellement
déclencheur de feedbacks et d'intégrer un modèle computationnel à base
de règles dans un agent artificiel permettant de raisonner sur les
feedbacks que ce dernier doit exprimer.

/Méthodologie/
La méthodologie explorée dans ce stage repose sur une approche
pluridisciplinaire. Il s'agira de construireun modèle computationnel
intégrant un ensemble de règles de déclenchement de feedbacks issues de
l'analyse d'un corpus réel d'interaction médecin-patient (Porhet et al.,
2017) et d'enrichir ces règles avec desconnaissances théoriques et
empiriques sur les feedbacks, et en particulier sur les
/hétéro-répétions/. Les hétéro-répétitions (appelées other-repetition)
sont un procédé impliquant la reproduction (totale ou partielle)par
l'interlocuteur de l'énoncé produit préalablement par le locuteur. Les
hétéro-répétitions sont des réponses feedback particulières et
constituent un mécanisme crucial dans la conversation en face à face
grâce à leurs fonctions discursive et communicative.
Ce modèle devra s'intégrer dans une plateforme d'agent artificiel que
nous avons développée au sein du LPL et qui permet d'animer un
personnage virtuel et un robot humanoïde. Le modèle devra raisonner sur
les données en entrée issues de la reconnaissance vocale et de la
reconnaissance du comportement non-verbal du médecin (direction de
regard, gestes et mouvements de tête). Une évaluation à travers un
ensemble de tests perceptifs auprès d'utilisateurs interagissant avec le
personnage virtuel et le robot humanoïde permettra de valider le modèle
proposé.

/Compétences requises /
Le stagiaire devra avoir des connaissances techniques (très bonnes 
connaissances en java sont essentielles pour ce projet mais aussi 
quelques connaissances en C++), des connaissances sur les modèles 
computationnels de raisonnement et en TAL seraient un plus, une 
ouverture pluridisciplinaire incontournable.

*Contact *: Magalie Ochs (magalie.ochs@lsis.org)"
"455","2018-01-08","Airbus & LIPN","Elancourt","Offre de Stage à Airbus Defence and Space (Advanced Information Processing)

Sujet de Stage : Apprentissage automatique profond pour l'extraction
d'information et d'évènements à partir de texte.

Cadre du stage :

Ce stage recherche, d'une durée de 6 mois, se déroulera sur le site
Airbus d'Elancourt au sein d'une équipe de Recherche & Développement
spécialisée dans le traitement massif de l'information non structurée
(Big Data).  Cette équipe est impliquée dans des projets d'études
amont ainsi que divers programmes de recherche partiellement financés
par l'Agence Nationale de la Recherche, l'Agence de Défense Européenne
ainsi que l'Union Européenne. Une poursuite du stage dans le cadre
d'une convention CIFRE est envisagée sur une problématique de
population de base de connaissances à partir de texte. L'encadrement
sera assuré par les membres du département (Leila Khelif et Bruno
Grilhers ) ainsi que par des chercheurs du LIPN (Haïfa Zargayouna et
Thierry Charnois)

Contexte :

Le département R&D développe actuellement, en s'appuyant sur le socle
technique open source OW2 WebLab, une solution de veille nommée
FORTION MediaMining. Cette solution vise à fournir une solution
complète de collecte d'information multimédia -texte, image, audio,
vidéo - disponible en sources ouvertes (web, réseaux sociaux),
d'analyse (extraction et recherche d'information, transcription de la
parole, traduction automatique, etc...) et d'exploitation
(visualisation spatio-temporelle, réseau relationnel, statistiques,
etc.). Celle-ci dispose notamment de fonctionnalités d'extraction
d'information de relations et d'évènement à base de patrons
linguistiques.

Objectifs :

Ce stage vise à étudier la possibilité de remplacer / hybrider les
systèmes d'extraction à base de patrons linguistiques par des systèmes
à base de réseaux de neurones profond, type réseau de neurones
récurrents. Les différentes étapes du travail à réaliser sont les
suivantes :

- Etat de l'art des méthodes d'extraction d'information, de relation
et d'évènement à base de méthode d'apprentissage,

- Identification de solutions open source ou de laboratoire,

- Mise en oeuvre des solutions techniques (apprentissage sur base
  annotée),

- Comparaison et évaluation des approches sur un corpus de référence

Domaines techniques/compétences informatiques :

Profil recherché : Master 2 en Informatique (orienté recherche)

Domaines techniques : Intelligence Artificielle, Apprentissage
automatique, Traitement automatique des Langues, Fouille de données,
Extraction d'information à partir de textes.

Compétences en développement logiciel : Java, Python

Compétences considérées comme un plus : Connaissance de Framework de
Deep Learning type Keras, Tensorflow

Bon niveau en Anglais exigé.

La sélection se fera en deux temps : une pré-sélection par le LIPN
suivi de la sélection finale par Airbus Group.  Les locaux d'Airbus
sont dans une zone à accès restrictif. Cela impose que le(a)
candidat(e) soit habilité(e) (CD- Special France). La procédure
d'habilitation prend au minimum deux mois, il nous est donc impossible
de sélectionner des candidats étrangers.

Début souhaité : mars-avril 2018

Modalité de dépôt de candidature :

Les candidatures seront ouvertes jusqu'à sélection d'un(e) candidat(e)
et au plus tard le 16 février.  Merci d'envoyer un CV détaillant la
formation et l'expérience acquise, les bulletins de notes ou
appréciations d'enseignants dans les compétences ciblées ainsi qu'une
lettre de motivation à : haifa.zargayouna@lipn.univ-paris13.fr,
thierry.charnois@lipn.univ-paris13.fr

Lieu du stage : Airbus Defence and Space Advanced Information
Processing, 1, Boulevard Jean Moulin - CS 30503, 78997 Elancourt
Cedex- France

Responsables (Airbus) :
Bruno GRILHERES (+33 (0)1 61 38 58 25, bruno.grilheres@airbus.com)
Leila KHELIF(+33 (0) 1 61 38 56 51, leila.khelif@airbus.com)"
"456","2018-01-08","EDL","Berre l'étang (13)","Analyse de fonctionnement de la reconnaissance vocale
(TAL ou Linguistique avec des compétences informatiques) 

Mots clés : reconnaissance vocale, correction orthographique et
syntaxique, transcription phonétique, recherche textuelle avec REGEX.

Société leader des solutions informatiques pour les services d'Imagerie
Médicale publics et privés recherche un(e) stagiaire niveau M1 ou M2.

Mission principale : analyse des erreurs textuelles de la reconnaissance
vocale et participation dans leur prévention.

Objectifs du stage :
- Comparaison des résultats issus du moteur de la reconnaissance (texte
  reconnu, texte corrigé, audio).
- Réflexion sur l'algorithme d'alignement automatique de
  l'enregistrement audio et du texte corrigé ;
- Repérage et classification des erreurs et des fautes ;
- Création de règles syntaxiques pour le correcteur orthographique et
  grammaticale ;
- Réflexion et création d'un outil pour la mise à jour du dictionnaire
  orthographique.

Compétences requises : 

- Linguistique (phonétique, orthographe et syntaxe) ;
- Très bonne maitrise de la grammaire française ;
- Rigueur et attention aux détails ;
- Maîtrise des expressions régulières (REGEX);
- Maîtrise de l'encodage des dictionnaires Hunspell serait un plus
- Maîtrise de l'outil OpenSource LanguageTool serait un plus ; 
- Maîtrise d'un langage de programmation serait un plus ;
- Connaissance du domaine médical serait un plus.

Début de stage : dès que possible
Durée de stage : 6 mois
Lieu de stage : Berre L'Etang
Rémunération : selon profil

Adresser CV + lettre de motivation à : mtaranina@edl.fr"
"457","2018-01-08","LATTICE","Paris","Testing Multilingual Language Representations for Parsing

Language diversity remains a challenge for NLP. Multilingual
distributional representations (multilingual word embeddings) are known
to be efficient to address different languages simultaneously, but other
approaches have also been proposed like language transfer [1]. These
techniques have been applied to many different NLP areas such as
morphological analysis, NER, Machine Translation and Dependency parsing
[2, 3, 4].

This internship is centered around a model-transfer dependency parsing
approach using multilingual feature representations previously developed
at LATTICE. This system obtained state-of-the art results during the
CoNLL shared task 2017 (see http://universaldependencies.org/conll17/ ).

The goal of the internship is to try to get a better knowledge of the
analysis process and, more specifically of the multilingual
approach. Neural nets are generally used as a black box but it is also
advisable to dive into the representations used and test for example the
quality of the multilingual word embeddings (have the different
languages been correctly aligned?). Different parameters (size of the
training corpora, dictionary, etc) will be tested to see how they affect
the result.

The exact content of the internship will depend on the interest and
skills of the student.

* Requirements are:

- excellent programming skills
- some knowledge of neural networks
- excellent English (both spoken and written, for this internship we
  will use English as the main communication language)

* Duration and conditions

3 to 5 months, Spring 2018. Normal working conditions (indemnités de
stage + transport)

* How to apply?

Send a CV, a recent grade statement and a short email explaining in a
few words your motivation to Thierry Poibeau (thierry.poibeau@ens.fr)
and Kyungtae Lim (kyungtae.lim@ens.fr). The position is opened until
filled (but applications after Feb 2018 will not be considered).

References

[1] Stanford CS224n: Natural Language Processing with Deep Learning
(http://web.stanford.edu/class/cs224n/lecture_notes/cs224n-2017-notes2.pdf)

[2] Joulin, Armand, et al. ""FastText. zip: Compressing text
classification models."" arXiv preprint arXiv:1612.03651
(2016). (https://github.com/facebookresearch/fastText)

[3] Mikel Artetxe, Gorka Labaka, and Eneko Agirre. 2017. Learning
bilingual word embeddings with (almost) no bilingual data. In
Proceedings of the 55th Annual Meeting of the Association for
Computational Linguistics (Volume 1: Long Papers), pages 451-462.

[4] Lim, KyungTae, and Thierry Poibeau. ""A system for multilingual
dependency parsing based on bidirectional LSTM feature representations.""
Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw
Text to Universal Dependencies(2017): 63-70."
"458","2018-01-08","E Motion Analysis","Paris","ENTREPRISE

E Motion Analysis est une jeune entreprise innovante, composée de jeunes
diplômés, passionnés d'analyse sémantique de données textuelles dans les
secteurs de l'hôtellerie, la santé et les ressources humaines.
Notre métier consiste à mettre en place une plateforme d'annotation,
d'analyse et de visualisation de données pour aider les professionnels à
prendre les bonnes décisions en innovant sans cesse.

POSTE

Nous recherchons actuellement un(e) stagiaire Développeur Chatbot /
Langage Naturel.

Au sein de notre Pôle R&D, vous participerez au développement d'un
chatbot qui devra utiliser les informations sémantiques produites par
nos outils d'analyse linguistique. Vous serez alors amené(e) à effectuer
les tâches suivantes :

- Evaluer les solutions de développement de Chatbot les mieux adaptées à
  notre contexte,
- Créer des réponses à partir des questions formulées via notre outil,
- Développer l'interface.

PROFIL

- Maîtrise d'un langage de programmation pour Chatbot (Angular, Node.JS,
  Vue.JS, etc.)
- Bonnes connaissances des bases de données MySQL et MongoDB
- Bonnes connaissances en TAL

Ce Stage est à pourvoir à partir de février 2018 au sein de nos bureaux
situés à La Défense.

CONTACT

contact@e-motion-analysis.com"
"459","2018-01-08","Argus de la presse","Paris","L'Argus de la presse, partenaire de plus de 30 000 marques, est une
entreprise d'intelligence économique appartenant au Groupe Cision,
leader mondial des logiciels de relations médias, d'influence et
d'intelligence médias. Le Groupe a une forte implantation
internationale, avec plus de 3.000 collaborateurs et près de 100.000
clients.

L'Argus de la presse répond aux enjeux de ses clients pour leur
permettre de piloter leur influence et leur réputation, mesurer et
nourrir leur stratégie de communication et accompagner leur stratégie de
développement.  L'Argus de la presse se décline en 3 pôles d'activités :
Media Intelligence, Media et Publics Insights et Market
Intelligence.L'Argus de la Presse - Groupe Cision doit répondre au
quotidien aux enjeux industriels du traitement de l'information à grande
échelle.

Pour cela elle déploie des systèmes de gestion, de collecte et d'analyse
de données structurées et non structurées à grande échelle et des outils
de veille et recherche d'information ad hoc.

L'Argus utilise pour cela un certain nombre de technologies :

   - technologies symboliques et numériques pour l'apprentissage
     automatique à partir de données
   - fouille de données
   - moteur de recherche texte
   - traitement automatique du langage.

Dans ce cadre, l'Argus est à la recherche d'un stagiaire en Machine
Learning et Information Retrieval.

*Missions :*

La société lance en 2018 une nouvelle étude afin de challenger ces
technologies dans un processus d'amélioration continue.

Dans une démarche d'innovation, la mission consiste à :

- collaborer aux travaux d'étude, de documentation, de conception et de
  mise en oeuvre des Proof of Concept jusqu'à la définition des meilleurs
  scénarios de déploiement en situation réelle.

Ces travaux seront menés par une équipe composée des utilisateurs du
système cible de recherche d'information, de spécialistes en sciences de
l'information et des référents IT sur ces sujets.

*Profil du candidat :*

Titulaire d'un master 2 ou doctorat en linguistique et informatique ou
en data science avec une composante extraction des connaissances.

Vous avez une expérience académique ou professionnelle sur les outils de
base de l'intelligence artificielle :

   - technologies symboliques et numériques pour l'apprentissage
     automatique à partir de données
   - constituants d'un outil opérationnel de fouille de données
   - fonctionnement des moteurs de recherche, texte, image, parole,
     vidéo
   - traitement automatique du langage.

Vous êtes à l'aise avec la programmation et le développement de script
et la manipulation d'algorithmes existants. Votre niveau en
programmation vous permet de prototyper des solutions afin de les faire
expérimenter en interne. Dans le cadre de vos travaux, vous serez
amené(e) à identifier et à réutiliser des algorithmes existants pour les
adapter à nos besoins métiers.

*Formation et compétences requises :*

*Compétences informatiques* :

Vous avez une connaissance académique ou pratique de certaines des
solutions suivantes :

   - Outils ou algorithmes TAL : extraction d'entités nommées,
     catégorisation automatique, annotation de corpus, analyse du
     sentiment, etc. ;
   - Sensibilisation aux problématiques d'analyse morphologique et
     terminologique et formalismes et analyse syntaxiques
   - Algorithmes de classification non supervisée (Ward clustering,
     K-means...) ;
   - Algorithmes de classification supervisée (Extratrees, SVM, RNN...) ;
   - Base de graphes
   - Langage de programmation : Python ou autre langage objet récent

Le stage est à pourvoir dès que possible pour une durée de 4 à 6 mois.



*Camille Connan*
Chargée de développement RH
+33(0)1 49 25 72 78
camille.connan@argus-presse.fr

http://www.argus-presse.fr/
https://twitter.com/argusdelapresse
https://www.facebook.com/Argusdelapresse/
https://www.linkedin.com/company/argus-de-la-presse/
*Consultez notre blog Culture RP http://culture-rp.com/*"
"460","2018-01-08","Prometil","Toulouse","Titre: Extraction automatique d'une taxonomie à partir des données
Wikipédia adaptée à des documents techniques

--------------------------

Stage financé par le projet CLE (Contrat de recherche Laboratoires -
Entreprises)-ELENAA (des Exigences en LangagE Naturel à leurs Analyses
Automatiques)

---------------------------

*Contexte*
---------------------------

Le projet CLE (Contrat de recherche Laboratoires - Entreprises) intitulé
""ELENAA (des Exigences en LangagE Naturel à leurs Analyses
Automatiques)"", est mené par une collaboration entre Onera DTIM, IRIT
SIG et la société Prometil avec un soutien financier de la région
Languedoc Roussillon Midi-Pyrénées (Occitanie).

Le but de ce projet est, à partir d'exigences réelles, écrites en
langage naturel, issues de systèmes embarqués, de réaliser des
vérifications automatiques pour aider à la spécification d'exigences
plus sûres et sans erreurs. Pour ce faire, nous partirons d'exigences
écrites en langage naturel et nous plongerons ces exigences dans un
cadre formel pour pouvoir utiliser des solveurs logiques. De plus, nous
analysons ces exigences en utilisant des technologies d'intelligence
artificielle (IA) comme de l'apprentissage automatique afin d'extraire
des anomalies spécifiques (par exemple la redondance).


*Objectif*
------------------------------

La société Prometil (www.prometil.com) développe depuis 3 ans un outil
d'analyse de la qualité des exigences qui sont au coeur de la conception
des systèmes embarqués, Semios (www.semiosapp.com). Il est actuellement
déployé chez des entreprises et des partenaires industriels (Toulouse,
Toulon, Paris). Prometil continue à innover Semios en renforçant les
activités R&D autour de cet outil par la collaboration avec les
laboratoires de recherche à travers le projet ELENAA.

Dans le cadre de ce projet, Prometil cherche un stagiaire en IA qui va
participer dans les missions suivantes:

   1. Extraction d'une hiérarchie de données à partir de wikipédia
   2. Etudes des différentes méthodes (algorithmes d'apprentissage
      automatique, réseaux neurones,...) d'extraction des connaissances
      à partir des documents techniques
   3. Extraction des concepts significatifs liés aux domaines
      spécifiques comme aéronautique, spatial, automobile, naval...
   4. Construction des relations hiérarchiques (taxonomie) entre les
      concepts identifiés en utilisant les données de Wikipédia.

*Profil souhaité*
------------------------------

Niveau : Master 2 en Informatique, spécialisé en IA, Traitement des
données

- Connaissances en méthodes d'apprentissage automatique (supervisé et/ou
  non-supervisé) et d'apprentissage profond

- Connaissances des techniques d'extraction de graphes est un plus

- Connaissances en outils du TAL (Tokenizers, POS taggers, Parsers) est
  un plus

- Capacités d'analyse et de synthèse

- Connaissance des langages de programmation Python et Java

- Organisé(-e), autonome et curieux(-se) de nouvelles technologies

*Modalités du poste*
--------------------

Durée : entre 4 et 6 mois

Date de début: souhaité à partir de mars 2018

Indemnité : minimum 550¤ /mois (possible de négocier selon les
compétences)

Lieu : Société Prometil - Toulouse

Merci d'adresser CV et lettre de motivation à l'adresse mail suivante :
semios@prometil.com

www.prometil.com
Charlotte BRETON COSTEDOAT

*Responsable Marketing et Communication*
Chef de produit Maperless
52 Rue Jacques Babinet 31100 Toulouse
E-mail : c.breton@prometil.com

Tel. Prometil : +33 5 62 87 52 42
Extension : 1090"
"461","2018-01-10","Yseop","Lyon","*Offre de stage en Traitement Automatique du Language*

Yseop est une entreprise française leader du marché de la Génération
Automatique de Textes. Présente en France (Paris, Lyon), en Angleterre
et aux Etats Unis, sa mission principale est de fournir à ses clients
des services, un serveur de production, et un logiciel de parmétrage
(IDE) permettant de construire des systèmes de génération de texte dans
le but de créer divers documents, tels que des rapports d'activité, des
préparations d'entretien, des FAQ intelligentes, etc.. Notre technologie
est également utilisée dans des situations de dialogue pour la
construction de chatbots et de systèmes de recommendation interactifs.

Le stage proposé a pour but de renforcer le coeur de la technologie
Yseop en lui fournissant de nouvelles ressources linguistiques. La
mission du stage consistera à créer des ressources linguistiques
(syntaxiques et sémantiques) dans le formalisme des Grammaires
Categorielles Abstraites (ACG), et à montrer l'utilité de ces ressources
dans le cadre d'un projet pilote représentatif de projets réels. Le
formalisme des grammaires catégorielles abstraites permet de représenter
de manière unifiée divers formalismes existants (ex. TAG). Une partie du
travail consistera à trouver ou créer des ressources dans divers
formalismes, puis à les traduire en ACG afin qu'elles puissent être
utilisées par le moteur de génération de texte d'Yseop. Les formalismes
utilisés et les langues cibles des ressources feront partie des
décisions prises lors du stage.

*Informations Pratiques*

Nous cherchons en priorité des étudiant.e.s en stage de fin d'étude
(Master 2). Le contrat proposé est un CDD de 6 mois (rémunération à
définir en fonction du profil) avec embauche possible à la fin du
stage. Pour postuler, merci d'envoyer C.V. et lettre de motivation à
l'adresse suivante: rsalmon@yseop.com. La maîtrise de l'anglais écrit
ainsi que de bonnes bases en programmation sont requises. Le stage se
déroulera au département R&D d'Yseop à Lyon."
"462","2018-01-10","CS","Paris","Description de l'offre

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les contrôleurs à travers d'échanges vocaux. Dans
ce contexte, CS conçoit et réalise une gamme de produits : systèmes de
communication vocale (VCS), enregistreurs et simulateurs. Pour
d'autres applications comme la recherche d'informations de parole dans
des enregistrements, les services de communication multilingue pour
les compagnies aériennes ou la traduction multilingue de grosses
documentations techniques, il est nécessaire de traiter non seulement
la voix (signal audio) mais aussi la parole, c'est à dire le contenu
sémantique du signal audio, ou le texte écrit.

Dans ce contexte, nous souhaitons analyser les solutions disponibles
pour les principaux constituants d'une chaîne de traduction de la
parole : microphones à champ lointain utilisés pour la reconnaissance
vocale (capteurs permettant d'obtenir des enregistrements de qualité
en environnement bruité), algorithmes permettant de déterminer le
début et la fin d'un message oral (question, réponse...), reconnaissance
de la parole et synthèse vocale, et explorer leurs limites. Les
expérimentations seront réalisées sur PC et sur Raspberry. Une
maquette en Python déjà existante sur Raspberry pourra servir de point
de départ.

Travail à réaliser :

1) Expérimentation des différents microphones en champ lointain

Dans la mouvance des assistants personnels apparus ces dernières
années, plusieurs fabricants de cartes électroniques proposent
aujourd'hui des microphones sophistiqués mettant en oeuvre des
techniques de traitement de signal (formation de faisceaux par calcul,
détection d'activité vocale, filtrage...) pour permettre un
fonctionnement optimal des systèmes de reconnaissance vocale appelés
en aval de la prise de son.  Le stagiaire expérimentera ces différents
microphones, en cherchant à les paramétrer de manière à obtenir le
maximum de leurs possibilités.

2) Prototypage

Suite à cette première phase relative aux capteurs, le stagiaire
réalisera un prototype de traduction de parole constitué :

- d'un module construisant les messages audio destinés à la
  reconnaissance vocale,
- d'un module de reconnaissance vocale,
- d'un module de traduction automatique,
- d'un module de synthèse vocale,
- d'une interface utilisateur.

Pour le premier module, le stagiaire réfléchira aux algorithmes
permettant de déterminer le début et la fin d'un message oral
(question, réponse...), de manière à offrir un service naturel à
l'utilisateur (limiter son attente du lancement de la reconnaissance
vocale sans le couper au milieu de son message, possibilité de prendre
plusieurs phrases successives du même locuteur avant de passer à son
interlocuteur, les traducteurs invoqués devant traduire en sens
opposés). Le stagiaire envisager le cas où les deux interlocuteurs
utiliseront le même microphone, et celui où l'un des interlocuteurs
utilisera une oreillette BlueTooth pour déterminer le sens de la
traduction à appliquer. Une reconnaissance du locuteur et de la langue
pourra aussi être étudiée.

Les modules de reconnaissance et de synthèse vocales feront appel aux
solutions du marché. Le stagiaire évaluera ces solutions. Il étudiera
aussi les possibilités d'envoi de la parole en continu (par opposition
à l'envoi de fichiers).

Le module de traduction automatique se limitera à l'appel d'un
exécutable, soit en local, soit sur un site Internet.

L'interface utilisateur devra offrir les informations et les champs
nécessaires à un dialogue entre un client eu un agent, ou entre un
agent et une machine.

Résultats attendus :
- Rapport d'étude sur les microphones.
- Rapport d'étude sur les solutions de reconnaissance de la parole.
- Rapport d'étude sur les solutions de synthèse vocale.
- Maquette implémentant la construction des messages audio destinés à
  la reconnaissance vocale.
- Prototype de traduction de parole.
- Rapport d'étude final.


Durée : 4 à 6 mois

Profil requis

Vous êtes en 4ème ou 5ème année et vous êtes à la recherche d'un stage
de 4 à 6 mois.

Vous avez idéalement les compétences techniques suivantes :
- C/C++.
- Python.


Postuler sur https://cs.jobs.net/fr-FR/job/stagiaire-systeme-embarque-en-traduction-de-parole-h-f/J3W5P77793RW21LRNX4"
"463","2018-01-10","CS","Paris","Description de l'offre

Dans le cadre de l'amélioration des performances de ses systèmes de
contrôle de Trafic Aérien, et en particulier pour les services
d'enregistrement des communications vocales, CSSI cherche à intégrer
dans ses solutions des technologies disponibles sur le marché :
reconnaissance vocale, streaming audio, technologies IP.

Dans le cadre de ces travaux, le stagiaire devra réaliser un ensemble
de maquettes permettant d'évaluer la maturité et les performances de
ces fonctions et leurs capacités à être intégrées dans les futurs
systèmes.

L'intégration de la reconnaissance vocale dans un enregistreur audio a
pour but de transcrire automatiquement en texte les conversations
radio des contrôleurs aériens et des pilotes d'aéronefs lors de leur
enregistrement.  

Profil requis

Vous êtes en dernière année et vous recherchez un stage de 4 à 6 mois.

Vous avez idéalement les compétences techniques suivantes :
- Développement C, C++, Linux, protocoles SIP, MRCP, RTP,
- Conception objet (UML) et algorithmique

Si possible également des compétences en :
- Audio, Streaming, Reconnaissance vocale,
- Conception d'IHM, Qt

Postuler sur https://cs.jobs.net/fr-FR/job/stagiaire-integration-de-la-reconnaissance-vocale-dans-un-enregistreur-audio-h-f/J3T5JT6YHL0M1GC86FY"
"464","2018-01-10","LS2N / LIMSI","Nantes ou Orsay","Objet : Stage M2 en TAL, Analyse distributionnelle en domaine de spécialité

Aujourd'hui les modèles d'analyse distributionnelle performants
fournissent des ressources « prêt-à-porter » construites à partir de très
gros corpus tout-venant de langue générale. Ces word embeddings
génériques ne sont pas suffisants pour représenter la sémantique en
domaine de spécialité, et il est donc nécessaire de les construire sur
la base de corpus spécialisés.

Dans ce contexte, nous souhaitons porter notre attention sur la prise en
compte des termes dans des méthodes distributionnelles en mettant en
oeuvre des mécanismes de généralisation terminologique qui permettent de
factoriser des unités terminologiques. Plus particulièrement, il s'agira
de développer une approche permettant de remplacer tout terme par un
terme plus générique par une acquisition préalable de classes
sémantiques acquises sur un corpus de langue générale ou d'un domaine
proche de celui étudié.

Ce stage s'inscrit dans le projet ANR ADDICTE (Analyse distributionnelle
en domaine de spécialité) et pourra donner lieu à une thèse selon les
résultats du stage.

Le stage est rémunéré selon les règles en vigueur.

Niveau: Master 2
Durée: 5 à 6 mois
Lieu: Nantes ou Orsay

Pour présenter votre candidature, merci d'envoyer CV, lettre de
motivation et relevé de notes à Emmanuel Morin
(emmanuel.morin@univ-nantes.fr) et Thierry Hamon
(thierry.hamon@limsi.fr)"
"465","2018-01-18","CS","Paris","Enconvertisseur UNL du français pour la traduction automatique

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les contrôleurs à travers d'échanges vocaux. Dans
ce contexte, CS conçoit et réalise une gamme de produits : systèmes de
communication vocale (VCS), enregistreurs et simulateurs. Pour
d'autres applications comme la recherche d'informations de parole dans
des enregistrements, les services de communication multilingue pour
les compagnies aériennes ou la traduction multilingue de grosses
documentations techniques (Rafale pour l'Inde/l'Égypte..., par
exemple), il est nécessaire de traiter non seulement la voix (signal
audio) mais aussi la parole, c'est à dire le contenu sémantique du
signal audio, ou le texte écrit.

Dans ce but, nous souhaitons étudier la faisabilité d'un
enconvertisseur du français, c'est-à-dire un analyseur produisant des
graphes UNL (Universal Networking Language) à partir de textes en
français. Cet enconvertisseur nous permettra par la suite d'évaluer la
pertinence des graphes UNL à la fois comme représentation source pour
générer du texte dans plusieurs langues (déconversion) ou pour faire
des inférences (ontologies) et aussi comme interlingua pour de la
traduction automatique (enconversion + déconversion).

Pour transformer des phrases en graphes UNL, nous suivons la méthode
du GETA : utiliser un transducteur générique qui produit les graphes
UNL à partir des représentations profondes (« structures multiniveaux
de Vauquois », ou plus simplement « arbres de Vauquois ») obtenues par
des analyseurs existants. Plusieurs tels analyseurs produisant des
structures de Vauquois ont été développés sous Ariane et sont
disponibles en sources ouvertes.

1) Transducteur générique « arbre de Vauquois graphe UNL »

Après une phase de prise de connaissance des principes d'UNL et des
structures multiniveaux de Vauquois, le stagiaire étudiera l'algorithme
simplifié du transducteur actuellement utilisé pour transformer les
structures multilniveaux en graphes UNL dans l'enconvertisseur du
français. Il  l'étendra ensuite :

- en intégrant un traitement actuellement réalisé sous Ariane
  (transfert),
  
- en prenant en compte les scopes, qui sont des entités sémantiques
  autonomes actuellement non prises en compte.
  
le stagiaire clarifiera les éventuelles contraintes que doivent
respecter les structures multiniveaux présentées en entrée du
transducteur arbre-graphe puis il programmera l'algorithme spécifié.

2) Génération automatique d'un analyseur du français à partir d'un
dictionnaire français-UNL

D'importantes ressources bilingues NL-UNL, avec NL = anglais (83507
entrées), russe (63287 entrées), français (51352 entrées), hindi (50391
entrées), malais (31406 entrées), espagnol (21874 entrées), vietnamien
(10150 entrées) sont maintenues par Vyacheslav Dikonov, au laboratoire
LCL de l'institut IPPI de l'Académie des Sciences de Moscou . Dans le
but de tirer le meilleur parti de ces dictionnaires, le stagiaire
étudiera un programme générant automatiquement les fichiers.

Si ce domaine vous intéresse, que vous êtes idéalement en 4ème ou 5ème
année d'étude supérieur n'hésitez pas à consulter nos offres de stage et
à postuler sur :
https://cs.jobs.net/fr-FR/search?keywords=stagiaire&location= ou
directement par mail à alice.kauffmann@c-s.fr."
"466","2018-01-18","EDF","Chatou (78)","Stage - TALN, text-mining et ontologies pour la maintenance d'éoliennes
H/F (Ref. St-18-0018)

Mise en ligne le 11/01/2018
Type d'offre : Offre de stage (long)
Niveau de formation : A partir de bac +4
Spécialité(s) : Génie informatique / Télécommunications
Domaine d'intervention : R&D
Pays / Région(s) : France / Ile de France
Département : YVELINES (78)
Ville : CHATOU (78400)
Nombre de places : 1

Description de la mission

CONTEXTE DE LA MISSION

Sur les éoliennes des paramètres issus de capteurs permettent de réguler
et de surveiller le fonctionnement des différents composants de
l'installation et sont historisés dans des entrepôts de données. Lors de
l'observation d'un phénomène inhabituel ou d'un paramètre proche des
limites prévues de fonctionnement, l'exploitant consulte notamment ces
séries de données numériques pour établir un diagnostic et un pronostic
sur le phénomène sous-jacent et ses conséquences prévisibles. Son
objectif est de déterminer si l'exploitation doit être adaptée ou
interrompue pour maintenance ou si elle peut continuer jusqu'à la
prochaine période de maintenance prévue. Pour interpréter les évolutions
de ces paramètres dans le temps, il a besoin de prendre en compte des
informations de contexte sur les opérations de maintenance (c'est-à-dire
événements de maintenance) qui ont été réalisées sur l'installation
ainsi que les événements d'exploitation subis par l'installation. Une
grande partie de ces événements sont présents dans des documents
textuels non structurés ou dans du texte libre d'outils de maintenance.

L'objectif du stage est de contribuer à la reconstitution de bases de
données d'événements de maintenance et d'exploitation à partir de corpus
textuels non structurés. Il s'agit de mettre en oeuvre des techniques de
fouille de données textuelles ou text-mining non pas statistiques (ou
pas uniquement) mais de traitement automatique du langage naturel (TALN)
et d'analyse sémantique afin de retrouver ces évènements présents dans
les textes pour reconstituer ces bases d'évènements de maintenance et
d'exploitation des installations.

Un événement est une combinaison d'informations, comme par exemple pour
la maintenance, une date, un composant d'un matériel, un type
d'opération de maintenance et une action (prescription, réalisation,
...). Certaines de ces informations peuvent être corroborées par des
informations structurées disponibles dans d'autres parties du système
d'information (base de données de pièces de rechange...). Des documents
peuvent ne contenir aucune des informations recherchées alors que
d'autres documents peuvent en contenir plusieurs qu'il ne faudra pas
mélanger.

De premiers démonstrateurs ont été réalisés en 2017 (stage et
développement de chercheurs EDF R&D) pour répondre à un besoin métier et
en exploitant des données textuelles de maintenance. La chaîne de
traitement comporte notamment une phase de correction orthographique,
des développements dans GATE (lexiques par catégorie d'actions, règles
JAPE, ontologies) pour l'annotation ainsi qu'une restitution sous forme
structurée des données extraites. Les premiers résultats ayant été jugés
pertinents par le métier, nous souhaitons continuer les travaux au-delà
du premier cas test, ce qui nécessite d'améliorer la chaîne de
traitement.

OBJECTIF DE LA MISSION

L'objectif du stage est de proposer et de réaliser des améliorations sur
la chaîne de traitement (amélioration des développements et de
l'ontologie, développements complémentaires) afin de contribuer à
améliorer les résultats, à généraliser à un périmètre plus large et à
compléter la réponse au besoin d'analyse du retour d'expérience.

Avec des techniques et outils de text mining TALN/analyse sémantique, le
travail de stage consiste à :

  * Prendre connaissance de la chaîne de traitement, l'analyser et
    proposer des pistes d'amélioration ;
  * Contribuer à la priorisation des pistes d'amélioration avec les
    chercheurs EDF R&D ;
  * Concevoir, développer et évaluer des améliorations et compléments
    dans la chaîne de traitement ;
  * Positionner la solution mise en oeuvre dans l'étude vis-à-vis des
    autres solutions déjà mises en oeuvre par EDF sur d'autres projets.

DEBUT : à partir du 2ème trimestre 2018

DUREE : 6 mois (stage rémunéré)

Profil souhaité

ETUDIANTS CONCERNES : MASTER, ou Fin d'études ingénieur.

COMPETENCES SOUHAITEES : La réalisation de cette étude nécessite des
compétences en modélisation des connaissances, en techniques de fouille
de textes, en text-mining de type Traitement Automatique du Langage
Naturel et d'Analyse Sémantique, ainsi que des techniques et outils du
web sémantique, notamment RDF.

Information et candidature

En postulant sur cette offre sur le site internet edf recrute :

https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres

La référence de cette offre est : ST-18-0018

Lien vers cette offre :

https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-18-0018"
"467","2018-01-18","Experyenz","Paris","-------------------------
Titre

Stage: Développement et intégration d'un moteur de recherche multilingue
--------------------------

---------------------------
*Contexte*
---------------------------

La société eXperYenZ développe une solution de gestion de contrats
signés pour ses clients. Ces contrats sont téléchargés sur la plateforme
sous forme de fichiers pdf. Ces derniers doivent être OCRisés et soumis
à un moteur d'analyse qui doit retourner les index nécessaires aux
recherches et alertes nécessaires au service.

*Objectif*
------------------------------

Le moteur de recherche est un élément clé du service développé. Il doit
être performant pour minimiser la saisie manuelle des index et
multilingue pour accompagner notre développement à l'international.

Pour cela nous souhaitons que ce moteur puisse intégrer des technologies
d'apprentissage automatique, voire d'intelligence artificielle.

Nous possédons un moteur d'OCR qui fonctionne sous C#, avec lequel les
développements devront pouvoir être interfacés.

Dans le cadre de ce projet, eXperYenZ cherche un stagiaire en TAL qui va
participer dans les missions suivantes:


1. Etudes sur les outils du marché appliqués à l'analyse de la qualité
   des exigences

2. Construction du corpus des exigences

3. Choix des outils et technologies

4. Développement du moteur

5. Objectif de performance : à minima 50%. Plus le taux sera fort moins
   nous aurons de ressources humaines à recruter pour le faire
   manuellement, l'enjeu est donc crucial sur le business model

*Profil souhaité*
------------------------------

Niveau : Master 2 en Linguistique ou en Linguistique informatique

- Connaissances en Traitement Automatique du Langage Naturel (notamment,
  analyse syntaxique et sémantique)
- Connaissances en outils du TAL (Tokenizers, POS taggers, Parsers, ... )
- Capacités d'analyse, de rédaction et de synthèse
- Autonomie et curiosité

*Modalités du poste*
---------------

Durée : entre 4 et 6 mois

Date de début: souhaité à partir d'Avril ou Mai 2018

Indemnité : 550¤ à 700¤ /mois en fonction profil

Envoi des candidatures : laurent.lapierre@experyenz.com

Lieu : Région parisienne"
"468","2018-01-24","Workit","Boulogne-Billancourt","Stage Data Science (4 mois minimum)

 
A propos de WorkIT

WorkIT est un éditeur de logiciel SaaS qui fournit à ses clients
(grandes marques, e-commerçants) des solutions de veille
concurrentielle (analyses de prix, d'avis clients, alertes,
benchmarking...).
 
Ces solutions se basent sur des outils développés en interne et qui
permettent dans un premier temps de collecter les données sur le web
(infrastructure de crawl), de les analyser (machine learning), et de
les présenter à nos clients via différents canaux.

WorkIT analyse chaque jour les prix collectés dans plus de 17 pays sur
des univers allant de l'électronique grand public à la mode, et
accompagne ses clients depuis ses bureaux situés à Paris, London et
Düsseldorf.
 
L'équipe R&D et la datascience

L'équipe RD de WorkIT est installée dans ses bureaux de Boulogne
Billancourt et est constituée d'ingénieurs de développement, d'une
équipe opérations, d'une équipe qualité et de data scientists.

L'équipe de data scientists travaille spécifiquement sur des
algorithmes de catégorisation et de matching de produits vendus sur
des sites e-commerce. Par exemple, nous souhaitons parvenir, à partir
de photos et de textes descriptifs de produits, à les catégoriser
finement et à mettre en relation des offres de produits identiques ou
similaires vendues sur plusieurs sites distincts.

 Les spécificités du stage

Au sein de l'équipe data science, vous participerez aux diverses
activités permettant la mise au point et le déploiement de ces
algorithmes: organisation de la construction des datasets
d'apprentissage, recherche d'algorithmes et d'implémentations
pertinentes, entraînement et réglage des modèles, définition des
processus d'industrialisation, communication aux autres intervenants
de la société.

Ce stage offre l'opportunité de participer au sein d'une petite équipe
de recherche à toutes les phases de construction d'une solution à une
problématique métier centrale pour WorkIT.

 Parmi les technologies/algorithmes que vous pourrez manipuler:

   Machine learning appliqué aux images et/ou texte. Incluant le deep
    learning (CNN, RNN, CapsNet, word embeddings, etc).
 
   Environnement de développement Python/Java.

   Elasticsearch, MongoDB et MySQL

Le stage se déroule dans nos locaux à Boulogne-Billancourt.

 Le profil recherché

Formation/niveau souhaitée: stage de fin d'étude ou master en
informatique, statistiques, machine learning ou autre discipline
proche.

Compétences requise:

    Connaissance des principales méthodes de Machine Learning

    Expériences en apprentissage sur des images et/ou texte

    Maîtrise de Python (sk-learn, Numpy, Scipy, Pandas, Keras,
    Tensorflow, etc...)

    Les connaissances d'une ou plusieurs bases de données
    relationnelles ou non relationnelles sont un plus

    Autonome sous Linux

 
Par ailleurs,

   vous avez le sens de la communication et aimez travailler en
   équipe,
 
   vous avez d'excellentes capacités d'analyse/synthèse et savez faire
   preuve de rigueur,

   vous êtes curieux et créatif.

 
Une bonne maîtrise de l'anglais lu/écrit est indispensable.

 
Dates et sujet du stage

Nous avons plusieurs sujets possibles à différentes périodes de
l'année; si vous avez les compétences nécessaires, nous pouvons
construire ensemble un sujet de stage qui réponde à vos attentes.

Si vous vous reconnaissez et que vous avez envie de développer vos
compétences de data scientist dans une équipe jeune et ambitieuse,
chez un leader du big data dans l'e-commerce, alors venez nous voir;
nous vous attendons.

WorkIT, join the ascent.

Pour postuler, envoyez votre CV et votre lettre de motivation par
e-mail à stage-datascience@workit-software.com"
"469","2018-01-24","Akio Software","Paris","Offre de stage chez Akio software

Titre: Interprétation sémantique de la relation client

Descriptif:

Le sujet proposé traite de l'interprétation sémantique des informations
échangées entre une entreprise et ses clients. Le mode opératoire est
omnicanal dans le sens où quelque soit le moyen choisi par le client,
l'entreprise doit pouvoir faire le lien entre le contact présent et
l'historique des interactions passées, même si elles sont de nature
différente, que ce soit la voix, un tchat, le courriel ou les réseaux
sociaux.

Description du poste:

L'objectif du stage est d'apporter un regard extérieur sur la chaîne de
traitement actuelle afin de l'améliorer en anglais, via une
qualification quantitative. Nous sommes ouverts à de nouvelles idées qui
peuvent contribuer à notre succès au sein d'une équipe dynamique. Le
stage portera essentiellement sur la partie sémantique des composants
linguistiques de calcul des thématiques, des opinions et des modalités
d'expression.

Profil recherché:
- Niveau Master 2 ou ingénieur dernière année.
- Spécialité requise: traitement automatique de la langue.
- Bonne expérience des courriels et des réseaux sociaux.
- Bonne connaissance de l'anglais qu'il soit académique, familier ou
  argotique.
- La connaissance du néerlandais, du portugais ou de l'italien serait un
  plus.

Durée:
6 mois, de manière préférentielle d'avril à septembre.
Des adaptations sont possibles.

Lieu:
Akio
Equipe: traitement automatique de la langue.
43 rue de Dunkerque, 75010 Paris.

Gratification:
Selon les règles en vigueur avec participation aux frais de transports
en commun.

Encadrement:
Le stage sera encadré par Gil Francopoulo.

Candidature:
Merci d'envoyer un CV à gil.francopoulo@akio.com accompagné des notes de
l'année universitaire en cours et de celles de l'année dernière."
"470","2018-01-24","Price Observatory / LGI2P","Montpellier","Veuillez trouver ci-joint une offre de stage R&D sur Montpellier
proposée dans le cadre d'une collaboration entre la société Price
Observatory (http://www.price-observatory.com/en) et le laboratoire
LGI2P (http://lgi2p.mines-ales.fr/pages/la-recherche-au-centre-lgi2p) de
IMT Mines Alès.

*Algorithmes d'appariement de fiches produit*

Stage R&D 6 mois niveau Master 2 sur Montpellier, salaire 1188 euros
net/mois, perspectives de thèse ou d'embauche envisageables.
Date limite de candidature 28/02.

*Thématiques :* Comparaison de fiches produit, Algorithmique,
Apprentissage Automatique, développement Python/Java ou C++.

*Le stagiaire aura pour mission :*

 - D'analyser le contexte technique et les enjeux de la problématique
   d'appariement produit dans le contexte d'étude associé à la société
   Price Observatory.
 - De mener un travail bibliographique sur les approches d'appariements,
   et notamment sur celles basées sur des techniques d'apprentissage
   automatique supervisé et non supervisé.
 - De participer à la définition et au développement de nouveaux
   algorithmes d'appariement basés sur différentes techniques (fonctions
   de proximité multi-modales, apprentissage automatique).
 - De contribuer à la constitution d'une base d'appariements de
   référence et à la définition d'un protocole de test des algorithmes.
 - Et éventuellement, d'étudier la mise en production des solutions
   identifiées comme d'intérêt.

*Compétences requises :*

 - Forte autonomie en programmation Python (ou R), et Java ou C++. Une
   connaissance du langage PhP serait aussi appréciée mais ne constitue
   pas un prérequis.
 - Bon niveau en Mathématiques (e.g., Statistiques, Algèbre linéaire) et
   en Algorithmique.
 - Connaissances générales en apprentissage automatique (supervisé et
   non supervisé).
 - Connaissances élémentaires en bases de données (création, requêtes
   SQL, etc)
 - Maîtrise des processus qualité associés aux développements logiciels
   en entreprise - gestionnaire de version, (GIT), tests unitaire,
   rédaction de spécifications et documentations techniques, etc.
 - Capacité à travailler en équipe.

*Rémunération :* 1188¤ net par mois. Le stagiaire sera salarié ARMINES
(Première structure française de recherche orientée vers les
entreprises, adossée à 48 centres de recherche).

*Durée :* 6 mois (+ cf. perspectives précisées ci-dessous).

*Lieu :* Price Observatory 28 Avenue du Maurin, Montpellier (à proximité
de la gare).

*Perspectives :* Des perspectives de thèse financée et d'embauche sont
envisageables et seront évaluées en fonctions du travail réalisé lors du
stage.

*Contacts :*

 - Sébastien HARISPE, Enseignant-Chercheur IMT Mines Alès
   (sebastien.harispe@mines-ales.fr).
   
 - Nicolas SUTTON-CHARANI, Enseignant-Chercheur IMT Mines Alès
   (nicolas.suttoncharani@mines-ales.fr).

*Candidature :* Les dossiers de candidature doivent être envoyés par
courriel à M. HARISPE et M. SUTTON-CHARANI *avant le 28 février*. Ils se
composeront nécessairement d'un CV détaillé, d'une lettre de motivation,
et des notes obtenues lors des deux dernières années, et éventuellement
de lettres de recommandation. Une prise de contact avec l'encadrement
est souhaitée avant toute soumission de candidature."
"471","2018-01-24","INRIA","Sophia Antipolis","=== 6-month Internship available at INRIA Sophia Antipolis, France ===

--Title--

Text auto-illustration for improving reading accessibility to
low-vision people

--- Background and objectives ---

Low vision is a condition caused by eye disease which cannot be
corrected or improved with regular eyeglasses. Retinal-degeneration
disorders concern 285 million people in the world and it is predicted
that prevalence of visual disabilities will increase markedly during
the next 20 years. These disorders characterised by a progressive
retinal degeneration not only in photoreceptors but also in the
overall structure of the retina. So there is a real societal and
scientific challenge to provide new solutions to help low vision
people in their daily life activities. Among them, reading poses
problems for almost everyone with low vision and it is amongst the
strongest need reported by patients.

The BIOVISION team is currently working on a project to bring reading
experience to a higher level of immersivity by providing a highly
customizable visualization software running on phone-based virtual
reality platforms. In this context, in collaboration with the WIMMICS
team, we propose to explore text auto-illustration methods, consisting
in automatically extracting image from the web which are related to
the text, to make reading more efficient and enjoyable for low vision
patients.

During the internship, the successful candidate will be responsible for:

- investigating NLP methods to extract concepts and entities contained
  in some text and link them to online image contents.

- once images are collected, he/she will apply image processing
  methods to create meaningful visual content from a selection of
  ranked images representing the entities found.

--- Candidate profile ---

The successful candidate will have the following profile:
- Msc or MA Student in Computer Science, or Computational Linguistics.
- Experience in Natural Langage Processing, Artificial Intelligence
  and/or Machine Learning;
- Excellent programming skills;
- Strong interest in working in a multidisciplinary context made of
  computer scientists of different fields (NLP and image processing),
  and motivated my medical applications.

--- Terms of the internship position ---
Duration: 6 months
Starting date: asap

Location: INRIA, Sophia Antipolis, France.

Hosting teams: BIOVISION (https://team.inria.fr/biovision/) and
WIMMICS (http://wimmics.inria.fr/).

Internship grant: 1200¤ / month (net salary).

Applications : a curriculum vitae together with a motivation letter
should be sent to Pierre Kornprobst (pierre.kornprobst@inria.fr) and
Elena Cabrio (elena.cabrio@unice.fr)

Deadline for applications: position open until filled."
"472","2018-01-30","Altran","Puteaux","Stage R&D en ML && NLP niveau master2 chez Altran
Référence de l'offre : Stage_ALTRAN RESEARCH_GOTTRA++_2018
Date :  Mars 2018 - Ville : PUTEAUX - Entité : Altran Research


Contexte :
Depuis quelques années, le test et la recette applicative sont reconnus
comme une activité essentielle pour garantir le niveau de qualité d'un
système d'information livré, de ce fait il est devenu un domaine
d'expertise spécifique en termes d'outillage et de
méthodologie. Néanmoins, avec le développement des technologies IT et
des méthodologies de tests, il est devenu indispensable de faire recours
à l'automatisation des tests afin de réduire les temps des recettes et
leur coût. Par ailleurs, il est important de signaler que cette
automatisation n'est pas toujours possible ou évidente à mettre en oeuvre
comme elle dépend de plusieurs facteurs : nature et sensibilité des
applications testées, environnement de test utilisé, expérience requise
pour certain tests, complexité des tests, etc.
De ce fait, dans le présent stage, nous nous intéressons au
développement d'une application basée sur les algorithmes du traitement
du langage naturel et du machine learning afin de définir et d'extraire
des cas et scénarii de tests à partir des spécifications fonctionnelles
d'un projet TRA et/ou d'un enregistrement de l'activité des
utilisateurs, et de transformer ces cas de test en scripts d'exécution
pour réaliser des tests automatisé.

Mission :
Le candidat devra :
- Etude des techniques et outil d'automatisation des tests et choix d'un
  langage de script
- Etude des données projets TRA (Tierce Recette Applicative)
- Etude de diverses techniques du traitement du langage naturel pouvant
  être utilisées et caractérisation de l'orientation à suivre pour
  l'application.
- Identification des principaux factuers influant sur l'automatisation
  des tests
- Proposition d'une structuration de la base de données de l'outil
  prenant en compte les données projets et les facteurs identifiés
- Conception d'un moteur de recherche et d'extraction des cas et
  scénarii de test.
- Application des algorithmes de machine learning afin d'identifier les
  scénarii automatisables et pertinents
- Conception et développement d'une application d'automatisation des tests
- Tests et validation des développements  
- Formaliser les travaux effectués et tous les résultats obtenus dans un
  rapport de stage accompagné de l'ensemble des algorithmes et
  programmes développés.

Profil recherché:
- Formation ingénieur ou Master 2 en IA, Data Science, Machine Learning
- Programmation : javascript, HTML, JAVA J2EE, Python.
- Formalisation et conception : architecture MVC et SOA, modèles UML et
  MCD
- Framework : Spring MVC 
- Bonne Connaissance en méthodes de traitement du langage naturel. 
- Bonne Connaissance en statistiques et en machine learning
- Connaissance en BI (intégration des données + reporting)
- Autonomie, ouverture d'esprit
- Maitrise des outils informatiques

Durée : minimum 6 mois 
Date de début : Mars 2018
Lieu : Puteaux, siège d'Altran France / IT Paris 
Secteur d'Activité : Direction des Opération / IT Paris
Contact : ehab.hassan@altran.com 

A propos d'ALTRAN
Leader mondial du conseil en innovation et ingénierie avancée, Altran
accompagne les entreprises dans leurs processus de création et
développement de nouveaux produits et services. Les Innovation Makers[1]
du groupe interviennent depuis 30 ans auprès des plus grands acteurs des
secteurs aérospatial, automobile, énergie, ferroviaire, finance, santé,
télécommunications, etc. Les offres du groupe, déclinées depuis les
phases du plan stratégique en matière de technologies nouvelles
jusqu'aux phases d'industrialisation, assurent la capitalisation du
savoir au sein de 5 domaines principaux : intelligent systems,
innovative product development, lifecycle experience, ingénierie
mécanique, et systèmes d'information.
Le groupe Altran a réalisé en 2014 un chiffre d'affaires de 1 756 M¤. Il
compte désormais plus de 23 000 collaborateurs dans plus de 20 pays.
http://www.altran.com/fr 

A propos d'ALTRAN RESEARCH
Altran Research est le département de Recherche interne d'Altran en
France. Ses programmes de recherche adressent les domaines de l'e-santé,
des transports terrestres et de la mobilité, de l'aéronautique et du
spatial, de l'industrie et des services du futur, de l'énergie, des
systèmes complexes.

Les projets, développés dans une perspective de développement durable,
font intervenir des expertises variées en vue de développer :

- de nouvelles méthodologies, de nouveaux outils, de nouvelles offres de
  services permettant d'apprécier la vraie valeur durable des solutions
  en évaluant leur impacts sociaux, environnementaux et économiques
- de nouveaux produits, démonstrateurs ou systèmes complexes. Ces
  solutions sont modélisées et validées, à la fois sur le plan
  fonctionnel, technologique et systémique.


Ehab HASSAN 
Chef de Projet R&D, Département Recherche.  
Programme « Machine Driven Big Data »
Patios Défense 14 bis Terrasse Bellini
92807 Puteaux   
FRANCE
Tel. : +33 (0)1 46 17 46 17"
"473","2018-01-30","ERTIM & Reticular","Paris","*Extraction et prétraitement de données issues d'interviews politiques*
Stage proposé par l'entreprise Reticular et le laboratoire ERTIM
(Inalco)

*Contexte*

L'entreprise Reticular propose des services de veille à destination à
des décideurs publics, politiques, dirigeants d'entreprise, etc. Ces
services incluent une cartographie des acteurs (entités ou personnes),
la mise en évidence de liens organiques (filiale, autorité, concurrence,
partenariat, alliance) selon leur proximité d'opinion dans le débat
public.

Reticular et ERTIM sont partenaires du projet TALAD (2017-2021), qui se
focalise sur les interactions entre le traitement automatique des
langues (TAL) et l'analyse du discours (AD). L'objectif est de
déterminer comment le TAL peut outiller l'AD dans ses explorations et,
en retour, quel éventail de phénomènes complexes l'AD peut offrir comme
problématique nouvelle en TAL. En particulier, la nomination (différents
noms possibles pour désigner une entité) a été choisie comme objet
d'étude principal.

Pour ce projet, Reticular apporte des données issues d'une collecte
semi-automatique d'interviews « matinales ». Ces interviews constituent
un matériau original, étant spontanées et pouvant être par conséquent
porteuses de nominations particulièrement révélatrices sur les opinions
des personnalités interviewées (thématiques a priori : migrants vs
réfugiés / patriotisme économique vs protectionnisme). Depuis plus d'un
an, plus de 5000 interviews ont été transcrites et annotées.

*Objectifs principaux*

Le projet venant de démarrer, il s'agit en premier lieu de mettre en
place l'extraction des donnés et d'expérimenter les solutions adéquates
pour repérer les nominations, notamment en détectant les entités
coréférentes au sein du corpus.

1/ Écriture de scripts pour extraire les données des bases Reticular
   selon des mots-clés fournis par les linguistes
2/ Mise au format (XML) afin de les rendre exploitable par les équipe de
   recherche, notamment à des fins d'annotation, avec métadonnées
   (sources, date, interlocuteurs, etc.)
3/ Description des données (statistiques sur les données)
4/ Premiers travaux sur la détection de mentions d'entités coréférentes
   sur les thématiques choisies
5/ Extraction d'évènements dans les interviews liées aux entités
   détectées
6/ Interaction avec les équipes qui travaillent en TAL (entités nommées,
   coréférence) et en AD (annotation des nominations)

*Profil recherché*

- M2 en TAL
- Langages : python, langages web (HTML / JS)
- Bases de données : PostgresSQL, MongoDB, NoSQL, XML
- Compréhension des enjeux pour la linguistique et en particulier pour
  l'annotation des données
- La connaissance de NodeJS, AngularJS, Java est un plus

*Précisions sur l'offre*

- Durée du stage : 6 mois à temps plein
- Date de début : mai 2018
- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)
- Lieu : Inalco, 2 rue de Lille, 75007 Paris
- Possibilité de poursuivre en thèse sur le projet TALAD

Pour candidater, envoyez votre CV et de faire part de vos motivations à
Laurent Muller (lmuller@reticularproject.com), Didier Arbant
(darbant@reticularproject.com) et Damien Nouvel
(damien.nouvel@inalco.fr)."
"474","2018-01-30","CEFE & Praxiling","Montpellier","Stage Master 2 : automatisation d'analyse sémantique en vue de
synthétiser et faciliter les procédures de concertation dans le cadre
de projet d'aménagement du territoire

Durée : 5 mois

Localisation : Université Paul Valéry, Rte de Mende, 34000 Montpellier

Laboratoire CEFE

Le CEFE, créé en 1961, est le plus important laboratoire de recherche
en Ecologie en France. Le CEFE développe ses activités sur les grandes
préoccupations des sociétés : la biodiversité, les changements à
l'échelle planétaire et le développement durable. Une grande partie
des recherches porte sur les écosystèmes méditerranéens et tropicaux.
L'objectif du laboratoire est d'établir des scénarios d'évolution des
systèmes écologiques et des stratégies pour leur conservation, leur
restauration ou leur réhabilitation.

Le CEFE est organisé en quatre départements scientifiques entourés de
plates-formes techniques communes. Quatre thèmes transversaux
coordonnent l'apport scientifique du CEFE aux grands thèmes
internationaux de la recherche en Écologie :

1. Action de l'Homme, systèmes anthropisés et écologie de la conservation.
2. Adaptions des espèces aux modifications de leur environnement
3. Rôle de la biodiversité dans le fonctionnement des écosystèmes.
4. Changements globaux et fonctionnement des écosystèmes

Au sein du département `Action de l'Homme, systèmes anthropisés et
écologie de la conservation', une équipe de chercheurs en géographie
s'intéresse plus particulièrement au conséquence des projets
d'aménagement sur les écosystèmes. Aussi, elle questionne
l'acceptation des projets d'aménagement du territoire, notamment du
point de vue de leur impact environnementaux à travers la compensation
écologique qui entre en jeu lors de leur réalisation (autoroute, ferme
éolienne, etc.). Plus en amont, elle travaille depuis un an sur la
concertation au sein de quelques projets d'aménagement pour comprendre
comment le citoyen s'il est intégré dans la conception des projets
peut se porter garant d'une meilleure prise en compte de
l'environnement.

La justification du stage

D'un point de vue de la participation, les autorisations données pour
la réalisation de gros projets d'aménagement du territoire sont
conditionnées par la longue appréciation de l'enquête publique, étape
finale d'un processus de concertation amont plus ou moins long. Lors
de cette concertation amont, de nombreuses interventions d'acteurs ont
lieux et il est souvent difficile de faire état de ce qui se passe
pour organiser la concertation sous forme de débat, pour : - présenter
les changements de position, - expliciter les productions de savoirs
collectifs. Dans ce cadre, le passage aux outils numériques permet une
structuration de la concertation de manière dématérialisée : (i) un
enregistrement des paroles d'acteurs et (ii) l'identification des
sujets de discussion, des positionnements par acteurs. Cependant, la
mise en ligne de tous les contenus (oraux ou écris) pose problème et
il reste encore à traiter les contenus pour synthétiser et faciliter
les différentes étapes de la concertation, en toute équité et
transparence.

Le sujet du stage


En collaboration avec le laboratoire PRAXILING de l'Université Paul
Valéry, vous devrez réaliser un benchmark des outils d'analyse
sémantique dématérialisé. Puis vous devrez travailler avec des
chercheurs, des designers et des industriels/aménageurs pour aider à
choisir le/les meilleurs outils. Il s'agit de les adapter au contexte
de l'analyse de contenus relatifs à la concertation dans le cadre de
projet d'aménagement : (1) identification de thématiques communes, (2)
de fréquences des besoins, (3) argument d'oppositions et de soutiens,
(4) association d'idées et (5) explicitation des modes de discours sur
les enjeux.  Enfin, vous réaliserez une conception de l'application en
routine de l'outil afin de pouvoir le transférer à un développeur de
plateforme numérique en ligne, partenaire du projet.

Les attendus du stage

- Une procédure de traitement automatique sous forme de concept
transférable à un développeur web

- Un article scientifique sur le sujet « analyse de contenus non
argumentatifs et argumentatifs dans le cadre de projet d'aménagement
du territoire, proposition de synthétisation/facilitation de
concertation par traitement sémantique automatique »

Vos candidatures sous forme de CV et lettre de motivation doivent être
adressée à Mr Pierre Yves Hardy (pierre-yves.hardy@univ-montp3.fr) et
Sylvain Pioch (sylvain.pioch@univ- montp3.fr) avant le 20 février
2018."
"475","2018-02-07","LIG","Grenoble","* Titre : Outillage de l'accès aux textes par lecture active

  étymologique multilingue *



 Responsables à contacter  

Envoyez votre CV par Mel à :

Valérie Bellynck (Valerie.Bellynck@imag.fr)

Mathieu Mangeot (Mathieu.Mangeot@imag.fr)



* Mots clés - Keywords *

Ressources linguistiques, Ressources lexicales, TAL, service Web,

intercompréhension en langues romanes, intercompréhension en langues

sinogrammiques



* Profil - Compétences *

Étudiant en M2R informatique intéressé par les langues ou plus

généralement les humanités numériques ou linguiste ayant de bonnes

connaissances en programmation Web.

HTML/XML, javascript, PHP, services Web, analyse lexicale, bases

lexicales, API REST.



* Précisions sur l'offre *

- Durée du stage : 5 à 6 mois à temps plein

- Date de début : 2018

- Rémunération : tarif en vigueur (~550¤/mois)



- Lieu : Laboratoire LIG, Bâtiment IMAG, 700 avenue centrale 38400

  Saitn Martin d'Hères



 Description 



L'apprentissage des langues peut être grandement facilité par les outils

informatiques au sens large. La lecture active est un de ceux-ci. Elle

permet d'afficher des compléments d'information (transcriptions

phonétiques, traductions de mots, etc) pendant la lecture d'un texte.

En quelque sorte, elle réalise l'équivalent électronique du dictionnaire

main-gauche.

L'outil affiche au dessus d'un texte entré par l'utilisateur une

transcription des mots dans une autre langue mieux connue de celui-ci et

rend disponible la traduction de chaque mot au survol de la souris. La

traduction n'est pas affichée de manière permanente pour inciter le

lecteur à comprendre le texte.

L'utilisateur peut contribuer directement, améliorer, ou même juste

s'approprier des formes lexicales, au plus près de sa lecture. Voir

http://jibiki.fr/lecture .



Les traitements nécessaires à la réalisation de cet outil sont

principalement l'utilisation d'outils de traitement automatique des

langues dont des analyseurs morphologiques ainsi que la consultation

d'une base lexicale.



Nous voulons étendre ce concept pour aider à retenir la forme des mots

et faciliter l'intercompréhension dans des langues voisines. Il s'agit

alors d'afficher des constituants des mots, soit pour leur origine

étymologique, soit pour leur ressemblance.



 Problèmes durs 



- généricité

  L'application finale doit être conçue de manière totalement générique

  du point de vue des langues traitées mais également des ressources

  lexicales et des outils de TAL utilisés.



- extraction d'information

  L'information utile se trouve dans certains dictionnaires. Cependant,

  bien souvent, les entrées ne sont pas suffisamment structurées pour

  trouver simplement ces informations. Il faut donc les analyser pour

  trouver l'information voulue puis les modéliser pour les intégrer à la

  base lexicale.



- comparaison de chaînes de caractères

  Il faut également être capable de modéliser les permutations

  phonologiques à l'aide d'outils tels que des transducteurs à états

  finis puis calculer des distances de chaîne entre les mots des

  différentes langues en jeu (voir dans l'exemple ci-dessous densha <=>

  diànche).



- conception d'interfaces utilisateurs

  L'affichage final des résultats demande de concevoir les modalités

  d'affichage et d'interaction permettant de rendre sensible les

  différentes sources de ressemblance (racine linguistique, langue, mode

  d'écriture, ...).



L'exemple suivant est tiré d'un scénario où le lecteur apprend le

japonais et possède des connaissances en mandarin. D'autres scénarios

sont possibles avec des ensemble de langues voisines (groupes de langues

ou langues régionales comme les langues romanes, le français et le

breton, etc.). Cette partie du sujet peut s'adapter aux affinités du

stagiaire.



 Références 



Goudin, Y. Mangeot, M., Loiseau, M. Bellynck, Mboning, E. & Eggers,

E. (2017). `La prise en charge du lexique pour l'apprentissage sur

plateforme en ligne : scénarios d'utilisation et prises en compte des

spécificités du mandarin' avec , in Journées de l'AREC 2017 « Le lexique

chinois contemporain », Université Diderot, 2-3 juin.



Mangeot, M., Bellynck, V., Eggers, E., Loiseau, M., & Goudin,

Y. (2016). Exploitation d'une base lexicale dans le cadre de la

conception de l'ENPA Innovalangues. In I. Smilauer & J. Kostov (Éd.),

Actes de la conférence conjointe JEP-TALN-RECITAL 2016 (Vol. 9 : ELTAL,

p. 48-64). Paris: ATALA/AFCP. Consulté à l'adresse

https://jep-taln2016.limsi.fr/actes/Actes%20JTR-2016/V09-ELTAL.pdf



Mangeot, M., (2016). Collaborative construction of a good quality, board

coverage and copyright free Japanese-French dictionary. In International

Journal of Lexicography 2016; doi: 10.1093/ijl/ecw035; 35 p.



Degache, C. (1997) : « Développer l'intercompréhension dans l'espace

linguistique roman: le programmeGalatea/Socrates », Document ronéoté,

Assises de l'enseignement du et en français, séminaire de Lyon,

Aupelf-Uref, 23-25 septembre 1997.



Mathieu MANGEOT

GETALP-LIG Bureau 338

Bâtiment IMAG, 700 avenue Centrale

F-38400 St Martin d'Hères France

Tel : +33 4 57 42 15 26 / +33 4 79 75 81 89"
"476","2018-02-19","LNE","Trappes","- Stage informatique Master ou école d'ingénieur



- Sujet : développement d'un outil d'annotation - contexte : données

  multimédia générées dans le cadre d'une compétition en robotique

  agricole



- Requis : forte autonomie en développement informatique, connaissances

  en création d'interfaces graphiques, capacité à utiliser des

  librairies de manipulation de fichiers multimédia



- 6 mois à partir de mars 2018



- Lieu : Laboratoire national de métrologie et d'essais, Trappes (78) -

  Transilien lignes L et N



- Rémunération : 1054¤ bruts



Merci d'envoyer votre candidature (lettre de motivation et CV) en

rappelant en objet du mail la référence STA/ROSE/DE, à

recrut@lne.fr."
"477","2018-02-19","MoDyCo / LIMSI","Nanterre ou Saclay","Offre de stage Master 1 ou 2 de Linguistique/TAL



TITRE : Aide au développement d'un outil langagier bilingue LSF-Français

centré sur l'acquisition de la temporalité



--------------



Stage financé par la DGLFLF, Projet « Temporalité linguistique en LSF et

français écrit »



--------------



Le présent projet a pour objet d'étude l'acquisition d'un certain nombre

de notions linguistiques liées à l'expression de la temporalité chez

l'enfant sourd. On note en effet que desproblèmes sont rencontrés par

ces enfants pour maîtriser l'expression de la temporalité, en Langue des

Signes Française (LSF) comme en français écrit. L'objectif du projet est

de développer un premier prototype d'aide à l'acquisition (par des

exercices d'entraînement) des notions et structurations que nécessite

l'expression de la temporalité dans toutes les langues utilisées par les

enfants sourds. Cet outil s'adossera aux travaux menés en

psycholinguistique de la LSF et en TAL. Il sera centré sur les unités

adverbiales temporelles.



Les outils d'évaluation de la LSF sont absents des terrains éducatifs et

orthophoniques (Bogliotti C., Puissant-Schontz, L. et Heouaine, S.,

(2013) ; Cristini, M & Bogliotti C., 2015). En effet, les recherches

linguistiques sur la LSF sont relativement récentes et les rares

descriptions linguistiques et psycholinguistiques ne permettaient pas

d'envisager de développer de tels outils. C'est donc à partir de ces

modélisations proposées par Battistelli (2008) et Filhol (2012) que nous

allons élaborer cet outil visant à développer les compétences en

temporalité linguistique, et ce, pour les deux langues utilisées par les

enfants sourds. Cet outil d'entraînement serait proposé sous la forme

d'une application à télécharger. Il seraconstitué de plusieurs modules :

un module « temporalité en LSF », un module « temporalité en français

écrit » et un module « français écrit vers LSF » et « LSF vers français

écrit ».



Mots-clés : LSF, Français écrit, Traitement automatique des langues

(TAL), temporalité linguistique



--------------

Description du poste

---------------



Le stage prendra part au développement du 3ème module, celui visant à

assurer la traduction LSF-français écrit (et inversement). Il sera

centré sur les marques temporelles du type des adverbiaux temporels et

se déroulera en deux phases :



1) Une phase de modélisation linguistique et formelle à partir du sous

ensemble seulement d'expressions d'expressions temporelles adverbiales

considéré dans (Filhol 2012, 2014). Il s'agira d'établir les règles de

passage avec le formalisme de (Battistelli et al. 2008) (Teissèdre

2012).



2) Lister les manques à combler côté description formelle de la LSF et

compléter le passage LSF-français écrit en étendant le sous ensemble

considéré à d'autres expressions temporelles adverbiales et en incluant

également certains connecteurs.



En fonction des avancées au LIMSI de projets parallèles permettant la

synthèse (génération) de ces expressions, on pourra tester les

expressions produites avec des avatars comme support d'animation.



---------------

Profil souhaité

---------------



- Formation en cours : Master 1 ou2 en Linguistique ou linguistique

  informatique.



- Curiosité et capacité d'explorer de nouveaux domaines en linguistique.



- Des connaissances en TAL seront un plus, mais ne sont aucunement

  prérequises. Un soutien sera assuré par les encadrants an cas

  d'absence de connaissances en TAL. Du reste, le sujet sera adapté en

  fonction du niveau et des types de compétences en TAL du (de la)

  candidat(e).



- La maîtrise de la LSF est vivement souhaitée mais ne sera pas source

  de sélection (un cours intensif de LSF aura lieu pendant le stage)



-----------------

Conditions

-----------------



Contrat : stage conventionné 4 à 6 mois rémunéré



Début : février 2018



Lieu : laboratoire MoDyCo ou laboratoire LIMSI



Encadrants : Delphine Battistelli (MoDyCo), Caroline Bogliotti (MoDyCo),

Michael Filhol (LIMSI)



Merci d'envoyer votre candidature aux trois adresses suivantes :



delphine.battistelli@parisnanterre.fr 



caroline.bogliotti@parisnanterre.fr



michael.filhol@limsi.fr



Documents souhaités : CV, lettre de motivation, relevés de notes M1 et

M2.



-----------------

Bibliographie

-----------------



Battistelli D., Couto, J., Minel, J.L., Schwer S. (2008) Representing

and visualizing calendar expressions in texts, in Actes STEP'08

(Symposium on Semantics in Systems for Text Processing), 22-24 septembre

2008, Venise.



Bogliotti C., Puissant-Schontz, L. & Heouaine S. (2013) Assessing

morphosyntactic skills in French Sign Language , TISLR11 Theoretical

Issues in Sign Language Research, 10-13 juillet 2013



Cristini M. & Bogliotti, C. (2015) The phonology of French Sign Language

(LSF) : non-sign repetition and discrimination tests, ICSLA15,

Amsterdam, 1-3 juillet 2015



Filhol, M., Hadjadj, M.N., Choisier A. (2014), Non-manual features: the

right to indifference, Representation and Processing of Sign Languages:

Beyond the manual channel, Language resource and evaluation conference

(LREC), Iceland.



Teissèdre,C(2012)Analyse sémantique automatique des adverbiaux de

localisation temporelle : application à la recherche d'information et à

l'acquisition des connaissances, thèse de doctorat, Université

Paris-Ouest Nanterre La Défense."
"478","2018-02-19","Advanced Decision","Paris","Proposition de stage M1-M2 en fouille d'opinion



La société Advanced Decision est engagée dans la réalisation d'un

service de recommandation de produits touristiques « sur mesure ». La

recommandation visée sera fondée sur une appréhension fine des désirs et

des expériences associés à un produit touristique. Pour atteindre cette

finesse, seront notamment exploités des avis d'utilisateurs postés sur

des sites dédiés sous la forme de textes. L'analyse de ces textes doit

faire apparaître les opinions associées à certains aspects du produit

touristique évoqué (par exemple, pour un restaurant : la cuisine était

bonne mais le service laissait à désirer). Un premier prototype

développé par apprentissage automatique à partir de textes annotés

permet d'ors et déjà de repérer les aspects pertinents du produit

(cuisine, service...) et de qualifier leur polarité (plus ou moins

positive ou négative). L'objet du stage est d'améliorer cette dernière

fonctionnalité en tenant compte notamment de la structure syntaxique des

textes analysés.



compétences requises :



- niveau M1 ou M2 en informatique ou en Traitement Automatique des

Langues (TAL)



- maîtrise d'au moins un langage de programmation (de préférence Python,

C++, Java)



- connaissances en TAL (analyse syntaxique), en apprentissage

automatique (CRF, réseaux neuronaux), en fouille de textes et fouille

d'opinion



conditions :



Le stage peut durer de 4 à 6 mois et démarrer dès que possible. Il sera

rémunéré au tarif en vigueur. Possibilité de continuation en thèse avec

un contrat Cifre.



Les locaux de la société sont situés à Paris.



envoyer CV et lettre de motivation à stage@advanceddecision.fr et à

isabelle.tellier@sorbonne-nouvelle.fr"
"479","2018-02-19","Fortia","Paris","Dans le cadre d'un projet de deep learning lié au NLP/TAL au sein de

notre pôle R&D, nous recherchons 2 stagiaires suffisamment à l'aise,

l""un en anglais, l'autre en allemand, pour enrichir nos bases de données

nécessaires à nos travaux.



*Voici le descriptif du poste. *



Dans le cadre d'un travail de recherche informatique, nous recherchons 2

stagiaires : l""un en analyse de documents en Allemand, l'autre en

anglais. Votre mission sera de lire, analyser, recenser et

catégoriser/tagger les éléments textuels les plus appropriés afin de

constituer et enrichir, in fine, notre base de données informatiques.



Vous aiderez ainsi notre équipe d'experts scientifiques (data

scientists) dans leurs travaux de recherche liée à l'intelligence

artificielle et notamment au TAL/NLP (natural language processing).



Vous serez au coeur d'un sujet d'une très grande innovation.



Fortia, est une prometteuse start up de 45 salariés, en pleine

croissance, qui compte déjà parmi ses clients des grands comptes tels la

BNP Paribas Securities Services ou Swiss life.

D'après un récent classement, nous figurons au top 100 des Regtechs à

suivre en 2018.



Rejoindre Fortia Financial Solutions c'est rejoindre une équipe jeune,

ambitieuse et dynamique, bénéficiant d'une ambiance start-up et offrant

ses solutions aux grands noms du milieu financier en France comme à

l'international.





Profil



Etudiant (bac + 3 à 5) en langue étrangère appliquée allemande ou

anglais (LEA, LCCE ou équivalent) ou linguistique. Vous vous

caractérisez comme quelqu'un de très à l'aise en allemand ou en anglais.



Vous êtes rigoureux(se), méthodique et appliqué(e).





Il s'agit d'un stage entre 4 à 6 mois, rémunéré 600 euros + tickets

restaurants



Le stage se déroule au 17 avenue George V, 75008 Paris.



Si vous êtes intéressé(e), merci d'envoyer vos candidatures à

sarah.guighui@fortia.fr"
"480","2018-02-19","ERTIM","Paris","Extraction de concepts par AFC dans des corpus

Stage recherche proposé par le laboratoire ERTIM (Inalco)



Contexte



L'analyse formelle de concepts (AFC) (Wille, 1982) est une méthode

d'extraction de connaissances à partir de données, qui s'appuie sur le

lien entre les objets et leurs attributs. Celle-ci extrait des

""concepts"", liés les uns aux autres par une relation d'ordre

partiel. Cette méthode a l'avantage de proposer un compromis entre

l'énumération exhaustive de nombreuses combinaisons d'attributs

possibles et une sélection trop naïve de ces attributs, isolément et/ou

par régression.



Plusieurs travaux ont déjà abordé ce sujet, dont (Ilieva, Ormandjieva,

2007), (Falk, Gardent, 2010), (Kaytoue, Kuznetsov, Napoli, 2011).



Le stage proposé vise à explorer les utilisations possibles de l'AFC

pour l'exploration de données textuelles dans les corpus. Il comportera

l'implémentation ou l'utilisation de logiciel pour conduire l'AFC, son

exécution sur des corpus, la comparaison qualitative et quantitative

avec des algorithmes traditionnels en extraction d'information (TF.IDF)

et des algorithmes plus récents de construction d'espaces par méthodes

distributionnelles (embeddgins Word2Vec / FastText).



Objectifs principaux



- État de l'art sur l'adaptation de la FCA aux données textuelles

- Formalisation d'une méthode adéquate pour la recherche d'informations

- Implémentation de l'algorithme pour extraire les concepts

- Expérimentations sur des jeux de données

- Évaluation de la couverture, de la complétude, de la précision des

concepts

- Comparaison avec des méthodes traditionnelles ou plus récentes

- Utilisation de l'algorithme pour l'exploration de corpus



Profil recherché



- M2 informatique et TAL

- Programmation en python

- Bonne compréhension des méthodes de fouille de données

- Motivation et intérêt pour les problématiques de recherche



*Précisions sur l'offre*



- Durée du stage : 5 mois à temps plein

- Date de début : mai 2018

- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)

- Lieu : Inalco, 2 rue de Lille, 75007 Paris



Pour candidater, envoyez votre CV et faites part de vos motivations à

Damien Nouvel (damien.nouvel@inalco.fr).





Références 

- Ingrid Falk, Claire Gardent (2010). Bootstrapping a Classification of

French Verbs Using Formal Concept Analysis.. Interdisciplinary

Workshop on Verbs.

- Magda G. Ilieva, Olga Ormandjieva. (2007). Natural Language Processing

and Formal Concept Analysis Technologies for Automatic Building of

Domain Model.

- Mehdi Kaytoue, Sergei O. Kuznetsov, Amedeo Napoli (2011), Sébastien

Duplessis. Mining gene expression data with pattern structures in

formal concept analysis. Information Sciences, 181-10.

- Wille, R. (1982) Restructuring lattice theory: an approach based on

hierarchies of concepts."
"481","2018-03-11","Bertin IT","Montigny le Bretonneux","Société du Groupe CNIM, Bertin IT est éditeur et intégrateur de
solutions logicielles pour la Cybersécurité, l'intelligence numérique et
le traitement automatique de la parole.

Engagée dans la recherche et l'innovation dans les Technologies de
l'Information, Bertin IT s'appuie sur une expertise technique reconnue
et un savoir-faire industriel développé au travers de projets civils et
de défense de dimension européenne ou mondiale.

Bertin IT est également pionnière de l'Intelligence Artificielle et du 
machine learning, développe des technologies de transcription de la parole 
à l'état d'art.

Dans le cadre du développement de notre système de reconnaissance vocale
en langue Japonaise, nous recherchons un(e) Stagiaire Ingénieur
Linguiste en Japonais (h/f).

Votre Mission : 

Rattaché (e) au chef de projet, votre mission consistera à :

- Travailler sur la normalisation du texte (segmentation en phrases et
  en mots, adaptation des outils existants pour la conversion des
  chiffres en lettres, traitement des mots étrangers...)

- Construire un lexique : à partir du texte normalisé, définition du
  lexique pour l'ensemble du système de transcription japonais.

- Construire un dictionnaire phonétique pour l'ensemble des mots du
  lexique (évaluation et adaptation des phonétiseurs automatiques
  existants.

Profil recherché
Vous êtes en bac+4/5 dans le domaine du Traitement Automatique de la
Langue. Vous maîtrisez le japonais.
Stage basé à Montigny le Bretonneux (78).

Si cette offre vous intéresse, merci de transmettre votre cv+ lettre de
motivation à : elisabeth.rayemamby@bertin.fr"
"482","2018-03-19","Calea Solutions","Marseille","STAGE DATA SCIENTIST H/F 

QUI SOMMES-NOUS ? 

CALEA SOLUTIONS est une Startup fondée en 2014 par une équipe issue du
monde du jeu vidéo. Elle est basée à Marseille et compte actuellement 20
collaborateurs.
Nous avons créé l'application Android, MOOD MESSENGER
(https://play.google.com/store/apps/details?id=com.calea.echo [1]), une
messagerie combinant l'universalité du SMS avec des contenus innovants
comme le SmartEmoji ou des services enrichis intégrés à la conversation
(restaurant, cinéma, Uber...). 1.2 Millions d'utilisateurs utilisent
chaque jour notre application dans 215 pays du monde. Elle fait partie
des applications les mieux notées du Google Play Store avec 4.5 étoiles.

Forts d'une équipe en Data Science, nous utilisons le Machine Learning,
dont le Deep Learning, dans plusieurs domaines dont la prédiction et la
proposition d'émojis (objet d'une thèse de doctorat en cours),
l'amélioration de la connaissance de notre base utilisateur pour
identifier les fonctionnalités préférées ou l'anticipation du churn.

MISSIONS : 

Votre mission consistera à étudier, developper, tester et industrialiser
des algorithmes de Machine Learning pour favoriser la rétention et
l'usage de l'application.
Par exemple, il s'agira de : 

* trouver des patterns dans les comportements de nos utilisateurs
  annonçant un churn imminent via un apprentissage supervisé
* Proposer une segmentation de notre base utilisateur pour personnaliser
  nos interactions (pushes, fonctionnalités mises en avant) via de
  l'apprentissage non supervisé

TECHNOS 

* Machine Learning (Apprentissage Supervisé, non Supervisé, voire par
  renforcement)
* Deep Learning (Data dans le Cloud Google : Tensorflow, Google Cloud
  ML)
* Statistiques, Data Mining, Data Engineering
* données structurées et non structurées
* Langages et librairies : python ou Java, pandas, sk-learn, TensorFlow,
  SQL, BIGQUERY

VOUS : 

* un Etudiant préparant un diplôme de niveau BAC+5, Ecole d'ingénieurs
  ou Master Universitaire.
* Spécialité / Option souhaitée: Big Data  Data Mining  Machine
  Learning
* Soft Skills : Autonomie, sens de l'analyse, esprit de synthèse et de
  vulgarisation pour communiquer envers des Data-Scientist mais aussi
  vers le Management non spécialiste

CONTEXTE:  

* période : 6 mois à partir de juillet 2018 
* lieu : Marseille
* Stage rémunéré avec possibilité d'embauche à la fin

CONTACT: 

Florian FIRMIN / Data Scientist 
florian@calea.io / +33 6 60 35 75 68 [2] 

1 place Francis Chirat [3] 
13002 Marseille - France [3] 
www.calea.io [4] 

Links:
------
[1] https://play.google.com/store/apps/details?id=com.calea.echo
[2] tel:+33%206%2060%2035%2075%2068
[3] https://maps.google.com/?q=1+place+Francis+Chirat+13002+Marseille+-+%F0%9F%87%AB%F0%9F%87%B7+France&amp;entry=gmail&amp;source=g
[4] http://www.calea.io/
[5] https://htmlsig.com/t/000001CS6YVT
[6] https://htmlsig.com/t/000001CPCEY4
[7] https://htmlsig.com/t/000001CM8HDP
[8] https://htmlsig.com/t/000001CK7NPZ
[9] https://htmlsig.com/t/000001CQEHZQ"
"483","2018-03-25","European Commission's Joint Research Centre","Ispra (Italie)","EUROPEAN COMMISSION DIRECTORATE-GENERAL HUMAN RESOURCES AND SECURITY
Directorate HR.AMC -Account management Centre

HR.DDG. AMC 8 2018-IPR-I-000-9856

Position for:
Trainee

Entity and Sentential-level Sentiment Analysis
in the News


As the science and knowledge service of the
Commission, the mission of Joint Research Centre
is to support EU policies with independent
evidence throughout the whole policy cycle.
The JRC is located in 5 Member States (Belgium,
Germany, Italy, the Netherlands and Spain).


Further information is available at: http://www.jrc.ec.europa.eu


The Joint Research Centre (JRC; http://ec.europa.eu/dgs/jrc/) is the
scientific- technical arm of the European Commission. The
approximately 2200 JRC employees working in Ispra are from all EU
countries and there are also some non-EU visitors.

The working environment is multilingual, multi- cultural and
multi-disciplinary. The JRC's Europe Media Monitor (EMM) team carries
out research and development in the field of highly multilingual text
mining (Language Technology; Computational Linguistics) for the
purposes of media monitoring.  EMM gathers an average of 300,000
online news articles per day in over 70 languages and analyses them to
help its large international user community understand and use this
enormous amount of media information. The Europe Media Monitor EMM is
publicly accessible and widely used. The EMM team has produced over
200 international peer-reviewed publications. The team has also
produced and distributes a number of highly multilingual Language
Technology resources.

Short description of activity:

The Text and Data Mining Unit (I3) of the European Commission's Joint
Research Centre (JRC) in Ispra, Italy, is looking for a trainee to
support the JRC's Europe Media Monitor (EMM) team in its effort to
improve its multilingual sentiment analysis tools, especially at
sentence and entity level. EMM gathers and analyses reports from
traditional and social media in dozens of languages by clustering
related news items; categorising them; extracting information such as
entities (persons, organisations, locations), events2 (who did what to
whom, where and when), quotations by and about people; identifying
sentiment; as well as linking related news clusters over time and
across languages.  Methods used are mostly hybrid: machine learning
tools are used to gather evidence, learn vocabulary and rules, but the
results are usually controlled and optimised through human
intervention.

EMM is used by European Institutions, by national authorities in EU
Member States, by international organisations and by the public. The
public EMM applications NewsBrief, NewsExplorer and MedISys can be
accessed freely by the general public. EMM is part of the JRC's
Competence Centre on Text Mining and Analysis.  As of now, the EMM
team has implemented several approaches to multilingual sentiment
analysis, for different text types (newspaper articles, microblogs,
social media posts) and application scenarios (document level, short
texts, entity-centric).

The successful trainee will help to combine the current approaches and
resources and extend them when necessary to perform multilingual
entity and sentence-level sentiment analysis and evaluate the system
thus obtained. The trainee is also expected to contribute to writing a
scientific publication on the work carried out.

Qualifications:

Essential:

- University degree (or an almost completed degree) in computational
linguistics, computer science or related areas (the degree thesis has
to be registered and the subject has to match with the project) ;

- Java programming skills;

- Good working knowledge of English. (B2 level)

Advantage:

- Experience in methods and resources for sentiment analysis and
emotion detection;

- Knowledge of further foreign languages;

- Good knowledge of Language Technology- related tools and methods;

- Proven ability to work independently and as part of a team.


In your application, please provide clear information on your skill
set, by elaborating on the above-mentioned list of requirements and by
listing your level of languages and your computer / programming
skills.

For general eligibility requirements, please read the rules governing
the traineeship scheme of the JRC:

https://ec.europa.eu/jrc/en/working-with-us/jobs/temporary-positions/jrc-trainees

Unit /Directorate: I03 - Text and Data Mining Unit

Indicative duration: 5 months

Preferred starting date: As soon as possible

Directorate Competences

JRC Site: Ispra
Country: Italy

JRC contact details

For any technical problems with your application, please contact:

HR-AMC8-RECRUITMENT-TOOLS-SUPPORT@ec.europa.eu

Apply online (Code: 2018-IPR-I-000-9856 - ISPRA)

http://recruitment.jrc.ec.europa.eu/?type=TR&site=IPR"
"485","2018-03-25","ELDA","Paris","Nous recherchons un-e stagiaire dans le cadre d'un projet ayant pour but
l'actualisation d'un inventaire de ressources linguistiques pour les
langues régionales françaises, ainsi que la négociation des droits pour
permettre leur partage avec la communauté des technologies de la langue.

Les tâches consisteront principalement en:

- La mise à jour de l'inventaire de ressources linguistiques existant
- L'étude technique et juridique des conditions de partage actuelles de
  ces ressources (analyse des formats d'exploitation des ressources et
  identification des droits d'utilisation en coopération avec un expert
  juridique en interne)
- La négociation avec les fournisseurs, la définition des conditions de
  réutilisation des ressources linguistiques, l'établissement de
  contrats de distribution,
- La description et l'intégration des ressources disponibles dans le
  catalogue ELRA
- La rédaction d'un rapport final

Profil:

- Niveau master 2 traitement automatiques des langues ou domaines
  assimilés
- Durée : 6 mois
- Aptitude à travailler tant de façon indépendante qu'au sein d'une
  équipe
- Forte aptitude rédactionnelle et analytique
- Convention de stage requise

Toute candidature sera étudiée jusqu'à ce que le poste soit pourvu. Le
poste est basé à Paris.

Salaire : en fonction des qualifications et expériences.

Les candidatures doivent être adressées par courriel (lettre de
motivation et curriculum vitae) à:
ELDA
9, rue des Cordelières
75013 Paris
FRANCE
Email : job@elda.org

ELDA, unité opérationnelle de l'association ELRA, est chargée de
promouvoir le développement de ressources linguistiques sous toutes les
formes électroniques utilisables, en particulier sous la forme de corpus
oraux et écrits, de lexiques et de bases terminologiques. Depuis sa
création en 1995, ELDA s'est affirmée comme un centre unique en Europe
pour la distribution de ressources linguistiques, capable de répondre
aux divers besoins des développeurs de technologie. Ses activités se
développent maintenant vers de nouveaux types de ressources
linguistiques (données de type multimodal/multimédia). Certaines
ressources linguistiques sont conçues au cours de projets (co-)financés
par ELDA. Celles-ci sont ensuite compilées sous la forme d'un catalogue
de ressources linguistiques. ELDA est impliquée dans un certain nombre
de projets européens et nationaux. ELDA s'intéresse également aux
problèmes juridiques en rapport avec les ressources linguistiques,
réalise régulièrement des études de marché sur les besoins des
utilisateurs, et travaille à l'amélioration des procédures de validation
des ressources.

Pour de plus amples renseignements concernant ELRA/ELDA, voir :
http://www.elra.info ou www.elda.org"
"486","2018-04-21","INRA","Montpellier","Intitulé
Analyses bibliométrique et terminologique autour des matériaux et
emballages biosourcés

Contexte

La littérature et les travaux de recherche récents menés dans le domaine
des matériaux et emballages bio-sourcés révèlent un foisonnement
d'acteurs venant de champs disciplinaires multiples. Il est encore
difficile de partager un vocabulaire commun dû à des représentations
ontologiques divergentes et à la polysémie existante, à commencer par
les différents sens que prend le préfixe « bio » selon que l'on se place
du point de vue de la ressource (bio-ressources, biomasse), du procédé
(biotechnologies, bio-ingénierie, bioprocédés, bio-raffineries), du
produit (bioplastique, biomatériau, biomolécule) ou des fonctionnalités
post-usage (biodégradable, bio-compostable, bio-déchets) ou encore de
l'ensemble de la chaine (bio-économie, bio-industries, bio-marchés).

Nous souhaitons collecter et compiler les connaissances actuelles
concernant les définitions, les normes et les acteurs qui s'intéressent
aux matériaux bio-sourcés dans le but d'améliorer notre communication
scientifique et technique, grand public, nos dispositifs de veille mais
aussi d'aide à la décision.



Description des missions

La/le stagiaire aura pour principale mission de réaliser une analyse
bibliométrique et terminologique autour des matériaux et emballages
bio-sourcés. Le projet démarrera à partir d'entretiens et de collectes
d'information et de documents scientifiques (rapports, articles etc.)
produits au sein de l'Inra et notamment des départements à forte
activité dans les produits bio-sourcés. Ces primo-données (Web et autres
sources) feront l'objet d'une analyse lexicale et sémantique basée
notamment sur une extraction terminologique et bibliométrique en
utilisant les outils exploités et le savoir-faire développé au sein de
l'IST/Inra. Le vocabulaire identifié viendra compléter des listes déjà
établies par des scientifiques et le tout sera organisé sous la forme
d'un lexique ou d'un thésaurus proposant des définitions. Une fois
publié selon les standards du Web sémantique notamment, cette ressource
pourra servir de référence dans le domaine.

A cette fin, la/le stagiaire assurera la mobilisation d'un corpus coeur
d'une 40aine de chercheur localisés sur une 10aine de villes françaises,
afin de réaliser une analyse terminologique (Français/ Anglais)  issue
de la consultation. Ceci constituera un préambule à des requêtes sur le
WOS afin de compléter le corpus qui fera l'objet d'une analyse
bibliométrique. Elle/il mettra en place la solution logicielle
permettant aux scientifiques du département CEPIA d'accéder et de
consulter le corpus documentaire et les résultats de l'analyse
bibliométrique. Pour toutes ces tâches, les moyens techniques et
l'accompagnement nécessaires seront mis à disposition par la DIST/Inra
dans le cadre de son offre de services aux chercheurs.

Enfin, le stagiaire pourra étudier les apports potentiels du vocabulaire
dans le cadre d'une veille scientifique et/ou réglementaire.

Livrables

- Une analyse bibliométrique et une base documentaire sur les produits
  biosourcés (matériaux et emballages biosourcés)

- Un vocabulaire (thésaurus ou lexique) des produits biosourcés qui
  pourra être publié

Profil requis

- Étudiant en master 1 ou master 2 ou élève-ingénieur en 4ème ou 5ème
  année dans les domaines Documentaires/bibliométriques, Linguistique,
  Traitement Automatique des Langues, Analyse documentaire, ingénierie
  des connaissances et sciences. Des connaissances sur les matériaux
  issus de la biomasse seront appréciées.

- Capacités à travailler en autonomie et à solliciter les personnes
  ressources nécessaires à la réalisation du projet. Motivé,
  travailleur, rigoureux et ouvert d'esprit

- Anglais lu et parlé

Conditions du stage
Durée

6 mois

Lieu
Gratification

UMR IATE, Montpellier
Environ 550 ¤ net/mois


Modalités de candidature
Les candidats doivent transmettre un CV avant le 30 juin 2018, les dates
de démarrage et de fin seront adaptées 2018 à la situation du
candidat.e.

  * Nathalie GONTARD, INRA UMR IATE, Montpellier
    nathalie.gontard@inra.fr
  * Patrice BUCHE, INRA UMR IATE, Montpellier patrice.buche@inra.fr
  * Sophie AUBIN,  DIST, Versailles  sophie.aubin@inra.fr
  * Johnny BEAUGRAND, INRA Unité de Recherche BIA, Nantes
    johnny.beaugrand@reims.inra.fr"
"487","2018-04-25","Digimind","Paris","Stage - Linguistique Traitement Automatique des Langues

Paris, Île-de-France, France

QUI SOMMES-NOUS ?

Digimind est leader des logiciels SaaS de Social Media Analytics /
Market Intelligence permettant aux grandes marques de surveiller leur
réputation sur Internet et leur environnement concurrentiel.

Nous travaillons avec 200+ des plus grandes marques telles que Lexus,
Deloitte, BBDO et General Electrics.

Avec plus d'une centaine de collaborateurs à travers le monde,
Digimind est implantée à Paris, Grenoble, New-York, Singapour et
Rabat.

Si vous aimez toucher à tout, êtes curieux et attiré(e) par l'aventure
""PME en pleine croissance"",

Ne cherchez plus, ce stage est fait pour vous !

LA MISSION :

Dans le cadre de notre activité, nous recherchons un stagiaire TAL
pouvant participer à tout ou partie des missions suivantes :

- Documentation des algorithmes existants de traitement du langage
    dans nos solutions logicielles, dans une version vulgarisée pour
    nos équipes conseil et support. Pour cette mission, vous jouerez
    le rôle d'interface entre nos équipes techniques et business.

- Analyse de l'état de l'art de nos ressources sémantiques intégrées
  dans nos algorithmes et définitions de pistes d'optimisation de nos
  dictionnaires et règles sémantiques, notamment pour nos détections
  automatiques de genre, profession, âge etc.

Cette mission sera réalisée en plusieurs langues (a minima français,
anglais).

- Analyse et suivi des impacts des optimisations réalisées sur les
  résultats obtenus dans nos solutions logicielles.

- Vous serez rattaché à notre chef de produit et serez en contact
  opérationnel quotidien avec nos équipes développement, produit et
  conseil.

QUI RECHERCHONS NOUS ?

- Très bon niveau d'anglais et de français

- Idéalement de bonnes notions dans d'autres langues

- Jeune spécialiste des problématiques de traitement automatique de la
  langue et de l'ingénierie multilingue sans être nécessairement un
  ingénieur

- Formation supérieur de linguiste

- Une expérience préalable dans le domaine du traitement automatisé de
  la langue est un atout non négligeable

- Enthousiaste, dynamique et rigoureux(se)

QUE PROPOSONS-NOUS ?

Une opportunité unique de participer à la croissance d'une entreprise
internationale sur un secteur d'avenir.

- Un environnement de travail moderne et agréable au coeur de Paris
- Une atmosphère agréable avec les incontournables parties de babyfoot
  et de billard
- De nombreux avantages: tickets restaurant, remboursement des frais
  de transport
- Corbeille de fruits à disposition

Lieu : Paris

Statut : Stage

Rémunération selon profil


Postuler en ligne : http://digimind.recruiterbox.com/jobs/fk0fls1?apply=true"
"488","2018-05-23","Wiidii","Bordeaux","Stagiaire Linguiste Informaticien H/F

Début : Juin                                                  
Durée : 2 mois
Salaire : Gratification conventionnelle
Lieu : 56 rue de Tivoli - 33000 BORDEAUX

Qui est Wiidii ?

Wiidii est une jeune start-up bordelaise créée en 2014 qui développe
et commercialise en B2B une application d'assistant personnel
combinant l'intelligence artificielle et le savoir-faire humain : Un
assistant personnel propose à ses clients de gérer et simplifier leur
quotidien. L'entreprise connaît un fort développement depuis 2016.

Missions détaillées

Au sein d'une équipe d'une dizaine de personnes, et encadré par la
chef de projet, nous proposons un stage de linguiste informaticien,
d'une durée de 2 mois à partir de juin. Vos missions s'articuleront
autour de deux axes :

Conception d'une base de données

     - Alimenter la base de données (BDD) du nouveau moteur de
         l'application : recherche de sources de BDD, et au-delà des
         données pures, il s'agit aussi d'élaborer une BDD dynamique
         autour du langage sur le plan sémantique, pragmatique et
         syntaxique.

     -   Architecturer, diversifier et construire la BDD.

     -   Annoter la BDD en vue d'un enrichissement lexical.

Suivi client

    - Prendre en charge les demandes des clients en français et en
         anglais, via l'application Wiidii : comprendre la demande du
         client afin de lui apporter la réponse la plus pertinente
         possible.

    -    Prendre en charge l'envoi de notifications aux clients.

    -    Détecter et remonter les incidents.

    - Analyser l'activité client : profil des clients, nature des
         demandes et en sortir des données statistiques.

Profil et Compétences

Wiidii cherche un(e) candidat(e), maitrisant les bases de la
linguistique avec un fort attrait pour la sémantique. La maîtrise des
règles de la langue française est absolument indispensable et
l'anglais/espagnol/allemand écrit est un vrai plus. Le langage et sa
structuration vous passionne, vous vous intéressez à l'évolution des
nouvelles technologies appliquées au langage.

Rigueur, organisation, innovation, implication et adaptation sont les
qualités requises pour occuper ces missions.

Être à l'aise en informatique et avec les outils web est un atout
supplémentaire

De formation en sciences du langage, traitement automatique des
langues (TAL) ou en ingénierie des langues.

De plus l'esprit start-up et les nouvelles technologies vous attirent
alors candidatez !

                  
Avantages
      Tickets restaurant, participation au titre de transport

Temps de travail : 
      35 heures/semaine.
      Horaires variables du lundi au vendredi de 8h 19h.

Personne à contacter

Envoyez CV et lettre de motivation en français par mail à :
recrutement@wiidii.com"
"489","2018-06-06","Engie","Saint-Denis","Offre de stage R&D chez ENGIE LAB en Web Sémantique

Contexte et principales missions : 

Vous intégrez une équipe de recherche et de développement d'ENGIE, le
Lab CsAi (Computer Science and Artificial Intelligence), où vous
participez à la réalisation de solutions autour des technologies du web
sémantique.

L'objectif de ce stage est de faciliter l'intégration sémantique (accès,
partage et alignement) des données structurées hétérogènes non seulement
à l'aide des ontologies créées selon des besoins souhaités et/ou des
ontologies de domaine existantes mais aussi avec l'alignement aux
différentes données du Linked Data à savoir DBpedia, Data.gouv,
Wikidata, Geonames, etc.

Vous contribuez à mettre en place un outil permettant d'apprendre à lier
et à transformer les données structurées (CSV, JSON, XML, HTML, etc.)
en se basant sur les concepts d'ontologies et les relations entre eux,
et de créer des nouveaux concepts du domaine. Ces ontologies sont
développées pour différents domaines d'application, gaz, électricité,
bâtiments, eau, IoT, etc. Cet outil vise aussi à faciliter
l'enrichissement sémantique du modèle réalisé avec d'autres bases de
connaissances.

Tâches : 

- Revue de la littérature scientifique et analyse et veille
  technologique des développements existants liés aux systèmes
  d'apprentissage sémantique des données structurées [1,2]
- Développer et implémenter des algorithmes pour un nouveau système
  sémantique robuste à transformer et lier les différentes données
  structurées issues des cas d'usage métiers ENGIE
- Construire du code réutilisable et des bibliothèques pour une
  utilisation future
- Rédiger une documentation technique selon le besoin
- Déployer une application répondant aux enjeux scientifiques et
  métiers.
- Rédaction d'articles scientifiques.

Formation : 

Niveau : M2, école ingénieur en informatique, vous avez un profil
technique en développement logiciel et une connaissance des technologies
de web sémantique.

Compétences : 

- Vous maîtrisez les langages de programmation : Java, Python, script
  shell, des connaissances en IHM seraient un plus.
- Connaissances en technologies du web sémantique : RDF, OWL, SPARQL,
  etc.
- Connaissances en apprentissage et alignement sémantique.
- Vous avez une forte capacité d'empathie et le souhait de développer
  vos connaissances sur les problématiques métiers, liées au domaine de
  l'énergie.
- Vous avez idéalement une connaissance en open data. 
- Bon niveau d'anglais.

Détails du poste : 

- Le stage se déroulera au CRIGEN, le centre de R&D France d'ENGIE, est
  situé à Saint Denis.
- Durée : 6 mois à temps plein
- Rémunération : ce stage fait l'objet d'une rémunération, variable en
  fonction de l'école et diplôme préparé
- Début du contrat : dès que possible
- Contact :  philippe.calvez1@engie.com et
  sarra.ben-abbes@external.engie.com (CV + lettre de motivation)

[1] Mohsen Taheriyan, Craig A. Knoblock, Pedro A. Szekely, José Luis
Ambite: Learning the semantics of structured data sources. J. Web
Sem. 37-38: 152-169 (2016)

[2] Mohsen Taheriyan, Craig A. Knoblock, Pedro A. Szekely, José Luis
Ambite: Leveraging Linked Data to Discover Semantic Relations Within
Data Sources. International Semantic Web Conference (2016)"
"490","2018-07-09","Consortium CORLI","Paris","Job : Stage Consortium CORLI (CORpus, Langues et Interactions), Groupe
de Travail (GT3) Corpus multilingues et plurilingues

Date de début : 1 septembre 2018

Présentation de l'axe :

Le Groupe de Travail (GT3) Corpus multilingues et plurilingues du
Consortium CORLI recherche un-e stagiaire pour une durée de 3 mois,
régime d'indemnisation forfaitaire (env. 600 euros/mois).

Le GT3 Corpus multilingues et plurilingues a été officiellement créé en
2017. Dirigé par Evangelia Adamou (CNRS, Lacito), Natalie Kübler (Paris
Diderot, CLILLAC-ARP), Maria Zimina (Paris Diderot, CLILLAC-ARP) et
Antonio Balvet (Université de Lille, STL), le Groupe a organisé en
septembre 2017 une journée d'études sur la thématique du
""code-switching"" (annotations, traitements automatiques). Une autre
journée d'études est prévue fin novembre 2018 sur la thématique
""annotations, analyse cross-lingue et traitement automatique des corpus
multilingues et plurilingues parallèles et comparables"".

Les missions de stage sont les suivantes :

- recensement des corpus multilingues et plurilingues
- recensement des logiciels pour le traitement des corpus multilingues
  et l'analyse cross-lingue
- recensement des pratiques et guides d'annotation de corpus
  multilingues et plurilingues
- rédaction de fiches de présentation des différentes ressources, en
  français et en anglais

- gestion d'un wiki dédié au GT3 du Consortium CORLI : structuration des
  informations collectées, présentation sous différents formats (texte,
  tableaux de synthèse, base de données)

Le profil recherché pour ces missions est le suivant :

étudiant-e de niveau Master (M1 ou M2) de linguistique générale,
traduction outillée, linguistique de corpus, TAL, traduction spécialisée
outillée, communication, rédaction technique. Une bonne connaissance de
l'anglais est requise, ainsi qu'un intérêt pour la linguistique outillée
et les corpus.

Lieu de réalisation des missions : Université Paris Diderot Le suivi du
stage sera assuré par Natalie Kübler, Maria Zimina et Antonio Balvet

Les candidats sont invités à se manifester en contactant directement les
coordinateurs du Groupe :

Natalie Kübler : nkubler@eila.univ-paris-diderot.fr
Maria Zimina : mzimina@eila.univ-paris-diderot.fr
Antonio Balvet : antonio.balvet@univ-lille.fr
Evangelia Adamou : evangelia.adamou@cnrs.fr"
"491","2018-07-13","CLILLAC-ARP","Paris","TITRE
Type de poste: Stage/CDD
Durée du poste : 3 mois
Date de début : 1 octobre 2018
Ville: Paris

Laboratoire d'accueil : CLILLAC-ARP (Centre de Linguistique Inter-langues, de
Lexicologie, de Linguistique Anglaise et de Corpus-Atelier de Recherche sur la
Parole), Université Paris Diderot
Co-encadré par : LIPN (Laboratoire Informatique de Paris Nord)

Adresse: 8 place Paul Ricoeur, 75013 Paris
Contact : Alexandra Mestivier, Natalie Kübler et Emmanuel Cartier
Email : avolansk@eila.univ-paris-diderot.fr , nkubler@eila.univ-paris-
diderot.fr , emmanuel.cartier@lipn.univ-paris13.fr
Candidatures à envoyer avant : le 10 septembre 2018


Description du poste :

L'équipe d'accueil 3967 CLILLAC-ARP
(http://www.clillac-arp.univ-paris-diderot.fr/), dirigée par Natalie
Kübler, professeur à l'UFR EILA, est adossée à trois UFR : l'UFR
d'Études Anglophones, l'UFR EILA, et l'UFR de Linguistique.  Le projet
dans lequel interviendra le/ la candidat(e) concerne les membres de
l'équipe appartenant à l'UFR EILA, dont la recherche porte sur la
lexicologie, la terminologie, la néologie, la linguistique de corpus,
les langues de spécialité, la traductologie et les politiques
linguistiques dans un certain nombre de langues.

Plus particulièrement, le/la candidat(e) participera au transfert de la
plateforme Neoveille (http://lipn.univ-paris13.fr/neoveille/),
développée par Emmanuel Cartier au sein du LIPN, pour une utilisation
dans le cadre de l'étude de l'innovation dans les langues de spécialité
que mènera le CLILLAC- ARP. Il/elle devra installer la plateforme,
développer des fonctions supplémentaires, adapter les fonctionnalités
existantes et lancer la récupération de corpus.

Le/la candidat-e aura :
- des connaissances de Python
- une bonne connaissance/pratique des systèmes LAMP (Linux Apache MySQL
  PHP) et Javascript (Jquery). Une connaissance des librairies D3.js et
  Dc.js serait un plus
- des connaissances de base en linguistique.
- des connaissances en gestion des corpus
- une bonne connaissance du système d'exploitation Linux

Etant donnée la courte durée du stage, une bonne maîtrise de la
programmation est indispensable.

Rémunération : selon le niveau d'études"
"492","2018-07-18","Otherlang","Paris","Offre de stage: Stagiaire Linguiste

Qui sommes-nous ?

OtherLang développe une application de pratique et d'apprentissage des
langues. Elle part du constat que les solutions actuelles ne proposent
jamais ensemble ces deux démarches nécessaires à l'acquisition d'une
langue étrangère.

Nous proposons une approche différente qui part de la pratique écrite
collaborative en l'enrichissant de différents outils d'un apprentissage
personnalisé (""Adaptative Learning""). Certains sont basés sur des
développements sémantiques innovants.

Missions

Nous recherchons un linguiste ou un ingénieur linguiste pour travailler
sur le développement de notre application d'apprentissage des langues.

La mission consistera à travailler sur l'aide aux échanges entre
utilisateurs (chat) et l'apprentissage personnalisé. La mission portera
sur l'enrichissement des règles qui analysent les phrases pour
identifier les erreurs et les cartes d'apprentissage. Pour cela, il sera
notamment demandé d'effectuer les tâches suivantes :

* conception des règles linguistiques,

* création de corpus de tests,

* réalisation des tests,

* veille et tests des outils d'analyse morpho-syntaxique,

* veille des approches à la détection automatique des erreurs
  grammaticales.

Compétences 

* connaissances en grammaire formelle,

* bon niveau de l'anglais et/ou français,

* vous êtes passionné(e) par les langues,

* vous faites preuve de l'initiative vis-à-vis du sujet de votre stage,

* vous aimez évoluer en autonomie au sein d'une petite équipe,

* vous êtes organisé(e) et rigoureux(se),

* la connaissance des outils de Natural Language Processing, notamment
  de Stanford Parser et des expressions régulières seraient un plus.

Profil 

Étudiant-e de niveau Licence 3, Master 1 ou Master

2 de linguistique générale ou TAL ou équivalent.

Type d'offre

Stage de 3 à 6 mois

Date de début: dès que possible

Infos pratiques

Société

OtherLang

Ville : Paris

site: www.otherlang.com

Contact 

Si cette offre vous intéresse, merci de transmettre vos

motivations dans le corps du mail et joindre votre CV à
irina.maslowski@otherlang.com"
"493","2018-07-30","Advanced decision","Paris","Cadre du stage :

Ce stage de recherche d'une durée de 4 à 6 mois se déroulera au sein de
la société advanced decision.
Une poursuite du stage dans le cadre d'une convention CIFRE est
envisagée sur les mêmes problématiques.
L'encadrement sera assuré par l'équipe R&D de la société en
collaboration avec des laboratoires de recherche.

La société :
advanced decision est une startup spécialisée en Intelligence
Artificielle avec un savoir-faire industriel dans la réalisation de
moteurs intelligents de recommandation.
Nous développons un nouveau produit :  un agent virtuel de création de
voyages « sur mesure ».
Notre produit utilise les dernières techniques de l'IA et de la Data
Science : NLP, Machine Learning, et Decision Management.
Nous recherchons un stagiaire qui souhaite s'investir dans les domaines
de l'ingénierie linguistique et l'extraction du sens à partir des
textes.


Contexte :
Notre produit permet une appréhension des expériences grâce à une brique
d'analyse des avis et des commentaires. Un prototype permet d'ores et
déjà de repérer les expériences et de qualifier leur polarité. L'objet
du stage est d'améliorer cette dernière fonctionnalité en tenant compte
notamment de la structure syntaxique des textes analysés.

Activités :
- Appropriation des travaux réalisés
- État de l'art des techniques d'analyse des sentiments
- Identification des dimensions et des ressources adaptés à notre sujet
- Benchmark de certains algorithmes pour améliorer l'analyse des
  sentiments
- Implémentation et optimisation

Compétences :
- Langage de programmation (Python, C++, Java)
- Ingénierie linguistique, TAL, Fouille de textes et d'opinions
- Machine Learning (SVM, réseaux de neurones, ...)
- Connaissance appréciée d'un des frameworks (NLTK, Keras ou PyTorch)

Durée : 3 à 6 mois
Démarrage : asap
Lieu : Paris 17
Formation : Ingénieur Informatique, Master en TAL
Indemnité : selon convention et expérience
Documents à fournir : CV, lettre de motivation et bulletins de notes
Candidature : stage@advanceddecision.fr"
"494","2018-09-04","Amadeus","Sophia Antipolis","Amadeus (https://amadeus.com)

Data Insight Internship - CSS-SSP-EDS 

In the scope of a large code Reengineering Project, we are looking for
highly motivated and passionate Data Analyst to apply rigorous
scientific methodology and algorithms to data/information embarked
within the internal structures in our legacy code in order to improve
its understanding and efficiency.

As a Data Analyst, you will provide unique insight into understanding
the structures articulating around multiple business and customer
scenarios that cut across Amadeus organizational boundaries and lead
the current usage and incoming growth of a data-driven culture within
the Search Shopping and Pricing Core division.  

Key Responsibilities

As a Data Analyst, you will mainly formulate analytical approaches to
determine the functional adherence of our current internal C
structures based on the understanding of product functionality,
Business flows etc. in terms of entropy across different processes and
information reliability and redundancy between different internal
structures.

You will use data exploration techniques to uncover patterns in the
data from which predictive models, actionable insights or solutions
can be developed with the perspective to move from a monolithic to a
Service Oriented and Modular software.

You will interpret your results with the help of highly experienced
functional experts and skilled technical developers in an
international context, validate their approach, and learn to monitor,
clearly document, analyze, in order to iterate and automatize in the
mindset of a continuous improvement.

Qualifications

- Currently pursuing graduate degree in Software Engineering, Data
  Analytics, Machine Learning, Applied Mathematics or similar domain.

- Programming skills in C, C++,

- Proficiency using one or more scripting languages.

- Software technology savvy, creativity and forward thinking.

- Solid spoken and written English. 

- Self-driven to learn new technology area.

- Ability to interact with peers and stakeholders to drive product and
  business im pact.

- Strong interpersonal and communications skills.



Location: 
   Amadeus Espaces, 
   Rue des Amandiers, 
   06410 Biot,
   France.

Contact:
   Djamal Mohia, 
   djamal.mohia@amadeus.com
   +33 4 97 15 87 70
   www.amadeus.com"
"495","2018-09-24","Labex OBVIL","Paris","Offre de stage en Humanités Numériques chez le Labex OBVIL - Sorbonne
Université
http://obvil.sorbonne-universite.site
Septembre 2018

Contexte et principales missions : Vous intégrez une équipe de recherche
et de développement, le labex OBVIL (Observatoire de la Vie Littéraire),
où vous participez à la réalisation de solutions autour des technologies
des Humanités Numériques. Le stage se déroulera dans le cadre du projet
Apollinaire qui vise à mettre à mettre en ligne chronologiquement tous
les écrits et tous les manuscrits d'Apollinaire.
Les textes sont disponibles en XML : format TEI.

Tâches :
- Comprendre et apprivoiser la structure d'un document XML ;
- Savoir identifier et manipuler les éléments structurels d'un texte 
  XML ;
- Participer à l'encodage de nouveaux textes en XML-TEI ;
- Contrôler la qualité des textes encodés en XML-TEI par l'équipe 
  scientifique en charge d'éditer les manuscrits ;
- Comprendre la notion de transformation à partir de XML vers une 
  publication Web, une publication PDF, ou une publication EPUB.

Niveau de formation : Licence ou master

Compétences requises : Connaissances en XML-TEI, DTD, CSS et Xpath ;
familiarisation avec les logiciels d'édition numérique de contenu
(Oxygen...).

Encadrement: Éric THIÉBAUD et Motasem ALRAHABI (ingénieurs de recherche
OBVIL, Sorbonne Université).

Rémunération: standard

Localisation : Le stage se déroulera au Labex OBVIL, Maison de la 
Recherche, 28 rue Serpente, 75005 Paris.

Durée: 6 mois

Début du contrat : Début octobre ou dès que possible après cette date.

Candidature : Pour toute question ou pour nous adresser votre
candidature (curriculum vitae et lettre de motivation), merci d'écrire à
la secrétaire générale stephanie.guez@sorbonne-universite.fr en
indiquant comme sujet : ""recrutement stagiaire XML""."
"496","2018-09-26","OtherLang","Paris","Offre de stage: Stagiaire Linguiste
Qui sommes-nous ?

OtherLang développe une application de pratique et d'apprentissage des
langues. Elle part du constat que les solutions actuelles ne proposent
jamais ensemble ces deux démarches nécessaires à l'acquisition d'une
langue étrangère.

Nous proposons une approche différente qui part de la pratique écrite
collaborative en l'enrichissant de différents outils d'un apprentissage
personnalisé (""Adaptative Learning""). Certains sont basés sur des
développements sémantiques innovants.

Missions

Nous recherchons un linguiste ou un ingénieur linguiste pour travailler
sur le développement de notre application d'apprentissage des langues.

La mission consistera à travailler sur l'aide aux échanges entre
utilisateurs (chat) et l'apprentissage personnalisé. La mission portera
sur l'enrichissement des règles qui analysent les phrases pour
identifier les erreurs et les cartes d'apprentissage. Pour cela, il sera
notamment demandé d'effectuer les tâches suivantes :

   - conception des règles linguistiques,
   - création de corpus de tests,
   - réalisation des tests,
   - veille et tests des outils d'analyse morpho-syntaxique,
   - veille des approches à la détection automatique des erreurs
     grammaticales.

Compétences - connaissances en grammaire formelle,
   - bon niveau de l'anglais et/ou français,
   - vous êtes passionné(e) par les langues,
   - vous faites preuve de l'initiative vis-à-vis du sujet de votre
     stage,
   - vous aimez évoluer en autonomie au sein d'une petite équipe,
   - vous êtes organisé(e) et rigoureux(se),
   - la connaissance des outils de Natural Language Processing,
     notamment de Stanford Parser, des expressions régulières et de
     programmation seraient un plus.

Profil

Étudiant-e de niveau Master 1 ou Master 2 de linguistique générale ou
TAL ou équivalent.

Type d'offre

Stage de 4 à 6 mois

Date de début: janvier 2019

Infos pratiques

Société : OtherLang

Ville : Paris

site: www.otherlang.com

Contact

Si cette offre vous intéresse, merci de transmettre vos motivations dans
le corps du mail et joindre votre CV à irina.maslowski_at_otherlang.com"
"498","2018-10-03","LIFAT","Blois","6-month NLP internship in Blois, France:

*Verbal Multiword Expression Discovery in French Based on Seen Data and
 Distributional Semantics*

* Scientific field: Natural Language Processing (NLP)
* Location: University of Tours, LIFAT (Laboratoire d'Informatique
  Fondamentale et Appliquée de Tours), Blois campus (41)
* Duration: 6 months
* Remuneration : 577 ¤ / month
* Detailed description: http://parsemefr.lis-lab.fr/doku.php?id=2018-lifat-m2-1

* Important dates
  - Application deadline: *15 December 2018* (or until filled)
  - Notification: 15 January 2018
  - Position starts: around February-March 2018
  - Position ends: around July-August 2018

* Requested candidate profile
  - 2nd-year master student in computational linguistics, computer
    science or alike
  - Interests in linguistics and familiarity with language technology
  - Good knowledge of French
  - Good programming skills, preferably in Python.

* Applications:
  Send your CV and a cover letter to Caroline Pasquer
  (first.last@etu.univ-tours.fr) and Agata Savary
  (first.last@univ-tours.fr).

*Motivation and objectives*

The internship will take place in the framework of the PARSEME-FR
project (http://parsemefr.lis-lab.fr), which involves several NLP teams
in France.

The aim is to boost applications in Natural Language Processing (NLP),
by focusing on one of their major challenges: multiword expressions
(MWEs).

MWEs are groups of words which exhibit unpredicted properties (Baldwin &
Kim, 2010). Most prominently, their meaning does not straightforwardly
derive from the meanings of their components, as in 'casser sa pipe'
(literally `to break one's pipe') `to die'.

Two major MWE-related NLP tasks include MWE discovery and MWE
identification. In the former, the input consists in large quantities of
raw texts and the output is a list of potential MWEs. In the latter, and
identifier takes a text on input and automatically annotates (points at)
the occurrences of MWEs in it. MWE identification is a pre-requisite for
downstream applications such as machine translation (which may want to
treat MWEs with dedicated procedures).
Automatic identification of MWEs in 19 languages was addressed by the
PARSEME shared task1 (Ramisch et al., 20182018), in which the BdTln team
participated with the VarIDE system (Pasquer et al., 2018a). The results
of the shared task show that identifying unseen MWEs (i.e. those MWEs
which do not occur in the training data) is particularly
challenging. Thus, identification should, ideally, exploit not only
annotated corpora but also MWE lexicons and MWE discovery methods.

This internship is dedicated to discovering how MWE discovery could
benefit from the previously seen data, rather than be performed from
scratch. The hypothesis to be tested is that new (unseen) MWEs of
certain types can be discovered due to their semantic similarity with
known (previously seen) MWEs. We focus on the domain of distributional
semantics, which is based on the hypothesis that words having a similar
meaning occur in similar contexts. Recent developments in distributional
semantics include the construction of ""word embeddings"", i.e. mappings
from words or expressions to low-dimensional vectors of real numbers,
which are expected to represent co-occurrence contexts of these
words/expressions in a compact way. Thus, an embedding of a
word/expression can be considered an abstract representation of its
meaning.

The objectives of this internship are to exploit word embeddings for
discovery of new MWEs based on their semantic proximity to the
previously seen MWEs, contained in a lexicon or in an annotated corpus
(resources of both types belong to the outcomes of the PARSEME-FR
project). The discovery should lead to (semi-)automatic enrichment of
these initial resources."
"499","2018-10-15","Airbus","Elancourt","Stage Traitement de la Parole (h/f)

Airbus Defence and Space Elancourt

Airbus est un leader mondial de l'aéronautique, de l'espace, de la
défense et des services associés. En 2017, l'entreprise a dégagé un
chiffre d'affaires de 67,0 milliards d'euros avec un effectif
d'environ 130 000 personnes. Airbus propose la gamme d'avions de
transport de passagers la plus complète, de 100 à plus de 600
sièges. Airbus est également le fournisseur d'avion de ravitaillement,
de combat, de transport et de mission leader en Europe, ainsi que le
numéro un européen et le numéro deux mondial de l'industrie
spatiale. Sur le marché des hélicoptères, Airbus fournit les voilures
tournantes civiles et militaires les plus performantes au monde.

Nos équipes travaillent avec passion et détermination pour faire du
monde un endroit plus connecté, plus sûr et plus intelligent. Fiers de
notre travail, nous nous appuyons sur l'expertise et l'expérience de
chacun pour atteindre l'excellence. Notre diversité et culture du
travail en équipe nous poussent à accomplir l'extraordinaire - sur
terre, dans le ciel et dans l'espace.  Description du poste / stage

Une offre de stage Traitement de la Parole (h/f) vient de s'ouvrir au
sein d'Airbus Defence & Space à Elancourt.

Vous rejoindrez l'équipe de Recherche & Développement composée
d'ingénieurs, d'étudiants en thèse et de stagiaires, spécialisée dans
le traitement de données multimédias (texte, audio, etc.) et le
traitement massif de l'information non structurée (Big Data). Cette
équipe est impliquée dans des projets d'études amont ainsi que divers
programmes de recherche partiellement financés par l'Agence Nationale
de la Recherche, l'Agence de Défense Européenne ainsi que l'Union
Européenne.

Contexte :

Notre équipe développe et adapte des briques technologiques pour le
traitement automatique de documents multimédias. Ces composants visent
à fournir des solutions d'analyse du contenu (identification de la
langue, extraction d'information, transcription de la parole,
traduction automatique, etc.) et sont intégrés dans des applications
de traitement de l'information dans le domaine de la défense et de
l'aéronautique.

Dans cette perspective, ce stage s'inscrit dans le cadre des travaux
menés sur la transcription automatique de la parole.

Objectif:

La reconnaissance automatique de la parole (ASR, Speech recognition)
présente plusieurs défis notamment ceux liés à la qualité acoustique
des enregistrements (bruit, support de captation, etc.). L'objectif de
ce stage est de contribuer à l'identification et à la proposition de
solutions permettant de réduire l'impact de ces problèmes sur la
qualité de la transcription.

Ce stage commencera le 1er février 2019 (Date sujette à flexibilité)
et sera d'une durée de 6 mois.

Tâches et missions principales, responsabilités

- Contribution à l'établissement d'un état de l'art sur les méthodes
  de traitement de données audio bruitées et/ou de mauvaise qualité.

- Identification de solutions open source ou de laboratoire.

- Mise en oeuvre des solutions techniques (apprentissage sur des bases
  existantes).

- Comparaison et évaluation des approches sur un corpus de référence.

Ce poste exige une connaissance des risques potentiels de
non-conformité. Le/la titulaire s'engage à agir avec intégrité,
fondement du succès, de la réputation et de la croissance durable de
la Société.

Compétences requises

Vous préparez un BAC+5 en Traitement Automatique des langues (orienté
recherche), options Intelligence Artificielle, Apprentissage
automatique, Traitement automatique des Langues, Transcription
automatique.

Vous avez une bonne maitrise de Python, Shell, C++.

Vous avez des connaissances en Framework de Deep Learning.

Vous êtes doté(e) d'un bon esprit d'équipe et d'un bon relationnel.

Vous avez un niveau avancé en anglais et Français courant.



Candidature en ligne :

https://company.airbus.com/careers/jobs-and-applications/search-for-vacancies~lang=fr~jobid=001A4B0A914A1EE8B2F960A4F3A78704~.html#"
"500","2018-10-15","Airbus","Elancourt","Stage Text-Mining et population de bases de connaissances (h/f)

Airbus Defence and Space Elancourt

Airbus est un leader mondial de l'aéronautique, de l'espace, de la
défense et des services associés. En 2017, l'entreprise a dégagé un
chiffre d'affaires de 67,0 milliards d'euros avec un effectif
d'environ 130 000 personnes. Airbus propose la gamme d'avions de
transport de passagers la plus complète, de 100 à plus de 600
sièges. Airbus est également le fournisseur d'avion de ravitaillement,
de combat, de transport et de mission leader en Europe, ainsi que le
numéro un européen et le numéro deux mondial de l'industrie
spatiale. Sur le marché des hélicoptères, Airbus fournit les voilures
tournantes civiles et militaires les plus performantes au monde.

Nos équipes travaillent avec passion et détermination pour faire du
monde un endroit plus connecté, plus sûr et plus intelligent. Fiers de
notre travail, nous nous appuyons sur l'expertise et l'expérience de
chacun pour atteindre l'excellence. Notre diversité et culture du
travail en équipe nous poussent à accomplir l'extraordinaire - sur
terre, dans le ciel et dans l'espace.

Description du poste / stage

Une offre de stage Text-Mining et population de bases de connaissances
(h/f) vient de s'ouvrir au sein d'Airbus Defence & Space à Elancourt.

Vous rejoindrez l'équipe de Recherche & Développement composée
d'ingénieurs, d'étudiants en thèse et de stagiaires, spécialisée dans
le text-mining et le traitement massif de l'information non structurée
(Big Data). Cette équipe est impliquée dans des projets d'études amont
ainsi que divers programmes de recherche partiellement financés par
l'Agence Nationale de la Recherche, l'Agence de Défense Européenne
ainsi que l'Union Européenne.

Contexte :

Notre équipe développe actuellement en s'appuyant sur le socle
technique open source OW2 WebLab une solution de veille nommée FORTION
MediaMining. Cette solution vise à fournir une solution complète de
collecte d'information multimédia -texte, image, audio, vidéo -
disponible en source ouverte (web, réseaux sociaux), d'analyse
(extraction et recherche d'information, transcription de la parole,
traduction automatique, etc...) et d'exploitation (visualisation
spatio-temporelle, réseau relationnel, statistiques, etc.). Celle-ci
dispose notamment de fonctionnalités d'extraction d'information de
relations et d'évènement à base de patrons linguistiques permettant
d'enrichir des bases de connaissances.

Objectif :

Notre équipe souhaite extraire à partir de textes éventuellement
multilingues (type flux presse) des évènements de différentes natures
(militaires, économiques, catastrophes naturelles, etc). Une des
difficultés de la tâche d'extraction d'évènements vient de leur nature
composite qui nécessite d'extraire différentes dimensions (sémantique,
spatiale, temporelle, agentive, numérique) disséminées au sein des
textes. Analyse discursive, extraction d'entités nommées, de
relations, résolution d'anaphores sont ainsi nécessaires pour couvrir
pleinement cette tâche. Les campagnes d'évaluation récentes sur le
sujet (ex TAC KDP2017) montrent que de nombreuses pistes d'évaluation
restent à explorer (53% de F-Mesure pour le meilleur système à date).

Ce stage commencera le 1er février 2019 (Date sujette à flexibilité)
et sera d'une durée de 6 mois.

Stages chez Airbus

Tâches et missions principales, responsabilités

Ce stage vise ainsi à étudier la possibilité de remplacer / hybrider
les systèmes d'extraction à base de patrons linguistiques par des
systèmes à base de réseaux de neurones profonds de type réseaux de
neurones récurrents :

Contribution à l'établissement d'un état de l'art sur les méthodes
d'extraction d'information, de relation et d'évènements à base de
méthode d'apprentissage pour la population de base de connaissance.

Identification de solutions open source ou de laboratoire.

Mise en oeuvre des solutions techniques (apprentissage sur base
annotée).

Comparaison et évaluation des approches sur un corpus de référence.

Ce poste exige une connaissance des risques potentiels de
non-conformité. Le/la titulaire s'engage à agir avec intégrité,
fondement du succès, de la réputation et de la croissance durable de
la Société.

Compétences requises

Vous préparez un BAC+5 en Traitement d'Information (orienté
recherche), options Intelligence Artificielle, Apprentissage
automatique, Traitement automatique des Langues, Fouille de données,
Extraction d'information à partir de textes.

Vous avez une bonne maitrise de Java et Python.

Vous avez des connaissances en Framework de Deep Learning type Tensorflow.

Vous êtes doté(e) d'un bon esprit d'équipe et d'un bon relationnel.

Vous avez un niveau avancé en anglais et Français courant.

Candidature en ligne :
https://company.airbus.com/careers/jobs-and-applications/search-for-vacancies~lang=fr~jobid=001A4B0A914A1ED8B2F9907C4EB89502~.html"
"501","2018-10-15","Santé publique France","Saint-Maurice (94)","Stage à Santé Publique France pour des étudiants de Master

Année universitaire 2018-2019

- Stage proposé par

Titre : Influence de l'expression du temps et de la soudaineté de la
survenue d'une cause médicale de décès pour la surveillance réactive
de la mortalité à visée d'alerte sanitaire.

Direction/ Cire : DATA

Maîtres de stage / personne contact : 

Nom : FOUILLET Prénom : Anne

Téléphone : 01 41 79 57 25 Adresse email :
anne.fouillet@santepubliquefrance.fr

- Type de stage proposé

Master 1 Master 2 Professionnel Master 2 Recherche

Extension possible au-delà de la période obligatoire Oui Non

Commentaires :

- Date proposée pour le stage et durée

pas de contrainte de date 

A partir de Février/Mars 2019 

Durée en mois : 5/6 mois

- Sujet proposé pour le stage

Santé publique France est l'agence nationale de santé publique
française. Elle intervient au service de la santé des populations.
Agence scientifique et d'expertise du champ sanitaire, elle a pour
missions : (1) l'observation épidémiologique et la surveillance de
l'état de santé des populations ; (2) la veille sur les risques
sanitaires menaçant les populations ; (3) la promotion de la santé et la
réduction des risques pour la santé ; (4) le développement de la
prévention et de l'éducation pour la santé ; (5) La préparation et la
réponse aux menaces, alertes et crises sanitaires ; (6) le lancement de
l'alerte sanitaire.

Le stage se déroulera dans l'unité « Application, Big Data et
Surveillance Syndromique » de la Direction Appui, Traitements et
Analyses des données (DATA). Cette unité a de nombreuses missions au
sein de l'agence dont le traitement des grandes bases de données, la
réalisation d'outils de restitution graphiques et le pilotage du système
national de surveillance des urgences et des décès SurSaUD(R), mis en
place en 2004. SurSaUD(R) est un des principaux dispositifs de Santé
publique France pour assurer la veille sanitaire non spécifique à visée
d'alerte notamment par l'identification d'événements inhabituels. Cette
veille s'appuie sur l'analyse quotidienne du recours aux soins d'urgence
hospitaliers et libéraux (réseaux OSCOUR(R) et SOS Médecins) et de la
mortalité (analyse des décès toutes causes de l'Insee principalement et
analyse des décès par cause médicale, issue de la certification
électronique de décès).

Le stage portera sur les données de la certification électronique des
décès, contenant les causes médicales de décès exprimées en texte
libre. Cette source de données est en cours de généralisation sur le
territoire, elle enregistre 13% de la mortalité nationale en 2018,
proportion en hausse régulière depuis plusieurs années.

Un premier travail de recherche réalisé en 2018 dans le cadre d'un stage
de Master Linguistique Informatique, a permis de sélectionner et
d'évaluer deux méthodes de classement automatisé de ces causes médicales
de décès dans des regroupements prédéfinis (« regroupements syndromiques
») : une méthode par règles linguistiques et un SVM.  L'évaluation a été
menée sur des données annotées manuellement (4500 certificats de
décès). Chaque certificat de décès contient plusieurs causes médicales,
classées dans un ou plusieurs regroupements syndromiques. Ce travail a
été réalisé sous Python 3.5.

Objectifs du stage

Dans un premier temps, le stage visera à améliorer le classement réalisé
lors du travail de recherche de 2018, à travers la prise en compte
d'informations complémentaires précisées par le médecin dans le
certificat. Cela peut concerner en particulier :

- les informations permettant d'exprimer une date ou un délai de
  survenue d'une cause par rapport à la date de décès.

- l'expression de la soudaineté de la survenue d'une cause.

Des illustrations de causes de décès contenant des expressions du temps
et de la soudaineté sont présentées en annexe.

Dans un second temps, le stage visera à mettre en oeuvre une méthode de
classement automatisé par apprentissage et comparer ses performances à
celles obtenues à partir des deux premières méthodes (Méthodes par
règles et SVM). L'évaluation des performances pourra s'appuyer sur des
échantillons qui auront été annotés grâce à une méthode d'annotation
semi-automatique.

Les principales étapes du stage seront :

* Prise en main des scripts et ressources, développés lors du premier
  travail de recherche,

* Prendre en compte des informations complémentaires à l'aide de
  traitements linguistiques,

* Evaluer l'influence de ces informations sur la dynamique des
  regroupements syndromiques,

* Développer et évaluer une méthode de classement de type étiqueteur,

* Comparer les résultats à ceux obtenus à partir des méthodes par règles
  et SVM.

Le stage s'appuiera sur des scripts et ressources existants, complétés
par une documentation et un rapport de stage.

- Prérequis

Aucun

Compétences spécifiques (préciser) : 

Maîtrise d'un logiciel spécifique (préciser) : langage Python

Autre (préciser) : 

- Commentaires

Le stagiaire sera co-encadré par l'équipe du CNRS-LIMSI (Laboratoire
d'informatique pour la Mécanique et les Sciences de l'Ingénieur),
spécialisée dans le domaine du traitement automatique des langues.

Le stage se déroulera à la Direction Appui, Traitements et Analyses de
données de Santé publique France à Saint-Maurice (94) et au CNRS-Limsi à
Orsay (91)."
"502","2018-10-16","Naver Labs Europe","Grenoble","Machine translation has made great progress in recent years thanks to
deep neural networks [1,2,7].  However, current machine translation
systems make a simplifying assumption that the translation of a given
sentence does not depend on the other neighboring sentences. Yet, we
know that extended context can prevent mistakes in ambiguous cases and
improve translation coherence.

In the case of machine translation of user generated content (e.g.,
user reviews of hotels or restaurants), the source data is often
highly contextual and structured. Several reviews can be associated to
the same Point of Interest (POI), POIs can have specific features
(e.g., their name or their location) and can also be organized into
graphs according to their similarity.

The goal of this internship is to introduce context-aware neural
machine translation models that do not process sentences in isolation
but leverage their context (history of sentences already translated,
meta information associated to a POI, POI graph structure). The
machine translation experiments will be done on several language pairs
with a POI database gathering more than 100 million POIs.

Requirements

â— Student at Master (research-oriented) or PhD level.

â— Knowledge of deep learning as applied to NLP.

â— Good coding skills, including at least one the major deep learning
toolkits (preferably Pytorch).

References.

[1] Sequence to Sequence Learning with Neural Networks. Ilya
Sutskever, Oriol Vinyals, Quoc V. Le. NIPS 2014.

[2] Neural Machine Translation by Jointly Learning to Align and
Translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio. ICLR 2015.

[3] Conversational Analysis using Utterance-level Attention-based
Bidirectional Recurrent Neural Networks.  Chandrakant Bothe, Sven
Magg, Cornelius Weber, Stefan Wermter. Interspeech 2018

[4] End-to-End Memory Networks with Knowledge Carryover for Multi-Turn
Spoken Language Understanding.  Yun-Nung Chen, Dilek Hakkani-TÃ¼r,
Gokhan Tur, Jianfeng Gao, and Li Deng. Interspeech 2016

[5] An Efficient Approach to Encoding Context for Spoken Language
Understanding. Raghav Gupta, Abhinav Rastogi, Dilek
Hakkani-Tur. Interspeech 2018

[6] Multi-Timescale Long Short-Term Memory Neural Network for
Modelling Sentences and Documents. Pengfei Liu, Xipeng Qiu , Xinchi
Chen, Shiyu Wu, Xuanjing Huang. EMNLP 2015.

[7] Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,
Illia Polosukhin. NIPS 2017.

[8] Context-Aware Neural Machine Translation Learns Anaphora
Resolution. Elena Voita, Pavel Serdyukov, Rico Sennrich, Ivan
Titov. EMNLP 2018.

[9] Improving the Transformer Translation Model with Document-Level
Context. Jiacheng Zhang, Huanbo Luan, Maosong Sun, Feifei Zhai,
Jingfang Xu, Min Zhang and Yang Liu. EMNLP 2018.

[10] Learning to Remember Translation History with a Continuous
Cache. Zhaopeng Tu, Yang Liu, Shuming Shi, Tong Zhang. TACL 2018.

[11] Document Context Neural Machine Translation with Memory
Networks. Sameen Maruf, Gholamreza Haffari.  ACL 2018.

[12] Document-Level Neural Machine Translation with Hierarchical
Attention Networks. Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas,
James Henderson. EMNLP 2018

[13] Improving the Transformer Translation Model with Document-Level
Context. Jiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai,
Jingfang Xu, Min Zhang, Yang Liu. EMNLP 2018


Start Date
asap

Duration
5-6 months

Application instructions

To apply, please send a mail and CV to ioan.calapodescu@naverlabs.com,
alexandre.berard@naverlabs.com and laurent.besacier@univ-grenoble-alpes.fr"
"503","2018-10-16","Naver Labs Europe","Grenoble","Machine translation has made great progress in recent years thanks to
deep neural networks [1,2,3]. A conventional neural machine
translation (NMT) system uses a limited vocabulary of `tokens' and its
decoder generates a token in the vocabulary at each time step. The
`tokens' of current machine translation systems can be words,
characters [4] or subwords such as byte pair encodings (BPEs) [5]. The
latter have been particularly effective to deal with out-of-vocabulary
words and generally lead to state-of-the-art results. However, it is
not clear how many units1 should be kept for a particular MT task and
which is the optimal granularity (characters, subwords, words), if
any.

The goal of this internship is to investigate approaches that provide
models with several views (segmentations) of the text to strengthen
their robustness. This is particularly important for processing noisy
data such as user generated content (UGC - e.g., user reviews of
hotels or restaurants). Such a multiscale neural machine translation
model should take into account these different segmentation
granularities at both training and decoding stages. We also want the
proposed method to be applicable to the latest state-of-the-art NMT
based on transformer networks [3].

Requirements

- Student at Master (research-oriented) or PhD level.

- Knowledge of deep learning as applied to NLP.

- Good coding skills, including at least one of the major deep
learning toolkits (preferably Pytorch).

References.

[1] Sequence to Sequence Learning with Neural Networks. Ilya
Sutskever, Oriol Vinyals, Quoc V. Le. NIPS 2014.

[2] Neural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho,
Yoshua Bengio. ICLR q2015.

[3] Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki
Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,
Illia Polosukhin. NIPS 2017.

[4] Jason Lee, Kyunghyun Cho, and Thomas Hofmann. 2017. Fully
character-level neural machine translation without explicit
segmentation. TACL 2017

[5] Neural machine translation of rare words with subword units. Rico Sennrich, Barry Haddow, and Alexandra Birch. ACL,2016.

[6] Improving Neural Machine Translation by Incorporating Hierarchical
Subword Features. Makoto Morishita, Jun Suzuki* and Masaaki
Nagata. COLING 2018.5

[7] Subword Regularization: Improving Neural Network Translation
Models with Multiple Subword Candidates.  Taku Kudo. ACL 2018.6

[8] Google's neural machine translation system: Bridging the gap
between human and machine translation.  Yonghui Wu, Mike Schuster, et
al. arXiv preprint arXiv:1609.08144 2016.

[9] Neural Lattice-to-Sequence Models for Uncertain Inputs. Matthias
Sperber, Graham Neubig, Jan Niehues, Alex Waibel. EMNLP 2017.

[10] On Using Monolingual Corpora in Neural Machine
Translation. Caglar Gulcehre, Orhan Firat, Kelvin Xu, Kyunghyun Cho,
Loic Barrault, Huei-Chi Lin, Fethi Bougares, Holger Schwenk, Yoshua
Bengio. arXiv preprint:1503.03535.

[11] Optimally Segmenting Inputs for NMT Shows Preference for
Character-Level Processing. Julia Kreutzer, Artem Sokolov. arXiv
preprint:1810.01480. 2018

Start Date
asap

Duration
5-6 months

Application instructions

To apply, please send a mail and CV to matthias.galle@naverlabs.com ,
marc.dymetman@naverlabs.com and
laurent.besacier@univ-grenoble-alpes.fr"
"504","2018-10-22","LIG / LIA","Grenoble","The LIG (Laboratoire d'Informatique de Grenoble) and LIA (Laboratoire
d'Informatique d'Avignon) laboratories propose the following M2 stage
(research)

Title:
Dialog-Level Neural Spoken Language Understanding from Speech

Description:

Spoken Language Understanding (SLU) is an important part of
Human-Computer interaction, and aims at extracting semantic
interpretations from human utterances [De Mori et al., 2008]. Because of
the high complexity of the problem, real applications focus on specific
domains, e.g. hotel reservation and information [Bonneau-Maynard et al.,
2006]. Most of the times, SLU is performed on automatic transcriptions
of the speech signal or, at best, on ASR word lattices. Thanks to neural
networks, SLU can be possibly performed directly on speech signal,
overcoming or at least alleviating the problems related to automatic
transcription. Such end-2-end approaches from speech have been already
proposed for spoken language translation [Bérard et al., 2018, Berard et
al., 2016, Weiss et al., 2017]. Additionally, the use of Neural Networks
such like RNNs (LSTM/GRU) [Hochreiter and Schmidhuber, 1997, Cho et al.,
2014] and Transformers [Vaswani et al., 2017], in combination with
attention mechanisms [Bahdanau et al., 2014], allows potentially to use
contextual information going beyond the single or a few dialog turns
[Bothe et al., 2018]. This information is possibly crucial to solve
long-range ambiguïties.

In this internship the student will implement a complete neural SLU
system, decoding semantic interpretations directly from the speech
signal and keeping into account contextual information at the whole
dialog level. The student will use modular pre-built systems based on
Convolutional and Recurrent Neural Networks [Berard et al., 2018,
Dinarelli et al., 2017] and/or Transformer networks, with the objective
of creating a whole integrated SLU system. The student will run
experiments on its own using GPUs, and the system will be evaluated on
the SLU benchmark corpus MEDIA [Bonneau-Maynard et al., 2006, Hahn et
al., 2010].

Student Profile:
- Student for internship level (Master 2) in computer science, or from
  engineering school
- Computer science skills:
     - Python programming with good knowledge of deep learning libraries
       (Pytorch)
     - Data manipulation (both textual data and audio signal)
- Interested in Natural Language Processing
- Skills in machine learning for probabilistic models

The internship may last from 4 up to 6 months, it will take place at LIG
laboratory (with potential visits at LIA, Avignon), GETALP team
(http://lig-getalp.imag.fr/), starting from January/February 2019. The
student will be tutored by Marco Dinarelli
(http://www.marcodinarelli.it), Laurent Besacier
(https://cv.archives-ouvertes.fr/laurent-besacier), and Bassam Jabaian
(http://univ-avignon.fr/m-bassam-jabaian--3265.kjsp).

Interested candidates must send a CV and a motivation letter to
marco.dinarelli@ens.fr, laurent.besacier@univ-grenoble-alpes.fr, and
bassam.jabaian@univ-avignon.fr.


References:

Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio.  Neural machine
translation by jointly learning to align and translate.  CoRR,
abs/1409.0473, 2014. URL http://arxiv.org/abs/1409.0473.

Alexandre Berard, Olivier Pietquin, Christophe Servan, and Laurent
Besacier.  Listen and translate: A proof of concept for end-to-end
speech-to-text translation.  CoRR, abs/1612.01744, 2016. URL
http://arxiv.org/abs/1612.01744.

Alexandre Béerard, Laurent Besacier, Ali Can Kocabiyikoglu, and Olivier
Pietquin.  End-to-end automatic speech translation of audiobooks.  CoRR,
abs/1802.04200, 2018. URL http://arxiv.org/abs/1802.04200.

Hélène Bonneau-Maynard, Christelle Ayache, F. Bechet, A Denis, A Kuhn,
Fabrice Leféevre, D. Mostefa, M. Qugnard, S. Rosset, and J. Servan,
S. Vilaneau.  Results of the french evalda-media evaluation campaign for
literal understanding.  In LREC, pages 2054{2059, Genoa, Italy, May
2006.

Chandrakant Bothe, Sven Magg, CorneliusWeber, and StefanWermter.
Conversational analysis using utterance-level attention-based
bidirectional recurrent neural networks. CoRR, abs/1805.06242, 2018. URL
http://arxiv.org/abs/1805.06242.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares,
Holger Schwenk, and Yoshua Bengio.  Learning phrase representations
using RNN encoder-decoder for statistical machine translation.  CoRR,
abs/1406.1078,2014. URL http://arxiv.org/abs/1406.1078.

R. De Mori, F. Bechet, D. Hakkani-Tur, M. McTear, G. Riccardi, and G.
Tur.  Spoken language understanding: A survey. IEEE Signal Processing
Magazine, 25:50-58, 2008."
"505","2018-10-22","EDF R&D Lab","Saclay","STAGE INGÉNIERIE LINGUISTIQUE
SUJET 2019: Exploration, analyse, modélisation et représentation de
données semi-structurées à des fins d'utilisation pour la recherche et
la visualisation d'information.
DURÉE : 6 MOIS ENVIRON
Lieux : EDF R&D Lab Saclay et déplacements sur sites industriels en
France

------------------------------------------------------------------
1.	 CONTEXTE INDUSTRIEL 
------------------------------------------------------------------

L'approvisionnement en énergie compte parmi les enjeux politiques,
économiques et écologiques décisifs pour l'avenir. La satisfaction de la
demande énergétique mondiale et le respect des objectifs internationaux
de lutte contre le changement climatique imposent de développer des
énergies décarbonées. Le nucléaire apparaît ainsi comme un élément du
mix énergétique du futur.
Dans ce domaine où l'ensemble des intervenants doit être irréprochables
en matière de sûreté et de radioprotection, l'exploitant doit respecter
les Règles générales d'exploitation (RGE). Les RGE sont un recueil de
règles approuvées par l'Autorité de Sûreté Nucléaire qui définissent le
domaine autorisé de fonctionnement de l'installation et les
prescriptions de conduite associées. En effet, tel le Code de la Route,
les RGE regroupent l'ensemble des consignes à respecter par les
exploitants, pour garantir le meilleur niveau de sûreté de leurs
centrales.
Dans le cadre des réflexions associées à la transition numérique du
groupe EDF il s'agit d'instruire comment l'intégration d'outils «
intelligents » du Traitement Automatique de la Langue Naturelle écrite
pourrait soutenir l'utilisation des nouvelles RGE en facilitant
l'analyse exhaustive et l'interprétation de ses prescriptions par les
différentes fonctions concernées.

------------------------------------------------------------------
2.	 SUJET DU STAGE
------------------------------------------------------------------

Le stage consistera à participer à l'étude sur l'apport des TALN pour
faciliter la consultation, l'analyse et l'interprétation des règles
générales d'exploitation d'une centrale nucléaire.
Plus précisément, il s'agira de:
- Participer à l'analyse du besoin et s'approprier le use case retenu ;
- pré traitement : mettre sous forme exploitable pour des analyses et
  traitements automatiques, un document rédigé en français en chapitres
  et sous-chapitres
- Exploration des données (analyses statistiques ou linguistiques)
- Résoudre le use case
- Constituer les ressources
- Formater les données ;
- Proposer des représentations, parcours, réponses compte tenu du use
  case retenu
- Evaluer les propositions retenues.

Au terme du stage le stagiaire pourra proposer :
- Une documentation technique
- Le transfert et dépôt du code à l'équipe
- Un ou des prototypes des différentes propositions étudiées.
Il s'agira ensuite de mettre en perspective les éléments issus de ces
différentes propositions compte tenu des besoins, traitements et
environnements techniques identifiés.

*** Les avantages du stage 
Au sein de la R&D du groupe EDF ce stage vous permettra :
- De mettre en oeuvre des outils d'analyse de données non structurées ;
- De mettre en oeuvre des outils d'analyse et de représentation de
  données semi structurées ;
- D'interagir avec des experts en text mining et ergonomie ;
- D'être force de proposition dans un projet pluridisciplinaire dès les
  phases amonts de conception ;
- De participer à la phase amont d'un projet industriel.


------------------------------------------------------------------
3.	COMPETENCES REQUISES
------------------------------------------------------------------

Connaissance du langage python
Connaissance d'outils de TALN
Travail en équipe
Aisance relationnelle
Aisance rédactionnelle
Capacités d'adaptation et d'initiatives
Anglais lu

------------------------------------------------------------------
4.	INFORMATIONS PRATIQUES
------------------------------------------------------------------

1 - CONTACTS	
	Julien Kahn (Tuteur)	julien.kahn@edf.fr
	Delphine Lagarde	delphine.lagarde@edf.fr 
	Meryl Bothua	meryl.bothua@edf.fr

2 - Lieu du stage	
	EDF R&D Lab Saclay
	Département PErformance et prévention des Risques Industriels du
           parC par la simuLation et les EtudeS (PERICLES)
	Groupe Facteurs Organisationnels et Humains (FOH)
	7, boulevard Gaspard Monge 91120 PALAISEAU, FRANCE

3 - Date & Durée 
	2019 - 6 mois environ

4 - Rémunération
	A définir (environ 1.000¤/mois)"
"506","2018-10-22","Orange Labs","Lannion","Intitulé du stage : « Evaluation des systèmes de dialogue à chaque tour
de parole à partir de la satisfaction utilisateur»

Entité : Orange Labs (Lannion). Equipe NADIA (Natural Language Dialogue)
Contact : Lina Rojas (linamaria.rojasbarahona@orange.com)

Synthèse de la mission :

L'objectif du stage est d'étudier la corrélation entre les métriques
objectives (par exemple : le nombre de tours, les raccrochages, les
répétitions, les mots utilisés, etc.) et la satisfaction globale de
l'utilisateur donnée à la fin du dialogue en utilisant un modèle de
régression profond.

Pour cela, nous utiliserons le corpus DATCHA et ses annotations. Le
corpus DATCHA est une collection de conversations entre les opérateurs
et les clients du service d'assistance du chat Orange. Le corpus
comprend des annotations de la satisfaction de l'utilisateur sur les
thèmes suivants : accompagnement, écoute, conseil, solution et
recommander. [1,2]. Ces annotations sont issues des enquêtes de
satisfaction remplies par les clients à la fin de chaque conversation.

Le calcul de la récompense est un point clé de l'apprentissage par
renforcement en dialogue. La récompense est utilisée par l'utilisateur
(un humain) pour évaluer le système (la machine). La récompense peut
être vue comment une combinaison des métriques objectives et des
métriques subjectifs (la satisfaction de l'utilisateur) [3,4].

Dans ce stage, vous devrez dans un premier temps trouver les métriques
objectives qui peuvent affecter la satisfaction utilisateur. Pour cela,
vous utiliserez des métriques objectives déterminées à chaque tour de
parole en fonction du contexte (les tours de parole précédentes). Vous
pouvez également analyser les caractéristiques appris par les modèles
disponibles [2] et vous devrez implémenter un modèle de régression
profond similaire aux modèles proposés dans les travaux [3 et 4].


[1] Damnati, G., Guerraz, A. & Charlet, D. Web chat conversations from
    contact centers: a descriptive study. In LREC (2016).
[2] Auguste, J., Charlet, D., Damnati, G., Favre, B. & Béchet,
    F. Évaluation automatique de la satisfaction client à partir de
    conversations de type"" chat"" par réseaux de neurones récurrents avec
    mécanisme d'attention. Auto-encoding variational bayes. arXiv
    preprint arXiv:1312.6114 (2013).
[3] M.  Walker,  D.  J.  Litman,  C.  A.  Kamm,  and  A.  Abella,
    ""PARADISE: a framework for evaluating spoken dialogue agents,"" in
    Proc. of the 8th EACL.Morristown, NJ, USA: ACL, 1997, pp.271-280.
[4] A. Schmitt, B. Schatz, and W. Minker, ""Modeling and predicting
    quality  in  spoken  human-computer interaction,""  in Proc.  of  the
    12th SIGDial Conference. Portland, Oregon, USA: ACL, Jun. 2011,
    pp. 173-184.

Détail de la mission :

L'objectif de votre travail de recherche sera de :
- Analyser le corpus DATCHA et ses annotations.
- Trouver les caractéristiques importantes pour la satisfaction de
  l'utilisateur. (voir les caractéristiques extraites par les modèles
  présents dans [2]).
- Implémenter une régression avec deep learning pour calculer l'impact
  de métriques objectives (les caractéristiques identifiées dans l'étape
  précédente) sur la satisfaction de l'utilisateur.

Vous réaliserez vos travaux au sein d'une équipe pluridisciplinaire
menant à la fois des activités de recherche et de développement
logiciel.

Profil / Compétences :
Dans le cadre de votre formation bac+5 (école ingénieur ou master 2
informatique ou statistiques), vous êtes à la recherche d'un stage de 6
mois.
- Vous avez des connaissances en statistiques et informatique.
- Des connaissances en Python sont impératives.
- Des connaissances en apprentissage statistique sont requises."
"507","2018-10-22","CS","Le Plessis-Robinson","Stage - Extraction de grammaires à partir de banques d'arbres (H/F) - Le Plessis-Robinson - CS
Publiée le: 3/10/2018

Partager avec:

Résumé de l'offre

    Type de contrat:
    Alternance / Stage
    Lieu:
    Le Plessis-Robinson

Description de l'offre

Avec 1800 collaborateurs pour un chiffre d'affaires de 170 millions
d'euros en 2017, CS s'affirme comme un concepteur, intégrateur et
opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense, de
l'Aéronautique, du Spatial, de l'Énergie, du Transport, des secteurs
public et privé. CS réalise environ 80% de ses projets au forfait et
est coté sur le marché Euronext Paris.

Afin de renforcer notre équipe parisienne de la Business Unit Défense,
Sécurité & ATM, nous recherchons un stagiaire - Extraction de
grammaires à partir de banques d'arbres (H/F)

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les pilotes au travers d'échanges vocaux. Une des
activités de la BU DSA est de concevoir et de réaliser une gamme de
produits incluant systèmes de communication vocale (VCS),
enregistreurs et simulateurs.

Dans ce contexte, nous souhaitons élaborer des analyseurs syntaxiques
couvrants en nous appuyant sur les grammaires STCG, qui sont des
grammaires de correspondances chaînes-arbres. Le stage aura pour but
d'étudier la faisabilité d'un outil transformant une banque d'arbres
en une grammaire STCG probabilisée et la réalisation de cet outil.

En tant que stagiaire, vos missions seront les suivantes :

- État de l'art des grammaires (hors contexte, TAG...), statistiques ou
  non, générées à partir de banques d'arbres

- Étude des banques d'arbres disponibles pour le français (FTB,
  Sequoia...) et de leur utilisabilité dans un cadre commercial

- Développement d'un outil transformant une banque d'arbres en
  grammaire STCG

- Rédaction d'un rapport

Profil requis

Étudiant(e) en 4ème ou 5ème année d'un cycle ingénieur ou équivalent,
vous êtes à la recherche d'un stage.

Vous disposez idéalement des compétences techniques suivantes :

- Grammaires formelles
- Banques d'arbres

Postuler en ligne : https://cs.jobs.net/fr-FR/job/stage-extraction-de-grammaires-a-partir-de-banques-darbres-h-f/J3Q3NF651S5V7PLNX6B"
"508","2018-10-22","CS","Le Plessis-Robinson","Stage - Couplage vision-audio pour reconnaissance vocale (H/F) - Le
Plessis-Robinson - CS

Publiée le: 3/10/2018
Résumé de l'offre

    Type de contrat:
    Alternance / Stage
    Lieu:
    Le Plessis-Robinson

Description de l'offre

Avec 1800 collaborateurs pour un chiffre d'affaires de 170 millions
d'euros en 2017, CS s'affirme comme un concepteur, intégrateur et
opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense, de
l'Aéronautique, du Spatial, de l'Énergie, du Transport, des secteurs
public et privé. CS réalise environ 80% de ses projets au forfait et
est coté sur le marché Euronext Paris.

Afin de renforcer notre équipe parisienne de la Business Unit Défense,
Sécurité & ATM, nous recherchons un stagiaire - Couplage vision-audio
pour reconnaissance vocale (H/F)

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les pilotes au travers d'échanges vocaux. Une des
activités de la BU DSA est de concevoir et de réaliser une gamme de
produits incluant systèmes de communication vocale (VCS),
enregistreurs et simulateurs.

Dans ce contexte, nous souhaitons évaluer ce qu'une exploitation
multimodale peut apporter à la qualité du signal de parole issu d'un
microphone intelligent et à la connaissance de l'état émotionnel des
locuteurs. En particulier, les pistes suivantes seront étudiées :

- traitement de l'audio : reconnaissance du locuteur, émotions...
- vision par ordinateur : identification du locuteur, lecture labiale....

 

En tant que stagiaire, vos missions seront les suivantes :

 - Faire un état de l'art des traitements pouvant aider à :
    - améliorer le signal vocal issus de microphones intelligents
        (localisation des locuteurs, évaluer son état émotionnel...)
    - évaluer l'état émotionnel des locuteurs (énervement...)

- Implémenter sur une plate-forme ARM (Raspberry Pi 3B)

    - les solutions de vision permettant de commander les microphones
  (direction pour le beamforming)

    - toute autre solution identifiée lors de l'état de l'art et
      pouvant améliorer la qualité du signal audio, par exemple dans
      le cas où plusieurs personnes parlent simultanément

- Rédaction d'un rapport

Profil requis

Étudiant(e) en 4ème ou 5ème année d'un cycle ingénieur ou équivalent,
vous êtes à la recherche d'un stage.

Vous disposez idéalement des compétences techniques suivantes :

- Traitement du signal
- Vision par ordinateur

Postuler :
https://cs.jobs.net/fr-FR/job/stage-couplage-vision-audio-pour-reconnaissance-vocale-h-f/J3V4JP75MLXMD5JK87Z"
"509","2018-10-22","CS","Le Plessis-Robinson","Stage - Liens entre les bases lexicales riches du français et Wordnet
& UNL (H/F) - Le Plessis-Robinson - CS

Publiée le: 3/10/2018

Résumé de l'offre

    Type de contrat:
    Alternance / Stage
    Lieu:
    Le Plessis-Robinson

Description de l'offre

Avec 1800 collaborateurs pour un chiffre d'affaires de 170 millions
d'euros en 2017, CS s'affirme comme un concepteur, intégrateur et
opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense, de
l'Aéronautique, du Spatial, de l'Énergie, du Transport, des secteurs
public et privé. CS réalise environ 80% de ses projets au forfait et
est coté sur le marché Euronext Paris.

Afin de renforcer notre équipe parisienne de la Business Unit Défense,
Sécurité & ATM, nous recherchons un stagiaire - Liens entre les bases
lexicales riches du français et Wordnet & UNL (H/F)

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les pilotes au travers d'échanges vocaux. Une des
activités de la BU DSA est de concevoir et réaliser une gamme de
produits incluant systèmes de communication vocale (VCS),
enregistreurs et simulateurs.

Dans ce contexte, nous souhaitons élaborer une base de données
lexicales riche et couvrante pour le français, en nous appuyant sur
des ressources libres disponibles comme le LVF et le DEM, NooJ ou
encore Apertium. Devant à terme être liées à d'autres langues, nous
souhaitons que les entrées de cette base de données soient reliées aux
synsets de Wordnet et aux UW d'UNL.

Le stagiaire participera aux tâches suivantes :

- Faire un état de l'art des ressources libres du français

- Réaliser une base de données lexicale en Sqlite à partir d'un
  ensemble cohérent de ressources libres

- Relier les entrées de la base de données obtenue aux synsets Wordnet
  et aux UW UNL

- Rédaction d'un rapport

Profil requis

Étudiant(e) en 4ème ou 5ème année d'un cycle ingénieur ou équivalent,
vous êtes à la recherche d'un stage.

Vous disposez idéalement des compétences techniques suivantes :

- Morphologie
- Lexicologie
- Sémantique (Wordnet, UNL)
- Bases de données lexicales

Postuler : 
https://cs.jobs.net/fr-FR/job/stage-liens-entre-les-bases-lexicales-riches-du-francais-et-wordnet-unl-h-f/J3S3PS6TBCN451RG0QD"
"510","2018-10-22","CS","Paris","Stage - Conception et réalisation d'une ontologie spécialisée (H/F) - Paris - CS
Publiée le: 11/10/2018

Résumé de l'offre

    Type de contrat:
    Alternance / Stage
    Lieu:
    Paris

Description de l'offre

Avec 1800 collaborateurs pour un chiffre d'affaires de 170 millions
d'euros en 2017, CS s'affirme comme un concepteur, intégrateur et
opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense, de
l'Aéronautique, du Spatial, de l'Énergie, du Transport, des secteurs
public et privé. CS réalise environ 80% de ses projets au forfait et
est coté sur le marché Euronext Paris.

Afin de renforcer notre équipe parisienne de la Business Unit Défense,
Sécurité & ATM, nous recherchons un stagiaire -Conception et
réalisation d'une ontologie spécialisée (H/F).

Dans le domaine du contrôle du trafic aérien, les contrôleurs
interagissent avec les pilotes au travers d'échanges vocaux. Dans la
cadre de la BU Défense, Sécurité & ATM, CS conçoit et réalise une
gamme de produits incluant systèmes de communication vocale (VCS),
enregistreurs et simulateurs.  Dans ce contexte, nous souhaitons
développer une ontologie couvrant nos principaux produits.

Les missions du stagiaire seront les suivantes :

- Faire un état de l'art des éditeurs d'ontologies, des outils pour
  les construire et les stocker, et des moteurs d'inférence permettant
  de les interroger

- Comparer les intérêts respectifs de langages contrôlés tels que ACE
  et SBVR par rapport aux langages d'ontologies, pour opérer des
  raisonnements

- Faire un état de l'art des langages d'ontologies utilisables et
  faire un choix justifié d'un langage et d'un éditeur d'ontologie

- Recueillir le vocabulaire (avec sa sémantique) et les règles,
  souvent implicites, pour une partie restreinte du domaine

- Choisir un ou plusieurs raisonneurs pour les tests

- Définir un jeu de questions et tester l'ontologie créée en utilisant
  des raisonneurs

Profil requis

Étudiant(e) en 4ème ou 5ème année en informatique, école d'ingénieur
ou équivalent universitaire, vous êtes à la recherche d'un stage ou
d'une alternance.
 
Vous disposez idéalement des compétences techniques suivantes :

- Ontologies

- Logiques (commune, premier ordre, description ...)

- Langages formels

Postuler : https://cs.jobs.net/fr-FR/job/stage-conception-et-realisation-d%E2%80%99une-ontologie-specialisee-h-f/J3T51Y6MXQHF6VKP28W"
"511","2018-10-22","CS","Paris","Stage - Maquettage de déconvertisseur UNL (H/F) - Paris - CS
Publiée le: 2/10/2018

Résumé de l'offre

    Type de contrat:
    Alternance / Stage
    Lieu:
    Paris

Description de l'offre

Avec 1800 collaborateurs pour un chiffre d'affaires de 170 millions
d'euros en 2017, CS s'affirme comme un concepteur, intégrateur et
opérateur de systèmes critiques de tout premier plan. Nos clients
européens et mondiaux sont dans les secteurs de la Défense, de
l'Aéronautique, du Spatial, de l'Énergie, du Transport, des secteurs
public et privé. CS réalise environ 80% de ses projets au forfait et
est coté sur le marché Euronext Paris.

Afin de renforcer notre équipe parisienne de la Business Unit Défense,
Sécurité & ATM, nous recherchons un stagiaire - Maquettage de
déconvertisseur (H/F).

Une des activités de la BU DSA est de créer des déconvertisseurs du
français et de l'anglais performants. Ces programmes, basés sur le
framework de traduction automatique Ariane, génèrent du texte en
français et en anglais à partir d'une représentation interlingue
unique exprimée sous forme de graphes UNL.

Votre mission consistera à réaliser des déconvertisseurs pour le
français et l'anglais, et de les évaluer sur un corpus de test. Pour
cela,

- Vous vous familiariserez avec les notions le langage UNL, les
  langages de programmation linguistiques Ariane (EXPANS, ROBRA et
  SYGMOR), la maquette existante de déconversion du français et la
  nouvelle génération structurale.

- Vous vous appuyerez sur une maquette existante de déconversion du
  français. L'apport essentiel sera de remplacer la génération
  syntaxique actuelle par une génération syntaxique plus performante
  [Chappuy, 2011b]. Cette substitution nécessitera de mettre en
  cohérence le jeu de variables de cette nouvelle génération
  syntaxique avec :

    -  en amont celui provenant du dictionnaire UNL-FR,
    -  en aval celui attendu par la génération morphologique du français.

- Enfin, il s'agira de faire le point sur les éditeurs de graphes UNL
  disponibles et d'écrire les graphes UNL d'une partie représentative
  des phrases d'un corpus fourni par CS.

Profil requis

Étudiant(e) en 4ème ou 5ème année, école d'ingénieur ou équivalent
universitaire, vous êtes à la recherche d'un stage ou une alternance
de 6mois.
 
Vous disposez idéalement des compétences techniques suivantes :

- Traitement automatique des langues, syntaxe, sémantique, morphologie,
- C/C++ 
- Python

Postuler : 
https://cs.jobs.net/fr-FR/job/stage-maquettage-de-deconvertisseur-unl-h-f/J3V53S6J9PSY9P8VM1Z"
"513","2018-10-29","CEA","Palaiseau","Offre Stage Master 2 / ingénieur

Titre du stage: Apprentissage à partir de connaissances incertaines pour
l'annotation automatique de textes

Mots-clés : apprentissage automatique, traitement automatique des
langues, réseau de neurones, adaptation au domaine

Lieu : CEA (NanoInnov, Palaiseau)

Durée : 4 à 6 mois
Date de début : printemps 2019

Laboratoire d'accueil:
Au coeur du Plateau de Saclay (Ile-de-France), l'institut CEA LIST
focalise ses recherches sur les systèmes numériques intelligents. A sein
de cet institut, le LVIC (Laboratoire de Vision et d'Ingénierie des
Contenus) mène ses recherches dans les domaines de la Vision par
Ordinateur (Computer Vision) et l'analyse automatique de texte avec le
défi d'extraire et d'organiser l'information à partir de documents
faiblement ou non structurés (texte, image, vidéo, réseaux de capteurs).

Contexte du stage:
Les investissements en recherche dans Le traitement automatique du
langage sont en très grande croissance pour deux raisons principales:

- l'abondance des données, le 'big data', suscite la convoitise de
  beaucoup d'opérateurs mais toute la partie non structurée de ces
  données ne peut être véritablement exploitée qu'avec un traitement
  linguistique de base.
  
- de très grands progrès ont été réalisés récemment grâce aux techniques
  d'apprentissage et en particulier celles à base de réseau de neurones
  en s'appuyant sur les représentation distribuées des mots ou word
  embeddings (1).
  
Les applications de ces technologies sont multiples dans la société du
numérique : moteur de recherche, traduction automatique, outils de
veille ou de recommandations... Ce stage s'inscrit dans les activités de
Traitement Automatique du Langage du Laboratoire Vision et Ingénierie
des Contenus du CEA List. Le laboratoire développe sa propre technologie
d'analyse du texte qui est diffusée en open source avec la plate-forme
Lima : https://github.com/aymara/lima.

Sujet du stage:

Les systèmes de traitement linguistique ont largement adopté les
technique d'apprentissage supervisé : à partir de corpus annoté
(c'est-à-dire des textes pour lesquels des spécialistes de la langue ont
annoté chaque mot avec des informations sur le découpage, sur la
morphologie, sur la structure de la phrase, etc.), le système apprend un
modèle qui lui permet d'analyser des textes en entrée.

Quand on ne dispose pas de corpus annoté pour une tâche d'apprentissage
(par exemple pour traiter une nouvelle langue) ni du budget pour le
constituer, on réalise de façon automatisée un corpus dit ""synthétique""
par exemple issus d'une projection d'annotation cross-lingue (2) ou par
alignement d'une base de connaissances sur le texte (3). Bien sûr, ces
corpus ""synthétiques"" contiennent des erreurs ou plutôt des incertitudes
sur les annotations.

L'objectif du stage consiste à modéliser ces incertitudes et à les
exploiter dans le processus d'apprentissage et à évaluer les
amélioration des modèles produits. Les expérimentations se feront en
s'appuyant sur un framework de réseaux de neurones.

Travail attendu:
- Recherche bibliographique
- Expérimentation d'architecture innovantes à base de réseaux de
  neurones et évaluation

Le 1er sujet d'expérimentation pourra être l'annotation morphosyntaxique
par projection directe sur un corpus bilingue aligné.
L'apprentissage et l'évaluation se feront à partir de corpus annotés
fournis.

Compétences requises:
- bonne maîtrise d'un langage de programmation: C++ ou python
- bonne connaissances en statistique et connaissance de base des
  technologies d'apprentissage

Le goût pour les langues, le langage de façon générale et la capacité à
échanger avec les autres est un plus.

Contacts:
olivier.mesnard@cea.fr

Références:

(1) Ronan Collobert & al, 2011, Natural Language Processing (Almost)
    from Scratch

(2) Jörg Tiedemann and Zeljko Agic,  2016. Synthetic treebanking for
    cross-lingual dependency parsing

(3) Raphael Hoffmann & al 2011.  Knowledge-based weak supervision for
    information extraction of overlapping relations"
"514","2018-10-29","Orange Labs","Lannion","Intitulé du stage : « Extraction non-supervisée des bases de
connaissances à partir d'un corpus de Dialogue.»

Entité : Orange Labs (Lannion). Equipe NADIA (Natural Language Dialogue)
Contact : Lina Rojas (linamaria.rojasbarahona@orange.com)


Synthèse de la mission :

Le corpus DATCHA est une collection de conversations entre les
opérateurs et les clients du service d'assistance du web chat Orange. Le
corpus comprend des annotations linguistiques: syntaxiques, sémantiques,
etc. [1].

Néanmoins, il n'y a pas d'annotations qui décrivent le sujet de la
conversation. Par exemple : le problème à résoudre, les étapes
nécessaires au diagnostic et à la résolution du problème. Les ontologies
spécifiques au domaine ont un rôle central dans les systèmes de
dialogue.

Plusieurs méthodes d'apprentissage non supervisées ont été utilisées
pour le traitement automatique des langues : clustering, co-clustering
[2], la sémantique distributionnelle [3], l'analyse sémantique latente
(LSA) [4], l'allocation de Dirichlet latente (LDA) [5] ainsi que des
techniques de deep learning (Restricted Boltzmann Machines [6] et
Variational Autoencoders [7]).

L'objectif de ce stage est d'appliquer une méthode non supervisée de
deep learning pour l'extraction des connaissances du domaine à partir du
corpus DATCHA et de la comparer aux autres solutions disponibles
(co-clustering et LDA). Parmi les connaissances à extraire on trouvera
les concepts qui décrivent les services, le script du diagnostic, les
solutions adoptées. Il sera tout à fait possible d'utiliser les
annotations disponibles comme les annotations en actes de dialogue.



[1] Damnati, G., Guerraz, A. & Charlet, D. Web chat conversations from
contact centers: a descriptive study. In LREC (2016).

[2] Boullé, M. Data grid models for preparation and modeling in
supervised learning. In Guyon, I., Cawley, G., Dror, G.  & Saffari,
A. (eds.) Hands-On Pattern Recognition: Challenges in Machine Learning,
volume 1, 99-130 (Microtome Publishing, 2011).

[3] Lund, K. & Burgess, C. Producing high-dimensional semantic spaces
from lexical co-occurrence. Behav. research methods, instruments, &
computers 28, 203-208 (1996).

[4] Dumais, S. T. Latent semantic analysis. Annu. review information
science technology 38, 188-230 (2004).

[5] Blei, D. M., Ng, A. Y. & Jordan, M. I. Latent dirichlet
allocation. J. machine Learn. research 3, 993-1022 (2003).

[6] Larochelle, H. & Bengio, Y. Classification using discriminative
restricted boltzmann machines. In Proceedings of the 25th international
conference on Machine learning, 536-543 (ACM, 2008).

[7] Kingma, D. P. & Welling, M. Auto-encoding variational bayes. arXiv
preprint arXiv:1312.6114 (2013).

Détail de la mission :
L'objectif de votre travail de recherche sera de :

- Analyser le corpus DATCHA et ses annotations.
- Implémenter une solution non supervisée du deep learning pour extraire
  les concepts spécifiques aux domaines du DATCHA
- Comparer votre modèle avec des solutions internes Orange
  (co-clustering) ou disponibles dans les modules python (LDA).

Vous réalisez vos travaux au sein d'une équipe pluridisciplinaire menant
à la fois des activités de recherche et de développement logiciel.

Profil / Compétences :

Dans le cadre de votre formation bac+5 (école ingénieur ou master 2
informatique ou statistiques), vous êtes à la recherche d'un stage de 6
mois.
- Vous avez des connaissances en statistiques et informatique.
- Des connaissances en Python sont impératives.
- Des connaissances en apprentissage statistique sont requises.


Lina Rojas
IMT/OLS/DIESE/DIA/NADIA
Senior Research Engineer/Ingénieure de recherche senior IA&Dialogue
tél. +33 (0)2 96 07 04 10
linamaria.rojasbarahona@orange.com"
"515","2018-11-05","Naver Labs","Grenoble","Master/PhD Internship - Deep Machine Reading

 

NAVER LABS Europe's mission is to advance the state-of-the-art in
Ambient Intelligence, while paving the way for these innovations into
a number of NAVER flagship products and services. This includes
research in models and algorithms to give humans faster and better
access to data and to allow them to interact with technology in
simpler and more natural ways.

In this context, the field of Machine Reading has recently emerged as
a possible continuation of the tasks of Natural Language
Processing. Given a large set of passages of text associated with
questions and answers, our goal consists of learning a question
answering system solely from these examples. As research groups
dedicated to Machine Reading around the globe have started to produce
encouraging results, this task challenges our current understanding of
deep learning and machine comprehension.

In this internship, the successful candidate will be involved in the
design and development of novel models for machine comprehension
applied at the scale of NAVER in the context of electronic
encyclopedia and social media understanding. Finally, at NAVER LABS we
encourage participation in the academic community. Our researchers
collaborate closely with universities and regularly publish in venues
such as ACL, EMNLP, KDD, SIGIR, ICML and NIPS.

Requirements

- Master and/or Ph.D. in machine learning with a strong interest in
    Deep Learning.

- Knowledge of statistical and deep learning application to NLP.

- Strong development skills of relevant frameworks like pytorch and/or
  tensorflow.

References

    Gated End-to-End Memory Networks , Fei Liu and Julien Perez, EACL
    2017
    
    Dialog State Tracking, a machine reading approach using memory
    networks , Julien Perez and Fei Liu, EACL 2017
    
    ReviewQA: a relational aspect-based opinion reading dataset ,
    Quentin Grail and Julien Perez, CAP'2018

Start Date ASAP
Duration 6 months minimum

Application instructions


To submit an application, please send your CV, cover letter and the
names of at least two references to julien.perez@naverlabs.com and
dl_candidates@naverlabs.com"
"516","2018-11-05","Naver Labs","Grenoble","Meal Finder: fine grained information extraction from web-scale image database

 

Does a restaurant have your favourite dish? What's the price of this
dish? Have they vegetarian options? Do they have a kid's menu?

When looking for a restaurant, all these common questions are not
necessarily answered by your favourite search application or social
web portal So, as a user, when you have found a nice restaurant, you
usually end up using additional sources of information to answer these
questions, because the data is not available directly or in an easy
way. A great place to look at is directly on the restaurant's website,
to see if they provide additional information (like an updated menu).

The goal of this internship is to investigate how to facilitate this
Information Retrieval task by automatically enriching a restaurant
database with unstructured information available on the Internet.

The student will have to help design and implement an information
extraction tool for restaurant menus. More precisely, the tool should
be able to structure a menu, from an image representation, into its
main structures and sections, extracting first information on dishes
(name, description, price(s)) or on the restaurant itself (address,
opening hours, phone number).

The student will work with a multi-disciplinary team with expertise in
Computer Vision, OCR, Document Structure Analysis and Information
Extraction . A production database gathering more than 100 million
places, the associated user reviews, images and menus will be
available to test and develop the system. At Naver Labs Europe we
encourage participation in the academic community and our researchers
publish regularly at top venues in NLP, machine learning and computer
vision.

Start Date asap
Duration 5-6 months

Application instructions

- Student at Master (research-oriented) or PhD level.
- Knowledge of neural networks models and Conditional Random Fields
- Good coding skills in Python

http://www.europe.naverlabs.com/NAVER-LABS-Europe/Internships/Meal-Finder-fine-grained-information-extraction-from-web-scale-image-database"
"517","2018-11-05","Naver Labs","Grenoble","Honest Product Reviews

 

An increasing amount and value of information about products and
places is stored in collections of user reviews. This information is
messy, often contradictory or redundant but taken together hides
troves of insights that users without time to read them all are
interested in.

In this internship you will explore recent summarization techniques
and apply them to the problem of creating a unified review which
reflects that wisdom of the crowd.

At Naver Labs Europe you will interact with researchers working in the
latest developments of machine learning and natural language
processing, apply them to our data using our GPU cluster. We regularly
publish in top conferences, release data-set and otherwise interact
with our academic collaborators.

 

Requirements

- PhD or Master (research-oriented) level
- Knowledge of deep learning as applied to NLP
- Good coding skills, including at least one the major deep learning
toolkits (preferably pytorch)

Duration 5-6 months

Application instructions

To apply, please send a mail with CV and cover letter to
matthias.galle@naverlabs.com"
"518","2018-11-05","GeoTrend","Toulouse","Offre de Stage de Master / Fin d'étude Ingénieur :

Extraction de relations économiques à partir du texte



  * Cadre du stage

La société GeoTrend développe une plateforme innovante de « Business
Discovery » permettant de donner une vision rapide et complète sur
n'importe quel marché économique. Cette plateforme analyse en temps réel
des milliers de pages web pour extraire les principaux acteurs du
marché, les relations qui les lient (partenariat, compétition, etc.) et
de nombreuses 'autres informations utiles à la compréhension du marché
cible. Le coeur de notre métier consiste donc à développer des briques de
Traitement Automatique du Langage et de Machine Learning et de les faire
tourner sur des plateformes de Cloud Computing. Ce stage permettra de
travailler à la fois sur des problématiques scientifiques récentes et
sur des technologies de pointe. Nous souhaitons proposer ce stage en
collaboration avec l'équipe MELODI du laboratoire IRIT de Toulouse. Une
poursuite dans le cadre d'une thèse CIFRE est envisagée sur la base des
mêmes problématiques.


  * Objectifs

L'objectif du stage est d'améliorer le système d'extraction de relations
actuel qui se base uniquement sur des règles expertes en proposant un
nouveau modèle de Machine Learning.

Un data-set d'environ 2000 phrases a été annoté manuellement pour aider
le stagiaire dans cette tâche. Ce data-set pourra être utilisé pour
évaluer de manière précise le modèle proposé mais ne suffira pas à
constituer un corpus d'apprentissage. En effet, les modèles de Machine
Learning récents (particulièrement les Réseaux Neurones) nécessitent
beaucoup de données d'apprentissage. Des travaux récents proposent donc
de construire ces corpus de manière automatique en utilisant des règles
ou des bases de connaissances externes (Ratner et al. 2016; Ratner et
al. 2018). Les labels ainsi produits contiennent du bruit mais on peut
modéliser les erreurs commises par ces différentes règles pour améliorer
les résultats.

La première étape du stage consistera à faire un état de l'art plus
approfondi sur l'extraction de relations. Une piste ou plusieurs seront
ensuite retenues pour être mises en oeuvre, évaluées et comparées.


* Compétences recherchées

  * Modèles de Machine Learning (SVM, LSTM, etc.)
  * Intérêt pour le Traitement Automatique du Langage (analyse
    syntaxique, word embeddings, etc.)
  * Frameworks: python, sklearn, ...


* Contacts :

  * Grégoire Sigel, gregoire@geotrend.fr
  * Farah Benamara, Benamara@irit.fr <mailto:Benamara@irit.fr>


* Conditions:

  * Localisation : Toulouse, dans les locaux de Geotrend et
    ponctuellement à l'IRIT.
  * Date de démarrage : à partir de février 2019
  * Durée : de 4 à 6 mois
  * Indemnité : Indemnité légale
  * Suite envisagée en Thèse CIFRE
  * Ressources bibliographiques

Ratner, Alexander, Stephen H. Bach, Henry R. Ehrenberg, et
al.2018Snorkel: Rapid Training Data Creation with Weak
Supervision. InVLDB.

Ratner, Alexander J, Christopher M De Sa, Sen Wu, Daniel Selsam, and
Christopher Ré2016Data Programming: Creating Large Training Sets,
Quickly. InNIPS pp. 3567-3575.

*Grégoire Sigel*
CTO & Co-foundeur, Geotrend
+33(0)6 26 98 16 84 gregoire@geotrend.fr
www.geotrend.fr
Airbus BizLab 57 Avenue Jean Monnet, 31770 Colomiers"
"519","2018-11-05","Botfuel","Paris","6 Month NLP Internship Offer

Botfuel (www.botfuel.io) is a Paris-based startup specialized in
chatbots and conversational intelligence. We are looking for an intern
to join our NLP team, starting in the spring of 2019 (the exact date is
flexible and depends on your school/academic constraints). Please see
below for the internship details.

If you are interested or have any questions, please do not hesitate to
contact Zorana Ratkovic, Lead NLP Engineer (zorana@botfuel.io).

NLP Internship Offer

The Company

Botfuel (www.botfuel.io) specializes in chatbots and conversational
intelligence. We offer a chatbot-building framework for enterprises
looking to automate customer relationships by deploying conversational
services/chatbots at scale. Since 2016, we have been developing Natural
Language Processing (NLP) technologies in order to provide our customers
with a great conversational experience.

The Internship

At Botfuel, we develop Natural Language Understanding (NLU) services in
order to understand and interpret user utterances and requests. The NLP
team works on a variety of dialog-related problems, such as intent
classification, information extraction and coreference resolution.

What you'll be doing:

   - Researching, developing, testing and deploying NLP methods in order
     to improve the quality of Botfuel's NLU services
   - Collaborating with other member of the NLP team, including
     researchers, engineers and computational linguists

Who You Are

   - Pursuing an Engineering degree or a Masters degree in Artificial
     Intelligence, Data Science, NLP, Machine Learning (ML) or a related
     field
   - Experience in Python
   - Experience in NLP and/or ML
   - Capacity to work independently, as well as collaborate within a
     team
   - Interest in chatbots/dialogs/NLU is a plus

Practical Information
   - Duration: 6 months, starting in spring 2019
   - Location: Paris, France (75002)
   - Remuneration: depending on experience


If you are interested, please send your CV to Zorana Ratkovic, our Lead
NLP Engineer (zorana@botfuel.io)."
"520","2018-11-08","IRIT","Toulouse","**Title**

Detecting intentions during crisis events

**Background and objectives**

Social media platforms offer great opportunities to identify public
commitments to intentions and desires/plans to act from user-generated
contents. Automatically detecting intentions can have many potential
applications, such as in commerce marketing (consumption intentions:
sell, purchase), security and defense (intention to attack, to connect
to terrorist organizations), health (intention to suicide), and
emergency management (intentions to help, evacuate). Mining intentions
from texts can thus help decision makers to differentiate between
intentional and non-intentional messages (""I want to buy this great
phone"" vs.""Trump won the US election"") and to better identify the type
of intention behind each message which is a primordial step to help
companies, government, or institutions to better predict users' future
actions and thus improve their strategies.

The internship will focus on the development of an automatic intention
model on social media data which will foster the ability of public
services to take action quicker in crisis situations, by monitoring
user's expectations and intents.

The internship is funded by the French Interior Department (no French
citizenship required) within a joint project between Institut de
Recherche en informatique de Toulouse (IRIT-Toulouse University) and
Institut Jean Nicod (IJN-Ecole Normale Supérieure).

**Candidate profile**
The successful candidate will have one of the following profile:
- Msc or MA student in Computer Science, or Computational Linguistics.
- Experience in Natural Language Processing, and/or Machine Learning;

**Terms of the internship position**
- Duration: 5 months
- Starting date: from February to April 2019
- Location: IRIT, Toulouse University (France),

**Applications**
- A curriculum vitae together with a motivation letter should be sent to
Farah Benamara (farah.benamara@irit.fr), Véronique Moriceau
(veronique.moriceau@irit.fr) and Alda Mari (alda.mari29@gmail.com)
- Deadline for applications: position open until filled."
"521","2018-11-12","Linagora","Toulouse","Poste : Stage détection et formalisation des intentions dans les
emails

Réf. : Stage-2018-AssistantEmailIntentionDetection

Contrat : Stage de Fin d'études

Date de démarrage : ASAP (durée 6 mois)

Mots-clés : Intention dans les emails, Traitement Automatique des
Langues, Sémantique

Grâce à la compétence technique et l'engagement de ses 160
collaborateurs, LINAGORA est aujourd'hui le leader français sur le
marché très porteur du Logiciel Libre.  Nos clients sont en majorité
des grands comptes, public et privé.

Notre métier :

- L'édition de logiciels Open-Source innovants et répondant aux
besoins actuels et futurs du marché (bureau virtuel, assistant
intelligent pour l'entreprise, middleware SOA, sécurité, gestion des
identités).

- La prestation de services pour accompagner les grands projets
Open-Source : conseil, intégration/développement, maintenance,
formation des utilisateurs.

Linagora est présent en France (Paris, Marseille, Toulouse, Lyon) au
Vietnam (Hanoï), Quebec et Tunisie (Tunis).  Linagora participe à
diférent projets de recherche Européens H2020 (C2Net) et Français /
PSPC (OpenPaaS).

Nos principaux axes de recherche concernent la reconnaissance et la
compréhension de la parole, le « text mining », les architectures
middleware distribuées, le Cloud Computing, l'ingénierie
collaborative, la sécurité, les architectures Big-Data et les
communautés open-source.

CONTEXTE

La société Linagora (http://linagora.com) propose dans le cadre de son
projet de recherche Open-PaaS:NG des outils open-source innovants pour
améliorer le travail collaboratif en entreprise. La plate-forme
OpenPaaS (http://open-paas.org) est un outil de travail collaboratif
proposant plusieurs services tels que : gestion des mails et des
agendas partagés, édition collaborative temps-réel de documents, chat
et réseau social d'entreprise.

Dans ce contexte, nous nous intéressons au module de gestion des
mails. Nous voulons enrichir ce module avec des fonctionnalités de
recommandations à l'utilisateur qui s'appuient sur des techniques
sémantiques et des techniques de machine learning.

MISSION

Vous serez intégré au Linagora Labs (https://research.linagora.com) au
sein d'une équipe de recherche pluridisciplinaire à forte composante
Intelligence Artifcielle, pour améliorer un module d'identifcation et
de formalisation des intentions dans les emails. Une intention est le
but véhiculé par le mail. Nous nous focaliserons sur :

1. l'identifcation et la formalisation des intentions dans des
échanges emails répétitifs (comme la prise de rdv, les échanges de
pièces jointes, l'envoi de candidatures, les appels d'ofres, etc.).

2.  Pour chaque intention identifée, la ou les canevas des réponses
nécessaires pour répondre à l'intention.

Plus précisément, Linagora a développé un module smart reply
(https://ci.linagora.com/zsellami/automatic-email-answering)
permettant de proposer des réponses aux emails de RDV. L'identifcation
des intentions s'appuie sur une approche symbolique qui consiste à
rechercher dans le texte des éléments linguistiques (verbes, syntagmes
nominaux, entités nommées) qui manifeste un RDV. La formalisation de
ces intentions est intégrée dans une ontologie en utilisant les
principes du formalisme FrameNet
(http://asfalda.linguist.univ-paris-diderot.fr/frameIndex.xml).

La notion principale de FrameNet est le cadre conceptuel (Frame). Dans
notre cas, un Frame correspondra a une intention. Chaque Frame
comportera :

1.  des unités lexicales qui indique la présence d'une intention dans
un mail ou un sous-ensemble de phrases dans le mail (exemple, propose
un rdv, convenir à un rdv, changer de date de réunion, etc.)

2.  des rôles à instancier dans le Frame. Par exemple, pour un Frame
de suggestion de disponibilités, les dates/heures auront le rôle
créneau dans ce Frame.

PROFIL

Vous êtes issu d'une formation supérieure bac+5 et êtes en recherche
d'un stage de fn d'étude.

Vous disposez de :

1. Bonnes compétences en linguistique et en analyses de corpus
textuels.

2. Bonnes compétences en programmation Python ou Java.

3. Bonnes connaissances et compétences en Traitement Automatique des
Langues. La maîtrise d'un ou de plusieurs dependency parser (comme
core nlp, spacy python, GATE, etc.) et extracteurs d'entités nommées
(comme Gate, DBPedia spotlight, Duckling Facebook, etc.) serait un
plus ;

Vous saurez vous montrer passionné, rigoureux ainsi que faire preuve
d'autonomie. Vous avez un goût certain pour la découverte et
l'expérimentation, vous êtes force de proposition et êtes capable
d'argumenter vos choix techniques. Vous partagez notre choix de
privilégier des logiciels libres et de contribuer aux communautés
d'utilisateurs (listes, FAQ, HOWTO).

INFORMATIONS PRATIQUES

Contacts

Zied Sellami ou Jean-Pierre Lorré

zsellami@linagora.com, jplorre@linagora.com

Lieu du stage - Durée Toulouse - 6 mois

Société Linagora
Website : https://research.linagora.com / Twitter : @LinagoraLabs"
"522","2018-11-12","Linagora","Toulouse","Plateforme d'exploration de contenu textuel

Réf. : Stage-2018-NLP

Durée : 6 mois

Date de démarrage : ASAP 2018

ENVIRONNEMENT

Créée en 2000, Linagora (http://linagora.com) se positionne
aujourd'hui comme le leader français de l'Open Source.  Son but est de
promouvoir l'Open Source auprès des institutions publiques et privées
et d'accompagner ses clients vers leur indépendance numérique, en
proposant des produits de haute qualité, fruit du travail de
collaborateurs passionnés.  En pleine croissance et déjà présente sur
quatre continents, LINAGORA est à la recherche de nouveaux talents,
amoureux des technologies Libres et Open Source. Venez rejoindre une
équipe chaleu- reuse et une ambiance stimulante !

Notre métier :

- L'édition de logiciels Open-Source innovants et répondant aux
besoins actuels et futurs du marché (bureau virtuel, assistant
intelligent pour l'entreprise, middleware SOA, sécurité, gestion des
identités).

- La prestation de services pour accompagner les grands projets
  Open-Source : conseil, intégration/développement, maintenance,
  formation des utilisateurs.

CONTEXTE

Mots-clés : Traitement Automatique de la Langue (TAL) / Natural
Laguage Processing (NLP), annotation sémantique, indexation,
SolrTextTagger, Kibana, EalsticSearch, Open Linked Data

La société Linagora (http://linagora.com) propose dans le cadre de son
projet de recherche Open-PaaS:NG des outils open-source innovants pour
améliorer le travail collaboratif en entreprise. La plate-forme
OpenPaaS (http://open-paas.org) est un outil de travail collaboratif
proposant plusieurs services tels que : gestion des mails et des
agendas partagés, édition collaborative temps-réel de documents, chat
et réseau social d'entreprise.

Dans ce contexte, nous nous intéressons aux ressources textuelles de
cette plate-forme (emails, documents, pièces jointes dans les emails,
etc.). Nous voulons mettre en place un outil d'extraction de données
sémantiques (mots-clés, concepts et entités nommées) open-source.

MISSION

Vous serez intégré au Linagora Labs (https://research.linagora.com) au sein d'une équipe de re-
cherche pluridisciplinaire à forte composante Intelligence Artificielle.

Le contenu informationnel sous forme textuelle est prédominant dans
l'environnement des entreprises (mails, documents administratifs, CV,
comptes rendus de réunions, etc.). Ce type de contenu représente une
source riche en informations clés (chiffres clés de transactions, des
adresses mails, des contacts, etc.).

Paradoxalement, ce contenu est rarement exploité :

- En raison de la volumétrie usuelle de ces données, il est rarement
  possible d'exploiter manuellement ce contenu.

- En raison de la complexité de la structuration des données
textuelles, les technique traditionnelles de fouille de données ne
permettent pas d'en réaliser un traitement automatisé.

Dans ce contexte, les outils de Traitement Automatique de la Langue
(TAL / NLP) offrent une solution viable d'exploration et
d'exploitation de contenus textuels. En effet, ils permettent
d'extraire du texte des indicateurs saillants (termes, relations
lexicales, verbes, etc.). Pour cela, ces outils de TAL peuvent
s'appuyer sur des ressources externes comme des dictionnaires
d'entités nommées (Personnes, Lieux, Organisations) pour localiser des
indices précis. C'est ce que nous appelons l'annotation de textes.

Dans le cadre de ce stage, nous nous intéresserons plus précisément à
l'utilisation de dictionnaires sémantique ouverts (Open Linked Data)
comme DBPedia, Wikidata, Yago et FreeBase pour annoter sémantiquement
des documents textuels.

- Première objectif du stage : Tout d'abord, le stagiaire devra
recenser les principales ressources de données ouvertes exploitables
et de mettre en place un outil d'annotation sémantique capable
d'utiliser ces dictionnaires. La difficulté à lever est la volumétrie
des Open Linked Data (plusieurs millions d'entrées) et la
désambiguïsation des annotations polysémiques (exemple : Paris comme
Ville et Paris comme une Personne) .

- Deuxième objectif du stage : Le deuxième objectif du stage est de
mettre en place un outil d'exploration graphique des résultats de
l'outil d'annotation. Pour cela le stagiaire réalisera un état des
lieux de l'existant, identifiant les outils d'indexation et de
visualisation des indexes, tels que par exemple Kibana, solr,
ElasticSearch ... A l'issu de ce travail, l'outil cible sera choisit
collectivement Il devra définir des tableaux de bord à partir des
Charts disponibles. La difficulté à lever est la création d'un index
Solr à partir des annotations extraites.

PROFIL

Vous êtes issu d'une formation supérieure bac+5 et êtes en recherche
d'un stage de fin d'étude.

Vous disposez de :

1. Bonnes compétences en programmation Python ou Java. Connaître le
langage Scala serait un plus ;

2. Bonnes connaissances et compétences en Traitement Automatique des
Langues. La maîtrise d'un ou de plusieurs API (comme core nlp, spacy
python, GATE, etc.) et extracteurs d'entités nommées (comme Gate,
DBPedia spotlight, Duckling Facebook, etc.) serait un plus ;

3. Des compétences en Machine Learning et Deep learning seraient un
plus.

Vous saurez vous montrer passionné, rigoureux ainsi que faire preuve
d'autonomie. Vous avez un goût certain pour la découverte et
l'expérimentation, vous êtes force de proposition et êtes capable
d'argumenter vos choix techniques. Vous partagez notre choix de
privilégier des logiciels libres et de contribuer aux communautés
d'utilisateurs (listes, FAQ, HOWTO)

INFORMATIONS PRATIQUES

Contacts

Zied Sellami, Jean-Pierre Lorré

zsellami@linagora.com, jplorre@linagora.com

Lieu du stage - Durée Toulouse - 6 mois

Société Linagora

Website : https://research.linagora.com / Twitter : @LinagoraLabs"
"523","2018-11-12","STL","Lille","Phonétique pour les besoins cliniques des orthophonistes

L'orthophonie est dédiée à l'évaluation et au traitement de troubles
du langage oral et écrit. Elle concerne les troubles développementaux
(acquisition du langage) et les troubles acquis (troubles consécutifs
à une lésion cérébrale chez l'adulte).

Pour l'évaluation des déficits langagiers et l'établissement du
diagnostic, les orthophonistes utilisent des batteries de tests. Il
existe ainsi des batteries de tests pour les maladies
neurodégénératives comme la maladie d'Alzheimer [Sagot et al., 2012;
Guard, 2010], pour l'évaluation de la dyslexie [Lefavrais, 2005] et
pour le bilan informatisé de langage oral [Khomsi & Khomsi,
2009]. Cependant, les batteries de tests existants ne sont pas
nombreuses et ne permettent pas de couvrir toutes les situations que
les orthophonistes doivent prendre en charge ce qui constitue une
limitation pour le diagnostic et le traitement des troubles du
langage.

L'objectif de ce travail de stage consiste à proposer des méthodes
automatiques pour préparer des tests pouvant être utilisés pour un
diagnostic plus précis et un traitement plus ciblé des troubles du
langage. Le stage s'intéresse tout particulièrement au niveau
phonétique de la langue. Pour la réalisation du stage, des méthodes
d'Intelligence Artificielle, de Traitement Automatique de la Langue et
de fouille de textes seront utilisées.

Ce stage s'inscrit dans le projet ANR DEMONEXT [demonext]. Les
objectifs de ce projet consistent à construire une base de données
morphologiques du français et à répondre à des besoins multiples,
comme la confirmation empirique et l'élaboration d'hypothèses en
morphologie, le développement d'outils en traitement automatique des
langues, l'enseignement du vocabulaire et le diagnostic et le
traitement des troubles du langage développementaux ou acquis.

Plus spécifiquement, le stagiaire devra effectuer les tâches
suivantes:

-     travailler avec des corpus de textes
-     adapter un module de transcription phonétique au français
-     tester et améliorer ce module de transcription phonétique
-     travailler avec les orthophonistes pour élaborer des tests
-     faire des présentations lors des réunions
-     lire des articles et rédiger les rapports

Le stagiaire sera amené à utiliser des outils existants et à
développer ses propres programmes pour mieux traiter les données.

Prérequis:

-    connaissances en IA, TAL et informatique
-    manipulation et test des outils d'IA et de TAL
-    habitude de Linux
-    capacité de travailler en équipe et individuellement
-   lecture et analyse de la littérature scientifique, y compris en anglais
-    autonomie

Le stage est rémunéré selon les règles en vigueur.

    Niveau: Master, ingénieur
    Durée: 6 mois
    Lieu: Lille

Pour présenter une candidature: envoyer un CV, la lettre de
motivation, le relevé de notes et les contacts de deux référents à
Natalia Grabar (natalia.grabar@univ-lille.fr) et Mai Thi Tran
(thi-mai.tran@univ-lille.fr)

REFERENCES:

    Guard O. (2010). La batterie BAC 40 : un outil d'évaluation
    cognitive pour le diagnostic de la maladie d'Alzheimer au cabinet
    du spécialiste. Revue Neurologique 166(6-7): 615-620.
    
    Khomsi A., J. Khomsi. (2009). Bilo Petits. Bilan informatise de
    langage oral pour les enfants de 3 ans a 5 ans 6 mois. ECPA

Lefavrais P. (2005). Alouette-R test d'analyse de la lecture et de la
dyslexie. ECPA.

Sagot C and TM Tran and J Pariente. (2012). Développement d'une
batterie francophone pour l'évaluation des troubles du langage dans
les maladies neurodégénératives : 10 ans de recherches sur les
aphasies primaires progressives. Revue française de Linguistique
Appliquée 17(2): 117-133.

demonext : https://www.demonext.xyz/"
"524","2018-11-12","LIMSI","Orsay","Offre de stage: 

Titre

Comparaison de fonctions objectif pour l'apprentissage de représentation :
application à la vérification du locuteur et au calcul de similarité
sémantique textuelle

Descriptif

Pour candidater, envoyer lettre de motivation, CV et dernières notes à :
Sahar Ghannay (ghannay@limsi.fr), Sophie Rosset (rosset@limsi.fr), Hervé
Bredin (bredin@limsi.fr)

Sujet

Le rôle de la fonction objectif dans l'apprentissage neuronal est de
fournir une mesure de la performance du réseau de neurones (i.e. sa
capacité à répondre correctement à une tâche précise). Cette mesure,
lorsqu'elle est dérivable, permet alors de mettre à jour le réseau de
neurones par rétro-propagation du gradient de telle sorte que sa
performance soit améliorée. Parmi ces fonctions objectif, on peut par
exemple citer la ""contrastive loss"" [HCL06], la ""triplet loss"" [SKP15],
ou encore la ""center loss"" [WZLQ16]. L'objectif de ce stage est de
comparer différentes fonctions objectif permettant l'apprentissage des
représentations neuronales adaptées à des tâches applicatives telles que
la vérification du locuteur et la similarité sémantique textuelle. La
plupart de ces méthodes ont été initialement proposées dans le domaine
de la vision par ordinateur pour la reconnaissance d'image (et de visage
en particulier) et certaines ont été appliquées récemment à tâche de
vérification du locuteur [Bre17]. Cependant, elles n'ont pas encore été
utilisées pour la tâche de similarité sémantique textuelle.

Description des tâches

Implémentation des différentes fonctions objectif : Après une étape
d'étude de la littérature sur le sujet, la première tâche consiste à
implémenter les fonctions objectif les plus prometteuses en les testant
sur des exemples jouet bien maîtrisés (tels que la base MNIST de
reconnaissance de chiffre manuscrit, par exemple).

Application à la vérification du locuteur : La tâche de vérification du
locuteur consiste à déterminer si deux signaux audio proviennent ou non
de l'enregistrement du même locuteur. On utilisera la base de données
VoxCeleb [CNZ18, NCZ17] pour mener ces expériences. Elle contient plus
d'un million d'enregistrements correspondant à plus de 6000 locuteurs,
et constitue de fait le plus grand corpus librement disponible pour
l'identification et la vérification du locuteur.

Application au calcul de similarité sémantique textuelle : La tâche de
similarité sémantique textuelle (SST) est motivée par le fait que la
modélisation de la similarité sémantique des phrases est un problème
fondamental en compréhension de la langue, pertinent pour de nombreuses
applications, notamment la traduction automatique, la recherche de
réponses à des questions précises (ou questions-réponses), le dialogue
dialogue, etc. Cette tâche consiste à évaluer dans quelle mesure deux
phrases sont sémantiquement équivalentes. Plusieurs approches ont étés
proposées [CDA + 17], qui sont fondées généralement soit sur les
méthodes classiques en traitement automatique des langues (TAL), soit
sur des méthodes d'apprentissage profond. La première approche s'appuie
sur l'utilisation d'un classifieur enrichi par différents types de
descripteurs : sémantiques, syntaxiques, etc. La deuxième est fondée sur
l'exploitation des représentations de phrases et des architectures
neuronales. Dans le cadre des campagnes d'évaluation SemEval, la tâche
de SST a été proposée. Dans ce cadre, la tâche consiste pour le système
de SST à attribuer un score de similarité à chaque paire de phrase sur
une échelle de 0 (les deux phrases sont complètement différentes) à 5
(les deux phrases sont complè tement identiques)... Notre objectif dans ce
stage est de pouvoir étudier les différentes fonctions objectif sur la
tâche SST et de comparer nos résultats aux résultats obtenus par les
différents systèmes ayant participé à la tâche 5 (en anglais) de la
campagne d'évaluation SemEval 2017. Ce système fait la combinaison des
approches de TAL et d'apprentissage profond.

Références

[Bre17] Hervé Bredin. Tristounet : triplet loss for speaker turn
embedding. In 2017 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP), pages 5430-5434. IEEE, 2017.

[CDA + 17] Daniel Cer, Mona Diab, Eneko Agirre, Inigo Lopez-Gazpio, and
Lucia Specia. Semeval-2017 task 1 : Semantic textual
similarity-multilingual and cross-lingual focused evaluation. arXiv
preprint arXiv :1708.00055, 2017.

[CNZ18] Joon Son Chung, Arsha Nagr ni, and Andrew Zisserman. Voxceleb2 :
Deep speaker recognition. arXiv preprint arXiv :1806.05622, 2018.

[HCL06] Raia Hadsell, Sumit Chopra, and Yann LeCun. Dimensionality
reduction by learning an invariant mapping. In CVPR 2006, pages
1735-1742. IEEE, 2006.

[NCZ17] Arsha Nagrani, Joon Son Chung, and Andrew Zisserman. Voxceleb :
a large-scale speaker identification dataset. arXiv preprint arXiv
:1706.08612, 2017.

[SKP15] Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet
: A unified embedding for face recognition and clustering. In
Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 815-823, 2015.

[WZLQ16] Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A
discriminative feature learning approach for deep face recognition. In
European Conference on Computer Vision, pages 499-515. Springer, 2016.

Détails

Domaine
traitement du langage parlé, écrit et gestuel
Mots clés
reconnaissance de locuteur
Apprentissage
Traitement Automatique du Language Naturel Écrit
Niveau : M2
Groupe(s) : ILES, TLP
Date de début : date de début à définir avec le stagiaire
Durée du stage : 5-6 mois (stage pouvant donner lieu à une poursuite en
thèse)"
"525","2018-11-12","Bertin IT","Montpellier","Évaluation d'outils d'extraction d'entités nommées

Durée, démarrage
D'une durée de 6 mois, le stage se déroulera dans les locaux du centre
R&D à Montpellier. Démarrage dès que possible.

Présentation de l'entreprise
Société du Groupe CNIM, Bertin IT est un éditeur et intégrateur de
solutions logicielles pour la cyber sécurité, la cyber-intelligence, la
veille stratégique et le traitement automatique de la parole. Sa marque
AMI, leader dans l'édition de logiciels d'acquisition, de gestion et de
traitement de l'information texte issue du Web, offre des solutions de
veille stratégique et d'intelligence compétitive. En particulier, notre
solution, AMI Enterprise Intelligence, permet aux entreprises
d'exploiter le Big Data afin d'anticiper les évolutions de leur
environnement concurrentiel et technologique et d'identifier de
nouvelles perspectives de développement.

Description du stage
Dans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),
nous proposons des outils avancés d'analyse de texte en vue de faciliter
aux veilleurs et analystes l'exploitation et la navigation dans
l'importante masse de documents collectés à l'issue du processus de
veille. Divers traitements sont proposés tels que l'extraction des
principales thématiques, l'analyse de sentiment ou la détection des
événements clés. Nous fournissons en particulier des outils permettant
l'identification des entités nommées ainsi que les concepts clés
apparaissant dans les documents. Une entité nommée (Named Entity)
faisant référence à une personne ou tout autre objet du monde réel
pouvant être désigné par un nom propre (lieu géographique, nom
d'organisation, nom d'une marque, d'un produit, etc.). Ce type de
problématique est désigné sous la dénomination NER (Named entity
Recognition. Dans ce cadre et dans le but d'une amélioration de nos
outils NER existants, nous souhaitons tester et évaluer des approches
basées sur des réseaux de neurones. La mission consiste à sélectionner
des outils OpenSource permettant d'implémenter des réseaux de neurones
(Tensorflow, Theano ou autre), construire des modèles NER à base de ces
outils, évaluer et comparer les modèles construits avec les outils AMI
ainsi que des outils de référence comme Stanford NER.  Les langues
cibles de l'étude sont l'Anglais et le Français.

Mots clés Deep learning, Réseaux de neurones, Benchmark, Extraction
d'entités nommées, NER, Mesures d'évaluation,

Profil souhaité
Bac +4/5, vous êtes issu(e) d'une école d'ingénieur ou suivez un Master
en mathématiques appliquées, statistiques ou data science. Vous avez une
appétence pour les statistiques et le data science. Une bonne
connaissance d'au moins un langage de script tel que R, Python ou autre
est indispensable. Pour cette mission, l'autonomie, le dynamisme ainsi
le sens de la rigueur seront particulièrement appréciés.

Si vous êtes intéréssé(e) merci d'envoyer votre Cv et lettre de
motivation à :
Leila.khouas@bertin.fr  et frederique.segond@bertin.fr"
"526","2018-11-12",NULL,"Paris","Offre de stage : exploration de logiciels de traduction automatique dans
le contexte d'une maison d'édition

Descriptif

Un grand éditeur scientifique souhaite valoriser son fonds d'ouvrages
non encore traduits en anglais mais, pour des raisons de coût, une
traduction purement manuelle n'est pas envisageable. C'est pourquoi
l'éditeur souhaite lancer une étude préliminaire portant sur la
pertinence et les usages possibles de la traduction automatique dans ce
contexte. Il s'agit d'étudier la qualité possible d'une traduction
automatique et d'estimer le coût (en temps) de la post-édition par un
expert linguiste ou un traducteur, afin d' obtenir un ouvrage de qualité
satisfaisante pour une publication en ligne ou papier.

On propose donc un stage d'une durée de 3 à 6 mois, de préférence à
temps plein (ou à temps partiel, mais avec des horaires fixes chaque
semaine si l'étudiant doit encore suivre des cours pendant la période de
stage), autour de cette problématique.

Le stage consistera à :

1) sélectionner avec la maison d'édition en question quelques ouvrages
   représentatifs, tous disponibles en version électronique en français,
2) recenser, analyser et classer les différents systèmes de traduction
   automatique actuellement disponibles,
3) procéder à la traduction automatique de ces ouvrages (en activant le
   ou les logiciels de traduction automatique qui auront été choisis),
4) définir des indicateurs de qualité explicite, tant lexicale,
   syntaxique que sémantique,
5) évaluer la qualité comparée de ces traductions à l'aune de ces
   indicateurs,
6) étudier la faisabilité et le coût de la post-édition manuelle pour
   obtenir un texte de qualité satisfaisante pour une publication.

Il faudrait qu'un ouvrage soit entièrement traduit pendant le stage afin
d'évaluer la faisabilité sur un ouvrage complet.


Profil recherché :

- de préférence étudiant(e) anglophone ou, à défaut, avec un excellent
  niveau en anglais
- étudiant(e) de Master (M2) avec une formation pertinente (traduction,
  linguistique, traitement automatique des langues, informatique) -- il
  est indispensable de maîtriser l'informatique, au-delà d'une simple
  utilisation des outils  bureautique
- compétences en informatique (programmation de scripts en perl ou
  python)
- des compétences en traitement automatique des langues seraient un plus

Comment candidater ? 

Envoyer par mail (adressé à Thierry Poibeau: prenom.nom@ens.fr) les
documents suivants :

- une courte lettre de motivation (éventuellement directement dans le
  corps du mail)
- un CV
- un relevé de notes récent (de niveau M1 ou M2)
- des éléments concrets permettant d'apprécier les compétences en
  anglais

Le stage aura lieu dans le quartier latin à Paris. Il sera indemnisé
suivant les règles en vigueur pour les stages.  Il est soumis à
l'établissement d'une convention de stage préalable."
"527","2018-11-19","Advanced decision","Paris","***Cadre du stage***

Ce stage de recherche d'une durée de 4 à 6 mois se déroulera au sein de
la société Advanced Decision. Une poursuite du stage dans le cadre d'une
convention CIFRE est envisagée sur les mêmes problématiques.
L'encadrement sera assuré par l'équipe R&D (Hamid Hammouche) ainsi que
par des enseignants chercheurs de l'IRIT (Farah Benamara et Véronique
Moriceau).

La société Advanced Decision est une startup spécialisée en Intelligence
Artificielle avec un savoir-faire industriel dans la réalisation de
configurateurs d'offres intelligents. Nous développons un nouveau
produit, unique sur le marché : un assistant intelligent de voyage
personnalisé.

Notre produit utilise les dernières techniques de l'IA et de la Data
Science : NLP, Machine Learning. Nous recherchons un stagiaire qui
souhaite s'investir dans les domaines de l'ingénierie linguistique et
l'extraction du sens à partir de textes hétérogènes.

***Contexte & Objectif***

Advanced Decision est engagée dans la réalisation d'un service de
recommandation de produits touristiques (hébergement, loisirs, ...). Notre
solution permet une appréhension fine des expériences associées à chaque
produit. Pour atteindre cette finesse, nous analysons finement les
verbatim postés dans les réseaux sociaux. Notre première application est
dédiée à l'activité de restauration. L'analyse de ces verbatim doit
faire apparaître les opinions associées à chacun des aspects du
restauration (par exemple, la cuisine était bonne mais le service
laissait à désirer). Un corpus de 100 000 phrases a été qualifié et
annoté. Un prototype développé par apprentissage automatique permet
d'ores et déjà de repérer les aspects pertinents (cuisine, ambiance, ...)
et de qualifier leur polarité (plus ou moins positive ou négative). Les
résultats des analyses obtenus sont encourageants mais une amélioration
des performances est attendue. L'objectif du stage est double : (i)-
améliorer la précision et la polarité et (ii)- repérer des sens
implicites (figuré, ironie).

***Activités***

- Appropriation des travaux réalisés
- Benchmark des techniques et outils d'analyse des sentiments
- Proposition de solutions
- Implémentation et expérimentations

***Compétences***
- Langage de programmation (Python et/ou Java)
- Fouille de textes et d'opinions
- Connaissance appréciée d'un des frameworks suivants : NLTK, Keras,
  spaCy, PyTorch

***Durée***

4 à 6 mois

***Lieu***

Paris (France)

***Formation***

Ingénieur, Master en Informatique ou linguistique

***Indemnité***

Selon convention et expérience du candidat

***Dossier***

CV, lettre de motivation et bulletins de notes à envoyer à
stage@advanceddecision.fr ; benamara@irit.fr ;
veronique.moriceau@irit.fr"
"528","2018-11-19","Lattice","Paris","Offre de stage : génération de poésie à partir d'une base de poèmes
classiques

Descriptif

Le projet vise à mettre en ligne un programme de génération de poésie à
partir des poème existants, en s'inspirant du livre ""100.000 milliards
de poèmes"" de Queneau (mais, dans notre cas, le projet porte sur la
poésie du 19e siècle). Un premier générateur a été mis au point : il est
fondé sur un corpus de plus de 800 sonnets : des vers sont tirés au sort
au hasard au début, puis de façon à ce qu'ils forment un poème de type
classique (c'est-à-dire en respectant les contraintes de rimes
notamment).

Le stage vise à reprendre le premier prototype réalisé, à le mettre en
ligne en collaboration avec l'équipe chargée de la partie site Web du
projet, et à proposer et implémenter diverses extensions sur cette base
(générer des poèmes avec des contraintes de contenu, de manière
interactive, etc.).

Le stage est organisé dans le cadre du projet Oupoco (""L'Ouvroir de
Poésie Combinatoire »,
http://transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire).

Le stage aura lieu au Lattice, à Montrouge (à 5mn du métro Mairie de
Montrouge, ligne 4). Il sera indemnisé suivant les règles en vigueur
pour les stages.  Il est soumis à l'établissement d'une convention de
stage préalable. Dates exactes à définir (3 à 6 mois, de préférence à
temps plein, au premier semestre 2019)

Profil recherché :

- étudiant(e) de Master (M2) avec une formation pertinente (traitement
  automatique des langues, éventuellement informatique ou littérature
  avec les compétences informatiques adéquates)
- compétences en programmation (scripts en perl ou python)
- compétences en programmation Web et en mise en ligne d'applications
- compétences en traitement automatique des langues 
- intérêt pour la littérature et la poésie 


Comment candidater ? 

Envoyer par mail (à Thierry Poibeau : prenom.nom@ens.fr) les documents
suivants :

- une courte lettre de motivation (éventuellement directement dans le
  corps du mail)
- un CV
- un relevé de notes récent (de niveau M1 ou M2)

Les candidatures seront étudiées au fil de l'eau, la date limite pour
candidater est le 31 novembre (mais il est conseillé de candidater dès
que possible sans attendre la date butoir. Le stage peut être pourvu
avant la date de fin de candidature."
"529","2018-11-19","TETIS / CIRAD","Paris","Stage Master 2 ou école ingénieur: Conception et intégration d'une
plateforme de visualisation de données textuelles hétérogènes

Encadrement

Jacques Fize (UMR TETIS, CIRAD), Mathieu Roche (UMR TETIS, CIRAD ),
Maguelonne Teisseire (UMR TETIS, IRSTEA)

Contexte général

Le stage se déroule dans le cadre du projet SONGES sur la mise en
correspondance de données textuelles massives et hétérogènes. Dans ces
travaux, nous élaborons des modèles de représentation de données ainsi
que des mesures de similarité à partir d'indicateurs trouvés dans les
textes (thématiques, spatiaux et temporels). L'objectif est d'organiser
et valoriser des ensembles de données dans leurs dimensions hétérogènes
et massives. Parmi les données exploitées, nous travaillons sur un
ensemble de données produites dans le cadre du projet BVLAC, un projet
mené par le CIRAD (1) qui promeut des techniques agricoles issues de
l'agroécologie à Madagascar.

Objectif

L'objectif de ce stage est de développer une interface de visualisation
des liens (thématiques et spatiaux) entre documents d'un corpus. Cette
interface devra permettre aux producteurs des données d'explorer et de
valoriser ces corpus . Plus particulièrement, vous développerez une
plateforme Web utilisant des librairies dédiées telles que : D3.js,
Sigma.Js, Topogram.io, etc.

De façon plus précise, le stage sera décomposé en plusieurs étapes :
- Appropriation du sujet (état de l'art, exploration des données)
- Proposition de premières visualisations statiques des données à l'aide
  des librairies disponibles sur Python ou R comme : ggplot2,
  matplotlib, basemap, geopandas
- Conception de l'interface de visualisation
- Stockage des données dans un SGBD (2). La sélection du SGBD dépendra des
  besoins identifiés pour construireles différentes visualisations
- Choix du framework (Flask, Rshiny,...) et des librairies Javascript
  (Sigma.js, Topogram.io, leaflet, ...) nécessaires à l'implémentation de
  l'interface
- Développement de l'interface
- Analyse et évaluation des visualisations produites

Compétences

Langage de programmation : Python ou R

Maitrise de SGBD tels que MariaDB, MongoDB, ElasticSearch ou PostGreSQL
(avec POSTGIS)

Développement Web : HTML/CSS mais surtout Javascript (Connaissances en
design d'IHM (3) souhaitées)

Divers

Durée : 6 mois

Gratification : Taux légal en vigueur

Localisation : Maison de la télédétection - Montpellier

Comment candidater ?

Envoyer un CV ainsi que vos relevés de notes des deux dernières années à
jacques.fize@cirad.fr, maguelonne.teisseire@irstea.fr,
mathieu.roche@cirad.fr

1 Centre de coopération internationale en recherche agronomique pour le
développement

2 Système de Gestion de Base de Données

3 Interface Homme-Machine"
"530","2018-11-19","IRISA","Lannion","L'objectif de ce stage est de mettre en place des outils d'aide à la
comparaison de processus de pré-traitements agro-alimentaires sur la
base de leurs indicateurs environnementaux et économiques.

En s'appuyant sur des méthodes de classification automatique
non-supervisée (clustering), une première fonctionnalité visée sera
d'identifier des classes de procédés qui se comportent de manière
similaire sur des sous-ensembles d'indicateurs. De manière
complémentaire, il serait intéressant d'identifier au sein de chaque
classe et pour chaque procédé, les propriétés typiques et atypiques qui
les caractérisent.


Un enjeu majeur des méthodes d'analyse de données pour l'aide à la
décision est de fournir une représentation des données et des
connaissances extraites la plus interprétable possible. Pour répondre à
cet enjeu, l'originalité de l'approche d'analyse est de procéder à une
réécriture au préalable des données selon un vocabulaire personnalisable
par l'expert. Par exemple, une valeur de 0,85 pour un indicateur i
pourra être interprété comme « élevé » ou bien « pas significative »,
etc. Un travail confié au stagiaire sera d'adapter les méthodes
d'analyse de données pour gérer ces réécritures symboliques au lieu de
données numériques, puis de fournir des représentations graphiques de
ces données et des connaissances structurelles découvertes.

L'objectif du stage de master est donc de proposer une méthode qui
permette de transformer un vecteur de n dimensions (n étant le nombre
d'indicateurs retenus) en représentations graphiques de type « tag of
words » exprimées dans une seule dimension terminologique. Cette
transformation s'appuiera sur un système de partitionnement flou à
définir pour chaque indicateur afin de transformer une donnée numérique
en donnée catégorielle.

Mots clés du stage : analyse de données, fouille de données,
apprentissage automatique, visualisation de données

Compétences requises : programmation Java, modélisation de systèmes
d'informations, analyse de données (data mining, clustering, etc.),
communication et travail d'équipe, dynamisme.

Durée du stage : 6 mois

Lieu du stage : Lannion

Contacts: patrice.buche@inra.fr, gregory.smits@univ-rennes1.fr"
"531","2018-11-19","LIG","Grenoble","The LIG (Laboratoire d'Informatique de Grenoble) laboratory proposes the
following M2 stage (research)

Title:
Neural coreference resolution

Description:
Coreference resolution aims at detecting chains of coreference mentions 
in a text, that is mentions in the text that refer to the same entity.
While at first coreference resolution was split into two separated 
sub-problems, i.e. mention detections and resolution of coreferent 
mentions [1], thanks to the development of sophisticated neural models 
[2,3,4], end-to-end coreference resolution system can be based on a 
whole single model.
The aim of this stage is to study Sequence-to-Sequence [5] and 
Transformer [6] neural models for coreference resolution, integrating 
different types of attention mechanisms and possibly arbitrarily-long 
context [8], with the goal of understanding their impact in dealing with 
this complex NLP problem.

In this internship the student will implement parts of the systems for 
coreference resolution with Sequence-to-Sequence and Transformer neural 
models.
The student will run experiments on his own using GPUs, and the systems 
will be tested on the CoNLL Semeval 2012 benchmark [7].

Profile:
- Student for internship level stage (Master 2) in computer science, or 
  from engineering school
- Computer science skills:
     Python programming with good knowledge of deep learning libraries 
     (TensorFlow or PyTorch)
     Textual data manipulation (xml format, tabular format, CoNLL
     format)
- Interested in Natural Language Processing
- Skills in machine learning for probabilistic models

The internship may last from 4 up to 6 months, it will take place at LIG
laboratory, GETALP team (http://lig-getalp.imag.fr/), starting from
January/February 2019.
The student will be tutored by Marco Dinarelli (www.marcodinarelli.it) 
and Laurent Besacier (http://lig-membres.imag.fr/besacier/).
Interested candidates must send a CV and a motivation letter to
marco.dinarelli@ens.fr and laurent.besacier@univ-grenoble-alpes.fr.

[1] Vincent Ng
     Supervised noun phrase coreference research: The first fifteen 
     years.
     Proceedings of ACL, 2010

[2] Sam Wiseman, Alexander M. Rush, Stuart M. Shieber
     Learning Global Features for Coreference Resolution
     Proceedings of NAACL-HLT, 2016

[3] Kenton Leey, Luheng Hey, Mike Lewisz, and Luke Zettlemoyer
     End-to-end Neural Coreference Resolution
     Proceedings of EMNLP, 2017

[4] Kenton Lee Luheng He Luke Zettlemoyer
     Higher-order Coreference Resolution with Coarse-to-fine Inference
     Proceedings of NAACL, 2018

[5] Ilya Sutskever, Oriol Vinyals, Quoc V. Le
     Sequence to Sequence Learning with Neural Networks
     Proceedings of NIPS, 2014

[6] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion 
     Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin
     Attention Is All You Need
     Proceedings of NIPS, 2017

[7] Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, 
     Yuchen Zhang
     Conll-2012 shared task: Modeling multilingual unrestricted 
     coreference in ontonotes
     Proceedings of EMNLP and  CoNLL-Shared Task, 2012

[8] Zhang, Jiacheng, et al. ""Improving the Transformer Translation Model 
     with Document-Level Context."" EMNLP 2018."
"532","2018-11-23","Southpigalle","Paris","*INTITULÉ :* Data Science / Traitement du langage (NLP)

*CONTEXTE :* Stage rémunéré (1000 ¤ brut/mois) et conventionné, à Paris
(II). Durée : 4 / 6 mois.

*CONTACTS :* Louis de Cointet, CTO et co-fondateur
(louis@southpigalle.io / +33 6 71 70 18 11)

*PRÉSENTATION DE LA SOCIÉTÉ :*

southpigalle est une société spécialisée sur les technologies de l'AI et
les workflows conversationnels (""voice"", ""text"" et ""IoT"" bots), basée à
Paris II et StationF.

Nous permettons aux entreprises d'optimiser leurs processus et de
développer de nouveaux services personnalisés pour leurs collaborateurs
et clients.

Nous comptons de nombreux clients dans le secteur du Luxe (LVMH, Kering,
Richemont), du Retail (BEL, Royal Canin), des médias (MyLittleParis,
MK2), et de la Banque/Finance.

Nous faisons partie des programmes d'accélération du Groupe LVMH à
StationF (
http://southpigalle.io/presse/180410_LesEchos_LVMH-Inaugure-La-Maison-des-Startups-au-sein-de-StationF
) et Microsoft (programme ""Microsoft for Startups""). Nous sommes
également dans les 100 startups de la french retailTech identifiées par
LSA (
https://storage.googleapis.com/store-iobot/20180906_LSA_100_start_up_retailtech.pdf
)

*PRÉSENTATION DU STAGE :*

Southpigalle accueille régulièrement des stagiaires au sein de son pôle
Data Science / NLP.

L'objet de ce stage est de travailler à l'enrichissement de notre brique
de traitement du langage (""NLP"") qui fonctionne aujourd'hui en français
et anglais, et de proposer des pistes / implémenter des évolutions
permettant de la porter dans d'autres langues (espagnol, italien et
chinois par exemple).

Pour ce faire, on s'attachera à conserver la structure centrale de la
technologie comme base de départ, afin de pouvoir modifier certaines
composantes de cette dernière, et plus particulièrement :

(1) Data cleaning: nettoyage de la phrase, stop words, lemmatisation ;

(2) Data preprocessing : choix entre différents embeddings, entraînement
    de ces embeddings sur différents corpus ;
(3) Machine learning: évolution des algorithmes supervisés
    (classification) et non supervisé (text clustering) déjà présents ;
(4) Entités: adaptation de l'architecture de reconnaissance des entités
    et mise à jour de ces dernières.

Le stage pourra aborder l'un ou plusieurs des aspects cités avant.

La connaissance des langages utilisés sur notre stack technique (HDFS /
Spark / Python pour le Machine Learning) et des librairies du marché
(Manipulation de données : Numpy, Pandas, Seaborn, Analyse de données :
Sklearn, Gensim, Keras, Fasttext, Traitement de la langue : Spacy, Nltk
...  constitue un plus.

Au delà de l'expertise, nous valorisons fortement l'autonomie et la
prise d'initiative de la part de nos stagiaires, qui seront amenés à
travailler dans un environnement flexible, mais extrêmement dynamique et
challenging."
"533","2018-11-28","TETIS / LIRMM","Montpellier","Stage M2 - Recherche

Titre: Détection de fausses nouvelles (fake news) fondée sur les
informations textuelles et structurées

Encadrants : Mathieu Roche (TETIS, Cirad), Konstantin Todorov (LIRMM,
Univ. Montpellier)

Mots clés:  intelligence artificielle, fake news, machine learning,
graph/word embeddings, traitement automatique des langues, ...

Sujet:

Les fausses nouvelles (fake news) sont devenues un problème de plus en
plus important, tant du point de vue de la société que de celui de la
recherche. De nombreuses approches récentes [1,2] dans diverses
communautés scientifiques portent sur des problèmes tels que la
vérification des faits, la détection de la pertinence ou de point de
vue dans des documents par rapport à des assertions particulières.

Dan ce contexte, 3 laboratoires français et allemands (dont le LIRMM
et TETIS à Montpellier) ont uni leur efforts pour collecter et publier
sous la forme de graphe de connaissances les données et méta-données
contenues dans un grand nombre de site de fact-checking (tels que
Politifact www.politifact.com ou Snopes www.snopes.com). En résulte la
base ClaimsKG https://github.com/claimskg/claimskg_generator, un graphe de connaissances contenant plus de 24K
assertions annotées et liées qui facilite la création de requêtes
structurées sur les assertions, leurs valeurs de vérité (True, False,
etc.), leurs auteurs, dates de publication, etc.

Ce stage aura pour but d'exploiter cette ressource et de proposer des contributions
méthodologiques fondées sur des analyses statistiques approfondies :

(1) Intégration de nouveaux descripteurs (descripteurs dits exogènes,
word embeddings, etc.) pour améliorer l'identification de ""fake news""
dans un processus d'apprentissage automatique.

(2) Mise en place d'un processus de clustering d'assertions dans le
but d'identifier les descripteurs clés utiles pour discriminer les
fake news. Notons que le clustering visera à regrouper les assertions
qui portent sur le même événement ou bien sur des événements
similaires/liés.

Plan de travail  :

1) Etat de l'art du domaine de vérification automatique d'assertions à
la base de méthodes d'apprentissage automatique.

2) Etudes de l'état de l'existant, en particulier la ressource ClaimsKG.

3) Proposition de méthodes d'identification des descripteurs les plus
pertinents pour la détection de fake news.

4) Rédaction d'un papier scientifique à soumettre à une conférence
internationale

Le travail s'effectuera à TETIS et au LIRMM dans le cadre d'une
collaboration avec l'Institut de sciences sociologiques GESIS à
Cologne (Allemagne).

Prérequis  :
- Bon niveau de programmation (java / python)
- Des bases en science de données, machine learning et web sémantique
- Bon niveau en anglais

Le stage sera rémunéré et aura une durée de 6 mois à partir du mois de
février 2019.

Contacts  :

Envoyez un CV à  mathieu.roche@cirad.fr et  todorov@lirmm.fr .

Références:

[1] S. Vosoughi, D. Roy, and S. Aral. The spread of true and false
news online. Science, 359(6380):1146-1151, 2018

[2] K. Popat, S. Mukherjee, J. Strötgen, and G. Weikum. Where the
truth lies: Explaining the credibility of emerging claims on the web
and social media. In Proceedings of the 26th International Conference
on World Wide Web, pages 1003-1012. 2017"
"534","2018-11-28","TETIS","Montpellier","Stage Master 2 ou école ingénieur

Conception et intégration d'une plateforme de visualisation de données
textuelles hétérogènes

Encadrement

Jacques Fize (UMR TETIS, CIRAD), Mathieu Roche (UMR TETIS, CIRAD),
Maguelonne Teisseire (UMR TETIS, IRSTEA)

Contexte général

Le stage se déroule dans le cadre du projet SONGES sur la mise en
correspondance de données textuelles massives et hétérogènes. Dans ces
travaux, nous élaborons des modèles de représentation de données ainsi
que des mesures de similarité à partir d'indicateurs trouvés dans les
textes (thématiques, spatiaux et temporels). L'objectif est
d'organiser et valoriser des ensembles de données dans leurs
dimensions hétérogènes et massives. Parmi les données exploitées, nous
travaillons sur un ensemble de données produites dans le cadre du
projet BVLAC, un projet mené par le CIRAD (Centre de coopération
internationale en recherche agronomique pour le développement) qui
promeut des techniques agricoles issues de l'agroécologie à
Madagascar.

Objectif

L'objectif de ce stage est de développer une interface de
visualisation des liens (thématiques et spatiaux) entre documents d'un
corpus. Cette interface devra permettre aux producteurs des données
d'explorer et de valoriser ces corpus . Plus particulièrement, vous
développerez une plateforme Web utilisant des librairies dédiées
telles que : D3.js, Sigma.Js, Topogram.io, etc.

De façon plus précise, le stage sera décomposé en plusieurs étapes :


1. Appropriation du sujet (état de l'art, exploration des données)

2. Proposition de premières visualisations statiques des données à
l'aide des librairies disponibles sur Python ou R comme : ggplot2,
matplotlib, basemap, geopandas

3. Conception de l'interface de visualisation

4. Stockage des données dans un SGBD 2 . La sélection du SGBD dépendra
des besoins identifiés pour construire les différentes visualisations

5. Choix du framework (Flask, Rshiny,...) et des librairies Javascript
(Sigma.js, Topogram.io, leaflet, ...)  nécessaires à l'implémentation
de l'interface

6. Développement de l'interface

7. Analyse et évaluation des visualisations produites

Compétences

- Langage de programmation : Python ou R

- Maitrise de SGBD tels que MariaDB, MongoDB, ElasticSearch ou
  PostGreSQL (avec POSTGIS)

- Développement Web : HTML/CSS mais surtout Javascript (Connaissances
  en design d'IHM 3 souhaitées)

Divers

Durée : 6 mois

Gratification : Taux légal en vigueur

Localisation : Maison de la télédétection - Montpellier

Comment candidater ?

Envoyer un CV ainsi que vos relevés de notes des deux dernières années
à jacques.fize@cirad.fr, maguelonne.teisseire@irstea.fr,
mathieu.roche@cirad.fr"
"535","2018-11-28","TETIS","Montpellier","Stage Master 2 Pro ou école ingénieur

Mise en place d'un système d'acquisition semi-automatique d'un corpus de
données hétérogènes (Images et Textes) - Application à la problématique de la
sécurité alimentaire en Afrique de l'Ouest

Le stage s'inscrit dans le cadre d'un projet interdisciplinaire
concernant la gestion des risques liés à la sécurité alimentaire. Le
projet est centré sur le cas de l'Afrique de l'Ouest, où les risques
agricoles sont d'autant plus aigus que les services nationaux de
surveillance et de suivi peuvent être défaillants faute de moyens
techniques et financiers. Actuellement les images de télédétection
satellitaire sont utilisées en routine pour produire des cartes
d'anomalies de croissance de la végétation en temps quasi-réel, aux
échelles nationale et régionale. Cependant détecter une anomalie de
croissance ne suffit pas à établir un diagnostic sur la production
agricole d'une région, car de nombreux facteurs rentrent en ligne de
compte. D'un autre côté, les journaux locaux et les nouveaux médias
font état de certains événements (sécheresse, inondation, état
sanitaire, etc.) qui ont un impact direct sur la production
agricole. Ces événements ne sont pas tous répertoriés, ils ne
décrivent pas de façon exhaustive la situation régionale ou nationale,
mais ils apportent une information thématique complémentaire de celle
des images satellite. Ainsi, nous proposons un stage de recherche
ayant comme objectif d'établir un lien entre textes et images afin de
faire un diagnostic sur la production agricole en cours de saison en
vue d'améliorer les systèmes d'alerte précoce. Pour atteindre cet
objectif, deux activités seront menées : (i) utiliser des techniques à
la pointe de fouille de textes sur le thème du climat et de la
production agricole et avec un ancrage géographique en Afrique de
l'Ouest ; (ii) lier les informations géo-localisées ainsi extraites
aux observations faites par satellite pour poser un diagnostic en
temps quasi-réel.

La zone géographique d'étude concerne l'Afrique de l'ouest. Les
données textuelles à acquérir correspondent à des journaux, des
bulletins officiels de veille sur le déroulé de la campagne agricoles
émis par les systèmes d'alertes précoces internationaux, régionaux ou
nationaux et des données provenant de plateformes de médias sociaux
(p. ex., Blogs, Twitter, Flickr, Instagram). Ces données seront
récoltées en adaptant (si nécessaire) un système de web scraping mis à
disposition. Les données image sont essentiellement des cartes
d'indicateurs NDVI (Normalized Difference Vegetation Index) décadaires
produites à partir d'images acquises à basse et moyenne résolutions
spatiales (entre 250 m et 1 km).

Les objectifs de ce stage comprennent la production d'un corpus mis à
disposition et d'un rapport détaillant le contenu et les liens
sémantiques entre les différentes données. Le livrable consistera dans
la rédaction d'un data paper permettant la valorisation du corpus
constitué.

Le planning prévisionnel est structuré comme suit :


1. étude du cahier des charges du corpus à constituer et choix de la
zone d'étude,

2. adaptation et mise en oeuvre du processus de récolte des données
(via le système existant mis à disposition)

3. constitution du corpus (textes, images) sur la zone d'étude,

4. Mise en relation et évaluation du corpus avec les experts,

5. Rédaction du Data paper.

Compétences requises :

Langages Python et Java, outils NLP (souhaité)

Capacité de travail en équipe pluridisciplinaire.

Divers :

Durée : 5 à 6 mois

Gratification : taux légal en vigueur

Localisations : TETIS (Maison de la Télédétection) à Montpellier

Candidature :

Envoyer un CV + relevés de notes des deux dernières années à
roberto.interdonato@cirad.fr et agnes.begue@cirad.fr"
"536","2018-11-28","Yseop","Lyon","Sujet: Extraction non supervisée de relations syntaxiques profondes à
partir de corpus

= La société

Yseop est l'éditeur international d'un logiciel d'Intelligence
Artificielle spécialisé dans la génération automatique de texte en
langage naturel (Natural Language Génération ou NLG).
Nous offrons une solution qui raisonne, dialogue et rédige comme un être
humain, en plusieurs langues, et qui se concentre sur deux coeurs
d'expertise : la génération automatique de rapports et la relation
clients.
Aujourd'hui, nous comptons plus de 50 000 utilisateurs quotidiens de la
technologie Yseop, principalement des entreprises du CAC 40 et du
Fortune 500.

= La mission

L'objet du stage est de réaliser un analyseur de corpus extrayant des
relations syntaxiques profondes (et leur arguments) liées à des
prédicats donnés dans des corpus client. Cette extraction servira
d'entrée à un processus d'apprentissage qui permettra l'adaptation des
grammaires de génération à un contexte applicatif spécifique. On pourra
par exemple se baser sur des approches comme UCCA (Universal Conceptual
Cognitive Annotation) ou FrameNet.

La langue des documents est l'anglais mais le prototype réalisé devra
être aisément portable sur d'autres langues, en premier lieu le
français.

Cette mission se déroulera au sein de l'entité Yseop Lab, en étroite
collaboration avec les équipes travaillant sur l'apprentissage et
l'analyse automatique des langues.

= Le profil recherché

Vous avez un niveau M2 en TAL, avec de bonnes connaissances en
programmation, en particulier en Python avec des outils TAL associés
(Spacy, NLTK). Des connaissances en bases de données, en modélisation
des données et en apprentissage automatique seront appréciées.

Le stage se déroule dans les locaux de la société, à Paris (75001), pour
une durée de 6 mois à partir de début Janvier 2019.

= Pour postuler

Rendez-vous sur la page
https://www.welcometothejungle.co/companies/yseop/jobs/stage-nlp-analyse-de-corpus_paris"
"537","2018-11-28","INRA","Montpellier","L'INRA de Montpellier propose un stage de Master de constitution d'une
ressources terminologique en lien avec l'analyse de la littérature
scientifique sur les matériaux issus de la biomasse d'origine animale ou
végétale.

Contexte

La littérature et les travaux de recherche récents menés dans le domaine
des matériaux et emballages bio-sourcés révèlent un foisonnement
d'acteurs venant de champs disciplinaires multiples. Il est encore
difficile de partager un vocabulaire commun dû à des représentations
ontologiques divergentes et à la polysémie existante, à commencer par
les différents sens que prend le préfixe « bio » selon que l'on se place
du point de vue de la ressource (bio-ressources, biomasse), du procédé
(biotechnologies, bio-ingénierie, bioprocédés, bio-raffineries), du
produit (bioplastique, biomatériau, biomolécule) ou des fonctionnalités
post-usage (biodégradable, bio-compostable, bio-déchets) ou encore de
l'ensemble de la chaine (bio-économie, bio-industries, bio-marchés).

Nous souhaitons collecter et compiler les connaissances actuelles
concernant les définitions, les normes et les acteurs qui s'intéressent
aux matériaux bio-sourcés dans le but d'améliorer notre communication
scientifique et technique, grand public, nos dispositifs de veille mais
aussi d'aide à la décision.

Description des missions

La/le stagiaire aura pour principale mission de réaliser une analyse
bibliométrique et terminologique autour des matériaux et emballages
bio-sourcés. Le projet démarrera à partir d'entretiens et de collectes
d'information et de documents scientifiques (rapports, articles etc.)
produits au sein de l'Inra et notamment des départements à forte
activité dans les produits bio-sourcés. Ces primo-données (Web et autres
sources) feront l'objet d'une analyse lexicale et sémantique basée
notamment sur  une extraction terminologique et bibliométrique en
utilisant les outils exploités et le savoir-faire développé au sein de
l'IST/Inra. Le vocabulaire identifié viendra compléter des listes déjà
établies par des scientifiques et le tout sera organisé sous la forme
d'un lexique ou d'un thésaurus proposant des définitions. Une fois
publié selon les standards du Web sémantique notamment, cette ressource
pourra servir de référence dans le domaine.

A cette fin, la/le stagiaire assurera la mobilisation d'un corpus coeur
d'une 40aine de chercheur localisés sur une 10aine de villes françaises,
afin de réaliser une analyse terminologique (Français/ Anglais)  issue
de la consultation. Ceci constituera un préambule à des requêtes sur le
WOS afin de compléter le corpus qui fera l'objet d'une analyse
bibliométrique. Elle/il mettra en place la solution logicielle
permettant aux scientifiques du département CEPIA d'accéder et de
consulter le corpus documentaire et les résultats de l'analyse
bibliométrique. Pour toutes ces tâches, les moyens techniques et
l'accompagnement nécessaires seront mis à disposition par la DIST/Inra
dans le cadre de son offre de services aux chercheurs.

Enfin, le stagiaire pourra étudier les apports potentiels du vocabulaire
dans le cadre d'une veille scientifique et/ou réglementaire.

Livrables

- Une analyse bibliométrique et une base documentaire sur les produits
  biosourcés (matériaux et emballages biosourcés)

- Un vocabulaire (thésaurus ou lexique) des produits biosourcés qui
  pourra être publié

Profil requis

- Étudiant en master 1 ou master 2 ou élève-ingénieur en 4ème ou 5ème
  année dans les domaines Documentaires/bibliométriques, Linguistique,
  Traitement Automatique des Langues, Analyse documentaire, ingénierie
  des connaissances et sciences. Des connaissances sur les matériaux
  issus de la biomasse seront appréciées.

- capacités à travailler en autonomie età solliciter les personnes
  ressources nécessaires à la réalisation du projet Motivé, travailleur,
  rigoureux et ouvert d'esprit

- Anglais lu et parlé

Modalités de candidature

Les candidat.e.s doivent transmettre un CV et une lettre de motivation
aux encadrants, le stage démarrera à partir de début Mars 2019.

Conditions du stage
Durée : 6 mois, à partir de Mars 2019
Lieu : UMR IATE, INRA Montpellier
Gratification : Environ 550 ¤ net/mois

Sophie Aubin
DIST
INRA - Bâtiment D
42, Rue Georges Morel,
49070 Beaucouzé
02 41 22 56 57"
"538","2018-12-03","LIG / Gipsa Lab","Grenoble","Sujet

Système d'annotation automatique du beatbox et conversion morphographique

Encadrants

- Benjamin Lecouteux et Didier Schwab (LIG)
  [Benjamin.Lecouteux@univ-grenoble-alpes.fr Didier.Schwab@imag.fr]

- Nathalie Henrich Bernardoni (GIPSA-lab)
  [Nathalie.Henrich@gipsa-lab.fr]

avec la participation d'Adrien Contesse (Vocal Grammatics)

Description du stage

Communiquer par la parole ou par le chant requiert une bonne
coordination des gestes respiratoires, phonatoires et articulatoires,
adaptée aux contraintes phonétiques et physiologiques et à la situation
de communication. C'est même le corps tout entier, de la posture aux
gestes vocaux et manuels, qui devient instrument au service de
l'expression humaine. Dans ce contexte, un art vocal urbain émergent est
particulièrement intéressant, le Human Beatbox (en français, boîte à
rythme humaine). Cette pratique artistique s'est développée au cours des
années 1980 en s'inscrivant dans le cadre de la culture hip-hop.

Plusieurs équipes de recherche se sont intéressées au beatbox, notamment
l'équipe VSLD du GIPSA-lab, en collaboration avec le LPNC pour les
aspects phonétiques et le TIMC pour les aspects ventilatoires. Pour ces
travaux, les chercheurs annotent manuellement des performances de
beatbox au niveau phonétique pour en étudier la production. Ce travail
est long, fastidieux, et difficile à réaliser avec les alphabets actuels
(API, beatbox alphabet). Il pourrait être effectué avec le soutien des
outils d'annotation automatiques.

De grands progrès ont été réalisés récemment dans le domaine de la
reconnaissance automatique de la parole grâce à l'apprentissage profond
: nous pouvons voir le beatbox comme une langue à part entière, un
langage musical. L'objectif du stage est d'explorer les méthodes
permettant d'annoter automatiquement des prestations de beatbox (sous
formes d'unités phonétiques, par exemple), en s'appuyant sur des outils
état de l'art tels que KALDI ou ESPnet.

Un autre aspect de ce stage porte sur la représentation sous la forme
d'unités pictographiques de ces mêmes démonstrations. Récemment, des
infographistes et pratiquant du beatbox ont proposé des associations
sons/pictogrammes qui s'appuie sur une approche de phonétique
articulatoire des sons produits en Human Beatbox. Il s'agit du projet «
Vocal Grammatics » (http://www.vocalgrammatics.fr) qui permet par le
développement d'une représentation morphographique des sons du beatbox
de faciliter la transcription des séquences musicales, et
l'apprentissage par les enfants et les adultes. Le stagiaire de master
travaillera également sur la projection de sons de beatbox sous la forme
d'unités pictographiques.

Le master se fera dans le cadre d'une collaboration entre deux
laboratoires : le LIG pour les aspects reconnaissance automatique de la
parole et le GIPSA-lab pour les aspects voix/linguistique. Il sera
encadré par Benjamin Lecouteux et Didier Schwab (LIG) et Nathalie
Henrich Bernardoni (GIPSA-lab), avec la participation de l'infographiste
Adrien Contesse (Vocal Grammatics)."
"539","2018-12-03","Synomia","Boulogne-Billancourt","Sujet: Deep learning et parsing multilingue

= La société

Synomia édite des assistants professionnels qui aident les
""brain-workers"", c'est-à-dire celles et ceux qui ont la charge
d'identifier et de saisir de nouveaux territoires, idées et
opportunités, dans leurs tâches quotidiennes. Synomia dispose d'une
technologie NLP propriétaire qu'elle enrichit continuellement depuis
ses débuts, et qui constitue le socle technologique sur lesquelles
sont basées toutes les apps commercialisées par l'entreprise. Synomia
a été élue Meilleure start-up où il fait bon travailler au le
classement HappyAtWork en 2017 et en 2018.

= La mission

L'objet du stage est de tester différentes approches de Deep Learning
pour réaliser des analyseurs de corpus dans différentes langues. Cette
mission se déroulera au sein de l'équipe NLP de Synomia, dirigée par
D. Bourigault.

= Le profil recherché

Vous avez un niveau M1 ou M2 en TAL, avec de bonnes compétences en
programmation, en particulier en Python, ainsi qu'une bonne
connaissance des techniques d'apprentissage automatique.

Le stage se déroule dans les locaux de la société, à
Boulogne-Billancourt (92100), pour une durée de 3 à 6 mois à partir de
Janvier 2019.

Contacts : rose.louis@synomia.com"
"540","2018-12-03","IGN","Saint-Mandé","Le laboratoire des sciences et technologies de l'information
géographique (LaSTIG) de l'IGN propose un stage de M2 sur
l'identification des variations expressives des noms de lieux, en lien
avec l'intention du producteur.

------ Mots clés

Informatique, TAL, nom de lieu, distance entre chaîne de caractères

------ Contexte

Ce stage s'intègre au projet ANR 2016 CHOUCAS qui implique des
chercheurs en raisonnement spatial, gestion de données et de
connaissances, extraction d'information et géovisualisation de
données. Le projet vise à améliorer le processus de décision lors de la
localisation de personnes en détresse en milieu naturel terrestre, en
réponse à un besoin exprimé par le Peloton de gendarmerie de haute
montagne de Grenoble (PGHM). L'objectif est de proposer des méthodes et
des outils permettant de constituer et enrichir des données
géographiques issues de sources hétérogènes, des modèles de raisonnement
spatial flou, et des environnements de géovisualisation. La localisation
est effectuée, lors de l'appel téléphonique émis la victime, par les
secouristes du PGHM qui disposent de nombreuses sources de données
textuelles hétérogènes : guides touristiques, guides de randonnées,
descriptions d'itinéraires, récits de randonnées, etc. Ces sources sont
qualifiées d'hétérogènes parce qu'elles diffèrent par la longueur, les
objectifs, le niveau de langue, le contexte de production, le lexique,
la morphologie, la syntaxe, etc.

------ Sujet

Les noms propres de lieux constituent des informations cruciales pour
localiser un document. Cependant, la graphie de ces noms ne correspond
pas toujours à celle que l'on peut trouver dans les dictionnaires de
noms propres de lieux. Certaines variations peuvent être analysées comme
des coquilles, d'autres sont inspirées des pratiques d'écriture
véhiculées par les réseaux sociaux, et relèvent donc d'une variation
volontaire, portée par une intention.

Des outils informatiques existent pour mesurer la distance entre deux
chaînes de caractères. Cependant, ces distances ne prennent pas en
compte des phénomènes courants et facilement interprétables par des
humains : par exemple, la troncature de Pralognan-la-Vanoise en
Pralognan ou la construction du sigle PLV, ni l'intention éventuelle du
rédacteur dans la variation : Pralognaaaaaaaaaaaan. Des variations ont
été recensées et analysées, et de nouvelles distances sont définies qui
prennent en compte des variations de graphie et des approximations
phonétiques (stage en cours).

Le premier objectif de ce stage est de construire un processus
d'identification des noms propres de lieux intégrant ces différents
calculs de distance entre chaînes de caractères, dans l'interface GATE
et de mesurer ses performances (rappel, précision, F-mesure) selon les
types de textes (corpus CHOUCAS, récits de vie, corpus d'opinions
concernant des projets d'aménagements urbains, corpus de titres de
cartes, etc.).

Le deuxième objectif vise à explorer des modifications de ces distances
afin de mieux prendre en compte les caractéristiques (fondées sur des
indications lexicométriques) des différents corpus dans la désignation
des lieux et guider le choix des distances à utiliser pour identifier
les noms de lieux d'un corpus à l'aide de dictionnaires.

Un troisième objectif consisterait, au vu des résultats précédents, à
proposer et tester des pistes d'identification de l'intention de
l'auteur d'un texte, à partir de l'analyse de la désignation des lieux,
afin de quantifier les variations entre graphie utilisée dans un texte
et graphie de référence d'un nom de lieu.

------ Références

Dominguès, C., & Eshkol-Taravella, I. (2015). Toponym recognition in
custom-made map titles. International Journal of Cartography, 1(1),
109-120.

Fairon, C., Klein, J. R., & Paumier, S. (2006). SMS pour la science
(licence: 1 utilisateur, manuel+ CD-Rom): Corpus de 30.000 SMS et
logiciel de consultation (Vol. 3). Presses univ. de Louvain.

Panckhurst R. (2006a), « Le discours électronique médié : bilan et
perspectives », in A. Piolat (Éd.). Lire, écrire, communiquer et
apprendre avec Internet. Marseille : Éditions Solal, 345-366.

Véronis, J., & Guimier de Neef, E. (2006), « Le traitement des nouvelles
formes de communication écrite », in Sabah, G. (Éd.), Compréhension
automatique des langues et interaction, Paris : Hermès Science, 227-248.

Zenasni, S., Kergosien, E., Roche, M., & Teisseire,
M. (2016). Découverte de nouvelles entités et relations spatiales à
partir d'un corpus de SMS. Actes de la conférence JEP-TALN-RECITAL 2016,
volume 2, 403-410.


------ Compétences particulières et formation requise

Ce stage s'adresse aux étudiants de master 2 ou de 3ème année d'école
d'ingénieurs avec une spécialisation en informatique ou en TAL.


------ Lieu du stage

Laboratoire en sciences et technologies de l'information géographique 
Institut national de l'information géographique et forestière
73 avenue de Paris
94165 Saint-Mandé Cedex
métro : Saint-Mandé - ligne 1 ou RER A - Vincennes

------ Durée et rémunération

durée : 5 mois
début : avril 2019
gratification : environ 550 euros mensuels

------ Prolongements éventuels

Le COGIT propose chaque année des bourses de thèse ainsi que des
contrats de post-doctorant.

------ Encadrement du stage

Catherine Dominguès
IGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex
mél : catherine.domingues[@]ign.fr

Philippe Gambette
Université Paris-Est Marne-la-Vallée, LIGM, 5 Boulevard Descartes, 77420
Champs-sur-Marne
mél : philippe.gambette[@]u-pem.fr

------Pour candidater

Le dossier de candidature sera envoyé par courriel à Catherine Dominguès
et Philippe Gambette. Il devra se composer d'un curriculum vitae et
d'une lettre de motivation, accompagnés des relevés de notes des années
de M1 et M2 (ou deux dernières années d'école d'ingénieurs), de la
description des enseignements suivis (un lien vers le site internet de
la formation est le bienvenu) et du dernier rapport de stage ou mémoire
rédigé (en version électronique)."
"541","2018-12-03","LIUM","Le Mans","Le LIUM propose une offre de stage de *Master 2* en partenariat avec la
SNCF autour des word embeddings.

*Sujet de stage* : AmÃ©liorer la catÃ©gorisation de documents Ã  l'aide des
word embeddings.

*Laboratoire d'accueil* : LIUM, Ã‰quipe LST - https://lium.univ-lemans.fr 
*Partenaire industriel* : SNCF INNOVATION & RECHERCHE
*Site* : Le Mans
*Co-encadrement* : Nathalie Camelin (nathalie.camelin@univ-lemans.fr), 
 Nicolas DuguÃ© (nicolas.dugue@univ-lemans.fr)

*RÃ©sumÃ©* : Le LIUM a mis en oeuvre une chaÄ±Ì‚ne de traitement pour
apprendre des word embeddings sur le corpus SNCF dont le vocabulaire est
trÃ¨s spÃ©cialisÃ©. La qualitÃ© des vecteurs a Ã©tÃ© Ã©valuÃ©e qualitativement
par des agents SNCF. Il s'agit pour le stage d'utiliser ces word
embeddings dans le processus de classification des documents, notamment
en utilisant des Convolutional Neural Networks. Le stagiaire pourra
Ã©galement contribuer Ã  amÃ©liorer l'apprentissage des word embeddings,
une nouvelle Ã©valuation des reprÃ©sentations apprises est prÃ©vue avec les
agents SNCF dans la suite du projet.

*Pour postuler : *Ã‰crire Ã  Nathalie Camelin et Nicolas DuguÃ© avec un CV,
une lettre de motivation et votre relevÃ© de notes de M1."
"542","2018-12-03","ICVL","Blois","*Proposition de stage de recherche*

  * Sujet: Représentation orientée-objet d'expressions polylexicales
    dans une métagrammaire

  * Domaine de recherche: traitement automatique des langues

  * Lieu du stage:
    o Blois (antenne de l'Université de Tours),
    o déplacements fréquents à l'Université d'Orléans

  * Encadrement:
    o Agata Savary (http://www.info.univ-tours.fr/%7Esavary/),
      laboratoire LIFAT, Université de Tours
    o Emmanuel Schang (https://sites.google.com/site/emmanuelschang/),
      laboratoire LLL, Université de Orléans
    o Anaïs Lefeuvre-Halftermeyer
      (https://sites.google.com/site/nlplefeuvreanais/), laboratoire
      LIFO, Université de Orléans

  * Financement: fédération ICVL <http://www.info.univ-tours.fr/ICVL/>

  * Durée: 6 mois (début en février-mars 2018)

  * Rémunération: 577 EUR/mois
  
Contexte et objectifs

Le domaine de ce stage est celui de la linguistique computationnelle,
qui vise d'une part la compréhension du langage naturel (c'est à dire
celui de l'homme, par opposition aux langages formels, dédiés aux
machines) du point de vue computationnel, et d'autre part la
construction de modèles et logiciels pour un traitement et une
génération utiles des énoncés langagiers.

Nous nous intéressons à un des défis majeurs des données langagières,
qui sont les expressions polylexicales(EP), telles que le cordon bleu,
le hot dog, prendre le taureau par les cornes, etc. Le problème majeur
qu'elles posent est le fait que leur sens ne peut pas être déduit du
sens de leurs composants, ce qui rend difficile leur traitement par
ordinateur.

Nous souhaitions atteindre simultanément plusieurs objectifs pour le
codage de ces expressions dans une grammaire formelle:

  * sa non-redondance,

  * sa flexibilité,

  * la réduction du coût de son développement,

  * son interopérabilité.

Une preuve de concept a été développée récemment pour une méthode de
codage lexical, syntaxique et sémantique des expressions polylexicales
avec XMG2, un langage formel orienté-objet, développé au LIFO d'Orléans
et à l'Université de Düsseldorf en Allemagne. Cette méthode appliquée à
plus grande échelle devrait répondre aux 4 défis mentionnés plus haut.

Dans le cadre du stage, il s'agirait de la poursuite de ces travaux. Le
stage est interdisciplinaire et connecte les domaines de la linguistique
et de l'informatique. On vise:

  * une intégration de nouveaux types d'EP françaises dans la
    métagrammaire XMG existante, nommée FrenchTAG, selon le méthode
    citée plus haut,

  * l'examen de la portabilité des EP françaises dans une langue créole,
    à savoir le guadeloupéen, dont une Grammaire d'Arbres Adjoints (TAG)
    est développée au LLL,

  * l'examen de l'impact de ces méthodes novatrices pour la tâche de
    l'analyse syntaxique (parsing) avec le formalisme des Grammaires
    d'Arbres Adjoint, qui est connu pour une représentation habile des
    expressions polylexicales; un compilateur TAG et un parseur TAG sont
    développés par le LIFO d'Orléans et par l'Université de Düsseldorf
    (partenaire privilégié du LIFAT et du LIFO)

Profile attendu des candidat(e)s

  * Etudiant(e) en Master d'informatique, linguistique computationnelle ou linguistique

  * Connaissance de langages/grammaires formelles

  * Capacité de travail en autonomie

  * Mobilité Blois-Orléans
  
 Cadre international et national

  * Collaboration étroite entre le LIFAT, le LIFO et l'Université de
    Düsseldorf (Abteilung für Computerlinguistik
    (https://user.phil.hhu.de/kallmeyer/team/)

  * Groupe de Recherche International Structure, Emergence and Evolution
    of Pidgin and Creole Languages
    (http://www.pidgins-creoles.cnrs.fr/fr)

  * Projet ANR PARSEME-FR (http://parsemefr.lis-lab.fr) sur le parsing
    et les expressions polylexicales en français

  * *Réseau PARSEME (http://www.parseme.eu), financé en 2013-2017 dans
     le cadre d'une action COST*"
"543","2018-12-10","CEA LIST","Saclay","Présentation du laboratoire d'accueil

Le Laboratoire de Vision et d'Ingénierie des Contenus (LVIC) est l'un
des composants de l'Institut CEA LIST qui est spécialisé dans la
conception et le développement de systèmes complexes ou à forte
composante logicielle. Le LVIC emploie une cinquantaine de chercheurs et
ingénieurs travaillant sur l'analyse et l'interprétation de données
multimédia (texte, image et analyse de vidéos).  Dans un cadre « Big
Data », le laboratoire développe des algorithmes robustes pour
l'extraction, l'analyse et le traitement de grands volumes de données
multimédia. Nos technologies ont contribué à l'émergence de nouvelles
activités économiques par la création de startups. Par ailleurs, le
laboratoire participe à de nombreux projets collaboratifs (ANR, Europe
FP7, Pôle de Compétitivité) avec des partenaires académiques, PMEs ou
grands industriels.

Le Laboratoire de Vision et d'Ingénierie des Contenus mène ses
recherches dans les domaines de la Vision par Ordinateur (Computer
Vision) et l'analyse automatique de texte avec le défi d'extraire et
d'organiser l'information à partir de documents faiblement ou non
structurés (texte, image, vidéo).

Contexte du stage

Ce stage s'inscrit dans le cadre du projet ANR LabForSims2 dont le but
est de faire évoluer la simulation pour les professionnels de santé
grâce à l'introduction de technologies innovantes. Deux grands axes
technologiques (réalité mixte et analyse conversationnelle) sont
inscrits dans le projet et appliqués dans deux méthodologies de
simulation : jeu sérieux décrivant la stratégie diagnostique d'une
urgence chirurgicale abdominale, d'une part, et mannequin haute fidélité
dans un scénario de réanimation néonatale, d'autre part.

L'équipe Multimédia du LVIC est en charge, dans ce projet, du deuxième
axe technologique qui traite de l'analyse conversationnelle. Dans ses
travaux, elle a développé plusieurs agents conversationnels jouant les
rôles de patient, de radiologue, de chirurgien, etc. pour dialoguer en
langage naturel avec les étudiants en médecine.

Description du stage

L'objectif de ce stage est de réaliser l'évaluation scientifique des
différents agents conversationnels dans le contexte médical. Le travail
à réaliser consiste à collecter des données du domaine et à créer des
corpus pour l'évaluation de la capacité des agents à comprendre et à
dialoguer avec les étudiants en médecine pour des scénarios
spécifiques. Plus spécifiquement, il s'agit de :

- collecter des données orales (dialogues, questions/réponses) et les
  transcrire en texte (à l'aide d'outils automatiques) ;
- annoter les données collectées ;
- identifier et modéliser des critères qui permettront de mener
  l'évaluation ;
- exploiter les critères et corpus pour développer et appliquer une
  méthodologie d'évaluation ;
- participer à la rédaction de publications scientifiques.

Niveau demandé :
Master 2 en linguistique informatique 

Durée : 4 à 6 mois

Rémunération : 700¤ pour un master 2 en université

Compétences requises ou souhaitées :
- Collecte et création de ressources linguistiques ;
- Connaissances en TAL ;
- Bonne maîtrise de la ligne de commande sous Linux (bash, python, sed,
  awk...) ;
- Une connaissance des agents conversationnels (chatbots) serait un plus

Contact :
Gaël de Chalendar
gael.de-chalendar@cea.fr"
"544","2018-12-10","Akio software","Paris","Offre de stage chez Akio software

Titre: sémantique de la relation client en anglais

Descriptif:

Le sujet proposé traite de l'interprétation sémantique des informations
échangées entre une entreprise et ses clients. Le mode opératoire est
omnicanal dans le sens où quelque soit le moyen choisi par le client,
l'entreprise doit pouvoir faire le lien entre le contact présent et
l'historique des interactions passées.

Description du poste:

L'objectif du stage est d'apporter un regard extérieur sur la chaîne de
traitement actuelle afin de l'améliorer en anglais. Nous sommes ouverts
à de nouvelles idées qui peuvent contribuer à notre succès au sein d'une
équipe dynamique. Le stage portera essentiellement sur la partie
sémantique des composants linguistiques de calcul des thématiques, des
opinions et des modalités d'expression.

Profil recherché:

- Niveau Master 1 ou 2 en linguistique ou en traitement automatique du
  langage.
- Très bon niveau de langue en anglais, qu'il soit académique, familier
  ou argotique.
- Etre un anglophone natif serait un plus.
- Etre rigoureux.
- Bonne maîtrise des outils informatiques.

Durée:
6 mois, de manière préférentielle d'avril à septembre.
Des adaptations sont possibles.

Lieu:
Akio
Equipe: traitement automatique de la langue.
43 rue de Dunkerque, 75010 Paris.
www.akio.com

Gratification:
Selon les règles en vigueur avec participation aux frais de transports
en commun.

Encadrement:
Le stage sera encadré par Gil Francopoulo avec l'aide de Lynda Ould
Younes.

Candidature:
Merci d'envoyer un CV à gfrancopoulo@akio.com et louldyounes@akio.com
accompagné des notes de l'année universitaire en cours et de celles de
l'année dernière.

 * Gil Francopoulo  
  Expert Sémantique  
 *  Semantics Expert  
 *  T. +33 (0)1 53 20 60 44     
 *  43 rue de Dunkerque  
  75010 Paris - France  
  www.akio.com"
"545","2018-12-14","LIMSI / STL","Paris","Détection automatique de mésusages de médicaments dans les réseaux sociaux

On parle du mésusage de médicaments lorsque les patients ne respectent
pas les prescriptions ou le bon usage de médicaments, ce qui peut
mener à des situations potentiellement dangeureuses. Parmi les
mésusages les plus fréquents, se trouvent par exemple le non-respect
du dosage (sur-dosage ou sous-dosage) ou la prise de médicaments pour
des indications différentes de celles pour lesquelles ils ont été
prescrits.

Il est estimé que la non-adhérence aux prescriptions est d'environ 50%
chez les malades chroniques dans les pays industrialisés, et que le
taux de non-adhésion est supérieur dans les pays en voie de
développement [1]. Cela indique qu'il existe un vrai problème de santé
publique. En effet, les chercheurs indiquent que l'amélioration
d'adhésion peut avoir un impact bien plus positif sur la santé de la
population que des progrès effectués dans des traitements médicaux
spécifiques [2].

Actuellement, il existe très peu d'information sur les mésusages : les
patients ne les signalent pas aux médecins ni aux autorités de
santé. Il est donc nécessaire d'analyser d'autres sources
d'information [3-6]. Nous proposons d'étudier les informations
disponibles dans les réseaux sociaux et les forums de discussion
relatifs à la santé en français [7].

L'objectif de ce travail de stage consiste à proposer et tester des
méthodes automatiques pour explorer de grands volumes de données pour
détecter de nouveaux cas de mésusages dans les réseaux sociaux. Pour
la réalisation du stage, des méthodes d'Intelligence Artificielle, de
Traitement Automatique de la Langue et de fouille de textes seront
utilisées.

Plus spécifiquement, le stagiaire devra effectuer les tâches
suivantes:
- travailler avec des corpus de textes
- exploiter de méthodes de TAL, d'IA
- travailler avec les algorithmes d'apprentissage supervisé
- évaluer les résultats obtenus
- faire des présentations lors des réunions
- lire des articles et rédiger les rapports

Le stagiaire sera amené à utiliser des outils existants et à
développer ses propres programmes pour mieux traiter les données.

Prérequis:

- connaissances en IA, TAL et informatique
- manipulation et test des outils d'IA et de TAL
- habitude de Linux
- capacité de travailler en équipe et individuellement
- lecture et analyse de la littérature scientifique, y compris en anglais
- autonomie

Le stage est rémunéré selon les règles en vigueur.

    Niveau: Master, ingénieur
    Durée: 6 mois
    Lieu: Paris

Pour présenter une candidature: envoyer un CV, la lettre de
motivation, le relevé de notes et les contacts de deux référents à
Élise Bigeard (bigeard@limsi.fr) et Natalia Grabar
(natalia.grabar@univ-lille.fr) et

REFERENCES:


WHO (2003). Adherence to Long-Term Therapies: Evidence for
Action. Technical report, WHO. Available online at:
http://www.who.int/chp/knowledge/ publications/adherence_report/en/
(2018/06/01).

Haynes, R. B., McDonald, H., Garg, A. X., and Montague,
P. (2002). Interventions for helping patients to follow prescriptions
for medications. Cochrane Database Q11 Syst. Rev. CD000011. doi:
10.1002/14651858.CD000011

Feehan, M., Morrison, M. A., Tak, C., Morisky, D. E., DeAngelis,
M. M., and Munger, M. A. (2017). Factors predicting self-reported
medication low adherence in a large sample of adults in the US general
population: a cross-sectional study. BMJ Open 7:e014435. doi:
10.1136/bmjopen-2016- 014435

Natarajan, N., Putnam, W., Van Aarsen, K., Beverley Lawson, K., and
Burge, Q9 F. (2013). Adherence to antihypertensive medications among
family practice patients with diabetes mellitus and
hypertension. Can. Fam. Physician 59, e93-e100

Cameron, D., Smith, G. A., Daniulaityte, R., Sheth, A. P., Dave, D.,
Chen, L., et al. (2013). Predose: a semantic web platform for drug
abuse epidemiology using social media. J. Biomed. Inform. 46,
985-997. doi: 10.1016/j.jbi.2013. 07.007

Kalyanam, J., Katsuki, T., Lanckriet, G. R. G., and Mackey,
T. K. (2017). Exploring trends of nonmedical use of prescription drugs
and polydrug abuse in the twittersphere using unsupervised machine
learning. Addict. Behav. 65, 289-295. doi:
10.1016/j.addbeh.2016.08.019

Bigeard, É., Grabar, N., and Thiessard, F. (2018). Detection and
Analysis of Drug Misuses. A Study Based on Social Media
Messages. Frontiers in Pharmacology, Front Pharmacol. 2018 Jul
26;9:791. doi: 10.3389/fphar.2018.00791. eCollection 2018."
"546","2018-12-14","IRIT","Toulouse","PHD and Internship positions at IRIT (Toulouse) funded by the ANR COST
project (2019-2022)

Title: Deep models for task-based information retrieval

Keywords: information retrieval, deep sequential models, deep
reinforcement learning

Advisors: Eric Gaussier (eric.gaussier@imag.fr), Karen Pinel-Sauvagnat
(karen.pinel-sauvagant@irit.fr), Lynda Tamine-Lechani
(lynda.lechani@irit.fr)

===============
Context
===============

While search systems today are very efficient for simple look-up
information tasks (fact-finding search), they are unable to guide users
engaged in exploratory, multi-step and highly cognitive search tasks
(e.g, diagnosis, human learning). Hence, paradoxically, while we
consider information search nowadays to be 'natural' and 'easy', search
systems are not yet able to provide adequate support for achieving a
wide range of real-life work complex search tasks[1]. In the CoST
project (funded by ANR 2019-2022), we envision a shift from search
engines to task completion engines by dynamically assisting users in
making the optimal decisions, empowering them to achieve multi-step
complex search tasks. While most of previous work rely on query-aware
models and techniques to structure the session context and model search
satisfaction [2,3,4] at the query level, we rather attempt to design
task-aware IR models to make task-level satisfaction predictions.
===================================

PhD
===================================
This PhD will be focussed on applying neural approaches for task-based
information retrieval. Based on the findings that have raised from
previous works about the effectiveness of seq2seg models to capture
reformulation patterns for the next query prediction task [4,5], we
envision new end-to-end network architectures that make possible to
account for sequences of sub-tasks.  We will also explore end-to-end
learning for task satisfaction prediction based on deep reinforcement
learning that goes beyond query-level relevance. The candidate will
investigate the modelling, the deployment and evaluation of search
assistance techniques (eg., query suggestion) and ranking models using
deep neural networks architectures.  The evaluation of the resulting
systems will be carried out using both public benchmarks (eg., TREC
Tasks, TREC session, AOL dataset) as well as laboratory-built datasets
built within the CoST project.

- Starting and duration: September 2019, 36 months
- Skills: the successful candidate is expected to have skills/background
  in information retrieval, machine learning, deep learning. Background
  in reinforcement learning would be greatly appreciated.
===================================

Internship.
===================================

This internship will be focused on: (1) a review of recent neural
approaches for next query prediction in session-based search; (2) the
development of a baseline framework for query prediction in task-based
search.

- Starting and duration: March 2019, 4-6 months
- The successful candidate is expected to have skills/background in
  information retrieval and machine learning.

===================================
Application process: Deadline March, 30th 2019.
===================================
To apply, please email your application to: eric.gaussier@imag.fr,
karen.sauvagnat@irit.fr, lynda.lechani@irit.fr.

The application should consist of the following:
+ a curriculum vitae
+ transcript of marks according to M1-M2 profile or last 3 years of
  engineering school (with indication on the ranking if possible)
+ covering letter
+ letter(s) of recommendation including at least one letter drawn up by
  a university referent

Potential candidates will be invited for an interview with the supervisors.

[1] Ahmed Hassan Awadallah, Ryen W. White, Patrick Pantel, Susan T.
Dumais, and Yi-Min Wang. Supporting Complex Search Tasks, CIKM'2014.
[2] Jiyun Luo, Sicong Zhang, and Hui Yang. 2014. Win-win search:
dual-agent stochastic game in session search, SIGIR'2014
[3] Bhaskar Mitra. 2015. Exploring Session Context using Distributed
Representations of Queries and Reformulations, SIGIR'2015
[4] Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, and Pascal
Fleury. Learning to Attend, Copy, and Generate for Session-Based Query
Suggestion, CIKM'2017
[5] Alessandro Sordoni, Yoshua Bengio, Hossein Vahabi, Christina Lioma,
Jakob Grue Simonsen, and Jian-Yun Nie. A Hierarchical Recurrent
Encoder-Decoder for Generative Context-Aware Query Suggestion, CIKM'2015"
"547","2018-12-14","INRA / MAP-MAACC","Paris","AgroParisTech & INRA 
UMR MIA 518 
Equipe LINK (Learning and INtegration of Knowledge) 
16, rue Claude Bernard 
75 231 Paris cedex 05 	

UMR MAP-MAACC 
3495 CNRS/MCC 
144 avenue de Flandre 
75019 Paris, France 	

Sujet de stage de Master M2 

Construction d'une base de connaissances pour l'architecture
biomimétique durable

Contacts : liliana.ibanescu@agroparistech.fr ,
natasha.heil@paris-lavillette.archi.fr

Objectifs 

L'objectif du stage est de construire une ontologie pour représenter et
structurer une base de connaissances à partir des données, connaissances
et outils disponibles qui peuvent être utilisés pour la conception
biomimétique en architecture dans une démarche de développement durable.

Le biomimétisme étudie la nature pour l'imiter ou pour résoudre des
problèmes humains [1,3]. Les défis de la conception biomimétique sont
liés d'une part à la complexité de la biologie comme modèle à transférer
dans des domaines techniques, et d'autre part à la difficulté de
communiquer entre des domaines disciplinaires différents [5]. Une des
pistes à explorer serait d'évaluer les outils présentés dans [5] dans un
contexte donné et pour un objectif précis, e.g. l'optimisation
fonctionnelle d'un produit.

Parallèlement, en architecture il existe des exemples de conception
durable inspirés de la nature [2] :

 1. Le centre hydrologique de l'Université de Namibie a des capteurs
    de brouillard inspirés par la forme de la carapace du coléoptère
    namibien Stenocara dont les micro-bosses attirent l'eau et les
    rainures cireuses la font circuler.
    
 2. L'Esplanade Theater à Singapour [1] a une toiture inspirée par la
    peau des fruits du durian [2] et elle est composée de panneaux
    d'aluminium qui filtre la lumière naturelle et qui change de
    direction selon la position du soleil. Cette innovation dans
    l'architecture réduit de 30% l'énergie totale consommée dans le
    bâtiment et de 55 % l'utilisation de l'éclairage artificiel.
    
 3. La forme du bâtiment de l'ArtScience Museum de Singapour [3] ,
    inspirée par la fleur de lotus, permet de récupérer l'eau de pluie
    et laisse enter la lumière naturelle dans plusieurs directions
    diminuant ainsi l'usage de l'éclairage artificiel.

L'approche biomimétique est adoptée pour le développement durable, mais
elle n'est pas utilisée de manière productive dans le domaine de
l'architecture. La difficulté réside dans la recherche et
l'identification de modèles biologiques pertinents pour le défi de la
conception.


Résultats attendus 

Dans ce projet nous nous intéressons à l'identification et à la
capitalisation des ressources (données, référentiels et outils)
existantes dans le domaine de la conception biomimétique et qui seraient
utiles pour l'architecture durable. Le premier enjeu sera d'identifier
et de définir les concepts clés à la croisé de ces deux domaines
(conception biomimétique et architecture durable). Ensuite seront
évalués les ressources identifiées dans [5] pour sélectionner celles qui
peuvent être réutilisées en architecture, et qui sont
ouvertes/accessibles. Une troisième étape sera d'explorer s'il existe
sur le web de données liées des référentiels concernant les différents
domaines d'intérêt (i.e. biomimétisme, architecture, processus de
conception, développement durable) et proposer des liens entres les
concepts identifiés et ces référentiels. Enfin, un premier prototype
d'une ontologie noyau sera proposé.

Les trois partenaires de ce projet sont d'une part des membres de
l'équipe LInK de l'UMR MIA 518 experte en représentation de
connaissances, construction et alignement d'ontologies, et, d'autre
part, un membre du MAACC, le laboratoire de Modélisation pour
l'Assistance à l'Activité Cognitive de la Conception, qui est une équipe
de l'UMR MAP 3495 CNRS/MCC (Modèles et simulations pour l'Architecture
et le Patrimoine) et un membre de l'équipe BIOADAPT de l'UMR 7179
CNRS-MNHN.



Bibliographie 

Benyus J. (1997) Biomimicry: Innovation Inspired by Nature, New York,
Harper Collins Publishers

Chayaamor-Heil, N., Guéna, F., Hannachi-Belkadi, N. (2017) Biomimétisme
en architecture. État, méthodes et outils, Les Cahiers de la recherche
Architecturale Urbaine et Paysagère
https://journals.openedition.org/craup/309

ISO 18458:2015 Biomimetics -- Terminology, concepts and
methodology. https://www.iso.org/standard/62500.html

Suárez-Figueroa M.C., Gómez-Pérez A., Fernández-López M. (2012) The NeOn
Methodology for Ontology Engineering. In: Suárez-Figueroa M.,
Gómez-Pérez A., Motta E., Gangemi A. (eds) Ontology Engineering in a
Networked World. Springer, Berlin, Heidelberg

Wanieck, Kristina & Fayemi, Pierre-Emmanuel & Maranzana, Nicolas &
Zollfrank, Cordt & Jacobs, Shoshanah (2017) Biomimetics and its Tools,
Bioinspired, Biomimetic and Nanobiomaterials. 1-52

Lieu du stage: AgroParisTech (Paris), durée de 6 mois, stage rémunéré
(environ 500 euros par mois)

[1] https://fr.wikiarquitectura.com/b%C3%A2timent/complexe-esplanade/ 

[2] un fruit exotique originaire d'Asie du Sud 

[3] https://www.safdiearchitects.com/projects/marina-bay-sands-artscience-museum"
"548","2018-12-21","Viavoo","Boulogne-Billancourt","Stage 6 mois pour M2 : Ingénieur(e)-Linguiste TAL

Boulogne-Billancourt, Île-de-France, France - R&D - Ing-TAL

*Viavoo RECRUTE !*

Éditeur SaaS, Viavoo compte parmi les leaders européens en solutions
sémantiques multilingues et multicanaux.

Forte d'un important travail de R&D en continu depuis sa création en
2009, Viavoo a développé un ensemble technologique qui associe
ingénierie linguistique et intelligence artificielle au service de
solutions de Customer Intelligence (Analytics, Insights-API, Reports,
Benchmark) et de Bot (mail, chat, voice).

*Votre mission*

Viavoo recrute un(e) stagiaire dont le rôle sera de travailler sur une
méthode de classification automatique des verbatims clients selon des
thèmes ou catégories.

À partir d'un corpus de données multicanaux parlant des produits et du
parcours client, l'objectif du stage est de classifier ces données en
prenant en compte les technologies et modèles existants à Viavoo ainsi
que l'état-de-l'art autour des techniques d'annotation et de
classification automatiques.

Vous intégrerez l'équipe R&D et serez amené(e) à participer à
l'évolution de la technologie hybride existante à l'entreprise.

Les tâches entreprises tout au long du stage concernent principalement :

- Établir un état-de-l'art récent sur la classification automatique
- Créer un gold standard à des fins d'évaluation
- Conception et implémentation d'un classifieur automatique
- Détection automatique de classes
- Tests et évaluation

*Notre offre*

- Un stage conventionné de 6 mois à pourvoir sur Boulogne-Billancourt
- Rémunération du stage + mutuelle & prévoyance + remboursement de la
  moitié du passe Navigo
- Un environnement de travail dynamique, bienveillant et innovant
- Un encadrement rigoureux et une équipe technique de grande qualité
- Bonne ambiance, grande cuisine et babyfoot, plusieures activités entreprise

*Profil recherché*

- M2 en Ingénierie Linguistique / TAL / Data Science
- Compétences en TAL
- Connaissances en apprentissage automatique (supervisé et sans corpus
  d'entraînement)
- Programmation en Python et/ou Javascript
- Compréhension des enjeux pour la linguistique générale (morphologie,
  syntaxe, sémantique)
- Anglais technique
- Autonomie et capacité à travailler en équipe

*Postuler en ligne :* https://www.viavoo.com/carrieres/"
"549","2018-12-21","Institut international pour la Francophonie","Lyon","Offre de stage pour du balisage de corpus lexicographique

Titre : Stage

Durée : 4 mois
Fonction / métier : Informaticien

Niveau de responsabilité : -Aucun(e)-

Présentation - missions

L'Institut international pour la Francophonie (2IF) recrute un·e
stagiaire informaticien·ne.

Présentation de la structure

Composante de l'Université Jean Moulin Lyon 3, l'Institut
international pour la Francophonie (2IF)
(https://2if.universite-lyon.fr/) travaille sur l'étude, la
compréhension et le rayonnement de la Francophonie à travers trois
missions :

- La formation initiale sur le thème de la Francophonie ;
- La production de recherche sur l'objet francophonie et son attractivité ;
- Production d'idées, de discours et prospective sur et pour la Francophonie.

Parmi ses actions, l'institut est l'opérateur d'un projet de
Dictionnaire des francophones piloté et financé par la Délégation
générale à la langue française et aux langues de France
(http://www.culture.gouv.fr/Thematiques/Langue-francaise-et-langues-de-France).

Description de la mission du stage

Sous la direction de Noé Gasparini (chef de projet du Dictionnaire des
francophones, 2IF), la/le stagiaire participera au projet de
Dictionnaire des francophones. Ce projet vise à aligner plusieurs
ressources lexicographiques francophones afin de les rendre
accessibles en ligne, et de permettre leur enrichissement
ultérieur. La base de données est structurée grâce à l'ontologie
OntoLex. Le développement informatique est réalisé par une entreprise
extérieure, l'Institut international pour la francophonie assurera
l'encadrement stratégique mais n'assurera pas d'encadrement
informatique.

Ce stage consistera en une participation à la numérisation du
dictionnaire intitulé Inventaire des particularités lexicales du
français d'Afrique noire publié initialement en 1983 et réédité en
2004.

Plusieurs étapes sont prévues :

- Conception d'un outil de balisage permettant d'ajouter dans le
document numérisé les balises propres à l'ontologie OntoLex (RDF/OWL)
afin d'aligner cette ressource avec les ressources existantes.

- Identification des nouvelles balises nécessaires, qui ne sont pas
encore dans le vocabulaire contrôlé déjà collecté, et documentation de
leur intégration.

- Développement d'un outil d'affichage permettant de faciliter la
relecture manuelle des erreurs de balisage, des coquilles
typographiques et orthographiques. La relecture détaillée sera
réalisée durant le stage et l'outil doit pouvoir permettre la
relecture ultérieure d'autres ressources numérisées.

- Rédaction de la documentation afin de permettre l'extension de
l'outil de balisage à d'autres ressources.

Ces outils et la documentation associée, de même que tout le
développement logiciel et les données présentes dans les bases de
données seront publiés sous licence libre.

Type de structure : Etablissement public scientifique et technique

Structure de recrutement : Université Jean Moulin Lyon 3 (Institut
international pour la Francophonie - 2IF)

Emplacement : Bâtiment Citroën (bureau 110), 24 rue Salomon Reinach,
69007 Lyon

Conditions d'exercice : Stage conventionné de 4 mois du 1 er avril au
31 juillet 2019 à temps plein (35 heures par semaine avec
gratification légale minimale).

Profil recherché

Étudiant·e en informatique, de préférence formé·e en ingénierie de la langue.
 
- Connaissance du balisage des données, idéalement en RDF
- Sens de l'organisation et du travail en autonomie
- Rigueur, esprit d'initiative et de synthèse
- Un intérêt pour la diversité des usages de la langue française
  serait un plus

DATES LIMITES
Date limite de candidature : 03/03/2019
Date de prise d'effet du poste : 01/04/2019
Date de publication : 21/12/2018
Contact et information
Candidature et demande d'information à adresser à
noe.gasparini@univ-lyon3.fr
04.78.78.73.76"
"550","2019-01-07","EDF","Chatou","Stage - TALN, text-mining et ontologies pour la maintenance
d'installations solaires photovoltaïques - H/F (St-19-0001)

Extension d'une chaîne de traitement TAL (ontologie et règles)
d'extraction de données à partir de compte rendus textuels non
structurés d'interventions de maintenance.

Référence de l'offre de stage : ST-19-0001
https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-19-0001

Type d'offre : Offre de Stage (long)

Niveau de formation : A partir de bac +4

Spécialité(s) : Génie informatique / Télécommunications

Domaine d'intervention : R&D

Pays : France

Région(s) : Ile de France

Département(s) : Yvelines

Ville(s) : CHATOU (78400)

Nombre de postes : 1

Mise en ligne le : 2018-12-18

Description de l'offre

CONTEXTE

Les installations de production d'électricité solaires photovoltaïques
sont appelées à se développer très fortement en accord avec la
Programmation Pluriannuelle de l'Energie présentée par le gouvernement
fin novembre 2018 et le Plan Solaire d'EDF lancé le 11 décembre 2018
pour développer 30 GW d'énergie solaire en France d'ici 2035.

Comme toute installation de production d'électricité, la bonne
performance dans la durée est conditionnée à une maintenance et une
surveillance adaptées des installations pour identifier au plus tôt les
défauts ou sous-performances, les corriger mais aussi affiner les
politiques de maintenance préventives voire parfois les choix de
conception ; pour cela, les ingénieurs et techniciens spécialistes de
ces installations peuvent notamment analyser le Retour d'Expérience,
c'est-à-dire analyser les événements de surveillance et de maintenance
déjà intervenus sur les installations existantes pour en tirer des
leçons pour la maintenance à venir.

Dans un domaine et une problématique voisine, une chaîne de traitement
TALN a été développée pour extraire les actions de maintenance réalisées
sur les composants à partir de textes de compte-rendu techniques
d'intervention de maintenance d'éoliennes afin de constituer des bases
structurées d'historiques d'opérations de maintenance réalisées sur les
installations ; cette chaîne de traitement TAL se base notamment sur des
ressources dédiées qui ont été structurées dans une ontologie et sur des
règles d'extraction (JAPE) dans une application basée sur la plateforme
GATE de l'Université de Sheffield.

Le besoin est de constituer des bases de données d'événements de
maintenance et d'exploitation à partir de corpus textuels non
structurés. Il s'agit de mettre en oeuvre des techniques de traitement
automatique du langage naturel (TALN) et d'analyse sémantique afin
d'identifier les évènements tracés dans les textes pour reconstituer ces
bases d'évènements de maintenance et d'exploitation des installations.

Un événement est une combinaison d'informations, comme par exemple pour
la maintenance, une date, un composant d'un matériel, un type
d'opération de maintenance et une action (prescription, réalisation,
...) ou par exemple pour la surveillance une date, un composant d'un
matériel, et un état ou un défaut observé, ou encore une valeur
mesurée. Certaines de ces informations peuvent être corroborées par des
informations structurées disponibles dans d'autres parties du système
d'information (base de données de pièces de rechange...). Des documents
peuvent ne contenir aucune des informations recherchées alors que
d'autres documents peuvent en contenir plusieurs qu'il ne faut pas
mélanger.

OBJECTIF ET DESCRIPTIF DU STAGE

L'objectif du stage est de reprendre la chaîne de traitement TALN
développée pour la maintenance des éoliennes et d'éventuelles extensions
spécifiques déjà réalisées pour les documents du domaine photovoltaïque
et de proposer et de réaliser des améliorations pour en étendre le champ
d'application au traitement du domaine de la maintenance des
installations solaires photovoltaïques. Cela nécessitera notamment
d'enrichir l'ontologie pour prendre en compte les composants des
installations solaires, les actions de maintenance spécifiques à ces
installations (en enrichissant les actions et composants dans
l'ontologie existante), ainsi que la description de constats relatifs à
l'état (visuel et fonctionnel ainsi que des défauts, dégradations etc.)
des composants qui constitue un nouveau besoin du domaine (en plus de
l'identification des actions sur les composants).

Avec des techniques et outils de text-mining TALN/analyse sémantique, le
travail de stage consiste donc à :

- Prendre connaissance de la chaîne de traitement et de l'analyse à
  réaliser et proposer des pistes d'amélioration ;

- Contribuer à la priorisation des pistes d'amélioration avec les
  chercheurs EDF R&D ;

- Concevoir, développer et évaluer des améliorations et compléments dans
  l'ontologie et la chaîne de traitement ;

- Positionner la solution mise en oeuvre dans l'étude vis-à-vis des
  autres solutions déjà mises en oeuvre par EDF sur d'autres projets.

Conditions du stage :

Le stage se déroulera au sein des locaux d'EDF R&D à Chatou et sera
rémunéré.

Durée : 6 mois.


Profil souhaité

Etudiants concernés :
MASTER, ou Fin d'études ingénieur.

Compétences souhaitées :
La réalisation de cette étude nécessite des compétences en modélisation
des connaissances, en techniques de fouille de textes, en text-mining de
type Traitement Automatique du Langage Naturel et Analyse Sémantique,
ainsi que des techniques et outils du web sémantique, notamment RDF.


Information et candidature :
En postulant sur cette offre sur le site internet :
https://www.edf.fr/edf-recrute/rejoignez-nous/voir-les-offres/nos-offres?search[keyword]=ST-19-0001"
"551","2019-01-07","LIP6","Paris","Sujet Structuration et établissement de filiations entre des données hétérogènes: le cas des archives de Jacques Derrida

Contexte 

L'Institut des Textes et Manuscrits Modernes (ITEM, UMR 8132 ENS-CNRS)
et le LIP6 (UMR 7606 Sorbonne Université - CNRS) développent un
programme d'exploitation des archives numériques du philosophe Jacques
Derrida déposées à l'IMEC (disques durs et supports de sauvegarde
divers, dont plus de 500 disquettes). L'objectif du projet est d'adapter
la critique génétique à l'environnement technologique du XXIe siècle en
exploitant les documents nativement numériques (« born digital ») d'un
créateur. La critique génétique s'est développée à partir des traces
manuscrites du processus créateur conservées dans les brouillons des
écrivains. Depuis une trentaine d'années, on assiste au remplacement
progressif de l'écriture manuscrite par l'écriture numérique, et les
archives que les écrivains confient aux bibliothèques sont de plus en
plus constituées d'ordinateurs et de supports numériques. Préserver,
décrire et exploiter ces nouvelles collections numériques constitue un
enjeu majeur, tant pour les institutions de conservation que pour les
chercheurs.

En utilisant les outils d'exploration développés par l'informatique
forensique, que l'on appelle aussi la criminalistique numérique, et,
plus généralement, l'IA, le projet a l'ambition d'élaborer une
codicologie du XXIe siècle adaptée aux traces nativement numériques
stockées dans les disques durs.

Dans cette perspective, le corpus des archives numériques de Jacques
Derrida est particulièrement intéressant. D'une part, Derrida est un
témoin exemplaire de la mutation numérique qui se met en place à partir
du milieu des années 1980 (il avait plus de 50 ans lorsqu'il a fait
l'acquisition de son premier ordinateur en 1985), ce qui permet
d'observer à l'état natif le bouleversement des pratiques d'écriture
induit par ce qu'il appelle les « machines à traitement de texte ».

D'autre part, par crainte d'une disparition accidentelle de données (par
suite d'un cambriolage ou d'une coupure de courant), il a multiplié les
copies des textes à la rédaction desquels il travaillait. De ce fait,
l'archive numérique contient une masse de dossiers et de fichiers
portant le même nom mais n'ayant pas forcément le même contenu. Cette
redondance est disséminée aussi bien à l'intérieur d'un support donné
(on trouve des sous-arborescences partiellement identiques en différents
points de l'arborescence d'ensemble) qu'entre les différents supports.

Attendus du stage

C'est ce second volet qui fait l'objet du stage proposé. Son objectif
est de mettre de l'ordre dans ce buisson foisonnant, en établissant un
inventaire des différents fichiers présents dans l'archive, puis en
structurant ces données à l'aide d'un graphe des différents états
représentatifs du processus d'écriture et en le visualisant. Pour un
texte final donné, ceux-ci devront prendre notamment en compte les
emplacements physiques des fichiers correspondants, leurs noms, leurs
caractéristiques temporelles (dates de création et de modification,
absolues et relatives), les liens de parenté des fichiers entre eux
(jumeaux, frères, antécédents ou successeurs), leur place dans le
déroulement temporel de l'écriture induite de différentes façons, par
exemple avec les techniques algorithmiques mises en oeuvre pour
construire des arbres phylogénétiques.

Compétences requises :

- Intérêt pour les textes
- Bonne connaissance d'un langage de programmation objet (l'idéal serait
  un connaissance de Python, mais la maîtrise de Java ou d'un autre
  langage objet suffirait)
- Connaissance de base en algorithmique
- Des compétences dans les techniques de traitement du langage naturel
  seraient un plus


Encadrement et conditions financières

Il s'agit d'un projet interdisciplinaire conduit conjointement par
l'ITEM et le LIP6. L'encadrement sera assuré pour l'ITEM, en particulier
par Aurèle Crasson et Jean-Louis Lebrave, et pour le LIP6, par
Jean-Gabriel Ganascia.

Le candidat percevra une gratification d'environ 480 ¤ / mois. La durée
du stage est de 3 mois minimum pouvant se prolonger jusqu'à 6 mois.

Lieu du stage

Équipe ACASA, Laboratoire Lip 6, 4 Place Jussieu, 75005 Paris

Contact : Jean-Gabriel Ganascia (Professeur, Sorbonne Université):
jean-gabriel.ganascia@lip6.fr
01 44 27 37 27"
"552","2019-01-07","MaCompta.fr","La Rochelle","Offre de stage : Développements d'outils innovants de traitement de
documents électroniques et de reconnaissance de caractères dans le cadre
d'applications de gestion et comptabilité, stockage de données
sensibles.

Votre Mission :

Macompta.fr est un éditeur de site internet leader sur le marché des
petites entreprises et associations et en forte croissance (6.000
utilisateurs, croissance de 35 % par an, 10 collaborateurs).

Nous accompagnons nos clients dans la numérisation de leurs process de
gestion, comptabilité et paie.

Nous recherchons un stagiaire pour renforcer nos équipes chargées de
mettre au point des solutions innovantes dans des problématiques variées
: Séparation de fichiers pdf en documents unitaires, reconnaissance de
caractères pour l'enregistrement automatisé de documents comptables,
chiffrement et stockage de données, stockage sécurisé de codes d'accèset
utilisation pour une connexion sécurisée à des API bancaires.

Profil : Etudiant en master 2

Durée : _4 mois à 6 mois

Rémunération :
900 brut + Tickets Restaurant.

Plus de renseignements :
Sylvain Heurtier
Tél : 05 46 45 11 99
sheurtier@macompta.fr
Postuler :
envoyer CV + lettre de motivation à sheurtier@macompta.fr"
"553","2019-01-07","IGN","Saint-Mandé","*Budget participatif dans la gestion des villes*

*Mots clés*
Informatique, TAL, textométrie, budget participatif

*Contexte*

Le budget participatif (BP) est un outil de démocratie participative en
plein essor. Impulsé par une institution, il permet de dédier un budget
d'investissement à la réalisation de projets proposés par les
citoyen.nes.  Ce dispositif produit un certain nombre de données, les
plus intéressantes étant probablement les propositions et les
commentaires qui y sont attachés.

Open Source Politics (OSP) est une entreprise relevant du champ de
l'économie sociale et solidaire qui développe des plateformes numériques
libres et open source et anime des ateliers d'intelligence collective
pour accompagner des acteurs publics, privés et associatifs engagés dans
des démarches participatives.

Les chercheurs du LaSTIG, de l'EHESS et d'OSP travaillent sur les
budgets participatifs de plusieurs villes et ces corpus, par leur
taille, justifient l'utilisation d'outils de TAL afin d'effectuer des
synthèses aux institutions qui ont confié leurs données et leur faire un
retour sur la conception de leur budget participatif.

*Sujet*

Différents indicateurs et outils d'analyse des corpus de propositions
ont déjà été mis en oeuvre par les partenaires, mais ils dépendent de la
taille des corpus et des a priori des villes et diffèrent par leur
facilité d'utilisation. Dans ce contexte, l'objectif du stage est triple :


- proposer et mettre en oeuvre de nouvelles pistes d'analyse de ces
  corpus et détailler les variables sur lesquelles fonder la conception
  d'un budget participatif ;
- définir un protocole minimal d'analyse de budget participatif
  (catégories, propositions, commentaires) ;
- caractériser les BP, les préoccupations des contributeurs des
  différentes villes et leur évolution dans le temps par une analyse
  contrastive des différents corpus (différentes villes, plusieurs
  années).


Une partie du stage se déroulera chez OSP, et dans ce contexte, Dans la
partie du stage se déroulant chez OSP, le ou la stagiaire aura l'occasion
de se familiariser avec la technique du budget participatif déployée par
cette entreprise, et l'utilisation pratique du traitement automatique de la
langue dans un cadre professionnel.


*Productions attendues : *

- rédaction d'un mémoire qui devra répondre aux objectifs du stage ;
- définition d'un protocole minimal d'analyse de budget participatif
  (catégories, propositions, commentaires).

*Compétences particulières et formation requise*

Ce stage s'adresse aux étudiants de master 2 ou de 3ème année d'école
d'ingénieurs avec une spécialisation en informatique ou en TAL, ainsi
qu'à .des étudiants de master 2 dans une filière en sciences sociales
ayant des connaissances solides en TAL ou en textométrie.

*Lieu du stage*

Laboratoire en sciences et technologies de l'information géographique

Institut national de l'information géographique et forestière
73 avenue de Paris
94165 Saint-Mandé Cedex
métro : Saint-Mandé - ligne 1 ou RER A - Vincennes

*Durée et rémunération*

durée : 5 mois
début : avril 2019
gratification : environ 550 euros mensuels

*Prolongements éventuels*

Le COGIT propose chaque année des bourses de thèse ainsi que des
contrats de post-doctorant.

*Encadrement du stage*

Catherine Dominguès
IGN/DRE/LaSTIG/COGIT, 73 avenue de Paris, 94165 Saint-Mandé Cedex
mél : *catherine.domingues[@]ign.fr*


Carmen Brando

Centre de recherches historiques / Plateforme Géomatique de l'EHESS
54 boulevard Raspail, 75006 Paris
mél : carmen.brando@ehess.fr

Antoine Gaboriau (doctorant CIFRE EHESS/OSP)
Liberté Living Lab, 9 rue d'Alexandrie, 75002 Paris
mél : *antoine@opensourcepolitics.eu*

*Pour candidater*

Le dossier de candidature sera envoyé par courriel aux trois
encadrants. Il devra se composer d'un curriculum vitae et d'une lettre
de motivation, accompagnés des relevés de notes des années de M1 et M2
(ou deux dernières années d'école d'ingénieurs), de la description des
enseignements suivis (un lien vers le site internet de la formation est
le bienvenu) et du dernier rapport de stage ou mémoire rédigé (en
version électronique)."
"554","2019-01-07","LIUM / SNCF","Le Mans","Bonjour à tou.te.s,

Le LIUM propose une offre de stage de *Master 2* en partenariat avec la
SNCF autour des word embeddings.

*Sujet de stage* : Améliorer la catégorisation de documents à l'aide des
word embeddings.

*Laboratoire d'accueil* : LIUM, Équipe LST - https://lium.univ-lemans.fr 
*Partenaire industriel* : SNCF INNOVATION & RECHERCHE
*Site* : Le Mans
*Co-encadrement* : Nathalie Camelin (nathalie.camelin@univ-lemans.fr), 
 Nicolas Dugué (nicolas.dugue@univ-lemans.fr)

*Résumé* : Le LIUM a mis en oeuvre une chaîne de traitement pour
apprendre des word embeddings sur le corpus SNCF dont le vocabulaire est
très spécialisé. La qualité des vecteurs a été évaluée qualitativement
par des agents SNCF. Il s'agit pour le stage d'utiliser ces word
embeddings dans le processus de classification des documents, notamment
en utilisant des Convolutional Neural Networks. Le stagiaire pourra
également contribuer à améliorer l'apprentissage des word embeddings,
une nouvelle évaluation des représentations apprises est prévue avec les
agents SNCF dans la suite du projet.

*Pour postuler : *Écrire à Nathalie Camelin et Nicolas Dugué avec un CV,
une lettre de motivation et votre relevé de notes de M1.

Merci de transmettre aux intéressé.e.s.

Cordialement

Nicolas Dugué"
"555","2019-01-07","SNCF","Saint-Denis","Offre de stage SNCF : analyse d'émotions et d'opinions dans les
interactions client/agent ou agent/agent

La Direction Innovation & Recherche de SNCF recherche un stagiaire pour
travailler sur un projet d'étude ayant pour objectif de mieux comprendre
le ressenti des clients et des agents, et de détecter ce qui génère
satisfaction ou insatisfaction, à travers l'exploration de données
textuelles.

Mission :
Avec la montée en puissance des chatbots, agents conversationnels, ou
encore agents virtuels, la détection automatique ou semi-automatique des
émotions devient un enjeu industriel important. En effet, si un
assistant intelligent est capable de comprendre et de s'adapter en
fonction de l'état émotionnel de son utilisateur, alors ce dernier sera
plus enclin à accepter sa présence ainsi que son rôle.
Dans le cadre de cette problématique, SNCF souhaite mener une étude sur
la détection des émotions dans ses données. Celles-ci sont de type
textuel et sont issues de plusieurs sources : web, chatbots SNCF, forums
dédiés aux agents.
Le stagiaire aura pour mission d'analyser linguistiquement les marqueurs
d'émotions et d'opinions dans des corpus SNCF, d'étudier et de mettre en
oeuvre  des méthodes existantes, notamment en Traitement Automatique du
Langage, pour la détection des émotions dans les corpus mentionnés
ci-dessus. L'objectif du stage est double : i) le travail permettra de
tester le potentiel des technologies de TAL pour la détection des
émotions ; ii) les analyses fournies mettront en lumière la valeur des
données SNCF pour des cas d'usage client ou métier.

Descriptif de la mission :
Pour mener à bien son étude, le stagiaire devra :

- Prendre connaissance du contexte du stage (SNCF, Direction Innovation
  & Recherche, objectifs du stage et cadre de réalisation, projet dans
  lequel le stage s'insère et interlocuteurs sur les sujets concernés)

- Faire un état de l'art sur la détection des émotions dans les données
  langagières

- Constituer le corpus d'étude : nettoyer, transcrire, étiqueter les
  données SNCF

- Définir une grille d'annotation, analyser linguistiquement et annoter
  le corpus en marqueurs d'émotions

- Evaluer la qualité de l'annotation et la richesse du corpus en
  marqueurs d'émotions

- Proposer et tester des pistes d'exploitation des résultats à l'aide
  d'outils de traitement automatique du langage au regard des usages et
  besoins métiers

Présentations et rapports :

- Présentation de début de stage à la SNCF (au bout d'un mois de stage)
  : contexte du stage, planning de réalisation, premiers travaux
  réalisés, méthode envisagée

- Rapport final de stage complet comprenant : bref état de l'art,
  méthode retenue, travaux réalisés, résultats obtenus et difficultés
  rencontrées...

- Deux soutenances de fin de stage : une à l'école et une à la SNCF

- Des présentations en interne SNCF ou externes pourront être effectuées

Période souhaitée :
Avril - Septembre 2019

Diplôme préparé :
Master en Traitement Automatique des Langues, ou en Sciences du Langage
avec des notions d'informatique.

Profil souhaité / Particularités :

- Compétences en Traitement Automatique des Langues (TAL), ou en
  Sciences du Langage avec de bonnes notions en TAL

- Manipulation et test des outils de TAL

- Capacités d'analyse et de synthèse

- Autonomie, qualités relationnelles, qualité de présentation
  (orale/écrite)

Modalités du poste

- Durée : 6 mois

- Rémunération prévue : indemnités de stage + carte de circulation SNCF

- Début : à partir d'avril 2019

- Lieu : Saint-Denis

Tuteur : Luce Lefeuvre

Merci d'adresser CV et lettre de motivation à Luce Lefeuvre et Coralie
Reutenauer à l'adresse mail suivante : coralie.reutenauer@sncf.fr . Date
limite de soumission des candidatures : 20 janvier 2019."
"556","2019-01-07","LS2N","Nantes","3-6 Month ""Artificial Intelligence for Learning"" Internship Offers
https://aile.comin-ocw.org

The University of Nantes/LS2N Lab. (ls2n.fr) and IMT Atlantique (imt-atlantique.fr) aim at recruiting several 3-6 months interns to join our teams, starting in Spring/Summer of 2019.

The students are intended to work on research projects targeted at the Learning, Teaching and Education domains we have got running. A brief description of each internship topics is given below. The Artificial Intelligence domains concerned are Machine Learning, Data mining, Natural Language Processing, Distributed Data Management, Web Semantic, Learning analytics, User Interaction modeling.

If you are interested or have any questions, please do not hesitate to contact Olivier Aubert (olivier.aubert@univ-nantes.fr), Nicolas Hernandez (nicolas.hernandez@univ-nantes.fr) and the referrer of the internship topic.
To apply, send a curriculum vitae together with your academic results and a motivation letter and indicate the topics of interest.


Context and objectives
=================

  Artificial Intelligence is sometimes described as the new electricity. As such, it is supposed to have a profound influence over many fields, of which Education has been repeatedly singled out.

  At University of Nantes, IMT Atlantique and Ecole Centrale, researchers have taken on questions relating AI and education for some time now through several national and international projects such as COCo (coconotes.comin-ocw.org), Hubble (hubblelearn.imag.fr), PASTEL (projets-lium.univ-lemans.fr/pastel), SEDELA (sedela.cominlabs.u-bretagneloire.fr), eFIL (efil.cominlabs.u-bretagneloire.fr), X5-GON (www.x5gon.org), ClassCode (pixees.fr/classcode-v2).

  The AILE (Artificial Intelligence for Learning Environment) project (https://aile.comin-ocw.org) aims at strengthening this eco-system, to develop some regular scientific activities (seminars, joint events), and to prepare their activities in the theme over the next 5 years.


Internship topics (sujets de stage) list
============================

  In addition to the topic study, the students will also participate to transversal team activities involving simultaneously all the students and the researchers (research reading groups, seminars, conference organization).

Measuring the hardness of an educational resource
--------------------------------------------------------------------
  - Many educational resources are available on the web but it is important to evaluate automatically the age group the resource is intended for and the level required to understand it. This task requires the use of machine learning. This project is principally based on X5-GON data.
  - Referrers: Colin de la Higuera (cdlh@univ-nantes.fr), LS2N TALN team

Detecting the theme shifts in a lecture
--------------------------------------------------
  - In a lecture presented by a one hour video or a 50 pages pdf, the themes vary over time. We aim to use techniques from data science to study the so-called concept drift in this context. This project is based on X5-GON/PASTEL data.
  - Referrers: Nicolas Hernandez (nicolas.hernandez@univ-nantes.fr) and Colin de la Higuera (cdlh@univ-nantes.fr), LS2N TALN team

Predicting MOOC attrition
----------------------------------
  - Using learning traces left by MOOC users, and generalizing from previous activities, can we compute attrition indicators? This project is based on HUBBLE data.
  - Referrers: Antoine Pigeau (antoine.pigeau@univ-nantes.fr), LS2N DUKe team

Mixing AI techniques to give relevant insights on Mooc attrition
------------------------------------------------
  - Using learning traces left by MOOC users, how can we mix AI techniques to give relevant insights and explainable results as well. This project is based on HUBBLE data.
  - Referrers: Serge Garlatti (Serge.Garlatti@imt-atlantique.fr), IHSEV Lab-STICC

Designing feedback
---------------------------
  - How can we design feedback, for example dashboards that makes those insights explicit and actionable for the users?  This project is based on HUBBLE data.
  - Referrers: Jean-Marie Gilliot (jm.gilliot@imt-atlantique.fr), IHSEV Lab-STICC

Resource evolution
--------------------------
  - Analyzing user activity would allow to identify activities generating unexpected behaviour, and therefore help resource/MOOCs authors to refactor their content using this information. This project is principally based on FUN MOOCs data.
  - Referrers: Yannick Prié (yannick.prie@univ-nantes.fr), LS2N DUKe team

What next?
---------------
  - Identification and suggestion of personalized pedagogical paths (made of texts, videos, and other media) according to specific objectives of knowledge and competencies to be acquired by the learner. This is mainly related to X5-GON data.
  - Referrers: Hoël le Capitaine (hoel.lecapitaine@univ-nantes.fr), LS2N DUKe team

From micro-competence to professional project.
--------------------------------------------------------------
  - Can we support learner to define their personal learning paths, in terms of objectives and aimed competencies? A meta review on AI, competencies and self development will be part of the work;
- Referrers: Jean-Marie Gilliot (jm.gilliot@imt-atlantique.fr) & Issam Rebaï (issam.rebai@imt-atlantique.fr), IHSEV Lab-STICC

Educational datahub
-------------------------
  - Re-centralizing data is a powerful paradigm to enable semantic indexing, incremental data integration, and query discovery. Many resources exist in education but they are spread around the web. We propose to build a datahub for educational resources. This portal accepts resources as RDF data and allows query processing across data.
  - Referrers: Hala Skaf (hala.skaf@univ-nantes.fr), LS2N GDD team


Who You Are
==========
  - Pursuing an Engineering degree or a Masters degree in Artificial Intelligence, Data Science, Natural Language Processing, Machine Learning or a related field
  - Capacity to work independently, as well as collaborate within a team
  - Solid programming skills"
"557","2019-01-09","LIFO","Orléans","Le LIFO (Laboratoire d'Informatique fondamentale d'Orléans) recherche un
étudiant de Master 2 à partir de janvier 2019 pour la réalisation d'un
stage de recherche d'une durée de 6 mois et dont la description est
donnée ci-après.

Le personne recrutée terminera soit un *Master en Informatique* avec un
intérêt pour le Traitement Automatique des Langues, soit un *Master en
TAL*.

Dépôt des candidatures par courrier électronique auprès des trois
encadrants principaux _*avant le vendredi 18 janvier 2019*_, délai de
rigueur. Merci de joindre à votre candidature :

  * un CV détaillé de vos activités passées
  * une lettre de motivation
  * vos relevés de notes des deux dernières années d'études

*------ Description du sujet **------*

_*Titre*_ : Apprentissage de modèles pour l'extraction de graphes
temporels dans les discours

_*Description du stage*_ : Le groupe de travail ""Prétopologie, TAL et
temporalité"" réunit des chercheurs des laboratoires LIFO et LLL
spécialisés en Linguistique, Traitement Automatique des Langues et
Apprentissage Automatique. Le sujet d'étude de ce groupe est l'analyse
du discours et plus particulièrement la tâche consistant à extraire d'un
texte annoté une structure temporelle prenant la forme d'un DAG (Graphe
Orienté sans Cycle) d'événements verbaux pré-identifiés [Ning et al.,
2017]. L'approche envisagée consiste à apprendre un espace
prétopologique structurant (algorithme LPS [Caillaut&Cleuziou, 2018] à
partir d'un ensemble de prédicats censés capturer l'information
linguistique, lexicale, syntaxique et sémantique portée par chaque
événement temporel.

Le stagiaire aura pour mission la réalisation d'une preuve de concept
par le développement d'une chaîne de traitement complète permettant
d'extraire les relations prédicatives à partir d'une corpus d'énoncés
pré-annotés. Il participera à l'élaboration de ces prédicats en
concertation avec l'équipe au regard des travaux récents sur cette
problématique et évaluera quantitativement et qualitativement les
structures temporelles issues de l'algorithme LPS relativement aux
prédicats construits et aux approches existantes.

_*Encadrants*_ :

  * Encadrants principaux : Anaïs Lefeuvre-Halftermeyer
    (anais.halftermeyer@univ-orleans.fr) , Gaëtan Caillaut
    (gaetan.caillaut@univ-orleans.fr), Anne-Lyse Minard
    (anne-lyse.minard@univ-orleans.fr)

  * Autres membres du groupe de travail : Sylvie Billot et Guillaume
    Cleuziou

_*Références*_ :

[Caillaut&Cleuziou, 2018] Gaëtan Caillaut, Guillaume Cleuziou: Learning
Pretopological Spaces to Model Complex Propagation Phenomena: A Multiple
Instance Learning Approach Based on a Logical Modeling. CoRR
abs/1805.01278 (2018)

[Ning et al., 2017] Qiang Ning, Zhili Feng, Dan Roth: A Structured
Learning Approach to Temporal Relation Extraction. EMNLP 2017: 1027-1037

Paramita Mirza and Anne-Lyse Minard. HLT-FBK: a complete Temporal
Processing system for QA TempEval. In Proceedings of the 9th
International Workshop on Semantic Evaluation (SemEval 2015).

_*Rémunération*_ : conventionnelle (~570¤ mensuel)"
"558","2019-01-16","Jouve","Lens","Sujet de stage : Améliorer la classification de brevets à l'aide des
dernières technologies de l'IA (word embedding, deep learning, ...)

Durée :  Stage M2 de 4 à 6 mois,
Disponibilité : dès que possible
Lieu : Jouve, Parc d'activités du Gard, 62300 Lens

Contexte : Nous recherchons un stagiaire qui est intéressé par
           l'intelligence artificielle (IA) et le traitement automatique
           des langues (TAL)
           Spécialiste du traitement des données,  Jouve est un acteur
           important dans la dématérialisation des brevets.
           Le service R&D de Jouve a réalisé une chaîne de
           classification sémantique de brevets utilisant plusieurs
           méthodes (classifieurs SVM, méthodes par similarité,...)
           Au sein du service R&D et rattaché(e) à l'Ingénieur R&D, vous
           serez en charge de la recherche sur la classification
           sémantique de documents.

Missions :

  * Réaliser un état de l'art en se focalisant sur les dernières
    techniques (word-embedding, deep learning, ...), les différentes
    directions d'approfondissement des recherches seront alors définies.
  * Contribuer à l'amélioration des résultats de précision et de rappel
    de la classification et ajouter des traitements de visualisation.
  * Pour la visualisation, mettre en évidence des relations entre les
    termes de l'intitulé de classe  et le brevet lui-même.
  * Préparer des données /Apprentissage deep-learning ou autre
    classifieur/Evaluation/Visualisation
  * Mettre en place des tests et des apprentissages : plusieurs millions
    de brevets sont disponibles.

Vos forces et vos atouts :

  * Autonomie, curiosité et forte appétence « recherche »,
  * Esprit d'équipe
  * Connaissances en :
    - TALN (Traitement Automatique du Langage Naturel), Lemmatisation/
      * Analyse syntaxique / word embedding
    - Intelligence Artificielle : Réseaux de Neurones, SVM , deep
      learning
  * Au moins un de ces langages : C/C++, python, R, ...

Qui sommes-nous ? :

Entreprise :  Jouve (www.jouve.com) propose des
solutions et services pour transformer les données les plus complexes de
ses clients, optimiser leurs processus métiers et créer de nouvelles
expériences digitales. Pionnier sur les marchés de l'aéronautique et de
l'édition, Jouve propose également des solutions innovantes pour
répondre aux nouveaux besoins des acteurs de l'industrie, de la banque,
de l'assurance, de la santé et de l'éducation.  Jouve compte 2500
collaborateurs et est implanté dans 14 pays en Europe, en Amérique du
Nord, en Afrique et en Asie. Jouve Lens a bâti ses équipes managériales,
commerciales et d'ingénierie sur des profils dotés de connaissances
avancées dans le domaine de la conversion numérique.

Pour postuler : Ecrire aux Ressources Humaines, Marie Mendy
(mmendy@jouve.com) , avec un CV, une lettre de motivation et votre
relevé de notes de M1"
"559","2019-01-17","IGN","Saint-Mandé","CrÃ©ation d'une base de connaissances sur les ports Ã  partir des textes
des instructions nautiques

Mots-clÃ©s:  crÃ©ation et peuplement de bases de connaissances
gÃ©orÃ©fÃ©rencÃ©es, intÃ©gration de donnÃ©es Ã  rÃ©fÃ©rences spatiales,
extraction d'informations topographiques Ã  partir de textes.

Contexte et objectifs

L'Institut national de l'information gÃ©ographique et forestiÃ¨re (IGN)
et le Service Hydrographique et OcÃ©anographique de la Marine (SHOM)
sont les opÃ©rateurs publics respectivement en charge de l'information
gÃ©ographique et forestiÃ¨re et de l'information gÃ©ographique maritime
et littorale de rÃ©fÃ©rence. Ã€ ce titre, les deux Ã©tablissements
produisent des rÃ©fÃ©rentiels et des services destinÃ©s Ã  rÃ©pondre aux
besoins d'informations gÃ©olocalisÃ©es, notamment au profit des
politiques publiques comportant des enjeux d'analyse spatiale et de
localisation. Ceci suppose de produire des rÃ©fÃ©rentiels qui soient Ã 
la fois les plus exhaustifs, dÃ©taillÃ©s, qualifiÃ©s, Ã  jour et
interopÃ©rables possibles.

Les rÃ©fÃ©rentiels de donnÃ©es gÃ©orÃ©fÃ©rencÃ©es sont de plus en plus
utilisÃ©s pour permettre l'annotation spatiale de documents textuels et
ainsi faciliter l'accÃ¨s Ã  leur contenu, voire son analyse spatiale. En
revanche, peu de travaux se sont intÃ©ressÃ©s Ã  l'extraction
d'information gÃ©ographique Ã  partir de textes pour alimenter de tels
rÃ©fÃ©rentiels. Pourtant, certains textes offrent des descriptions de
l'espace trÃ¨s prÃ©cises et dÃ©taillÃ©es et constituent parfois la seule
source d'informations disponible.

Ce stage explorera les potentialitÃ©s de l'extraction d'information Ã 
composante spatiale dans des textes alliÃ©e aux standards du Web de
donnÃ©es pour construire et peupler une base de connaissances sur les
ports et mouillages dÃ©crivant leur localisation, leur configuration
spatiale, leurs Ã©quipements, etc. Ã  partir des  Instructions Nautiques
produites par le SHOM. L'objectif est de se doter de connaissances
structurÃ©es pour rÃ©pondre Ã  des requÃªtes sur la localisation des ports
et mouillages, leurs conditions d'accÃ¨s et d'utilisation et Ã  terme
dÃ©velopper des services d'aide Ã  la navigation Ã  base de raisonnement.

Corpus de travail

Les  Instructions Nautiques  sont des documents textuels dÃ©crivant les
amers et dangers pour la navigation cÃ´tiÃ¨re, les ports et mouillages,
leurs chenaux d'accÃ¨s, leurs Ã©quipements et les services proposÃ©s aux
navigateurs, etc.

Les sections dÃ©diÃ©es Ã  la description des ports et mouillages suivent
une structure relativement rÃ©guliÃ¨re. Elles dÃ©butent par un paragraphe
dÃ©crivant la localisation gÃ©nÃ©rale du port, sa capacitÃ© d'accueil
ainsi que son statut administratif. Puis viennent le plus souvent des
explications sur les manoeuvres de chenalage pour y accÃ©der, suivies
d'une description des diffÃ©rentes zones de mouillage et installations
portuaires. On y trouve enfin la liste des Ã©quipements - notamment Ã 
destination des plaisanciers - ainsi que les coordonnÃ©es des services
utiles - bureau du port, mairie, dÃ©lÃ©gation Ã  la mer et aux affaires
littorales, etc. L'extrait ci-dessous dÃ©crit le port de
Saint-Cast.Extrait des instructions nautiques pour le port de
Saint-Cast (Source : SHOM)

Verrous scientifiques

Il s'agira d'extraire, typer, dÃ©sambiguÃ¯ser et structurer les
informations sur les ports et les diverses entitÃ©s spatiales qui les
composent dÃ©crites par les textes (noms, types d'objets gÃ©ographiques,
localisations absolues et relatives, fonctions, ...) pour les intÃ©grer
dans une base de connaissances et vÃ©rifier la cohÃ©rence des
informations extraites, infÃ©rer de nouveaux faits. Ceci suppose de
proposer des solutions pour :

- Adapter les approches existantes d'extraction d'information Ã 
composante spatiale Ã  partir de textes Ã  des corpus techniques
caractÃ©risÃ©s par un vocabulaire trÃ¨s spÃ©cifique au domaine,
maisrelativement peu structurÃ©s au sein des diffÃ©rentes sections. En
particulier, de nombreuses entitÃ©s spatiales mentionnÃ©es ne possÃ¨dent
pas de nom ;

- ReprÃ©senter, stocker et manipuler des informations Ã  composante
spatiale qualitative (rÃ©fÃ©rences spatiales indirectes, positionnement
relatif, etc.) et Ã  diffÃ©rents niveaux de dÃ©tail selon les standards
du Web de donnÃ©es ;

- DÃ©sambiguÃ¯ser les entitÃ©s spatiales extraites. Ceci nÃ©cessite de
prendre en compte :

	- des critÃ¨res de liage dont la disponibilitÃ© pourra varier,

	- les Ã©ventuelles variations des entitÃ©s spatiales d'une source Ã 
l'autre (variations de nom, de propriÃ©tÃ©s, de temporalitÃ©, de niveau
de dÃ©tail de descriptions, etc.).

- DÃ©tecter et corriger d'Ã©ventuelles incohÃ©rences spatiales ou
temporelles dans les informations extraites, amÃ©liorer le typage des
entitÃ©s spatiales, infÃ©rer des relations spatio-temporelles entre
entitÃ©s gÃ©ographiques, etc.

Renseignements pratiques

Une poursuite du sujet de stage en thÃ¨se de doctorat est possible (financement SHOM/IGN).

Profil recherchÃ© : Master 2 ou diplÃ´me d'ingÃ©nieur en informatique :
reprÃ©sentation de connaissances, Web sÃ©mantique, sciences de
l'information gÃ©ographique, extraction d'informations Ã  partir de
textes.

CompÃ©tences et connaissances:
- Un bon niveau en programmation est essentiel

- En raison de la nature du corpus de documents, la maÃ®trise du
  franÃ§ais est nÃ©cessaire.

- Extraction d'informations Ã  partir de textes.

- DonnÃ©es gÃ©ographiques vectorielles.

- Web de donnÃ©es, notamment RDFS et OWL.

DurÃ©e et pÃ©riode de stage :  5 mois, au cours du printemps et de l'Ã©tÃ©
2018.

Lieu du stage :  Equipe  LaSTIG /Strudel,  Institut national de
l'information gÃ©ographique et forestiÃ¨re (IGN), Saint-MandÃ© (mÃ©tro 1,
station Saint MandÃ©).

IndemnitÃ©s de stage :  Stage gratifiÃ© selon la lÃ©gislation franÃ§aise.

ModalitÃ©s de candidature : Envoyer un CV, une lettre de motivation 
ciblÃ©e sur le sujet et les relevÃ©s de notes des 2 derniÃ¨res annÃ©es
d'Ã©tudes par email, au format PDF et en un seul fichier Ã 
nathalie-f.abadie@ign.fr

Encadrement du stage :

- Nathalie Abadie (LaSTIG - COGIT/Strudel,  IGN, 
  nathalie-f.abadie@ign.fr )

- Eric Kergosien (Geriico - UniversitÃ© de Lille, 
  eric.kergosien@univ-lille3.fr )

- Eric Saux (Irenav - Ecole Navale,  eric.saux@ecole-navale.fr )"
"560","2019-01-17","IGN","Saint-Mandé","Géoréférencement d'images anciennes à l'aide des indications de
localisation fournies par leurs métadonnées

Mots-clés:  Web de données, référentiels de données géographiques
vectorielles, analyse spatiale, extraction d'informations
topographiques à partir de textes, programmation.

Contexte

De plus en plus d'institutions patrimoniales et culturelles publient
les catalogues des collections dont elles ont la garde sur le Web afin
de faciliter la découverte de ces collections. Ces catalogues se
composent, pour chaque ressource patrimoniale ou culturelle, de
métadonnées permettant d'en découvrir le contenu même lorsque aucune
copie numérique de la ressource n'est disponible: titre, auteur,
éditeur, date, mots-clés, etc. Désenclaver ces jeux de métadonnées
suppose de les interconnecter avec des référentiels communs, comme des
thésaurus sur les types d'oeuvres architecturales, des index d'auteurs
ou des jeux de données géographiques. Ceci permet de désambiguïser les
chaînes de caractères utilisées pour désigner les auteurs, les types
d'oeuvres ou les lieux en leur substituant les identifiants de
ressources décrites par les référentiels et faisant autorité. En
outre, ceci permet de naviguer aisément au travers des collections et
de leurs référentiels associés en suivant les liens ainsi explicités.

Le projet  ALEGORIA vise à valoriser des fonds iconographiques
institutionnels décrivant le territoire français à différentes époques
allant de l'entre-deux-guerres à nos jours. Ces clichés s'accompagnent
de métadonnées, et lorsqu'une photographie représente une entité
géographique, sa légende peut contenir des indications sur la
localisation de cette entité ou sur le lieu de prise de vue. On
retrouve ce type d'informations dans les métadonnées de la
photographie présentée en figure 1.

Figure 1: Une photographie conservée au musée Nicéphore Niépce et ses
métadonnées
(http://www.open-museeniepce.com/recherche-photos/photo,2611 )

Principales hypothèses et objectifs du stage

Une des réalisations prévues par le projet  ALEGORIA est un moteur
d'indexation et de recherche multimodal et à grande échelle, couplant
recherche par contenu et par métadonnées dans les fonds d'images
numérisées et documentées. Ce moteur s'appuiera, entre autres, sur les
indications de localisation fournies par les métadonnées des images.

L'objectif de ce stage est de faciliter l'exploitation par le moteur
d'indexation des indications de localisation disponibles dans les
métadonnées. Une première étape consistera à extraire des métadonnées
des jeux d'images du projet ALEGORIA les indications de localisation,
représentées sous la forme d'entités spatiales nommées [M15]. Il
conviendra en outre de déterminer si ces entités spatiales nommées
désignent le contenu de l'image ou le lieu de sa prise de vue. Enfin,
une dernière étape consistera à résoudre ces entités spatiales
nommées, c'est-à-dire à associer à chaque mention d'entité spatiale
nommée l'identifiant de l'entité géographique du monde réel à laquelle
elle fait référence [PAB17]. L'utilisation d'un jeu de données
géographiques de référence comportant des indications de localisation
directes (coordonnées ou géométrie), permettra de localiser
précisément les entités spatiales mentionnées dans les métadonnées.

Verrous scientifiques

Une première difficulté réside dans le manque d'informations de
contexte dans les métadonnées, dans la mesure où ce sont des textes
relativement courts. Les approches d'extraction et de résolution des
entités spatiales choisies devront s'adapter à cette contrainte.

Le traitement des entités spatiales relatives constitue une seconde
difficulté majeure. En effet, il s'agit d'entités spatiales
identifiées et localisées par référence à une autre entité spatiale
nommée, comme ""la rive droite de la Saône"" par exemple. L'approche
d'extraction proposée devra être en mesure de détecter ces entités
spatiales relatives. En outre, dans la mesure où elles ne figurent pas
dans les référentiels géographiques, il conviendra de proposer une
approche pour dériver leur localisation à partir des données
géographiques disponibles.

Renseignements pratiques

- Formation : Master 2 ou troisième année d'école d'ingénieur en
informatique ou en géomatique avec une forte composante informatique.

- Durée et période de stage : 5 mois, au cours du printemps et de
  l'été 2018.

- Lieu de stage : Equipe  LaSTIG /Strudel,  Institut national de
l'information géographique et forestière (IGN), Saint-Mandé (métro 1,
station Saint Mandé).

- Indemnités de stage:  Stage gratifié selon la législation française.

- Modalités de candidature : Envoyer par email un fichier PDF avec
votre curriculum vitae, une lettre de motivation ciblée sur le sujet ,
vos relevés de notes des deux dernières années d'études.

- Encadrement de stage :
 Nathalie Abadie (IGN/COGIT):  nathalie-f.abadie[]ign.fr
 Carmen Brando (EHESS):  carmen.brando[]ehess.fr

- Bibliographie

[M15] Moncla, L. (2015) Automatic Reconstruction of Itineraries from
Descriptive Texts. Thèse de doctorat de l' Université de Pau et des
Pays de l'Adour et de l'Université de Saragosse.

[PAB17] Paris, P-H, Abadie, N., Brando C. (2017). Linking spatial
named entities to the Web of Data for geographical analysis of
historical texts. Journal of Map & Geography Libraries. Volume 13,
2017 - Issue 1: Semantic Historical Gazetteers: A Place for Places -
Papers from the DH2016 GeoHumanities SIG Workshop."
"561","2019-01-17","GREYC","Caen","Research Internship on Multimodal Deep Learning Techniques for the
Identification of Asymmetric Relations

Gaël Dias, Youssef Chahir and Houssam Akhmouch

CNRS GREYC UMR 6072 - Normandy University

Internship Description

Traditionally in classification, a learning example refers to a unique
object 0 A that must be categorized in some class given an input set
of features. For example in sentiment classification, a text
transformed in some learning representation can be classified either
as positive, negative or neutral [4].

But many other situations exist. In this internship, we are
particularly interested in identifying relations between pairs of
objects. In this case, a learning example (0 A r 0 B ) refers to a
pair of objects 0 A and 0 B that must be transformed in some
learning representation so that the model can predict if some relation
r holds between them, or not. For instance, in image classification, a
model may have to predict if two patches are similar or not [10].

Within this context, a vast majority of works have been tackling
symmet- ric relations (e.g. matching images, synonymy detection),
while asymmetric relations (e.g. textual entailment, temporal image
ordering) have received less attention. Indeed, it has been shown that
asymmetry is usually a difficult prob- lem [8] as it involves the
direction of the relation. So, if two objects O A and O B are in an
asymmetric relation , let's say (O A -> O B ), then the learning
example (O A -> O B ) is a positive example, while (O B -> O A ) is a
negative example.

In this internship, we are particularly interested in designing
learning models that can positively handle asymmetry. Different work
directions will be studied such as (1) the development of specific
asymmetric deep learning architectures [2, 9], (2) the computation of
semantic feature spaces capable of handling asymmetry [7, 1, 3, 6]
or (3) a combination of both ideas [5]. In particular, multimodal
(text, image and text/image) experiments will be performed on gold
standard data sets in order to evaluate the performance of the
different proposed models.

Candidate Profile

The successful candidate must pursue Master or Engineering School
level stud- ies in Data Science, Computer Science, Applied
Mathematics, or related scientific fields and show strong background
in Mathematics, Machine Learning and Programming. Additional knowledge
in Deep Learning (both theoretically and practically) will be highly
appreciated as well as experience in Natural Language Processing
and/or Computer Vision.


Internship Organization

The internship will start at the beginning of 2019 (January, February
or March) and will last up to 6 months. It will take place at the CNRS
GREYC UMR 6072 Laboratory in Caen (France). Some visits to the
internship partner Crédit Agricole Brie Picardie in Serris near Paris
will be planned. The candidate will be compensated following the rules
in force for internships. Note that the internship is subject to the
establishment of a preliminary internship agreement.

Internship Perspectives

Depending on the obtained results and the dedication/motivation of the
success- ful candidate, there shall be a possibility to pursue PhD
studies in collaboration with all the internship partners, i.e. CNRS,
Normandy University and Crédit Agricole Brie Picardie.


Application Procedure

Applicants are requested to submit their application with an academic
CV, copies of academic degree records and certificates, and two
potential references (if possible). Applications must be sent directly
to the internship coordinators:

Gaël Dias (gael.dias@unicaen.fr), Youssef Chahir (youssef.chahir@unicaen.fr)
and Houssam Akhmouch (houssam.akhmouch@unicaen.fr).

Note that the CNRS GREYC UMR 6072 is committed to being a fully
inclusive institution which actively recruits staff from all sectors
of society. It is proud to be an equal opportunities employer and
encourages applications from everybody, regardless of race, sex,
ethnicity, religion, nationality, sexual orientation, age, disability,
gender identity, marital status/civil partnership, pregnancy and
maternity, as well as being open to flexible working practices.

References

[1] Haw-Shiuan Chang, ZiYun Wang, Luke Vilnis, and Andrew McCallum.
Distributional inclusion vector embedding for unsupervised hypernymy de-
tection. In Conference of the North American Chapter of the Association
2for Computational Linguistics: Human Language Technologies (NAACL-
HLT), pages 485-495, 2018.
[2] Goran Glava¨ and Simone Paolo Ponzetto. Dual tensor model for detecting
asymmetric lexico-semantic relations. In Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages 1757-1767, 2017.
[3] Goran Glava¨ and Ivan Vulic. Explicit retrofitting of distributional word
vectors. In 56th Annual Meeting of the Association for Computational
Linguistics (ACL), volume 1, pages 34-45, 2018.
[4] Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. Recurrent convolutional
neural networks for text classification. In 29th AAAI Conference on Arti-
ficial Intelligence (AAAI), volume 333, pages 2267-2273, 2015.
[5] Simon Moura, Amir Azarbaev, and Massih-Reza Amini. Heterogeneous
dyadic multi-task learning with implicit feedback. In 25th International
Conference on Neural Information Processing (ICONIP), 2018.
[6] Marek Rei, Daniela Gerz, and Ivan Vulic. Scoring lexical entailment with
a supervised directional similarity network. In 56th Annual Meeting of the
Association for Computational Linguistics (ACL), pages 638-643, 2018.
[7] Ivan Vulic and Nikola Mrksic. Specialising word vectors for lexical entail-
ment. In Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies (NAACL-
HLT), pages 1134-1145, 2018.
[8] Ekaterina Vylomova, Laura Rimell, Trevor Cohn, and Timothy Baldwin.
Take and took, gaggle and goose, book and read: Evaluating the utility
of vector differences for lexical relation learning. In 54th Annual Meeting
of the Association for Computational Linguistics (ACL), pages 1671-1682,
2016.
[9] Qi Wang, Tong Ruan, Yangming Zhou, Daqi Gao, and Ping He. An
attention-based bi-gru-capsnet model for hypernymy detection between
compound entities. arXiv preprint arXiv:1805.04827, 2018.
[10] Sergey Zagoruyko and Nikos Komodakis. Learning to compare image
patches via convolutional neural networks. In IEEE Conference on Com-
puter Vision and Pattern Recognition (CVPR), pages 4353-4361, 2015."
"562","2019-01-18","Crigen-Engie",NULL,"Offre de stage R&D chez Crigen-ENGIE
Active Learning
Vision par ordinateur, Traitement Automatique du Langage

Contexte

ENGIE est l'un des leaders mondiaux dans les domaines de l'énergie et de
l'environnement. ENGIE est fortement engagé dans la transition
énergétique et dans le développement des énergies renouvelables.

L'équipe de recherche et de développent du lab CSAI (Computer Science
and Artificial Intelligence) réalise des solutions pour de nombreuses
entités d'ENGIE, notamment autour des problématiques de la vision par
ordinateur et du traitement automatique du langage naturel.

Pour mener à bien ces travaux, des bases de données annotées sont
nécessaires. C'est dans ce cadre là que s'inscrit ce stage sur
l'apprentissage actif. Afin d'optimiser le processus de labélisation de
données et éviter d'annoter d'énormes bases contenant des informations
redondantes, les méthodes d'apprentissage actif permettent de
sélectionner les meilleurs exemples à labéliser par l'utilisateur. Cela
permet ainsi d'annoter moins d'exemples mais de manière plus pertinente.

L'objectif du stage consiste donc à développer un algorithme
d'apprentissage actif permettant d'accélérer le processus d'acquisition
de données labélisées de qualité. Cet outil servira notamment pour les
projets de vision par ordinateur et de traitement automatique du langage
naturel [1][2][3][4].


Missions

- Conduire une étude bibliographique sur les méthodes d'apprentissage
  actif. Cette étude devra notamment comporter les méthodes standard de
  l'apprentissage actif ainsi que leur application dans les domaines du
  traitement naturel du langage et de la vision par ordinateur.
- Ré-implémenter certaines méthodes existantes et les évaluer.
- Analyser et comparer ces méthodes afin de synthétiser les avantages et
  défauts de chacunes d'entre elles.
- Proposer des pistes de travaux et d'amélioration par rapport à l'état
  de l'art.
- Implémenter les améliorations identifiées dans les environnements et
  architectures du lab CSAI.
- Valider les contributions par des expérimentations appropriées.
- Dans la mesure du possible, rédiger et soumettre une publication
  scientifique.
- Documenter le code.


Profil recherché

Niveau: M2, école d'ingénieur. Spécialisation: Machine Learning ou
Maths.


Compétences nécessaires:

- Connaissances en machine learning
- Connaissances en mathématiques (algèbre, optimisation, statistiques,
  ...)
- Expérience en programmation dans au moins un langage informatique
- Bon niveau d'anglais
- Motivé
- Autonome


Compétences appréciables:

- Connaissance en vision par ordinateur et en traitement naturel du
  langage
- Expérience en python et/ou en C++
- Connaissance en deep learning et des outils associés (tensorflow,
  keras, pytorch,caffe...)



Divers

Durée du stage: 6 mois - date de commencement flexible.

Convention de stage obligatoire.

Le dossier de candidature doit être envoyé le plut tôt possible à
Philippe Calvez (philippe.calvez1@engie.com), Ahmed Mabrouk
(ahmed.mabrouk@engie.com) et Chan-Lang Solène
(solene.chan-lang@external.engie.com). Il doit contenir les documents
suivants:
- un CV détaillé (ensemble des expériences et technologies maîtrisées)
- une lettre de motivation
- des lettres de recommandations (optionnel)


References

[1] Burr Settles. Active learning literature survey. Computer Sciences
    Technical Report 1648, University of Wisconsin- Madison, 2009.
[2] Cynthia A. Thompson, Mary Elaine Califf, and Raymond
    J. Mooney. Active learning for natural language parsing and
    information extraction. In Proceedings of the Sixteenth
    International Conference on Machine Learning (ICML- 99), pages
    406-414, Bled, Slovenia, June 1999.
[3] Kuoliang Wu, Deng Cai, and Xiaofei He. Multi-label active learning
    based on submodular functions. Neurocom- puting, 313:436-442, 2018.
[4] Ozan Sener and Silvio Savarese. Active learning for convolutional
    neural networks: A core-set approach. In International Conference on
    Learning Representations, 2018."
"563","2019-01-21","Softlaw","Paris","OFFRE DE STAGE M2 :  Analyse automatique des contrats

CONDITIONS DU STAGE :
Début : démarrage possible à tout moment à partir de février 2019
Durée : 4 à 6 mois
Gratification : standard de marché
Locaux : beaux locaux dans le centre de Paris (M° Chaussée d'Antin - Le
         Pelletier - Trinité d'Orves)

ENTREPRISE :
SOFTLAW est une entreprise pionnière de la legaltech et la première
société en France à avoir développé une solution d'analyse automatique
de contrats utilisant l'intelligence artificielle pour extraire
automatiquement les informations clés des contrats et faciliter leur
analyse.

SUJET DU STAGE :
Afin de permettre à nos utilisateurs d'adapter les algorithmes
d'extraction d'information présente dans les contrats, par exemple pour
permettre de reconnaître de nouvelles catégories non prévues
initialement, nous travaillons sur des solutions d'online machine
learning pouvant cohabiter avec des modèles pré-entraînés.

Dans le cadre du stage, vous mettrez en oeuvre des méthodes d'analyse de
contrats reposant sur l'online machine learning.

Le stage comportera plusieurs étapes :
- Réalisation d'un état de l'art,
- Sélection et implémentation des techniques les plus prometteuses,
- Évaluation des différents modèles proposés,
- Intégration des développements dans la plateforme NLP de la Société,
- Utilisation du/des modèle(s) dans le cadre de l'identification de
  concepts juridiques (topic modeling).

PRINCIPALES TECHNOLOGIES UTILISÉES :
- Langage : Python
- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.
- IDE : pycharm

CONNAISSANCES, COMPÉTENCES RECHERCHÉES
- Fort intérêt pour le traitement de données textuelles
- Autonomie, rigueur et communication
- Innovation/R&D et force de proposition
- Travail en équipe

LES PLUS DU STAGE :
- Stage extrêmement formateur permettant de se former sur les
  technologies à la pointe de l'état de l'art en NLP / Machine Learning
- Travail dans un cadre stimulant : l'entreprise a ses bureaux au sein
  d'un accélérateur de startups prometteuses et des locaux très
  agréables
- Entreprise et secteur dynamiques

Contact : s.morard@softlaw.digital (06 11 12 14 87)"
"564","2019-01-21","Softlaw","Paris","STAGE M2 :  Analyse automatique des textes juridiques

CONDITIONS DU STAGE :
Début : démarrage possible à tout moment à partir de février 2019
Durée : 4 à 6 mois
Gratification : standard de marché
Locaux : très beaux locaux dans le centre de Paris (M° Chaussée d'Antin
         - Le Pelletier - Trinité d'Orves)


ENTREPRISE :
SOFTLAW est une entreprise pionnière de la legaltech et la première
société en France à avoir développé une solution d'analyse automatique
de contrats utilisant l'intelligence artificielle pour extraire
automatiquement les informations clés des contrats et faciliter leur
analyse.

SUJET DU STAGE :
Dans le cadre du développement de notre solution d'analyse de contrats,
vous utiliserez notre approche hybride basée à la fois sur des méthodes
de machine learning et d'analyse sémantique pour prendre en compte de
nouveaux types de contrats.

Notamment, vous entrainerez des classifieurs dédiés pour catégoriser des
articles spécifiques et des algorithmes permettant l'identification et
l'extraction d'informations précises.

Le stage comportera plusieurs étapes :
- Réalisation d'un état de l'art sur les différentes techniques
  d'extraction d'information textuelle à partir des documents non
  structurés,
- Implémentation d'une approche hybride : machine learning et analyse
  sémantique,
- Évaluation des performances de la solution développée,
- Intégration des développements dans la plateforme NLP de la Société

PRINCIPALES TECHNOLOGIES UTILISÉES :
- Langage : Python
- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.
- IDE : pycharm

CONNAISSANCES, COMPÉTENCES RECHERCHÉES
- Fort intérêt pour le traitement de données textuelles
- Autonomie, rigueur et communication
- Innovation/R&D et force de proposition
- Travail en équipe

LES PLUS DU STAGE :
- Stage extrêmement formateur permettant de se former sur les
  technologies à la pointe de l'état de l'art en NLP / Machine Learning
- Travail dans un cadre stimulant : l'entreprise a ses bureaux au sein
  d'un accélérateur de startups prometteuses et des locaux très
  agréables
- Entreprise et secteur dynamiques


Contact : s.morard@softlaw.digital (06 11 12 14 87)"
"565","2019-01-23","ERTIM","Paris","*Reconnaissance et désambiguïsation des entités*
Stage proposé par le laboratoire ERTIM (INALCO)

*Contexte*

Les entités nommées sont des éléments linguistiques utilisés par de
nombreuses applications en TAL, telles quelles (indexation de documents,
recherche et extraction d'information, etc.) ou comme éléments exploités
pour de nombreuses autres tâches. Leur détection et leur catégorisation
sont aujourd'hui assez bien maîtrisées.

Ces dernières années, de nombreux travaux de recherche ont porté sur la
désambiguïsation (ou liaison, résolution) d'entités. Il s'agit alors de
déterminer à quel référent d'une base de connaissances une expression
linguistique fait mention (ou NIL si le référent n'existe pas). Cela
concerne une plus large gamme d'expressions linguistiques que les
""entités nommées"".

Dans le cadre du projet TALAD (https://web.u-cergy.fr/anr-talad/) nous
exploitons les entités pour l'étude des ""nominations"" (diversité
d'expressions linguistiques qui réfèrent à une même entité). La
détection, reconnaissance et désambiguïsation des entités est une brique
importante dans ce projet, en interaction avec la
coréférence. L'objectif du projet est de déterminer quelles entités sont
mentionnées dans un texte, par quelles expressions linguistiques, et
dans quels contextes.

Par ailleurs, le traitement des entités nécessite de s'appuyer sur un
corpus à large couverture, contenant de nombreuses mentions. À cet
effet, les travaux initialisés récemment par l'entreprise Emvista
exploitent les liens contenus dans les résumés d'articles Wikipedia afin
de constituer un corpus volumineux, en français, contenant des
annotations collectées automatiquement, qui peuvent être utilisées pour
la détection, la reconnaissance et la désambiguisation des entités.

*Sujet de stage*

En premier lieu, il s'agira d'exploiter le corpus fourni dans le cadre
du projet TALAD (transcription d'interviews matinales), en interaction
avec des collègues linguistes de l'équipe PraxiLing, afin d'y
caractériser les entités d'intérêt (entités nommées, entités
collectives, nominations et dénominations) et de déterminer les méthodes
adéquates pour les repérer automatiquement.

Pour ce qui concerne les ressources extraites depuis Wikipedia, on
cherchera à évaluer la qualité des ressources, à prototyper un système
de désambiguïsation des entités pour le français en utilisant les
méthodes état de l'art de machine learning et à l'évaluer
comparativement à d'autres systèmes existants, avec une attention
particulière portée au cas difficile des organisations.

*Objectifs principaux*

- Caractérisation des entités d'intérêt pour le projet TALAD
- Expérimentation de la détection automatiques d'entités pour la
  nomination
- Participation à l'extraction et l'évaluation du corpus de référence
  depuis Wikipedia
- Prototypage d'un système de désambiguïsation à base de machine
  learning
- Implémentation et évaluation comparative des systèmes de
  désambiguisation

*Profil recherché*

- M2 TAL, ou informatique avec for intérêt pour le TAL
- Programmation en python
- Méthodes de machine learning (CRF, LSTM, SVM, etc.)
- Intérêt pour la reconnaissance et la désambiguïsation des entités

*Précisions sur l'offre*

- Durée du stage : 5 ou 6 mois à temps plein
- Date de début : mars ou avril 2019
- Rémunération : tarif en vigueur (~550¤/mois, rbst de 50% navigo)
- Lieu : Inalco, 3bis rue Taylor, 75010 Paris

*Candidature*

Envoyez votre CV et faites part de vos motivations à Damien Nouvel
(damien.nouvel@inalco.fr)


*Références *

- Named Entities for Computational Linguistics. Damien Nouvel, Maud
  Ehrmann, Sophie Rosset. John Wiley & Sons, 2016.
- Dénomination référentielle, désignation, nomination. Pierre
  Frath. Langue française 4, 2015.
- Data Adaptation for Named Entity Recognition in Twitter with
  Features-Rich CRF. Ngoc Tan Le, Fatiha Sadat, Damien Nouvel. WiNLP
  2018.
- Learning Multilingual Named Entity Recognition from Wikipedia. Joel
  Nothman et. al. Artificial Intelligence 194 2013.
- Evaluating Entity Linking: An Analysis of Current Benchmark Datasets
  and a Roadmap for Doing a Better Job. Marieke Van Erp et. al. LREC
  2016."
"566","2019-02-04","LIFAT","Tours","==========
Stage de master de 6 mois au Lifat, université de Tours : annotation
automatique d'expériences en biologie systémique
========== 

****Description**** 

Dans le cadre du projet ANR Abliss (Automating Building from Literature
of Signalling Systems), le laboratoire de recherche en informatique
fondamentale et appliquée (Lifat) de l'université de Tours propose un
stage de master de 6 mois (avec prolongement possible par un CDD ou une
thèse), à compter de mars-avril 2019.
Le stagiaire travaillera sur le logiciel libre Unitex pour modéliser
(dans des textes en anglais) les protéines, gènes, molécules, etc. qui
apparaissent dans des descriptions d'expériences extraites des articles
scientifiques du domaine de la biologie systémique. Ceci pour
sélectionner les phrases contenant de telles descriptions et les annoter
sous une forme Prédicat-Arguments. Il aura aussi pour charge le
dépouillement et l'analyse des résultats obtenus.

****Compétences**** 

Idéalement, la personne candidate devra être dans un master en
bio-informatique (si possible avec une licence en informatique) ou un
master mention CCI (avec des études antérieures en biologie). Des
candidatures d'étudiants en master de traitement automatique des langues
(avec une formation informatique) sont aussi possibles, sous réserve de
connaissances en biologie. La connaissance d'Unitex peut être un plus,
mais n'est pas obligatoire.

****Localisation**** 

Le stage est situé au laboratoire de recherche en informatique
fondamentale et appliquée (Lifat) de l'université de Tours, 64 avenue
Jean-Portalis, 37200 Tours. La personne recrutée travaillera dans
l'équipe BdTln. Des déplacements chez les autres partenaires du projet
(INRA de Tours et LRI de l'université Paris-Sud) pourront être demandés.

****Gratification**** 

La gratification est celle prévue par la loi. 

****Date limite de candidature**** 

28 février 2019 

****Procédure de candidature**** 

Merci de joindre une lettre de motivation et un CV avec un contact
académique et, éventuellement, une lettre de recommandation.

Contacts : Denis Maurel (Lifat) et Anne Poupon (INRA) 
denis.maurel@univ-tours.fr, anne.poupon@inra.fr"
"567","2019-02-04","ITESOFT-Yooz","Aimargues","*Stage d'Ingénieur d'exploitation d'une plateforme d'intelligence 
artificielle d'analyse de document*

*Présentation de l'entreprise*

Yooz est l'activité SaaS du Groupe ITESOFT-Yooz, éditeur leader sur le
marché de la dématérialisation des processus documentaires. Yooz est une
SAS de 47 personnes, fondée au 1/1/15, le siège social est localisé à
Aimargues (30) et un établissement secondaire est à La Rochelle (17).
Yooz propose des solutions logicielles, sous forme de service Internet
(en mode SaaS), permettant à toutes les organisations quelle que soit
leur taille (entreprises, experts comptables, collectivités,
associations...), de bénéficier des avantages apportés par la
dématérialisation et le traitement automatique des documents ; et ce,
quels que soient les volumes à traiter.

Aujourd'hui Yooz offre des solutions de traitement de toute pièce
comptable (factures, achats...). Une valeur ajoutée essentielle du service
de dématérialisation de Yooz est la performance de l'intelligence
artificielle de Document Understanding des documents dématérialisés,
c'est-à-dire l'automatisation de la classification et de l'extraction
des informations portées par les documents. L'innovation technologique
dans ce domaine est dans le coeur de la stratégie de Yooz. Cette
innovation s'appuie sur nos développements propres et sur des
collaborations avec la recherche académique. La performance de notre
intelligence artificielle dans sa capacité à traiter l'ensemble des
documents d'entreprise est un défi technologique et un enjeu économique
important pour maintenir notre leadership sur le marché très
concurrentiel de la capture.

*Cadre du Stage : l'équipe d'exploitation d'une plateforme
d'intelligence artificielle d'analyse de document*

Maintenir la performance et au-delà, l'amélioration continue de la 
performance d'un service d'IA traitant 80 000 documents par jour 
provenant de plus de 2000 clients est un défi quotidien. Cette mission 
se décline en 3 champs d'ingénierie :

- *Développement logiciel *: il s'agit de réaliser la maintenance du
  service global de document understanding. Ce service orchestre et
  intègre les différents modules d'IA et de traitement de document qui
  permettent la classification et la fouille de document. Les
  développements sont réalisés suivant les spécifications du responsable
  du développement produit et en collaboration avec l'équipe de
  recherche fournissant les technologies. Juge et partie, cette tâche de
  développement logiciel s'accompagne de l'implantation du logiciel sur
  les postes de production. Elle inclut donc les actions de
  paramétrages, de recette et de déploiement de l'ensemble du logiciel
  sur les machines de production.

- *Exploitation *: il s'agit de superviser la production du service de
  document understanding, c'est-à-dire garantir que tout document
  présenté sur une machine de production est traité
  rapidement. Basiquement cette mission consiste à détecter les
  blocages, réaliser des reprises et analyser les causes pour proposer
  des solutions, soit en collaboration avec les équipes de R&D et
  d'exploitation des data centers, soit en corrigeant le service global
  le cas échéant, soit en proposant et en implémentant une
  automatisation de la détection et de la reprise du cas.

- *L'amélioration continue des performances*, il s'agit d'une part de
  concevoir et réaliser les apprentissages pour maintenir et améliorer
  les performances de différents sous-systèmes d'IA, et d`autre part de
  proposer et spécifier avec l'équipe de recherche des améliorations des
  modules technologiques. Pour ce faire, l'ingénieur doit analyser des
  résultats de traitement des documents et déterminer les axes de
  progrès en conséquence. Il est responsable du contenu de la base de
  connaissance sur laquelle repose le service d'IA. Tout comme le
  développement du service global, l'ingénieur est responsable du
  déploiement des apprentissages sur les machines de production. Le
  reporting de la supervision des performances est réalisée directement
  auprès du directeur R&D.

En conclusion, la position est stratégique, technique et analytique, au
centre de la R&D en relation avec les équipes de développement produit,
de recherche, d'exploitation des data center et du directeur R&D. A la
fois intégrateur technique, utilisateur de technologie et responsable de
l'exploitation en production, l'équipe d'exploitation a des missions
variées et nécessite une grande rigueur, perspicacité et capacité
d'analyse de systèmes complexes.

*Objectif du Stage *: il s'agit de participer à toute la variété des
missions de l'équipe d'exploitation. En particulier dans le cadre du
stage il s'agit concrètement :

- De participer au développement logiciel du service global de document
  understanding V2 actuellement en cours de développement. Les
  développements se feront avec le progiciel Freemind d'analyse de
  document et par des scripts d'intégration de technologie en jscript,
  éventuellement python ou java. Ce service est un système complexe
  combinant des modules d'IA, d'OCR et de manipulation de document (PDF,
  JPG...). En collaboration avec un ingénieur, le stagiaire montera en
  compétence sur les modules intégrés et participera à leur intégration
  dans un service global.

- D'assister l'ingénieur d'exploitation dans la supervision de
  l'exploitation, notamment en étudiant les procédures appliquées pour
  en identifier les tâches automatisables et implémenter des outils
  d'automatisation. Pour acquérir le savoir-faire, il participera
  occasionnellement aux tâches de suivi.

- De réaliser des améliorations d'apprentissage sur des cas précis
  sélectionnés par l'ingénieur d'exploitation. La stagiaire se formera à
  quelques techniques d'apprentissage, de réglages et de paramétrage des
  bases de connaissance. Il mettra en oeuvre, et suivant la
  méthodologie, procèdera la recette et la démonstration des
  améliorations.

Lors du stage, le ou la stagiaire sera sous la supervision de Vincent
Poulain d'Andecy (resp Recherche), travaillera en collaboration avec
Laurent Danièle (resp Développement), avec un ingénieur de
développement, un ingénieur d'exploitation et occasionnellement fera du
reporting d'exploitation au directeur R&D.

*Compétences techniques *: pas de forte contrainte (JAVA ou Python ou
JScript). Le stagiaire se formera aux outils de l'entreprise, en
particulier le progiciel Freemind.

*Division *: Recherche et Développement
*Lieu du Stage *: Aimargues
*Indemnité *: 900 ¤ mensuel + 176 ¤ de ticket restaurant (mensuel) + 
hébergement gracieux sur site (sous réserve disponibilité).
Perspective à l'issue du stage : le poste pourra être pérennisé en CDI
ingénieur d'exploitation"
"568","2019-02-04","Syllabs","Paris","------------------------------------------------------------------------
Offre de stage TAL M2 : Génération automatique de textes
------------------------------------------------------------------------

Syllabs est spécialisée en analyse sémantique et en génération
automatique de textes. Nos technologies sont le fruit d'années de
développement et maîtrisent toutes les étapes du processus d'analyse de
données textuelles du Web : identification des pages pertinentes,
extraction et catégorisation des informations clés. La génération est
proposée au travers de notre moteur de rédaction qui permet, à partir
d'une base de données structurées, de produire automatiquement des
textes de qualité humaine. Nos robots rédacteurs écrivent pour des
médias de référence français comme Le Monde ou Radio France.

C'est dans le contexte de la génération automatique de textes que nous
recherchons un·e ingénieur·e linguiste pour intégrer l'équipe actuelle
et participer au paramétrage du moteur de rédaction. Les domaines
d'application sont principalement les médias et l'immobilier.

-----------------------------
 Description du poste
------------------------------
Les tâches principales concernent:
- Prise en main de notre moteur de rédaction.
- Écriture des règles pour alimenter notre moteur de rédaction et
  produire des contenus pour nos clients.
- Préparation des bases de connaissances structurées utilisées par les
  règles.

-----------------------
 Profil recherché
------------------------

- Étudiant·e en Linguistique Informatique, Traitement automatique des
  langues ou Traduction
- Excellentes qualités rédactionnelles, goût pour l'écriture
- Aptitude pour la représentation formelle du langage
- Excellente capacité de communication et aptitude pour le travail en
  équipe
- Programmation en Python
- Compétences en rédaction web seraient un plus
- Langues maternelle : français, espagnol, anglais, allemand ou
  portugais.

-----------------
 Conditions
-----------------
- Stage conventionné 6 mois rémunéré en fonction du niveau d'étude
- tickets resto + remboursement à moitié du pass Navigo (transport)
- Bonne ambiance, coin canapé et équipe technique de grande
  qualité. Apéro mensuel

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com en
indiquant dans l'objet du mél « stage génération ».

Lieu : Quartier de Charonne (Paris 11), entre Bastille et Nation. Locaux
conviviaux partagés avec d'autres start-ups data-lovers. Possibilité
d'embauche après le stage à Paris ou à Nantes."
"569","2019-02-04","DGA-MI","Rennes","L'équipe TAL de DGA-MI recrute un stagiaire :

CONTEXTE :
Le domaine du traitement automatique des langues (TAL/NLP) a connu un
grand essor ces dernières années, notamment grâce aux approches de deep
learning et à la généralisation de l'open source. Cependant ces
traitements ne correspondent souvent qu'à des briques technologiques
indépendantes, qui ne suffisent pas pour mettre en place une chaîne de
traitement complète, allant du texte brut jusqu'à l'information
structurée.

SUJET :
L'objectif de ce stage est donc de tirer parti des technologies open
source pour développer des systèmes pour plusieurs tâches de TAL, puis
les intégrer dans une même chaîne de traitement, complétée par une IHM
permettant de visualiser directement le résultat des traitements.

Les technologies intégrées seront définies en coordination avec le
stagiaire, parmi les principales tâches TAL pour l'écrit :
prétraitements, identification de langue, traduction automatique, OCR,
détection d'entités nommées, fouille d'opinions, classification
thématique, résumé automatique, etc. En fonction des cas, ces systèmes
pourront provenir de diverses sources : soit des modèles pré-entraînés
distribués en ligne, soit des modèles déjà entraînés en interne, soit de
nouveaux modèles que le stagiaire entraînera à partir de code open
source et de données libres.

PROFIL DU CANDIDAT :

- Bac +4 ou bac +5

- Compétences requises : apprentissage automatique, programmation Python
  et bash, expressions régulières Perl ou équivalent, aisance avec
  l'environnement Linux et les outils en ligne de commande, maîtrise de
  l'anglais

- Compétences souhaitées : traitement automatique des langues,
  développement d'IHM, deep learning, maîtrise d'une langue étrangère
  autre que l'anglais

CONDITIONS DU STAGE
Durée : 4 à 6 mois (pas de contrainte sur la date de début de stage)
Gratification standard

Point de contact : dga-mi.stage.fct@intradef.gouv.fr"
"570","2019-02-04","STL","Lille","Stage : M2 TAL, Simplification automatique de textes médicaux, STL
(CNRS/Université de Lille)

La simplification automatique de textes est un domaine du TAL, dans
lequel il s'agit d'appliquer des transformations sur les phrases d'un
texte pour les rendre plus lisibles, tout en conservant leur sens
intact. Cela est pratiqué aussi bien à destination des humains que pour
faciliter les tâches nécessitant l'analyse automatique de textes [3].

La simplification, dont l'objectif est de faciliter des traitements
d'analyse automatique, peut faire partie de différentes applications.
Ainsi, la première application à l'avoir exploitée cherchait à
simplifier les structures de phrases avant de procéder à leur analyse
syntaxique automatique [3].  Dans d'autres contextes, la simplification
peut être utilisée pour adapter certains genres de textes à des outils,
qui n'ont pas été entraînés pour les traiter spécifiquement, comme par
exemple l'analyse d'un texte biomédical effectuée avec des outils
entraînés sur des textes journalistiques [6].

Dans le domaine médical, la simplification peut également servir à
faciliter l'éducation thérapeutique des patients [2] ou l'accès à
l'information par les enfants [5]. En effet, des études ont montré
qu'une meilleure compréhension des informations de santé par les
patients et leurs familles mène à une meilleure adhésion au traitement
et à un processus de soins plus réussi [4,1].

L'objectif du travail de stage consiste en la création, le test et
l'évaluation de ressources et/ou de méthodes en vue de la simplification
automatique de textes médicaux. La question de recherche précise pourra
être définie en accord avec le ou la stagiaire.

Le ou la stagiaire sera amené(e) à utiliser des outils existants et à
développer ses propres programmes pour effectuer les traitements
adaptés.

Compétences demandées :

- connaissances en TAL et informatique
- aptitude à installer et tester de nouveaux outils informatiques
- habitude de Linux
- lecture et analyse de la littérature scientifique, en français et en
  anglais
- autonomie

Le stage est rémunéré selon les règles en vigueur.

- Niveau: Master, ingénieur
- Durée: 6 mois
- Lieu: Lille

Pour présenter une candidature: envoyer un CV, la lettre de motivation,
le relevé de notes et les contacts de deux référents à Rémi Cardon
(remi.cardon@univ-lille.fr) et Natalia Grabar
(natalia.grabar@univ-lille.fr).

[1] ND Berkman, SL Sheridan, KE Donahue, DJ Halpern, and K Crotty.  Low
health literacy and health outcomes : An updated systematic review.
Annals of Internal Medicine, 155(2) : 97-107, 2011.

[2] Frédérique Brin-Henry. Éducation thérapeutique du patient et
orthophonie.  In Communiquer malgré l'aphasie. S. Médical, 2014.

[3] R. Chandrasekar, Christine Doran, and B. Srinivas. Motivations and
methods for text simplification. In Proceedings of the 16th Conference
on Computational Linguistics - Volume 2, COLING '96, pages 1041-1044,
Stroudsburg, PA, USA, 1996. Association for Computational Linguistics.

[4] T. Davis and M. Wolf. Health literacy : implications for family
medicine.  Fam Med, 36 :595-598, 2004.

[5] J. De Belder and M.-F. Moens. Text simplification for children. In
Workshop on accessible search systems of SIGIR, pages 1-8, 2010.

[6] Siddhartha Jonnalagadda, Luis Tari, Jörg Hakenberg, Chitta Baral,
and Graciela Gonzalez. Towards effective sentence simplification for
automatic processing of biomedical text. In Proceedings of Human
Language Technologies : The 2009 Annual Conference of the North American
Chapter of the Association for Computational Linguistics, Companion
Volume : Short Papers, pages 177-180. Association for Computational
Linguistics, 2009."
"571","2019-02-11","Lattice","Paris","STAGE : MISE AU POINT DE DISPOSITIFS INFORMATIQUES ET ARTISTIQUES POUR
LA DIFFUSION DE POESIE EN LIGNE

Stage de 3 à 4 mois, à Paris (début en mars ou avril 2019)
Niveau M2 ou équivalent
Convention de stage obligatoire


CONTEXTE
Le stage est organisé dans le cadre du projet OuPoCo (« L'Ouvroir de
Poésie Combinatoire »,
http://transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire). Ce
projet vise à développer d'une part, un « générateur automatique de
poésie » (c'est-à-dire un programme capable de générer automatiquement
des poésies) et, d'autre part, des dispositifs permettant de diffuser
ces poésies sur différents supports et sous différents formats (recueil
sous forme d'un ouvrage classique, réseaux sociaux, installation
artistique).

Le stage concerne les dispositifs de diffusion des poésie. Il mêlera
informatique, chaîne éditoriale et développements artistiques. Le stage
sera dirigé par Mathilde Roussel et Matthieu Raffard depuis leur atelier
(http://www.raffard-roussel.com), en lien avec Thierry Poibeau
(http://lattice.cnrs.fr/Thierry-Poibeau qui dirige le projet OuPoCo.

LIEU ET HORAIRE DU STAGE
Le stage aura lieu du lundi au vendredi de 10h00 à 18h00 dans l'atelier
des artistes Mathilde Roussel et Matthieu Raffard au 189 rue Ordener
(accessible depuis le métro Lamarck-Caulaincourt ligne 12 ou bien Guy
Moquet ligne 13).

OBJECTIF DU STAGE
Le stage aura pour but de développer un certain nombre de projets
satellites autour du générateur de poésie élaboré par le Lattice. Il
pourra s'agir, par exemple, de développer un programme qui puisse
produire, via un site d'édition en ligne, des recueils de poésie créés
sur demande à partir du générateur de poésie. Il pourra aussi s'agir de
développer une petite application qui puisse permettre de publier sur
les réseaux sociaux via un flux RSS des fragments de poésies illustrés
par des images générées automatiquement. Il faudra enfin gérer les
évolutions du site Web du projet, en fonction de l'avancement de
celui-ci et en partenariat avec le prestataire qui réalisera la version
d'amorçage du site Web du projet.

D'autres applications et projet périphériques seront également à
développer au cours du stage, ils seront réalisés en étroite
collaboration avec Mathilde Roussel et Matthieu Raffard qui à travers
leur travail d'artiste cherchent à inventer de nouvelles attitudes face
aux machines.

Pour finir, le stagiaire sera invité à participer à la création d'une
oeuvre d'art en relation avec le projet OUPOCO. L'oeuvre de cette création
reste à définir, elle pourra prendre la forme d'un système d'impression,
d'une performance, ou bien d'une installation interactive.


PROFILS RECHERCHÉS :

- étudiant(e) de niveau M2 (Master universitaire, Ecole d'art, etc.)
  avec une formation pertinente (design numérique, édition numérique,
  éventuellement informatique ou littérature avec les compétences
  informatiques adéquates).
- compétences en programmation (scripts en perl ou python)
- compétences en programmation Web et en mise en ligne d'applications
- compétences ou intérêt en programmation et génération d'images (
  processing ou python )
- intérêt pour la littérature et la poésie 
- sensibilité et intérêt pour les arts plastiques
- sens de la créativité et de l'innovation

Le stage durera 3 à 4 mois, à partir du 1er mars 2019 si possible. Il
est indemnisé suivant les règles en vigueur. Il implique la signature
d'une convention de stage fournie par l'université ou l'école de
l'étudiant.


COMMENT CANDIDATER ?

Envoyer par mail (à Matthieu Raffard et Mathilde Roussel :
raffard.roussel@gmail.com avec copie à Thierry Poibeau,
thierry.poibeau@ens.fr) les documents suivants :

- une courte lettre de motivation (éventuellement directement dans le
  corps du mail)
- un CV
- un relevé de notes récent (de niveau M1 ou M2)

Les candidatures seront étudiées au fil de l'eau, la date limite pour
candidater est fin février (mais il est conseillé de candidater dès que
possible sans attendre la date butoir. Le stage peut être pourvu avant
la date de fin de candidature)."
"572","2019-02-11","GEOLSemantics","Gentilly","Stage en TAL, Analyse syntaxique de l'arabe

Contexte : 

Créé en 2009, GEOLSemantics est un éditeur de logiciels innovants dans
le monde des technologies de l'information et de la communication et
particulièrement dans les domaines de la linguistique et de la
sémantique. Les solutions de GEOLSemantics analysent les contenus des
textes pour identifier, normaliser et structurer les données pertinentes
contenues dans les textes pour les rendre directement utilisables par
des processus automatiques apportant les réponses appropriées aux
objectifs métiers.

Objectifs de lamission

Dans le cadre d'un projet de recherche l'entreprise GEOLSemantics
propose un stage dans le traitement automatique de la langue arabe. La
mission principale sera de mettreau point l'analyse morphosyntaxique
profonde de l'arabe en enrichissant les ressources existantes et en
participant à l'élaboration des règles de désambiguïsation et des règles
syntaxiques pour son intégration dans l'outil d'extraction d'information
existant.

Tâches principalesà réaliser

   - Prise en main du système de GEOLSemantics   
   - Amélioration de la désambiguïsation   
   - Élaboration de règles pour l'analyse syntaxique   
   - Reconnaissance des entités nommées   
   - Réalisation des tests et de la documentation technique   

Profil recherché
   
   - Étudiant(e) en Linguistique Informatique, Traitement automatique
     des langues ou Traduction
   - Langue maternelle : arabe   
   - Bonne capacité de communication et aptitude pour le travail en
     équipe
   - Connaissance d'un langage de script (Python, Perl, etc)   
   - Connaissances en Linux et SVN appréciées   

Conditions
   
   - Stage conventionné de 5 à 6 mois rémunéré   
   - Remboursement à moitié du pass Navigo (transport)   

Merci d'envoyer votre candidature à l'adresse
christian.fluhr@geolsemantics.comet en indiquant dans l'objet du mail «
stage en traitement de l'arabe ».

Lieu : Gentilly."
"573","2019-02-15","Orthodidacte","Grenoble","Intitulé du stage : Amélioration d'un moteur d'analyse syntaxique du
français écrit destiné à détecter des erreurs orthographiques.

Contact par courriel : Baptiste Ranty
(baptiste.ranty@orthodidacte.com<mailto:baptiste.ranty@orthodidacte.com>)

Durée du stage : 4 à 6 mois

Région : Auvergne-Rhône-Alpes

Ville : Grenoble

Niveau d'étude : Master 2

Nous sommes :

Une entreprise grenobloise innovante. Orthodidacte est le spécialiste du
diagnostic, de la formation et de la certification en langue française,
au travers de plateformes numériques.
Avec la plateforme d'e-learning, professionnels, étudiants et
particuliers suivent un parcours personnalisé selon leurs besoins. Des
services d'accompagnement pédagogique en présentiel sont également
proposés.
Avec la plateforme de dictée numérique, élèves et adultes peuvent
s'entraîner sur Internet à la dictée et bénéficier d'une correction
automatique et instantanée.
Enfin, grâce à la Certification Le Robert, cocréée par Orthodidacte et
les Éditions Le Robert, chacun peut faire valoir son niveau en français
sur son CV.


Votre mission :

Dans la plateforme e-learning Orthodidacte.com, un outil de détection et
de catégorisation d'erreurs de langue est en cours de développement.

Il fonctionne à partir de règles de détection qui s'appuient notamment
sur de l'analyse morphosyntaxique.

Dans l'optique de rendre cet outil plus performant, vous aurez la charge
de mettre au point et d'implémenter de nouvelles règles d'analyse
syntaxique.

Il s'agira donc de réaliser l'analyse syntaxique automatique de textes
pour faire fonctionner des règles de détection prédéterminées.

Vous travaillerez en collaboration avec l'équipe linguistique.

Votre profil :

- Master 2 en linguistique informatique ou TAL
- Goût prononcé pour la langue française et la linguistique
- Bases en programmation Python
- Notions de TAL
- Autonomie, rigueur et communication

Compétences appréciées :

- Connaissance de la librairie python spaCy
- Traitement automatique de corpus"
"574","2019-02-25","Exane","Paris","Stage Natural Language Processing / NLG / IA - H/F
Référence :                  SOGLAC.STA.NLP-NLG-IA
Type de contrat :            Stage / 6 mois
Lieu :                       Paris


NOTRE SOCIÉTÉ

Depuis plus de 25 ans, le Groupe Exane se développe à travers 3
fondamentaux : les actions européennes, l'investissement et la recherche
actions et dérivés. Reconnu dans les principaux sondages professionnels,
le Groupe figure aujourd'hui parmi les principaux acteurs indépendants
de la Finance de Marché en Europe et intervient sur trois métiers :

- l'Intermédiation Actions (Cash Equities) : Exane BNP Paribas propose à
  une clientèle institutionnelle des services incluant la recherche, la
  vente et l'exécution sur les valeurs européennes. Depuis 2004,
  l'Intermédiation Actions est au coeur du partenariat qui lie Exane à
  BNP Paribas ;

- les Dérivés : acteur historique sur les produits de flux, Exane
  Derivatives a développé une offre complète de services allant de la
  recherche à l'exécution ;

- l'Asset Management : la gestion d'actifs du Groupe est incarnée par
  deux sociétés de gestion, Exane Asset Management et Ellipsis AM,
  spécialisées respectivement sur l'univers des actions et des
  obligations.

Avec plus de 900 collaborateurs, le Groupe Exane s'est développé à
l'échelle internationale et est aujourd'hui présent sur 10 sites dans le
monde, Paris et Londres étant ses principales implantations.

VOS MISSIONS

L'explosion récente des techniques de Machine Learning, de la robotique
et du Big Data, les projets de génération automatique de texte et le
traitement automatique du langage naturel (« Natural Language Generation
», « Natural Language Processing») sont en plein essor.

A ce titre, au sein du département Recherche et Développement, vous
intégrez l'équipe Cash Equity Advisory d'Exane BNP Paribas.

Vous participerez à la construction de nouveaux produits qui mettront en
valeur ces nouvelles technologies et interactions conversationnelles.

Vos missions s'articuleront de la façon suivante :

- Mise au point de méthodes avancées de génération et de traitement du
  langage appliqués à des outils de production de texte, d'interfaces
  conversationnelles et la détection automatique d'intentions de
  l'utilisateur,

- Interprétation des données financières (bilan, comptes de résultats,
  cash-flow),

- Participation au projet d'intégration des prévisions des analystes
  financiers, en collaboration avec nos analystes financiers et nos
  forces de vente afin de digitaliser l'interprétation des « grilles
  financières"" en traduisant, sous la forme de commentaires
  synthétiques, les éléments clefs observés par les investisseurs,

- Participation à des projets de type « bot » de support utilisateurs,
  clients et plus généralement d'aide utilisateur.
  
Ces spécifications sont non-exhaustives et pourront évoluer tout au long
du stage, au fur et à mesure des réflexions, des recherches, des tests
et résultats intermédiaires obtenus.

Ce stage vous permettra d'aboutir à la réalisation de démonstrateurs
techniques et à l'évolution des règles de génération de texte
existantes.  Vous maîtriserez ainsi les techniques avancées de
génération automatique de texte et comprendrez les techniques de
traitement et de génération du langage.

Enfin, vous aurez réalisez les différentes étapes d'un travail de
recherche et développement dans le domaine du conseil en investissement
financier.

PROFIL

- Bac + 4/5 en Master type linguistique informatique ou équivalent,
  spécialités Traitement Automatique de la Langue, Traduction
  Automatique, Traitement Automatique du Langage Naturel, Linguistique
  Informatique,

- Bilingue anglais ; une 3ème langue européenne, comme l'allemand,
  serait appréciée,

- Très bonne capacité de rédaction et aisance en communication orale et
  écrite,

- Excellente orthographe et grammaire,

- Aptitude à apprendre rapidement de nouveaux concepts techniques et à
  prendre en main des outils internes ou externes.

- Environnement technique : Windows/Linux, Opensource, Java / C++ /
  Python...

POSTULER

Ce stage d'une durée de 6 mois est à pourvoir dès Juin 2019. Ouvert à
l'alternance pour 12 mois.

Pour postuler, veuillez adresser votre candidature sur :

https://exane-recrute.talent-soft.com/Pages/Offre/detailoffre.aspx?idOffre=2775&idOrigine=380&LCID=1036"
"575","2019-02-25","Labex OBVIL","Paris","Ceci est une offre de stage en Humanités Numériques chez le Labex OBVIL 
- Sorbonne Université

Contexte et principales missions :

Vous intégrez une équipe de recherche, de développement et d'édition, le
labex OBVIL (Observatoire de la Vie Littéraire), où vous participez à la
réalisation de solutions autour des technologies des Humanités
Numériques.

Le stage se déroulera dans le cadre du projet HyperPaulhan, mené dans le
cadre du Labex OBVIL en partenariat avec l'IMEC, et a pour objectif la
mise en ligne des correspondances inédites de Jean Paulhan déposées dans
les fonds d'archives de l'IMEC
(http://obvil.sorbonne-universite.site/projets/hyperpaulhan) Le(La)
stagiaire recruté(e) participera à la numérisation des lettres dans le
cadre de séjour à l'IMEC (Caen) pris en charge par le LABEX. Il/Elle
s'occupera aussi de la transcription d'une partie des lettres (images et
lettres sont présentées côte à côte sur le site). Il/Elle sera
associé(e) aux réunions d'équipe, ainsi qu'à la préparation d'une
journée d'études en 2019, qui interrogera les moyens d'exploiter un
corpus électronique de correspondances. Elle pourra bénéficier d'une
formation au langage XML-TEI et Oxygen, et aura également un accès
privilégié aux archives de l'IMEC, qui pourront nourrir le travail de
réflexion d'un mémoire.

La rémunération perçue est conforme à ce qui est prévu par l'université.

Durée: 3 à 6 mois
Début du contrat: dès que possible.

Si vous êtes intéressé(e), vous pouvez envoyer votre cv et une lettre de
motivation à Camille Koskas : Camkoskas@gmail.com"
"576","2019-03-11","Yseop","Paris","Sujet : Stage - enrichissement et maintenance des bases lexicales
 
= La société

Yseop est l'éditeur international d'un logiciel d'Intelligence
Artificielle spécialisé dans la génération automatique de texte en
langage naturel (Natural Language Génération ou NLG).
Nous offrons une solution qui raisonne, dialogue et rédige comme un être
humain, en plusieurs langues, et qui se concentre sur deux coeurs
d'expertise : la génération automatique de rapports et la relation
clients.
Aujourd'hui, nous comptons plus de 50 000 utilisateurs quotidiens de la
technologie Yseop, principalement des entreprises du CAC 40 et du
Fortune 500.

= La mission

Les applications (chatbots, etc.) réalisées pour nos clients intègrent
un lexique applicatif qui mêle fréquemment des données très métier et
des améliorations qui peuvent bénéficier à l'ensemble de nos
réalisations futures.

L'objectif est de concevoir et de développer les outils permettant
d'analyser et de ré-intégrer ces données issues des projets dans notre
dictionnaire commun.  Ces outils devront également permettre d'enrichir
le dictionnaire à partir de données lexicographiques ou terminologiques
ouvertes.

Cette mission se déroulera au sein de l'entité Yseop NLU, en étroite
collaboration avec les équipes travaillant sur l'apprentissage et
l'analyse automatique des langues.

= Le profil recherché

Vous avez un niveau M2 en TAL, avec de bonnes connaissances en
programmation, en particulier en Python ainsi qu'en SQL (MySQL de
préférence) Des connaissances sur les outils de TAL standard (Spacy,
NLTK) et la manipulation de données ouvertes seront appréciées.

Le stage se déroule dans les locaux de la société, à Paris (75001), pour
une durée de 6 mois à partir de début Avril 2019.

= Pour postuler

Rendez-vous sur la page
https://www.welcometothejungle.co/companies/yseop/jobs/stage-nlu-enrichissement-et-maintenance-des-bases-lexicales_paris"
"577","2019-03-11","Airbus","Toulouse","Airbus is a global leader in aeronautics, space and related services. In
2017, it generated revenues of ¤ 67 billion and employed a workforce of
around 130,000. Airbus offers the most comprehensive range of passenger
airliners from 100 to more than 600 seats. Airbus is also a European
leader providing tanker, combat, transport and mission aircraft, as well
as Europe's number one space enterprise and the world's second largest
space business. In helicopters, Airbus provides the most efficient civil
and military rotorcraft solutions worldwide.

Our people work with passion and determination to make the world a more
connected, safer and smarter place. Taking pride in our work, we draw on
each other's expertise and experience to achieve excellence. Our
diversity and teamwork culture propel us to accomplish the extraordinary
- on the ground, in the sky and in space.

Description of the job

Start date: 1st May 2019 (date subject to some flexibility)

Duration: 4-8 Months

Location: Toulouse (France)

The internship will take place within the AIRBUS central research
division among the Artificial Intelligence and Data Science team.

In order to meet the extraordinary challenges of AIRBUS group future,
our group is in charge of augmenting our systems with Artificial
Intelligence technologies. The team's goal is to actively research the
latest approaches that can enhance AIRBUS products and services as well
as developing beyond state-of-the-art components to address the specific
challenges of our industrial domain.

This internship will be embedded in our learning assistant initiative
that is trying to enhance traditional system interaction by adding
conversational agent.

Depending on the profile and research objectives, the intern could
contribute to NLP (Natural Language Processing) research topics:
conversational technologies (NLU, speech recognition), knowledge
extraction, information retrieval, question answering...

Tasks & accountabilities

Your main tasks will include:

  * Grasp the research objectives and the long term targets of the
    project

  * Analyse the state-of-the-art (SotA) in the relevant literature as
    well as published open source projects

  * Re-implement existing approaches on AIRBUS dataset

  *Perform analysis of relevant metrics to identify limitations

  * Develop an innovative approach to overcome current limitations

You will work in a transnational team composed of senior scientists and
research engineers. You may also work in close cooperation with trainees
dealing with connected topics.

This job requires an awareness of any potential compliance risks and a
commitment to act with integrity, as the foundation for the Company's
success, reputation and sustainable growth.

Required skills

You must be an undergraduate for the full duration of the placement,
studying towards a degree in one of the following: Computer Science,
NLP, Speech Recognition, Machine Learning, Deep Learning. You ideally
have initial experience or past projects in this field.

You have existing practice of Python or JAVA. Additional programming
languages or scripting such as shell would be a plus. Familiarity with
docker, GPUs and the cloud would also be a plus.

You are a good team player and have excellent interpersonal skills. You
are recognized for your curiosity, creativity and ability to learn
quickly and to suggest potential solutions.

English: negotiation level. French, German or Spanish would be a plus.

Contact point:

catherine.kobus@airbus.com and gerard.dupont@airbus.com"
"578","2019-03-20","LIDILEM","Grenoble","/*Stage ""Structuration d'une base de ressources sonores et analyse de 
traces""*/

*PrÃ©sentation gÃ©nÃ©rale du projet*

1. Contexte et environnement de travail

L'UniversitÃ© Grenoble Alpes accueille plus de 45 000 Ã©tudiants avec le
concours de 3000 enseignants-chercheurs, chercheurs et enseignants, et
de 2500 personnels de support et d'accompagnement.

Le projet e-FRAN Fluence (2017-2020) est portÃ© par Sylviane Valdois
(LPNC-CNRS) et par le CNRS.

  * Fluence : http://fluence.cnrs.fr/

  * Luciole : http://wiki.lezinter.net/index.php/LUCIOLE:Accueil

L'UniversitÃ© Grenoble Alpes est reprÃ©sentÃ©e par le Service des Langues,
qui gÃ¨re les budgets pour 2 tÃ¢ches :

  * CrÃ©ation du jeu Luciole (LIDILEM) ;
  * Interface de suivi (Service des Langues).

    Dans le cadre du projet e-FRAN FLUENCE, le LIDILEM recrute un
    stagiaire pour participer au projet Â« LUCIOLE Â» pour une durÃ©e de 6
    mois (800h).

    La prise de fonctions se fera entre le 18/03 et le 01/04.

2. Objectifs...

    1. ...du projet Fluence

Le projet Fluence cible avant tout la fluence de lecture, qui est un
fort prÃ©dicteur de la rÃ©ussite scolaire. L'hypothÃ¨se centrale est que
les jeux vidÃ©os d'action (Green, Li, et Bavelier 2010) permettent
d'entraÃ®ner des mÃ©canismes cognitifs favorisant l'amÃ©lioration de la
Fluence de lecture (Meyer, Diard, et Valdois 2017).

3 applications (dont 2 ciblant la fluence de lecture) ont Ã©tÃ© conÃ§ues
pour le projet Fluence :

 1. EVAsion (LPNC) : jeu d'action ciblant les mÃ©canismes
    visuo-attentionnels ;
 2. ELARGIR (Gipsa) : application visant Ã  assister les tÃ¢ches de
    lecture rÃ©pÃ©tÃ©e visant l'amÃ©lioration de la vitesse et de la
    prosodie ;
 3. Luciole (LIDILEM) : application ciblant la comprÃ©hension de l'oral
    en anglais.

Pour valider les deux applications portant sur la lecture (applications
1 et 2), une Ã©tude longitudinale est au coeur du projet, impliquant
Luciole pour le groupe Â« contrÃ´le Â».

    2. ...du projet Luciole

Dans ce contexte, le projet Luciole a Ã©tÃ© intÃ©grÃ© au projet Fluence pour
fournir un groupe contrÃ´le aux autres applications. Inversement, la
conception du protocole expÃ©rimental fait que les autres applications
sont le groupe contrÃ´le de l'application Luciole.

Afin qu'il n'y ait pas d'interfÃ©rence entre les applications, nous ne
mettons pas les Ã©lÃ¨ves en contact avec la langue anglaise Ã©crite et
n'avons pas non plus de modalitÃ©s de jeu d'action.

""Poster des suspects"" affichÃ© dans les salles de classe et utilisÃ© par
les enfants pour identifier les ""mÃ©chants"" (en les scannant avec la
tablette)

Les objectifs du jeu sont de faire travailler la comprÃ©hension de l'oral
(en anglais) aux Ã©lÃ¨ves franÃ§ais qui semblent avoir certaines
difficultÃ©s avec cette activitÃ© langagiÃ¨re (Commission EuropÃ©enne
2012). Pour cela, nous nous appuyons sur les thÃ©ories de l'acquisition
fondÃ©es sur l'usage (Bybee 2008; Krashen 1982).

En nous appuyant sur les Instructions Officielles (MEN 2015), nous avons
conÃ§u des modalitÃ©s de jeu autour d'Ã©lÃ©ments langagiers ciblÃ©s dans les
programmes (lexique, phonologie, culture, etc.). Plusieurs types
d'activitÃ© sont proposÃ©s Ã  l'Ã©lÃ¨ve, celles-ci vont permettre de
prÃ©senter des Ã©lÃ©ments langagiers, d'entraÃ®ner l'Ã©lÃ¨ve Ã  les reconnaÃ®tre
et enfin de lui proposer de les reconnaÃ®tre en contexte.  Toutes les
activitÃ©s sont justifiÃ©es par une narration qui donne au joueur le rÃ´le
d'un agent secret. Cette narration vise Ã  faire de la langue un moyen
d'atteindre un autre objectif (Cornillie, Thorne, et Desmet 2012), Ã 
savoir libÃ©rer des animaux, Ã  l'Ã©gard desquels les enfants ont de
l'empathie (Cassels et al. 2017).

Dans le cadre de ce protocole, les groupes sont testÃ©s concernant la
lecture et l'anglais en dÃ©but de la 1re annÃ©e puis Ã  la fin de chaque
annÃ©e, ce qui permet d'Ã©valuer l'efficacitÃ© de chaque dispositif. Dans
le cadre de Luciole, nous allons pouvoir confronter la rÃ©ussite des
Ã©lÃ¨ves dans le jeu Ã  leurs progrÃ¨s, afin d'Ã©valuer le transfert de
compÃ©tences du jeu vers la vie ""rÃ©elle"", enjeu au coeur du domaine du jeu
sÃ©rieux (Girard, Ã‰calle, et Magnan 2013).

    Le projet commence sa 3^e annÃ©e au cours de laquelle nous allons
    commencer Ã  prÃ©parer les contenus pour les sessions de jeu de
    l'annÃ©e 2020.

    Le travail est effectuÃ© au LIDILEM en collaboration avec le LIDILEM.

3. Bibliographie

Bybee, Joan. 2008. Â« Usage-Based Grammar and Second Language Acquisition
Â». In /Handbook of Cognitive Linguistics and Second Language
Acquisition/, Ã©ditÃ© par Peter Robinson et Nick C. Ellis,
216-26. Routledge. http://www.unm.edu/jbybee/downloads/Bybee2008UBGandSLA.pdf.

Cassels, Matthew T., Naomi White, Nancy Gee, et Claire Hughes. 2017.  Â«
One of the family? Measuring early adolescents' relationships with pets
and siblings Â». /Journal of Applied Developmental Psychology/ 49 (2017):
12-20. http://dx.doi.org/10.1016/j.appdev.2017.01.003.

Champin, Pierre-Antoine, Alain Mille, et Yannick PriÃ©. 2013. Â« Vers des
traces numÃ©riques comme objets informatiques de premier niveau : une
approche par les traces modÃ©lisÃ©es Â». /Intellectica/, n^o 59 (juin):
171-204.

Commission EuropÃ©enne. 2012. Â« First European Survey on Language
Competences: Final Report Â». Luxembourg: Publications Office of the
European Union.
http://ec.europa.eu/dgs/education_culture/repository/languages/policy/strategic-framework/documents/language-survey-final-report_en.pdf.

Cornillie, Frederik, Steven L. Thorne, et Piet Desmet. 2012. Â« Digital
games for language learning: from hype to insight? Â» /ReCALL/ 24 (3):
243-256. https://doi.org/10.1017/S0958344012000134.

Girard, Coralie, Jean Ã‰calle, et Annie Magnan. 2013. Â« Serious games as
new educational tools: how effective are they? A meta-analysis of recent
studies Â». /Journal of Computer Assisted Learning/ 29 (3):
207-219. https://doi.org/10.1111/j.1365-2729.2012.00489.x.

Green, C. Shawn, Renjie Li, et Daphne Bavelier. 2010. Â« Perceptual
Learning During Action Video Game Playing Â». /Topics in Cognitive
Science/ 2 (2):
202-216. https://doi.org/10.1111/j.1756-8765.2009.01054.x.

Krashen, Stephen D. 1982. /Principles and Practice in Second Language
Acquisition/. Language Teaching Methodology Series. Oxford: Pergamon
Press.

MEN. 2015. Â« Programmes d'enseignement de l'Ã©cole Ã©lÃ©mentaire et du
collÃ¨ge Â». Bulletin officiel spÃ©cial 386. Paris: MinistÃ¨re de
l'Ã‰ducation Nationale.
http://www.education.gouv.fr/cid95812/au-bo-special-du-26-novembre-2015-programmes-d-enseignement-de-l-ecole-elementaire-et-du-college.html.

Meyer, Sventlana, Julien Diard, et Sylviane Valdois. 2017. Â« How do
action video games improve reading performance? Theoretical framework
and design principles of an educational software, based on
visuo-attentional training Â». In . Ajaccio.
https://sile2017france.sciencesconf.org/121465.

*Sujet

Structuration d'une base de ressources sonores et analyse de traces*

Alors qu'Ã  l'heure actuelle, un peu plus de la moitiÃ© du jeu LUCIOLE a
Ã©tÃ© rÃ©alisÃ©e (2 annÃ©es de jeu sur 3 annÃ©es prÃ©vues), il a dÃ©jÃ  nÃ©cessitÃ©
la crÃ©ation d'une base de plus de 2000 sons enregistrÃ©s par des
locuteurs natifs. Chacun des sons est dÃ©crit dans une base de donnÃ©es
indiquant les locuteurs concernÃ©s (genre, variÃ©tÃ© d'anglais, etc.), la
transcription des sons et la liste des activitÃ©s auxquelles ils sont
intÃ©grÃ©s.


  Des sons pour l'enseignement

En outre, le jeu ne vise pas Ã  se substituer Ã  l'enseignement de la
langue anglaise Ã  l'Ã©cole primaire, mais Ã  le complÃ©ter ou Ã 
l'enrichir. S'il peut faciliter pour les enseignants une diffÃ©renciation
de l'apprentissage en permettant de faire travailler certains Ã©lÃ¨ves en
autonomie pour de courtes sessions, l'intÃ©gration du jeu Ã  la classe n'a
pas vocation Ã  Ãªtre dÃ©finie par les chercheurs dans le cadre du projet
FLUENCE. Toutefois, bien conscients de certaines des difficultÃ©s des
professeurs des Ã©coles par rapport Ã  la langue anglaise, il nous semble
pertinent de mettre Ã  disposition de la communautÃ© enseignante
(formateurs ou professeurs des Ã©coles) les enregistrements audio
rÃ©alisÃ©s par des locuteurs natifs.

De ce fait, nous aimerions, en marge du projet FLUENCE, structurer les
diffÃ©rentes donnÃ©es de maniÃ¨re Ã  pouvoir servir de matÃ©riel pÃ©dagogique
et permettre Ã  des enseignants et / ou des ingÃ©nieurs pÃ©dagogiques de
les intÃ©grer au sein de leurs pratique. Pour permettre Ã  ces derniers de
s'emparer de la base de sons, nous voulons mettre Ã  disposition une API
qui permettrait aux utilisateurs de sÃ©lectionner les sons en fonction
des diffÃ©rents traits rÃ©pertoriÃ©s, voire de l'analyse des transcriptions
des sons (ex : tous les sons croisant de l'anglais et du franÃ§ais dans
lesquels le mot Â« /spy /Â» est mentionnÃ©).


  Des informations pour la recherche

Les requÃªtes permises par le systÃ¨me d'information mis en place devront
pouvoir Ãªtre attaquÃ©s par le logiciel de statistiques R [1] afin de nous
permettre une analyse fine des traces d'interaction Ã  notre disposition.

En effet, Ã  chaque fois qu'un joueur (faisant partie du protocole
expÃ©rimental) entend un son, un observÃ©(Champin, Mille, et PriÃ© 2013)est
collectÃ©. En croisant les donnÃ©es de nos traces, avec celles des
prÃ©/post-tests et de la base de son Ã  crÃ©er, il nous sera possible de
savoir si certains Ã©noncÃ©s rendent l'acquisition plus efficaces que
d'autres, en fonction de la situation d'Ã©coute et du rÃ´le du son dans
l'interaction du joueur avec le systÃ¨me.


  Missions

  * proposer une structuration des diffÃ©rentes donnÃ©es ;
  * fournir un systÃ¨me d'interrogation (API) ;
  * interroger cette API avec R ;
  * Si possible : interroger cette API pour le Web ;
  * proposer des scripts pour la transformation de certaines traces.


  ActivitÃ©s

 1. Familiarisation avec le jeu existant, sa structuration, son
    fonctionnement ;
 2. Prise en main des outils mis Ã  disposition (gitlab, mediawiki) ;
 3. Choix d'une solution technique (technologie) ;
 4. ModÃ©lisation :
    1. des sons ;
    2. de la base de sons ;
    3. de l'API ;
    4. des traces et de leurs transformations ;
 5. ImplÃ©mentation ;
 6. Test de l'API Ã  travers la transformation de traces.

  Profil recherchÃ©

Ã‰lÃ¨ve ingÃ©nieur en derniÃ¨re annÃ©e ou Ã©tudiant Master 2 avec
spÃ©cialisation EIAH, SystÃ¨mes d'Information, Sciences cognitives,
HumanitÃ©s numÃ©riques, Traitement Automatique des Langues ou Psychologie.


  CompÃ©tences recherchÃ©es

  * Programmation Web (php, javascript, MariaDB, API REST) ;
  * Programmation R ;
  * IngÃ©nierie des traces ;
  * Connaissances en statistiques infÃ©rentielles apprÃ©ciÃ©es ;
  * Aptitude au travail en Ã©quipe ;
  * Gestion de projet ;
  * CapacitÃ© Ã  dÃ©fendre et justifier un point de vue ;
  * Dynamisme, force de proposition, capacitÃ© d'adaptation ;
  * Bon niveau d'anglais apprÃ©ciÃ©.

[1] https://cran.r-project.org/
https://cran.r-project.org/web/packages/RMariaDB/index.html
https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html 

https://cran.r-project.org/web/packages/jsonlite/index.html"
"579","2019-03-27","GEOLSemantics","Gentilly","Contexte :

Créée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans
le domaine des technologies de l'information et de la communication, et
plus particulièrement dans le domaine de l'extraction
d'informations. Les solutions de GEOLSemantics analysent les contenus
textuels pour identifier, normaliser et structurer les données
pertinentes qu'ils contiennent, afin de les rendre directement
exploitables par des processus automatiques.

Mission :

Dans le cadre de la mise en place d'une nouvelle fonctionnalité dans sa
solution globale, GEOLSemantics propose un stage en informatique pour
l'industrialisation de son outil de détection d'une grande liste de mots
dans un flux très volumineux de textes. L'algorithme à implémenter est
un automate d'etat fini réalisé sous forme d'un dictionnaire arborescent
au niveau du caractère garantissant des temps de traitement compatibles
avec les volumes à traiter.

La mission principale sera de réaliser la préparation des données,
l'algorithme de détection des mots ba sé sur le parcours du dictionnaire
arborescent. Il sera aussi demandé de réaliser une interface afin de
permettre la consultation des résultats obtenus afin de présenter les
capacité de ce traitement..

Le stage se découpera de la manière suivante :

* Compréhension et implémentation de l'algorithme de détection des mots

* Émission d'alertes

* Réalisation d'une interface de consultation des résultats

Il sera aussi demandé, à chaque phase, de réaliser les tests et la
documentation nécessaires.

Profile recherché :

- Formation d'ingénieur ou maitrise informatique

- Environnement technique : Windows/Linux, Java/Python,
  Eclipse/Netbeans, SVN, Maven, ...

- Autonomie

- Bonne aisance rédactionnelle

- Capacité à travailler en équipe

Durée : minimum 6 mois

Date de début : avril 2019

Lieu : Gentilly

Pour postuler, envoyez votre candidature à
christian.fluhr@geolsemantics.com

www.geolsemantics.com"
"580","2019-03-27","BRGM et LLL","Orléans","Stage de master 1 ou 2

BRGM (bureau de recherches géologiques et minières) et LLL (Laboratoire
Ligérien de Linguistique)

Structuration de descriptions géologiques

*Contexte* : Toutes les données sur les ouvrages souterrains (forages,
sondages, puits et sources) du territoire sont collectées pour être
conservées dans une base de données nommée la Banque du Sous-Sol (BSS),
organisée et gérée par le BRGM, service géologique national. Cette
bancarisation permet d'améliorer notre connaissance du sous-sol et de
favoriser les applications en ressources naturelles (ressources fossiles
et énergétiques), en géotechniques (travaux d'infrastructure et
d'aménagement, etc.). Cette base de donnée contient 700 000 ouvrages et
travaux souterrains qui, pour près de la moitié, contiennent des données
et information sur la géologie du sous-sol et plus particulièrement la
description géologique le long des logs de sondages/forages. Ces données
sont actuellement mises à disposition sur notre plateforme de diffusion
InfoTerre (http://inforterre.brgm.fr).

Ces coupes géologiques sont par la suite validées et traitées afin de
fournir une information géologique en tout point de
l'espace. Aujourd'hui, environ 20% des logs possèdent une coupe
géologique élaborée et vérifiée par un professionnel.

Afin de pouvoir mieux traiter et vérifier ces données, il nous faut
transférer ces descriptions géologiques aujourd'hui sous forme de textes
dans des champs attributaires du modèle de données accueillant les
coupes géologiques.

L'extraction d'information, domaine du Traitement Automatique des
Langues, s'intéresse à cette question de la structuration de données à
partir d'informations non structurées présentes dans des descriptions
textuelles.  Les méthodes permettant de structurer l'information peuvent
être de deux types : symboliques ou statistiques. Lorsque le domaine
d'application est très restreint, par exemple la nature des roches, les
méthodes symboliques basées sur des règles ou grammaires locales et des
lexiques du domaine permettent d'obtenir des résultats satisfaisants.

*Descriptif du stage* : Le sujet du stage proposé portera sur le
développement d'une approche visant à automatiser un « transfert » des
description d'une nature de roche aujourd'hui en texte vers des champs
attributaires (contenant des lexiques) bien définis.
Par exemple :
En texte : « sable argileux »
Structuré : lithologie 1 : sable ; qualifiant : argileux

Pendant la durée du stage, le stagiaire sera en charge d'établir un état
de l'art sur les méthodes existantes permettant de résoudre la
problématique.  Il pourra travailler sur des logiciels comme Unitex
(https://unitexgramlab.org/fr) ou tout autre outil adapté pour modéliser
les descriptions des natures de roche et ainsi les extraire des textes,
et devra mettre en place une évaluation automatique régulière du système
développé. Le stagiaire sera également amené à développer des scripts
python pour le traitement des données textuelles (pré- et
post-traitement) ainsi que pour interagir avec la base de données.


*Profil candidat(e)* : Stage de master

   - Formation en Traitement Automatique des Langues
   - Connaissance de base de l'outil UNITEX ou d'un outil d'analyse de
     corpus
   - Manipulation de base de données et des registres des lexiques
   - Programmation Python
   - Intérêt pour le langage scientifique de description/observation des
     roches.

Motivation, rigueur, capacité d'organisation et relationnelle, autonomie
et esprit d'initiative sont des plus pour la sélection des candidats.


*Encadrement* :
BRGM : Christelle Loiselet (Ingénieur géologue),
LLL : Anne-Lyse Minard (Maître de Conférences en TAL)

*Durée du stage* : 6 mois

*Période du stage* : Avril - Septembre 2019

*Localisation du stage* : au Centre scientifique et technique du BRGM à
Orléans (45) et au Laboratoire Ligérien de Linguistique à l'Université
d'Orléans (45).


Une lettre de motivation et un CV actualisés sont à adresser à
Christelle Loiselet (c.loiselet@brgm.fr) ou à Anne-Lyse Minard
(anne-lyse.minard@univ-orleans.fr)."
"581","2019-03-27","Crédit Agricole","Montrouge","Emploi : Freelance/Stage Annotation manuelle de textes financiers en
Anglais/Français
=========================================================================

Le DataLab Groupe de Crédit Agricole SA recherche 3 ou 4 annotateurs à
temps plein ou partiel, débutants et confirmés, pour l'annotation
manuelle de textes financiers Anglais/Français.

Contexte

Le DataLab développe des méthodes d'extraction d'information à partir de
textes en langue naturelle.
Dans le cadre de la préparation de cette tâche d'extraction
d'information, l'équipe construit un corpus de textes annotés.

Durée : 1 à 2 mois (temps plein ou partiel)
Lieu de travail : DataLab Groupe
Date de démarrage souhaitée : Juin
Rémunération : selon profil
Candidature : envoi d'un CV
Contacts:
Aymen SHABOU
(aymen.shabou@credit-agricole-sa.fr),
Yulia KOLOSKOVA
(Yulia.koloskova@credit-agricole-sa.fr)

Description

La mission de la personne recrutée sera d'annoter des entités nommées
d'intérêt et leurs relations.
L'annotation se fera en équipe à l'aide d'un logiciel collaboratif dédié
et selon des consignes d'annotation détaillées, pour lesquels la
personne recrutée sera formée.
L'annotation se fera sous la supervision d'un infolinguiste Sénior du
DataLab.

Compétences
- maîtrise de la langue anglaise
- maitrise de la langue française
- grande rigueur
- aptitude pour le travail en équipe
- une expérience en annotation manuelle de textes serait un plus
- des connaissances en TAL / linguistique / ingénierie de la
  connaissance seraient un plus
- des connaissances en corpus financiers seraient un plus.

Autres opportunités

Les opportunités d'annotation de corpus textuels sont nombreuses dans le
groupe. Les profils recrutés sur ce projet seront donc sollicités en
priorité par le DataLab pour les futurs besoins d'annotation."
"582","2019-04-10","Lo Congrès","Pau","OFFRE DE STAGE

Développeur/Développeuse TAL (Traitement Automatique des Langues)

LOCALISATION : Pau (Billère, 64)

Le Congrès permanent de la langue occitane est une institution
académique de régulation de la langue occitane. Il rassemble les
fédérations historiques et les institutions d'étude, de valorisation
et transmission de cette langue, et est soutenu par les collectivités
(Régions Occitanie et Nouvelle-Aquitaine via l'Office public de la
langue occitane, Auvergne-Rhône-Alpes) et le ministère de la Culture
et de la Communication-DGLFLF.

Le Congrès est éditeur du portail locongres.org (300 000 visites/an),
plateforme de ressources lexicales et d'outils linguistiques en langue
occitane. Il pilote également la Feuille de route de développement
numérique de l'occitan, dirige différents projets en technologies de
la langue (programme LINGUATEC, clavier prédictif Android, correcteur
orthographique pour éditeurs de texte, client de messagerie et
navigateurs web) et travaille en partenariat avec le laboratoire
CLLE-ERSS (UMR CNRS/Toulouse 2) autour de la constitution d`une base
textuelle (BaTelÒc) et d'un lexique ouvert des formes fléchies
(LOFlÒc).

Le Congrès est constitué d'une équipe de 6 personnes (directeur,
développeuse TAL/Webmaster, chargé de mission linguistique,
lexicographes et secrétaire-comptable).

MISSIONS

Vos missions s'effectueront dans le cadre d'un consortium européen
associant universités, académies de la langue et une société de
développement de logiciels : LINGUATEC (EFA227/16) « Développement de
la coopération transfrontalière et du transfert de connaissances en
technologies de la langue ». Il s'agit d'un programme retenu par le
second appel à projets du Programme de Coopération Territorial
Espagne-France- Andorre POCTEFA (2014-2020) qui a pour objectif le
transfert de technologies et le développement de ressources et
d'applications linguistiques innovantes en aragonais, basque et
occitan.

En fonction de la durée du stage et de vos centres d'intérêt, vous
effectuerez tout ou partie des tâches suivantes :

1. Réalisation d'un lexique de formes fléchies contenant les mots
français des dictionnaires bilingues du Congrès :

Dans le cadre de la refonte de son site Internet, Le Congrès souhaite
fusionner ses applications en une seule multi-application. Celle-ci
permettra d'accéder, pour un mot tapé par l'utilisateur, à ses
traductions (ou aux traductions de son lemme), à ses flexions, aux
expressions qui le contiennent... Cet outil permettra, entre autres,
d'accéder aux traductions en occitan du lemme d'une forme fléchie en
français.

Vous serez chargé de la réalisation de la base de formes fléchies françaises qui sera interrogée par cet outil, qui
servira également à construire divers outils comme un traducteur automatique. Vous extrairez les formes
françaises des dictionnaires bilingues du Congrès, recenserez les formes fléchies existantes et génèrerez les
formes fléchies manquantes. Vous pourrez vous appuyer pour ce faire sur les règles de flexion du français et sur la base de formes fléchies Morphalou.

2. Enrichissement des ressources en français du traducteur automatique
Apertium :

Dans le cadre de Linguatec, Le Congrès développe un traducteur
automatique occitan-français et français- occitan. Afin d'améliorer
son fonctionnement, vous aurez la charge d'enrichir les lexiques de
formes fléchies en français d'Apertium à partir du lexique de forme
fléchies décrit ci-dessus ainsi que du lexique de formes fléchies
Morphalou.

Vous serez également chargé d'améliorer le PoS-tagger français
d'Apertium en enrichissant sa base de règles de désambiguisation.

PROFIL
- Etudiant en Master 1 informatique ou linguistique.
- Capacité à utiliser un ou plusieurs langages de programmation.
- Connaissances solides en grammaire française.
- Autonomie, rigueur, capacité d'analyse, maîtrise des échéances

DUREE DU STAGE

Entre un et deux mois.

REMUNERATION

Montant de la gratification obligatoire. Si stage inférieur à 44
jours, possibilité de prise en charge de l'hébergement.

Envoyer CV + Lettre de motivation à : b.dazeas@locongres.org"
"583","2019-08-26","Worldline","Seclin","Smarter Chatbots (F/H) en Alternance

Publish Date: Aug 13, 2019

Location: Seclin - 59, Nord, FR

Company: Atos

About Worldline

Worldline [Euronext: WLN] is the European leader in the payment and
transactional services industry. With innovation at the core of its
DNA, Worldline's core offerings include pan-European and domestic
Commercial Acquiring for physical or online businesses, secured
payment transaction processing for banks and financial institutions,
as well as transactional services in e-Ticketing and for local and
central public agencies. Thanks to a presence in 30+ countries,
Worldline is the payment partner of choice for merchants, banks,
public transport operators, government agencies and industrial
companies, delivering cutting-edge digital services. Worldline's
activities are organized around three axes: Merchant Services,
Financial Services including equensWorldline and Mobility &
e-Transactional Services. Worldline employs circa 11,000 people
worldwide, with estimated pro forma revenue of circa 2.3 billion euros
on a yearly basis. worldline.com

Le contexte

Remises sur le devant de la scène grâce à l'explosion récente des
techniques de machine learning, de la robotique grand public et du big
data, les problématiques de reconnaissance vocale (« Automatic Speech
Recognition »), ou de traitement automatique du langage naturel («
Natural Language Processing/Understanding ») voient s'ouvrir un nouvel
horizon. Au sein de l'équipe « User Experience » du département
Recherche et Développement de Worldline, nous nous intéressons aux
interactions avec des assistants personnels virtuels grâce à ces
nouvelles interfaces conversationnelles : comment extraire des
concepts présents dans les requêtes formulées par l'utilisateur ?
Comment créer un dialogue qui semble « naturel » ? Quelles sont les
meilleures solutions logicielles et matérielles à mettre en place ?

Le projet

Ce stage a pour objet l'expérimentation de méthodes avancées de
traitement du language dans le but de proposer une meilleure
expérience conversationnelle : prise en compte de feedback explicite
ou implicite pour enrichir une écoute active lors de la conversation,
contextualisation du dialogue et gestion de modèles multilingues,
équivalence sémentique pour une reformulation précise de réponses à
partir de contenus externes, recommandations et système de relance de
conversation pour éviter les impasses.

Des approches de Machine Learning orientées traitement de séquences
seront à privilégier. En relation avec des partenaires de Worldline,
on cherchera des outils pour mesurer les performances des différentes
méthodes, et pour industrialiser la création de modèles. Le stage
aboutira à la réalisation d'un démonstrateur technique ou
d'usage. Vous serez amené à partager vos travaux lors d'événements
internes.

Environnement technique : Kotlin, Javascript, Opensource, etc.

Compétences développées

- Maîtriser des techniques avancées de traitement automatique du
  langage orienté conversations et chatbots

- Réaliser les différentes étapes d'un travail de recherche et
  développement entreprise : élaborer une réflexion originale sur un
  sujet donné, établir un état de l'art des technologies et des
  usages, faire des choix techniques appropriés à un contexte donné,
  valider ces choix par la réalisation de solutions innovantes et
  démonstratives.

Qui êtes-vous ?

De formation supérieure en informatique (Bac+5), vous recherchez un
stage dans l'innovation.

Vous avez acquis de bonnes connaissances dans le domaine du traitement
du langage.

Autonome et impliqué(e), vous faites preuve d'une grande curiosité et
d'une appétence particulière pour tout ce qui a trait à l'Innovation,
aux nouveaux usages et nouvelles technologies.

Why work at Worldline?

Our success comes from strong skills, new ideas, diverse points of
view and the energy of all women and men from Worldline. Not only do
they represent our Human Capital, they are also key players in our
success. We make managing our talents a major asset in the success of
our business.

At Worldline, we do more than just managing our talents. It is our top
priority to involve them, inspire them, and develop them. In line with
our guiding principle ""Build your career and grow with us"", it is our
mission to ensure that their potential can grow and flourish through
the numerous development programs and career opportunities we offer.

Your Application

If you wish to apply for this position, please click below to complete
our online application form and attach your CV in either Word, rtf or
text format.  Worldline is an equal opportunity employer. All
applicants will be considered for employment without attention to
their race, color, religion, sex, sexual orientation, gender identity,
national origin, veteran or disability status. Our recruitment
decisions are based solely on qualifications, skills, knowledge and
experience and relevant business requirements.

We are committed to making reasonable adjustments to the applications
process for people with disabilities.

Postuler en ligne :

https://jobs.atos.net/job/Seclin-Smarter-Chatbots-%28FH%29-en-Alternance-Nord/535071901/"
"584","2019-10-14","Naver Labs","Grenoble","NAVER LABS Europe: Internship  

Start date: Fall 2019 or early 2020

Duration; 5-6 months

We are opening a research internship on Reinforcement Learning
techniques for applications to controlled text generation.  Under
conditions where training data is limited, standard end-to-end
training of seq2seq models may generalize poorly and produce
inadequate results at test time. A possible remedy is to augment
models with rewards that control the quality of the outputs. These
rewards can address two complementary goals: (i) taking into account
global characteristics of observed sequences that go beyond standard
local teacher-forcing training techniques (observation bias problem),
and (ii) moving the generation process towards desired properties of
the output (e.g. favoring shorter sentences or performing style
transfer).

Supervisors: Marc Dymetman and Hady Elsahar.

We are looking for a motivated intern to help us develop methods and
algorithms for addressing this general problem, both in theory and in
practice. Experiments will be conducted on selected text generation
tasks (NLG, Summarization or Machine Translation).

The successful candidate should be enrolled in a graduate program, at
the Master or (preferably) PhD level, with experience (ideally) in
Deep Learning, Reinforcement Learning and Natural Language Processing.

Publication of results in major conferences/journals will be strongly
encouraged.

REQUIRED SKILLS :

Strong mathematical and programming skills as well as familiarity with
one of the major current deep learning toolkits (PyTorch preferred but
not compulsory) are a requirement.

For more information and for applying, please visit the link below:

https://europe.naverlabs.com/job/reinforcement-learning-for-controlled-text-generation/"
"585","2019-10-15","Naver Labs","Grenoble","Job Type : Internship  
Start date : November 2019 or otherwise August2020
Duration : 5-6 months

Description

Aspect-based sentiment analysis (ABSA) is the task of identifying
fine-grained opinion polarity towards specific aspects associated with
a given target.

The goal of this internship is exploring and implementing a new neural
architecture for end-to-end ABSA, where term detection, aspect and
polarity classification are jointly modeled. Special attention will be
given to data-efficient methods in order to cope with situations where
little amount of annotated data is available. Experiments will be
conducted and evaluated on multiple datasets from various domains and
languages and results will be evaluated not only on specific ABSA
subtasks but also on the full chain of annotations.

The expected outcome is, a minima, a multilingual prototype working on
different domains.

The successful candidate should be enrolled in a graduate program, at
the Master or PhD level, with a focus on NLP and Deep Learning.

Publication of results in major conferences/journals will be strongly
encouraged.

Required skills

Good programming skills and proficiency with TensorFlow or PyTorch

References

Task: SemEval2016 Task 5: http://alt.qcri.org/semeval2016/task5/

[1] Pontiki, Maria, Dimitris Galanis, Haris Papageorgiou, Ion
Androutsopoulos, Suresh Manandhar, Mohammed AL-Smadi, Mahmoud
Al-Ayyoub, et al. 2016. ""SemEval-2016 Task 5 : Aspect Based Sentiment
Analysis."" In Proceedings of the 10th International Workshop on
Semantic Evaluation (SemEval-2016), 19-30. Association for
Computational Linguistics.

[2] Bailin, Wang and Lu, Wei. ""Learning Latent Opinions for
Aspect-level Sentiment Classification"". Proceedings of AAAI 2018, New
Orleans.

[3] Chi Sun, Luyao Huang, Xipeng Qiu. ""Utilizing BERT for Aspect-Based
Sentiment Analysis via Constructing Auxiliary Sentence"". Proceedings
of NAACL-HLT 2019, pages 380-385 Minneapolis, Minnesota, June 2 - June
7, 2019.

Application instructions

Please note that applicants must be registered students at a
university or other academic institution and that this establishment
will need to sign an 'Internship Convention' with NAVER LABS Europe
before the student is accepted.

You can apply for this position online. Don't forget to upload your CV
and cover letter before you submit. Incomplete applications will not
be accepted.

About NAVER LABS

NAVER LABS is a world class team of self-motivated and highly engaged
researchers, engineers and interface designers collaborating together
to create next generation ambient intelligence technology and services
that are rich with the organic understanding they have of users, their
contexts and situations.

Since 2013 LABS has led NAVER's innovation in technology through
products such as the AI-based translation app `Papago', the
omni-tasking web browser `Whale', the virtual AI assistant `WAVE',
in-vehicle information entertainment system `AWAY' and M1, the 3D
indoor mapping robot.

The team in Europe is multidisciplinary and extremely multicultural
specializing in artificial intelligence, machine learning, computer
vision, natural language processing, UX and ethnography. We
collaborate with many partners in the European scientific community on
R&D projects.

NAVER LABS Europe is located in the south east of France in
Grenoble. The notoriety of Grenoble comes from its exceptional natural
environment and scientific ecosystem with 21,000 jobs in public and
private research. It is home to 1 of the 4 French national institutes
in AI called MIAI (Multidisciplinary Innovation in Ai) It has a large
student community (over 62,000 students) and is a lively and
cosmopolitan place, offering a host of leisure opportunities. Grenoble
is close to both the Swiss and Italian borders and is the ideal place
for skiing, hiking, climbing, hang gliding and all types of mountain
sports.

Apply Online

https://europe.naverlabs.com/job/end-to-end-aspect-based-sentiment-analysis/"
"586","2019-10-15","Syllabs","Paris","Offre de stage : M2 Linguistique informatique (H/F) - Extraction 
d'information (Paris 11e)

Créée en 2006, Syllabs compte parmi les leaders mondiaux en solutions
sémantiques et production automatique de contenus multilingues.

Forts d'un important travail de R&D en continu depuis notre création,
nous avons développé un ensemble technologique comprenant des solutions
de collecte (/web mining/), d'analyse (/text mining/) et de génération
de textes (robots rédacteurs). Nous développons des solutions de
rédaction automatique d'articles pour plusieurs acteurs médias (Les
Echos, Le Monde, Slate, Radio France...) ainsi que des descriptifs pour
des sites de l'e-commerce, de l'immobilier ou du tourisme.

Syllabs recrute un(e) stagiaire dont le rôle sera d'améliorer la partie 
linguistique de notre système d'extraction d'information.

*-----------------------------*
*Description du stage*
-----------------------------

L'extraction d'information de Syllabs utilise un outil dédié à base de
règles linguistiques afin d'identifier et d'extraire, à partir d'un
document rédigé en langage naturel, tous type d'expressions
linguistiques et de tonalité. Nous souhaitons prolonger les travaux
d'extraction au gré des différents projets en cours et à venir.

En collaboration avec les personnes travaillant sur l'outil, les tâches
entreprises tout au long du stage concerneront principalement :

  * La compréhension du fonctionnement du système et des besoins.

  * La prise en main de l'existant et la révision des règles et de la
    structure des projets.

  * L'écriture de nouvelles règles et la gestion de lexiques.

  * L'écriture de tests unitaires, à partir de corpus définis au
    préalable.

  * Selon la durée du stage, le développement spécifique et
    apprentissage pour la désambiguïsation en sortie d'extraction.

-----------------------------
*Profil recherché*
*-----------------------------*

  * Formation M2 en linguistique informatique

  * Aptitude pour la représentation formelle du langage

  * Expérience avec un outil d'extraction d'information (Nooj, Gate...)

  * Bon niveau en Python serait un plus

  * Autonomie et capacité à travailler en équipe

  * Bon sens relationnel et à l'écoute

-----------------------------

*Divers*

-----------------------------

Durée : de 4 à 6 mois

Stage conventionné, rémunération supérieure à la rémunération minimale +
tickets resto + remboursement de la moitié du passe Navigo.

Nos locaux sont situés dans le très agréable quartier de Charonne, entre
Bastille et Nation, au 35 rue Chanzy (75011), que nous partageons avec
d'autres start-ups innovantes.

Merci d'envoyer votre candidature à l'adresse jobs@syllabs.com"
"587","2019-11-07","HelloWork","Rennes","Stage M2 : Segmentation textuelle dans un cadre de classification
automatique d'offres d'emploi (English version below)


Contexte

Chez HelloWork, nous mettons en relation les recruteurs, les
collectivités et les centres de formations avec tous les actifs. Qu'ils
cherchent à évoluer dans leur entreprise ou juste à en changer. Qu'ils
se réorientent ou montent en compétences. Qu'ils soient en recherche
active ou à l'écoute d'opportunité. Nos services RegionsJob, ParisJob,
Cadreo, BDM et MaFormation leur permettent de trouver leur équilibre vie
pro / vie perso tout au long de leur carrière. HelloWork développe
également des logiciels RH pour accompagner et favoriser l'expérience
recruteur et candidat sur l'intégralité d'un processus de recrutement
avec Talent Detection, Talentplug ou encore CVCatcher.


HelloWork recherche un(e) stagiaire pour travailler sur la segmentation
automatique des offres d'emploi en vue de la classification supervisée
des offres.


Description du stage

Afin de rendre le processus du recrutement plus efficace et ainsi
d'améliorer l'expérience candidat et recruteur, nous développons un
système de classification supervisée multi-classe des offres
d'emploi. Pour améliorer notre système, nous souhaitons mettre en place
une segmentation automatique des offres basée sur des approches
statistiques (clustering / similarité entre les segments textuels /
glissement thématique (topic shift) pour déterminer les frontières des
segments textuels, etc.), combinées si besoin avec des règles manuelles
ou déduites automatiquement.

Nous disposons d'offres semi-structurées ou non-structurées. Votre
objectif sera de proposer et d'implémenter un algorithme qui découpe une
offre en segments sémantiquement homogènes (ex. ""Intitulé de poste"",
""Description de l'entreprise"", ""Missions"", ""Profil recherché"", etc.). Ce
découpage doit répondre à nos besoins d'amélioration de la
classification supervisée des offres.

Cette mission implique de :

  * analyser la structure ""type"" de l'offre d'emploi,

  * comprendre le fonctionnement de notre classifieur d'offres,

  * définir quels segments doivent être utilisés/écartés pour une
    performance de classification optimale,

  * faire un état de l'art des techniques de segmentation de documents
    textuels, mais aussi de détection de plagiat et de doublons ou Near
    Duplicate Detection en anglais (pour écarter la partie ""Description
    de l'entreprise"" partagées par plusieurs offres).

  * sélectionner une/des approche(s) adaptée(s) à la nature du document
    et au contexte industriel,

  * implémenter cette approche en Python,

  * évaluer l'impact de cette approche sur les performances de
    classification automatique.


Vous serez intégré dans notre équipe pluridisciplinaire DataLab. En
charge des problématiques Big Data, elle est composée de data
scientists, d'experts NLP et web sémantique, de data architectes, data
ingénieurs, d'un web analyste et d'une référente qualité. Vous pourrez
vous appuyer sur nos connaissances du domaine du recrutement issues de
19 ans d'activité de l'entreprise. Vos travaux seront appliqués à nos
flux d'offres grandissants et auront un vrai impact business. En
fonction de la durée du stage et de votre avancement, vous pourrez aussi
être amené à mesurer l'impact de vos travaux sur la mise en ligne
automatique des offres et sur notre système de recommandation.



Profil recherché

  * Etudiant en M2 en Traitement Automatique des Langues ou en Data
    Science avec un intérêt pour des technologies type NLP / Text
    Analytics

  * Vous souhaitez compléter votre formation par un stage résolument
    tourné vers l'opérationnel

  * Maîtrise du langage de programmation Python

  * Connaissances en Machine Learning appréciées


Ce poste est basé à Rennes au sein de notre siège social.

Stage de 4 à 6 mois.


Contact

Cécile Bagot (cbagot@hellowork.com)"
"588","2019-11-13","LIMSI","Orsay","Stage M2 : *Identifier des phrases identiques et similaires en corpus *
*clinique*.

[Identifying identical and similar sentences in clinical corpus]
Mots-clés : traitement automatique de la langue, similarité, domaine
biomédical

*Durée* : 5 mois
*Niveau* : Master 2 (professionnel ou recherche), fin d'école d'ingénieur
*Rémunération* : Indemnité de stage, soit ~ 600 ¤/mois, indemnité de
transport incluse

Contexte

 1. L'apprentissage automatique est un levier important des technologies
    du langage. Il repose sur la disponibilité de corpus annotés pour
    définir des méthodes, entraîner des modèles et évaluer des
    algorithmes. Ces données doivent être représentatives de différents
    phénomènes linguistiques (formulations syntaxiques, distribution
    statistique de l'emploi de termes spécifiques, erreurs humaines
    telles que les fautes d'orthographe, etc.)  afin de garantir la
    robustesse des méthodes et outils développés. Par ailleurs, les
    données doivent également être partageables afin de garantir la
    transparence et la reproductibilité des expériences.

 2. Dans le domaine biomédical, le secret médical et la préservation de
    la confidentialité s'accompagnent d'un cadre réglementaire qui
    restreint l'accès aux données textuelles telles que les
    comptes-rendus hospitaliers dans un objectif de recherche en
    traitement automatique de la langue. Le partage des documents
    cliniques n'est possible qu'après *anonymisation*, c'est à dire un
    traitement des textes qui garantisse scientifiquement
    l'impossibilité de savoir que des informations concernant un
    individu donné sont présentes dans les textes, de ré-identifier tout
    individu concerné par les textes, ou de faire des inférences sur les
    informations concernant ces individus.

Objectifs du stage

L'objectif de ce projet est d'analyser un corpus de do*cuments cliniques
du point de vue de la similarité entre énoncés*. Ce travail permettra
d'identifier dans un corpus clinique les phrases les plus similaires à
une phrase source, afin de mettre en oeuvre le principe de k-anonymat
pour identifier des phrases cliniques - réelles ou synthétiques -
propice au partage dans le respect de la confidentialité.  Approche
proposée

Nous nous intéressons ici à la constitution d'un corpus de phrases
redondantes. L'approche suivie par Li et al. (2015) consiste à filtrer
les phrases par fréquence et à conserver les phrases qui reviennent à
l'identique dans les compte-rendu de différents patients. Si cette
approche permet d'éliminer les phrases de faible fréquence contenant
potentiellement des données identifiantes, elle élimine également les
phrases contenant des données cliniques (résultats de laboratoire) alors
que nous souhaitons disposer d'outils du TAL capables de les traiter. La
solution que nous envisageons vise à produire des données fictives mais
néanmoins réalistes sur les plans cliniques (permettant une association
entre plusieurs données cliniques telles que descriptions et résultats
de laboratoire) et linguistiques en identifiant en plus des phrases
strictement identiques des groupes de phrases similaires qui pourraient
donner lieu à la production de phrases anonymes et réalistes en générant
une nouvelle variante non rencontrée en corpus. A partir d'une phrase
synthétique (générée), l'examen des phrases réelles les plus similaires
permettra de sélectionner des phrases conformes au principe de
k-anonymat (Sweeny, 2002).

Dans ce contexte, nous prévoyons de confier au stagiaire de M2 une étude
exploratoire permettant d'implémenter plusieurs méthodes de calcul de
similarité entre énoncés (phrases) et d'analyser la prévalence de
différents types de similarité au sein de deux corpus clinique en
français : un corpus réel (LERUDI) et un corpus synthétique, issu de la
traduction de documents américain (MIMIC).


Programme de Travail :

 - Identifier les phrases redondantes dans un corpus
 - Prendre en charge le découpage en phrase du corpus, l'identification
   de phrases identiques
 - Identifier des phrases similaires dans un corpus
 - Etudier différents types de « similarités » : distance de
   Levenshtein, similarité Dice ou cosine, homologie à l'aide d'outils
   fournis (module Text::Similarity dans PERL, BLAST, ...)
 - Si l'avancement du travail le permet, proposer une visualisation des
   résultats

Références

Sweeney, L. (2002). k-anonymity : A model for protecting privacy.
International Journal of Uncertainty, Fuzziness and Knowledge-Based
Systems, 10(05) :557-570.

Li, Dingcheng & Rastegar-Mojarad, Majid & Li, Yanpeng & Sohn, Sunghwan &
Mehrabi, Saeed & Elayavilli, Ravikumar & Yu, Yue & Liu, Hongfang & Wang,
Yanshan. (2015). A Frequency-based Strategy of Obtaining Sentences from
Clinical Data Repository for Crowdsourcing. Studies in health technology
and informatics. 216. 1033-4.


Compétences souhaitées:

Le stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue et/ou en
apprentissage automatique seront un plus. Le contenu et l'ambition du
stage pourront être modulés en fonction du niveau d'étude et de la durée
du stage du candidat.

Pour candidater :

Envoyer un CV, un relevé de notes récent ainsi que les coordonnées (nom,
mail) d'au moins deux référents (professeurs ou encadrants de précédents
stages ou emplois pouvant attester de vos compétences) à
Cyril.Grouin[at] limsi.fr et Aurelie.Neveol[at]limsi.fr"
"589","2019-11-13","IRIT","Toulouse","Proposition d'un stage niveau Master 2:
Explication de modèles en Traitement Automatique des Langues par
extraction d'arguments
Natural Language Processing model explanation by argument extraction.


Contexte: Ce stage aura lieu dans le cadre du projet 3IA toulousain
ANITI, au sein de la chaire de Leila Amgoud ""Empowering Data-driven AI
by Argumentation and Persuasion"", à l'IRIT.

Le succès croissant des modèles d'apprentissage neuronal en Traitement
Automatique des Langues (TAL/NLP) soulève des questions cruciales sur la
confiance que l'on peut accorder à des ""boites noires"" dont les
décisions sont difficiles à diagnostiquer. Une approche courante en
apprentissage automatique est de chercher à repérer quels éléments de
l'entrée (des pixels d'une image, des mots d'un texte) ont influencé le
modèle appris ou ses prédictions.

Ces approches sont en général peu structurées et ne fournissent pas une
explication cohérente reliant les éléments importants de la décision
(Belinkov & Glass, 2019).

En traitement automatique des langues, ou l'entrée est un texte, isoler
des éléments pertinents est déjà une base compréhensible par l'humain
(Lei et al., 2016; Bastings et al., 2019), mais une explication
convaincante demanderait à relier ces éléments pour expliciter leur rôle
dans la décision, que ce soit pour supporter un choix ou pour ignorer un
autre, en d'autre terme développer une argumentation de la décision.

Ce stage a pour but d'enrichir les approches par extraction d'arguments
de la décision en fournissant des argumentations structurées, en
combinant les méthodes de repérage de ""bons"" arguments et les méthodes
permettant d'induire automatiquement des liens pertinents entre éléments
textuels (Liu & Lapata, 2018).


Encadrement: Philippe Muller, Leila Amgoud, Emiliano Lorini
Contact: philippe.muller@irit.fr


- Compétences attendues:
Master 2 en mathématique ou informatique en cours, connaissances en
apprentissage automatique. Des connaissances en TAL seraient un plus,
mais ne sont pas un prérequis.

- Compétences développées pendant le stage: TAL, Deep learning,
  argumentation, IA explicable.

- Durée: 5 ou 6 mois
- Gratification au taux légal


Références

- Joost Bastings, Wilker Aziz, Ivan Titov: Interpretable Neural
  Predictions with Differentiable Binary Variables.  ACL (1) 2019:

- Yonatan Belinkov, James R. Glass: Analysis Methods in Neural Language
  Processing: A Survey. TACL 7: 49-72 (2019)

- Tao Lei, Regina Barzilay, Tommi S. Jaakkola: Rationalizing Neural
  Predictions. EMNLP 2016: 107-117

- Tim Miller: Explanation in artificial intelligence: Insights from the
  social sciences. Artif. Intell. 267: 1-38 (2019)

- Yang Liu, Mirella Lapata: Learning Structured Text
  Representations. TACL 6: 63-75 (2018)

- Julia Strout, Ye Zhang, Raymond J. Mooney: Do Human Rationales Improve
  Machine Explanations?  Proceedings of the Second BlackboxNLP Workshop
  on Analyzing and Interpreting Neural Networks for NLP, (2019)"
"590","2019-11-22","CIRAD","Montpellier","Stage Master 2

Intégration d'informations sémantiques pour identifier les variables
essentielles à partir de données textuelles hétérogènes : application à la
Malherbologie

Durée : 5 à 6 mois à partir de février 2020

Encadrement : Sandrine Auzoux (AIDA) et Mathieu Roche (TETIS)

Contact : sandrine.auzoux@cirad.fr et mathieu.roche@cirad

Description :

Les adventices (mauvaises herbes) sont une contrainte majeure de la
production agricole tropicale, induisant des pertes de récoltes de 30
à 80%. Le calage des pratiques de désherbage dans les itinéraires
techniques nécessite une bonne connaissance de leur comportement. Le
développement de l'agroécologie en région tropicale nous amène à
considérer les dimensions négatives et positives des adventices.

Le travail proposé dans le cadre de ce stage au Cirad (TETIS/AIDA)
consiste à proposer et mettre en oeuvre une méthode automatique
d'identification de variables essentielles pour la gestion des
adventices qui implique la mise en place de nouvelles pratiques
agricoles et la mobilisation de la biodiversité. Nous définissons les
variables essentielles comme une combinaison d'éléments
caractéristiques, par exemple le climat, le milieu, la localisation et
le nom vernaculaire.

Le but du stage est d'identifier, par des méthodes de fouille de
textes, les variables essentielles de manière automatique à partir de
données textuelles. Dans l'extrait ci- dessous, les variables
essentielles du pissenlit à extraire sont par exemple une combinaison
de climat tempéré, milieux humides et échelle mondiale.
---
Faire connaissance avec le Pissenlit et ses bienfaits.
L'herbacée, Taraxucum officinale, connue sous le nom de pissenlit,
elle est une plante originaire d'Europe de l'Ouest. Le pissenlit pousse
à l'état sauvage dans les climats tempérés et milieux humides de toutes
les régions du monde, pouvant vivre jusqu'à 2 000 mètres d'altitude.
---

Dans le processus de fouille de textes à mettre en place, deux verrous
scientifiques seront particulièrement étudiés :

- Adapter les méthodes de fouille de textes aux différents types de
données mobilisées (scientifique vs. grand public).

- Intégrer des ressources sémantiques et scientifiques (par exemple,
thésaurus) au processus proposé.

Dans ce cadre, le processus reposera sur 3 grandes étapes qui seront
mises en place et évaluées avec des experts du domaine :

1) Acquisition de données textuelles en anglais par des méthodes
semi-automatiques (web crawling / web scraping). Deux types de
documents seront étudiés : (1) des documents « grand public » issus du
web (blogs, sites touristiques, presse) et ( 2) des publications
scientifiques (articles scientifiques).

2) Extraction de variables essentielles dans ces données par des
méthodes adaptées au domaine de la Malherbologie. Ces méthodes
s'appuieront sur l'intégration de connaissances sémantiques notamment
spatiales (par exemple, Geonames, OpenStreetMap, etc.) et thématiques
(par exemple, Agrovoc, dictionnaire des plantes, etc.)

3) Evaluation de ces informations dans un cadre pluridisciplinaire et
mise en lien avec des bases de données de référence.

Lieu et gratification :

Ce stage basé au Cirad à Montpellier (https://www.cirad.fr/) bénéficie
d'une gratification mensuelle de 580 euros .

Profil : Master 2 ou École d'Ingénieur en Informatique / Science des Données"
"591","2019-11-22","CIRAD","Montpellier","Stage Master 2

Biodiversité et pratique de recherche : extraction automatique de mots-
clés caractérisant les thématiques saillantes issues de données
textuelles

Durée : 5 à 6 mois à partir de février 2020

Encadrement : Mathieu Roche (TETIS) et Christian Leclerc (AGAP)

Contact : mathieu.roche@cirad et christian.leclerc@cirad.fr

Description :

De nombreux travaux de fouille de textes permettent (i) de faire
émerger les descripteurs linguistiques les plus significatifs (mots,
syntagmes) à partir d'un corpus puis (ii) de les regrouper. Ceci
permet de mettre en relief, de manière automatique, les thématiques
abordées dans les textes facilitant l'organisation et l'indexation des
documents, la recherche d'information, la compréhension et l'analyse
des textes. Il permet aussi de comparer, pour une période donnée, les
approches privilégiées par différentes unités de recherche, ou encore
de décrire l'évolution de ces approches au cours du temps. Cette
analyse portera sur Biodiversité et pratique de recherche au Cirad,
avec l'objectif d'appliquer la méthode à d'autres thématiques,
notamment le territoire et la mobilité.

La réalisation du premier point (identification des descripteurs
linguistiques significatifs) s'appuie, en grande partie, sur
l'utilisation de méthodes d'extraction de la terminologie à partir de
textes, en combinant méthodes linguistiques et statistiques pour
constituer une liste de descripteurs linguistiques. La deuxième étape
du processus consiste à utiliser ces descripteurs afin de mettre en
lumière les différentes thématiques abordées dans les textes. Pour
découvrir des structures thématiques ""cachées"" dans les corpus de
textes, les méthodes appelées ""topic models"" seront utilisées,
notamment, le modèle probabiliste génératif LDA, i.e. Latent Dirichlet
Allocation.

Dans ce contexte, les objectifs du stage sont déclinés selon 4
sous-tâches :

(1) Intégrer des outils de la littérature d'extraction de la
terminologie (en particulier BioTex -
http://tubo.lirmm.fr:8080/biotex) et des approches LDA dans le cadre
du développement d'un système générique et utilisable par des non
informaticiens.

(2) Intégrer et combiner des ressources sémantiques (vocabulaire
contrôlé) fournies par les utilisateurs aux méthodes d'extraction de
la terminologie.

(3) Étudier la valeur structurante des termes rares (queue de
distribution) associées aux fonctions de rangs propres aux systèmes
d'extraction de la terminologie. De nouvelles fonctions de rangs
pourront alors être proposées, pour mettre en valeur les termes rares
et pertinents.

Lieu et gratification :

Ce stage basé au Cirad à Montpellier (https://www.cirad.fr/) bénéficie d'une
gratification mensuelle de 580 euros.

Profil :
Master 2 ou École d'Ingénieur en Informatique / Science des Données"
"592","2019-11-22","Bertin IT","Montpellier","Durée, démarrage
D'une durée de 6 mois, le stage se déroulera dans les locaux du centre
R&D à Montpellier.
Démarrage dès que possible.

Présentation de l'entreprise
Société du Groupe CNIM, Bertin IT est un éditeur et intégrateur de
solutions logicielles pour la cyber sécurité, la cyber-intelligence, la
veille stratégique et le traitement automatique de la parole. Sa marque
AMI, leader dans l'édition de logiciels d'acquisition, de gestion et de
traitement de l'information texte issue du Web, offre des solutions de
veille stratégique et d'intelligence compétitive. En particulier, notre
solution, AMI Enterprise Intelligence, permet aux entreprises
d'exploiter le Big Data afin d'anticiper les évolutions de leur
environnement concurrentiel et technologique et d'identifier de
nouvelles perspectives de développement.

Description du stage
Dans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),
nous proposons des outils avancés d'analyse de texte en vue de faciliter
aux veilleurs et analystes l'exploitation et la navigation dans
l'importante masse de documents collectés à l'issue du processus de
veille. Divers traitements sont proposés tels que l'extraction des
principales thématiques, l'identification des entités nommées ainsi que
les concepts clés apparaissant dans les documents.

Votre mission principale sera de développer un module d'extraction
d'événements de type « rachat d'entreprise ». Ce choix découle de
l'intérêt de nos clients d'étudier la présence d'un tel événement dans
différents médias afin d'avoir une vision générale de leur marché et de
maintenir automatiquement à jours leur base de connaissance sur les
différents acteurs de ce marché.

Ce module d'extraction se basera sur un corpus de textes issus de
différents médias référents à la notion de rachat (à construire), sur
l'utilisation de FrameNet pour la définition des arguments de
l'événement «rachat» dans les médias analysés, et une approche hybride
pour l'extraction des événements. Cette approches hybride consistera à
voir quel serait le meilleur algorithme d'apprentissage pouvant prendre
en compte les relations de dépendances syntaxiques existant entre les
différents arguments d'un événement. La langue cible est l'anglais.


Mots clés : TALN, Deep learning, Réseaux de neurones, Extraction
d'événement, rôles thématiques, extraction d'informations

Profil souhaité
Vous êtes actuellement en dernière année d'école d'Ingénieur (ou cursus
universitaire en mathématiques appliquées, statistiques ou data science,
linguistique informatique). Vous avez une appétence pour le traitement
du langage naturel et les méthodes d'apprentissage. Une bonne
connaissance d'au moins un langage de script tel que R, Python ou autre
est indispensable ainsi qu'une bonne connaissance d'outils de NLP tel
que Standford parser et librairie de deep learning telle que Torch ou
Tensorflow. Vous êtes également reconnu(e) pour votre rigueur et votre
dynamisme.

Vous êtes enthousiaste à l'idée de contribuer au développement de notre
activité, rejoignez-nous !
Si vous êtes intéressé(e) merci d'envoyer votre Cv et lettre de
motivation à : sabrina.pagel@bertin.fr et frederique.segond@bertin.fr"
"593","2019-11-22","Bertin IT","Montpellier","Durée, démarrage
D'une durée de 6 mois, le stage se déroulera dans les locaux du centre
R&D à Montpellier.
Démarrage dès que possible.

Présentation de l'entreprise
Société du Groupe CNIM, Bertin IT est un éditeur et intégrateur de
solutions logicielles pour la cyber sécurité, la cyber-intelligence, la
veille stratégique et le traitement automatique de la parole. Sa marque
AMI, leader dans l'édition de logiciels d'acquisition, de gestion et de
traitement de l'information texte issue du Web, offre des solutions de
veille stratégique et d'intelligence compétitive. En particulier, notre
solution, AMI Enterprise Intelligence, permet aux entreprises
d'exploiter le Big Data afin d'anticiper les évolutions de leur
environnement concurrentiel et technologique et d'identifier de
nouvelles perspectives de développement.

Description du stage
Dans le cadre de notre solution AMIEI (AMI Enterprise Intelligence),
nous proposons des outils avancés d'analyse de texte en vue de faciliter
aux veilleurs et analystes l'exploitation et la navigation dans
l'importante masse de documents collectés à l'issue du processus de
veille. Divers traitements sont proposés tels que l'extraction des
principales thématiques, l'identification des entités nommées ainsi que
les concepts clés apparaissant dans les documents.

Votre mission principale sera d'étudier la mise en oeuvre d'un outil
permettant de déterminer, de façon la plus fiable possible, les
documents les plus pertinents correspondant à des requêtes utilisateurs,
en utilisant les techniques de l'apprentissage (Machine Learning).
Le projet de stage se composera :
- D'une phase d'étude (identification d'algorithme de machine learning,
  benchmarks, réglages, tests)
- D'une phase d'implémentation logicielle (module d'apprentissage,
  modélisation, corpus, évaluation)

Encadré(e) par les responsables du projet, vous travaillerez en
collaboration avec les chercheurs et l'équipe d'ingénieurs. Votre
rigueur, votre curiosité et votre prise d'initiative vous permettra de
mener à bien le stage.

Mots clés : TALN, Deep learning, Réseaux de neurones, Recherche
d'informations

Profil souhaité
Vous êtes actuellement en dernière année d'école d'Ingénieur (ou cursus
universitaire équivalent), vous disposez idéalement d'une première
expérience (stage inclus) réussie dans un domaine similaire. Vous
disposez d'une bonne connaissance des algorithmes et des bibliothèques
d'algorithmes de Machine Learning et Deep Learning, des systèmes de
recherche d'information et des langages C++ et/ou Java.
La connaissance de Python est un plus.


Vous êtes enthousiaste à l'idée de contribuer au développement de notre
activité, rejoignez-nous !

Si vous êtes intéréssé(e) merci d'envoyer votre Cv et lettre de
motivation à : sabrina.pagel@bertin.fr et frederique.segond@bertin.fr"
"594","2019-11-29","ICVL","Blois","======= Offre de stage de 5 mois, ICVL (Fédération informatique de la
        région Centre-Val de Loire): apprentissage à partir d'un système
        symbolique ==========


****Description**** 
L'ICVL propose un stage de 5 mois sur l'apprentissage à partir d'un
système symbolique. Aujourd'hui la plupart des systèmes de Tal utilisent
de l'apprentissage. Mais la construction de corpus annotés présente un
réel coût qui freine le développement de ces méthodes lorsque de tels
corpus ne sont pas disponibles (langues sous-dotées ou sujets peu
communs). Le stage propose l'étude d'une hybridation entre un système
symbolique et un système d'apprentissage. Le système symbolique sera
utilisé pour constituer un corpus annoté sur lequel sera fait
l'apprentissage. Celui-ci pourrait disposer, en plus des annotations
fournies, de toutes autres sources d'informations disponibles librement
: étiqueteur probabiliste, plongements de mots, etc.

La question se pose alors de l'intérêt de cette hybridation entre les
deux systèmes. Est-ce que le système apprenant fera mieux au final que
le système ayant servi à l'apprentissage?

Une description plus précise est disponible sur le site TLN
(tln.lifat.univ-tours.fr).


****Profil recherché**** 
Idéalement, la personne recrutée intégrera ce stage dans un cursus de
master (soit finalisation en M2, soit stage de M1) et disposera de
connaissances théoriques et pratiques sur les techniques
d'apprentissage, telles que les CRF ou les réseaux neuronaux. Un intérêt
pour la langue et son traitement automatique serait apprécié, sans être
un pré-requis au recrutement.
Cependant, ce stage est également proposé à des étudiants en fin d'étude
de Licence (L3) qui disposeraient d'un excellent niveau académique
(mention B en licence au minimum) et désireraient découvrir les
problématiques du Tal et de l'apprentissage automatique.


****Localisation**** 
Le stage, piloté par des chercheurs de l'ICVL, pourra se dérouler au
choix de l'étudiant, sur les sites de Blois ou de Tours du Lifat
(laboratoire d'informatique fondamentale et appliquée de l'université de
Tours) ou sur le site d'Orléans du Lifo (laboratoire d'informatique
fondamentale de l'université d'Orléans).


****Gratification et durée**** 
Gratification légale, à savoir 15% du plafond de la sécurité sociale.
Cinq mois de stage de préférence (22 semaines), à partir de janvier 2020
au plus tôt.


****Date limite de candidature**** 
18 décembre 2019 


****Procédure de candidature**** 

Merci de joindre une lettre de motivation et un CV avec un contact
académique et, éventuellement, une lettre de recommandation.

Contacts : Denis Maurel (Tours-Lifat), Nathalie Friburger et Nicolas
Labroche (Blois-Lifat), Matthieu Exbrayat (Orléans-Lifo):
denis.maurel@univ-tours.fr, nathalie.friburger@univ-tours.fr,
nicolas.labroche@univ-tours.fr, matthieu.exbrayat@univ-orleans.fr"
"595","2019-11-29","LIG","Grenoble","The LIG (Laboratoire d'Informatique de Grenoble) laboratory proposes the
following M2 stage (research)

Title:
Automatic Coreference Extraction

Description:
Coreference Resolution is one of the most challenging tasks in Natural
Language Processing (NLP) [Ng 2010], [Godbert and Benoit 2017], [Lee et
al. 2017].  Recent advances in neural model architectures allowed for
impressive improvements in this domain [Wiseman et al. 2016], [Lee et
al. 2017, 2018]. Traditionally however, coreference resolution tasks are
based on previously, manually annotated corpora [Pradhan et al. 2012],
[D esoyer et al. 2016]. Such resources are relatively rare, and very
expensive to obtain from scratch. Recent neural translation models
proved to be very e ffective in capturing long range contexts [Vaswani
et al. 2017], [Voita et al. 2018], [Maruf and Ha ari 2017], [Bawden et
al. 2017], [Zhang et al. 2018], [Miculicich et al. 2018]. In particular
[Voita et al. 2018] showed that document-level neural translation models
capture to some extent coreference (at least anaphora) phenomena. We
want to exploit this feature of neural translation models to
automatically extract coreference phenomena from text. The automatically
extracted annotations will be used for data augmentation for coreference
resolution neural models [Vaswani et al.  2017] in order to study their
impact on quantitative evaluations.

In this internship the student will use and modify existing systems
[Voita et al.  2018], [Lee et al. 2017] in order to automatically
extract coreference phenomena from textual data. The latter will be used
to augment existing data [Pradhan et al. 2012] for training a
coreference resolution neural model and study the impact of
automatically created data on its performance.

Profi le:

- Student for internship level (Master 2) in computer science, or from
  engineering school
- Computer science skills:
  * Python programming with good knowledge of deep learning libraries
    (Pytorch)
  * Data manipulation (textual data): loading di fferent formats, format
    transformation, storing in smart data structures, writing on disk in
    different format, etc.
- Interested in Natural Language Processing
- Skills in machine learning for probabilistic models

The internship may last from 4 up to 6 months, it will take place at LIG
laboratory, GETALP team (http://lig-getalp.imag.fr/), starting from
January/ February 2020. The student will be tutored by Marco Dinarelli
(http:// www.marcodinarelli.it), and Laurent Besacier
(https://cv.archives-ouvertes.  fr/laurent-besacier).

Interested candidates must send a CV and a motivation letter to
marco.dinarelli@univ-grenoble-alpes.fr, and
laurent.besacier@univ-grenoble-alpes.fr.

REFERENCES

Rachel Bawden, Rico Sennrich, Alexandra Birch, and Barry Haddow.
Evaluating discourse phenomena in neural machine translation. CoRR,
abs/1711.00513, 2017. URL http://arxiv.org/abs/1711.00513.

Ad ele D esoyer, Fr ed eric Landragin, Isabelle Tellier, Ana s Lefeuvre,
Jean-Yves Antoine, and Marco Dinarelli. Coreference resolution for
french oral data: Machine learning experiments with ancor. In
Proceedings of the 17th In- ternational Conference on Computational
Linguistics and Intelligent Text Processing, Konya, Turkey, April
2016. Lecture Notes in Computer Science (Springer).

Elisabeth Godbert and Favre Benoit. D etection de cor ef erences de bout
en bout en fran cais. In TALN 2017, Orl eans, France, June 2017. URL
https: //hal.archives-ouvertes.fr/hal-01687116.

Kenton Lee, Luheng He, Mike Lewis, and Luke Zettlemoyer. End-to-end
neural coreference resolution. In Proceedings of EMNLP. Association for
Computational Linguistics, 2017. URL
http://aclweb.org/anthology/D17-1018.

Kenton Lee, Luheng He, and Luke Zettlemoyer. Higher-order coreference
resolution with coarse-to- ne inference. CoRR, abs/1804.05392, 2018. URL
http://arxiv.org/abs/1804.05392.

Sameen Maruf and Gholamreza Ha ari. Document context neural machine
translation with memory networks. CoRR, abs/1711.03688, 2017. URL
http://arxiv.org/abs/1711.03688.

Lesly Miculicich, Dhananjay Ram, Nikolaos Pappas, and James Henderson.
Document-level neural machine translation with hierarchical attention
networks.  CoRR, abs/1809.01576, 2018. URL http://arxiv.org/abs/1809.
01576.

Vincent Ng. Supervised noun phrase coreference research: The rst fteen
years. In Proceedings of the 48th Annual Meeting of the Association for
Com- putational Linguistics, ACL '10, pages 1396{1411, Stroudsburg, PA,
USA, 2010. Association for Computational Linguistics. URL
http://dl.acm.org/ citation.cfm?id=1858681.1858823.


Sameer Pradhan, Alessandro Moschitti, Nianwen Xue, Olga Uryupina, and
Yuchen Zhang. Conll-2012 shared task: Modeling multilingual unrestricted
coreference in ontonotes. In Joint Conference on EMNLP and CoNLL -
Shared Task, CoNLL '12, pages 1{40, Stroudsburg, PA, USA,
2012. Association for Computational Linguistics. URL
http://dl.acm.org/citation.  cfm?id=2391181.2391183.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all
you need. In Proceedings of NIPS, 2017. URL https://arxiv.org/pdf/1706.
03762.pdf.

Elena Voita, Pavel Serdyukov, Rico Sennrich, and Ivan
Titov. Contextaware neural machine translation learns anaphora
resolution. CoRR, abs/1805.10163, 2018. URL
http://arxiv.org/abs/1805.10163.

Sam Wiseman, Alexander M. Rush, and Stuart M. Shieber. Learning global
features for coreference resolution. CoRR, abs/1604.03035, 2016. URL
http: //arxiv.org/abs/1604.03035.

Jiacheng Zhang, Huanbo Luan, Maosong Sun, FeiFei Zhai, Jingfang Xu, Min
Zhang, and Yang Liu. Improving the transformer translation model with
document-level context. CoRR, abs/1810.03581, 2018. URL http://arxiv.
org/abs/1810.03581."
"596","2019-12-09","LIMSI","Orsay","- Title: Research internship in NLP and ML: Text generation with
  disentangled semantic and syntactic representations
- Duration: 5-6 months, during the year 2020
- Location: LIMSI, Orsay (south of Paris)
- Supervisor: Caio Corro http://caio-corro.fr/
- Team: Spoken Language Processing / Traitement Automatique de la Parole
- Contact: caio.corro@limsi.fr

*Context*

This internship will focus on text generation with deep generative
models, in particular Variational Auto-Encoders (VAEs) [1,2]. The goal
is to study how we can build a generative model for text generation
where the semantic and syntactic representations are disentangled [3].
That is, we aim to generate a sentence through the following process:

- sample z: a latent variable encoding a meaning,
- sample z': a latent variable encoding a surface structure (i.e. how
  the meaning is expressed),
- sample x from p(x | z, z'): a sentence conditioned on its meaning
  and syntactic structure.

This kind of models could be used for sentence simplification,
paraphrasing or generating diverse text responses [4,5]. Previous work
in the literature has explored models where z' is encoded as a discrete
combinatorial structure [6,7]. However, these methods require annotation
of linguistic structures to be available during training and they may
not be suitable for large scale learning as they are computationally
expensive.

Therefore, we aim to focus on techniques closer to the ones developed in
computer vision where both the semantic and syntactic representations
are encoded in a fixed size continuous latent space and learned in a
fully unsupervised setting. To this end, the successful candidate will
explore generative losses for disentangled representation learning and
propose neural architectures specifically developed for text generation
in this setting.

*Missions*

- review the literature on learning disentangled latent space with VAEs;
- reproduce the experiments from [3,8] with a transformer architecture
  instead of recurrent networks;
- explore VAE losses for learning disantangled representations;
- propose transformer architectures that isolates structural information
  from semantic information (e.g. distance, see Section 3 in [9])


[1] ""Auto-Encoding Variational Bayes"" Diederik P Kingma and Max Welling.
[2] ""Stochastic backpropagation and approximate inference in deep
    generative models"" Danilo Jimenez Rezende et al.
[3] ""A Multi-Task Approach for Disentangling Syntax and Semantics in
    Sentence Representations"" Mingda Chen et al.
[4]  ""Generating Informative and Diverse Conversational Responses via
     Adversarial Information Maximization"" Yizhe Zhang et al.
[5] ""Jointly Measuring Diversity and Quality in Text Generation Models"" 
    Danial Alihosseini et al.
[6] ""StructVAE: Tree-structured Latent Variable Models for
    Semi-supervised Semantic Parsing"" Pengcheng Yin et al.
[7] ""Differentiable Perturb-and-Parse: Semi-Supervised Parsing with a
    Structured Variational Autoencoder"" Caio Corro and Ivan Titov
[8] ""Effective Estimation of Deep Generative Language Models"" Tom
    Pelsmaeker and Wilker Aziz
[9] ""Constituency Parsing with a Self-Attentive Encoder"" Nikita Kitaev
    and Dan Klein"
"597","2019-12-09","LIMSI","Orsay","- Title: Cross-lingual transfer with multi-lingual BERT via
  linguistically informed fine-tuning
- Duration: 5-6 months, during the year 2020
- Location: LIMSI, Orsay (south of Paris)
- Supervisor: Caio Corro - http://caio-corro.fr/
- Team: Spoken Language Processing / Traitement Automatique de la Parole
- Contact: caio.corro@limsi.fr

*Context*

Recently, much attention has been paid to large scale pre-training of
context-sensitive representations (or context-sensitive word
embeddings), in particular ELMO [1] and BERT [2] models. The main idea
is to pre-train the first layers of a neural network on a large amount
of unlabeled data before fine-tuning the rest of the network on a
downstream task. As such, context-sensitive representations allow to
lower annotation cost and improve classification performance on a wide
range of tasks.

The multilingual BERT model pre-trains context sensitive representations
on a collection of texts in 104 languages instead of texts in a single
language. One question that arises is whether we can use the
multilingual BERT model for cross-lingual learning, that is training a
model on a subset of these languages (source languages) and testing it
on a different subset (target languages). This problem is both important
under a research perspective (how can we learn multi-lingual
representations of typologically diverse languages?) and under an
applied industry perspective (i.e. increase language coverage of
NLP-based products at low cost). Previous work observed that
cross-lingual transfert based on multi-lingual BERT works best for
typological similar languages (i.e. languages with similar word order),
which is expected but disappointing [3].

This internship will focus on multilingual dependency parsing with the
Universal Dependency treebank https://universaldependencies.org/ .
Previous work has considered re-ordering source language sentences with
respect to word order in target languages [4]. However, re-ordering is
not possible for unsupervised large scale pre-training where syntactic
structures is not annotated. A different line of work proposed to force
word order statistics at test time using constraints [5], but this
method is based on a costly lagrangian optimization procedure and cannot
be applied on a per sentence basis. Alternatively, we propose to explore
fine-tuning methods for multi-lingual BERT model using a linguistically
informed training algorithm, i.e. to use dominant word order information
(is the object placed before or after the verb in a given language?) to
ensure unsupervised transfer to target languages.

*Missions*

The successful candidate will develop neural network architectures and
training algorithms for cross-lingual generalization of pre-trained
context-sensitive representations. The main evaluation task will be
cross-lingual dependency parsing. As there are many ways to tackle this
problem, the specific approach will be determined by the intern
aspiration, which could be for example posterior regularization or
latent variable modeling. In a nutshell, the aim is to:

- propose a method for cross-lingual generalization of multi-lingual
  BERT using typological information;
- evaluate the proposed method on cross-lingual parsing;
- evaluate if results generalize to other tasks, for example
  cross-lingual named entity recognition.

[1] ""Deep Contextualized Word Representations"" Matthew Peters et al.
[2] ""BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding"" Jacob Devlin et al.
[3] ""How multilingual is Multilingual BERT?"" Telmo Pires et al.
[4] ""Zero-resource Dependency Parsing: Boosting Delexicalized
    Cross-lingual Transfer with Linguistic Knowledge"" Lauriane Aufrant
    et al.
[5] ""Target Language-Aware Constrained Inference for Cross-lingual
    Dependency Parsing"" Tao Meng et al."
"598","2019-12-09","LIA","Avignon","Analyse de graphes signés pour détecter la corruption dans les marchés publics 

Encadrants

Rosa Figueiredo <rosa.figueiredo@univ-avignon.fr>
Vincent Labatut <vincent.labatut@univ-avignon.fr>

Lieu du stage

Laboratoire Informatique d'Avignon (LIA), Avignon, France

Descriptif du stage 

Contexte 

L'ouverture massive des données publiques recouvre une importance
particulière dans le cadre des marchés publics, et la récente réforme
de ces marchés introduit explicitement l'open data dans la commande
publique. Ce sont donc dès aujourd'hui une masse importante, et à
court terme l'intégralité des données relatives aux marchés publics
qui peuvent faire l'objet d'analyses qui jusqu'à présent se heurtaient
à l'inexistence ou à la partialité de jeux de données. Que ce soit par
les montants en jeu (la commande publique correspond à presque 15% du
PIB, 200 milliards d'euros par an pour les seuls marchés publics), ou
par les bénéfices économiques et sociétaux escomptés derrière cet
impératif de transparence, le traitement et l'analyse de ces données
constituent un enjeu tant académique que sociétal majeur.

Le travail motivant la présente offre de stage s'insère dans les deux
axes transversaux du LIA : Systèmes Complexes et Société Numérique. À
l'intersection de l'informatique, des sciences économiques et des
sciences juridiques, il fait partie de DéCoMaP (Détection de la
corruption dans les marchés publics) un projet à plus grande échelle
financé par l'ANR et visant à collecter, traiter et analyser les
données ouvertes relatives aux marchés publics français, afin
d'élaborer un outil basé sur les méthodes de graphes signés pour la
détection des risques de corruption qui peuvent exister entre
acheteurs publics et entreprises. La prise en compte de la nature
duale des liens unissant entreprises et donneurs d'ordres (relation
contractuelle normale ou corruption) est fondamentale à la bonne
modélisation du système étudié, et nécessite d'utiliser des réseaux
signés. Il s'agit d'un type de réseau bien moins exploré que les
réseaux non-signés classiques, et permettant d'inclure dans un même
modèle des relations antagonistes.

L'élaboration d'outils de détection automatique des risques de
corruption dans les marchés publics (""red flagging"") n'est en soit pas
totalement nouvelle, et se développe depuis quelques années déjà [1],
notamment à l'échelle européenne [2]. Outre qu'aucun outil n'a à ce
jour été adapté au cadre juridique et aux données des marchés publics
français, les méthodes appliquées présentent une limite
importante. Les approches existantes se focalisent sur des données
individuelles, caractérisant de façon indépendante clients et
fournisseurs, et ignorent les informations relationnelles,
correspondant aux interdépendances et interactions entre ces
différents acteurs. De ce fait, les outils produits passent à côté
d'un certain nombre de propriétés émergentes, i.e. présentes à une
granularité plus élevée que l'acteur isolé.


Travail demandé 

Le travail effectué avant ce stage a permis de collecter et structurer
l'ensemble des données issues des marchés publics français, telles que
proposées par le Bulletin Officiel des Annonces des Marchés Publics
(BOAMP) (annonces et avis d'attribution). Il s'agit maintenant
d'identifier les données a priori pertinentes, et de les enrichir à
partir à la fois de l'état de l'art académique (analyse juridique,
approche économique théorique et empirique) et de l'expertise d'un
Professeur en économie, Pierre-Henri Morand (LBNC - AU), qui porte le
projet DéCoMaP. En fonction du déroulement du projet, il est
envisageable de compléter la BD existante en exploitant d'autres
sources de données telles que TED (l'équivalent européen du BOAMP).

Le stagiaire utilisera les graphes signés afin de modéliser,
visualiser et analyser les réseaux complexes formés par les
entreprises (fournisseurs) et les collectivités (donneurs
d'ordres). Il s'agit de graphes dont les liens sont caractérisés par
un signe, pouvant être positif ou négatif, afin de représenter des
relations antagonistes. Ces graphes seront construits à partir des
données obtenues à la première étape. Comme illustré dans la Figure
ci-dessous, plusieurs méthodes sont possibles pour effectuer cette
opération, que le stagiaire devra mettre en oeuvre et comparer.

Une fois les graphes obtenus, ils seront principalement utilisés pour
deux tâches. La première est leur analyse via des outils descriptifs
classiques dans le champ des réseaux complexes (taille, densité,
transitivité, centralités diverses...). La seconde vise à résoudre des
problèmes de partitionnement définis sur les graphes signés en
utilisant les méthodes de résolution existantes plus adaptées [3,4]
aux réseaux obtenus. Avec les solutions obtenues émergeront des
groupes d'acteurs (acheteurs publics et entreprises fournisseurs)
susceptibles d'être liés entre eux par des pratiques délictueuses.



Perspectives

Sous réserve qu'à la fois le stagiaire et les encadrants soient
satisfaits du déroulement du stage, celui-ci est susceptible de
déboucher sur un doctorat prévu dans le cadre du projet ANR DéCoMaP
déjà mentionné. Ce doctorat sera co-encadré par Rosa Figueiredo et
Vincent Labatut (LIA - AU), comme le stage, et en plus par Christine
Largeron (Laboratoire Hubert Curien - Université Jean Monnet).



Références

[1] Fazekas, Mihály, et István János Tóth. New ways to measure institutionalised grand corruption in public procurement, U4 Brief, n°9 (2014).

[2] Ferwerda, Joras, et Ioana Deleanu. Identifying and Reducing Corruption in Public Procurement in the EU. European Commission, OLAF, 2013.

[3] Figueiredo, Rosa et Yuri Frota. The maximum balanced subgraph of a signed graph: Applications and solution approaches. European Journal of Operational Research, 236(2) : 473-487, 2014.

[4] Labatut, Vincent. Generalized Measures for the Evaluation of Community Detection Methods, International Journal of Social Network Mining, n°2(2015):44-63.
Thématique(s) associée(s) au stage / Keywords 	Analyse de graphes signés / Signed graphs analysis"
"599","2019-12-09","Fortia Financial Solutions","Paris","""*Fortia Financial Solutions* est une RegTech créée en 2012, basée à
Paris.

Les RegTech proposent aux acteurs financiers des solutions
technologiques destinées à gérer leurs activités « Compliance » ou
conformité, c'est-à-dire le respect des dispositions législatives et
réglementaires ainsi que des normes internes et statutaires.

*Fortia Financial Solutions* a développé la plate-forme logicielle
*INNOVA*, solution innovante reposant sur le Machine-Learning (ML) et
l'Intelligence Artificielle (IA), dédiée aux métiers de la Finance. Elle
permet l'automatisation des processus et des contrôles de conformité.

*DATA AVANGARDE*, solution de Master Data Management alimentée par l'IA,
visant à automatiser et à sécuriser l'ensemble de la chaîne de
production des données et de gestion des référentiels, vient compléter
cette offre d'automatisation des process réglementaires.

Rejoindre Fortia Financial Solutions, c'est rejoindre une équipe
dynamique et passionnée.

*DESCRIPTION DU POSTE*
En collaboration avec l'équipe Produit et l'équipe Data Science, vous
serez en charge de l'*évaluation d'algorithmes existants* dans le cadre
de travaux de recherche informatique.

L'objectif de ce stage est de *mettre en place un protocole
d'évaluation* de qualité pour les différents algorithmes de l'IA
utilisés dans nos solutions et de mener cette évaluation d'un point de
vue qualitatif.

Dans le cadre d'un stage d'une durée de 4 à 6 mois, votre mission
consistera à :

- Comprendre l'impact de sorties des algorithmes sur les produits finaux
- Analyser le besoin et le type d'évaluation nécessaire pour différents
  algorithmes existants dans le but de mesurer ses performances qualitatives
- Définir le périmètre et le(s) protocoles(s) de l'évaluation
- Effectuer l'évaluation
- Proposer une synthèse qualitative sur les résultats de l'évaluation

*PROFIL RECHERCHE*

- Formation supérieure (Licence minimum) avec *spécialisation en
  Traitement Automatique des Langues indispensable (TAL)*
  
- Maîtrise de l'*anglais** et du français indispensable*

- Vous êtes rigoureux et vous avez une capacité d'analyse et de
  synthèse, ce stage est fait pour vous!""


*Sabrina JEAN-BOLO *Chargée de Recrutement et RH
17 avenue George V, 75008 Paris
+33(0)6 49 28 67 68 / +33 (0)1 49 53 95 90
sabrina.jeanbolo@fortia.fr  |  www.fortia.fr
https://www.fortia.fr"
"600","2019-12-09","LIFAT","Blois","Weakly supervised multilingual identification of verbal multiword
expressions


Domain: Natural Language Processing

Keywords: natural language processing, multi-word expressions,
multilingualism, supervised machine learning

Location: University of Tours, LIFAT (Laboratoire d'Informatique
Fondamentale et Appliquée de Tours), Blois campus, France

Supervisors: Agata Savary, Caroline Pasquer, Jean-Yves Antoine

Duration: 6 months

Remuneration: around 577 EUR / month (minimum)

Funding: ANR PARSEME-FR project

Motivation and context

The aim of this internship is to boost applications in Natural
Language Processing (NLP), by focusing on one of their major
challenges: multiword expressions (MWEs). MWEs are groups of words
which exhibit unpredicted properties (Baldwin & Kim, 2010). Most
prominently, their meaning does not straightforwardly derive from the
meanings of their components. For instance, faire `make/do' and valoir
`be worth sth' are verbs, while their combination yields a noun:
faire-valoir `a stooge, a person who is used by somebody to do things
that are unpleasant or dishonest'. Similarly, the meaning of casser sa
pipe `to die' (literally to break one's pipe) cannot be
straightforwardly deduced from the meanings of the individual
components. Additionally, MWEs exhibit unpredicted morpho-syntactic
and lexical constraints. For instance, replacing the verb in lancer un
appel `to issue a call' (lit. to throw a call) by a synonym yields an
invalid expression *jeter un appel `to throw a call'. Doing alike in
casser sa pipe `to die' imposes a literal reading of the resulting
expression: briser sa pipe `to break one's pipe'.

One of the main aims of MWE-oriented NLP research is to model such
expressions so as to optimize their automatic processing (for
instance, to avoid their literal translation in machine translation
systems). Two major MWE-related NLP tasks include MWE identification
and MWE discovery. In the former, an identifier takes a text on input
and automatically annotates (points at) the occurrences of MWEs in
context. In the latter, the input consists in large quantities of raw
texts and the output is a list of potential MWEs given out of
context. MWE identification is usually done in a supervised manner,
i.e. by training a system on a manually annotated corpus. MWE
discovery, conversely, is usually unsupervised, i.e. can be applied to
very large quantities of raw data. MWE identification is a
pre-requisite for downstream applications such as machine translation
(which may want to treat MWEs with dedicated procedures).

Automatic identification of verbal MWEs in 19 languages was addressed
by the PARSEME shared task edition 1.1 (Ramisch et al., 2018), in
which the BdTln team participated with the VarIDE system (Pasquer et
al., 2018a). The results of the shared task show that identifying
unseen MWEs (i.e. those MWEs which do not occur in the training data)
is particularly challenging (Savary et al. 2019). Thus, identification
should, ideally, exploit not only annotated corpora but also MWE
lexicons and MWE discovery methods.

The aim of this internship is, thus, to study the potential of
coupling MWE identification with their discovery, so as to better cope
with unseen data and increase the global identification
performances. The general idea is to use the MWE candidates extracted
by a discovery tool, and their occurrence contexts, as seen data (as
if they have been manually annotated) but with a lower reliability
score. This is to be done in a highly multilingual context, where
manually annotated data for at least 19 language are openly available.

We believe that the context of this internship is particularly
stimulating. It includes the European research network PARSEME
(Parsing and Multiword Expressions) and its French spin-off ANR
project PARSEME-FR. These communities have developed cross-lingually
unified and validated corpora manually annotated for verbal MWEs (like
casser sa pipe or lancer un appel), which undelay the PARSEME shared
task 1.1 mentioned before. In 2020, edition 1.2 of this shared task is
planned. It will be dedicated to weakly supervised identification of
verbal MWEs. The outcome of this interniship (i.e. a VMWE
identification and discovery tool) will potentially be proposed to
compete in this shared task, side-by-side with many other systems
developed worldwide. The student working in this internship will,
thus, regularly participate in on-site or on-line meetings not only
with her/his supervisors but also with other external members of the
aforementioned initiatives.

Expected outcomes

The expected outcomes of this internship include:

- an overview of the state-of-the-art in MWE identification and
  discovery, and especially on coupling these two functionalities

- a system which couples, MWE identification and discovery, so as to
  address the major challenge in MWE identification stemming from
  unseen data

- running the system on the data of the PARSEME shared task 1.2 early
  2020

- submitting the results to the shared task platform

- submitting a system description paper to the MWE-LEX 2020 workshop

- presenting the system at the MWE-LEX 2020 workshop, co-located with
  the COLING 2020 conference in Barcelona in September 2020

Expected follow-up

    A 3-4-year PhD grant, related to the same line of research, might
    be available in the research team starting from September 2020

Candidate's profile


- 2nd-year master student in computational linguistics, computer
  science or alike

- Interests in linguistics and familiarity with language technology

- Good knowledge of French

- Good programming skills, preferably in Python

Important dates

    Application deadline: 16 December 2019 (or until filled)
    Notification: 20 December 2019
    Position starts: mid-January 2020
    Position ends: around mid-July 2020

How to apply

Send your CV and a cover letter to Agata Savary, Caroline Pasquer and
Jean-Yves Antoine (first.last@univ-tours.fr).


References

Baldwin, T. and Kim, S. N. (2010) Multiword Expressions, in Nitin
Indurkhya and Fred J. Damerau (eds.) Handbook of Natural Language
Processing, Second Edition, CRC Press, Boca Raton, USA, pp. 267-292.

Matthieu Constant, Gülsen Eryigit, Johanna Monti, Lonneke van der
Plas, Carlos Ramisch, Michael Rosner, and Amalia
Todirascu. 2017. Multiword expression processing: A
survey. Computational Linguistics, 43(4):837-892.

Caroline Pasquer, Carlos Ramisch, Agata Savary, Jean-Yves Antoine
(2018) VarIDE at PARSEME Shared Task 2018: Are variants really as
alike as two peas in a pod?, in the Proceedings of the Joint Workshop
on Linguistic Annotation, Multiword Expressions and Constructions
(LAW-MWE-CxG-2018), 25-26 August 2018, Santa Fe, USA.

Carlos Ramisch, Silvio Ricardo Cordeiro, Agata Savary, Veronika
Vincze, Verginica Barbu Mititelu, Archna Bhatia, Maja Buljan, Marie
Candito, Polona Gantar, Voula Giouli, Tunga Güngör, Abdelati Hawwari,
Uxoa Iñurrieta, Jolanta Kovalevskaite, Simon Krek, Timm Lichte, Chaya
Liebeskind, Johanna Monti, Carla Parra Escartín, Behrang QasemiZadeh,
Renata Ramisch, Nathan Schneider, Ivelina Stoyanova, Ashwini Vaidya,
Abigail Walsh (2018) Edition 1.1 of the PARSEME Shared Task on
Automatic Identification of Verbal Multiword Expressions, In the
Proceedings of the Joint Workshop on Linguistic Annotation, Multiword
Expressions and Constructions (LAW-MWE-CxG-2018), 25-26 August 2018,
Santa Fe, USA.

Agata Savary, Silvio Ricardo Cordeiro, Carlos Ramisch (2019) Without
lexicons, multiword expression identification will never fly: A
position statement, In the Proceedings of the Joint Workshop on
Multiword Expressions and WordNet (MWE-WN 2019), 2 August 2019,
Florence, Italy."
"601","2019-12-09","Ludo-Vic","Paris","*6 mois de stage (Informatique - IHM - IA)*

Le but de ce stage est de contribuer dans le projet ""Basic-Français : un
outil d'intégration et d'accès à l'emploi sur le territoire ITI"" qui a
pour but de renforcer les compétences des populations de migrants de
première, deuxième ou troisième génération, en les aidant à acquérir les
bases du français, en se basant dans un premier temps sur le niveau A1
requis par l'Office Français de l'Immigration et de l'Intégration, et
qui correspond au niveau minimal nécessaire à une intégration réussie
dans le monde du travail.

L'application « Basic-Français » propose le développement d'un nouvel outil
qui se distingue selon plusieurs aspects :

- C'est un outil destiné à être disponible et en classe et pour un usage
  individuel, afin de renforcer la capacité de répétition des exercices
  en dehors des cours, pour renforcer l'apprentissage.
- C'est un outil qui s'adresse à l'apprenant dans sa langue maternelle,
  et à l'oral, levant ainsi la barrière de l'écrit et de la langue
  nationale.  Les consignes d'utilisation de l'outil sont donc traduites
  et énoncées dans la langue maternelle idoine.
- L'apprentissage est basé en grande partie sur des animations qui
  contextualisent les éléments de langage. Non seulement les apprenants
  enregistrent des éléments de français, mais ils reçoivent également
  des informations d'ordre comportemental : comment agit un citoyen
  français.

*Missions principales*

Deux avatars Ludo - le personnage masculin - et Vic - le personnage
féminin -, choisis pour ne pas stigmatiser les populations visées, et
pour promouvoir l'égalité des sexes, sont mis à votre disposition pour
les mettre en scène et faire des animations qui illustrent les bases de
français.  Vous avez en plus à votre disponibilité :
- Un système de reconnaisssance automatique de parole
- Un système de reconnaisssance automatique d'émotions

Les 2 humanoides sont donc en interaction avec l'apprennant.

*Conditions du stage *

Le stage se déroulera sur une période de 6 mois dans le département R&D
du Ludo-Vic SAS. Des outils de travail à distance sont disponibles au
sein de l'entreprise.

*Profil recherché *
- Bac +4/5 dans le domaine de l'informatique et de l'IA.
- Capacité à scénariser des interactions et réaliser des animations 3D.
- Expérience avec Unity3D et compétence en langage C# sont un vrai plus.

*Rémunération* : conditions standard de rémunération de stage.

*Contacts et candidature *
Merci d'envoyer votre CV, vos relevés de notes, vos rapports de
projets/stages... à :
- Jack Amberg : jack@ludo-vic.com
- Atef Ben-Youssef : atef@ludo-vic.com"
"602","2019-12-13","Tetis","Montpellier","Stage Master 2 Pro ou école ingénieur

Acquisition et analyse de transcriptions de vidéos Youtube - la problématique de la sécurité alimentaire en Afrique de l'Ouest

Le stage, financé par l'Institut Convergences Agriculture Numérique
#DigitAg (https://www.hdigitag.fr), s'inscrit dans le cadre d'un
projet interdisciplinaire concernant la gestion des risques liés à la
sécurité alimentaire. Le projet est centré sur le cas de l'Afrique de
l'Ouest, où les risques agricoles sont d'autant plus aigus que les
services nationaux de surveillance et de suivi peuvent être
défaillants faute de moyens techniques et financiers. Les objectifs
globaux du projet sont doubles :

(i) montrer comment les données de télédétection peuvent être
enrichies par d'autres sources de données afin de les rendre plus
adaptées à l'analyse de conditions de sécurité alimentaire et (ii)
définir des techniques originales de fouille de données. L'analyse et
l'interprétation de données agroclimatiques (par exemple, imagerie
satellitaire, données climatiques) pourrait être facilitée par
l'utilisation conjointes de données indépendantes provenant de sources
textuelles, ce qui permettrait de localiser correctement les risques
agricoles à l'échelle régionale, en temps quasi-réel. Néanmoins,
l'obtention de données textuelles de qualité et leur analyse sont des
tâches complexes.

Le stage est axé sur l'acquisition et l'analyse de données textuelles
sur le thème de la sécurité alimentaire provenant de la transcription
textuelle du contenu audio de vidéos Youtube. La zone géographique
d'étude est le Burkina Faso. L'idée est de traiter une source
d'information représentant une alternative inexplorée à celles qui
sont exploitées classiquement dans les processus de construction des
corpus textuels et dans des tâches de fouille de texte (par exemple,
journaux, articles scientifiques, plateformes de médias sociaux
classiques). Le chaîne Youtube gérée par la RTB - Radiodiffusion
Télévision du Burkina, qui contient près de 12000 vidéos, a été ciblée
pour cette analyse. En choisissant un canal officiel, nous visons un
compromis idéal entre les aspects dynamiques du contenu des médias
sociaux et la qualité de l'information des sources
officielles. L'hypothèse est que les vidéos diffusées par une chaîne
d'information officielle sont plus susceptibles de contenir de
l'information utile (c.-à-d. reportages, documentaires, entrevues,
tournages d'événements officiels, etc.). De plus, le langage standard
et clair utilisé dans ce type de vidéos garantit une bonne qualité des
transcriptions textuelles. Les processus d'acquisition et analyse des
données seront basés sur l'utilisation d'API Web et de bibliothèques
python.

Les objectifs de ce stage comprennent la production d'un corpus public
et d'une série de tâches d'analyse basées sur l'utilisation de
techniques de fouille de texte les plus avancées (e.g., LDA,
word2vec). Le livrable consistera en un document de recherche
présentant les résultats du processus d'analyse, et notamment les
connaissances sur la sécurité alimentaire qui peuvent être découvertes
dans une telle source d'information.  Le planning prévisionnel est
structuré comme suit :

1. étude du cahier des charges du corpus à constituer,
2. définition et mise en oeuvre du processus de récolte des données
3. constitution du corpus sur la zone d'étude,
4. analyse du corpus,
5. rédaction des livrables.

Compétences requises :

Langage Python, outils NLP (souhaité)
Capacité de travail en équipe pluridisciplinaire.

Divers :

Durée : 5 à 6 mois

Gratification : taux légal en vigueur

Localisations : TETIS (Maison de la Télédétection) à Montpellier

Candidature :

Envoyer un CV + relevés de notes des deux dernières années à
roberto.interdonato@cirad.fr et mathieu.roche@cirad.fr"
"603","2019-12-13","Sorbonne Université","Paris","*Offre de stage | Sorbonne Université : Imprimés de la première 
modernité/Corpus/OCR*


L'équipe Antonomaz (ANalyse auTOmatique et NumérisatiOn des MAZarinades)
de Sorbonne Université (Labex OBVIL et EA4509 STIH) propose, dans le
cadre d'un projet financé par le DIM STCN et l'initiative CORLI, un
stage de 3 à 5 mois à temps plein. Les missions de ce stage
contribueront principalement à améliorer la reconnaissance automatique
de caractères (OCR) des imprimés anciens (en particulier du
XVIIe siècle). Le stagiaire bénéficiera d'un encadrement combinant
chercheurs en informatique et en humanités numériques de manière à
assurer sa progression quant aux compétences requises sur les
technologies exploitées.

*Missions*
Construire une méthodologie d'évaluation de sorties d'OCR sur des
documents anciens [2] [3]. Les documents nécessitant ce passage de
l'image au texte sont une sélection d'un corpus de « mazarinades »
(imprimés français datant de la Fronde, XVIIe siècle) [4]. L'étudiant.e
sera amené.e à manipuler des outils d'OCR (Tesseract [5], Calamari [6]
et Kraken [7] en premier lieu) et à étudier leur qualité selon, par
exemple :
- les prétraitements des images ;
- les corpus d'apprentissage offerts aux outils ;
- la réalisation ou non d'un apprentissage des outils sur les données de
  l'étude ;
- l'apprentissage d'un modèle de reconnaissance from scratch ou 
  l'affinement d'un modèle déjà appris.

L'étudiant.e pourra ensuite mener une étude exploratoire de ce corpus
océrisé en utilisant des outils de TAL ou des algorithmes de
classification (SVM ou arbres de décision par exemple).

On proposera des tests sur d'autres corpus imprimés de la première 
modernité (XVIe-XVIIIe siècles), ainsi que sur des données 
d'apprentissage augmentées (ajout de flou, de tâches, etc.)
Plusieurs tâches de post-traitements seront proposées 
(normalisation-modernisation, lemmatisation, etc.).

La réalisation concrète attendue du ou de la stagiaire sera double : la
description d'un protocole de recherche appliquée (à partir d'un premier
corpus exploratoire à océriser) et la transformation de ce premier
corpus en un ensemble normalisé et lemmatisé.

*Profil et compétences requises*
- Connaissances en TAL et appétence pour le livre ancien
- Connaissances basiques en HTML/XML et en langage de programmation
  Python
- Anglais (maîtrise de la littérature critique sur le sujet) et 
  éventuellement allemand.

*À acquérir*
- Prise de connaissances de travaux universitaires contemporains en OCR
  de documents historiques (en français/anglais/allemand)
- Mise à niveau en OCR (Optical Character Recognition) [1]
- Informatique et programmation Python :
- Packaging des programmes et versionning avec git
- Outils de Traitement Automatiques des Langues (T.A.L.) : TXM, gate,
  Spacy
- Machine Learning : sklearn (librairie Python)

*Conditions de recrutement*
- Structure de recrutement : Sorbonne Université
- Gratification : en vigueur + remboursement de 50 % des frais de
  transports
- Matériel : matériel informatique fourni par l'équipe
- Durée du stage : 4 à 6 mois (selon profil), 35h/semaine
- Prise de fonction : Possible à partir d'avril 2020
- Localisation : Maison de la Recherche, Serpente (Quartier Saint 
  Michel, 75005 Paris)
- Stage au sein d'une équipe-projet de 4 personnes

*Date limite de candidature : 29 février 2020*

Modalités de candidature : Envoyer CV et lettre de motivation à
karine.abiven@sorbonne-universite.fr et
gael.lejeune@sorbonne-universite.fr

*Références*
[1] Lefèvre, P. (1999). Reconnaissance de l'imprimé. Techniques de
l'Ingénieur :
https://www.techniques-ingenieur.fr/base-documentaire/archives-th12/archives-documents-numeriques-gestion-de-contenu-tiahc/archive-1/reconnaissance-de-l-imprime-h1348/.
[2] Wick, C., Reul, C., & Puppe, F. (2018). Comparison of OCR Accuracy
on Early Printed Books using the Open Source Engines Calamari and
OCRopus. JLCL, 33(1), 79-96.
[3] Springmann, U., Fink, F., & Schulz, K. U. (2016). Automatic quality
evaluation and (semi-) automatic improvement of OCR models for
historical printings. arXiv preprint arXiv:1606.05157.
[4] Carrier, H., La Presse de la Fronde (1648-1653) : les mazarinades.
Genève, Droz, 1989-1991.
[5] Smith, R. (2007, September). An overview of the Tesseract OCR
engine. In Ninth International Conference on Document Analysis and
Recognition (ICDAR 2007) (Vol. 2, pp. 629-633). IEEE.
[6] Wick, C., Reul, C., & Puppe, F. (2018). Calamari-A High-Performance
Tensorflow-based Deep Learning Package for Optical Character
Recognition. arXiv preprint arXiv:1807.02004.
[7] https://editiones.hypotheses.org/1958"
"604","2019-12-13","Lattice","Montrouge","*** Annotation de corpus en entités nommées avec apprentissage actif ***

Lieu du stage : laboratoire LATTICE, Montrouge

Encadrants : Frédérique Mélanie, Thierry Poibeau (LATTICE) 

* Motivation et descriptif

On dispose aujourd'hui d'outils de traitement des langues opérationnels
et efficaces, en partie grâce à l'apprentissage automatique. On
s'aperçoit malgré tout souvent que ces outils restent peu robustes face
à la diversité des corpus. Par exemple, les outils de reconnaissance des
entités nommées sont souvent mis au point et évalués sur des corpus
comme le journal Le Monde, mais les performances observées sur des
corpus différents sont souvent très faibles, même quand il s'agit de
texte édités et supposés écrits dans un ""français correct"". Dans ce
contexte, les performances rapportées sur les jeux de test classiques
sont très peu informatives et on se heurte dès lors à des problèmes bien
connus, notamment le coût souvent prohibitif pour obtenir un corpus
annoté représentatif.

Des techniques comme l'apprentissage actif peuvent aider à contourner
partiellement cette difficulté, en offrant des moyens d'annotation
rapides et efficaces. Des interfaces graphiques évoluées permettant en
outre d'améliorer de manière notable la vitesse et l'efficacité de
l'annotation en vue d'obtenir un modèle performants pour une tâche
donnée.

Le stage portera donc sur l'annotation des entités nommées
(essentiellement noms de personnes et noms de lieux) au sein de romans
du 19e ou 20e siècle, avec une visée applicative (obtention d'un corpus
annoté), et plus expérimentale (test de l'efficacité de
l'annotation). L'application visée est une exploration du ""Paris des
écrivains"" : comment les écrivains parlent-ils de Paris ? Quels
quartiers sont mis en avant ? Quel imaginaire autour de Paris ?

* Public visé

Ce stage s'adresse à un(e) étudiant(e) de niveau M2, de formation TAL ou
Humanités numériques.

* Conditions du stage

Stage de 4 à 6 mois, à partir du printemps 2020, indemnisé suivant les
conditions en vigueur.
Convention de stage obligatoire. 

* Comment candidater ? 

Envoyer un mail avec quelques mots sur votre intérêt pour ce stage dans
le corps du mail, et en pièces attachées un CV et un relevé de notes
récent.

Adresser le mail à Thierry Poibeau (thierry.poibeau@ens.fr)"
"605","2019-12-13","Lattice","Montrouge","*** Génération automatique de poésie inspirée de poèmes existants ***

Collaboration entre les laboratoires LATTICE (Paris, Montrouge) et IRIT
(Toulouse)

Lieu du stage : laboratoire LATTICE, Montrouge

Encadrants : Thierry Poibeau, Clément Plancq (LATTICE) ; Tim Van de
Cruys (IRIT)

* Motivation et descriptif

La génération automatique de poésie est une tâche ardue pour un système
informatique.  Pour qu'un poème ait du sens, il est important de prendre
en compte à la fois des aspects linguistiques et littéraires. Tout
d'abord, un système de génération de poésie doit modéliser de manière
correcte la syntaxe, et la cohérence sémantique et discursive.  De plus,
le système doit intégrer diverses contraintes (telles que la forme et la
rime) liées à un genre poétique particulier. Enfin, le système doit
faire preuve d'une certaine créativité littéraire, ce qui rend le poème
intéressant et digne d'être lu.

Ce stage s'inscrit dans le contexte du projet Oucopo [1], qui vise à
explorer les liens entre textes et numérique avec, au-delà des aspects
purement techniques et scientifiques, la prise en compte d'aspects
esthétiques. Le projet s'inspire en premier lieu de l'ouvrage de Raymond
Queneau ""Cent mille milliards de poèmes"", paru en 1961, qui permet de
combiner des vers pour composer des poèmes respectant la forme du
sonnet. Dans ce contexte, ce stage vise à étendre l'idée de
recombinaison, en explorant l'interaction entre des poèmes écrits par
des humains, et les poèmes générés de manière automatique. Plus
spécifiquement, on utilisera des poèmes existants comme source
d'inspiration pour un système de génération de poésie automatique. A
partir d'un poème existant, un système de génération pourrait par
exemple :

- induire une représentation à base d'une partie des vers d'un poème
  existant, et générer des vers pour compléter le poème ; la génération
  des vers est censée suivre les contraintes du poème existant
  (notamment par rapport au rythme et à la rime) ;

- générer un nouveau poème similaire au poème existant, mais en
  changeant le schéma de rime ;

- générer un nouveau poème à base des thèmes évoqués dans le poème
  existant.

Cette liste n'est pas exhaustive; il existe évidemment de nombreuses
manières de générer des poèmes sur la base de ceux existants.

De manière pratique, ce stage s'appuiera sur une système de génération
de poésie existant, appelé Charles, et développé à l'IRIT à Toulouse
[2,3]. Ce système de génération utilise un modèle de réseaux de neurones
récurrents dans une configuration encodeur-décodeur. L'encodeur
construit d'abord une représentation d'une phrase entière en incorporant
séquentiellement les mots de cette phrase dans un vecteur d'état caché
de taille fixe. La représentation finale est ensuite donnée au décodeur,
qui émet une séquence de mots selon une distribution de probabilité
dérivée de l'état caché de la phrase en entrée. En apprenant au réseau à
prédire la phrase suivante avec la phrase actuelle en entrée, le réseau
apprend à générer du texte brut avec une certain cohérence
discursive. En transformant la distribution de probabilité fournie par
le décodeur, afin d'incorporer des contraintes poétiques, le réseau peut
être exploité pour la génération de vers poétiques. Pendant ce stage, le
système de génération serait adapté et étendu afin de mettre en oeuvre
les objectifs décrits ci-dessus.

* Public visé

Ce stage s'adresse à un(e) étudiant(e) de niveau M2 ou 3ème année
d'école d'ingénieurs, ayant de bonnes connaissances de programmation en
Python. La connaissance de bibliothèques pour l'implémentation de
réseaux de neurones (et plus spécifiquement Pytorch) est un atout.

* Conditions du stage

Stage de 4 à 6 mois, à partir du printemps 2020
indemnisé suivant les conditions en vigueur
Convention de stage obligatoire

* Comment candidater ? 

Envoyer un mail avec quelques mots sur votre intérêt pour ce stage dans
le corps du mail, et en pièces attachées un CV et un relevé de notes
récent.

Adresser le mail à Thierry Poibeau (thierry.poibeau@ens.fr)

* Références


[1] http://www.transfers.ens.fr/l-oupoco-l-ouvroir-de-poesie-combinatoire
[2] https://github.com/timvdc/poetry
[3] Tim Van de Cruys. La génération automatique de poésie en
    français. Proceedings of TALN 2019, pages 113-126, Toulouse, France."
"606","2019-12-16","INRA","Clermont-Ferrand","Titre: Fouille de texte pour extraction de terminologies agricoles

Contact : Catherine Roussey, Irstea Centre de Clermont-Ferrand (catherine.roussey@irstea.fr)

Co-encadrement par Robert Bossy, INRA, Jouy-en-Josas

Localisation : Irstea, Centre de Clermont-Ferrand, Aubière

Type : Stage de Master 2

Profil : Étudiants de master 2 en informatique ou bioinformatique, data science

Période: courant 2020

Date de début de stage mars 2020

Durée: 2 à 5 mois
Contexte du stage

Dans le cadre de l'ANR D2KAB

Les ressources sémantiques (e.g., thesaurus, terminologies,
vocabulaires et ontologies) sont des éléments clés pour assurer
l'interopérabilité des données. Dans certains domaines de recherche en
agriculture, les scientifiques développent déjà des ressources
sémantiques pour faciliter l'intégration de leurs données avec
d'autres et permettre l'extraction de connaissances e.g., Crop
Ontology ou FrenchCropUsage thesaurus. Cependant, bien souvent les
personnes concernées ne sont pas nécessairement des scientifiques, qui
ont l'opportunité de s'intéresser au monde du web sémantique, mais des
acteurs du monde agricole, qui produisent ou utilisent des
référentiels simples et souvent spécifiques à une filière. Par
exemples, le référentiel des stades phénologiques de la vigne ou la
liste des variétés en vigne produit par l'IFV (Institut Français de la
Vigne et du Vin) ou le référentiel de produits phytosanitaires produit
par l'ACTA. Récemment, une première étape a été franchie avec la mise
à disposition de certains de ces référentiels sur la plateforme de
partage de données agricoles, API-AGRO
(https://plateforme.api-agro.fr). Mais pour aller plus loin dans le
partage et la réutilisation de ces référentiels, il est nécessaire
d'adopter les principes FAIR (Findable, Accessible, Interoperable and
Reusable).

Le projet ANR D2KAB (www.d2kab.org), démarré en 2019, regroupe un
consortium multidisciplinaire unique de 7 organisations dont 4 dans
DigitAg (UM, INRA, IRSTEA, ACTA + et un partenariat avec API-AGRO)
dont l'objectif principal est de mettre en place les processus
permettant de transformer les données d'agricole en connaissances -
sémantiquement riches, interopérables, ouvertes - ainsi que les
méthodes scientifiques et les outils pour exploiter et diffuser ces
connaissances dans des applications scientifiques et agricoles. Le
projet est guidé par plusieurs scénarios dont un navigateur de
recherche améliorée des bulletins d'alerte agricole intitulés Bulletin
de Santé du Végétal [BSV]. D2KAB développe et maintient AgroPortal
(http://agroportal.lirmm.fr), un portail de ressources sémantiques
pour l'agronomie et l'agriculture.

L'ANR D2KAB propose plusieurs offres de CDD ingénieur dont un qui sera
la suite de ce stage.

Objectif du stage

L'objectif de ce stage est d'améliorer la couverture terminologique des référentiels agricoles existants en les enrichissant grâce à l'extraction de termes spécifiques  à partir du corpus des bulletins d'alertes (BSV). Plus précisément :

- Mise en place d'un workflow de text mining à partir du système Alvis
de TALN [Alvis] proposé par l'équipe de Bibliome de l'INRA

- Mise en place d'un protocole de validation des termes à l'aide de
l'outil TyDI [TyDI] . Les termes devront être validé par un réseau
d'experts par type de culture (vigne, céréale, légume)

- Publication de la nouvelle version des référentiels sur l'Agroportal.

Profil du candidat


- Niveau Master 2 en mathématique, informatique ou bioinformatique, data
science

- Expérience avec des outils d'apprentissage automatique et motivation
pour apprendre de nouvelles technologies.

- Une expérience des technologies du Web sémantique sera appréciée mais
n'est pas obligatoire.

- Bonnes compétences en anglais à l'oral et à l'écriture. Une bonne
connaissance du français ou une motivation pour apprendre est
souhaitable.

- Excellentes compétences en rédaction scientifique, car il sera
nécessaire de produire des rapports, de la documentation technique et
des compte rendu de réunion.

- Excellente compétence en gestion de projet et planification, car il
sera nécessaire de faire des points réguliers avec différentes équipes
du projet D2KAB

- Autonomie et initiative, être capable de proposer de nouvelles
techniques au sein du projet et de justifier de ses choix.

- Personne dynamique pour rejoindre une petite équipe de recherche à
Clermont-Ferrand.

Candidature

Répondre à l'annonce sur le site de l'INRA (un CV et une lettre de
motivation)

http://jobs.inra.fr/offers/detail/285917

Pour toute demande d'information contacter catherine.roussey@irstea.fr

Date limite de candidature mai 2020.

Rémunération

Prime de stage de master 2 (environs 580 ¤ par mois)

Références

[Alvis] Nédellec C, Nazarenko A, Bossy R: Information
Extraction. Ontology Handbook. Edited by: Staab S, Studer R. 2008,
Springer Verlag, 663-686. URL: github.com/Bibliome/alvisnlp

[BSV] C. ROUSSEY, T. ABDERRAHMANI GHORFI. Annotation sémantique pour
une interrogation experte des Bulletins de Santé du Végétal. Dans les
Actes des 29e Journées Francophones d'Ingénierie des Connaissances IC
2018, adossée à la 11e Plate-forme Francophone d'Intelligence
Artificielle, 2-6 juillet 2018, Nancy, p 37-52

Plus d'information sur http://ontology.irstea.fr/pmwiki.php/Site/BSV

[TyDI] Nédellec C., Golik W., Aubin S., Bossy R. (2010) Building Large
Lexicalized Ontologies from Text: A Use Case in Automatic Indexing of
Biotechnology Patents. In: Cimiano P., Pinto H.S. (eds) Knowledge
Engineering and Management by the Masses. EKAW 2010. Lecture Notes in
Computer Science, vol 6317. Springer, Berlin, Heidelberg"
"607","2019-12-16","IRIT","Toulouse","- Title: Extracting Semantic Information from Noisy Data
- Duration: 6 month internship, starting February-March 2020
- Location: IRIT, Toulouse (https://www.irit.fr)
- Research Team: MELODI (https://www.irit.fr/-Equipe-MELODI-)
- Supervisors: Nicholas Asher, Tim Van de Cruys
- Contact: nicholas.asher@irit.fr, tim.vandecruys@irit.fr

In cooperation with AIRBUS

Description

A prominent research subject within the domain of machine learning is
adjusting learning and training to noisy data. The subject has been
actively researched within the context of computer vision (Goldberger
and Ben-Reuven, 2017; Vahdat, 2017; Veit et al., 2017); in our case we
are interested in training from noisy linguistic data. While many groups
are looking at noisy linguistic data for general purpose learning in
open domains (Baldwin et al., 2015), the goal of this research
internship is to extract semantic information from noisy linguistic data
in closed or relatively closed domains. Use cases involve notices to
airmen (Notams) and airport traffic information bulletins (ATIS),
maintenance logs or notes for aircraft or other industrial productions,
and notes from meetings. The interest in such use cases is that they
allow us to look at a variety of learning systems and compare
them. Within relatively closed domains, we have had success with distant
supervision models, where we learn weights for a set of expert coded
rules based on an estimation of ground truth labels for unannotated
data, where the rules are derived from the study of a small but
representative and meticulously annotated corpus (Badene et al.,
2019). We would like to compare such models with neural network based
approaches, such as word embedding that incorporate character-based
representations (Joulin et al., 2017), as well as transformer networks
(viz. BERT; Devlin et al., 2019) that we can adapt to the task with
specific pretraining.

This research internship would be suitable for a 2nd year master student
(M2) with knowledge of machine learning and natural language processing
algorithms. Experience with Python libraries for neural network
implementations (specifically Pytorch) is a plus.

References

Sonia Badene, Kate Thompson, Jean-Pierre Lorré, and Nicholas Asher
(2019). Weak Supervision for Learning Discourse Structure. In
Proceedings of the 2019 Conference on Empirical Methods in Natural
Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP), pp. 2296-2305.

Baldwin, Timothy, Marie-Catherine de Marneffe, Bo Han, Young-Bum Kim,
Alan Ritter, and Wei Xu (2015). Shared tasks of the 2015 workshop on
noisy user-generated text: Twitter lexical normalization and named
entity recognition. In Proceedings of the Workshop on Noisy
User-generated Text, pp. 126-135.

Devlin, Jacob, Chang, Ming-Wei, Lee, Kenton and Toutanova, Kristina,
2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
Understanding. In Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human
Language Technologies, pp. 4171-4186.

Jacob Goldberger and Ehud Ben-Reuven (2017). Training deep
neural-networks using a noise adaptation layer. In 5th International
Conference on Learning Representations (ICLR 2017), Toulon, France.

Joulin, A., Grave, E., Bojanowski, P., & Mikolov, T. (2017). Bag of
Tricks for Efficient Text Classification. In Proceedings of the 15th
Conference of the European Chapter of the Association for Computational
Linguistics: Volume 2, Short Papers (pp. 427-431). Association for
Computational Linguistics.

Arash Vahdat (2017). Toward Robustness against Label Noise in Training
Deep Discriminative Neural Networks. In Advances in Neural Information
Processing Systems 30: Annual Conference on Neural Information
Processing Systems 2017, Long Beach, CA, USA, pp. 5596-5605.

Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and
Serge J. Belongie (2017). Learning from Noisy Large-Scale Datasets with
Minimal Supervision. In 2017 IEEE Conference on Computer Vision and
Pattern Recognition (CVPR 2017), Honolulu, HI, USA, pp. 6575-6583."
"608","2019-12-16","IRIT","Toulouse","- Titre : Prédiction de la difficulté de compréhension de contenu
  audiovisuel - approche basée sur des données textuelles faiblement
  annotées

- Domaine : Analyse, indexation et compréhension de contenus
  audiovisuels (audio, vidéo, texte)
- Thématique : Traitement automatique des langues - Analyse
  conversationnelle et interaction
- Lieu du stage : IRIT, Université Toulouse III - Paul Sabatier,
  Toulouse (https://www.irit.fr)
- Durée : 5 à 6 mois de stage (début février ou mars 2020)
- Equipes : SAMoVA (https://www.irit.fr/recherches/SAMOVA/) et MELODI
  (https://www.irit.fr/-Equipe-MELODI-)
- Contacts : Isabelle Ferrané (isabelle.ferrane@irit.fr) - Tim Van de
  Cruys (tim.vandecruys@irit.fr)

Contexte

L'exploitation avancée de grands volumes de documents audiovisuels passe
par la compréhension de leur contenu. L'analyse automatique de ces
contenus peut être réalisée sous plusieurs angles, en fonction des
modalités considérées.

- L'analyse de la composante audio permet d'extraire des informations
  (descripteurs audio) concernant l'environnement sonore (zones de
  musique, de parole ou de bruits environnants, ...), les locuteurs et
  les tours de parole (Vallet et al., 2012).

- L'analyse de la composante vidéo permet d'extraire des informations
  (descripteurs visuels) concernant le cadre (intérieur, extérieur,
  nuit, jour, ...) ou les intervenants (foule, personne présente en
  premier plan ou groupe de plusieurs personnes, ...) (Bost et al.,
  2015).

- L'analyse de la composante textuelle, à travers les sous-titres ou
  bien les transcriptions automatiques à disposition, permet d'extraire
  des informations sémantiques (descripteurs texte) qui permettent
  d'enrichir la caractérisation du contenu basée sur les modalités audio
  et vidéo (Lison and Tiedemann, 2016).

Objectif

Dans ce stage, on cherche de caractériser les contenus de films selon
leur niveau de difficulté de compréhension. Vue que le niveau de
difficulté de compréhension est principalement lié à la composante
linguistique, on explorera les possibilités offertes par le domaine du
traitement automatique des langues pour extraire les informations
pertinentes, qui pourraient donner des indications sur la tâche
envisagée.  Sujet de stage : L'objectif de ce stage est de prédire de
manière automatique la difficulté de compréhension de séquences vidéo à
travers leurs sous-titres ou transcriptions. Dans ce but, on appliquera
des méthodes supervisées basées sur les plongements de mots (word
embeddings). Ces représentations sont généralement obtenues par
apprentissage non-supervisé réalisés à partir d'un volume très important
de textes, et permettent de représenter les mots sous forme vectorielle
(vecteur de N dimensions à coefficients réels associé à chaque mot) afin
de mieux caractériser leur sens (Mikolov et al., 2013). En les intégrant
dans un modèle de réseau de neurones supervisé, il est possible de
construire des représentations vectorielles pour de plus grandes
sections de texte, capable de prédire les descripteurs pertinents
(Joulin et al., 2017). Pour l'entraînement des plongements de mots, nous
utiliserons un corpus de textes ciblé par rapport à la tâche envisagée
(sous-titres de documents de fictions ou de transcriptions automatiques
de vidéos issues du web).  L'application d'un modèle de classification
nécessite également des données labellisées. Dans ce stage, nous avons
pour objectif de construire un ensemble d'entraînement fournissant un
premier niveau d'annotation approximatif, c'est-à-dire correspondant à
des « données faiblement annotées », à la différence d'une vérité
terrain exacte et précise. Pour cela, nous explorerons le paradigme de
programmation de données (data programming ; Ratner et al., 2017). Le
but est de labelliser de manière automatique une grande quantité de
données par l'application de fonctions de labellisation, éventuellement
bruitées ; un modèle génératif effectuera alors un débruitage des
données en analysant les fonctions de labellisation comme variables
latentes. Ceci permet de labelliser de manière assez rapide une grande
quantité de données avec une exactitude satisfaisante. Les fonctions de
labellisation s'appuieront sur des traits linguistiques (par rapport au
lexique, syntaxe, etc.). Ils pourront également s'appuyer sur les
travaux antérieurs réalisés lors de stages précédents (Petiot, 2018 ;
Berdeaux, 2019). Ce travail pourrait potentiellement se faire en
collaboration avec la société Archean Labs et le laboratoire commun
ALAIA, afin de comparer différentes approches possibles.

Compétences

Ce stage s'adresse à un(e) étudiant(e) de niveau M2 ou 3ème année
d'Ecole d'ingénieurs, ayant de bonnes connaissances en programmation
objet (python) sous Linux. Des compétences en reconnaissance de formes
et apprentissage automatique sont également attendues. La connaissance
des méthodes de traitement d'images, ou traitement de l'audio sont un
plus pour bien comprendre les objectifs visés à terme de fusion des
descripteurs audio, vidéos et texte. Un bon niveau d'anglais est
également requis pour la lecture et compréhension d'articles
scientifiques en lien avec les différentes thématiques de recherche.

Références

X Bost, G Linares, S Gueye Audiovisual speaker diarization of TV series
- Acoustics, Speech and Signal Processing (ICASSP), 2015.

Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas
Mikolov. 2017. Bag of Tricks for Efficient Text Classification. In
Proceedings of the 15th Conference of the European Chapter of the
Association for Computational Linguistics: Volume 2, Short Papers,
Valencia, Spain, pp 427-431

Pierre Lison and Jörg Tiedemann. 2016. OpenSubtitles2016: Extracting
Large Parallel Corpora from Movie and TV Subtitles. In Proceedings of
the Tenth International Conference on Language Resources and Evaluation
(LREC'16), pp. 923-929.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient
Estimation of Word Representations in Vector Space. CoRR abs/1301.3781

Jim Petiot, Exploitation de données textuelles pour la recherche de
Topics et la caractérisation de contenus de fiction : approche
non-supervisée et semi-supervisée. Stage M2 IARF, 2018.

Alexandre Berdeaux, Classification supervisée de thèmes de dialogues de
film en contexte de données faiblement annotées, Stage M2 IARF, 2019.

Ratner, Alexander, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen
Wu, and Christopher Ré.  ""Snorkel: Rapid training data creation with
weak supervision."" Proceedings of the VLDB Endowment 11, no. 3 (2017):
269-282.

Félicien Vallet, Slim Essid, Jean Carrive, Gaël Richard, High-Level TV
Talk Show Structuring Centered on Speakers' Interventions, TV Content
Analysis: Techniques and Applications, Edited by Shiguo Lian Auerbach
Publications 2012."
"609","2019-12-16","CEA LIST","Palaiseau","Le CEA LIST propose le sujet de stage ci-dessous pour l'année
universitaire 2019-2020.

Titre de stage: Intégration de lexiques bilingues spécialisés dans des
modèles neuronaux pour l'adaptation au domaine en traduction automatique

Lieu du stage: CEA Saclay Nano-INNOV, Laboratoire Analyse Sémantique
Texte et Image (LASTI), 8 Avenue de la Vauve, 91120 Palaiseau

Encadrant: Nasredine Semmar, CEA LIST, Laboratoire Analyse Sémantique
Texte et Image (LASTI)


Le Laboratoire d'Analyse Sémantique des Textes et des Images (LASTI) est
une équipe de 25 personnes (chercheurs, ingénieurs, doctorants) menant
des travaux de recherche sur les technologies de description et de
compréhension du contenu multimédia (image, texte, parole) et des
documents multilingues, en particulier à grande échelle. Les enjeux
scientifiques sont:

- développer des algorithmes efficaces et robustes pour l'analyse et
  l'extraction de contenu multimédia, leur classification et analyse
  sémantique;
  
- reconstitution ou fusion de données hétérogènes pour interpréter des
  scènes ou documents;
  
- développer des méthodes et des outils pour la construction, la
  formalisation et l'organisation des ressources et connaissances
  nécessaires au fonctionnement de ces algorithmes;
  
- intégrer plusieurs de ces briques technologiques afin d'accéder à
  l'information et répondre à un besoin utilisateur (moteurs de
  recherche, chatbot, rapports synthétiques de veille).

Contexte :

L'adaptation au domaine des applications du traitement automatique de la
langue telles que la traduction automatique, la recherche et
l'extraction d'information est devenu un axe de recherche important en
apprentissage automatique et plus particulièrement en apprentissage par
transfert. En traduction automatique, plusieurs pistes ont été explorées
pour adapter des modèles statistiques construits pour un domaine source
pour lequel existent une quantité suffisante de données d'apprentissage
vers un domaine cible pour lequel peu de données sont disponibles (Lewis
et al., 2010; Pecina et al., 2011; Wang et al., 2012). Au cours des
dernières années, de nombreux travaux ont exploré l'utilisation des
lexiques bilingues spécialisés pour améliorer la performance des
systèmes de traduction statistique. La plupart d'entre eux consistent,
soit à ajouter au corpus d'apprentissage un lexique bilingue ou un
corpus parallèle du domaine de spécialité, soit à étendre les tables de
traduction en leur incorporant les entrées du lexique spécialisé
(Langlais, 2002; Bouamor et al., 2012; Semmar et al., 2017).

En comparaison avec la traduction à base de règles ou la traduction
statistique, peu de travaux ont été réalisés pour intégrer des lexiques
bilingues spécialisés dans des systèmes de traduction utilisant des
modèles neuronaux pour leur adaptation au domaine. Nous pouvons citer
les travaux de Wang et al. (2017) qui ont proposé une méthode pour
intégrer un lexique bilingue d'expressions multi-mots dans un modèle
neuronal de type encodeur-décodeur. En revanche, plusieurs études
récentes ont abordé l'intégration de connaissances expertes ou
ressources linguistiques externes dans des modèles de réseaux de
neurones profonds. Trois stratégies d'intégration ont été explorées :
Les connaissances expertes ou ressources linguistiques sont introduites
en amont (Kuznetsov et al., 2018), en cours (Hu et al., 2016) ou en aval
du processus d'apprentissage, de manière focalisée ou répartie dans le
modèle neuronal (Zennaki et al., 2018).


Sujet de stage:

Le stage proposé portera sur l'exploitation de lexiques bilingues
spécialisés en traduction neuronale pour l'adaptation au domaine. Il
consistera, d'une part à implémenter un système de traduction neuronale

en utilisant les librairies open source disponibles, et d'autre part à
explorer l'intégration d'un lexique bilingue spécialisé dans ce type de
système et à étudier l'impact de ce lexique sur la qualité de
traduction.

Le stage se déroulera selon les étapes suivantes:

- Développement ou adaptation d'un outil d'alignement de mots pour la
  constitution de lexiques bilingues spécialisés à partir de corpus de
  textes parallèles.

- Installation du système de traduction neuronale Open Source OpenNMT
  (http://fr.opennmt.net/).

- Spécification et implémentation d'un modèle pour l'intégration dans le
  système OpenNMT d'un lexique bilingue spécialisé.

- Evaluation de l'impact de ce lexique sur la qualité de traduction du
  système OpenNMT.

- Implémentation d'une interface Web pour le traducteur automatique
  neuronal.

Références:
- LEWIS W. D., WENDT C., BULLOCK D. Achieving Domain Specificity in SMT
  without Overt Siloing. Actes de the seventh international conference
  on Language Resources and Evaluation, 2010.
- PECINA P., TORAL A., WAY A., PAPAVASSILIOU V., WAY A., PROKOPIDIS P.,
  GIAGKOU M. Towards Using Web-Crawled Data for Domain Adaptation in
  Statistical Machine Translation, 2011. Actes de the 15th Conference of
  the European Association for Machine Translation.
- WANG W., MACHEREY K., MACHEREY W., OCH F., XU P. Improved Domain
  Adaptation for Statistical Machine Translation. Actes de the
  Conference of the North American Chapter of the Association for
  Computational Linguistics: Human Language Technologies, 2012.
- LANGLAIS P. (2002). Improving a general-purpose statistical
  translation engine by terminological lexicons. Actes de COLING: Second
  international workshop on computational terminology.
- BOUAMOR D., SEMMAR N., ZWEIGENBAUM P. Identifying bilingual Multi-Word
  Expressions for Statistical Machine Translation. Actes de LREC 2012.
- SEMMAR N., ZENNAKI O., LAIB M. Improving the Performance of an
  Example-Based Machine Translation System Using a Domain-specific
  Bilingual Lexicon. Actes de 29th Pacific Asia Conference on Language,
  Information and Computation, Shanghai, China, 2015.
- WANG X., TU Z., XIONG D., ZHANG M. Translating Phrases in Neural
  Machine Translation. Actes de EMNLP 2017.
- KUZNETSOV I., GUREVYCH I. From Text to Lexicon: Bridging the Gap
  between Word Embeddings and Lexical Resources. Actes de COLING 2018.
- HU Z., MA X., LIU Z., HOVEY E., XING E. P. Harnessing Deep Neural
  Networks with Logic Rules. Actes de ACL 2016.
- ZENNAKI O., SEMMAR N., BESACIER L. A Neural Approach for Inducing
  Multilingual Resources and Natural Language Processing Tools for
  Low-Resource Languages. Journal of Natural Language Engineering,
  Cambridge University Press, 2018.


Conditions sur les candidatures et Profil recherché:

Niveau demandé: Master 2, Ingénieur

Durée : 6 mois

Rémunération : entre 700 ¤ et 1300 ¤ suivant la formation

Compétences requises :

- environnement de travail : linux

- maîtrise d'un langage de programmation : C++ ou Python

- expérience avec une bibliothèque de type Tensorflow, PyTorch, etc.

- notion de base en apprentissage automatique et en réseaux de neurones

- notions de base en traitement automatique des langues.



Modalité de dépôt de candidature :

Les candidatures (CV + Lettre de motivation) sont à envoyer le plus
rapidement possible à Nasredine Semmar
(nasredine.semmar@cea.fr<mailto:nasredine.semmar@cea.fr>).


Contacts pour plus d'information :
Nasredine Semmar, Email: nasredine.semmar@cea.fr, 
Tél: +33 (0)1 69 08 01 46"
"610","2019-12-16","INA","Bry-sur-Marne","Segmentation et détection automatique des situations conflictuelles en
interview politique

    
Mots clés : Machine Learning, Diarization, Humanités numériques, parole
politique, expressivité
    
Contexte
L'Institut national de l'audiovisuel (INA) est un établissement public à
caractère industriel et commercial (EPIC), dont la mission principale
consiste à archiver et valoriser la mémoire audiovisuelle française
(radio, télévision et web média). L'INA assure également des missions de
recherche scientifique, de formation et de production.

Ce stage s'inscrit le cadre du projet OOPAIP (Ontologie et outil pour
l'annotation des interventions politiques). C'est un projet
transdisciplinaire porté par l'INA et le CESSP (Centre européen de
sociologie et de science politique) de l'Université Paris 1
Panthéon-Sorbonne. L'objectif est de concevoir de nouvelles approches
pour élaborer des analyses détaillées, qualitatives et quantitatives des
interventions politiques médiatisés en France. Une part du projet porte
sur l'étude de la dynamique des interactions conflictuelles dans les
interviews et débats politiques, ce qui nécessite une description fine
et un large corpus afin de généraliser les modèles. Les verrous
technologiques concernent la performance des algorithmes de segmentation
en locuteurs et en styles de parole. L'amélioration de leur précision,
l'ajout de la détection de parole superposée, de mesures de l'effort
vocal et d'éléments expressifs, permettront d'optimiser le travail
d'annotation manuel.
    
Objectifs du stage
Le stage vise principalement à l'amélioration de la segmentation
automatique d'interviews politiques pour assister les travaux de
recherche en science politique. La thématique de recherche
correspondante que nous retiendrons est la mise en évidence des
situations conflictuelles. Dans ce cadre, nous nous intéresserons
notamment à la détection du brouhaha (parole superposée). De manière
plus fine, nous aimerions pouvoir extraire des descripteurs du signal de
parole corrélés au niveau de conflictualité des échanges, basés, par
exemple, sur le niveau d'activation (niveau intermédiaire entre le
signal et l'expressivité [Rilliard et al, 2018]) ou l'effort vocal
[Liénard, 2019].

Le stage pourra s'appuyer initialement sur deux corpus totalisant 30
interviews politiques annotés finement en tours de paroles - dans le
cadre du projet OOPAIP. Il débutera par la réalisation d'un état de
l'art de la diarization (segmentation et regroupement en locuteurs
[Broux et al., 2019]) et de la détection de la parole superposée
[Chowdhury et al, 2019]. Il s'agira ensuite de proposer des solutions
basées sur des frameworks récents pour améliorer la localisation des
frontières de tours de parole, notamment lorsque la fréquence des
changements de locuteurs est importante - le cas limite étant la
situation du brouhaha.

La seconde partie du stage se penchera sur une mesure plus fine du
niveau conflictuel des échanges, via la recherche des descripteurs les
plus pertinents et par la mise au point d'architecture d'apprentissage
pour sa modélisation.

Le langage de programmation utilisé dans le cadre de ce stage sera
Python. Le stagiaire aura accès aux ressources de calcul de l'INA
(serveurs et clusters), ainsi qu'à un desktop performant avec 2 GPU de
génération récente.
    
Valorisation du stage
    Différentes stratégies de valorisation des travaux du·de la
    stagiaire seront envisagées, en fonction du degré de maturité des
    travaux réalisés :
    
    - Diffusion des outils d'analyse réalisés sous licence open-source
      via le dépôt GitHub de l'INA : https://github.com/ina-foss
    -  Rédaction de publications scientifiques
    
Conditions du stage
    Le stage se déroulera sur une période de 4 à 6 mois, au sein du
    service de la Recherche de l'Ina. Il aura lieu sur le site Bry 2,
    situé au 18 Avenue des frères Lumière, 94360 Bry-sur-Marne. La·le
    stagiaire sera encadré·e par Marc Evrard (mevrard@ina.fr).
    Gratification : environ 550 Euros par mois.
    
Profil recherché
    - Étudiant·e en dernière année d'un bac +5 dans le domaine de
      l'informatique et de l'IA.
    - Compétence en langage Python et expérience dans l'utilisation de
      bibliothèques de ML (Scikit-learn, TensorFlow, PyTorch).
    - Vif intérêt dans les SHS, les humanités numériques et les sciences
      politiques en particulier.
    - Capacité à réaliser une étude bibliographique à partir d'articles
      scientifiques rédigés en anglais.
    
Pour postuler, vous pouvez envoyer un email à mevrard@ina.fr comprenant
un CV et une lettre de motivation.
    
Bibliographie
   Broux, P. A., Desnous, F., Larcher, A., Petitrenaud, S., Carrive,
    J., & Meignier, S. (2018). ""S4D: Speaker Diarization Toolkit in
    Python"". In Inter-speech 2018.
   Chowdhury, S. A., Stepanov, E. A., Danieli, M., Riccardi,
    G. (2019). ""Automatic classification of speech overlaps: Feature
    representation and algo-rithms"", Computer Speech & Language,
    vol. 55, pp.145-167.
   Liénard, J.-S. ""Quantifying vocal effort from the shape of the
    one-third octave long-term-average spectrum of speech""
    J. Acoust. Soc. Am. 146 (4), Oc-tober 2019.
   Rilliard, A., d'Alessandro, C & Evrard, M. (2018). Paradigmatic
    variation of vowels in expressive speech: Acoustic description and
    dimensional analysis. The Journal of the Acoustical Society of
    America, 143(1), 109-122."
"611","2019-12-16","Eloquant","Grenoble","Offre de stage

Sémantique : traitement automatique de la langue

Le genre masculin est utilisé sans aucune discrimination et dans le seul but d'alléger le texte.

Eloquant, spécialiste des solutions de Relation Client et du feedback client, recherche un stagiaire pour le
développement d'une catégorisation sémantique spécifique.

Informations sur l'offre

Date cible de prise de poste : 02 mars 2020, pour 6 mois

Localisation du poste : Gières (siège social)

Type de contrat : Stage

Pour envoyer votre candidature : jobs_rd@eloquant.com

Stage

Dans le cadre de son offre Explore, Eloquant propose à ses clients
d'effectuer l'analyse sémantique des verbatims (commentaires, avis,
mails...) issus de leur propre clientèle et/ou du système
d'information. L'analyse sémantique proposée permet, à partir d'un
verbatim fourni en entrée, d'extraire diverses informations
structurées.  Le stage consiste à mener une étude des corpus issus de
transcriptions automatiques d'appels téléphoniques pour dégager les
entités pertinentes à relever, et développer les briques linguistiques
et logicielles permettant de les extraire, à l'aide des formalismes
utilisés par l'équipe.


Tâches à réaliser

La technologie TAL d'Eloquant inclut une composante d'apprentissage
machine pour la classification automatique, et une composante «
experte » utilisant d'une part des lexiques annotés, et d'autre part,
des règles linguistiques pour l'extraction de traits sémantiques pour
l'apprentissage machine, l'extraction des fragments de texte exprimant
des opinions et des alertes, et pour la correction des résultats de
classification.  Le travail commencera donc par une prise en main de
la technologie d'Eloquant, avec en parallèle une définition des
besoins (volet en lien avec le marketing).


Le stagiaire devra ensuite :

- mener une étude des corpus afin de modéliser les éléments à
  détecter, déterminer ce qui est possible compte tenu de la qualité
  des données (volet linguistique),

- effectuer plusieurs annotations des corpus, dont une pour
  l'identification des rôles des locuteurs, et d'autres pour les
  autres analyses (volet linguistique),

- développer les briques linguistiques et logicielles d'analyse
  sémantique (volet développement),

- évaluer les résultats en les confrontant aux annotations, et
analyser les erreurs (volet linguistique et développement).

Profil

Le candidat devra avoir de solides connaissances en linguistique
computationnelle, et posséder des bases d'un langage de programmation
(de préférence Java). Il devra travailler en équipe (l'équipe
Sémantique est composée d'ingénieurs-linguistes,
linguistes-informaticiens et ingénieurs-informaticiens).  Il prendra
part à la phase d'études en amont, et devra pouvoir proposer et
implémenter des solutions.  Le stagiaire fera état de son avancement
lors des points d'équipe hebdomadaires, des points d'avancement
internes bimensuels, et de points réguliers avec son encadrant
académique.

Entreprise

Spécialiste de la Relation Client depuis 2001, ELOQUANT est le seul
acteur du marché à proposer une solution globale, associant la gestion
multicanal des contacts entrants et sortants, les enquêtes en ligne et
l'analyse sémantique.  ELOQUANT a réalisé une croissance de plus de
25% sur les 3 dernières années, et, grâce à une notoriété croissante
et une forte légitimité auprès des clients, a pour objectif
d'accélérer cette croissance dans les années à venir."
"612","2019-12-16","Eloquant","Grenoble","Offre de stage

Sémantique : traitement automatique de la langue

Le genre masculin est utilisé sans aucune discrimination et dans le seul but d'alléger le texte.

Eloquant, spécialiste des solutions de Relation Client et du feedback
client, recherche un stagiaire pour le développement d'une
catégorisation « Ressources Humaines ».

Informations sur l'offre

Date cible de prise de poste : ASAP, pour 6 mois

Localisation du poste : Gières (siège social)

Type de contrat : Stage


Dans le cadre du développement de notre offre, nous recherchons un
stagiaire dont la mission sera de développer une classification «
ressources humaines » pour les enquêtes RH des clients Eloquant. En
parallèle, vous serez également amené à intervenir sur des projets
clients avec pour principale mission de développer des classifieurs
automatiques de verbatim clients.


- Recueillir les besoins de l'équipe et des clients.

- Définition des catégories, développement du système de machine
learning, des taxonomies, des lexiques et des règles linguistiques.

- Confrontation des résultats avec l'équipe métier (Pôle étude).

Le stagiaire travaillera en étroite collaboration avec l'équipe
sémantique et le département Professional Services responsable de la
gestion des clients.

Le stage comprend deux étapes :
- Développement du système de classification « RH »
- Accompagnement sur des projets clients

Profil
- Enthousiasme et forte appétence à être en contact avec les clients
- Compétences en traitement automatique des langues
- Compétences en programmation (en Java serait un plus)

Envoyez votre candidature à : jobs_ps@eloquant.com


Entreprise

Spécialiste de la Relation Client depuis 2001, ELOQUANT est le seul
acteur du marché à proposer une solution globale, associant la gestion
multicanal des contacts entrants et sortants, les enquêtes en ligne et
l'analyse sémantique.  ELOQUANT a réalisé une croissance de plus de
25% sur les 3 dernières années, et, grâce à une notoriété croissante
et une forte légitimité auprès des clients, a pour objectif
d'accélérer cette croissance dans les années à venir."
"613","2019-12-16","Latts & IGN","Champs-sur-Marne & Saint-Mandé","stage : Processus de construction sociale des incertitudes et des
risques en aménagement et urbanisme
********

Mots clés : TAL, aménagement du territoire, environnement
----------

Équipes de recherche et lieux du stage  
---------------------------------------
Latts  (Laboratoire Techniques, territoires, sociétés, École des Ponts
et Chaussées, CNRS, Université Paris Est). Champs-sur-Marne.
LaSTIG (Laboratoire en Sciences et technologies de l'information
géographique pour la ville et les territoires numériques,
IGN). Saint-Mandé.


Description du projet de recherche  dans lequel s'intègre le stage
------------------------------------------------------------------
L'impact sur l'environnement humain et naturel est un enjeu de plus en
plus courant dans le processus de planification, réalisation et
concertation des projets d'infrastructure et d'urbanisme. Cela touche
les grands projets (LGV, autoroutes, grands stades, etc) mais aussi, et
de plus en plus, les micro-projets (lotissement, ZAC, centre
commercial). Un enjeu peut être érigé en risque par les associations,
les habitants ou les élus locaux sur la base d'une connaissance fine du
territoire et/ou d'études spécialisées et expertes.

Ce risque pour l'environnement, notamment s'il contre les textes
réglementaires sur la protection de l'environnement, peut être utilisé
par les acteurs pour s'opposer au projet lors du débat public ou de
l'enquête publique ou à d'autres moments du processus de décision. Cette
opposition peut faire annuler, reporter ou modifier le projet
d'aménagement. Le recours gracieux ou contentieux est même de plus en
plus fréquent, ce qui peut occasionner une incertitude ou un risque
social, puis un risque de retard et un risque financier (pour le projet
et la collectivité locale ou le maître d'ouvrage qui le pilotent).

Le processus de construction des enjeux de territoire en incertitude
puis en risque (et par conséquent la construction d'une chaine
d'incertitudes ou de risques : social puis politique puis financier,
etc.) nécessite d'être approfondi en raison de la multiplication des
conflits fondés sur le risque, et des enjeux que cela pose en matière de
concertation, de participation et de politiques publiques d'aménagement
et de protection de l'environnement. Le cas de la construction de «
faux-risques » assimilables à des fake news serait aussi à explorer.

Pour comprendre la construction du discours des acteurs opposés à un
projet, et la construction des incertitudes et des risques, l'objet du
stage est de réaliser une analyse textuelle des positions de ces acteurs
(recherche d'occurrences de mots-clés par exemple) dans les registres de
débat public, les rapports de l'enquête publique, de la concertation, la
presse, etc. et de l'interpréter.

Sujet du stage  (durée :  6 mois maximum)
-------------------------------------------
Le stage a pour objet de tester et de développer la démarche précédente
sur un corpus de positions d'acteurs (élus, associations, entreprises,
habitants, etc) issues de la concertation continue menée par la maîtrise
d'ouvrage publique et privée d'une infrastructure de transport ou
d'urbanisme. Ce corpus sera constitué avant le début du stage.

Le stage comporte les étapes suivantes :

- appropriation selon le profil du-de la candidat-e des fondamentaux sur
  les enjeux de contestation des projets, la construction
  socio-technique du risque et les outils (analyse textuelle) ;
- appropriation du corpus dans la diversité de ses textes (débat public,
  enquête publique, articles de presse, sites internet, interviews,
  etc.), des thématiques, des champs lexicaux, des niveaux de langue,
  etc. ;
- définition des incertitudes et risques analysés. Il peut s'agir de
  risques sociaux (opposition des associations ou habitants à un projet)
  ; de risques politiques (opposition des élus) ; de risques
  environnementaux (impact du projet sur l'environnement naturel et
  humain) ; de risques juridiques ; de risques financiers ou de retard.
- traduction de ces incertitudes et risques en éléments linguistiques :
  mots-clés, champs lexicaux spécifiques, verbes modaux, indices de
  prise en charge du discours par le locuteur, etc., ou statistiques :
  fréquences, répartitions, analyse contrastive entre sous-corpus, etc.,
  à rechercher ;
- état de l'art des ressources et outils existants adaptés à
  l'identification (automatique) de ces éléments linguistiques, et mise
  en oeuvre de ces outils sur le corpus sélectionné ;
- analyse des résultats ;
- bilan de la recherche.

Les résultats de cette recherche exploratoire sont destinés aux
organismes publics ou privés en charge d'une concertation et au milieu
associatif qui y participe.

Débouchés de la recherche et du stage
----------------------------------------
Cette recherche exploratoire a pour objet de déboucher sur l'étude d'un
mode de représentation de la construction du risque, ce qui peut
permettre de visualiser la façon dont un impact pressenti à un endroit
de la concertation est transformé en risque. Une poursuite de la
recherche par une thèse peut être envisagée avec deux voies :

- tester un mode de représentation du processus de construction du
  risque dans le temps et dans l'espace et adapté à un public donné
  (cartographie par exemple).

- élargir la recherche à d'autres projets comme les ZAC, les
  lotissements, les équipements de loisirs, etc.

Profil du/de la candidat-e
--------------------------
- Master 2 Aménagement et Urbanisme, intéressé-e par l'informatique et
  l'analyse de discours.
- Master 2 en Traitement automatique des langues, intéressé-e pour
  travailler sur un corpus de textes issus de la concertation d'un
  projet d'infrastructure ou d'urbanisme


Contacts : 
----------
Le dossier de candidature devra contenir les documents suivants :
- CV,
- lettre de motivation,
- derniers relevés de notes (M1, et premier semestre de M2 si
  disponible),
- description des enseignements suivis (un lien vers le site internet de
  la formation est le bienvenu),
- dernier mémoire ou rapport de stage rédigé,

et est à envoyer avant le 20 janvier 2020 à :
Geneviève ZEMBRI-MARY, professeure en Aménagement et Urbanisme,
université de Cergy-Pontoise, en délégation CNRS au Laboratoire
techniques territoires sociétés (Latts-UPEM, ENPC, CNRS),
Genevieve.zembri-mary@enpc.fr

Catherine DOMINGUÈS, chargée de recherche au Laboratoire en sciences et
technologies de l'information géographique (LaSTIG, IGN),
Catherine.Domingues@ign.fr"
"614","2019-12-16","LIPN","Villetaneuse","Title: Multitask Learning of Easy-first Hierarchical Tree LSTMs for Joint Syntactic and Semantic Arabic Dependency Parsing


Context: Collaboration between RCLN (https://lipn.univ-paris13.fr/accueil/equipe/rcln/), LIPN, Université Paris 13, and CAMeL Lab (https://bit.ly/2M0XsAG), New York University Abu Dhabi

Host lab: LIPN, Université Paris 13, 99 Avenue Jean Baptiste Clément,
93430 Villetaneuse

Supervisors: Joseph Le Roux and Nadi Tomeh

Collaborators: Nizar Habash and Dima Taji

Start date: February 2020

Duration: 6 months

Salary: 550 euros/month

Profile and required skills:

- Masters in Computer Science, Computational Linguistics, Applied
Mathematics, or Statistics

- Knowledge in Natural Language Processing and Deep Learning is highly
appreciated

- Programming skills in Python (and libraries such as pytorch, numpy,
or scikit-learn)

How to apply: send CV and available Masters' grades to tomeh@lipn.fr
and leroux@lipn.fr


Description:

In recent work on semantic parsing, Peng et al. [2017; 2018]; and
Kurita and Søgaard [2019] showed that the overlap between three
different theories of semantics and their corresponding
representations can be exploited to improve performance on all three
tasks. This is done using multitask learning in a deep neural
architecture. We would like to explore ways in which this approach can
be applied to Arabic, which has rich morphology and complex
morpho-syntactic interactions. We will work with two different
dependency representations. The first is the Columbia Arabic Treebank
(CATiB) representation [Habash and Roth, 2009], which is inspired by
Arabic traditional grammar and which focus on modeling syntactic and
morpho-syntactic agreement and case assignment.  The second is the
Universal Dependency (UD) representation for Arabic [Taji et al.,
2017], which has relatively more focus on semantic/thematic relations
within the sentence, and which is coordinated in design with a number
of other languages [Nivre et al., 2016]. The two representations
complement each other and stand to benefit from multitask learning
approaches.

In this context, we propose to

(i) Extend the easy-first hierarchical LSTM parser of Kiperwasser and
Goldberg [2016] to multitask settings. We have shown that this
approach can be useful for joint lexical segmentation and dependency
parsing [Constant et al., 2016]. In that work we used as our
single-task model the easy-first parser of Goldberg and Elhadad [2010]
trained with dynamic oracles [Goldberg and Nivre, 2013];

(ii) Apply the model to parse Arabic sentences to both CATiB and UD
representations;

(ii) Employ multitask modeling insights from Peng et al. [2017; 2018];
and Kurita and Søgaard [2019] to enhance the multitask easy-first
parser.


References

    Peng, Hao, Sam Thomson and Noah A. Smith. ""Deep Multitask Learning
    for Semantic Dependency Parsing."" ACL (2017).

    Peng, Hao, Sam Thomson, Swabha Swayamdipta and Noah
    A. Smith. ""Learning Joint Semantic Parsers from Disjoint Data.""
    NAACL-HLT (2018).

    Kurita, Shuhei and Anders Søgaard. ""Multi-Task Semantic Dependency
    Parsing with Policy Gradient for Learning Easy-First Strategies.""
    ACL (2019).

    Nizar Habash and Ryan M. Roth. ""CATiB: The Columbia Arabic
    Treebank."" Proceedings of Annual Meeting of the Association for
    Computational Linguistics, 2009.

    Dima Taji, Nizar Habash, and Daniel Zeman. ""Universal Dependencies
    for Arabic."" Proceedings of the Workshop on Arabic Natural
    Language Processing (with EACL), 2017.

    Yoav Goldberg and Michael Elhadad. 2010. An efficient algorithm
    for easy-first non-directional dependency parsing. In Human
    Language Technologies: NAACL, pages 742-750, Los Angeles,
    California.

    Eliyahu Kiperwasser and Yoav Goldberg. 2016. Easy-first dependency
    parsing with hierarchical tree LSTMs. Transactions of the
    Association for Computational Linguistics, 4, 445-461.

    Mathieu Constant, Joseph Le Roux, Nadi Tomeh. Deep Lexical
    Segmentation and Syntactic Parsing in the Easy-First Dependency
    Framework. NAACL, 2016, San Diego, United States."
"615","2020-01-06","SNCF","Saint-Denis","La Direction Innovation et Recherche et la Direction Générale Sécurité
de la SNCF recherchent un stagiaire pour contribuer à l'évaluation d'un
moteur de recherche interne.

Titre : Évaluation d'un moteur de recherche d'entreprise sur un corpus
métier SNCF

*Contexte*
------------------------------
Dans le cadre un programme de transformation documentaire, SNCF fait
évoluer le moteur de recherche utilisé sur une base de documents métiers
internes. En 2019, des travaux ont permis de faire un bilan des limites
du moteur de recherche actuel, de pré-qualifier les besoins en
information sur la base d'un historique de requêtes et d'identifier des
critères de paramétrage du nouveau moteur. Le paramétrage de ce nouveau
moteur est prévu courant 2020. Il s'accompagnera d'un protocole
d'évaluation, qui nécessite de définir un jeu de requêtes de test, des
métriques de pertinence et de mettre en oeuvre le protocole d'évaluation.


*Description *
------------------------------
Le stagiaire devra :

- Prendre connaissance du contexte du stage (SNCF, objectifs du stage et
  cadre de réalisation, programme de rattachement : programme PRISME et
  Plateau Simplification de la Direction Générale Sécurité, projet dans
  lequel le stage s'insère et interlocuteurs sur les sujets concernés),

- Réaliser une analyse descriptive des données utilisées en entrée
  (corpus documentaire et historique de requêtes), par une analyse
  sémantique et statistique. L'analyse sera réalisée à l'aide d'outils
  de lexicométrie et d'outils statistiques,

- Étudier les méthodes d'évaluation de moteur de recherche et leur
  application pratique dans le contexte du stage,

- Proposer un protocole d'évaluation du moteur, à travers la définition
  et la construction d'un jeu de données de test, ainsi que la
  proposition de métriques.


Présentations et rapports :

- Présentation de début de stage à la SNCF (au bout d'un mois de stage)
  : contexte du stage, planning de réalisation et premiers travaux
  réalisés.

- Rapport final de stage complet comprenant : méthodologie utilisée,
  travaux réalisés, résultats obtenus et problèmes rencontrés

- 2 soutenances de fin de stage : une à l'école et une à la SNCF.

- Des présentations en interne SNCF ou externes pourront être
  effectuées.


*Profil recherché*
------------------------------

Niveau : De formation Bac+5 en Sciences du langage/Traitement
Automatique du Langage Naturel ou Data Science / Statistiques.

Compétences attendues :

- Capacités d'analyse, de rédaction et de synthèse

- Autonomie, qualités relationnelles, qualités de présentation
  (orale/écrite).

- Connaissances en Traitement Automatique du Langage et linguistique

- Compétences en statistiques

Compétences additionnelles souhaitées :

- Maîtrise d'outils de lexicométrie/textométrie

- Maîtrise de R

- Compétences en informatique (programmation)


*Modalités du poste*
------------------------------

   - Durée : 6 mois
   - Rémunération prévue : indemnités de stage + carte de circulation
     SNCF sur le réseau national
   - Début : à partir de mars 2019
   - Lieu : Saint-Denis


Merci d'adresser CV et lettre de motivation à Luce Lefeuvre et Coralie
Reutenauer aux adresses mail suivantes :
luce.lefeuvre@sncf.fr,
coralie.reutenauer@sncf.fr"
"616","2020-01-06","LIMSI","Orsay","*Veille scientifique automatisée / Scientific Survey Automation*
(English description below)

- Lieu du stage : LIMSI, Orsay (91)
- Durée : Stage de 5 mois, pouvant démarrer après obtention de l'accord
  du fonctionnaire de défense (délai maximum de 2 mois après soumission
  du dossier), le LIMSI étant une Zone à Régime Restrictif et signature
  d'une convention de stage entre le CNRS votre établissement
  d'enseignement d'origine (délai environ 1 mois).
- Indemnités de stage : le montant des indemnités de stage est d'environ
  568 ¤ par mois.
- Encadrants : Ce stage s'effectue dans le cadres d'un projet
  scientifique interne au LIMSI (une des ""actions incitatives"" de 2020),
  avec comme encadrant principal Patrick Paroubek (groupe ILES) pour les
  aspects fouille d'opinion et scientométrie, Cyril Grouin (groupe ILES)
  pour les aspects extraction d'information et traitement de corpus,
  Bérengère Podvin (groupe AERO ) pour la mécanique des fluides et
  Michel Pons (groupe TSF) pour la mécanique énergétique.
- Contact Patrick Paroubek, pap@limsi.fr, merci de mentionner ""stage
  veille scientifique"" dans le sujet (thanks for mentioning ""Science
  Survey Internship"" in the subject),
  https://perso.limsi.fr/pap/internship_AI2020_science_survey/

*Description*

Le but de ce stage est de mener une étude pour savoir dans quelle mesure
on peut automatiser la construction d'une réponse à la aux questions
suivantes :
- Si je suis un chercheur, étant donné : mon domaine de recherche, les
  articles que j'ai publiés et les connaissances du domaine,
- Quels sont les articles parmi un ensemble d'articles que j'ai à
  relire, ceux qui vont susciter mon intérêt ?
- Quels sont dans le contenu textuel des articles, les indices qui ont
  déclenché mon intérêt ? et Pourquoi ? A cause de leur nouveauté ou
  bien au contraire à cause de leur similarité avec des idées qui ont
  déjà été abordées par d'autres chercheurs ?

L'expérience comprendra plusieurs parties distinctes:

- Élaborer, en se basant sur des interviews d'experts du domaine et
  d'articles fournis eux, une description des critères d'intérêt et de
  leur différentes réalisations linguistiques, comme par exemple les
  noms d'auteurs connus, la présence de certaines références
  bibliographiques, d'une argumentation particulière, de la mention
  d'idées nouvelles ou importées d'autres disciplines, de références à
  des thèmes spécifiques, des expressions d'opinions sur certaines
  approches etc.
- Utiliser les algorithmes d'extraction d'information [6] et d'analyse
  du langage naturel pour repérer et classer les mentions d'indices
  suscitant l'intérêt dans les contenus textuels d'un ensemble
  d'articles [1]
- Utiliser les marqueurs d'intérêt identifiés pour classer
  automatiquement les articles par ordre décroissant d'intérêt
- Concevoir et implémenter une évaluation de la performance du
  classement obtenu à partir d'articles déjà publiés (une mesure
  d'évaluation possible pourrait utiliser le nombre de citations d'un
  article)


*Moyens*

Les travaux combineront une approche linguistique et/ou une approche de
gestion des connaissances pour descrire des critères d'intérêt qui
seront mis en relation avec les algorithmes état de l'art en fouille de
textes scientifiques [2][3]. Une fois les critères définis en
collaboration avec les chercheurs de deux domaines applicatifs : d'une
part le Traitment Automatique des Langues et d'autre part la mécanique
des fluides - mécanique énergétique, le/la stagiaire
déploiera/développera des algorithmes d'extraction d'information et
d'analyse automatique du langage naturel dans une environnement Unix
pour implémenter la chaîne de traitement informatisée chargée d'annoter
et de classer les articles scientifiques fournis en entrée de la chaîne.

*Données/corpus*

Les données qui seront utilisée pour les tests d'automation avec la
chaîne de traitement seront constituées d'une part du corpus NLP4NLP
[4][5] contenant 64953 articles représentatif de la littérature
scientifique du domaine du Traitement Automatique des Langues, publiée
sur une période de 50 ans (http://www.nlp4nlp.org/) et d'autre part des
publications de mécanique des fluides / mécanique énergétique
disponibles dans la base des publications du LIMSI.

*Profil de recherche*

Linguiste, linguiste-informaticien(ne)-TAListe, ou informaticien(ne).
Des compétences en spécifiques en linguistique, gestion des
connaissances, traitement automatique des langues, extraction
d'information ou apprentissage automatique seront appréciées. En
fonction du profil de recherche, l'accent pourra être mis sur la
définition formelle des critères d'intérêt (formalisation linguistique)
ou sur les aspects extraction d'information précise (identification des
critères) ou bien encore sur l'apprentissage automatique pour construire
la représentation de la question de recherche à partir d'un ensemble
d'articles et son évaluation. Dans tous les cas une autonomie pour la
mise en place d'une chaîne de traitement de corpus dans un environnement
Unix est indispensable (des compétences en programmation Python seront
appréciées).

*Bibliographie*

1 Romaric Besançon, Anne-Laure Daquo, Clustering de documents dans des
  collections hétérogènes, Document numérique 2015/2-3 (Vol. 18), pages
  81 à 100,
  https://pdfs.semanticscholar.org/7c6a/b9f77507b0a585dbd7328fbc2d50e0315ac0.pdf
2 Steffen Eger, Chao Li, Florian Netzer, Iryna Gurevych, Predicting
  Research Trends From Arxiv, 2019,
  https://www.researchgate.net/publication/331587503_Predicting_Research_Trends_From_Arxiv
3 Kata Gábor, Isabelle Tellier, Thierry Charnois, Haïfa Zargayouna,
  Davide Buscaldi, Détection et classification non supervisées de
  relations sémantiques dans des articles scientifiques, Actes de la
  conférence conjointe JEP-TALN-RECITAL 2016, volume 2 : TALN,
  http://www.lattice.cnrs.fr/sites/itellier/articles/TALN2016b.pdf
4 Joseph Mariani, Gil Francopoulo, Patrick Paroubek, The NLP4NLP Corpus
  (I): 50 Years of Publication, Collaboration and Citation in Speech and
  Language Processing, 2019
  https://www.frontiersin.org/articles/10.3389/frma.2018.00036/full
5 Joseph Mariani, Gil Francopoulo, Patrick Paroubek, Frédéric Vernier,
  The NLP4NLP Corpus (II): 50 Years of Research in Speech and Language
  Processing, 2019,
  https://www.frontiersin.org/articles/10.3389/frma.2018.00037/full
6 Laure Soulier, Définition et évaluation de modèles de recherche
  d'information collaborative basés sur les compétences de domaine et
  les rôles des utilisateurs, Thèse de doctorat d'informatique, 2014,
  https://hal.archives-ouvertes.fr/tel-01110721/document


ENGLISH VERSION

*Description*

The goal of this internship is to perform a study to know whether it is
possible automatizing the elaboration of an answer to the following
question:
If I am a researcher, given: my research domain, the articles I already
published and the knowledges of the domain,
Which, among some articles that I have to read, are the ones that will 
spark my interest?
Which are the specific clues in the text content of the articles that 
sparked my interest ? and Why? Because of their novelty? Or because they 
are similar to ideas that have already addressed by other researchers?

The experiment will address several points:
- From domain expert interviews and the reading of articles provided by
  these experts, write a description of the criteria associated to a
  sparking of interest from the reader and of their various linguistic
  realizations, for instance : the occurrence of the name of renown
  authors of the field, the presence of certain bibliographic
  references, of a particular claim or argument, the mention of novel
  ideas or concepts imported from other disciplines, the existence of
  references to specific topics or opinions expressed about particular
  approaches etc.
- Deploy information extraction [6] and natural language processing
  algorithms to identify and classify the occurrences of interest clues
  in the text content of a set of scientific articles [1]
- Use the interest markers identified to rank the articles automatically
  in decreasing order of interest
- Design and implement an evaluation of the performance of the ranking
  obtained on already published articles (a possible evaluation measure
  can be based on the number of citation of an article)

*Means*

The work will combine a linguistic approach and/or a knowledge
management approach for describing interest criteria which will be used
later with state of the art algorithms in scientific publication mining
[2][3]. Once the criteria will have been defined in collaboration with
experts from two application domains: on the one hand Natural Language
Processing and on the other hand fluid mechanics and energy, the intern
will deploy/develop information extraction and natural language
processing algorithms in a Unix environment to implement a processing
pipeline to annotate and rank the scientific articles given as input to
the pipeline.

*Data/Corpora*

The data that will be used for testing the automation process performed
with the pipeline will be taken on the one hand from the NLP4NLP corpus
[4][5] which contains 64953 articles representative of Natural Language
Processing literature over a period of 50 years
(http://www.nlp4nlp.org/) and on the other hand from the publication
database of the fluid mechanics and energy department of LIMSI.

*Research Profile*

Linguist, linguist-computer-scientist-NLPist, or computer scientist.
Specific experience in linguistics, knowledge managements, natural
language processing, information extraction or machine learning will be
appreciated. Depending on the research profile, focus can be put on the
formal definition of the criteria for interest sparking (linguistic
formalization) or on the precise information extraction aspect (criteria
identification) or also on machine learning for building the
representation of the research question of interest from a set of
articles and on its evaluation. In all cases, an autonomy for deploying
a corpus processing pipeline in a Unix environment is required (practice
of Python programming language will be a plus)."
"617","2020-01-06","LIMSI","Orsay","- Lieu : LIMSI, Orsay (91), RER B Le Guichet, Orsay-ville, ou 
  Gif-sur-Yvette + bus
- Durée : 5 mois, gratifications de stage et remboursement des frais de
  transports
- Niveau : M2
- Profil : formation en TAL, goût pour l'analyse des données
- Encadrants : Gilles Adda (gadda@limsi.fr) et Cyril Grouin
  (cyril.grouin@limsi.fr)

*Description*

Les médias entretiennent des rapports complexes avec la société. Ils
décrivent la société, mais en retour ils contribuent également à
façonner notre représentation du monde. Dans le cadre d'un projet plus
vaste, nous envisageons de décrire les différences objectives de
représentation et de traitement existant entre les femmes et les hommes
dans les médias. A ce titre, nous proposons un stage sur l'analyse des
transcriptions manuelles ou automatiques de la parole pour identifier le
genre des locuteurs.

Pour cela, plusieurs tâches sont possibles :
- catégoriser les entités nommées existantes en genre, soit parmi deux
  classes (femme/homme), soit parmi plusieurs classes
  (femme/homme/autre)
- étendre cette catégorisation en genre aux éléments linguistiques qui
  permettent d'identifier le genre
- identifier les thèmes et sujets évoqués dans le discours et dans les
  textes
- identifier les références à la vie privée (âge, physique, sexualité,
  vêtements, etc.)

Les travaux s'appuieront sur des corpus existants de transcription de la
parole (corpus Ester et Quaero Broadcast News). Des annotations existent
déjà en entités nommées (Quaero), et des méta-données sur les locuteurs
sont disponibles (Ester).

L'objectif final est de pouvoir s'appuyer sur les éléments identifiés à
l'occasion de ce stage pour analyser et décrire les différences de
traitement entre femme et hommes, par exemple lors des interruptions de
parole des femmes par les hommes (manterrupting), ou lors de
réexplications condescendantes par des hommes (mansplaining).

Profil de recherche

Linguiste, linguiste-informaticien(ne)-TAListe, ou informaticien(ne).
Des compétences en linguistique, traitement automatique des langues, et
extraction d'information seront appréciées. Dans tous les cas, une
autonomie pour la mise en place d'une chaîne de traitements dans un
environnement Unix est indispensable."
"618","2020-01-06","ATILF & IHRIM","Nancy ou Lyon","Titre: lemmatisation automatique de l'ancien français

Durée:  5 à 6 mois
Encadrement: Mathieu Constant (ATILF, Université de Lorraine) et Alexei
             Lavrentiev (IHRIM, ENS Lyon)

Lieu: laboratoire Analyse et Traitement Informatique de la Langue
      Française (ATILF), Nancy
      ou éventuellement, Institut d'Histoire des Représentations et des
      Idées dans les Modernités (IHRIM), Lyon

Gratification standard

Contact: Mathieu Constant (Mathieu.Constant@univ-lorraine.fr) et Alexei
Lavrentiev (alexei.lavrentev@ens-lyon.fr)

Compétences requises:
master de traitement automatique des langues ou linguistique
  informatique
bonnes compétences de programmation (python ou/et java)
le gout de mettre le nez dans les données

Description:

Le thème de recherche du stage s'inscrit dans le cadre du projet ANR
Profiterole (2017 - 2021). Ce projet a trois objectifs fortement
corrélés qui se situent dans les domaines de la linguistique et du
traitement automatique des langues (TAL).  Le premier objectif est de
modéliser les aspects morphologiques et syntaxiques de l'évolution
diachronique du français. Le deuxième objectif est de développer une
méthodologie pour explorer et annoter des données linguistiques
hétérogènes tout en fournissant des analyseurs automatiques pour
différents états du français. Le dernier objectif est d'augmenter la
couverture des ressources linguistiques existantes pour le français, en
construisant un corpus annoté de français médiéval (IXe - XVe siècles)
et des lexiques morphologiques couvrant plusieurs états du français.

Le stage sera dédié à la tâche de lemmatisation de l'ancien
français. Cette tâche consiste à automatiquement prédire la forme de
base d'une forme fléchie d'un mot apparaissant dans un texte dans le but
de rechercher ce mot dans des dictionnaires ou de neutraliser les
variations morphologiques. L'ancien français, qui est une langue
non-standardisée, est caractérisé par une variation morphologique bien
plus importante qu'en français moderne, ce qui complexifie la tâche de
lemmatisation. Par ailleurs, les données annotées manuellement pour
cette tâche sont rares ce qui rend difficile l'utilisation d'approches
reposant sur l'apprentissage automatique. Une autre difficulté est qu'il
n'existe pas de standard pour les formes lemmatisées en ancien français,
bien que des initiatives de standardisation soient en cours. Différentes
études se sont penchées sur le problème de la lemmatisation de l'ancien
français en utilisant diverses approches: par exemple, l'utilisation de
lexiques et de règles (Souvay et Pierrel 2009), l'utilisation d'outils
existants de lemmatisation réappris pour l'ancien français (Stein 2007,
Lavrentiev et al. 2017), l'utilisation d'une architecture neuronale
(Manjavacas et al. 2019).

L'objectif principal du stage est de développer un outil de
lemmatisation pour l'ancien français en s'appuyant sur des outils
existants, des corpus annotés et des ressources lexicales. Plus
particulièrement, les objectifs détaillés sont les suivants:

- lire la littérature sur la lemmatisation pour l'ancien français

- compiler et préparer les données disponibles 
- expérimenter divers lemmatiseurs existants adaptés aux données
  préparées
- développer un lemmatiseur reposant sur plusieurs sources d'information
  (ressources lexicales, corpus annotés et sorties des lemmatiseurs
  existants, plongements de mots)
- évaluer l'outil à la fois quantitativement et qualitativement


Références 

- Alexei Lavrentiev, Serge Heiden, and Matthieu Decorde. Building an
  Open Morphological Lexicon and Lemmatizing Old French Texts with the
  TXM Platform. In Corpus linguistics - 2017, Proceedings of the
  international conference ""Corpus linguistics - 2017"", pages 48-52,
  St-Pétersbourg, Russia, 2017. St-Petersburg State University and
  Institute for Linguistic Studies (RAS) and Herzen State Pedagogical
  University of Russia.
- Enrique Manjavacas, Ákos Kádár, and Mike Kestemont. Improving
  lemmatization of non-standard languages with joint learning. In
  Proceedings of the 2019 Conference of the North American Chapter of
  the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers), pages 1493-1503,
  Minneapolis, Minnesota, June 2019. Association for Computational
  Linguistics.
- Gilles Souvay and Jean-Marie Pierrel. LGeRM Lemmatisation des mots en
  Moyen Français. Traitement Automatique des Langues, 50(2):21, 2009.
- Achim Stein. Corpus-based perspectives in linguistics. In Yuji
  Kawaguchi, editor, Computing Machinery and Intelligence, pages
  217-229. Benjamins, 2007."
"619","2020-01-07","ViaDialog","Lannion","ViaDialog
Customer Interactions Management

VENEZ DÉVELOPPER LA RELATION CLIENT DU FUTUR AVEC NOUS !

RECHERCHE DATA SCIENTIST (H/F)

À PROPOS

Depuis 2004, ViaDialog innove dans l'industrie de la gestion des
interactions clients. Nos solutions SaaS permettent aux PME et aux
Grands comptes de communiquer avec leurs clients sur tous les canaux
via des téléconseillers et/ou des assistants virtuels. L'excellence
technique et la QoS sont au coeur de notre stratégie. Entreprise de 50
collaborateurs enthousiastes, ingénieux et audacieux, nous évoluons au
quotidien dans un marché stimulant et concurrentiel.

Nous recherchons un(e) stagiaire Data Scientist pour notre offre
ViaSpeech, notre ensemble de solutions (ASR, NLU, NLP) qui permet la
qualification, le traitement, l'analyse et l'automatisation des
dialogues clients vocaux.

RESPONSABILITÉS

En relation avec le Product Owner et en support aux équipes de
développement de la solution, vous serez amené(e) à :

- Accompagner les équipes de Viadialog dans la structuration des données.

- Accompagner les équipes de ViaDialog dans la constitution de corpus
  de données d'intérêt et tester le comportement de ces corpus.

- Identifier les marqueurs sémantiques propre à chaque corpus
  génériques.

- Accompagner les équipes techniques dans l'intégration des corpus
  génériques dans les solutions actuelles.

- Prendre part aux brainstormings, à la conception et à la promotion
  de la solution.

QUALIFICATIONS

Intérêt réel pour les chatbots et les voicebots et les technologies
d'analyse du langage naturel et de la reconnaissance vocale (STT, TTS,
Speaker recognition, Emotion Analysis, ...).

Autonome, curieux(se) et volontaire.

Compétences avancées en Python, Connaissance académique des
environnements et des framework de Machine Learning.

Formation de niveau Bac +5 dans le domaine de l'Intelligence
Artificielle ou du traitement Big Data.

INFOS

Ambiance stimulante dans un environnement en plein essor, conditions
de stage flexibles.

Perspectives d'évolution au sein de l'entreprise. Le stage est basé à
LANNION (22) avec des déplacements ponctuels à Paris.

Envoyez-nous votre lien linkedin (ou votre CV) par e-mail à
recrutement@viadialog.com"
"620","2020-01-15","Lattice","Montrouge","*** Modélisation de l'évolution des langues ***

Stage de M2 proposé par le laboratoire Lattice (Montrouge)

* Motivations et contexte

Il est aujourd'hui admis que le changement linguistique s'inscrit dans
un continuum. A. Kroch (1989) a ainsi mis au jour, pour certains
changements (par exemple, l'évolution du sens des mots), un schéma
d'évolution souvent qualifié de « courbe en S » (S-curve) : dans un
premier temps, les emplois augmentent lentement, gagnant progressivement
de nouveaux contextes, puis, dans un second temps, leur fréquence
s'accroît rapidement et pareillement en tous contextes, avant de
ralentir, formant ainsi une sorte de palier. Établir les temporalités
exactes - durée et rythme - n'est pas simple et suppose de travailler
sur un corpus suffisamment représentatif du ou des état(s) de langue
dans le(s) quel(s) s'inscrit l'évolution du phénomène.

Ce type d'évolution a été étudié et observé sur différents corpus et
différentes langues, notamment le français par Quentin Feltgen dans sa
thèse (2017). Le but du stage est de reprendre ce type d'expériences
pour d'autres langues (allemand, italien, espagnol...) pour lesquelles de
tels corpus existent.

A partir de scripts existants pour différentes bases de données
(français et anglais), il s'agira d'interroger une ou plusieurs bases de
données en passant des scripts, et de mener des analyses quantitatives
et qualitatives en collaboration avec des linguistes.

Ce stage s'inscrit dans le cadre du projet OpLaDyn (Understanding
Opinion and Language Dynamics using massive data - modélisation des
dynamiques sociétales et langagières), auquel participe le Lattice, en
collaboration avec d'autres laboratoires (physiciens du LPS et du LPTM
notamment).


* Modalités  

Stage de 6 mois maximum (début entre février et avril 2020), de niveau
M2, conventionné et indemnisé suivant les règles en vigueur. Le stage se
déroulera dans les locaux du Lattice à Montrouge (métro Mairie de
Montrouge).

* Profil recherché. 

Etudiant en linguistique-informatique ou en linguistique avec des
connaissances en programmation.

- Compétences en programmation (scripts python) et en TAL nécessaires.
- Des compétences en histoire de la langue seraient un plus. 

* Comment candidater ? 

Envoyer par mail un CV et un relevé de notes récent à
benjamin.fagard@ens.fr et thierry.poibeau@ens.fr, ainsi que quelques
mots expliquant votre intérêt pour ce stage dans le corps du mail."
"621","2020-01-15","ERIC","Lyon","Titre du stage : Recommandation de liens dans un réseau d'auteurs
Contact : julien.velcin@univ-lyon2.fr
Durée: 4 à 6 mois
Gratification : environ 600 euros par mois
Localisation : Laboratoire ERIC, Université Lyon 2 (campus de Bron)
Début du stage : Mars-Avril 2020 (possibilités de commencer plus tôt si besoin)
Mots clefs : data science, natural language processing, machine
learning, representation learning, topic modeling, digital humanities

## Contexte général

Le projet LIFRANUM (Littératures FRAncophones Numériques), financé par
l'Agence Nationale de la Recherche pour une période allant de 2020 à
2023, vise à analyser l'impact des modifications des supports de l'écrit
sur les pratiques littéraires. Il regroupe des chercheurs de l'équipe
MARGE (Université Lyon 3) et du laboratoire ERIC (Universités Lyon 2 et
Lyon 1), en partenariat avec la Bibliothèque nationale de
France. L'ambition du projet est notamment de construire une plateforme
en ligne qui permettra de faciliter l'analyse des créations littéraires
sur le Web par les chercheurs en information-communication et en
littérature.

## Objectif du stage

Dans le cadre du projet LIFRANUM, nous cherchons un stagiaire en
Informatique afin de pouvoir tester plusieurs algorithmes de la
littérature (informatique) pour suggérer de nouveaux liens dans le
réseau des auteurs des textes produits sur les supports numériques (par
ex. site web personnel, blog), mais également pour proposer des
algorithmes originaux. Pour bien débuter, le stagiaire pourra s'appuyer
sur des travaux en cours menés par des chercheurs du laboratoire ERIC
sur l'apprentissage de représentation (representation learning)
d'auteurs. Il aura accès à des données récupérées dans le cadre du
projet, mais il travaillera également sur un jeu de données déjà
collectées au sein du laboratoire.

## Ce qu'il faut faire

Les tâches prioritaire à réaliser sont les suivantes :

- Etudier les travaux récents en apprentissage de représentations à
  partir de réseaux de documents textuels, en particulier ceux
  développés au sein du laboratoire (partie état de l'art).
  
- Prendre connaissance des données fournies pour le stage (banc d'essaie
  et données du projet).
  
- Mettre en pratique des méthodes basées sur l'apprentissage de
  représentation et sur la modélisation.
  thématique afin de suggérer des liens entre documents et auteurs.
- Implémenter au moins une méthode originale développée par les
  chercheurs du laboratoire, en collaboration avec le stagiaire.
- Intégrer cette solution dans un logiciel actuellement en cours de
  développement au sein du laboratoire.

## Profil recherché

Nous recherchons un candidat ayant des compétences solides en
analyse/fouille de données, en programma- tion (Python de préférence) et
si possible des notions de traitement automatique des langues (natural
language processing) / fouille de données textuelles (text mining) et
d'apprentissage automatique (machine learning). Un intérêt pour le
travail pluridisciplinaire serait un plus.

## Déroulement du stage

Le stage se déroulera dans les locaux du laboratoire ERIC, sur le campus
de Bron (à environ 30 min. du centre-ville de Lyon en tram). Il sera
encadré par un enseignant-chercheur permanent accompagné par un étudiant
en Doctorat travaillant sur les thématiques du stage. Une réunion
hebdomadaire est prévue, en plus des réunions organisées pour le projet
LIFRANUM.

## Poursuite du stage possible

Un financement de thèse pour 3 ans est prévu à partir de septembre
2020. Si le stage donne satisfaction et que l'étudiant est intéressé,
celui-ci constitue un candidat privilégié pour obtenir cette allocation.

## Procédure de candidature

Les candidats doivent envoyer les documents suivants à l'adresse
julien.velcin@univ-lyon2.fr avant le 15 janvier 2020 :

- CV
- lettre de motivation
- relevés de notes des deux dernières années

Les candidats retenus seront convoqués pour un entretien durant la
deuxième quinzaine du mois de janvier. Les résultats devraient être
communiqués dans la première semaine de février."
"622","2020-01-15","IGN","Saint-Mandé","Constitution d'une base de connaissances sur la réorganisation du
maillage administratif de la France lors de la Révolution

Contexte

L'Institut National de l'Information Géographique et Forestière (IGN)
produit pour sa mission de service public des référentiels
géographiques avec une certaine profondeur temporelle destinés à
l'analyse des évolutions du territoire national. Le laboratoire LASTIG
travaille ainsi depuis de nombreuses années avec des historiens pour
constituer des référentiels de données spatio-temporelles décrivant
les transformations du territoire dans le temps long. L'une de ces
collaborations reconstitue la création et l'évolution du maillage
communal français depuis le 18 e siècle. L'historique des
transformations communales depuis 1795 ainsi que la cartographie des
paroisses religieuses de l'Ancien Régime sont très avancés. Le dé but
de la période Révolutionnaire (1789-1794) est peu couvert, pourtant il
a vu les paroisses être réorganisées pour former les futures
communes. Cette réorganisation est mal connue et aucune base de
données spatio-temporelle la décrivant n'existe encore. Les
informations permettant la constitution d'une telle base existent
pourtant sous la forme de texte légaux promulgués par l'Assemblée
Nationale Constituante et les assemblées de district en 1790-1791
(voir figure 1). Ce stage porte sur l'extraction automatique et la
géolocalisation des informations contenues dans ces textes historiques
pour construire une base de connaissances géohistoriques des
remembrements paroissiaux sous la Révolution française, premier
chaînon manquant entre paroisses d'Ancien Régime et premières
communes.

Un premier stage a abouti à la mise en place d'une chaîne de
traitement montrant la faisabilité de l'extraction, de la
structuration et de la géolocalisation automatique des informations à
partir d'un échantillon de textes (Keller, Abadie, Dumenieu, Baciocchi
& Kergosien, 2018). Cette première proposition présente toutefois
plusieurs limites :

- La relative variabilité des textes est encore mal prise en compte,
réduisant la généricité de la chaîne d'extraction.

- Les textes décrivent l'évolution des paroisses à deux niveaux de
  granularité : le territoire et les lieux de culte. Seul le niveau du
  territoire est actuellement pris en compte.

- La géolocalisation est gênée par la variabilité des formes écrites
  des toponymes.

Figure 1 - Un extrait de décret de l'Assemblée Nationale portant sur
la réorganisation des paroisses du département du Puy de Dôme. Extrait
de l'article 25 - 1 er juin 1791

Objectif du stage

L'objectif du stage est double :

1. améliorer la chaîne d'extraction automatique des informations
spatio-temporelles à partir des textes,

2. améliorer l'approche de géolocalisation des lieux cités dans les
textes (on parle d'entités spatiales nommées ou ESN).

Dans les deux cas, on s'appuie sur une base de données de toponymes
produite par vectorisation de la carte de Cassini (voir figure 2),
quasi contemporaine des textes et présentant un niveau de détail
équivalent. Les toponymes de la carte de Cassini sont ainsi très
susceptibles d'être mentionnés dans les textes sur les remembrements
paroissiaux.

Cette base de toponymes est exploitée par la chaîne d'extraction des
informations spatiotemporelles pour faciliter l'identification des
portions de textes désignant des entités spatiales nommées,
c'est-à-dire des noms de lieux éventuellement accompagnés de
descripteurs (p.ex. ""l'église paroissiale de Bourg-Lasticq"", ""le
hameau de Laveix""). Ne disposant pas d'un corpus pré-annoté, cette
chaîne de traitement a été implémentée à l'aide de lexiques et de
patrons lexico-syntaxiques. Ceux-ci ont cependant été définis pour un
corpus restreint et manquent parfois de généricité :

- Si la majorité des entités spatiales mentionnées sont des toponymes
seuls ou éventuellement accompagnés d'un descripteur, certains textes
comportent néanmoins des entités spatiales étendues nécessitant un
traitement adéquat.

- L'extraction des relations spatio-temporelles entre paroisses repose
sur une approche essentiellement lexicale et reste largement
perfectible. Elle gagnerait notamment à traiter l'expression
""ci-devant"", très utilisée pendant la Révolution, qui fait référence
au caractère révolu de l'information mentionnée à sa suite (p.ex. ""la
partie du village de Jouffreits ci-devant dépendant de la paroisse de
Charbonnières-lès-vieilles"").

Figure 2 - Extrait de la feuille 12 de la carte de Cassini sur la
Creuse. Les lieux nommés en gras et symbolisés par un clocher sont des
chefs-lieux de pa- roisses ; le clocher représente l'église
paroissiale. Source gallica.bnf.fr / BnF
https://gallica.bnf.fr/ark:/12148/btv1b53095185n/

- L'extraction des informations sur les lieux de culte permettrait de
compléter les infor mations relatives au territoire des paroisses,
notamment dans le cas des paroisses urbaines jusqu'ici non traitées
car ne figurant pas sur la carte de Cassini. La base des toponymes de
Cassini est aussi utilisée pour géolocaliser les ESN extraites des
textes. À chaque mention d'ESN extraite du texte sont associés les
lieux de la carte de Cassini qui peuvent lui correspondre à l'aide
d'une mesure de similarité de chaînes de caractères. Chacune de ces
listes de lieux candidats est ensuite ordonnée d'après la distance de
chaque lieu à la médiane marginale de l'ensemble des lieux candidats
des autres ESN présentes dans le même article que celle en cours de
désambiguïsation. L'analyse des résultats obtenus via cette approche
révèle deux principaux points d'amélioration :

1. La mesure de similarité de chaînes de caractères utilisée s'appuie
sur une distance d'édition, ce qui présente des limites importantes
dès lors que les ESN et les toponymes sont orthographiés
différemment. Or l'hétérogénéité des graphies de toponymes est encore
très présente au XVIIIe siècle. Le passage à une similarité fondée
sur la phonétique des toponymes est une piste d'amélioration majeure.

2. La médiane marginale est une approximation du point central de la
distribution spatiale des lieux candidats qui a l'avantage de la
simplicité. Le classement des candidats pourrait être amélioré par une
meilleure approximation comme la médiane géométrique.

Compétences et formation requises

Compétences et connaissances
- Extraction d'informations à partir de textes
- Résolution d'Entités Spatiales Nommées
- Apprentissage automatique
- Données géographiques vectorielles
- Web de données
- Un intérêt pour les données anciennes et la linguistique est un plus

Formation

Master 2 ou troisième année d'école d'ingénieur en informatique,
traitement automatique des langues ou en géomatique avec une forte
composante informatique.  Selon le profil du candidat, l'un ou l'autre
des deux principaux objectifs du stage pourra être plus
particulièrement développé.

Informations pratiques

Durée et période de stage

5 mois, printemps-été 2020

Lieu du stage

Equipe LaSTIG/STRUDEL de l'Institut National de l'Information
Géographique et Forestière (IGN), à Saint-Mandé (métro 1, station
Saint Mandé). Le stage se déroulera dans l'équipe STRUDEL menant des
recherches en géomatique sur les structures spatio-temporelles pour
l'analyse des territoires.

Indemnités de stage

Stage gratifié selon la législation française.

Modalités de candidature

Envoyer CV et lettre de motivation ciblée sur le sujet par email au format PDF et en un seul fichier aux encadrants listés ci dessous.

Encadrement du stage

Nathalie Abadie [STRUDEL/IGN] : nathalie-f.abadie[at]ign.fr

Éric Kergosien [GERiiCO/SID/Université Lille 3] : eric.kergosien[at]univ-lille3.fr

Bertrand Duménieu [CRH/EHESS] : bertrand.dumenieu[at]ehess.fr

Stéphane Baciocchi [CRH/EHESS] : stephane.baciocchi[at]ehess.fr

Références

Keller, A., Abadie, N., Dumenieu, B., Baciocchi, S. & Kergosien,
E. (2018). Vers la construction d'une base de connaissances sur la
réorganisation territoriale française à la Révolution. In Conférence
Sagéo 2018 Atelier Exces, Récupérée à partir de
https://hal.archives-ouvertes.fr/hal-02399176/"
"623","2020-01-21","Litt&Arts","Grenoble","Stage « TAL pour les corpus en littérature »
Équipe Littératures, Arts et Numérique (ELAN)
au sein du laboratoire Litt&Arts (UMR 5316), Grenoble
Année 2020

En appui à nos projets de recherche, nous proposons 1 stage de 4 à 6
mois en enrichissement de corpus numériques TEI.

Spécialité recherchée : traitement automatique des langues et corpus
textuels

Profil du candidat : étudiant·e en TAL ou linguistique outillée ayant
un intérêt pour les corpus littéraires et la TEI ou étudiant·e dans
l'une des disciplines des SHS dans une filière à très forte coloration
numérique et/ou informatique

Contexte

Au sein de l'UMR Litt&Arts, ELAN est une équipe d'ingénieur·e·s
accompagnant les projets de recherche de l'unité. De nombreux projets,
qu'ils traitent de manuscrits, de correspondances, de bibliographies
ou d'autres types de données, nous amènent à manipuler des corpus en
TEI (de leur modélisation à leur visualisation en ligne en passant par
des outils de recherche). Le stage propose de travailler sur les
données d'un ensemble de projets choisis et de concevoir - selon les
cas et les objectifs du projet - une ou plusieurs approches utilisant
des outils et méthodes issues du TAL afin d'enrichir les corpus, leur
visualisation ou encore les exploitations faites de ces données.

Objectifs du travail

Le stagiaire devra, sous la responsabilité de deux ingénieures d'ELAN :

- étudier les spécificités des corpus littéraires vs les corpus
linguistiques et identifier les besoins de nos projets ;

- faire un état de l'art d'outils utilisés en linguistique et en TAL
pour répondre à ces besoins ;

- compiler les corpus issus de différents projets partageant une même
problématique afin de constituer un ensemble conséquent ;

- tester différents outils et méthodes pour analyser le corpus ainsi
constitué ;

- documenter ces tests et rédiger des méthodologies à destination
d'utilisateurs néophytes ou peu formés.

Compétences recherchées

- bonne connaissance du domaine du TAL ;
- bonnes capacités rédactionnelles ;
- lecture courante de l'anglais ;
- la connaissance du format XML, voire de la TEI sera appréciée ;
- capacité d'organiser son propre travail avec rigueur.

Nous attendons du ou de la candidate un goût certain pour la
transmission du savoir et des capacités didactiques. En effet, les
documentations devront viser une autonomie maximale des membres des
projets, tant sur la mise en oeuvre de l'outil ou de la méthode que sur
l'utilisation, l'exploitation et l'interprétation des résultats.

Cadre du stage

La·e stagiaire sera accueilli au sein du Laboratoire Arts et pratique
du texte, de l'image, de l'écran et de la scène (Litt&Arts, UMR 5316,
UGA/CNRS). Il ou elle sera accompagné·e dans son travail par deux
encadrantes et travaillera en collaboration avec plusieurs
chercheuse·eur·s de l'unité.

Durée et date de début du contrat

Le stage est prévu au printemps-été 2020.
 
Répondre à l'offre

Les candidats doivent envoyer :

(1) un CV, (2) une lettre de motivation et (3) une lettre de recommandation d'un
enseignant
par mail, ayant comme objet :
[Stage ELAN] Candidature de M/Mme Prénom NOM
à:
Anne Garcia-Fernandez : annegf@univ-grenoble-alpes.fr
Elisabeth Greslou : gresloue@univ-grenoble-alpes.fr"
"624","2020-01-21","Datalab Groupe Crédit Agricole","Montrouge","Stage : Assistant Infolinguiste au sein du DataLab Groupe Crédit
Agricole SA
========================================================================

Au sein du Pôle Développement Clients et Innovation, le DataLab Groupe
Crédit Agricole est un centre de compétences dédié aux sciences de la
donnée et à leurs applications dans le domaine bancaire. Son rôle est de
créer des approches innovantes pour la valorisation de la donnée interne
et externe, qu'elle soit structurée ou non structurée. Dans le cadre de
ses missions, des thématiques scientifiques à forte valeur ajoutée sont
étudiées : Apprentissage Automatique, Auto-ML, Traitement du Langage
Naturel, Process Mining, Time Series Mining, Deep Learning, Géomatique,
etc. Ces activités sont menées conjointement avec des partenaires
internes : les Caisses Régionales, les Entités du Groupe et les
Producteurs Informatiques. Le DataLab développe également un réseau de
partenaires externes lors de missions industrielles (Editeurs de
logiciels, startup, SSII, etc.) ou de collaborations universitaires.

Dans le cadre de ce stage, vous rejoindrez l'équipe Data Science afin de
contribuer à la valorisation de la Data et participer à la création
d'une base de connaissance au service des Clients du Groupe.

Descriptif du stage :

Contexte et objectifs du stage :

Dans l'industrie bancaire, les corpus textuels internes ou externes sont
nombreuses et exploitées par différents métiers de la banque:
conformité, marketing et communication, conseil, etc. Les experts
métiers ont souvent recours à ces corpus au quotidien, pour réaliser
différentes tâches d'analyse sémantique d'une façon manuelle ou
semi-manuelle : extraction de l'information pertinente, reconnaissance
de type de document, recherche d'information, etc. Ces tâches sont le
plus souvent consommatrices en temps et effort humain.

L'équipe IA sémantique du DataLab développe des méthodes automatiques
basées essentiellement sur le machine learning et l'analyse sémantique
qui permettent de faciliter le travail des experts et simplifier leur
accès à l'information pertinente. Dans le cadre de développement d'un
modèle ML, l'équipe doit souvent construire un corpus de textes annotés
qui sert en tant que corpus d'apprentissage pour le modèle. Vu que la
performance du modèle dépend fortement de la qualité des données
annotées, l'annotation représente une phase capitale du projet.

L'objectif du stage consiste à participer à la mise en oeuvre d'une
chaîne complète d'annotation dans le cadre d'un projet de l'IA
sémantique : à partir de construction d'un plan de classement jusqu'à
l'implémentation de métriques afin d'établir la consistance de données
annotées. Une partie importante de stage sera consacrée à l'annotation
manuelle d'un ou plusieurs corpus à l'aide d'un logiciel collaboratif
dédié et selon des consignes d'annotation détaillées. Finalement, un
sujet R&D dans le domaine TAL (analyse de sentiments/émotions) sera
proposé qui permettra de mettre en valeur un corpus annoté.

Organisation et livrables :

Le stage se déroulera en quatre étapes principales, sous l'encadrement
d'un infolinguiste expérimenté :

- Participation dans la mise en place d'une chaîne complète d'annotation
  : construction de plan de classement, rédaction de consignes
  d'annotation, annotation manuelle, revue de résultats en équipe

- Réalisation d'un état de l'art sur les techniques d'annotation et de
  métriques de performances (par exemple, l'accord inter-annotateurs)

- Développement des briques d'évaluation de qualité d'annotation et leur
  intégration dans la plateforme sémantique du DataLab

- Travail sur un sujet R&D dans le domaine d'analyse de
  sentiments/émotions

Compétences techniques ou spécifiques au poste:


- Traitement de langage naturel (NLP)

- Linguistique

- Développement python


Compétences générales et transverses :


- Ecoute, partage et communication

- Grande rigueur et autonomie

- Aptitude pour le travail en équipe

- Une expérience en annotation manuelle de textes serait un plus

Outils informatiques :

- Librairies de développement :  Scikit-learn, NLTK, Spacy, etc.

- Outils : Gate, Unitex, Protege, outils d'annotation


Durée : 6 mois
Lieu de travail : DataLab Groupe  (Montrouge)
Date de démarrage souhaitée : mars/avril 2020
Rémunération : selon profil
Candidature : envoi d'un CV, lettre de motivation
Contacts:
Aymen SHABOU (aymen.shabou@credit-agricole-sa.fr),
Yulia KOLOSKOVA (yulia.koloskova@credit-agricole-sa.fr)"
"625","2020-01-21","INRIA","Rennes","The digital world is offering an amazing range of possibilities for
everyone, especially for people with disabilities. Come and join us as
a Master 2 intern to leverage new technologies to offer life-changing
solutions for people with visual impairment.

Towards Large-Scale Evaluation Protocols for the Visually Impaired

Pierre Kornprobst, Senior research scientist, BIOVISION Lab, Inria
Jean-Charle Régin, full professor and head of the C&A Lab of the I3S, CNRS
Aurelie Calabrese, Junior research scientist, BIOVISION Lab, Inria

CONTEXT: In 2015, 405 million people were visually impaired around the
globe, against `only` 285 million in 2010 [1]. Almost half of it could
have been prevented by earlier interventions in the form of treatment
or rehabilitation. Because of aging, and its strong correlation with
eye disease prevalence, this number is only expected to grow. To
address this global health problem, actions must be taken to design
effective solutions for earlier and more decisive detection of visual
pathologies.

PROBLEM: Since reading speed is a strong predictor of visual ability
and vision-related quality of life for patients with vision loss,
reading performance has become one of the most important clinical
measures for judging the effectiveness of treatments, surgical
procedures or rehabilitation techniques.  Accurate measurement of
reading performance requires highly standardized reading test, such as
the MNREAD acuity chart [2]. This test, available in 19 languages,
allows to measure reading performance in people with normal and low
vision. In brief, performance is measured from the time needed to read
a series of short sentences that were designed to be equivalent in
terms of linguistics, length and layout. To ensure accurate
measurement, each sentence must be presented only once to avoid
introduction of a memorization bias. However, because of their highly
constrained nature, MNREAD sentences are hard to produce, leading to a
very limited number of test versions (only two in French). Given that
repeated measures are needed in many applications of MNREAD, there is
a strong interest from the scientific and medical communities for a
much larger pool of sentences.

STATE-OF-THE-ART: Very recently, a method for computer-generated
sentences has been explored by the MNREAD creators themselves
[3]. However, this semi-automated method presents several major
drawbacks: (1) it relies on sentence templates that must be created
manually (i.e., sequences of placeholders, each containing a list of
possible words that fit into the sentence at that point); (2) it works
in two stages (i.e., sentence creation followed by sentence selection)
implying additional calculations and longer execution time; (3) it can
not be extended to other languages.

SHORT-TERM OBJECTIVE (Internship research program): Fully automated
generation of constrained text is a very complex task. The problem
that we must solve here is to generate a very large number of
sentences, while taking into account very strict linguistics, length
and layout rd constraints, such as: fixed number of characters,
restricted vocabulary (3 grade level), tightly constrained physical
layout, etc. To tackle this matter, one approach we will consider is
oriented towards the automatic production of constrained text from a
corpus. However, to further extend the test capabilities, we must keep
the option to modify these constraints along the course of our
project. Therefore, it is crucial to consider methods based on
constraints satisfaction, such as those developed by J.C. Régin at
I3S, in collaboration with the Sony Computer Science Lab [4]. These
methods are essentially based on multivalued decision diagrams and the
operations that allow them to be manipulate [5,6,7], and have already
proven to be efficient [8].

PERSPECTIVE: In the short run, the MNREAD Android app will serve as a
research tool, allowing for instance to generalize the principles of
the test to evaluate the effects on reading of dependent variables
other than print size e.g., evaluate the readability of a new
typeface, letter spacing and line length. In the long run, the MNREAD
Android app may be commercialized to serve as a valuable tool in
clinical settings.

BIBLIOGRAPHY:

[1] Bourne, R., et al. (2017) Magnitude, temporal trends, and
projections of the global prevalence of blindness and distance and
near vision impairment: a systematic review and meta-analysis. The
Lancet Global Health, Volume 5, Issue 9, e888 - e897

[2] Mansfield J.S., Ahn S.J., Legge G.E., Luebker A. (1993) A new
reading-acuity chart for normal and low vision. Ophthalmic and Visual
Optics/Noninvasive Assessment of the Visual System Technical Digest,
(Optical Society of America, Washington, DC., 1993.) 3: 232--235.

[3] Mansfield, J.S., Atilgan, N., Lewis, A.M., Legge, G.E. (2019)
Extending the MNREAD sentence corpus: Computer-generated sentences for
measuring visual performance in reading. Vision Research, 158, 11-18.

[4] Papadopoulos, A., Roy, P., Régin, J.-C., Pachet, F. (2015)
Generating all Possible Palindromes from Ngram Corpora. IJCAI 2015:
2489-2495

[5] Perez, G., Régin, J.-C. (2015) Efficient Operations On MDDs for
Building Constraint Programming Models. IJCAI 2015: 374-380

[6] Perez, G., Régin, J.-C. (2017) Soft and Cost MDD Propagators. AAAI
2017: 3922-3928

[7] Perez, G., Régin, J.-C. (2018) Parallel Algorithms for Operations
on Multi-Valued Decision Diagrams. AAAI 2018: 6625-6632

[8] Perez, G., Régin, J.-C. (2017) MDDs: Sampling and Probability
Constraints. CP 2017: 226-24

SUPERVISORS: The candidate will be co-supervised by P. Kornprobst, a
mathematician with strong expertise in computer vision and human
vision understanding, J.C. Régin, a world-wide known specialist in
constraint programming, and A. Calabrèse, a psychophysicist
specialized in visual neuroscience with a strong clinical expertise.

CONDITIONS:
- Duration: 6 months
- Starting date: February/March 2020
- Where: Inria Sophia Antipolis - Méditerranée, France (https://www.inria.fr/en/centre/sophia).
- Salary: approx. 550 euros per month.

CURRICULUM OF THE CANDIDATE: Applicants should have a keen interest in
linguistic, low vision or both, and a relevant Master, for example in
natural language processing, computer science, digital humanities or
linguistics.

FOLLOW-UP: Funding opportunities to continue for a 4 year
Ph.D. including a six month period in the US.

TO APPLY: Please visit https://team.inria.fr/biovision/job-offers."
"626","2020-01-21","INRIA","Rennes","The digital world is offering an amazing range of possibilities for
everyone, especially for people with disabilities. Come and join us as
a Master 2 intern to leverage new technologies to offer life-changing
solutions for people with visual impairment.

Development of an Android Application to Measure Reading
Performance in both Clinical and Research Environments

Aurelie Calabrese, Junior research scientist, BIOVISION Lab, Inria
Pierre Kornprobst, Senior research scientist, BIOVISION Lab, Inria

CONTEXT: The MNREAD ACUITY CHART is a standardized reading test has
been designed to measure the reading performance of people with normal
and low vision [1] (see also video [2]). Its prominent use worldwide
in both clinical and research settings makes it a strong diagnostic
tool for reading deficit. In brief, the MNREAD allows to measure how
reading performance changes when print size decreases, by presenting a
series of short sentences with decreasing size printed on cardboard.

PROBLEM: To respond to the rapid transition to digital reading in our
culture, the time has come to adapt reading-acuity measures to
evaluate legibility on digital displays. Therefore, the creators of
the MNREAD have recently developed an electronic version of the MNREAD
test, running on iOS: the MNREAD iPad App ©2017 [3,4]. This digital
transition will help standardize reading assessment in several ways:
(a) through unified testing and scoring methods that increase inter-
tester reliability; (b) by promoting data sharing and
portability. However, the MNREAD test is not yet available on Android,
while many clinics use this platform for patient-care and data
collection.

METHOD: Our main objective is to develop an Android application that
will replicate the MNREAD iPad App, while bringing new
features. Throughout the developing process, e-ink tablets will be
used (e.g., BOOX 13.3""). Once development is completed, the same
devices will be used for experimental validation through
within-subject comparison.

PERSPECTIVE: In the short run, the MNREAD Android app will serve as a
research tool, allowing for instance to generalize the principles of
the test to evaluate the effects on reading of dependent variables
other than print size e.g., evaluate the readability of a new
typeface, letter spacing and line length. In the long run, the MNREAD
Android app may be commercialized to serve as a valuable tool in
clinical settings.

BIBLIOGRAPHY:

[1] Mansfield JS, Ahn SJ, Legge GE, Luebker A (1993) A new
reading-acuity chart for normal and low vision. Ophthalmic and Visual
Optics/Noninvasive Assessment of the Visual System Technical Digest,
(Optical Society of America, Washington, DC., 1993.) 3: 232--235.

[2] VIDEO of the classical MNREAD test:
https://www.precision-vision.com/mn-read-testing- demonstration/

[3] Calabrèse, A., To, L., He, Y., Berkholtz, E., Rafian, P., & Legge,
G. E. (2018a). Comparing Performance on the MNREAD iPad Application
with the MNREAD Acuity Chart. Journal of Vision, 18(1),
8. http://doi.org/10.1167/18.1.8

[4] MNREAD iPad App ©2017 - Version 1.5 Legge G.E., Calabrèse A., To
L., Mansfield J.S., Bigelow C.  Apple App Store -
https://itunes.apple.com/us/app/mnread/id1196638274?ls=1&mt=8

SUPERVISORS: The candidate will be co-supervised by A. Calabrèse, a
psychophysicist specialized in visual neuroscience with a strong
clinical expertise, and P. Kornprobst, a mathematician with strong
expertise in computer vision and human vision understanding.

CONDITIONS:
- Duration: 6 months
- Starting date: February/March 2020
- Where: Inria Sophia Antipolis - Méditerranée, France
  (https://www.inria.fr/en/centre/sophia).
- Salary: approx. 550 euros per month.

CURRICULUM OF THE CANDIDATE: Applicants should have experience in
developing Android applications, a keen interest in user experience,
low vision or both, and a relevant Master, for example in computer
science, linguistics, digital humanities or natural language
processing.

FOLLOW-UP: Funding opportunities to continue for a Ph.D.

TO APPLY: Please visit https://team.inria.fr/biovision/job-offers."
"627","2020-01-21","GEOLSemantics","Gentilly","Contexte

Créée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans
le domaine des technologies de l'information et de la communication, et
plus particulièrement dans le domaine de l'extraction
d'informations. Les solutions de GEOLSemantics analysent les contenus
textuels pour identifier, normaliser et structurer les données
pertinentes qu'ils contiennent, afin de les rendre directement
exploitables par des processus automatiques.

Mission

Dans le cadre d'un projet sur l'apport des technologies de NLP pour le
domaine de la santé, nous proposons un stage afin de mettre au point un
système de détection des intentions suicidaires à partir de messages
écrits sur les réseaux sociaux. Pour cela, nous nous baserons sur une
étude réalisée par l'INSERM, sur l'expression du mal-être et des
intentions de suicide. Le stage consistera donc à implémenter les
résultats de l'étude dans notre système, pour le français mais aussi
pour l'anglais, ainsi que de participer à la réalisation du produit
final, qui générera des alertes en fonction du degré d'urgence exprimé
dans les messages.

Le stage se découpera de la manière suivante :

* Enrichissement de l'ontologie métier de GEOLSemantics pour la
  détection des intentions suicidaires,

* Enrichissement des analyses anglais et français afin d'extraire tous
  les critères nécessaires,

* Mise en place du calcul de probabilité permettant de classer les
  messages arrivants selon ce qu'ils contiennent (RAS, état inquiétant,
  état urgent),

* Mise en place du processus d'alerte pour les états inquiétants et
  urgents,

* Test sur un corpus représentatif.

Il sera aussi demandé, à chaque phase, de réaliser la documentation
nécessaire.

Formation

Master en informatique et linguistique

Langues

Français et anglais
Autres langues bienvenues

Environnement technique

* Méthodologie Agile (Scrum)
* Outils 
 * Gestion de versions (SVN) 
 * Gestion de production (Maven) 
 * Intégration continue (Jenkins) 
 * Environnement de développement (Eclipse et/ou Netbeans) 

* Développement (Python, Java) 
* Base de données (SGBD-R, NO SQL, Base de connaissance, web sémantique) 
* Format d'échange (XML, RDF) 
* Système d'exploitation (Windows, Linux) 

Autres compétences

* Autonomie
* Bonne aisance rédactionnelle
* Capacité à communiquer avec les membres de l'équipe

Caractéristiques du stage

* Durée : minimum 6 mois
* Date de début : avril 2020
* Lieu : Gentilly

Pour postuler, envoyez votre candidature à
christian.fluhr@geolsemantics.com

www.geolsemantics.com"
"628","2020-01-21","GEOLSemantics","Gentilly","Contexte :

Créée en 2009, GEOLSemantics est un éditeur de logiciels innovants dans
le domaine des technologies de l'information et de la communication, et
plus particulièrement dans le domaine de l'extraction
d'informations. Les solutions de GEOLSemantics analysent les contenus
textuels pour identifier, normaliser et structurer les données
pertinentes qu'ils contiennent, afin de les rendre directement
exploitables par des processus automatiques.

Mission :

Dans le cadre de l'amélioration continue de notre solution globale
d'extraction d'informations, nous proposons un stage en NLP afin de
désambiguïser les lieux pouvant référer à plusieurs endroits dans les
textes. Pour cela, nous nous baserons sur des systèmes géographiques
existants, en les adaptant à notre besoin, afin d'enrichir notre Système
d'Information Géographique stocké dans une base ElasticSearch, ainsi que
sur des ontologies existantes et propriétaires, et la contextualisation
à travers le texte, afin d'identifier de quel lieu il s'agit lorsque le
nom est ambigu.

Le stage se découpera de la manière suivante :

* Récupération de systèmes géographiques mondiaux existants
  (OpenStreetMap, Geonames), transformation au format souhaité, et
  intégration dans ElasticSearch

* Adaptation du système géographique pour la désambiguïsation
  (suppression des doublons, ajout d'inclusions manquantes)

* Création des corpus de développement et de test

* Étude des critères de désambiguïsation, par exemple la distance
  séparant deux lieux, dans le cadre de :

 * textes journalistiques,
 * messages de forums,

* Implémentation du système de désambiguïsation des lieux afin d'obtenir
  leurs coordonnées GPS

* Test sur un corpus représentatif.

Il sera aussi demandé, à chaque phase, de réaliser la documentation
nécessaire.

Formation

  Master en informatique et linguistique

Langues

  Français
  Autres langues bienvenues

Environnement technique

* Méthodologie Agile (Scrum)
* Outils 
 * Gestion de versions (SVN) 
 * Gestion de production (Maven) 
 * Intégration continue (Jenkins) 
 * Environnement de développement (Eclipse et/ou Netbeans) 

* Développement (Python, Java) 
* Base de données (SGBD-R, NO SQL, Base de connaissance, web sémantique,
  ElasticSearch)
* Format d'échange (XML, RDF) 
* Système d'exploitation (Windows, Linux) 

Autres compétences

* Autonomie
* Bonne aisance rédactionnelle
* Capacité à communiquer avec les membres de l'équipe

Caractéristiques du stage

* Durée : minimum 6 mois
* Date de début : avril 2020
* Lieu : Gentilly

Pour postuler, envoyez votre candidature à
christian.fluhr@geolsemantics.com

www.geolsemantics.com
GEOLSemantics - Analyse des textes      
Analyse des textes"
"629","2020-02-24","EDF R&D","Palaiseau","Offre de stage Master 2 dans le domaine du text mining

Libellé stage : Exploration, analyse, modélisation et représentation de
données pour la recherche et la visualisation d'information avec Open
Semantic Search et sa base Apache Lucene / Solr.

Durée : 6 mois

Lieux : EDF R&D Lab Saclay et déplacements sur sites industriels en
France

Tuteurs : Julien Kahn, Lydia Ould Ouali

Contacts : julien.kahn@edf.fr et lydia.ould-ouali@edf.fr

Entreprise : EDF Recherche & Développement Lab Saclay - Département
PErformance et prévention des Risques Industriels du parC par la
simuLation et les EtudeS (PERICLES) - groupe Facteurs Organisationnels
et Humains (FOH)

Adresse : 7, boulevard Gaspard Monge 91120 PALAISEAU, FRANCE

Contexte industriel

L'approvisionnement en énergie compte parmi les enjeux politiques,
économiques et écologiques décisifs pour l'avenir. La satisfaction de la
demande énergétique mondiale et le respect des objectifs internationaux
de lutte contre le changement climatique imposent de développer des
énergies décarbonées. Le nucléaire apparaît ainsi comme un élément du
mix énergétique du futur.

Dans ce domaine où l'ensemble des intervenants doit être irréprochables
en matière de sûreté et de radioprotection, l'exploitant doit respecter
les Règles générales d'exploitation (RGE). Les RGE sont un recueil de
règles approuvées par l'Autorité de Sûreté Nucléaire qui définissent le
domaine autorisé de fonctionnement de l'installation et les
prescriptions de conduite associées. En effet, tel le Code de la Route,
les RGE regroupent l'ensemble des consignes à respecter par les
exploitants, pour garantir le meilleur niveau de sûreté de leurs
centrales.

Dans le cadre des réflexions associées à la transition numérique du
groupe EDF, il s'agit de participer à la réflexion sur comment
l'intégration d'outils « intelligents » du Traitement Automatique de la
Langue (TAL) écrite peut soutenir l'utilisation des nouvelles RGE en
facilitant l'analyse exhaustive et l'interprétation de ses prescriptions
par les équipes de conduite de Centrales Nucléaires de Production
Electrique (CNPE).

Définition du stage

Le stage consistera à participer à l'étude sur l'apport et les
conditions de mise en oeuvre du TAL pour faciliter la consultation,
l'analyse et l'interprétation des règles générales d'exploitation d'une
centrale nucléaire.

Plus précisément, il s'agira de:

1. Consolider et enrichir la chaine de traitement (aujourd'hui scripts
   python et Java) déjà constituée en l'utilisant et la faisant évoluer
   pour intégrer 3 chapitres supplémentaires des RGE (documents d'entrée
   en word) ;

2. Consolider et enrichir les modalités de recherche et de présentation
   des résultats au moyen du paramétrage d'Open Semantic Search ou de sa
   base Apache Lucene / Solr.

En interface avec une équipe pluridisciplinaire (ingénieurs en
Traitement Automatique de la Langue, ingénieurs Facteurs Humains et
ingénieurs membres d'équipes de conduite de CNPE), l'approche développée
durant le stage, consistera à :

- Identifier et prioriser les modifications et enrichissement des
  traitements à réaliser ;

- Implémenter les traitements retenus ;

- Mettre à disposition d'un échantillon d'utilisateurs représentant des
  équipes de conduite de CNPE le prototype.

Ceci afin de permettre :

- Aux utilisateurs de faire des retours sur l'usage du prototype et de
  procéder à l'amélioration incrémentale de ce dernier ;

- Au titulaire du stage et à l'équipe projet de procéder à
  l'amélioration incrémentale du prototype.

Le recueil des retours utilisateur sera porté par les ingénieurs
facteurs humains. L'analyse de ces retours sera réalisée en
collaboration avec le titulaire du stage.

Au terme du stage le stagiaire aura produit :

- Une documentation technique (chaîne de traitement, paramétrage d'Open
  Semantic Search et Solr, utilisation du prototype) ;

- Le transfert et la dépose du code à l'équipe projet ;

- Un prototype de consultation des RGE sous Open Semantic Search.

- Son rapport de stage avec une mise en perspective des développements
  réalisés et résultats obtenus.

Les avantages du stage

Au sein de la R&D du groupe EDF ce stage vous permettra :

- De mettre en oeuvre des outils et techniques d'analyse de données non
  structurées ;

- De mettre en oeuvre des techniques d'analyse et d'enrichissement de
  représentation des données ;

- D'évoluer et interagir au sein d'une équipe pluridisciplinaire en
  confrontant les réalisations aux utilisateurs ;

- D'être force de proposition dans les phases initiales d'un projet de
  R&D ;

- De participer à la phase amont d'un projet industriel.

Le prototype réalisé a pour ambition de nourrir une réflexion en termes
de Facteurs Humains sur l'intelligibilité de système de recherche
d'information et à terme d'aide à la décision à base de TAL pour les
industries à risque.

Compétences requises

- Python, PHP
- Travail en équipe
- Aisance rédactionnelle
- Connaissance d'outils de TAL
- Aisance relationnelle
- Anglais lu
- Capacités d'adaptation
- Capacités d'initiatives"
"630","2020-03-09","Acolad","Boulogne-Billancourt","Acolad is the European leader in professional translation and is one of
the most dynamic businesses in the industry. The group has a presence in
14 countries and on 3 continents and distinguishes itself by its
multi-local market approach, a rare trait which has made it the
preferred partner of many clients around the world. Acolad offers a wide
range of language services, for all industries and sectors, including
translation, localisation, and interpretation. The Acolad group
maintains a strong partnership with over 15,000 professional translators
and 6,000 clients, for 300 different language combinations.

Acolad's Research & Development team, composed of highly dedicated
Computational Linguists, Natural Language Processing (NLP) Engineers,
and Machine Translation (MT) Experts, develops NLP technology for the
Acolad group, employing state-of-the-art models and capitalising on our
group-wide natural language resources. We work in close collaboration
with production teams, ensuring an industry-oriented, applied research
approach.

As an intern in our team, you will have the opportunity to develop your
Python programming and research skills in the context of the rich Neural
Machine Translation (NMT) scientific community we operate in. Our
projects include domain adaptation of NMT engines, a study of
inter-language variability of Translation Edit Rate (TER),
linguistic-driven evaluation of Post-Edited Machine Translation (PEMT),
and prediction of PEMT effort.

Your profile:

  * A student in or a holder of a Master's degree in Computational
    Linguistics, Natural Language Processing, Computer Science and/or
    Linguistics, Data Science, or a related field
  * Solid grasp of Python and Bash
  * Familiar with Linux and Virtual Machines
  * Fluent in French and English, knowledge of other languages is a plus
  * Familiar with recent Machine Learning approaches for NLP
  * Knowledge of Machine Translation and CAT Tools is appreciated but
    not required

Position located in Boulogne-Billancourt, 20 minutes by public transport
from the centre of Paris

Start date: ASAP

Salary: 600¤ net, transport costs, and meal vouchers (Ticket Restaurant)

To apply, send your CV and a cover letter to nalkhadhar@acolad.com"
"631","2020-03-09","LIGM","Marne-la-Vallée","Titre du stage : Approches automatiques de modernisation de textes du
XVIe au XVIIIe siècle
******** 

Description du stage 
--------------------------------------- 
Dans le cadre du projet de recherche Cité de Dames, créatrices dans la
cité, qui se centre sur la thématique de la visibilité des créatrices
sur la dimension urbaine (https://citedesdames.hypotheses.org/a-propos),
coordonné par Philippe Gambette et Caroline Trotot, un stage en TAL est
proposé sur le sujet de la mise en oeuvre d'approches statistiques et à
base de règles pour la modernisation orthographique des textes issus du
XVIe au XVIIIe siècle.

Le stage aura lieu au LIGM, Laboratoire d'Informatique Gaspard-Monge. La
personne recrutée interagira tout particulièrement avec Eleni
Kogkitsidou, post-doctorante et Philippe Gambette, enseignant-chercheur
à l'Université Gustave Eiffel.

Objectifs du stage 
--------------------------------------- 
Alors que la langue se trouve en plein évolution au cours de la période
du XVIe au XVIIe, il a été constaté qu'elle présente une extrême
variabilité graphique (scauoir/sauoir/sçauoir/sçavoir/savoir,
alternances u/v et i/j). En effet, elle conserve certains archaïsmes
(amy/ami), son système flexionnel n'est pas encore stabilisé (amiz/amis,
chevaulx/cheval) et l'accentuation est souvent peu régulière (Souvay &
Pierrel, 2009). De plus ces textes anciens issus d'une océrisation
dépendante de la qualité de l'impression du texte original, peuvent
contenir souvent des problèmes de conversion de caractères spéciaux (s
long - ) et sont parfois peu conformes à leur version originale (Abiven
& Lejeune, 2019).

Traiter de façon automatique des anciens textes nécessiterait donc
prendre en compte un certain nombre de paramètres afin d'obtenir une
version modernisée : la syntaxe, la ponctuation, la conjugaison, l'OCR
etc. (Catach, 1996). Également, il ne faut pas omettre la résolution de
l'ambiguïté homographique (marchez peut être utilisé comme nom au
pluriel alors qu'aujourd'hui il est le plus souvent utilisé comme verbe
à la deuxième personne du pluriel) qui vient s'ajouter à cette
problématique.

Des approches à base de règles devraient être appliquées idéalement à
l'aide du logiciel Unitex (Unitex 3.1), couplées avec des approches
statistiques. Les résultats de ce stage contribueront à l'amélioration
du traitement automatique des corpus informatisés de textes allant du
XVIe au XVIIIe siècle, notamment ceux écrits par des femmes utilisés
dans le cadre du projet de recherche Cité des Dames. Les outils
développés le seront sous licence libre.

Profil recherché 
--------------------------------------- 
Formation en cours : Master en traitement informatique des langues ou en
informatique.

Compétences requises 
--------------------------------------- 
- un langage de script (Python de préférence, ou Javascript) 
- capacité d'explorer de nouvelles méthodes statistiques en TAL 
- analyse morphosyntaxique et bonne connaissance d'outils et logiciels
  TAL

Compétences complémentaires utiles 
--------------------------------------- 
- manipulation de fichiers XML 
- connaissances en graphes Unitex et en grammaires locales 
- utilisation d'outils de versionnement (Git) 

Durée et gratification 
--------------------------------------- 
Le stage aura lieu sur une durée d'au moins 12 semaines réparties au
choix entre début avril et mi-juillet.

La gratification versée correspond au montant légal, avec remboursement
partiel des frais de transport.

Contacts 
---------- 
Merci d'envoyer, le 16 mars 2020 au plus tard, un CV et une lettre de
motivation à Eleni Kogkitsidou (eleni.kogkitsidou@u-pem.fr) et Philippe
Gambette (philippe.gambette@u-pem.fr).

Références 
------------------ 

- Abiven, K., & Lejeune, G. (2019). Analyse automatique de documents
  anciens : tirer parti d'un corpus incomplet, hétérogène et
  bruité. Recherche d'information, Document et Web Sémantique, 2(1),
  1-15. https://doi.org/10.21494/iste.op.2019.0335
- Bollman, M. (2019). « A Large-Scale Comparison of Historical Text
  Normalization Systems », NAACL-HLT 2019.
- Catach, L. (1996). « Graphist : Logiciel de lemmatisation, indexation
  et modernisation automatique de textes anciens », Digital Studies/le
  Champ Numérique, (4). http://doi.org/10.16995/dscn.215
- Gabay, S., Riguet, M. & Barrault, L. (2019). « A Workflow For On The
  Fly Normalisation Of 17th c. French », DH 2019, ADHO.
- Souvay, G., & Pierrel, J.-M. (2009). « LGeRM Lemmatisation des mots en
  Moyen Français ». Traitement Automatique Des Langues, 50(2), 21.
- Unitex 3.1, User Manual. Disponible sur : https://unitexgramlab.org."
"632","2020-02-13","BCL","Nice","OFFRE DE STAGE

STAGE pour un.e. étudiant.e. de Master 1 ou 2

        Recherche outillée sur les corpus en littérature

Axe transversal ""Nouvelles textualités. Statistique, pragmatique,
énonciation"",
Laboratoire Bases, corpus, langage (UMR 7320), Année 2020.


En appui à nos projets de recherche, nous proposons 1 stage de 4 à 6
mois en exploitation des corpus textuels, en particulier littéraires.

Spécialité recherchée : un.e. étudiant curieux.se. des nouvelles
approches des textes littéraires.

Profil du candidat : étudiant.e en Lettres ou Sciences du langage
ayant un intérêt pour les outils numériques appliqués à la recherche
littéraire. Niveau Master 2 ou Master 1. Le stage a pour objectif de
préparer un travail de thèse au sein de BCL, sur les corpus
littéraires.

    Contexte

Au sein de l'UMR BCL, un axe réunit au moins deux équipes : l'équipe
""Linguistique de l'énonciation"" et l'équipe ""Logométrie. Corpus,
traitements, modèles"". Cet axe transversal s'intéresse aux nouvelles
textualités, notion qui peut être envisagée comme nouvelles
productions textuelles mais aussi comme nouvelles approches du texte
littéraire. C'est cette seconde perspective qui est privilégiée pour
ce stage.

L'étudiant.e. pourra travailler sur les nouvelles formes de
textualités induites par les textes littéraires numérisés. On pourra
s'interroger sur la délinéarisation du texte électronique et sur la
lecture rhizomatique. Le deep learning et l'application de
l'intelligence artificielle aux textes littéraires pourra être
expérimentée ; on pourra également observer la transformation des
textes anciens en nouveaux objets textuels par le transfert numérique.

    Objectifs du travail

Le stagiaire devra, sous la responsabilité de membres de l'équipe
Logométrie, enseignant et ingénieur d'étude :
- choisir une base de données littéraires : voir à titre d'exemples
    http://logometrie.unice.fr/pages/bases/
- exploiter les données avec les outils disponibles au laboratoire
- tester différentes méthodes d'analyse
- interpréter les résultats d'un point de vue stylistique

    Compétences recherchées

- excellente maîtrise de la langue française
- très bonnes capacités rédactionnelles
- capacité à organiser son propre travail avec rigueur
- curiosité pour les nouvelles technologies

    Cadre du stage

La.e stagiaire sera accueilli au sein du laboratoire Bases, corpus,
langage. Il ou elle sera accompagné.e dans son travail par deux
encadrants et travaillera en collaboration avec plusieurs
chercheuse.eur.s de l'unité.

Durée et date de début du contrat :
Le stage est prévu au printemps-été 2020.

Montant de la gratification : 591,51 euros/mois

    Répondre à l'offre

Les candidats doivent envoyer :
(1) un CV, (2) une lettre de motivation et (3) une lettre de
recommandation d'un enseignant par mail, ayant comme objet :
[Stage Nouvelles textualités BCL] Candidature de M/Mme Prénom NOM
à Véronique Magri :
    magri@unice.fr"
"633","2020-03-24","STIH","Paris","Comparaison de résultats d'outils de Détection d'Entités Nommées

Description du stage
---------------------------------------
L'extraction d'entités nommées (NER) est un domaine très actif du
traitement Automatique des Langues en particulier pour la reconnaissance
d'entités de lieux ou de personnes. Seulement, les progrès affichés par
les systèmes concernent principalement des cas très spécifiques en terme
de langues d'application, de bruitage des données (données standard ou
non ...) ou encore de types de données utilisées (registres de langue,
genre textuels...).

Dès lors, il est difficile pour les utilisateurs finaux, notamment dans
le domaine des humanités numériques, de trouver l'outil approprié sans
devoir sacrifier leurs besoins aux limites des systèmes considérées
surtout que les scores affichés par les systèmes sont souvent obtenus
sur des données d'évaluation très spécifiques, en ""conditions de
laboratoire"".

Nombre de systèmes ne font que fournir des mentions d'entités nommées
dans un texte déjà formaté, rares sont les outils capables de prendre un
texte non normalisé et de le traiter de bout en bout, jusqu'à la
production d'un résultat structuré selon un format normé en passant par
l'analyse.

Divers systèmes ont été conçus sur les même données ou sur des données
similaires, quelques études comparent différentes approches (Augenstein
et al. 2017, Dupont 2017), mais assez peu étudient l'intersection des
outils et, à l'inverse, leur complémentarité. Un travail de ce stage
serait de comparer des outils afin d'établir un différentiel des outils
et de mieux estimer les apports spécifiques de chacun.

Les systèmes existants sont souvent appris sur du texte bien formé
(domaine sources) comme les articles de journaux (Sagot et al. 2012).
Avec l'arrivée du Web 2.0 et les contenus générés par les utilisateurs,
de plus en plus de tâches (dont la reconnaissance d'entités nommées)
portent attention sur ces données bruitées et souvent mal formées
(Ritter et al. 2012).

L'utilisation d'un tel système (de reconnaissance d'entités nommées par
exemple) sur ces données bruitées (domaine cible) nécessite donc une
adaptation au domaine (Xiao et al. 2015, Tian et al. 2016). La
couverture multilingue est aussi un enjeu important dans le domaine.

Aucune définition des entités nommées ne fait à l'heure actuelle
consensus, malgré divers efforts pour proposer un cadre général (Ehrmann
2008, Sekine & Ranchlod 2009, Grouin et al. 2011). Bien souvent, ces
types génériques ne correspondent pas exactement à des types d'entités
d'intérêt, où une couche supplémentaire de sémantique est souvent
nécessaire. Par exemple, une personne peut être auteur(rice) dans le
cadre bibliographique, partie ou membre de la cour dans un contexte de
décisions de justice, etc. Bien souvent, de nouveaux systèmes sont créés
depuis zéro pour répondre à cette demande. Au meilleur de notre
connaissance, aucune étude n'a été montré sur l'adaptation d'un schéma
d'annotation général ou d'outils déjà existants. Un travail de ce stage,
si le temps le permet, serait d'étudier ce point particulier.

Objectifs du stage
---------------------------------------
Fusionner et comparer sur des corpus variés les résultats d'outils
existants pour deux langues autres que l'anglais (Allemand, Français,
Chinois ...). Ceci ne nécessite pas d'être un locuteur des langues
considérées même si cela peut être un plus.

Profil recherché
---------------------------------------
Master 1 ou master 2 Traitement Automatique des langues , Humanités
Numériques ou profil équivalent

Compétences requises
---------------------------------------
- Langage de script (Python de préférence).
- Notions en Traitement Automatique du Langage (TAL).

Compétences complémentaires
---------------------------------------
- Connaissance en apprentissage Automatique.
- Connaissance d'un ou plusieurs outils d'extraction d'Entités Nommées.

Lieu de Stage
---------------------------------------
Équipe de Linguistique Computationnelle du laboratoire STIH (Sorbonne
Université)
Maison de la Recherche 28, rue Serpente, Paris (métro St Michel/Odéon)

Durée et gratification
---------------------------------------
Le stage aura lieu sur une durée de 3 à 6 mois (selon profil). Le
démarrage du stage se ferait au 1er Juin 2020, à voir selon évolution de
la situation.

La gratification versée correspond au montant légal, avec remboursement
de 50% des frais de transport (pass Navigo).

Contacts
----------
Yoann Dupont yoann.dupont@paris-sorbonne.fr
Tian Tian tian.tian@sorbonne-universite.fr
Gaël Lejeune gael.lejeune@sorbonne-universite.fr

Références
------------------

Augenstein, I., Derczynski, L., & Bontcheva, K. (2017). Generalisation
in named entity recognition: A quantitative analysis. Computer Speech &
Language, 44, 61-83.

Dupont, Y. (2017, June). Exploration de traits pour la reconnaissance
d'entités nommées du Français par apprentissage automatique. In TALN
2017.

Ehrmann, M. (2008). Les Entitées Nommées, de la linguistique au TAL:
Statut théorique et méthodes de désambiguïsation (Doctoral
dissertation).

Grouin, C., Rosset, S., Zweigenbaum, P., Fort, K., Galibert, O., &
Quintard, L.  (2011, June). Proposal for an extension of traditional
named entities: From guidelines to evaluation, an overview. In
Proceedings of the 5th linguistic annotation workshop
(pp. 92-100). Association for Computational Linguistics.

Ritter, A., Clark, S., & Etzioni, O. (2011, July). Named entity
recognition in tweets: an experimental study. In Proceedings of the
conference on empirical methods in natural language processing
(pp. 1524-1534). Association for Computational Linguistics.

Sagot, B., Richard, M., & Stern, R. (2012, June). Annotation
référentielle du Corpus Arboré de Paris 7 en entités nommées.

Sekine, S., & Ranchhod, E. (Eds.). (2009). Named entities: recognition,
classification and use (Vol. 19). John Benjamins Publishing.

Tian, T., Dinarelli, M., Tellier, I., & Cardoso, P. D. (2016,
May). Domain Adaptation for Named Entity Recognition Using CRFs. In
Proceedings of the Tenth International Conference on Language Resources
and Evaluation (LREC'16) (pp.  561-565).

Xiao, M., & Guo, Y. (2015, July). Learning hidden markov models with
distributed state representations for domain adaptation. In Proceedings
of the 53rd Annual Meeting of the Association for Computational
Linguistics and the 7th International Joint Conference on Natural
Language Processing (Volume 2: Short Papers) (pp. 524-529)."
"634","2020-10-19","Kaisens Data","La Défense","Kaisens Data est un éditeur de logiciels spécialisé en NLP/NLG.
Nous proposons de nombreuses APIs de génération de texte multilingues
et d'analyse sémantique des données.

Nos solutions sont utilisées par de grands groupes notamment : Total,
TechnipFMC, Saint Gobain, la Société Générale etc.



Descriptif du stage

Vous serez encadré par un Data Scientist senior, PhD, spécialisé en
NLP, et vous mènerez des projets qui auront vocation à devenir les
futures fonctions innovantes de nos APIs.
Les tâches principales :
-   Étudier l'état de l'art des modèles basés sur les deep Learnining
    et les systèmes experts
-   Implémenter les approches à base de Deep Learning et de système
    expert, et évaluer leur valeur ajoutée dans notre contexte.
-   Entrainer vos propres modèles sur des corpus disponibles.
-   Assurer une veille technologique sur l'état de l'art en NLP
-   Faire rayonner le savoir-faire de Kaisens Data en NLP

Profil recherché
-   Vous êtes issu d'une formation spécialisée en NLP ou machine
    Learning,
-   Vous maîtrisez la théorie et la pratique de certaines techniques de
    NLP.
-   Vous savez travailler avec Python éventuellement des GPU,
-   Vous êtes curieux, créatif et vous aimez faire partager vos
    connaissances.

Le processus de recrutement se déroule en 3 étapes : un entretien
visio/call RH + 1 test technique + 1 entretien présentiel

-   Type de contrat : Stage de pré-embauche 3 ou 6 mois
-   Lieu : La Défense, France (92400)
-   Niveau d'études : Bac + 4 ou Bac+5 / Master
-   Expérience : < 6 mois

     Aymen KHELIFI
     Data scientist associé, PhD

     9 allée de l'Arche, 92671 Courbevoie
     aymen.khelifi@kaisensdata.fr

     Bureau : +33 (0)1 46 49 32 61
     Mobile :  +33 (0)6 79 25 77 95
     www.kaisensdata.fr"
"635","2020-11-04","Akio","Montpellier ou Paris","Offre de stage chez Akio

Titre: Annotateur de langue espagnole

Descriptif:
Le sujet proposé traite de la qualification de verbatim en espagnol
pour le compte d'un éditeur de logiciel français dans le domaine de la
relation client.


Description du poste:
L'objectif du stage est principalement d'annoter des verbatim en
espagnol à partir d'un outil spécifiquement créé auquel vous serez
formé. Il s'agit d'annoter des textes de sources diverses (emails, avis
clients, textes en provenance des réseaux sociaux) afin de déterminer
pour chaque segment le sentiment associé : positif, négatif ou neutre.

L'autre objectif est de contribuer à l'annotation sémantique et
l'exploration textuelle des données afin d'être en mesure d'en détecter
les thèmes relatifs à la relation client.


Profil recherché:
-   Niveau Licence minimum en linguistique ou en traitement automatique
    du langage
-   Très bon niveau en espagnol
-   Grande rigueur
-   Bonne maîtrise des outils informatiques

Durée:
2 mois

Date début de stage
ASAP

Lieu:
Le stage pourra se dérouler sur notre site de Paris (75010) ou
Montpellier (quartier Antigone)


Akio
Equipe: traitement automatique de la langue.
43 rue de Dunkerque, 75010 Paris.
www.akio.com


Gratification:
Selon les règles en vigueur avec participation aux frais de transports
en commun et repas.

Encadrement:
Le stage sera encadré par Lynda Ould Younes

Candidature:
Merci d'envoyer un CV à srumeur@akio.com et louldyounes@akio.com
accompagné des notes de l'année universitaire en cours et de celles
de l'année dernière."
"636","2020-11-17","CEA/LIMSI/LORIA","NR","Mots-clés : traitement automatique de la langue, similarité, domaine
biomédical
Durée : 5 mois
Niveau : Master 2 (professionnel ou recherche), fin d'école d'ingénieur
Rémunération : Indemnité de stage, soit ~ 600 ¤/mois, indemnité de
transport incluse

Contexte
       L'apprentissage automatique est un levier important des
technologies du langage. Il repose sur la disponibilité de corpus
annotés pour définir des méthodes, entraîner des modèles et évaluer des
algorithmes. Ces données doivent être représentatives de différents
phénomènes linguistiques (formulations syntaxiques, distribution
statistique de l'emploi de termes spécifiques, erreurs humaines telles
que les fautes d'orthographe, etc.) afin de garantir la robustesse des
méthodes et outils développés. Par ailleurs, les données doivent
également être partageables afin de garantir la transparence et la
reproductibilité des expériences.
       Dans le domaine biomédical, le secret médical et la préservation
de la confidentialité s'accompagnent d'un cadre réglementaire qui
restreint l'accès aux données textuelles telles que les comptes-rendus
hospitaliers dans un objectif de recherche en traitement automatique de
la langue. Le partage des documents cliniques n'est possible qu'après
anonymisation, c'est à dire un traitement des textes qui garantisse
scientifiquement l'impossibilité de savoir que des informations
concernant un individu donné sont présentes dans les textes, de
ré-identifier tout individu concerné par les textes, ou de faire des
inférences sur les informations concernant ces individus.

Objectifs du stage
L'objectif de ce projet est d'analyser un corpus de documents cliniques
du point de vue de la similarité entre énoncés. Ce travail permettra
d'identifier dans un corpus clinique les phrases les plus similaires à
une phrase source en utilisant un large éventail de mesures de
similarité, y compris des modèles de recherche d'informations,
représentations vectorielles denses (Johnson et al. 2019), réseaux
siamois ( Neculoiu et al. 2016 ).

Approche proposée
Nous nous intéressons ici à la constitution d'un corpus de phrases
redondantes. L'approche suivie par Li et al. (2015) consiste à filtrer
les phrases par fréquence et à conserver les phrases qui reviennent à
l'identique dans les compte-rendu de différents patients. Si cette
approche permet d'éliminer les phrases de faible fréquence contenant
potentiellement des données identifiantes, elle élimine également les
phrases contenant des données cliniques (résultats de laboratoire)
alors que nous souhaitons disposer d'outils du TAL capables de les
traiter. La solution que nous envisageons vise à produire des données
fictives mais néanmoins réalistes sur les plans cliniques (permettant
une association entre plusieurs données cliniques telles que
descriptions et résultats de laboratoire) et linguistiques en
identifiant en plus des phrases strictement identiques des groupes de
phrases similaires qui pourraient donner lieu à la production de
phrases anonymes et réalistes en générant une nouvelle variante non
rencontrée en corpus. A partir d'une phrase synthétique (générée),
l'examen des phrases réelles les plus similaires permettra de
sélectionner des phrases conformes au principe de k-anonymat (Sweeny,
2002).
Dans ce contexte, nous prévoyons de confier au stagiaire de M2 une
étude exploratoire permettant d'implémenter plusieurs méthodes de
calcul de similarité entre énoncés (phrases) et d'analyser la
prévalence de différents types de similarité au sein de deux corpus
clinique en français : un corpus réel (LERUDI) et un corpus
synthétique, issu de la traduction de documents américain (MIMIC).

Programme de Travail :
    -   Identifier les phrases identiques dans un corpus
        -   Prendre en charge le pré-traitement du corpus:
            découpage en phrase, ...
    -   Identifier des phrases similaires dans un corpus
        -   Etudier différents types de « similarités » :
            distance de Levenshtein, similarité Dice ou cosine,
            homologie, similarité à partir de plongements de phrases à
            l'aide d'outils fournis (module Text::Similarity dans PERL,
            BLAST, librairie FAISS, ...)
    -   Si l'avancement du travail le permet, proposer une
        visualisation des résultats

Références
Johnson, J., Douze, M., & Jégou, H. (2019). Billion-scale similarity
search with GPUs. IEEE Transactions on Big Data.
Li D, Rastegar-Mojarad M, Li Y, Sohn S, Mehrabi S, Elayavilli R, Yu Y,
Li, H, Wang Y.  2015. A Frequency-based Strategy of Obtaining Sentences
from Clinical Data Repository for Crowdsourcing. Studies in health
technology and informatics. 216:1033-4.
Neculoiu, P., Versteegh, M., & Rotaru, M. 2016. Learning text
similarity with siamese recurrent networks. In Proceedings of the 1st
Workshop on Representation Learning for NLP:148-157.
Sweeney, L. (2002). k-anonymity : A model for protecting privacy.
International Journal of Uncertainty, Fuzziness and Knowledge-Based
Systems, 10(05) :557-570.

Compétences souhaitées:
Le.a stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue seront
particulièrement appréciées. Le contenu et l'ambition du stage pourront
être modulés en fonction du niveau d'étude et de la durée du stage
du/de la candidat.e. Une poursuite en thèse sur la génération
d'énoncés similaires est possible dans le cadre de l'ANR CODEINE.

Pour candidater :
Envoyer un CV, un relevé de notes récent ainsi que les coordonnées
(nom, mail) d'au moins deux référent.e.s (professeur.e.s ou
encadrant.e.s de précédents stages ou emplois pouvant attester de vos
compétences) à Aurelie.Neveol[at]limsi.fr, Olivier.FERRET[at] cea.fr
et karen.fort [at] loria.fr"
"637","2020-11-17","LIG","Grenoble","The LIG (Laboratoire d'Informatique de Grenoble) proposes the following
Master 2 level internship:

*Title*: Multi-Task Neural Spoken Language Understanding from Speech

*Description*: Spoken Language Understanding (SLU) is an important part
of Human-Computer Interaction (HCI), and aims at extracting semantic
interpretations from human utterances [De Mori, 2008]. Because of the
high complexity of the problem, most real applications focus on
specific narrow domains, e.g. hotel reservation and information
[Bonneau-Maynard et al., 2005].
Traditionaly, SLU was performed from automatic transcriptions of the
speech signal or, at best, on a word lattices. With the emergence of
Deep Neural Networks (DNN), SLU can be performed directly from speech
signal, overcoming or at least alleviating the problems related to
automatic transcription. Such end-to-end approaches from speech have
been already proposed for spoken language translation [Berard et al.,
2018; Berard et al., 2016; Weiss et al., 2017], and more recently for
E2E SLU [Qian et al., 2017; Serdyuk et al., 2018; Haghani et al., 2018;
Desot et al., 2019; Caubrière et al., 2019].
Additionally, the use of Neural Networks such like RNNs (LSTM/GRU)
[Hochreiter and Schmidhuber, 1997; Cho et al., 2014] and Transformers
[Vaswani et al., 2017], in combination with attention mechanisms
[Bahdanau et al., 2014], allows potentially to use contextual
information going beyond the single or a few dialog turns [Bothe et al.,
2018]. This information is possibly crucial to solve long-range
ambiguïties.

In this internship the student will investigate multi-task learning
using several neural models, decoding semantic interpretations directly
from the speech signal and learning SLU tasks in a multi-task learning
framework.
The student will use modular pre-built systems based on Convolutional
and Recurrent Neural Networks [Berard et al., 2018; Dinarelli et al.,
2020] and/or Transformer networks, with the objective of creating a
whole integrated SLU system. The student will run experiments using the
team GPUs, and the system will be evaluated on the SLU benchmarks
corpora MEDIA [Bonneau-Maynard et al.,2006, Hahn et al., 2010],
PORT-MEDIA [Lefévre et al., 2012] and VOCADOM [Desot et al., 2019]

Profile:

   - Master 2 student level in computer science or NLP
   - Interested in Natural Language Processing
   - Skills in machine learning for probabilistic models
   - Computer science skills:


   1.   Python programming with good knowledge of deep learning
        libraries Pytorch and Fairseq
   2.   Data manipulation (both textual data and audio signal)

The internship may last from 5 up to 6 months, it will take place at
LIG laboratory, GETALP team (http://lig-getalp.imag.fr/), starting from
January/February 2021. The student will be tutored by Marco Dinarelli
(http://www.marcodinarelli.it), and François Portet
(https://lig-membres.imag.fr/portet/home.php)

Interested candidates must send a CV and a motivation letter to
marco.dinarelli@univ-grenoble-alpes.fr and/or françois.portet@imag.fr

Desot, T., Portet, F., and Vacher, M. (2019). Slu for voice command in
smart home: Comparison of pipeline and end-to-end approaches. In 2019
IEEE Automatic Speech Recognition and Understanding Workshop (ASRU),
pages 822-829. IEEE.

Ghannay, S., Caubrière, A., Estève, Y., Camelin, N., Simonnet, E.,
Laurent, A., and Morin, E. (2018). End-to-end named entity and semantic
concept extraction from speech. In 2018 IEEE Spoken Language Technology
Workshop (SLT), pages 692-699. IEEE.

Haghani, P., Narayanan, A., Bacchiani, M., Chuang, G., Gaur, N.,
Moreno, P., Prabhavalkar, R., Qu, Z., and Waters, A. (2018). From audio
to semantics: Approaches to end-to-end spoken language understanding.
In 2018 IEEE Spoken Language Technology Workshop (SLT), pages 720-726.

Qian, Y., Ubale, R., Ramanaryanan, V., Lange, P., Suendermann-Oeft, D.,
Evanini, K., and Tsuprun, E. (2017). Exploring asr-free end-to-end
modeling to improve spoken language understanding in a cloud-based
dialog system. In 2017 IEEE Automatic Speech  Recognition and
Understanding Workshop (ASRU), pages 569-576. IEEE.

Serdyuk, D., Wang, Y., Fuegen, C., Kumar, A., Liu, B., and Bengio, Y.
(2018). Towards end-to-end spoken language understanding. In 2018 IEEE
International Conference on Acoustics, Speech and Signal Processing
(ICASSP), pages 5754-5758."
"638","2020-11-25","LIMSI","Orsay","Le LIMSI propose un sujet de stage dont le sujet est détaillé ci-dessous
Si ce sujet vous intéresse, contactez sahar.ghannay@limsi.fr ou
sophie.rosset@limsi.fr.

Title :

Dialogue history integration

Contact :

Master internship at LIMSI CNRS

Sahar Ghannay (ghannay@limsi.fr), Sophie Rosset (rosset@limsi.fr)

Subject :

The proposed internship is about task-oriented dialogue system working
on the cooking domain. This dialogue system handles two different types
of scenarios : (1) the user wants to find a recipe meeting his/her
criteria, and (2) the user asks a question related to the cooking
domain. For the first scenario, the system accesses a database which
contains recipes. For the second scenario, the system accesses
unstructured data using a community question answering module.

For, this internship we are interested in two tasks. First, we propose
to investigate the use of new approaches to integrate the dialog
history in different modules of the dialogue system including the NLU
and cQA modules. Thus, these modules have to capture the common
information between the dialog history and the candidate answers. The
second task concerns the evaluation of the different modules and of the
dialogue system through user simulation.

Some of those terms are defined as follows :
- Dialogue system : a dialogue system allows a user to interact using
natural language [DRO+19]. Two families of dialogue systems exist :
conversational systems and task-oriented systems. Conversational
systems have to generate the most appropriate reaction given a user's
utterance and a context, without any restriction about the domain.
A task-oriented system aims to help the user perform a task or access
information. A dialogue system generally consists of three modules :
natural language understanding (NLU), dialogue management and natural
language generation (NLG).

- NLU takes as input the utterance of the user and returns the slots
and the intent associated to this utterance. Considering the following
user utterance :""Please find me a recipe of pancakes without eggs"", the
NLU should detect the slots ""recipe : pancakes"" and ""neg-ingredient :
eggs"" plus the intent ""RECING"",that means that the user is looking for
a recipe by giving the name of the recipe and the ingredients.

- Community Question Answering : Community Question Answering (cQA)
[Pat17] forums, such as Quora and Stack overflow offer a new
opportunity for users to provide, search and share knowledge. The cQA
system consists on automatically search for relevant answers among many
responses provided for a given question, and search for relevant
questions to reuse their existing answers.

Many approach have been proposed to integrate dialogue history
[TRC+20, BZZZ19, PRMU18, BTHTH17]. Popular contextual NLU models
[BTHTH17, BZZZ19] exploit the dialogue history with the memory network
[WCB14].The use of the memory mechanism helps the NLU model to retrieve
context knowledge to reduce the ambiguity of the current utterance.
Other approaches propose to represent the dialog history in the form of
dialog history embedding vectors. The embeddings vector can be computed
weather by predicting bag-of-concepts expected in the answer of the
user from the last dialog system response [TRC+20], or by adapting the
word2vec [MCCD13] approach to compute utterance embeddings that take
into account dialogue context [PRMU18]. The dialog history embedding
vectors are provided as an additional information to the NLU module.

History modeling is essential for ConvQA, since previous history turns
play an essential role in understanding the user's current information
need. Some existing methods simply prepend history turns [CCO+20,
RCM19, BHJM19] or mark answers in the passage[CHI+18]. These methods
cannot handle a long conversation history. Another existing method
[HCY18] uses complicated attention mechanisms to model history and thus
generates relatively large system overhead. [QYQ+19] propose a history
answer embedding method to model conversation history. The proposed
method is specifically tailored for BERT-based architectures.

Expected profile

-   Master 2 profile student in computer Science, specialized at least
    in one of the following topics :

-   Machine learning

-   Natural language processing

-   Technical skills : python, linux

Practical information

-   Duration of internship : 5-6 months

-   Beginning of the internship : start date to be defined with the
    intern

-   Gratification : around 591.91e /month and reimbursement of
    transport costs and canteen subsidy

References

[BHJM19] Basma El Amel Boussaha, Nicolas Hernandez, Christine
    Jacquin, and Emmanuel Morin. Multi-level context response matching
    in retrieval-based dialog systems. In Proceedings of the 7th
    edition of the Dialog System Technology Challenges Workshop at AAAI
    (DSTC7'19). Honolulu, HI, USA, 2019.
[BTHTH17] Ankur Bapna, Gokhan Tür, Dilek Hakkani-Tür, and Larry Heck.
    Sequential dialogue context modeling for spoken language
    understanding. In Proceedings of the 18th Annual SIGdial Meeting on
    Discourse and Dialogue, pages 103-114, Saarbrücken, Germany, August
    2017. Association for Computational Linguistics.
[BZZZ19] He Bai, Yu Zhou, Jiajun Zhang, and Chengqing Zong. Memory
    consolidationfor contextual spoken language understanding with
    dialogue logistic inference.In Proceedings of the 57th Annual
    Meeting of the Association for Computational Linguistics, pages
    5448-5453, 2019.
[CCO+20] Jon Ander Campos, Kyunghyun Cho, Arantxa Otegi, Aitor Soroa,
    Gorka Azkune,and Eneko Agirre. Improving conversational question
    answering systems after deployment using feedback-weighted
    learning. arXiv preprint arXiv:2011.00615, 2020.
[CHI+18] Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih,
    Yejin Choi, PercyLiang, and Luke Zettlemoyer. Quac: Question
    answering in context. arXiv preprint arXiv:1808.07036, 2018.
[DRO+19] Jan Deriu, Alvaro Rodrigo, Arantxa Otegi, Guillermo Echegoyen,
    Sophie Rosset, Eneko Agirre, and Mark Cieliebak. Survey on
    evaluation methods for dialogue systems. arXiv preprint
    arXiv:1905.04071, 2019.
[HCY18] Hsin-Yuan Huang, Eunsol Choi, and Wen-tau Yih. Flowqa:
    Graspingflow in history for conversational machine comprehension.
    arXiv preprint arXiv:1810.06683, 2018.
[MCCD13] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
    Efficient estimation of word representations in vector space. arXiv
    preprint arXiv:1301.3781, 2013.
[Pat17] Barun Patra. A survey of community question answering.CoRR,
    abs/1705.04009,2017.
[PRMU18] Louisa Pragst, Niklas Rach, Wolfgang Minker, and Stefan Ultes.
    On the vector representation of utterances in dialogue context. In
    Proceedings of the Eleventh International Conference on Language
    Resources and Evaluation (LREC 2018), 2018.
[QYQ+19] Chen Qu, Liu Yang, Minghui Qiu, W Bruce Croft, Yongfeng Zhang,
    and Mohit Iyyer. Bert with history answer embedding for
    conversational question answering. In Proceedings of the 42nd
    International ACM SIGIR Conference on Research and Development in
    Information Retrieval, pages 1133-1136, 2019.
[RCM19] Siva Reddy, Danqi Chen, and Christopher D Manning. Coqa:
    A conversational question answering challenge. Transactions of the
    Association for Computational Linguistics, 7:249-266, 2019.
[TRC+20] Natalia Tomashenko, Christian Raymond, Antoine Caubrière,
    Renato De Mori,and Yannick Estève. Dialogue history integration
    into end-to-end signal-to-concept spoken language understanding
    systems. In ICASSP 2020-2020 IEEE International Conference on
    Acoustics, Speech and Signal Processing (ICASSP), pages 8509-8513.
    IEEE, 2020.
[WCB14] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory
    networks. arXiv preprint arXiv:1410.3916, 2014."
"639","2020-11-25","IMT-Atlantique / LS2N","Brest ou Nantes","Offre de stage Master Recherche en EIAH et TALN/Fouille de texte
===============================

Titre : Explorer le contenu textuel des forums des MOOCs pour analyser
        le niveau d'engagement des apprenants
Mots-clés : IA, TALN, EIAH, MOOC, e-Learning, modèle de l'apprenant
Durée : 6 mois
Gratification : environ 580 ¤/mois
Lieu :  selon la situation sanitaire, télétravail ou un des locaux
        suivants :
*   IMT Atlantique, Laboratoire Lab-STICC,
    Technopôle Brest-Iroise CS 29238 Brest. France
*   LS2N (UMR 6004) 2, Rue de la Houssinière
    F-44322 Nantes Cedex 3 - FRANCE
Perspective : la présente offre intervient en contexte de montage de
projets avec financement de thèse ; un financement effectif devra être
confirmé.

Contexte et sujet du stage
--------------------------
L'engouement pour l'apprentissage en ligne à des fins de formation
continue, notamment via les MOOCs (Massive Online Open course), n'est
plus à prouver[1], et cela indépendamment de situations sociales
critiques inédites (enseignement d'une langue à des milliers de
réfugiés, continuité pédagogique de millions d'enfants et d'étudiants
en période de confinement mondial) qui soulignent la nécessité d'avoir
la capacité d'enseigner (et d'apprendre) à distance[2]. Pour
l'UNESCO[3], il est nécessaire de réviser nos stratégies pour être en
mesure de suivre les processus d'apprentissage à distance des
apprenants, de veiller à leur niveau d'engagement et d'évaluer leurs
résultats d'apprentissage.
Dans le cadre d'un amorçage de collaboration scientifique, l'équipe
MOTEL (MOdels and Tools for Enhanced Learning) du laboratoire Lab-STICC
et l'équipe TALN (Traitement Automatique du Langage Naturel) du
laboratoire LS2N s'associent pour proposer un stage de recherche en
traitement automatique des langues (TAL) appliqué à l'apprentissage
humain et indirectement au développement d'Environnements informatiques
pour l'apprentissage humain (EIAH).

Objectifs du stage
------------------
Ce stage vise à mener une étude linguistique qualitative et
quantitative des messages entre les différents acteurs (apprenants,
tuteurs, enseignants) d'un forum de discussion d'un MOOC afin de 1)
mieux comprendre la nature des participations et des échanges, et par
là, 2) exprimer des indices langagiers pouvant soutenir la construction
d'indicateurs nécessaires à l'estimation du niveau d'engagement des
apprenants dans leur formation. Les fonctions méta-discursives (e.g.
salutation, demande d'assistance, acquittement, ...) sont un des indices
envisagés pour décrire les différentes formes de participation. Une des
activités consistera à adapter une taxonomie de fonctions existante aux
données manipulées. La dimension émotionnelle pourra être considérée.
Ce travail s'accompagnera d'une activité d'annotation manuelle, d'abord
à des fins d'exploration puis éventuellement d'entraînement ou
d'évaluation d'un système de reconnaissance automatique. Le travail
d'exploration doit donner lieu à la définition d'indices, ainsi qu'à
l'implémentation de méthodes permettant leur extraction (prédiction,
reconnaissance...). Diverses approches peuvent être envisagées, de
l'usage de règles à l'apprentissage profond en passant par
l'apprentissage statistique. La langue d'étude sera le français.
Des perspectives possibles à ce stage concernent la construction
d'indicateurs d'engagements à partir de ces indices langagiers,
l'alimentation d'un modèle d'apprenant à l'aide de ces indicateurs, la
classification des apprenants selon leur niveau d'engagement,
l'alimentation de tableaux de bord destinés aux différents acteurs
pédagogiques ou encore la personnalisation de l'interaction avec un
chatbot.

Missions
--------
*   Réaliser un état des lieux des recherches scientifiques en analyse
    linguistique des messages échangés sur des forums ;
*   Mener une étude quantitative/qualitative de forums de plateformes
    d'apprentissage en ligne ;
*   Proposer une taxonomie de fonctions méta-discursives existantes aux
    données et réaliser un travail d'annotation à des fins
    d'exploration, d'évaluation ou d'entraînement ;
*   Déterminer des indices linguistiques soutenant le calcul du niveau
    d'engagement des apprenants ;
*   Proposer et implémenter des méthodes automatiques pour l'extraction
    de ces indices à l'aide d'apprentissage et/ou de règles ;
*   Valider la performance de ces systèmes sur un corpus de test ;
*   Produire, synthétiser et restituer les résultats dans un rapport
    et/ou une publication de niveau scientifique.

Bibliographie
-------------
*   Ghada AlHarbi, Thomas Hain, The OpenCourseWare Metadiscourse
    (OCWMD) Corpus. LREC, 2016
*   Chang-Qin Huang, Zhong-Mei Han, Ming-Xi Li, Morris Siu-yung Jong,
    Chin-Chung Tsai, Investigating students' interaction patterns and
    dynamic learning sentiments in online discussions, Computers &
    Education 140, 2019
*   Kiruthika Ragupathi, Muthu Kumar Chandrasekaran, Min-Yen, Kan,
    Bernard C Y Tan, Investigating student learning in online
    discussion forums through a transactivity framework, ISSoTL,
    Calgary, October 11-14, 2017
*   Denyze Toffoli, De la théorie à la pratique : appliquer des modèles
    cognitifs de la motivation dans un centre de langues,
    ASp, 41-42, 2003
*   Miaomiao Wen, Investigating Virtual Teams in Massive Open Online
    Courses: Deliberation-based Virtual Team Formation, Discussion
    Mining and Support, PhD thesis, Carnegie Mellon University,
    August 16, 2016

Profil recherché
----------------
Candidat.e de niveau Master Recherche :
*   Des compétences solides en programmation/algorithmique (python)
*   Des notions en TAL, Fouille de texte, Linguistique
    computationnelle, Apprentissage Automatique ou en EIAH
*   Des qualités d'écriture et d'organisation. La connaissance du
    français est nécessaire. La pratique de l'anglais écrit est
    fortement souhaitée.
*   Des qualités relationnelles (accompagnement, collaboration)
*   Un dynamisme, curiosité, sens de l'organisation et du travail en
    équipe, autonomie et capacité de restitution.

Candidature
-----------
CV et lettre de motivation à envoyer à nicolas.hernandez à
univ-nantes.fr et issam.rebai à imt-atlantique.fr
________________
[1] https://www.classcentral.com/moocs-year-in-review-2019
[2] https://www.ifs.org.uk/publications/15038
[3] https://unesdoc.unesco.org/ark:/48223/pf0000373305.locale=en"
"640","2020-11-25","LIRIS-INSA Lyon","Lyon","Offre de stage Master Recherche en Science des données et TALN
Sujet : Machine Learning et Word Embeddings pour la classification et
l'analyse d'articles encyclopédiques

#########
Contexte :
Dans le cadre du projet GEODE financé par le LabEx ASLAN nous
recherchons un stagiaire en informatique pour travailler sur le
développement et l'expérimentation de méthodes de classification et
d'analyse d'articles encyclopédiques. Il s'agit de mettre en oeuvre des
techniques d'intelligence artificielle adaptées au traitement
automatique de la langue.
Ce stage s'inscrit dans le cadre d'une collaboration académique
interdisciplinaire (informatique, linguistique, géographie et histoire)
ayant comme objet principale une étude diachronique des discours
géographiques au sein des encyclopédies. Ce projet exploratoire
nécessite une activité à l'interface de plusieurs disciplines
(intelligence artificielle, informatique, et linguistique) pour
élaborer des méthodes innovantes, rapides et fiables de classification
de textes et des modes adéquats de représentation et de visualisation
de l'information.

#########
Objectifs du stage :
Ce stage a pour objectif principal de développer des modèles
de classification des articles de différentes encyclopédies
(l'Encyclopédie de Diderot et d'Alembert (1751-1772), La Grande
Encyclopédie, l'Encyclopaedia Universalis et Wikipedia). Une première
tâche s'intéressera en particulier à la sous-classification des
articles de géographie (articles décrivant des lieux : ville, rivière,
pays, etc.). Une deuxième tâche sera consacrée à l'expérimentation et
la génération de modèles de langue permettant une représentation
informatique des articles pour réaliser une analyse et une comparaison
des différents corpus. L'utilisation de méthodes d'apprentissage
supervisé ou d'apprentissage profond sera privilégiée et nécessitera de
réaliser un travail important pour la préparation des données afin de
constituer les jeux d'entrainement et de validation.

#########
Bibliographie :
-   Horton, R., Morrissey, R., Olsen, M., Roe, G., & Voyer, R. (2009)
    Mining Eighteenth Century Ontologies: Machine Learning and
    Knowledge Classification in the Encyclopédie, Digital Humanities
    Quarterly, Volume 3 Number 2.
-   Roe, G., Gladstone, C. & Morrissey, R. (2016), Discourses and
    Disciplines in the Enlightenment: Topic Modeling the French
    Encyclopédie. Frontiers in Digital Humanities 2.
-   Vigier, D., Moncla, L., Brenon, A., Mcdonough, K., & Joliveau, T.
    (2020) Classification des entités nommées dans l'Encyclopédie ou
    dictionnaire raisonné des sciences des arts et des métiers par
    une société de gens de lettres (1751-1772). 7e Congrès Mondial
    de Linguistique Française (CMLF), Montpellier, France.


#########
Profil recherché et candidature :

Master 2 Informatique
Des compétences sont attendues en programmation, en science des
données (Data Mining et Machine Learning) et en traitement automatique
de la langue (TAL).

Lieu du stage : Laboratoire LIRIS-INSA Lyon, Bâtiment Blaise Pascal,
Campus La Doua, Villeurbanne.

Période de stage : 5 à 6 mois entre février et juillet 2021

Encadrants :
Ludovic Moncla, LIRIS UMR 5205 CNRS - INSA Lyon
Denis Vigier, ICAR UMR 5191 CNRS - Université Lumière Lyon 2

Pour candidater, envoyer votre CV et vos derniers relevés de notes par
mail à ludovic.moncla@insa-lyon.fr et denis.vigier@ens-lyon.fr avant le
30 novembre."
"641","2020-11-25","LISN / LIMSI","Orsay","Stage M2 :  Évaluation de l'impact environnemental des méthodes de
            traitement automatique de la langue.

Mots-clés : traitement automatique de la langue, complexité
            algorithmique

Durée :     5 mois

Niveau :    Master 2 (professionnel ou recherche), fin d'école
            d'ingénieur

Rémunération :  Indemnité de stage, soit ~ 600 ¤/mois, indemnité de
                transport incluse

Lieu :  Laboratoire LISN/LIMSI, campus de l'université Paris Saclay à
        Orsay

Contexte

De nombreux travaux en Traitement Automatique de la Langue (TAL)
s'appuient sur des méthodes d'apprentissage. Ainsi, l'apprentissage
profond offre des performances souvent intéressantes pour de nombreuses
tâches d'analyse de textes. L'essor récent des méthodes neuronales
donne lieu à une utilisation croissante de ressources numériques pour
un large éventail de problèmes. Dans ce contexte, les méthodes
symboliques ou méthodes d'apprentissage ""classiques"" sont délaissées
alors qu'une comparaison systématique serait intéressante du point de
vue scientifique, opérationnel et environnemental. En particulier, les
méthodes neuronales ont un impact environnemental élevé qui ne cesse
d'augmenter avec les années (Schwartz et al., 2019).
Un exemple de travail pertinent en traitement automatique des langues
est présenté par (Strubell et al. 2019), qui a étudié la consommation
énergétique de l'apprentissage de plusieurs modèles.
Schwartz et al. (2019) prône donc l'émergence de travaux en
intelligence artificielle « verte » ou Green AI, en parallèle de
travaux standards, dans lesquels l'efficience des méthodes serait mise
en valeur, c'est-à-dire la capacité à obtenir une performance avec un
minimum de ressources.
Ainsi il sera intéressant de proposer une comparaison détaillée de
l'utilisation d'un large panel de méthodes de traitement automatique de
la langue du point de vue de leur performance, de leur complexité
algorithmique, du temps humain et machine requis pour les mettre en
oeuvre. Pour ce faire, il est nécessaire de s'intéresser à l'estimation
de ces critères d'impact des méthodes numériques.

Objectifs du stage

Le stage a pour objectif de recenser et de caractériser les outils
disponibles pour des travaux en intelligence artificielle verte en ce
qui concerne l'estimation de l'impact environnemental des méthodes
numériques. Les outils recensés seront mis en oeuvre dans le cadre
de l'application d'une méthode de traitement automatique de la langue
(par exemple: classification de textes) afin de caractériser
l'utilisation des outils sur le plan de la facilité de prise en main,
qualité et niveau de détail des informations fournies sur les méthodes
TAL, et tout autre critère d'évaluation pertinent.

Approche proposée

Le stage aura pour objet de réaliser une revue systématique des outils
de mesure de l'impact environnemental des expériences informatiques.
Une veille de la littérature récente montre que divers outils existent
afin d'estimer l'impact des expériences informatiques. On recense
notamment des outils en ligne (par exemple, Green Algorithms
http://www.green-algorithms.org/ et ML CO2 impact
https://mlco2.github.io/impact/ ) ou des outils à intégrer dans la mise
en oeuvre des expériences (par exemple, ""experiment impact tracker""
(Henderson et al., 2020) et ""carbon tracker"" (Anthony et al., 2020)).
Nous souhaitons recenser systématiquement les outils existant et les
étudier afin de déterminer les mesures d'impact calculées, la facilité
de mise en oeuvre, la portée d'utilisation possible.

Références

-   Anthony, L. F. W., Kanding, B., and Selvan, R. (2020).
    Carbontracker : Tracking and predicting the carbon footprint of
    training deep learning models. In ICML Workshop on ""Challenges in
    Deploying and monitoring Machine Learning Systems"".
-   Henderson, P., Hu, J., Romoff, J., Brunskill, E., Jurafsky, D., and
    Pineau, J. (2020). Towards the systematic reporting of the energy
    and carbon footprints of machine learning.
-   Schwartz, R., Dodge, J., Smith, N. A., and Etzioni, O. (2019).
    Green AI.
-   Strubell, E., Ganesh, A., and McCallum, A. (2019). Energy and
    policy considerations for deep learning in NLP. In Proceedings of
    the 57th Annual Meeting of the Association for Computational
    Linguistics, pages 3645-3650.

Compétences souhaitées:

Le.a stagiaire devra avoir de bonnes compétences en informatique. Des
connaissances en traitement automatique de la langue seront
particulièrement appréciées. Le contenu et l'ambition du stage pourront
être modulés en fonction du niveau d'étude et de la durée du stage
du/de la candidat.e.

Pour candidater :

Envoyer un CV, un relevé de notes récent ainsi que les coordonnées
(nom, mail) d'au moins deux référent.e.s (professeur.e.s ou
encadrant.e.s de précédents stages ou emplois pouvant attester de vos
compétences) à Anne-Laure.Ligozat[at]limsi.fr et
Aurelie.Neveol[at]limsi.fr"
"642","2020-12-03","LIMSI","Orsay","NL2FL (Natural to Formal Language)

Encadrants :
gabriel.illouz@limsi.fr, sahar.ghannay@limsi.fr,
Vincent Letard, sophie.rosset@limsi.fr,

Sujet

L'objet de stage est la traduction de la langue naturelle en langue
formelle, par exemple de l'anglais au SQL.

Prenons une base de données sur des avis d'utilisateurs sur des
restaurants. Autant

""Donner les notes de Encieux Cecile : notes, et nomLieu""

est assez direct et se traduit en :

SELECT noteAvis,messageAvis,nomLieu
FROM ETUDIANT NATURAL JOIN AVIS NATURAL JOIN LIEU
WHERE nomEtudiant='Encieux' AND prenomEtudiant='Cecile';

Autant, la suivante nécessite de l'interprétation : ""la note d'un
restaurant est calculée comme étant la moyenne des avis sur celui-ci.
Elle est stocké dans la table LIEU pour ne pas tre recalculée tout
le temps. Afficher les lieux dont le calcul n'est pas à jour.""

Elle se traduit au final par :

SELECT nomLieu
FROM AVIS NATURAL JOIN LIEU
GROUP BY nomLieu
HAVING AVG(noteAvis) != noteLieu;
Les données utilisées pendant le stage sont composées de 3 792
requêtes en anglais et leurs équivalent en SQL. Elles sont réparties
en 4 niveaux de difficultés sur 5 bases de données (MOVIEDATA,
CHINOOK, COLLEGE, DRIVING SCHOOL, et FORMULA I). Sur ces données, le
systme neuronal qui traduit de langue naturelle en langue formelle a
des performances qui dépassent difficilement 50% [DMS+20].

Les difficultés  étudier seront celles liées au transfert
d'apprentissage, aux interprétations linguistiques, aux ambiguïtés
qui devront être détectées entre les deux langues.

Le but du stage sera d'abord d'étudier les limites des méthodes
existantes, puis de proposer une nouvelle méthode.



Description des tches

Tester la limite de l'approche de l'article [DMS+20]
Faire une analyse quantitative et qualitative des erreurs
Proposer et évaluer d'autres approches (analogie, PCFG +
deep learning, ...)[LRI16,YN17, DMS+20]

Profil attendu

Master 2 en Informatique (ou équivalent), avec au moins une
spécialité en
Apprentissage
Traitement automatique de la langue

Compétences techniques : python, linux, SQL

Informations pratiques

Durée du stage: 5-6 mois
Début du stage: date de début à définir avec le stagiaire
Gratification: environ 591 emois. Subvention frais de transport et
cantine


References
[DMS+20]    Jan Deriu, Katsiaryna Mlynchyk, Philippe Schläpfer, Alvaro
            Rodrigo, Dirk von Grünigen, Nicolas Kaiser, Kurt
            Stockinger, Eneko Agirre, and Mark Cieliebak. A methodology
            for creating question answering corpora using inverse data
            annotation. In Proceedings of the 58th Annual Meeting of
            the Association for Computational Linguistics, pages
            897-911, Online, July 2020. Association for Computational
            Linguistics.
[LRI16]     Vincent Letard, Sophie Rosset, and Gabriel Illouz.
            Incremental learning from scratch using analogical
            reasoning. In 28th IEEE International Conference on Tools
            with Artificial Intelligence, ICTAI 2016, San Jose, CA,
            USA, November 6-8, 2016, pages 204-211. IEEE Computer
            Society, 2016.
[YN17]      Pengcheng Yin and Graham Neubig. A syntactic neural model
            for general-purpose code generation. In Proceedings of the
            55th Annual Meeting of the Association for Computational
            Linguistics (Volume 1: Long Papers), pages 440-450,
            Vancouver, Canada, July 2017. Association for Computational
            Linguistics."
"643","2020-12-03","IMS","Bordeaux","Objet :  Automatisation d'une méthode d'Analyse des Communications au
sein d'une Dyade en situation de Coopération (ACDC)

début  : début 2021 (janvier, février ou mars)

durée  : 5 à 6 mois

rémunération  : oui
lieu (selon contexte sanitaire)  : Equipe CIH, Laboratoire IMS (UMR CNRS 5218) ENSC-Bordeaux INP, 109 Avenue Roul, 33400, Talence, France

CV et lettre de motivation à envoyer à  : delphine.graeff@ensc.fr

Contexte

Depuis plusieurs années l'équipe CIH (Cognitique et Ingénierie
Humaine), s'intéresse aux problématiques de la cognition collective ou
partagée.  Le travail de Recherche dans lequel s'inscrit ce stage a
pour objectif de formaliser et de valider une méthodologie innovante
pour comprendre les mécanismes cognitifs mis en jeu dans différentes
situations complexes de cognition collective (collaboration,
coopération, etc.).

Dans ce contexte, des études sont menées sur les méthodes permettant
d'étudier la répartition et la dynamique temporelle des échanges et du
leadership au sein d'un binôme d'individus engagés dans une tâche
cognitive collaborative.  Une méthode d'analyse innovante basée sur
des données qualitatives a été mise au point ces deux dernières
années, permettant de révéler la dynamique temporelle du leadership au
sein d'une dyade réalisant une tâche en collaboration.

Présentation de la méthode ACDC

ACDC est une méthode innovante d'Analyse de la dynamique
Communicationnelle au sein d'une Dyade en situation de Coopération
(cf.  Graeff et al., 2020 ).  Pour formaliser et valider
expérimentalement le modèle ACDC, nous l'avons jusqu'alors uniquement
appliqué à une situation particulière de coopération : le jeu de
tétris. Dans cette expérience, deux participants jouent à Tetris de
façon coopérative durant 10 minutes.  La méthode comporte 5 étapes
(Figure 1). Les échanges conversationnels entre participants
enregistrés sont retranscrits, caractérisés et formalisés selon le
modèle ACDC. En résulte une frise chronologique qui illustre la
dynamique temporelle de l'échange.

Figure 1 : Illustration des étapes de la méthode ACDC

Le modèle couvre de façon exhaustive les caractéristiques d'un échange
telles que le type performatif, directif ou non-directif, le type de
décision, assentiment ou dissentiment ou encore le type d'interaction,
socio-émotionnelle ou liée à la tâche.

Intérêt et applications potentielles de la méthode ACDC

Une des forces de notre modèle d'analyse est la prise en compte de la
temporalité qui permettrait d'observer par exemple la dynamique du
leadership au sein de la dyade. En effet, les fluctuations et les
éventuelles passations du pouvoir de décision sont déterminantes et
pourraient être noyées dans une approche trop globale qui ne tiendrait
pas compte de la variable temps.

De la même façon, la possibilité d'ajouter des événements permet de
contextualiser les échanges et les fluctuations associées. Cela permet
d'observer si par exemple le leadership change de main quand la
situation se complique ou après un échec. Par exemple, les
qualificatifs des interactions (remarques positives ou négatives) ou
encore le type de décision finale prise permettraient de déterminer le
type de leadership et de followership associé à la dyade observée.

La méthode ACDC a vocation à être utilisée à termes dans différents
cas d'usage, seule ou associée à d'autres outils d'analyse. La méthode
peut s'adresser à un chercheur mais également à un formateur ou un
concepteur par exemple. En effet, toute personne peut avec cette
méthode observer la dynamique du leadership d'une équipe qui collabore
et mesurer l'impact que peuvent avoir les évènements sur cette
dynamique. Qu'ils s'agissent d'évènements en lien avec une expérience,
un apprentissage ou encore l'interaction avec une Interface
Homme-Système.

Périmètre du stage

Aujourd'hui, la méthode ADCD est très peu automatisée. La
retranscription est faite entièrement manuellement par un opérateur
formé à la méthode : elle est réalisée sur papier et par la suite
saisie sous forme d'une matrice de données temporelles sur tableur
(Excel/Matlab), qui est elle-même retranscrite sous la forme de
représentation graphique (InDesign).

Nous souhaitons limiter au maximum les tâches chronophages, peu
intéressantes ou source d'erreur, et donc automatiser la méthode pour
gagner en fiabilité, en simplicité d'usage et en rapidité d'exécution
(si possible temps réel).

Nous envisageons d'automatiser tout ou partie de la méthode ACDC. La
visualisation temporelle sous forme chronologique pourrait notamment,
sans grande contrainte technique, être directement générée par un
logiciel à partir des matrices de données. Toujours dans un souci de
gain de temps, nous souhaitons automatiser / semi-automatiser le
processus de modélisation, notamment grâce à l'utilisation d'outils
d'intelligence artificielle, en donnant en entrée le fichier son et en
demandant au logiciel de découper puis caractériser les échanges
entendus, sur la base de la symbolique proposée et en fonction de
règles imposées au préalable.

Missions / planning du stage

- Explorer les solutions d'automatisation existantes

- Prototyper les solutions qui viendraient à manquer

- Intégrer ces différentes solutions dans un même outil

- Participer à l'évaluation de l'impact de cet outil sur l'utilisation
de la méthode ACDC en termes de rapidité de prise en main, rapidité
d'exécution, mais aussi de richesse et fiabilité de résultat.

- Si suffisamment de temps disponible : Possibilité de participer à la
rédaction d'un article scientifique sur les résultats de cette étude.

Premières actions

La première étape sera de se familiariser avec la méthode ACDC, pour
pouvoir reformuler et prioriser les besoins d'automatisation des
différentes étapes de la méthode avec l'équipe.

Compétences requises

- Étudiant niveau Master : Soit dernière année école Ingénieur, soit
2ème année Master.

- Compétences sollicitées  : Programmation logicielle, Traitement
Automatique des Langues.

- Sensibilités appréciées  : Data visualisation, Intelligence
artificielle, démarche expérimentale.

- Curieux et rigoureux.

Informations pratiques

- Rémunération : stage rémunéré

- Lieu :  Equipe CIH, Laboratoire IMS (UMR CNRS 5218) ENSC-Bordeaux
INP, 109 Avenue Roul, 33400, Talence, France

- Présence sur site privilégiée , mais télétravail possible en
fonction de la situation Covid.

- Début de stage : début 2021. Janvier, février ou mars à définir en
fonction des contraintes de l'étudiant.

- Encadrement : Delphine Graeff, Doctorante, ENSC-laboratoire IMS de Bordeaux,
Véronique Lespinet-Najib, Enseignante-Chercheur, ENSC-laboratoire IMS de
Bordeaux et Jean-Marc André, Enseignant-Chercheur, ENSC-laboratoire IMS de
Bordeaux.

Candidature

Merci d'envoyer votre CV et lettre de motivation à Delphine Graeff : 
delphine.graeff@ensc.fr"
"644","2020-12-10","CEA LIST","Palaiseau","Présentation du laboratoire d'accueil
=====================================

Basé à Paris-Saclay, le CEA List, membre de l'Université Paris Saclay,
est l'un des quatre instituts de recherche technologique de CEA Tech,
direction de la recherche technologique du CEA. Dédié aux systèmes
numériques intelligents, il contribue au développement de la
compétitivité des entreprises par le développement et le transfert de
technologies.
L'expertise et les compétences développées par les 800
ingénieurs-chercheurs et techniciens du CEA List permettent à
l'Institut d'accompagner chaque année plus de 200 entreprises
françaises et étrangères sur des projets de recherche appliquée
s'appuyant sur 4 programmes et 9 plateformes technologiques.
21 start-ups ont été créées depuis 2003. Labellisé Institut Carnot
depuis 2006, le CEA List est aujourd'hui l'institut Carnot Technologies
Numériques.
Le Laboratoire d'Analyse Sémantique des Textes et des Images (LASTI)
est une équipe de 25 personnes (chercheurs, ingénieurs, doctorants)
menant des travaux de recherche sur les technologies de description et
de compréhension du contenu multimédia (image, texte, parole) et des
documents multilingues, en particulier à grande échelle. Les enjeux
scientifiques sont :
    -   développer des algorithmes efficaces et robustes pour
        l'analyse et l'extraction de contenu multimédia, leur
        classification et analyse sémantique ;
    -   reconstitution ou fusion de données hétérogènes pour
        interpréter des scènes ou documents ;
    -   développer des méthodes et des outils pour la construction,
        la formalisation et l'organisation des ressources et
        connaissances nécessaires au fonctionnement de ces
        algorithmes ;
    -   intégrer plusieurs de ces briques technologiques afin d'accéder
        à l'information et répondre à un besoin utilisateur (moteurs de
        recherche, agents conversationnels, rapports synthétiques de
        veille)

Description du stage
====================

Le laboratoire LASTI participe au projet Européen H2020 Decoder visant
entre autres à exploiter les technologies du traitement automatique des
langues dans le cadre de l'ingénierie logicielle. En effet,
l'information textuelle est partout dans ce cadre : exigences,
spécifications, commentaires du code, documentations utilisateur,
forums (stackoverflow...), gestionnaires de tickets, etc. De plus la
quantité de texte et de code correspondant disponibles en ligne
permettent d'utiliser efficacement les techniques d'apprentissage
automatique. Les applications peuvent aller de la simple extraction
d'information (entités nommées, semantic role labeling...) pour mettre des
éléments en évidence dans les interfaces utilisateurs, jusqu'à la
conversion automatique de texte en code source en utilisant des
techniques issues de la automatique, en passant par l'aide à la
traçabilité pour repérer par exemple des commentaires ou du code qui
violeraient des exigences.

Nous avons jusqu'à présent reproduit un certain nombre de modèles et
collecté des données. Nous avons aussi développé les outils logiciels
permettant de mettre nos résultats à la disposition des partenaires du
projet.
Nous avons enfin spécifié un certain nombre d'améliorations que nous
comptons apporter aux modèles pour aller au-delà des résultats de
l'état de l'art. Le travail du ou de la stagiaire consistera à
participer à l'implémentation de ces améliorations et à leur évaluation
sur des données génériques permettant la comparaison avec l'état de
l'art ainsi que sur les données du projet. Les résultats seront soumis
pour publication dans des conférences internationales.
Les modèles sont implémentés en python avec les frameworks de deep
learning PyTorch et TensorFlow.

Les modèles concernés sont ceux de [Strubell et al., 2018] pour le
semantic role labeling ;  [Thang et al., 2015] et  [Iver et al., 2018]
pour le semantic parsing (traduction de spécifications de haut niveau
en spécifications formelles ou en code) ; [Guo et al., 2017],
[Narayanan, 2019] et [Seki, 2018, 2019] pour la traçabilité horizontale
et verticale. Le ou la stagiaire pourra être amené.e à travailler sur
plusieurs de ces modèles en fonction de l'avancement des travaux lors
de son arrivée et de ses progrès pendant son stage.

Le ou la stagiaire utilisera les clusters de calcul du laboratoire.
Ceux-ci incluent plusieurs dizaines de noeuds GPU régulièrement mis
à jour. Si jamais le confinement devait se poursuivre, il ou elle aura
accès au réseau CEA et aux clusters par VPN, permettant une poursuite
du stage dans les meilleures conditions possibles.

Mots-clés
=========

Traitement automatique des langues, deep learning,
ingénierie logicielle.

Références
==========

[Guo et al., 2017] Guo, J., J. Cheng, et J. Cleland-Huang.
    « Semantically Enhanced Software Traceability Using Deep Learning
    Techniques ». In 2017 IEEE/ACM 39th International Conference on
    Software Engineering (ICSE), 314, 2017.
[Iver et al., 2018] Iyer, Srinivasan, Ioannis Konstas, Alvin Cheung, et
    Luke Zettlemoyer. « Mapping Language to Code in Programmatic
    Context ». In Proceedings of the 2018 Conference on Empirical
    Methods in Natural Language Processing, 1643-1652. Brussels,
    Belgium: Association for Computational Linguistics, 2018.
    https://doi.org/10.18653/v1/D18-1192.
[Narayanan, 2019] Narayanan, Siddharth. « Semantic Similarity in
    Sentences and BERT ». Medium, 27 septembre 2019.
https://medium.com/analytics-vidhya/semantic-similarity-in-sentences-and-bert-e8d34f5a4677.
    (Last accessed, 07/08/2020).
[Seki, 2018] Seki, Kazuhiro. « Exploring Neural Translation Models for
    Cross-Lingual Text Similarity ». In Proceedings of the 27th ACM
    International Conference on Information and Knowledge Management,
    1591-1594. CIKM'18. Torino, Italy: Association for Computing
    Machinery, 2018. https://doi.org/10.1145/3269206.3269262.
[Seki, 2019] Seki, Kazuhiro. « On Cross-Lingual Text Similarity Using
    Neural Translation Models ». Journal of Information Processing 27,
    no 0 (2019):315-21. https://doi.org/10.2197/ipsjjip.27.315.
[Strubell et al., 2018] Emma Strubell, Patrick Verga, Daniel Andor,
    David Weiss, and Andrew McCallum. Linguistically-Informed
    Self-Attention for Semantic Role Labeling. Conference on Empirical
    Methods in Natural Language Processing (EMNLP). Brussels, Belgium.
    October 2018.
[Thang et al., 2015] Luong, Thang, Hieu Pham, et Christopher D.
    Manning. « Effective Approaches to Attention-based Neural Machine
    Translation ». In Proceedings of the 2015 Conference on Empirical
    Methods in Natural Language Processing, 1412-1421. Lisbon,
    Portugal: Association for Computational Linguistics, 2015.
    https://doi.org/10.18653/v1/D15-1166.


Profil du candidat/de la candidate
==================================

Niveau demandé : Ingénieur, Master 2

Durée : 6 mois
Rémunération : entre 700 ¤ et 1300 ¤ suivant la formation.
Compétences requises :
    - Natural Language processing
    - Deep Learning
    - Python
    - Good proficiency in English

Contact
=======

Gaël de Chalendar (mailto:gael.de-chalendar@cea.fr)"
"645","2020-12-16","IRD & LIRMM","Montpellier","Liage de jeux de données complémentaires à l'aide de méthodes
d'augmentation de bases de connaissances


Mots clefs: Linked Open Data, Data Linking, Knowledge Base
Augmentation, Knowledge Extraction


Encadrants: Konstantin Todorov et Pierre Larmande

Contact: konstantin (dot) todorov (at) lirmm (dot) fr - pierre (dot)
larmande (at) ird (dot) fr

Lieu de stage: IRD et LIRMM (Montpellier)

Le liage (ou bien l'interconnexion) de données est un domaine de
recherche actif qui vise à établir des liens sémantiques entres des
entités décrites dans des jeux de données différentes. Nous nous
intéressons ici aux données représentées en graphes de connaissances
RDF (Resource Description Framework), publiées sur le web dans le
cadre du projet collaboratif LOD (Linked Open Data) qui accueille
aujourd'hui plus de 1100 jeux de données. Les liens sémantiques que
nous cherchons à établir sont ceux d'identité, donnés par la relation
""owl:sameAs"" du vocabulaire OWL (Web Ontology Language). La difficulté
provient par la grande hétérogénéité des descriptions des entités que
l'on peut retrouver dans des graphes différents [1]. La majorité des
outils de liage existants se base sur l'hypothèse que pour chaque
couple d'entités à lier potentiellement, il existe au moins un
sous-ensemble de propriétés commun (c'est-à-dire l'intersection des
propriétés de deux entités) qui permettra d'inférer le lien d'identité
(ou son absence). Or, dans un nombre de cas réels, cette intersection
est très faible ou inexistante -- nous parlons ici de jeux de données
complémentaires. Nous nous intéressons en particulier des données du
domaine agronomique issue du projet AgroLD [4] qui manifestent ce
problème.

La question se pose alors où chercher les informations qui peuvent
permettre la comparaison des ressources.

D'une part, dans un nombre de cas ces informations sont présentes dans
les graphes, mais sous une forme non-structurée (dans des champs de
commentaires textuels). Des méthodes d'extraction de connaissances à
partir du texte peuvent être appliquées afin de structurer ces
informations. Par exemple, une particularité des données biologiques
d'AgroLD est que la plupart d'entre elles contiennent des champs
textes qui ne sont pas décrits à l'aide de terminologies standardisées
ou d'ontologies. En résultat, les découvertes qui pourraient être
réalisées par la fouille de ces ressources sont limitées. Nous allons
donc nous intéresser à l'extraction automatique d'entités d'intérêt et
de relations à partir de ces champs textuels afin de structurer et
rendre utilisables les informations y contenues [2,3].

D'autre part, un nombre d'approches d'augmentation de bases de
connaissances existent, qui permettent de compléter la connaissance
manquante dans un graphe de connaissance de manière automatique en
utilisant les informations contenus dans des grands graphes sur le LOD
(telles que DBpedia ou Wikidata). Nous proposons ici d'utiliser et
adapter ces méthodes pour la tâche particulière du liage de jeux de
données complémentaires en augmentant automatiquement les
connaissances dans ces jeux de données afin de permettre leur
comparaison.


Tâches à accomplir

    Etablir un état de l'art détaillé du domaine de liage de données
    web et du domaine d'augmentation automatique de bases de
    connaissances

    Proposer une méthode de liage de jeux de données complémentaires à
    l'aide des méthodes d'augmentation de connaissances et des
    méthodes d'extraction d'entités nommées dans le texte

    Appliquer cette méthode sur des données réelles du domaine
    agronomique (dans le cadre du projet AgroLD).


Références

[1] Manel Achichi, Zohra Bellahsene, Konstantin Todorov: A survey on
web data linking. Ingénierie des Systèmes d'Information (ISI) 21(5-6):
11-29 (2016)

[2] Rafael Vieira and Kate Revoredo. Using Word Semantics on Entity
Names for Correspondence Set Generation. OAEI 2017 challenge.

[3] Yuanzhe Zhang, Xuepeng Wang, Siwei Lai, Shizhu He, Kang Liu, Jun
Zhao, and Xueqiang Lv. Ontology Matching with Word Embeddings. 13th
China National Conference, CCL 2014. LNCS, volume 8801

[4] Aravind Venkatesan, Gildas Tagny Ngompe, Nordine El Hassouni,
Imene Chentli, Valentin Guignon, Clement Jonquet, Manuel Ruiz, Pierre
Larmande. Agronomic Linked Data (AgroLD): a Knowledge-based System to
Enable Integrative Biology in Agronomy. Plos One 13 (11), e0198270
2018. https://doi.org/10.1371/journal.pone.0198270


Profil recherché :

Nous recherchons un étudiant motivé avec une expérience en
apprentissage automatique et en technologies web sémantique. Le
candidat démontrera des aptitudes ou des correspondances avec la
plupart des aspects suivants:

- Forte motivation pour la recherche scientifique

- Connaissance des technologies du web sémantique, notamment JSON /
  RDF / SPARQL.

- Expérience avec les outils d'apprentissage automatique (par exemple,
  Scikit Learn de Python)

- Connaissance des techniques d'exploration de texte et de données
  (reconnaissance d'entités nommées)

- Excellentes compétences techniques pour mener des expériences avec
  des données réelles et de référence

- Bonne maîtrise de l'anglais oral et écrit

- Bonnes compétences en rédaction

- Autonomie et initiative, prendre les décisions techniques au sein du
  projet et justifier les choix"
"646","2020-12-16","Sorbonne Université","Paris","*Offre de stage | Sorbonne Université : Analyse de Défigements par des
méthodes de TAL*


L'équipe de Linguistique Computationnelle du laboratoire STIH propose
un stage de Master en TAL/Fouille de Données d'une durée de 3 à 6 mois
(selon profil) dans le cadre d'un projet de recherche financé par le
GIS « Jeu et Sociétés ». Les missions de ce stage concerneront
principalement la détection automatique des séquences défigées dans des
écrits courts : microblogs et slogans publicitaires.

*Objet *
Les défigements sont des procédés créatifs de nature linguistique et
sémiotique, qui visent à désolidariser les séquences polylexicales à
caractère figé et leurs contextes discursifs. Dès qu'une séquence est
défigée, de nouvelles interprétations de la séquence sont possibles,
tout en gardant des liens en filigrane avec la séquence initiale. Ce
mécanisme de (re)mise en relation est utilisé dans certains types de
production langagière tels que slogans publicitaires, écrits
humoristiques, calembours etc.

*Missions*

 1. Construction d'un corpus de slogans publicitaires

 2. Modélisation des moules de séquences défigées en discours (typage
    de construction, dépendance syntaxique, fréquence, etc.)

 3. Retrouver leurs origines dans des corpus

 4. Proposer des critères d'appréciation et de classification

La réalisation concrète attendue : création d'un outil de détection et
d'évaluation de la qualité des séquences défigées, notamment celle des
slogans publicitaires

*Profil et compétences requises*
-   Connaissances en TAL et/ou en Apprentissage Automatique

-   Pratique du langage Python

-   Savoir utiliser des étiqueteurs (POS /tagger/)

-   Des connaissances en phraséologie seraient un plus

*À acquérir*
-   Prise de connaissances de travaux universitaires contemporains en
    Sciences du Langage et TAL
-   Programmation Python
-   Versionnage avec git


*Conditions de recrutement*
-   Structure de recrutement : Sorbonne Université
-   Gratification : en vigueur + remboursement de 50 % des frais de
    transports
-   Matériel : matériel informatique fourni par l'équipe
-   Durée du stage : 3 à 6 mois (selon profil), 35h/semaine
-   Prise de fonction : Possible à partir de mars/avril 2021
-   Localisation : Maison de la Recherche, Serpente (Quartier Saint
    Michel, 75005 Paris)
-   Stage au sein d'une équipe-projet de 4 personnes

*Date limite de candidature : 29 décembre 2020*

Candidature : envoyer CV et lettre de motivation à
gael.lejeune@sorbonne-universite.fr et lichao.zhu@gmail.com

*Références*
[1] Blanche GRUNIG (1990), /Les mots de la publicité,/Paris, Collection
    CNRS Plus, Presses du CNRS, 255 p.

[2] François MANIEZ(2000), « Le repérage par traitement automatique du
    défigement lexical des proverbes dans la presse américaine ».
    Revue Française De Linguistique Appliquée, 2, 19-32.

[3] Salah MEJRI (2013)*,« Figement et défigement : problématique
    théorique », /Pratiques/, 159-160, 79-97."
"647","2020-12-16","ELAN","Grenoble","Stage FAIRisation@ELAN - Décembre 2020

Stage M1 ou M2 « FAIRisation de données »

Équipe Littératures, Arts et Numérique (ELAN)
au sein du laboratoire Litt&Arts (UMR 5316), Grenoble

En appui à nos projets de recherche, nous proposons 1 stage de 4 à 5 mois pour
accompagner la FAIRisation des données que nous produisons.

Profil du candidat : étudiant·e de Master dans l'une des disciplines
des SHS dans une filière à coloration numérique

Contexte

Au sein de l'UMR Litt&Arts, ELAN est une équipe d'ingénieur·e·s
accompagnant les projets de recherche de l'unité (une vingtaine) sur
leurs aspects numériques. Quel que soit le projet, nous manipulons des
données de multiples natures : facsimilés, sources transcrites,
documentation, code informatique...  manuscrits, correspondances,
bibliographies...  Le stage propose de travailler sur l'application
des  principes FAIR à l'ensemble des données ainsi produites.

Objectifs du travail

Le ou la stagiaire devra, sous la responsabilité de deux ingénieures d'ELAN :

- vérifier le degré d'adéquation des données avec les principes FAIR ;

- effectuer une recherche d'information (veille) sur les vocabulaires
contrôlés et thésaurus utilisables pour renseigner les métadonnées
Dublin Core des corpus ;

- intégrer les recommandations du groupe  Data CAHIER 1 aux données en
TEI ;

- enrichir le site CERVIDAE (sous Omeka Classic) dédié au suivi et à
la description des données des projets accompagnés par Elan ;

- produire de la documentation autour de la démarche mise en oeuvre ;

- mener avec l'équipe une réflexion sur le choix d'un entrepôt de
données.

Le ou la stagiaire participera au travail de l'équipe et sera impliqué
dans notre réflexion autour de la notion de (ré)utilisabilité des
données en SHS.

Compétences recherchées
- capacité d'organiser son propre travail avec rigueur
- connaissance des principes FAIR
- connaissance de standards de métadonnées Dublin Core
- connaissance du format XML-TEI ou bonne connaissance du format XML
- connaissance du CMS Omeka
- lecture de l'anglais

Cadre du stage

La·e stagiaire sera accueilli au sein du Laboratoire Arts et pratique
du texte, de l'image, de l'écran et de la scène (Litt&Arts, UMR 5316,
UGA/CNRS) sur le Campus Saint-Martin d'Herès de l'université
Grenoble-Alpes.  Il ou elle sera accompagné·e dans son travail par
deux encadrantes et travaillera en collaboration avec plusieurs
chercheuse·eur·s de l'unité.

Durée et contrat

Le stage est prévu au printemps-été 2021 pour une durée de 4 à 5
mois. Le stagiaire bénéficiera de la gratification de stage minimale
prévue par la réglementation 2 et d'une prise en charge partielle de
ses frais de transports.

Répondre à l'offre

Les candidats doivent envoyer :
(1) un CV,
(2) une lettre de motivation et
(3) une lettre de recommandation d'un de leurs enseignants
par mail, ayant comme objet :
[Stage ELAN] Candidature de  M/Mme Prénom NOM
à :
Anne Garcia-Fernandez :  annegf@univ-grenoble-alpes.fr
Elisabeth Greslou :  gresloue@univ-grenoble-alpes.fr"
"648","2020-12-16","LIG","Grenoble","Subject Title: Artificial intelligence and legal decisions: comparison
of the performance of artificial intelligence techniques in order to
understand and anticipate judges' reasoning based on evidence
(evidential reasoning)

Supervisors:
Caroline BAZZOLI, Jean Kuntzmann Laboratory,
caroline.bazzoli@univ-grenoble-alpes.fr
Jean-Pierre CHEVALLET, Laboratoire d'Informatique de Grenoble,
jean-pierre.chevallet@univ-grenoble-alpes.fr
Duration: 5-6 months
Keywords : NLP; Machine learning ;Deep learning ; Text mining ;

Introduction

The objective of the project is to test and compare the performance of
artificial intelligence systems derived from two different
methodologies for predicting court decisions and identifying the
criteria (facts and evidence) that influence the reasoning of judges.
The first method consists in creating a mathematical model of judges'
decisions based on a learning process that relies on the detailed
annotation of several hundred judgments. The second method, is based on
deep neural networks trained on the same corpus of judgments annotated
with decision labels.

This project is grounded on a close cooperation between computer
scientists, jurists and statisticians. It involves both academic and
industrial partners. It is the first academic research in France whose
objective is to measure the performance of AI in the field of legal
sciences. It seeks to find out to what extent state-of-the-art
artificial intelligence models are likely to help understanding and
anticipating judges' decisions.

Internship subject

The objective of the internship is to compare the performance of two
scientific methods for analyzing the decision-making process of judges:
on the one hand, a mathematical modeling method based on human
annotation work, which requires both significant human resources and
advanced legal skills; on the other hand, the use of recent advanced in
natural language processing models based on word embeddings, i.e.
representing words as vectors of numbers, based on their context (e.g.
BERT Bidirectional Encoder Representations from Transformers) to build
efficient text classification on legal texts.

In this project, the student must setup an experiment that will test
the capacity of a Neural Network (NN) to be trained to learn the judges
decision. The NN will have as input vectors embedding transformations
using FlauBERT developed in LIG as the sources text are in French.

The internship missions are:

Bibliographic study on the predictive efficiency of supervised
classification applicable to our context by presenting their advantages
and disadvantages.

Programming of the Natural Language pre-processing phase of the text of
court decisions for the use of FlauBERT.

Test if a NN with text embeddings input, can learn and predict judges
decisions only from judgments corpus

Analyze and understand the usefulness on human annotation in the
efficiency of the learning processing

Find a way to automatically highlight in the original text, the
passages that has been evaluated as strongly influential for the NN
decision making.

Candidate profile

Master 2 in Computer science of Applied Mathématics

Knowledge of programming tools in the machine learning domain : R,
Python, pyTorch, etc.

Theoretical knowledge in multivariate statistics, logistic regression
and data analysis (classification, clustering and neural networks,
DeepLearning)

Scientific English. French reading could be important as the text
collection is in French.

Practical informations

Location : Laboratoire Informatique de Grenoble, Bâtiment IMAG,
Université Grenoble Alpes, 700 avenue Centrale, 38401 Domaine
Universitaire de Saint-Martin-d'Hères.

Usual internship gratuity (around 540,00¤ per month)

Duration : 5 or 6 months

Supervisors :
Jean-Pierre CHEVALLET (LIG), Caroline BAZZOLI (Laboratoire Jean
Kuntzmann), Etienne VERGES (Centre de recherche Juridique)"
"649","2020-12-16","LIPN","Villetaneuse","Title:  Multitask Deep Learning for Joint Syntactic and Semantic
        Easy-first Dependency Parsing

Context: Collaboration between RCLN
    (https://lipn.univ-paris13.fr/accueil/equipe/rcln/), LIPN,
    Université Paris 13, and CAMeL Lab (https://bit.ly/2M0XsAG),
    New York University Abu Dhabi
Host lab: LIPN, Université Paris 13, 99 Avenue Jean Baptiste Clément,
    93430 Villetaneuse
Supervisors: Nadi Tomeh and Joseph Le Roux
Collaborator: Nizar Habash, NYU Abu Dhabi
Start date: February 2021
Duration: 6 months
Stipend: 550 euros/month
Profile and required skills:
    -   Masters in Computer Science, Computational Linguistics, Applied
        Mathematics, or Statistics
    -   Knowledge in Natural Language Processing and Deep Learning is
        highly appreciated
    -   Programming skills in Python (and libraries such as pytorch,
        numpy, or scikit-learn)
How to apply:
    send CV, grades, motivation and recommendation letters to
    tomeh@lipn.fr and leroux@lipn.fr
Permalink:
https://lipn.univ-paris13.fr/~tomeh/public/uploads/offers/2021-internship-multitask-parsing.pdf

Context
In recent work on dependency parsing for Arabic (Kankanampati et al.
2020), we proposed a multitask algorithm based on the easy-first
hierarchical LSTM parser of Kiperwasser and Goldberg (2016). The
multitask algorithm is capable of decoding a sentence into multiple
formalisms and is learned from multiple corresponding treebanks. In the
experiments, we considered two representations, the first one is the
Columbia Arabic Treebank (CATiB) (Habash and Roth, 2009), which is
inspired by Arabic traditional grammar and focuses on modeling
syntactic and morpho-syntactic agreement and case assignment.  The
second is the Universal Dependency (UD) treebank for Arabic (Taji et
al., 2017), which has relatively more focus on semantic/thematic
relations within the sentence, and is coordinated in design with a
number of other languages.
The multitask system enables sharing representations at various levels
of abstraction, and at different time steps of the parsing process,
which makes it possible to communicate information across formalisms
and to learn when sharing is important and when it is not. The joint
system outperforms the single-task baseline on both CATiB and UD
treebanks.

Propositions
We propose to extend the work of Kankanampati et al. (2020) in two
ways:

(i) The joint parser indirectly learns the order in which to produce
the arcs of CATiB and UD trees. In fact, the easiest decision in a
local context is selected at each step during parsing. During training,
the parser is allowed to explore erroneous arcs to reduce the effect of
error propagation, sometimes referred to as the exposure bias problem.
This is done by designing an optimal learning policy also known as a
dynamic oracle. In our multitask setting, the dynamic-oracle-based
training is suboptimal, since the number of arcs allowed by the dynamic
oracle during training is large and the order in which they should be
predicted is unknown. In the experiments, the parser switches between
the two dimensions in about 65% of the time, but we noticed that its
performance can be improved by explicitly controlling the switching
frequency heuristically. Instead of designing a new dynamic oracle for
the multitask parser, we will explore reinforcement learning as a
principled framework to learn this kind of sequential decisions to
further reduce error propagation, similar to Zhang and Chan (2009). We
will however consider a policy gradient approach since it is
straightforward to apply in deep learning because it is gradient-based.
Policy gradient learning was shown to help transition-based syntactic
dependency parsing (Le and Fokkens, 2017), constituency parsing (Fried
and Klein, 2018), and semantic dependency parsing (Kurita and Søgaard,
2019). Other approaches to RL such as DQN, Actor/Critic and MaxEnt RL
can also be considered.

(ii) The current model uses Bi-LSTMs for contextual encoding of lexical
and part-of-speech tags and. It also uses a multilayer perceptron for
arc and label scoring. We will be exploring options to replace these
components with transformer-based encoders and attention mechanisms.
The multitask model uses a predefined parameter sharing strategy by
specifying which layers have tied parameters. The search for the best
sharing architecture considered a few alternatives and compared them on
the devset to select the best one. Similar to Yang and Hospedales
(2017) and Ruder et al. (2019) we want to consider learning the best
sharing strategy in a data-driven way to find the layers or subspaces
that benefit from sharing, the appropriate amount of sharing, and the
appropriate relative weights of the different task losses.

The baseline multitask parser is implemented in Python and will be our
starting point:
https://github.com/yash-reddy/MEF_parser

References
-   Nizar Habash and Ryan M. Roth. ""CATiB: The Columbia Arabic
    Treebank."" ACL (2009).
-   Lidan Zhang and Kwok Ping Chan. ""Dependency Parsing with
    Energy-based Reinforcement Learning."" IWPT (2009).
-   Eliyahu Kiperwasser and Yoav Goldberg. ""Easy-first dependency
    parsing with hierarchical tree LSTMs."" TACL (2016).
-   Dima Taji, Nizar Habash, and Daniel Zeman. ""Universal Dependencies
    for Arabic."" WANLP (2017).
-   Yongxin Yang, Timothy M. Hospedales. ""Trace Norm Regularised Deep
    Multi-Task Learning."" ICLR (2017).
-   Minh Le and Antske Fokkens. ""Tackling Error Propagation through
    Reinforcement Learning: A Case of Greedy Dependency Parsing"".
    EACL (2017).
-   Fried, Daniel and D. Klein. ""Policy Gradient as a Proxy for Dynamic
    Oracles in Constituency Parsing."" ACL (2018).
-   Ruder, Sebastian, Joachim Bingel, Isabelle Augenstein and Anders
    Søgaard. ""Latent Multitask Architecture Learning."" AAAI (2019).
-   Shuhei Kurita and Anders Søgaard. ""Multi-Task Semantic Dependency
    Parsing with Policy Gradient for Learning Easy-First Strategies.""
    ACL (2019).
-   Kankanampati, Yash, Joseph Le Roux, Nadi Tomeh, Dima Taji and Nizar
    Habash. ""Multitask Easy-First Dependency Parsing: Exploiting
    Complementarities of Different Dependency Representations.""
    COLING (2020)."
"650","2021-01-05","Ludo-Vic","Paris","Nous proposons un stage (de niveau Master 2/5ième année ingénieur)
portant sur la détection de baisse d'engagement durant une interaction
avec nos agents conversationnels.
La solution peut être trouvée en utilisant des modèles à base de règles
ou en utilisant des techniques de machine/deep learning [1, 2, 3, 4, 5]

OBJECTIFS :
-   Analyser le comportement (mouvement de tête, émotion, ...) pour
    trouver les caractéristiques de baisse d'engagement.
-   Modélisation et détection de la baisse d'engagement
-   Évaluation
-   Application en temps réel

CONDITION DU STAGE :
Le stage se déroulera sur une période de 6 mois dans le département R&D
du Ludo-Vic SAS. Des outils de travail à distance sont disponibles au
sein de l'entreprise.

PROFIL RECHERCHÉ :
-   Bac +5 dans le domaine de l'informatique et de l'IA.
-   Capacité à réaliser des interactions et des animations 3D.
-   Expérience avec Unity3D et compétence en langage C# sont un vrai
    plus.

RÉMUNÉRATION :
-   conditions standards de rémunération de stage.

CONTACTS ET CANDIDATURE
Merci d'envoyer votre CV (vos relevés de notes, vos rapports de
projets/stages...) à :
Jack Amberg : jack[at]ludo-vic.com
Atef Ben-Youssef : atef[at]ludo-vic.com

RÉFÉRENCE :
[1] A. Ben-Youssef, C. Clavel, S. Essid, M. Bilac, M. Chamoux, and A.
    Lim, ""UE-HRI: A new dataset for the study of user engagement in
    spontaneous human-robot interactions,"" in Proc. 19th ACM Int. Conf.
    Multimodal Interaction (ICMI), 2017, pp. 464-472. DOI:
    10.1145/3136755.3136814
(https://www.tsi.telecom-paristech.fr/aao/en/2017/05/18/ue-hri-dataset/)
[2] A Gupta, A DCunha, K Awasthi, V Balasubramanian, DAiSEE: Towards
    User Engagement Recognition in the Wild, arXiv preprint:
    https://arxiv.org/abs/1609.01885
[3] A. Ben Youssef, C. Clavel and S. Essid, ""Early Detection of User
    Engagement Breakdown in Spontaneous Human-Humanoid Interaction,"" in
    IEEE Transactions on Affective Computing, 2019, doi:
    10.1109/TAFFC.2019.2898399.
[4] A. Ben-Youssef, G. Varni, S. Essid, and C. Clavel, ""On-the-Fly
    Detection of User Engagement Decrease in Spontaneous HumanRobot
    Interaction Using Recurrent and Deep Neural Networks,""
    International Journal of Social Robotics, 2019.
    (https://hal.archives-ouvertes.fr/hal-02288044)
[5] L. Geng, M. Xu, Z. Wei and X. Zhou, ""Learning Deep Spatiotemporal
    Feature for Engagement Recognition of Online Courses,"" 2019 IEEE
    Symposium Series on Computational Intelligence (SSCI), Xiamen,
    China, 2019, pp. 442-447, doi: 10.1109/SSCI44817.2019.9002713."
"651","2021-01-05","LIG","Grenoble","Titre :     Développement d'un système question / réponse
            pour l'application mobile d'un cyber opéra
Encadrant : Jean-Pierre Chevallet, équipe MRIM du Laboratoire
            d'Informatique de Grenoble (LIG)
Contact :   jean-pierre.chevallet@imag.fr
Lieu :      Laboratoire d'Informatique de Grenoble (LIG), Bâtiment
            IMAG, 700 avenue Centrale, Domaine Universitaire de
            Saint-Martin-d'Hères

Durée : 5-6 mois

Financement : celui d'un stage (1/3 du SMIC), financé par
MIAI@Grenoble Alpes, (ANR-19-P3IA-0003)

Mot clés : Accès à l'information, Intelligence artificielle, Traitement
automatique de la langue naturelle, Apprentissage automatique,
Apprentissage profond par réseaux de neurones, Génération automatique
de phrases, Interaction homme machine avec un avatar, plongements de
mots (embeddings), BERT et FlauBERT, programmation mobile.

Contexte

Ce projet est dans le contexte du montage d'un spectacle qui sera en
tournée en France à partir de fin 2022 avec des répétitions prévue fin
2021. La première aura lieu à partir du printemps 2022 à Grenoble
(Hexagone de Meylan). Il s'agit d'un ""cyber-opéra"" sur le thème de
l'interaction d'un robot avec les humains, plus précisément, il s'agit
de suivre l'évolution d'une intelligence artificielle en apprentissage
avec les humains. Cet oeuvre artistique posera des questions sur le
rôle des machines dans notre réalité, en particulier le rôle de
l'intelligence artificielle. Le spectacle mettra en scène un robot
ayant une intelligence artificielle, mais ce robot sera en fait animés
par un acteur. Par contre, il est prévu une application sur téléphone
mobile, qui permettra au spectateur ayant acheté un billet pour le
spectacle, de faire connaissance avec le robot du spectacle, et d'avoir
des informations sur le contenu du spectacle sous la forme d'énigmes à
résoudre. Le spectacle en lui même répondra à une partie de l'énigme
mais l'énigme se poursuivra dans l'application mobile après le
spectacle.

Le projet informatique consiste à participer au développement de cette
application, en relation avec le scénariste, le musicien, les designers
(visuel, et audio), le metteur en scène et une structure d'aide et
d'accueil au CEA de Grenoble. Le stage se déroulera au Laboratoire
d'Informatique de Grenoble (LIG). Le développement se fera en
collaboration avec une start-up spécialisée dans la conception et la
réalisation d'avatars interactifs sur téléphone portable. Un serveur
devra être mis en place pour la partie intelligence artificielle.
Le but du développement informatique est de servir l'oeuvre mais aussi
de rendre visible à des néophytes le travail scientifique réalisé dans
le Laboratoire Informatique de Grenoble, en particulier le modèle de
langue FlauBERT, réalisé par l'équipe GETALP du LIG.

Sujet du stage

Le projet concerne le développent de l'application sur téléphone mobile
qui sera disponible pour les spectateurs, avant et après le spectacle.
Cette application sera développée à priori dans le langage Dart et
l'environnement Flutter. Le développement de la partie mobile fera
l'objet d'un autre stage. Dans ce stage, il s'agit du développement
d'un serveur qui contiendra l'IA de l'application mobile. Ce serveur
pourra fonctionner en mode question / réponse. La réponse sera produite
par un réseau de neurones. Ce projet concerne précisément le
développement de la partie question / réponses en langue naturelle en
rapport avec le scénario du spectacle.

Ce projet passera par les étapes suivantes

-   Etat de l'art dans la génération de texte et les systèmes
    question / réponse avec apprentissage profond;

-   Analyse de la fonctionnalité d'interaction textuelle avec l'avatar
    sur le téléphone mobile;

-   Proposition d'un modèle de construction de réponse à partir de
    questions de l'utilisateur et en tenant compte du scénario du
    spectacle;

-   Création d'un corpus d'apprentissage et d'un corpus de questions,
    pour réaliser plusieurs versions du générateur de réponses en
    fonction de l'évolution dans le temps de l'IA et du parcours de
    l'utilisateur dans le scénario;

-   Proposition d'une architecture pour apprendre et produire les
    phrases;

-   Expérimentations de l'apprentissage avec le corpus et évaluation
    des réponses aux questions.

Profil attendu :
-   Connaissance du traitement des langues par plongement de mots
    (ex: BERT), ou systèmes question / réponse;

-   Pratique de l'apprentissage automatique appliqué au traitement de
    la langue;

-   A l'aise avec la mise en oeuvre de réseaux de neurones, et
    connaissance des frameworks logiciels comme pyTorch.

-   Facilité d'interaction avec des non informaticiens, comme un
    auteur, un metteur en scène, un musicien, etc."
"652","2021-01-05","Lattice","Montrouge","*** Production d'un package R à partir de scripts d'analyse
textométrique pour le français ***

Stage de M2 proposé par le laboratoire Lattice (Montrouge)

* Motivations et contexte

Le but de ce stage en informatique est de produire un paquet R
reprenant un ensemble de scripts (déjà écrits en R et utilisant
principalement les extensions Tidyverse) constituant une chaîne
d'analyse textométrique pour le français. Cette chaîne est actuellement
opérationnelle, mais ne peut prétendre être diffusée en l'état auprès
du public. Elle vise à identifier dans des corpus des patrons
lexico-grammaticaux (motifs) permettant, notamment, d'identifier des
éléments stylistiques représentatifs d'un auteur ou d'un genre textuel.
La chaine est ainsi composée :

-       1°) Étiquetage morphosyntaxique. (UDPipe)
-       2°) Transformation en motifs
-       3°) Wordcloud
-       4°) TF-IDF
-       5°) AFC
-       6°) Calcul de spécificités
-       7°) Barycentres et pourcentage d'apparition
-       8°) Statistiques générales
-       9°) Retour aux textes

La diffusion de cette chaine sous un paquet R serait un apport
important pour les chercheurs en stylométrie. Un premier travail
consistera donc à nettoyer le code et à le rendre portable et
partageable sous la forme d'un paquet R.

Au-delà, et suivant la durée du stage, diverses extensions
sont envisageables, comme une extension à d'autres langues,
une réflexion sur les moyens de visualisation des résultats,
une amélioration des calculs statistiques, et la recherche d'une
complémentarité avec d'autres scripts (par exemple stylo).


* Modalités

Stage de 3 à 6 mois (début entre février et avril 2021), de niveau M2,
conventionné et indemnisé suivant les règles en vigueur. Le stage se
déroulera dans les locaux du Lattice à Montrouge (métro Mairie de
Montrouge) ou en télétravail, suivant les mesures sanitaires en vigueur
durant le stage. Si le stage est effectué en télétravail, un suivi
régulier se fera en visio.

* Profil recherché.

Étudiant-e en informatique ou en linguistique-informatique avec des
connaissances solides en programmation.

- Bonne connaissance du langage R indispensable
- Compétences en traitement automatique des langues

* Comment candidater ?

Envoyer avant le 15 janvier 2021 par mail un CV et un relevé de
notes récent à thierry.poibeau@ens.psl.eu et
dominique.legallois@sorbonne-nouvelle.fr, ainsi que quelques mots
expliquant votre intérêt pour ce stage et détaillant
sommairement votre expérience de la programmation en R."
"653","2021-01-05","LIFO","Orléans","Laboratoire/Entreprise : LIFO
Durée : 6 mois (max)
Contact : mirian@univ-orleans.fr <mailto:mirian@univ-orleans.fr>

*Contexte :*
Stage financé par la fédération ICVL (Informatique Centre
Val de Loire)

Calendrier du recrutement:

+ Date limite des candidatures: 3 janvier
+ Éventuelles auditions: 6 janvier
+ Notifications: 7 janvier

Les candidatures (CV et les relevés de notes) sont à envoyer, a
u plus
tôt, aux encandrants (voir emails contacts)

Contacts : nhiot@ennov.com, anne-lyse.minard@univ-orleans.fr,
mirian@univ-orleans.fr, agata.savary@univ-tours.fr

*Sujet :*
Le stage proposé portera sur l'extraction des relations et
l'instanciation de graphes, et s'inscrira dans la continuité d'un
stage de M2 réalisé au 1er semestre 2020. Ce dernier a conduit au
développement d'un système de reconnaissances des entités médicales
et de la réalisation d'une première étude de la problématique de
l'extraction des relations.

Titre du stage : Construction d'un graphe de connaissances à partir des
relations extraites dans des cas cliniques

Disciplines scientifiques : Traitement Automatique des Langues ;
Apprentissage et Bases de Données

Encadrants : LIFO (Nicolas Hiot), LLL (Anne-Lyse Minard), LIFO (Mirian
Halfeld Ferrari Alves), LIFAT (Agata Savary)

Type de stage : M2, stage de 6 mois, financé par la fédération ICVL

Projet dans lequel s'inscrit le stage :
Le groupe de travail DOING@DIAMS se concentre sur la question de la
transformation des informations (obtenues dans des documents ou des
bases de données plus au moins structurées) en connaissance. Il réunit
des chercheurs des laboratoires LLL, LIFO et LIFAT, spécialisés en
Traitement Automatique des Langues, Apprentissage et Bases de Données.
À partir d'un schéma représentant des connaissances expertes, nous
cherchons à extraire les informations de textes permettant d'instancier
le graphe. L'approche visée consiste en l'extraction d'entités du
domaine et de relations entre entités, relations représentant les arcs
du graphe. Les entités comme les relations devront être typées,
normalisées et associées aux noeuds du graphe. Les informations
extraites seront ensuite transformées en base de connaissance. Elle
devrait permettre d'assurer la qualité des informations, d'offrir des
méthodes permettant l'interrogation et l'analyse des informations et
d'offrir des mécanismes pour assurer l'évolution cohérente des
connaissances.

Le stage proposé portera sur l'extraction des relations et
l'instanciation de graphes, et s'inscrira dans la continuité d'un stage
de M2 réalisé au 1 er semestre 2020. Ce dernier a conduit au
développement d'un système de reconnaissances des entités médicales
([1]) et de la réalisation d'une première étude de la problématique de
l'extraction des relations.

Descriptif du stage :
Les objectifs du stage seront de continuer le développement d'une
chaîne de traitements pour des textes du domaine médical en français
(corpus de cas cliniques utilisé pour la campagne DEFT 2020) qui
permettra d'extraire des relations entre les entités, les typer et de
représenter ces informations sous forme de graphes grâce notamment à la
normalisation des entités. L'extraction des relations reposera sur des
règles (ou patrons) qui utiliseront l'analyse syntaxique (en
constituants [2] ou en dépendances [3]) et/ou en rôles sémantiques [4].
Les perspectives à la suite du stage seront la généralisation du
système à d'autres cas d'usage.Nicolas Hiot, doctorant au LIFO, sera
l'encadrant principal de ce stage. Le LLL et le LIFAT seront des
personnes ressources pour la partie extraction d'information, en
particulier Anne-Lyse Minard (LLL) sur la problématique de l'extraction
de relations en domaine médical et Agata Savary du LIFAT sur les
questions de grammaires locales. Mirian Halfeld Ferrari Alves du LIFO
encadrera le stage pour la partie définition du schéma/graphe et leur
instanciation en fonction des besoins pour la base de données.

Le stage sera décomposé en plusieurs étapes :
-   Réalisation d'un état de l'art des systèmes d'extraction de
    relations dans le domaine général et dans le domaine médical.
-   Annotation manuelle d'un sous-corpus pour l'évaluation du système
    et un affinage de la définition de la tâche.
-   Développement d'une méthode pour l'extraction des relations entre
    les entités d'intérêts et leur typage.
-   Développement d'une méthode pour représenter les relations
    extraites entre entités sous forme de graphes.

Compétences requises :
-   Étudiants de master en TAL ou master en informatique avec un
    intérêt fort pour le TAL
-   Bonne connaissance de python et des méthodes de TAL (parsing,
    text mining, etc.)
-   Capacité de travail en équipe pluridisciplinaire

Références :
[1] Anne-Lyse Minard, Andréane Roques, Nicolas Hiot, Mirian Halfeld
    Ferrari Alves, Agata Savary. DOING@DEFT : cascade de CRF pour
    l'annotation d'entités cliniques imbriquées. DEFT 2020 (workshop de
    TALN 2020).
[2] Anne-Lyse Minard, Anne-Laure Ligozat, Brigitte Grau, Apport de la
    syntaxe pour l'extraction de relations en domaine médical.
    TALN 2011.
[3] Brahim Batouche, Claire Gardent and Anne Monceaux. Parsing Text
    into RDF graphs. SEPLN 2015.
[4] Piek Vossen, Rodrigo Agerri, Itziar Aldabe, Agata Cybulska,
    Marieke van Erp, Antske Fokkens, Egoitz Laparra, Anne-Lyse Minard,
    Alessio P. Aprosio, German Rigau, Marco Rospocher, and Roxane Segers.
    Newsreader: Using knowledge resources in a cross-lingual reading
    machine to generate more knowledge from massive streams of news.
    In knowledge-based systems, elsevier, 2016.

CANDIDATURES : envoyer un CV et les relevés de notes aux encadrants
(via email)

Contacts : nhiot@ennov.com, anne-lyse.minard@univ-orleans.fr,
mirian@univ-orleans.fr, agata.savary@univ-tours.fr

*Adresse d'emploi :*
LIFO - Batiment IIIA - Rue Léonard de Vinci - BP6759
45067 Orléans Cedex 2

**"
"654","2021-01-06","LIFAT / LIFO","Blois ou Orléans","Analyse des propriétés des mesures de qualité pour la coréférence
================================================
## Contexte scientifique

Le Laboratoire d'Informatique Fondamentale de l'Université d'Orléans
(LIFO) et le Laboratoire d'Informatique de l'Université de Tours
(LIFAT) proposent un stage dans le cadre d'un financement de la
fédération ICVL (Informatique Centre Val de Loire). Ce stage fait suite
à une collaboration déjà initiée par le passé sur l'étude des
propriétés théoriques et statistiques des mesures de qualité des
systèmes de détection des coréférences.

La détection des coréférences est une tâche classique de traitement
automatique des langues naturelles (TALN). Elle consiste à identifier
les chaînes de référence dans un texte, c'est-à-dire les suites de
mentions d'une même entité ou concept. Les techniques d'apprentissage
automatique sont aujourd'hui dominantes dans ce domaine et leurs
performances ont connu un saut quantitatif notable au cours de ces
dernières années. Les laboratoires LIFAT et LIFO ont d'ailleurs
développé un système de ce type pouvant travailler sur tout type de
document textuel.

Cependant, des travaux récents, tels que ceux et Chai et al. (2020)
suggèrent que ces performances ne sont pas nécessairement dues
à une meilleure compréhension du discours par les systèmes
automatiques, mais pourraient être en partie le résultat de
l'exploitation d'artefacts statistiques par les formidables outils de
reconnaissance de motifs que sont les réseaux de neurones profonds.
Dans ce contexte, les limites - soupçonnées depuis longtemps - des
mesures de qualité existantes de ces systèmes deviennent
problématiques, l'évaluation *qualitative* des systèmes semble refléter
de moins leurs capacités réelles aussi bien comme outils à part entière
que comme briques dans des chaînes de traitements.

Nos premiers travaux à ce sujet, concentrés sur les propriétés
intrinsèques de ces métriques, nous ont permis de mettre en lumière le
caractère contre-intuitif de certaines de leurs propriétés théoriques
et a donné lieu à une publication en 2020 (Lion-Bouton et al. 2020) et
à initier des expériences de comparaisons entre les jugements apportés
par ces métriques et les jugements d'annotateurs humains.

Le sujet proposé ici consiste à poursuivre ces travaux - notamment par
la poursuite de comparaisons entre mesures quantitatives, tests
d'évaluation qualitative et jugements humains - et à les compléter par
une étude des propriétés des métriques dans des cas concrets, notamment
en étudiant de façon systématique leur réponse à des perturbations
aléatoires de données réelles, dans l'esprit de travaux comme ceux de
Bregeon et al. (2019).

## Résultats attendus

-   Établissement d'un jeu de tests, issu de données réelles mais
    permettant d'évaluer précisément des systèmes automatiques de
    détection des coréférences en fonction de leurs réponses à
    différents phénomènes.
-   Comparaison du comportement de systèmes existants sur ce jeu de
    test avec leurs performances quantitatives rapportées et avec le
    jugement porté par des humains sur la cohérence de leurs sorties.
-   Construction d'un système automatique de perturbation de données
    annotées en chaînes de coréférences et étude des réponses des
    métriques à différents types et différentes intensités de
    perturbation.

## Profil recherché

Ce stage demande des capacités de recherche et développement relevant
d'un niveau d'études de fin de M2 en informatique ou en traitement
automatique du langage.
Mais avant tout, on attend de la personne recrutée qu'elle présente un
intérêt marqué pour la recherche, qu'elle ait une autonomie et un sens
critique développés, et qu'elle ne soit pas rétive à considérer les
notions de statistique nécessaires à cette étude - bien que ces notions
ne soient pas pré-requises.
Ce stage est donc proposé à des étudiants qui disposeraient d'un bon
niveau académique, d'une curiosité scientifique affirmée et qui
envisagent une orientation professionnelle future dans le domaine de la
recherche.

##  Date et lieu de stage

La personne recrutée travaillera soit au sein du laboratoire LIFAT
(antenne universitaire de Blois) dans l'équipe BDTLN
(http://li.univ-tours.fr/equipes/equipe-bdtln-198022.kjsp) soit au sein
du LIFO, dans l'équipe Contraintes et Apprentissage
(http://www.univ-orleans.fr/lifo/equipes/CA/), et en collaboration avec
Loïc Grobol (laboratoire Lattice de l'École Normale Supérieure et
Laboratoire de Linguistique Formelle de l'Université de Paris).
En outre, un séminaire de recherche régulier autour de la langue
naturelle (RITUEL) est organisé entre les centres de recherche des
universités de Tours (LI) et Orléans (LIFO, LLL). La personne recrutée
sera invitée à y participer si elle le souhaite.

Compte tenu du contexte sanitaire, des arrangements de travail à
distance sont envisageables.

## Durée et période de stage

La durée du stage sera de 5 mois. Début de stage à négocier avec la
personne sélectionnée (mi-février 2021 au plus tard).

## Rémunération

La personne recrutée recevra une gratification mensuelle correspondant
à la réglementation, à savoir 15% du plafond horaire de la sécurité
sociale. À titre d'exemple, cette gratification représente un montant
de 554 ¤ pour un mois avec 22 jours ouvrés, et 600,60¤ pour un mois
avec seulement 20 jours ouvrés (jours fériés, par exemple). Pourra
également se rajouter une indemnité de transports en commun
correspondant à 50% d'un abonnement mensuel étudiant. La personne
recrutée participera aux réunions de l'équipe projet. Les frais de
mission induits par ces déplacements seront remboursés.

## Contact - Dépôts de candidature

-   Anaïs Lefeuvre-Halftermeyer
    (anais.halftermeyer@univ-orleans.fr) LIFO (U. Orléans)
-   Jean-Yves Antoine (Jean-Yves.Antoine@univ-tours.fr) LIFAT
    (U. Tours)
-   Loïc Grobol (loic.grobol@ens.psl.eu) Lattice (ENS) et LLF
    (U. Paris)
-   Sylvie Billot (sylvie.billot@univ-orleans.fr ) LIFO (U. Orléans)

Dépôt des candidatures par courrier électronique auprès de Jean-Yves
Antoine, Anaïs Lefeuvre-Halftermeyer, Loïc Grobol et Sylvie Billot,
avant le 10 janvier 2021, délai de rigueur. Merci de déposer :

- Un CV détaillé de vos activités passées
- Une lettre de motivation
- Vos relevés de notes des deux dernières années d'études

Le cas échéant une lecture critique d'article scientifique pourront
être demandés pour la sélection.

## Références

-   Chai, Haixia, Wei Zhao, Steffen Eger, et Michael Strube. 2020.
    « Evaluation of Coreference Resolution Systems Under Adversarial
    Attacks ». In Proceedings of the First Workshop on Computational
    Approaches to Discourse, 154 59. Association for Computational
    Linguistics. https://www.aclweb.org/anthology/2020.codi-1.16.
-   Grobol, Loïc. 2020. « Coreference Resolution for Spoken French ».
    PhD Thesis, Paris, France: Université Sorbonne Nouvelle.
    https://hal.archives-ouvertes.fr/tel-02928209.
-   Lion-Bouton, Adam, Loïc Grobol, Jean-Yves Antoine, Sylvie Billot,
    et Anaïs Lefeuvre-Halftermeyer. 2020. « Comment arpenter sans
    mètre : les scores de résolution de chaînes de coréférences
    sont-ils des métriques ? » In Actes du 2e atelier Éthique et
    TRaitemeNt Automatique des Langues (ETeRNAL), édité par Gilles
    Adda, Maxime Amblard, et Karën Fort, 10 18. Association pour le
    Traitement Automatique des Langues.
    https://hal.archives-ouvertes.fr/hal-02750222.
-   Moosavi, Nafise Sadat. 2020. « Robustness in Coreference
    Resolution ». PhD Thesis, Heidelberg, Deutschland: Universität
    Heildelberg. heiDOK. http://www.ub.uni-heidelberg.de/archiv/27919.
-   Bregeon, Dany, Jean-Yves Antoine, Jeanne Villaneau, et Anaïs
    Lefeuvre-Halftermeyer. 2019. « Redonner du sens à l'accord
    interannotateurs : vers une interprétation des mesures d'accord en
    termes de reproductibilité de l'annotation ». Traitement
    Automatique des Langues 60 (2): 23.
-   Recasens, Marta, et Eduard Hovy. 2011. « BLANC: Implementing the
    Rand Index for Coreference Evaluation ». Natural Language
    Engineering 17 (4): 485 510.
    https://doi.org/10.1017/S135132491000029X."
"655","2021-01-21","ATILF","Nancy","Offre de stage de 5 mois à l'ATILF en TAL

*** Titre ***
Levée d'ambiguïté lexicale à partir d'un lexique sémantique

*** Contexte et objectifs ***
Les ressources linguistiques sont des composants essentiels du
traitement automatique des langues (TAL). En particulier, les corpus
annotés sont sources d'exemples pour apprendre des modèles pour
résoudre différentes tâches. Les modèles état-de-l'art en TAL reposent
généralement sur des réseaux de neurones appris sur des corpus annotés,
complémentés de plongements lexicaux eux-mêmes pré-entrainés sur de
grandes masses textuelles brutes (ex. Le et al. 2020, Martin et al 2020
pour le français). Les ressources lexicales sont très peu exploitées
bien qu'elles puissent jouer un rôle complémentaire grâce à leur
couverture et la finesse de leurs descriptions linguistiques.
Ce sujet de stage est dédié à la tâche de levée d'ambiguïté lexicale
avec pour objectif de combiner ressources lexicales et données
textuelles annotées. La levée d'ambiguité lexicale est l'un des défis
majeurs du TAL et consiste à prédire le sens d'un mot cible dans un
contexte donné. Dans ce projet, nous nous focalisons sur les verbes.
Tout en nous appuyant sur des travaux récents reposant sur des méthodes
supervisées (Segonne et al 2019), nous souhaitons exploiter le lexique
sémantique de verbes VerbNet (Kipper 2006) ou son équivalent français
VerbNet (Danlos et al. 2016) pour bénéficier de son contenu
linguistique fin: ex. structures syntaxiques et sémantiques, classes
sémantiques, exemples d'usages pour les différentes entrées.

*** Tâches à réaliser ***
-   Annotation manuelle ciblée et limitée d'un petit corpus pour un
    sous-ensemble de verbes
-   Encodage du lexique
-   Développement et évaluation d'algorithmes à base d'heuristiques
    (ex. Aguirre et al. 2014)
-   Développement et évaluation de méthodes avancées:
    ex. apprentissage supervisé, intégration de plongements lexicaux et
    de plongements de graphes

*** Informations complémentaires ***
Durée: 5 mois
Lieu: laboratoire Analyse et Traitement Informatique de la Langue
    Française (ATILF), Nancy
Encadrement: Mathieu Constant (ATILF), Bruno Guillaume (LORIA), Karen
    Fort (Univ. Sorbonne)
Formation requise: niveau master 2 de traitement automatique des
    langues ou de linguistique informatique
Gratification réglementaire

Contacts: Mathieu.Constant@univ-lorraine.fr, Bruno.Guillaume@loria.fr,
karen.fort@sorbonne-universite.fr

Candidature:
Les personnes intéressées doivent envoyer un CV et une lettre
de motivation avant le 31 janvier 2021 aux personnes mentionnées
ci-dessus.


*** Références***

E. Agirre, O. López de Lacalle, and A. Soroa (2014). Random walks
for knowledge-based word sense disambiguation. Computational
Linguistics, 40(1):57-84.

K. Kipper Schuler (2006). VerbNet: A Broad-Coverage, Comprehensive Verb
Lexicon. PhD thesis, University of Pennsylvania.

L. Danlos, Q. Pradet, L. Barque, T. Nakamura, and M. Constant (2016).
Un Verbenet du français. Traitement Automatique des Langues, 57(1):25.


H. Le, L. Vial, J. Frej, V. Segonne, M. Coavoux, B. Lecouteux, A.
Allauzen, B. Crabbé, L. Besacier, D. Schwab (2020). FlauBERT:
Unsupervised Language Model Pre-training for French. Proceedings of the
12th Language Resources and Evaluation Conference.

L. Martin, B. Muller, P. J. Ortiz Suárez, Y. Dupont, L. Romary, E.
de la Clergerie, D. Seddah, B. Sagot (2020). CamemBERT: a Tasty French
Language Model. Profeedings of ACL 2020 - 58th Annual Meeting of the
Association for Computational Linguistics.

V. Segonne, M. Candito, B. Crabbé (2019), Using Wiktionary as a
resource for WSD : the case of French verb. Proceedings of the 13th
International Conference on Computational Semantics."
"656","2021-01-21","INRIA","Paris","Stage 1: construction d'un vocabulaire de brevets à l'aide du deep
learning sur très grands corpus

Création d'un vocabulaire technique multimots par croisement du
vocabulaire extrait de Wikipédia et d'autres ressources scientifiques
avec un corpus de brevets.


- Lire  https://stackoverflow.com/questions/61218518/count-frequency-of-multi-word-terms-in-large-texts-with-python/61293305#61293305

- Extraction de phrases définitoires, analyse syntaxique, extraction
  de termes et d'hyponymes par simplification de syntagmes. Lire
  https://towardsdatascience.com/unsupervised-synonym-harvesting-d592eaaf3c15

- Ajout de vocabulaire multi-mots par fréquence et entropie.

- Utilisation des informations portant sur les classes de brevets
  (p. ex. CPC) pour la définition d'un vocabulaire dépendant du
  domaine technique.

- Compléter le vocabulaire à l'aide de plongements multi-mots

- Développement d'une taxonomie de terminologie

- Intégration de la taxonomie dans un API Django

L'essentiel pour réussir

- Il est important d'être opérationnel en python et outils TAL
  d'apprentissage profond (Spacy, Pytorch, ...)

- Aussi : Vous êtes passionné(e) par l'étude de la langue et par le
  traitement automatique de la langue

Début du contrat idéal : début mars.

https://qatent.com/jobs/intern-1/"
"657","2021-01-21","INRIA","Paris","Stage 2 : Paraphrases technologiques par apprentissage profond

Stage 2: paraphrases spécifiques aux brevets (environ 6 mois)


- Entraînement d'un système de génération de paraphrases spécifiques
  au corpus des brevets par apprentissage croisé avec des corpus
  génériques de paraphrases.

- Spécialisation du modèle de langage par domaine technologique
  (e.g. tels que définis par les sections CPC/IPC).

- Évaluation de mesures de similarités entre phrases.

- Utilisation des ontologies (Wordnet, stage 1, ...) pour obtenir une
  mesure / ranking de spécificités des paraphrases proposées.

- Intégration dans une API Django.

L'essentiel pour réussir

- Il est important d'être opérationnel en python et outils TAL
  d'apprentissage profond (NLTK, Spacy, Pytorch, ...)

- Aussi : Vous êtes passionné(e) par l'étude de la langue et par le
  traitement automatique de la langue

Début du contrat idéal : début mars.


FAQ


- Sur quelles données entraîner ?

Lire : Aaditya Prakash, Sadid A Hasan, Kathy Lee, Vivek Datla, Ashequl
Qadir, Joey Liu, and Oladimeji Farri. 2016. Neural paraphrase
generation with stacked residual lstm
networks. arXiv:1610.03098. https://arxiv.org/abs/1610.03098 (MSCOCO,
Quora Duplicates, WikiAnswers Duplicates, PPDB)


- Quel type de modèle neuronal utiliser ?

lire :
 https://proceedings.neurips.cc/paper/2019/file/5e2b66750529d8ae895ad2591118466f-Paper.pdf
 https://opendata.stackexchange.com/questions/6094/paraphrase-data-sets

V. aussi: Wang, S., Gupta, R., Chang, N. and Baldridge, J., 2019,
July. A task in a suit and a tie: paraphrase generation with semantic
augmentation. In Proceedings of the AAAI Conference on Artificial
Intelligence (Vol. 33,
pp. 7176-7183). http://suwangcompling.com/wp-content/uploads/2018/10/AAAI_2019___Draft_3-1.pdf


Postuler :
https://qatent.com/jobs/intern-2/"
"658","2021-01-21","INRIA","Paris","Stage en legaltech: Construction d'une base de données légale pour brevets

Le startup studio d'Inria propose un stage pour le projet qatent: Il
s'agit de constituer un corpus de la jurisprudence des brevets et le
préparer pour y identifier les termes spécifiques au langage des
brevets. Vous serez assisté par un Conseil en Propriété Industrielle,
qui vous guidera et vous fournira les textes légaux.

mots clés : patent-NER


- Constitution d'une base de jurisprudence annotée de l'Office
  Européen des Brevets


- Identification dans les textes des références à la jurisprudence et
  des mentions aux articles/règles de la Convention Européenne des
  Brevets (Article 56 EPC, A. 56, Art. 56 CBE...)


- Identifier les mentions aux jurisprudences (T 00/641 = ""COMVIK"",
  etc...)


- Identifier les références aux situations de droit (""inventive step /
  non-obviousness / inventiveness "", ""novelty"",
  ""clarity/clear/unclear/vague"", ""technical effect"", ""objective
  problem"", ""problem-solution"", ""added subject-matter"", etc...)


- Utiliser des outils spécifiques pour les brevets (patent-NER) pour
  établir une relation entre jurisprudence et Directives OEB, voir
  https://www.epo.org/law-practice/legal-texts/html/caselaw/2019/f/index.htm


Postuler :
https://qatent.com/jobs/intern-3/"
"659","2021-01-21","Akio","Paris ou Montpellier","Stage: Analyste / linguiste pour l'interprétation des données de
la relation client

Descriptif:

Le sujet proposé traite de l'analyse et de la qualification de verbatim
en français pour le compte d'un éditeur de logiciel français dans le
domaine de la relation client.


Description du poste:

L'objectif premier du stage est d'analyser et d'annoter des verbatim en
français à partir d'un nouvel outil spécifiquement créé auquel vous
serez formé.
Il s'agit d'annoter des textes de sources diverses (emails, avis
clients, textes en provenance des réseaux sociaux ...) afin de
déterminer pour chaque segment le sentiment associé : positif, négatif
ou neutre.

L'autre objectif est de contribuer à l'annotation sémantique et
l'exploration textuelle des données afin d'=EAtre en mesure d'en
détecter les topics relatifs à la relation client principalement dans
le domaine du E-commerce et des Mutuelles / Assurances.

Vous serez intégré au p=F4le linguiste et travaillerez au sein
d'une équipe dynamique qui met en oeuvre les technologies les plus
récentes dans le domaine NLP.


Profil recherché:
-   Niveau Licence minimum en linguistique ou en traitement automatique
    du langage
-   Très bon niveau en français
-   Grande rigueur et esprit logique
-   Maîtrise des outils informatiques / compétences en programmation
    non requises
-   Une langue parlée couramment serait un plus : espagnol, italien,
    anglais ou allemand

Durée:
6 mois

Date début de stage
ASAP

Lieu:
Le stage pourra se dérouler sur notre site de Paris (75010) ou
Montpellier (quartier Antigone)


Akio
Equipe: traitement automatique de la langue.
43 rue de Dunkerque, 75010 Paris.
www.akio.com<http://www.akio.com/>


Gratification:
Selon les règles en vigueur avec participation aux frais de
transports en commun et repas.

Encadrement:
Le stage sera encadré par Lynda Ould Younes

Candidature:
Merci d'envoyer un CV à srumeur@akio.com et louldyounes@akio.com
accompagné des notes de l'année universitaire en cours et de celles
de l'année dernière."
"660","2021-01-21","LISN","Orsay","Internship for Last Year Engineer or Master 2 Students

Keywords: Machine Learning, Diarization, Digital Humanities, Political
Speech, Prosody, Expressive Speech


Context

This internship is part of the Ontology and Tools for the Annotation of
Political Speech (OOPAIP), a transdisciplinary project funded under the
DIM-STCN (Text Sciences and New Knowledge,
http://www.dim-humanites-numeriques.fr/en/) by the Regional Council of
Ile de France. The project is carried out by the European Center for
Sociology and Political Science (CESSP, https://www.cessp.cnrs.fr/) of
the University of Paris 1 Panthéon-Sorbonne, the National
Audiovisual Institute (INA, https://www.ina.fr/), and the LISN
(https://www.limsi.fr/en/). Its objective is to design new approaches
to develop detailed, qualitative, and quantitative analyzes of
political speech in the French media. Part of the project concerns the
study of the dynamics of conflicting interactions in interviews and
political debates, which requires a detailed description and a large
corpus to allow for the models' generalization. Some of the main
challenges concern the performance of speaker and speech style
segmentation, e.g., improving the segmentation accuracy, detecting
superimposed speech, measuring vocal effort and other expressive
elements.


Objectives

The main objective of the internship is to improve the automatic
segmentation of political interviews. In this context, we will be
particularly interested in the detection of ""hubbub"" (strong and
prolonged overlapped speech). More precisely, we would like to extract
features from the speech signal (Eyben, 2015) correlated with the level
of conflictual content in the exchanges, based, for example, on the
arousal level in the speaker's voice-intermediate level between the
speech signal analysis and the expressivity description (Rilliard,
2018)-or vocal effort (Lienard, 2019).

The internship will initially be based on two corpora of 30 political
interviews manually annotated in speech turns and speech acts-within
the framework of the OOPAIP project. It will begin with a state of the
art review of speech diarization  and overlapped speech detection
(chowdhury, 2019). The aim will then be to propose solutions based on
recent frameworks (Bredin, 2020) to improve the precise localization of
speaking segments, in particular when the frequency of speaker changes
is high.

In the second part of the internship, we will look at a more detailed
measurement and prediction of the conflicting level of exchanges. We
will search for the most relevant features to describe the conflicting
level and by adapting or developing a neural network architecture for
its modeling.

The programming language used for this internship will be Python. The
candidate will have access to the LISN computing resources (servers and
clusters with recent generation GPUs).


Publications

Depending on the degree of maturity of the work carried out, we expect
the applicant to:

*   Distribute the tools produced under an open-source license

*   Write a scientific publication


Conditions

The internship will take place over a period of 4 to 6 months at the
LISN (formerly LIMSI) in the Spoken Language Processing (TLP) group.
The laboratory is located near the ""plateau de Saclay"", university
campus building 507, rue du Belvédère, 91400 Orsay. The candidate
will be supervised by Marc Evrard (marc.evrard@lisn.upsaclay.fr).
Allowance under the official standards
(https://www.service-public.fr/professionnels-entreprises/vosdroits/F32131).


Applicant profile

*   Student in the last year of a 5-years diploma in the field of
    computer science (AI is a plus)

*   Proficiency in Python language and experience in using ML libraries
    (Scikit-Learn, TensorFlow, PyTorch)

*   Strong interest in digital humanities and political science in
    particular

*   Experience in automatic speech processing is preferred

*   Ability to carry out a bibliographic study from scientific articles
    written in English

To apply: Send an email to marc.evrard@lisn.upsaclay.fr including a
résumé and a cover letter.


Bibliography

Bredin, H., et al. (2020). Pyannote.audio: neural building blocks for
speaker diarization. In ICASSP 2020 (pp. 7124-7128).

Chowdhury, S. A., Stepanov, E. A., Danieli, M., Riccardi, G. (2019).
""Automatic classification of speech overlaps: Feature
representation and algorithms"", Computer Speech & Language, vol.
55, pp.145-167.

Eyben, F., Scherer, K. R., et al. (2015). The Geneva minimalistic
acoustic parameter set (GeMAPS) for voice research and affective
computing. IEEE transactions on affective computing, 7(2), 190-202.

Liénard, J.-S. ""Quantifying vocal effort from the shape of
the one-third octave long-term-average spectrum of speech"" J.
Acoust. Soc. Am. 146 (4), Oc-tober 2019.

OOPAIP (Ontologie et outil pour l'annotation des interventions
politiques), DIM STCN (Sciences du Texte et connaissances nouvelles),
Conseil régional d'Ile de France,  url:
http://www.dim-humanites-numeriques.fr/projets/oopaip-ontologie-et-outils-pour-lannotation-des-interventions-politiques/

Rilliard, A., d'Alessandro, C & Evrard, M. (2018). Paradigmatic
variation of vowels in expressive speech: Acoustic description and
dimensional analysis. The Journal of the Acoustical Society of America,
143(1), 109-122."
